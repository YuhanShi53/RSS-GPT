<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>科学空间|Scientific Spaces</title>
<link>https://kexue.fm/</link>

<item>
<title>利用Bias自由度优化MoE模型以提升Token分配效率</title>
<link>https://spaces.ac.cn/archives/10815</link>
<guid>https://spaces.ac.cn/archives/10815</guid>
<content:encoded><![CDATA[

  <div><p style=color:gray;>本文探讨如何利用Bias额外自由度优化MoE模型的Token计算资源分配。</p><br><br><p><strong>摘要：</strong> 在本文中，我们将深入探讨如何利用Loss-Free方案中引入的Bias项的冗余自由度，优化Mixture of Experts（MoE）模型的Token分配方法。传统的MoE方法仅为每个Token选择最匹配的$k$个专家进行计算，这种方式虽然增加了模型参数，但在计算效率上却存在不足。我们指出，不同Token的计算难度并不相同，因此应根据Token的难度合理分配计算资源：对于难度大的Token，分配更多的计算资源，而对于简单的Token，分配的资源则相应减少。通过利用Bias的额外自由度，可以实现更合理的资源分配，从而在有限的资源下最大化模型的效果。</p><br><br><p><em>使用 gpt-4o-mini 生成 </em></p><a href=https://spaces.ac.cn/archives/10815 target="_blank">查看原文</a></div>

]]></content:encoded>
<pubDate>Fri, 28 Mar 2025 19:13:00 +0800</pubDate>
<pubDate>Fri, 28 Mar 2025 19:13:00 +0800</pubDate>
</item>

<item>
<title>谱条件：高阶muP的直观与简化</title>
<link>https://spaces.ac.cn/archives/10795</link>
<guid>https://spaces.ac.cn/archives/10795</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文介绍了谱条件，作为muP的高阶版本，更加直观简洁。</p><br /><br /><p><strong>摘要：</strong> 文章讨论了谱条件这一新概念，相较于maximal update parametrization（muP），其推导过程更为直观和简化。谱条件基于谱范数的基本不等式，能够提供比muP更丰富的结果。值得注意的是，谱条件不仅是对muP的一种高阶理解，也为相关领域的研究提供了新视角。本篇文章在相对完整地探讨muP的基础上，进一步引入谱条件，展示其潜在的应用与优势，强化了对于损失增量与特征变化之间关系的认识。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://spaces.ac.cn/archives/10795" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 24 Mar 2025 11:21:00 +0800</pubDate>
</item>
<item>
<title>Maximal Update Parametrization (muP) 的探索与应用</title>
<link>https://spaces.ac.cn/archives/10770</link>
<guid>https://spaces.ac.cn/archives/10770</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文探讨了muP在大型LLM超参数搜索中的应用。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了Maximal Update Parametrization（muP）及其在大型语言模型（LLM）训练中的应用。随着LLM训练的普及，muP逐渐成为了优化超参数的有效工具。由于完整训练大型LLM的高成本，研究者们提出在小模型上进行超参数搜索，再将最佳结果迁移至大模型的方法。然而，成功实现这一目标并不简单，需要理解超参数与模型规模之间的缩放规律。尽管原论文表述较为晦涩，本文尝试以简明的方式重现其核心结论，旨在帮助读者更好地理解muP的实用性。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://spaces.ac.cn/archives/10770" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 17:36:00 +0800</pubDate>
</item>
<item>
<title>探讨MoE负载均衡的新方案：Loss-Free</title>
<link>https://spaces.ac.cn/archives/10757</link>
<guid>https://spaces.ac.cn/archives/10757</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文探讨了MoE的负载均衡问题及其新方案Loss-Free。</p><br /><br /><p><strong>摘要：</strong> 本文继续探讨混合专家模型（MoE）的负载均衡问题，重点介绍了名为“Loss-Free”的新方案。作者指出，以往使用Aux Loss促进负载均衡的方式虽然直观，但在权重调节方面存在明显缺陷。新的Loss-Free方案则通过改变分配思路，保持Router的现有打分结果，避免引入额外损失，从而实现有效的负载均衡。尽管该论文在众多开源作品中可能不算突出，但其方法的简便性、有效性和普适性使其在学术上具有潜在的深远影响。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://spaces.ac.cn/archives/10757" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 11:29:00 +0800</pubDate>
</item>
<item>
<title>Muon优化器技术报告解读</title>
<link>https://spaces.ac.cn/archives/10739</link>
<guid>https://spaces.ac.cn/archives/10739</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文分享了Muon优化器在大规模实践中的训练效率优势。</p><br /><br /><p><strong>摘要：</strong> 本文解读了我们最新的技术报告，重点介绍了Muon优化器在大规模实践中的应用及其与Adam优化器的对比。从实验结果显示，Muon在训练效率上相较于Adam具有将近2倍的优势，呈现出惊人的性能提升。文章分析了选择Muon作为优化方向的原因，并提供了从已调参的Adam切换至Muon的实用建议。同时，文章探讨了在模型规模扩大后，Muon与Adam的性能表现差异，分享了整个思考过程和实验结果，旨在为开发者提供参考和启示。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://spaces.ac.cn/archives/10739" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 15:25:00 +0800</pubDate>
</item>
<item>
<title>负载均衡在MoE模型中的重要性</title>
<link>https://spaces.ac.cn/archives/10735</link>
<guid>https://spaces.ac.cn/archives/10735</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文讨论了负载均衡在MoE模型中的关键作用及其实现细节。</p><br /><br /><p><strong>摘要：</strong> 在过去的讨论中，我们对MoE模型进行了几何诠释，并介绍了其基本形式。然而，训练一个有效的MoE模型不仅依赖于公式的推导，更需要关注模型训练中的负载均衡问题。负载均衡的核心在于确保每个Expert都充分参与计算，并尽可能均匀地分担任务，以提高算力的利用效率并发挥MoE的潜力。通过分析负载均衡的需求，本文强调了该问题的重要性，并为实现有效的MoE模型训练提供思路。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://spaces.ac.cn/archives/10735" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 11:18:00 +0800</pubDate>
</item>
<item>
<title>DDCM：有限集合下的去噪扩散模型</title>
<link>https://spaces.ac.cn/archives/10711</link>
<guid>https://spaces.ac.cn/archives/10711</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文介绍了一种新模型DDCM，通过有限集合改进去噪扩散模型的采样效果。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了一种新的模型DDCM（Denoising Diffusion Codebook Models），该模型将传统的去噪扩散概率模型（DDPM）的噪声采样限制在一个有限集合内，从而实现了独特的重构效果。通过这种方式，DDCM能够将样本编码为离散的ID序列并在无需额外训练的情况下进行重构，展现了与传统方法不同的奇妙效果。文章作者强调，这些操作都建立在已预训练的DDPM模型之上，为研究者提供了一个新的视角，以探索生成模型的新应用。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://spaces.ac.cn/archives/10711" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 14 Feb 2025 15:56:00 +0800</pubDate>
</item>
<item>
<title>深入探讨MoE架构及其应用</title>
<link>https://spaces.ac.cn/archives/10699</link>
<guid>https://spaces.ac.cn/archives/10699</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文探讨了MoE架构的流行原因及其解决的关键问题。</p><br /><br /><p><strong>摘要：</strong> 文章介绍了Mixture of Experts（MoE）架构在近年来的流行趋势，以及其优势和面临的挑战。尽管MoE的研究已有较长时间，但其应用起初并未受到广泛关注。近年来，尤其是GPT-4等主流模型开始使用MoE后，MoE架构逐渐引起重视。文章指出，MoE的显著优点在于其庞大的参数量和较低的训练、推理成本，但早期发展中的训练不稳定和负载不均衡问题一度制约了其普及。随着研究的深入，这些问题已得到有效解决，文章将进一步探讨这些改进和MoE架构的实际应用。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://spaces.ac.cn/archives/10699" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Sat, 08 Feb 2025 15:54:00 +0800</pubDate>
</item>
<item>
<title>三球交点问题的求解方法</title>
<link>https://spaces.ac.cn/archives/10684</link>
<guid>https://spaces.ac.cn/archives/10684</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文探讨了三球交点问题的求解流程及其应用背景。</p><br /><br /><p><strong>摘要：</strong> 三球交点问题是一个数学上明晰且具有实际应用的重要问题，特别是在卫星定位等领域。然而，笔者在研究时发现缺少可读性好的标准求解流程，尽管这一问题早已被解决。本文旨在填补这一空白，为读者提供清晰的求解步骤。设想三个球的方程，文中将详细探讨如何通过数学模型求解这三个球的交点坐标，以及在此背景下的相关应用。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://spaces.ac.cn/archives/10684" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 16:46:00 +0800</pubDate>
</item>
<item>
<title>流模型TARFLOW的崛起与发展</title>
<link>https://spaces.ac.cn/archives/10667</link>
<guid>https://spaces.ac.cn/archives/10667</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">TARFLOW模型的出现标志着流模型的再次崛起。 </p><br /><br /><p><strong>摘要：</strong> 本篇文章介绍了流模型系列“细水长flow”的发展历程，特别提到2018年OpenAI发布的流模型对当时流行的GAN模型造成的震撼。虽然Glow及其后期改进在生成效果上曾逊色于GAN并且在当前流行的扩散模型面前也显得不够强劲，但最近的一项研究提出了新的流模型TARFLOW，其在各类生成任务中的表现已接近当前的SOTA，实现了流模型的“满血”回归。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://spaces.ac.cn/archives/10667" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 17 Jan 2025 15:31:00 +0800</pubDate>
</item>
<item>
<title>CUR分解及其与插值分解的关系</title>
<link>https://spaces.ac.cn/archives/10662</link>
<guid>https://spaces.ac.cn/archives/10662</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">介绍CUR分解及其与插值分解的相似性与应用。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了CUR分解，它与插值分解（ID）相互关联，都是通过原始矩阵的行和列构建其近似。与ID仅使用行或列不同，CUR分解同时考虑了矩阵的行与列，呈现出更为全面的近似形态。我们回顾了CUR分解的基本定义，并提到了先前关于Nyström近似的讨论，实际上Nyström近似就是CUR分解。此外，CUR分解在降低交互式相似度模型的检索复杂度方面的应用也进行了简要回顾，强调了其在处理大规模数据时的重要性。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://spaces.ac.cn/archives/10662" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Sun, 12 Jan 2025 21:00:00 +0800</pubDate>
</item>
<item>
<title>梯度裁剪技术及其默认阈值的深层含义</title>
<link>https://spaces.ac.cn/archives/10657</link>
<guid>https://spaces.ac.cn/archives/10657</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">探讨梯度裁剪的原理及其默认阈值的潜在意义。</p><br /><br /><p><strong>摘要：</strong> 梯度裁剪是一种常用的技巧，用于使模型训练更加稳定。常见的做法是通过计算所有参数的梯度总模长来裁剪梯度，使得模长不超过预设阈值$	au$，而其方向保持不变。尽管现代模型参数规模从数百万到数百亿不等，但在许多情况下，$	au$的取值依然选择为1。这引发了对这种默认值的思考，是否是对其有效性的简单复制，还是反映了某些深刻的原理。这一观察提示我们在使用梯度裁剪时，需要关注参数规模对训练过程的影响及其潜在关系，以更好地理解和优化模型训练的稳定性与效果。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://spaces.ac.cn/archives/10657" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 02 Jan 2025 22:19:00 +0800</pubDate>
</item>
<item>
<title>谱范数优化：Muon优化器及新权重衰减的探索</title>
<link>https://spaces.ac.cn/archives/10648</link>
<guid>https://spaces.ac.cn/archives/10648</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文探讨Muon优化器与谱范数下的新权重衰减方法。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了一种名为“Muon”的新优化器，视其为在谱范数正则化下的最速梯度下降，从而揭示矩阵参数的优化方向。文章探讨了通过谱范数平方的梯度来构建新型权重衰减的可能性，并提出了相关的问题，例如谱范数的梯度形式及其在权重衰减设计中的应用。此外，基础回顾谱范数的定义及其在矩阵乘法中的重要性，以及与传统的F范数比较时所揭示的本质信号，旨在为优化算法的设计提供新的视角与思考。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://spaces.ac.cn/archives/10648" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 25 Dec 2024 11:17:00 +0800</pubDate>
</item>
<item>
<title>一致性模型在加速采样中的应用与理解</title>
<link>https://spaces.ac.cn/archives/10633</link>
<guid>https://spaces.ac.cn/archives/10633</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文探讨了一致性模型在扩散模型加速采样中的重要性和理解。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了一致性模型在扩散模型加速采样中的作用，尽管其理论深度可能不足，但实践中却成为了重要的参考点。随着对扩散模型加速采样进展的关注，一致性模型开始引起重视。文章指出，加速采样的Shortcut模型与其他模型的对比中，一致性模型不可忽视。以ReFlow为例，探讨了其训练目标与ODE式扩散的简单理解。本研究为进一步理解一致性模型提供了视角，为扩散模型的快速进展奠定了基础。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://spaces.ac.cn/archives/10633" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 18 Dec 2024 17:20:00 +0800</pubDate>
</item>
<item>
<title>扩散模型采样加速的新思路</title>
<link>https://spaces.ac.cn/archives/10617</link>
<guid>https://spaces.ac.cn/archives/10617</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出了一种新的扩散模型采样加速方法，可实现单步生成。</p><br /><br /><p><strong>摘要：</strong> 本文聚焦于扩散模型的采样加速，探讨了提高求解器效率与事后蒸馏的两种常见方案。然而，除了已有研究外，能够将生成步数降低至一步的有效方法较少。尽管SiD可以实现单步生成，但其需额外的蒸馏成本和复杂的交替训练过程，使得效果不尽如人意。为此，文章创新性地提出将生成步长作为扩散模型的条件输入，并在训练目标中加入直观的正则项，成功实现了可直接稳定训练的单步生成模型。这种方法简洁有效，展现了经典的突破性思想。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://spaces.ac.cn/archives/10617" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Sun, 15 Dec 2024 16:20:00 +0800</pubDate>
</item>
<item>
<title>新兴优化器的研究与AdamW的比较</title>
<link>https://spaces.ac.cn/archives/10592</link>
<guid>https://spaces.ac.cn/archives/10592</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文探讨了一种声称比AdamW更高效的新优化器。</p><br /><br /><p><strong>摘要：</strong> 随着大型语言模型（LLM）时代的到来，学术界对新优化器的研究兴趣有所减退，主要由于现有的AdamW已能满足大部分需求。对优化器进行重大改动需要巨大验证成本，因此目前的调整多为工业界根据经验对AdamW的小修小补。然而，近日在社交媒体上，一种新优化器引起关注，声称其效率超越AdamW，并且在原理上并不仅仅是对Adam的简单改进，而是深入探讨了向量与矩阵之间的差异。本文将分析这一新兴优化器的设计理念与实际表现，探讨其在学术和工业界的潜在影响。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://spaces.ac.cn/archives/10592" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 10 Dec 2024 11:26:00 +0800</pubDate>
</item>
<item>
<title>新视角下自适应学习率优化器的解析</title>
<link>https://spaces.ac.cn/archives/10588</link>
<guid>https://spaces.ac.cn/archives/10588</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">论文探讨自适应优化器与Hessian矩阵的新关联。</p><br /><br /><p><strong>摘要：</strong> 最近回顾了一篇Meta的论文，提出自适应学习率优化器如Adam和RMSprop可以被视为一种二阶的Newton法。这种新视角表明，梯度平方的滑动平均在某种程度上近似于Hessian矩阵的平方，这与传统的Hessian近似方式存在显著差异。牛顿法通过展开损失函数到二阶，以期更精准地寻找优化参数。文中详细阐述了优化目标和具体步骤，值得深入学习与思考。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://spaces.ac.cn/archives/10588" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 29 Nov 2024 23:25:00 +0800</pubDate>
</item>
<item>
<title>生成扩散模型漫谈（二十六）：基于恒等式的蒸馏（下）</title>
<link>https://spaces.ac.cn/archives/10567</link>
<guid>https://spaces.ac.cn/archives/10567</guid>
<content:encoded><![CDATA[
<p>继续回到我们的扩散系列。在<a href="https://kexue.fm/archives/10085" target="_blank">《生成扩散模型漫谈（二十五）：基于恒等式的蒸馏（上）》</a>中，我们介绍了SiD（Score identity Distillation），这是一种不需要真实数据、也不需要从教师模型采样的扩散模型蒸馏方案，其形式类似GAN，但有着比GAN更好的训练稳定性。</p><p>SiD的核心是通过恒等变换来为学生模型构建更好的损失函数，这一点是开创性的，同时也遗留了一些问题。比如，SiD对损失函数的恒等变换是不完全的，如果完全变换会如何？如何从理论上解释SiD引入的$\lambda$的必要性？上个月放出的<a href="https://arxiv.org/abs/2410.19310" target="_blank">《Flow Generator Matching》</a>（简称FGM）成功从更本质的梯度角度解释了$\lambda=0.5$的选择，而受到FGM启发，笔者则进一步发现了$\lambda = 1$的一种解释。</p><p>接下来我们将详细介绍SiD的上述理论进展。</p><p class="more"><a href="https://spaces.ac.cn/archives/10567" title="生成扩散模型漫谈（二十六）：基于恒等式的蒸馏（下）">[...]</a></p>
]]></content:encoded>
<pubDate>Fri, 22 Nov 2024 17:43:00 +0800</pubDate>
</item>
<item>
<title>探索Adam优化器中ε对学习率与Batch Size比例规律的影响</title>
<link>https://spaces.ac.cn/archives/10563</link>
<guid>https://spaces.ac.cn/archives/10563</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文探讨了ε在Adam优化器中对学习率及Batch Size缩放规律的影响。</p><br /><br /><p><strong>摘要：</strong> 本文讨论了使用SignSGD近似Adam优化器时，如何科学评估ε的影响。我们关注到，在低精度训练中，ε的取值通常偏大，这导致在训练过程中其值可能超过梯度平方的大小，从而影响Adam优化器的效果。文章进一步分析了这种情况对学习率与Batch Size之间的缩放规律的影响，并提供了一种计算方案，以帮助研究者更好地理解和利用这种关系。通过理论与实证结合，我们旨在为相关领域的研究提供参考与启发。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://spaces.ac.cn/archives/10563" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 18:01:00 +0800</pubDate>
</item>
<item>
<title>算力与Batch Size调整的关系研究</title>
<link>https://spaces.ac.cn/archives/10542</link>
<guid>https://spaces.ac.cn/archives/10542</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">探讨增加Batch Size时学习率如何调整以优化模型训练效率。</p><br /><br /><p><strong>摘要：</strong> 随着算力的迅速提升，越来越多的场景希望通过增加算力来缩短模型训练时间。但实际上，单纯增加算力并不总是能有效缩短训练时间，尤其是在Batch Size增大时。本文讨论了Batch Size与学习率之间的缩放法则，强调了在Batch Size增大时，如何合理调整学习率以维持训练效果并提升效率。研究表明，增大Batch Size后，梯度的准确性提高，使得可以适当增大学习率，但问题在于增大多少才是最佳选择。通过对这一领域的深入探讨，可以为优化模型训练提供理论依据和实际指导。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://spaces.ac.cn/archives/10542" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 14 Nov 2024 15:18:00 +0800</pubDate>
</item>
<item>
<title>SimVQ：一种简单有效的VQ训练技巧</title>
<link>https://spaces.ac.cn/archives/10519</link>
<guid>https://spaces.ac.cn/archives/10519</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文介绍了SimVQ，通过线性变换提升VQ的训练效果。</p><br /><br /><p><strong>摘要：</strong> 文章介绍了VQ（Vector Quantization）的新训练技巧SimVQ，该方法通过在编码表上增加一个简单的线性变换，从而显著改善VQ的梯度，解决了编码表利用率低和编码表坍缩的问题。与传统的VQ方法相比，SimVQ不仅提升了重构质量，还加速了收敛速度。实验证明，SimVQ能够有效提高编码表的利用率，使得模型在训练过程中表现更优。作者认为，这种过参数化的策略或许可以推广到其他需要优化的稀疏训练模型，比如MoE（Mixture of Experts）。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://spaces.ac.cn/archives/10519" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 06 Nov 2024 17:13:00 +0800</pubDate>
</item>
<item>
<title>插值分解（ID）：低秩矩阵近似的新方法</title>
<link>https://spaces.ac.cn/archives/10501</link>
<guid>https://spaces.ac.cn/archives/10501</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">插值分解通过关键列逼近原始矩阵，提高低秩近似的实用性。</p><br /><br /><p><strong>摘要：</strong> 插值分解（ID）是一种低秩分解方法，旨在从一个矩阵中找出若干关键列来逼近原始矩阵，使其具备特定结构。通过识别这些关键列，ID可视为一种有效的矩阵压缩与近似技术，这一点与奇异值分解（SVD）相似。尽管ID在学术界的知名度较低，但其已被内置在SciPy库中，显示了其实际应用的潜力。文章还提及了与ID相关的其他低秩近似方法，强调了寻找特定结构的低秩近似在数据处理与分析中的重要性。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://spaces.ac.cn/archives/10501" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 30 Oct 2024 10:43:00 +0800</pubDate>
</item>
<item>
<title>VQ的改进之道：旋转技巧的探索</title>
<link>https://spaces.ac.cn/archives/10489</link>
<guid>https://spaces.ac.cn/archives/10489</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文讨论了一种新旋转技巧，旨在改善VQ的编码效率和利用率问题。</p><br /><br /><p><strong>摘要：</strong> 随着多模态大语言模型（LLM）的迅速发展，矢量量化（VQ）作为一种重要的技术，日益受到关注。VQ能够将视觉及其他模态的数据统一到自回归生成框架中，然而自VQ提出以来，其理论进步相对缓慢，存在编码表坍缩和低利用率等问题尚未解决。因此，虽然如FSQ的替代方案应运而生，但VQ的改进仍然非常重要。最近，有研究提出了一种旋转技巧，声称能够有效改善VQ的一系列问题。通过本文，读者可以了解到这一新技巧如何在理论和实践中提供帮助，提升VQ的性能和应用范围。以及以VQ-VAE等为背景的VQ技术的发展历程，为后续研究提供了参考框架。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://spaces.ac.cn/archives/10489" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 24 Oct 2024 17:00:00 +0800</pubDate>
</item>
<item>
<title>Cool Papers Redirector 插件升级至 v0.2.0，功能更强大</title>
<link>https://spaces.ac.cn/archives/10480</link>
<guid>https://spaces.ac.cn/archives/10480</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">Cool Papers Redirector 插件 v0.2.0 更新，增加多个新功能与论文源，提升用户体验。</p><br /><br /><p><strong>摘要：</strong> 年初发布的 Cool Papers Redirector 插件在 Chrome 应用商店顺利升级至 v0.2.0，现提供了诸多新功能以提升用户体验。新版本的主要更新包括：右键菜单跳转选项现可在新标签页打开，支持同时访问多个论文 ID，兼容 PDF 页面。此外，新增了多个论文源如 arXiv、OpenReview、ACL、IJCAI 和 PMLR，并引入了在无法搜索到论文 ID 时转入站内搜索的功能。同时，在一些网站上还插入了快捷跳转链接，以便用户访问相关论文。这些改进极大地方便了用户获取 Kimi 对论文的理解，增强了插件的实用性。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://spaces.ac.cn/archives/10480" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 16 Oct 2024 17:52:00 +0800</pubDate>
</item>
<item>
<title>实现MathJax公式在移动端自适应缩放</title>
<link>https://spaces.ac.cn/archives/10474</link>
<guid>https://spaces.ac.cn/archives/10474</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">探索如何使MathJax公式在移动端自适应缩放，以优化显示效果。</p><br /><br /><p><strong>摘要：</strong> 随着MathJax的普及，网页上数学公式的显示逐渐标准化。然而，MathJax（及其竞品KaTeX）仍然面临数学公式在移动端适应性不足的挑战。许多在线数学文章在PC端显示良好，但在手机端却显得杂乱无章。为了解决这个问题，笔者探索了一种方法，使MathJax公式能够像图片一样自适应缩放，从而优化移动端的用户体验。这种方法有助于解决因公式长度超出网页宽度而导致的排版问题，尤其对于不适合自动换行的长公式。笔者建议通过调整HTML代码的字体大小，允许公式在不同设备上保持清晰可读的状态，为广大用户带来更好的阅读体验。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://spaces.ac.cn/archives/10474" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 15 Oct 2024 15:09:00 +0800</pubDate>
</item>
<item>
<title>基于CR近似的矩阵低秩近似研究</title>
<link>https://spaces.ac.cn/archives/10427</link>
<guid>https://spaces.ac.cn/archives/10427</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">探讨具有特定结构的低秩近似，聚焦CR近似以加速矩阵乘法。</p><br /><br /><p><strong>摘要：</strong> 在这篇文章中，我们探讨了具有特定结构的低秩近似方法，尤其关注CR近似（Column-Row Approximation）。相较于传统的奇异值分解（SVD）提供的最优$r$秩近似，CR近似在保持矩阵乘法效率的同时，增加了解释性与可用性。文章首先引入矩阵的最优$r$秩近似的定义，并讨论了基于SVD的低秩近似所面临的局限性。接着，我们深入分析了CR近似的构造方法及其在特定应用中的优势。通过公式化定义和相关理论背景的介绍，为后续的应用研究打下基础。该研究意义在于为寻求具有特定结构的矩阵近似方案提供新思路，特别是在需考虑非线性处理或可解释性的情况下，CR近似可以作为有效的工具。最后，文章还将展望CR近似在不同领域中的潜在应用。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://spaces.ac.cn/archives/10427" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 09:56:00 +0800</pubDate>
</item>
<item>
<title>低秩近似之路（二）：SVD</title>
<link>https://spaces.ac.cn/archives/10407</link>
<guid>https://spaces.ac.cn/archives/10407</guid>
<content:encoded><![CDATA[
<p>上一篇文章中我们介绍了“<a href="https://kexue.fm/archives/10366" target="_blank">伪逆</a>”，它关系到给定矩阵$\boldsymbol{M}$和$\boldsymbol{A}$（或$\boldsymbol{B}$）时优化目标$\Vert \boldsymbol{A}\boldsymbol{B} - \boldsymbol{M}\Vert_F^2$的最优解。这篇文章我们来关注$\boldsymbol{A},\boldsymbol{B}$都不给出时的最优解，即<br />
\begin{equation}\mathop{\text{argmin}}_{\boldsymbol{A},\boldsymbol{B}}\Vert \boldsymbol{A}\boldsymbol{B} - \boldsymbol{M}\Vert_F^2\label{eq:loss-ab}\end{equation}<br />
其中$\boldsymbol{A}\in\mathbb{R}^{n\times r}, \boldsymbol{B}\in\mathbb{R}^{r\times m}, \boldsymbol{M}\in\mathbb{R}^{n\times m},r < \min(n,m)$。说白了，这就是要寻找矩阵$\boldsymbol{M}$的“最优$r$秩近似（秩不超过$r$的最优近似）”。而要解决这个问题，就需要请出大名鼎鼎的“SVD（奇异值分解）”了。虽然本系列把伪逆作为开篇，但它的“名声”远不如SVD，听过甚至用过SVD但没听说过伪逆的应该大有人在，包括笔者也是先了解SVD后才看到伪逆。</p><p>接下来，我们将围绕着矩阵的最优低秩近似来展开介绍SVD。</p><h2>结论初探</h2><p>对于任意矩阵$\boldsymbol{M}\in\mathbb{R}^{n\times m}$，都可以找到如下形式的奇异值分解（SVD，Singular Value Decomposition）：<br />
\begin{equation}\boldsymbol{M} = \boldsymbol{U}\boldsymbol{\Sigma} \boldsymbol{V}^{\top}\end{equation}</p><p class="more"><a href="https://spaces.ac.cn/archives/10407" title="低秩近似之路（二）：SVD">[...]</a></p>
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 17:45:00 +0800</pubDate>
</item>
<item>
<title>普通燃气灶智能化改造方案</title>
<link>https://spaces.ac.cn/archives/10394</link>
<guid>https://spaces.ac.cn/archives/10394</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文介绍了基于熄火保护装置将普通燃气灶接入米家的智能关火方案。</p><br /><br /><p><strong>摘要：</strong> 随着智能家居的普及，燃气灶的智能化改造逐渐受到关注。目前，燃气灶的智能化主要分为两个方向：一是检测开关火状态，实现与抽油烟机等设备的联动；二是实现智能关火，包括定时关火和接入米家等平台，实现语音或远程关火。然而，市面上具备这些功能的燃气灶较少，且价格高昂，使得消费者在升级时面临经济压力。为此，出现了一些改装方案，利用现有的燃气灶熄火保护装置，通过通断器将其接入米家，从而实现智能关火。此方案不仅成本相对低廉，且能够充分利用现有设备的功能，满足用户对于智能家居的需求，为普通燃气灶的升级提供了新的思路。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://spaces.ac.cn/archives/10394" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 26 Sep 2024 10:39:00 +0800</pubDate>
</item>
<item>
<title>Softmax后传：寻找Top-K的光滑近似</title>
<link>https://spaces.ac.cn/archives/10373</link>
<guid>https://spaces.ac.cn/archives/10373</guid>
<content:encoded><![CDATA[
<p>Softmax，顾名思义是“soft的max”，是$\max$算子（准确来说是$\text{argmax}$）的光滑近似，它通过指数归一化将任意向量$\boldsymbol{x}\in\mathbb{R}^n$转化为分量非负且和为1的新向量，并允许我们通过温度参数来调节它与$\text{argmax}$（的one hot形式）的近似程度。除了指数归一化外，我们此前在<a href="https://kexue.fm/archives/10145" target="_blank">《通向概率分布之路：盘点Softmax及其替代品》</a>也介绍过其他一些能实现相同效果的方案。</p><p>我们知道，最大值通常又称Top-1，它的光滑近似方案看起来已经相当成熟，那读者有没有思考过，一般的Top-$k$的光滑近似又是怎么样的呢？下面让我们一起来探讨一下这个问题。</p><h2>问题描述</h2><p>设向量$\boldsymbol{x}=(x_1,x_2,\cdots,x_n)\in\mathbb{R}^n$，简单起见我们假设它们两两不相等，即$i\neq j \Leftrightarrow x_i\neq x_j$。记$\Omega_k(\boldsymbol{x})$为$\boldsymbol{x}$最大的$k$个分量的下标集合，即$|\Omega_k(\boldsymbol{x})|=k$以及$\forall i\in \Omega_k(\boldsymbol{x}), j \not\in \Omega_k(\boldsymbol{x})\Rightarrow x_i > x_j$。我们定义Top-$k$算子$\mathcal{T}_k$为$\mathbb{R}^n\mapsto\{0,1\}^n$的映射：<br />
\begin{equation}<br />
[\mathcal{T}_k(\boldsymbol{x})]_i = \left\{\begin{aligned}1,\,\, i\in \Omega_k(\boldsymbol{x}) \\ 0,\,\, i \not\in \Omega_k(\boldsymbol{x})\end{aligned}\right.<br />
\end{equation}<br />
说白了，如果$x_i$属于最大的$k$个元素之一，那么对应的位置变成1，否则变成0，最终结果是一个Multi-Hot向量，比如$\mathcal{T}_2([3,2,1,4]) = [1,0,0,1]$。</p><p class="more"><a href="https://spaces.ac.cn/archives/10373" title="Softmax后传：寻找Top-K的光滑近似">[...]</a></p>
]]></content:encoded>
<pubDate>Thu, 19 Sep 2024 15:09:00 +0800</pubDate>
</item>
<item>
<title>矩阵低秩近似系列之伪逆解析</title>
<link>https://spaces.ac.cn/archives/10366</link>
<guid>https://spaces.ac.cn/archives/10366</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文介绍了伪逆的概念及其在低秩近似中的重要性。</p><br /><br /><p><strong>摘要：</strong> 本文旨在系统梳理矩阵低秩近似相关的理论内容，尤其是伪逆（Pseudo Inverse）这一基本概念。伪逆，又称广义逆（Generalized Inverse），是对不可逆矩阵的逆矩阵概念的推广。通过对伪逆的理解，读者可以更好地掌握低秩近似的原理及其在优化问题中的应用，特别是在如LoRA等微调技术中的重要性。从数学角度探讨伪逆的性质及其在实际应用中的效果，将为后续讨论低秩近似的其他技术奠定良好的基础。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://spaces.ac.cn/archives/10366" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Sun, 15 Sep 2024 16:53:00 +0800</pubDate>
</item>
<item>
<title>多模态位置编码的探讨与优化</title>
<link>https://spaces.ac.cn/archives/10352</link>
<guid>https://spaces.ac.cn/archives/10352</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文探讨多模态LLM中位置编码的现状与优化方案，提出改进的RoPE策略。</p><br /><br /><p><strong>摘要：</strong> 本文讨论了多模态LLM（大型语言模型）在位置编码方面的挑战，指出当前多模态模型尚未达成共识。以RoPE（旋转位置编码）为基础，明确其在1D序列中的应用极限，并探讨了如何将其扩展到2D和3D序列。基于之前的RoPE-2D和可推广至RoPE-3D的思路，对视频等3D序列的具体实现进行分析。文章旨在从整体上重新审视多模态位置编码的机制，提出可行的改进方案，力求为多模态LLM的发展提供理论支持和实践参考。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://spaces.ac.cn/archives/10352" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 06 Sep 2024 17:57:00 +0800</pubDate>
</item>
<item>
<title>解读Causal Attention与位置编码的关系</title>
<link>https://spaces.ac.cn/archives/10347</link>
<guid>https://spaces.ac.cn/archives/10347</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">探讨主流LLM使用位置编码原因及NoPE的优势与不足。</p><br /><br /><p><strong>摘要：</strong> 近年来，基于Causal Attention的Decoder-only模型成为主流，但位置编码（如RoPE、ALIBI）仍被普遍应用。首先，位置编码在Attention机制中帮助模型捕捉序列中元素的相对位置，从而使模型能够更好地理解上下文信息。其次，NoPE（无位置编码）的Causal Attention通过自我学习位置关系，实现了一定的位置信息使用，虽然能够取得较好的结果，但在长序列处理和上下文理解上可能存在潜在不足。最后，尽管研究表明无位置编码具备可行性，主流LLM仍倾向于引入位置编码，以进一步增强模型表现，尤其是在复杂任务和多样化应用场景中。因此，位置编码在提升模型性能方面的重要性仍不容忽视。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://spaces.ac.cn/archives/10347" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Sun, 01 Sep 2024 15:09:00 +0800</pubDate>
</item>
<item>
<title>解决MathJax与Marked的兼容性问题</title>
<link>https://spaces.ac.cn/archives/10332</link>
<guid>https://spaces.ac.cn/archives/10332</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文探讨了MathJax与Markdown解析工具Marked之间的兼容性问题，并提出解决方案。</p><br /><br /><p><strong>摘要：</strong> 在使用MathJax来解析LaTeX公式的过程中，我们遇到了与Markdown解析器Marked之间的兼容性问题。尽管这些问题可能只是笔者的个人偏好引起的，但为了追求一个尽可能完美的展示效果，值得花时间解决。Markdown是一种轻量级标记语言，广泛用于文档编写，但其本质是需要转换为HTML才可在浏览器中呈现。Cool Papers中的Kimi功能也是基于Markdown语法。为了使MathJax能够顺利与Marked配合使用，我们需研究如何在Markdown转HTML的过程中保持MathJax公式的正常显示，从而提供更好的用户体验。这篇文章将聚焦于解决这些兼容性冲突的问题，旨在改善这类技术的整合。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://spaces.ac.cn/archives/10332" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 26 Aug 2024 11:03:00 +0800</pubDate>
</item>
<item>
<title>数学公式渲染的兼容性解决方案</title>
<link>https://spaces.ac.cn/archives/10320</link>
<guid>https://spaces.ac.cn/archives/10320</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文总结了Cool Papers成功渲染数学公式的解决方案，提升了阅读体验。</p><br /><br /><p><strong>摘要：</strong> 随着科研论文中数学公式的广泛使用，如何有效渲染这些公式一直是影响阅读体验的一个重要问题。早期，尽管有读者希望将数学公式渲染出来，但由于负责渲染的MathJax与谷歌翻译及延时加载之间存在兼容性问题，导致这一需求未能满足。最近经过多次查阅与调试，作者终于解决了这一兼容性问题，使得Cool Papers现在可以成功渲染LaTeX代码书写的数学公式。此次改进不仅提升了文章的可读性，也为以后的论文阅读提供了更加友好的体验。本文总结了解决方案，供有类似需求的读者参考。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://spaces.ac.cn/archives/10320" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 15 Aug 2024 20:24:00 +0800</pubDate>
</item>
<item>
<title>提升Cool Papers站内搜索效率的新算法探索</title>
<link>https://spaces.ac.cn/archives/10311</link>
<guid>https://spaces.ac.cn/archives/10311</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文介绍了Cool Papers站内搜索系统，通过算法效率提升论文检索与筛选的技巧。</p><br /><br /><p><strong>摘要：</strong> 在本文中，我们讲述了Cool Papers站内搜索系统的新增技术，其目的在于帮助用户高效寻找所需论文。高效检索并非易事，需要用户精准提炼关键词。对此，算法的应用显得尤为重要。某些步骤若依赖人工处理将显得繁琐，但通过算法的介入，可以显著简化这一过程。我们将探讨一些利用算法来提升Cool Papers搜索和筛选论文效率的新尝试。此系统背后的核心技术为全文检索引擎（Full-text Search Engine），该引擎基于关键词匹配的搜索算法，是实现高效检索的关键。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://spaces.ac.cn/archives/10311" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 12 Aug 2024 16:51:00 +0800</pubDate>
</item>
</channel>
</rss>