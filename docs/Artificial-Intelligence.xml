<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>Huggingface Daily Papers</title>
<link>https://huggingface.co/papers</link>

<item>
<title>低秩近似之路（二）：SVD</title>
<link>https://spaces.ac.cn/archives/10407</link>
<guid>https://spaces.ac.cn/archives/10407</guid>
<content:encoded><![CDATA[

  <p>上一篇文章中我们介绍了“<a href="https://kexue.fm/archives/10366" target="_blank">伪逆</a>”，它关系到给定矩阵$M$和$A$（或$B$）时优化目标$\Vert AB - M\Vert_F^2$的最优解。这篇文章我们来关注$A,B$都不给出时的最优解，即<br />
\begin{equation}\mathop{\text{argmin}}_{A,B}\Vert AB - M\Vert_F^2\label{eq:loss-ab}\end{equation}<br />
其中$A\in\mathbb{R}^{n\times r}, B\in\mathbb{R}^{r\times m}, M\in\mathbb{R}^{n\times m},r < \min(n,m)$。说白了，这就是要寻找矩阵$M$的“最优$r$秩近似（秩不超过$r$的最优近似）”。而要解决这个问题，就需要请出大名鼎鼎的“SVD（奇异值分解）”了。虽然本系列把伪逆作为开篇，但它的“名声”远不如SVD，听过甚至用过SVD但没听说过伪逆的应该大有人在，包括笔者也是先了解SVD后才看到伪逆。</p><p>接下来，我们将围绕着矩阵的最优低秩近似来展开介绍SVD。</p><h2>基本形式</h2><p>对于任意矩阵$M\in\mathbb{R}^{n\times m}$，都可以找到如下形式的奇异值分解（SVD，Singular Value Decomposition）：<br />
\begin{equation}M = U\Sigma V^{\top}\end{equation}</p><p class="more"><a href="https://spaces.ac.cn/archives/10407" title="低秩近似之路（二）：SVD">[...]</a></p>

]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 17:45:00 +0800</pubDate>
<pubDate>Tue, 01 Oct 2024 17:45:00 +0800</pubDate>
</item>

<item>
<title>双重嵌入模型的神经音频水印技术研究</title>
<link>https://arxiv.org/abs/2409.19627</link>
<guid>https://arxiv.org/abs/2409.19627</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出了一种双重嵌入的神经音频水印模型，提升了水印的鲁棒性和定位能力。</p><br /><br /><p><strong>摘要：</strong> 本文设计了一种双重嵌入的神经音频水印模型，旨在提高水印的定位能力和鲁棒性。随着深度学习的发展，神经音频水印相较传统方法，在水印的嵌入和提取效果上更具优势，但仍存在低容量和不可感知性差的问题。此外，水印定位问题在神经水印中尤为重要，尚未得到充分研究。为此，本文提出的IDEAW模型针对攻击层对可逆神经网络的影响进行优化，加强了模型的合理性和稳定性。实验结果表明，IDEAW模型在抵御各种攻击的能力、容量以及高效的定位功能上均优于现有方法。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2409.19627" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 04:52:47 GMT</pubDate>
</item>
<item>
<title>Cottention：一种基于余弦相似度的新型注意力机制</title>
<link>https://arxiv.org/abs/2409.18747</link>
<guid>https://arxiv.org/abs/2409.18747</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">Cottention通过余弦相似度替代softmax，具备线性内存复杂度，适合处理长序列。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了一种新的注意力机制Cottention，它用余弦相似度替代传统的softmax操作，从而实现了序列长度上原生的线性内存复杂度。这一特性使得Cottention在处理长序列时比softmax注意力显著更为高效。Cottention可以重构为具有有限隐藏状态的递归神经网络（RNN），在推理过程中能够保证常量内存使用。通过在双向BERT和因果GPT任务上的评估，Cottention展现出了与softmax注意力相当的性能，同时显著降低了内存需求。为了确保有效的计算，我们为Cottention开发了一个自定义的CUDA内核。实验结果表明，Cottention是softmax注意力的有希望的替代方案，能在不牺牲性能的情况下处理更长的序列，因为它具备原生线性内存复杂度和在推理时维持常量内存占用的能力。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2409.18747" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 04:33:45 GMT</pubDate>
</item>
<item>
<title>MM1.5：提升多模态大语言模型的文本与图像理解</title>
<link>https://arxiv.org/abs/2409.20566</link>
<guid>https://arxiv.org/abs/2409.20566</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">MM1.5是一种新型多模态大语言模型，专注于文本丰富的图像理解和多图像推理。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了MM1.5，这是一个新兴的多模态大语言模型（MLLM）系列，旨在提升文本丰富图像理解、视觉参考与定位以及多图像推理的能力。MM1.5在MM1架构的基础上，采用数据中心化的训练方式，系统性地探索了整个模型训练生命周期中不同数据混合对模型性能的影响。这包括高质量的OCR数据和合成描述用于持续预训练，以及针对监督微调的优化视觉指令调优数据混合。我们的模型参数范围从1B到30B，涵盖了密集型和专家混合（MoE）变体，证明了精心的数据策划和训练策略可以在小规模模型（1B和3B）上实现强大的性能。此外，我们还介绍了两个专业变体：MM1.5-Video，专门用于视频理解，以及MM1.5-UI，专为移动用户界面理解而设计。通过广泛的经验研究和消融实验，我们提供了关于训练过程和设计决策的详细洞见，为未来的MLLM开发研究提供了宝贵的指导。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2409.20566" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 04:30:20 GMT</pubDate>
</item>
<item>
<title>超连接：替代残差连接的有效方法</title>
<link>https://arxiv.org/abs/2409.19606</link>
<guid>https://arxiv.org/abs/2409.19606</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文介绍了超连接方法，旨在改善残差连接的不足，并在大语言模型及视觉任务中取得显著性能提升。</p><br /><br /><p><strong>摘要：</strong> 本文提出了一种简单有效的超连接方法，作为残差连接的替代方案，主要解决了残差连接变体中常见的几个缺点，如梯度消失与表征崩溃之间的秋千效应。超连接理论上允许网络调整不同深度特征之间的连接强度，并动态重排列。通过对大语言模型的预训练实验，包括稠密模型与稀疏模型，超连接显示出显著的性能提升。此外，针对视觉任务的附加实验也显示出了类似的改进。我们预期这一方法将在广泛的人工智能问题中得到广泛应用与好处。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2409.19606" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 04:27:44 GMT</pubDate>
</item>
<item>
<title>DiaSynth：一种高质量领域特定对话生成框架</title>
<link>https://arxiv.org/abs/2409.19020</link>
<guid>https://arxiv.org/abs/2409.19020</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">DiaSynth框架通过大规模语言模型生成丰富的领域特定对话，提升对话系统的训练效果。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了一种名为DiaSynth的合成对话生成框架，旨在解决领域特定对话数据集稀缺的问题。当前对话系统的研发受到通用对话数据集和规模小的特定领域数据集的限制。DiaSynth通过动态生成对话，模拟不同的人物角色、子主题和多样的对话特征，利用大规模语言模型及其链式推理能力，生产具有上下文丰富性和真实性的领域特定对话。通过对不同大规模语言模型生成的合成数据进行实验，发现经过合成数据微调的预训练语言模型比基础模型提升了16.47%的表现。此外，合成数据能够捕捉到领域特定数据的90.48%的分布特征，且生成数据的质量会随着大规模语言模型的规模增加而提高。这些结果证实了DiaSynth作为传统数据收集方法的有力替代方案的潜力。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2409.19020" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 04:22:04 GMT</pubDate>
</item>
<item>
<title>ICDiff：专为扩散模型设计的图像复制检测方法</title>
<link>https://arxiv.org/abs/2409.19952</link>
<guid>https://arxiv.org/abs/2409.19952</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文介绍了ICDiff以及D-Rep数据集，用于检测扩散模型生成图像的复制情况。</p><br /><br /><p><strong>摘要：</strong> 随着扩散模型产生的图像在数字艺术和视觉营销中的受到越来越多的关注，内容原创性的问题也随之而来。现有的图像复制检测（ICD）模型在检测手工制作的复制品方面虽然准确，但忽略了来自扩散模型所产生图像的挑战。为此，本文介绍了ICDiff，这是首个专为扩散模型开发的ICD方法。我们构建了Diffusion-Replication（D-Rep）数据集，并提出了一种新颖的深度嵌入方法。D-Rep基于最先进的扩散模型Stable Diffusion V1.5生成4万对图像复制品，并将这些复制品手动标注为6个复制级别，范围从0（无复制）到5（完全复制）。我们的PDF-Embedding方法将每对图像复制品的复制级别转化为概率密度函数（PDF），作为监督信号。实验结果表明，PDF-Embedding在D-Rep测试集上表现优于基于协议的方法和非PDF选择。此外，通过利用PDF-Embedding，我们发现著名扩散模型与开放源代码图库之间的复制比例介于10%到20%之间。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2409.19952" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 03:46:15 GMT</pubDate>
</item>
<item>
<title>HDFlow：一种结合快速与慢速思维的大语言模型复杂推理框架</title>
<link>https://arxiv.org/abs/2409.17433</link>
<guid>https://arxiv.org/abs/2409.17433</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">提出HDFlow框架，结合快速与慢速思维，显著提升大语言模型的复杂推理能力。</p><br /><br /><p><strong>摘要：</strong> 本文提出了一种名为HDFlow的新框架，旨在通过结合快速与慢速思维的适应性方式，提升大语言模型在复杂推理问题上的能力。该框架包含两个关键组成部分：1) 动态工作流（Dynamic Workflow），自动将复杂问题拆解为更易管理的小任务，并动态设计工作流程，组合专门的语言模型或符号推理工具来解决子任务；2) 混合思维（Hybrid Thinking），根据问题的复杂性，动态结合快速与慢速思维。我们还提出了一种易于扩展的方法，自动合成包含27K个挑战性推理问题的大规模数据集，并开发了一种混合思维微调方法，以训练较小的语言模型，使其内化快速/慢速混合推理策略。实验结果显示，在四个推理基准数据集上，使用动态工作流的慢速推理显著优于链式推理，而混合思维在计算效率和性能之间达到了最佳平衡。通过我们的混合思维方法进行微调，显著增强了开放源码语言模型的复杂推理能力。实验结果展示了慢速思维、动态工作流和混合思维在拓展大语言模型复杂问题解决能力方面的潜力。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2409.17433" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 30 Sep 2024 15:42:07 GMT</pubDate>
</item>
<item>
<title>大语言模型诚实性研究综述</title>
<link>https://arxiv.org/abs/2409.18786</link>
<guid>https://arxiv.org/abs/2409.18786</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本研究综述了大语言模型的诚实性问题及改进策略，旨在促进相关领域的进一步探索。</p><br /><br /><p><strong>摘要：</strong> 诚实是将大语言模型（LLMs）与人类价值观对齐的基本原则，这要求模型能够认识到自己所知与未知的知识，并真实地表达这些知识。然而，尽管后续发展有希望，目前的LLMs仍然表现出显著的不诚实行为，例如自信地给出错误答案，或未能明确表达自己所知的知识。此外，关于LLMs诚实性的研究面临多重挑战，包括对诚实性的定义不一、确切区分已知和未知知识的困难，以及缺乏对相关研究的全面理解。为解决这些问题，我们提供了LLMs诚实性问题的综述，涵盖了这一主题的澄清、评估方法及改进策略。此外，我们还提供了未来研究的见解，旨在激励这一重要领域的进一步探索。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2409.18786" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 30 Sep 2024 14:41:55 GMT</pubDate>
</item>
<item>
<title>基于语言模型学习的新型分类方法</title>
<link>https://arxiv.org/abs/2409.18957</link>
<guid>https://arxiv.org/abs/2409.18957</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出一种新方法，利用大型语言模型进行分类，验证了其优越性与解释性。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了一种新的利用大型语言模型（LLMs）进行分类任务的方法，称为“语言模型学习”（LML），并提出了一种名为“数据增强预测”（DAP）的新方法。与传统机器学习模型依赖数据清洗和特征工程不同，该方法通过使用LLMs简化了分类过程。分类过程模拟人类对数据的探索与理解，通过对训练数据的总结和评估，确定对每个标签分类最有帮助的特征。在DAP过程中，系统利用数据摘要自动生成查询，从数据集中检索相关行，以确保在复杂数据条件下生成准确的分类结果。通过使用数据摘要和类似数据，DAP确保了上下文感知的决策。此外，系统在提示中使用“充当可解释的机器学习模型”来增强预测的可解释性，让用户能够审核每个预测背后的逻辑。测试中，该方法在多个场景中取得了超过90%的准确率，表明其有效性，并可能优于传统的机器学习模型。相关代码已在GitHub上提供。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2409.18957" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 30 Sep 2024 13:30:27 GMT</pubDate>
</item>
<item>
<title>调节干预偏好优化方法的研究</title>
<link>https://arxiv.org/abs/2409.17545</link>
<guid>https://arxiv.org/abs/2409.17545</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出了调节干预偏好优化（MIPO）方法，以改善模型对参考模型的干预程度，进而提升模型的对齐效果。</p><br /><br /><p><strong>摘要：</strong> 在偏好优化方法中，常以训练良好的SFT模型作为参考模型进行训练。强化学习与人类反馈（RLHF）和差异化偏好优化（DPO）在优化过程中使用正则化项，以防止模型过度偏离参考模型，从而避免生成异常响应。然而，当参考模型与给定数据对齐不佳且需要显著调整时，正则化项可能会妨碍模型的对齐。因此，我们提出了一种新的方法——调节干预偏好优化（MIPO）。MIPO根据数据与参考模型的对齐程度，调节对参考模型的干预程度：当数据和参考模型良好对齐时，增加干预；若对齐较差则减小干预，以促进更广泛的训练。通过在Alpaca Eval 2.0和MT-Bench上比较MIPO和DPO的性能，采用Mistral-7B和Llama3-8B的实验结果表明，MIPO在多种评估场景中均优于DPO。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2409.17545" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 30 Sep 2024 05:36:26 GMT</pubDate>
</item>
<item>
<title>MinerU：高精度文档内容提取开源解决方案</title>
<link>https://arxiv.org/abs/2409.18839</link>
<guid>https://arxiv.org/abs/2409.18839</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">MinerU提供了一种高精度的文档内容提取方法，有效应对多样化文档类型。</p><br /><br /><p><strong>摘要：</strong> 文档内容分析在计算机视觉领域一直是一个重要的研究方向。尽管在OCR、布局检测和公式识别等方法上取得了显著进展，现有开源解决方案在高质量内容提取方面仍面临挑战，特别是面对多样化的文档类型和内容。为了解决这些问题，我们提出了MinerU，一个开源的高精度文档内容提取解决方案。MinerU利用先进的PDF-Extract-Kit模型，能够有效地从各种文档中提取内容。同时，该系统还采用精细调整的预处理和后处理规则，以确保最终结果的准确性。实验结果表明，MinerU在多种文档类型中均表现出色，显著提高了内容提取的质量和一致性。MinerU开源项目已在https://github.com/opendatalab/MinerU上发布。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2409.18839" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 30 Sep 2024 05:17:52 GMT</pubDate>
</item>
<item>
<title>Emu3：一种基于下一个令牌预测的多模态模型</title>
<link>https://arxiv.org/abs/2409.18869</link>
<guid>https://arxiv.org/abs/2409.18869</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">Emu3通过下一个令牌预测在多模态任务中超越了多个主流模型，展示了其在生成和感知能力上的优越性。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了Emu3，一套新的多模态模型，完全基于下一个令牌预测进行训练。通过将图像、文本和视频转化为离散的令牌，Emu3从零开始训练一个单一的变换器，利用多种多模态序列的混合进行学习。研究表明，Emu3在生成和感知任务中优于多种任务专用的模型，明显超越了SDXL和LLaVA-1.6等知名模型，同时淘汰了扩散或组合架构。Emu3还能通过预测视频序列中的下一个令牌生成高保真视频。我们简化了复杂的多模态模型设计，专注于令牌这一单一方面，从而在训练和推理过程中释放出巨大的潜力。研究结果表明，下一个令牌预测是构建超越语言的通用多模态智能的有前景的方向。我们开源了关键技术和模型，以支持该领域的进一步研究。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2409.18869" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 30 Sep 2024 03:23:21 GMT</pubDate>
</item>
<item>
<title>PhysGen：一种基于单幅图像生成视频的新方法</title>
<link>https://arxiv.org/abs/2409.18964</link>
<guid>https://arxiv.org/abs/2409.18964</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">PhysGen通过物理模拟与数据驱动的方法，为单幅图像生成现实与物理一致性的视频。</p><br /><br /><p><strong>摘要：</strong> PhysGen是一种新颖的图像到视频生成方法，能够将单幅图像与输入条件（如施加于图像中对象的力和扭矩）转换为现实、物理上合理且时间上连贯的视频。该方法的关键在于结合了基于模型的物理模拟和数据驱动的视频生成过程，从而在图像空间内实现合理的动态。系统核心包括三大组件：一是图像理解模块，有效捕捉图像的几何形状、材料和物理参数；二是图像空间动态模拟模型，利用刚体物理和推断的参数进行真实行为的模拟；三是基于图像的渲染和精炼模块，利用生成的视频扩散技术生产具有模拟运动的真实视频。生成的视频在物理和外观上都高度真实，且可精确控制，经过量化比较和全面的用户研究显示出优于现有的数据驱动图像到视频生成工作的效果。PhysGen生成的视频可应用于多种下游任务，例如将图像转化为真实动画，或允许用户与图像互动并创建各种动态。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2409.18964" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 30 Sep 2024 03:17:46 GMT</pubDate>
</item>
<item>
<title>MIO：一种新型的多模态基础模型</title>
<link>https://arxiv.org/abs/2409.17692</link>
<guid>https://arxiv.org/abs/2409.17692</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">MIO是一种采用多模态令牌构建的新模型，能实现多种形式的智能生成与理解。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了一种名为MIO的新型基础模型，具有处理多模态令牌的能力，能够理解和生成语音、文本、图像和视频。尽管近期大型语言模型（LLMs）和多模态大型语言模型（MM-LLMs）的出现推动了人工通用智能的发展，但它们仍然缺乏真正的任意到任意的理解和生成能力。最近发布的GPT-4o展示了这一领域的潜力，但因闭源且不支持生成多模态交错序列而存在局限。为了填补这一空白，MIO采用因果多模态建模，通过混合离散令牌的方式进行训练。MIO经历了四个阶段的训练过程：对齐预训练、交错预训练、语音增强预训练和多样化任务的综合监督微调。实验结果表明，MIO在多个方面表现出竞争力，甚至比之前的双模态基线和任意对任意模型基线更为优越。此外，MIO还展现了其任意对任意特性带来的高级能力，如交错视频文本生成、视觉链推理、视觉指导生成和图像编辑等。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2409.17692" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 30 Sep 2024 02:16:43 GMT</pubDate>
</item>
<item>
<title>基于向量的后训练量化方法用于极低位宽的大语言模型</title>
<link>https://arxiv.org/abs/2409.17066</link>
<guid>https://arxiv.org/abs/2409.17066</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本研究提出了一种向量后训练量化方法，显著提高大语言模型的低位量化性能与推理效率。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了一种新的向量后训练量化（VPTQ）方法，旨在对大型语言模型（LLMs）进行极低位宽量化。为克服传统标量量化在极低位宽时的数值表示局限性，我们引入了第二阶优化技术来构建LLM的向量量化问题，并通过求解该优化问题指导量化算法设计。此外，我们采用与通道无关的第二阶优化来精细调整权重，以实现更精细的向量量化。我们还提出了一种简洁有效的码本初始化算法，以简化优化问题的分解。同时，VPTQ方法支持残差和异常值量化，进而提高模型准确性并进一步压缩模型。实验结果表明，VPTQ在2位宽下，相较于当前最先进技术（SOTA），在LLaMA-2上量化困惑度下降0.01-0.34，Mistral-7B下降0.38-0.68，LLaMA-3下降4.41-7.34，并且在LLaMA-2、Mistral-7B和LLaMA-3的问答任务中平均精度提高了0.79-1.5%、1%和11-22%。我们仅利用10.4-18.6%的量化算法执行时间，使推理吞吐量提升了1.6-1.8倍。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2409.17066" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 30 Sep 2024 01:55:09 GMT</pubDate>
</item>
<item>
<title>多尺度洞察智能体（MSI-Agent）在决策优化中的应用</title>
<link>https://arxiv.org/abs/2409.16686</link>
<guid>https://arxiv.org/abs/2409.16686</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文介绍多尺度洞察智能体（MSI-Agent），通过优化洞察生成和选择提高决策能力。</p><br /><br /><p><strong>摘要：</strong> 本文提出多尺度洞察智能体（MSI-Agent），旨在提升大语言模型（LLM）在计划和决策中的效率。MSI-Agent通过经验选择器、洞察生成器和洞察选择器的三部分管道，能够有效生成任务特定和高层洞察，并将其存储在数据库中，以便于在决策过程中调用相关洞察。实验结果表明，MSI-Agent在规划任务上优于其他洞察策略，并展示出在面对领域转移场景时的更强鲁棒性。本文还探讨了选择种子经验和洞察的策略，以便为大语言模型提供更有用和相关的洞察，从而改善其决策能力。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2409.16686" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 30 Sep 2024 01:22:44 GMT</pubDate>
</item>
<item>
<title>利用“熄火保护 + 通断器”实现燃气灶智能关火</title>
<link>https://spaces.ac.cn/archives/10394</link>
<guid>https://spaces.ac.cn/archives/10394</guid>
<content:encoded><![CDATA[
<div>燃气灶智能化主要有两个方向：一是检测开关火状态，实现跟抽油烟机等其他设备的联动；二是实现智能关火，这包括定时关火以及接入米家（或者其他智能家居）实现语音关火、远程关火等。目前带有这两点功能的燃气...</div>
]]></content:encoded>
<pubDate>Thu, 26 Sep 2024 10:39:00 +0800</pubDate>
</item>
<item>
<title>Softmax后传：寻找Top-K的光滑近似</title>
<link>https://spaces.ac.cn/archives/10373</link>
<guid>https://spaces.ac.cn/archives/10373</guid>
<content:encoded><![CDATA[
<p>Softmax，顾名思义是“soft的max”，是$\max$算子（准确来说是$\text{argmax}$）的光滑近似，它通过指数归一化将任意向量$\boldsymbol{x}\in\mathbb{R}^n$转化为分量非负且和为1的新向量，并允许我们通过温度参数来调节它与$\text{argmax}$（的one hot形式）的近似程度。除了指数归一化外，我们此前在<a href="https://kexue.fm/archives/10145" target="_blank">《通向概率分布之路：盘点Softmax及其替代品》</a>也介绍过其他一些能实现相同效果的方案。</p><p>我们知道，最大值通常又称Top-1，它的光滑近似方案看起来已经相当成熟，那读者有没有思考过，一般的Top-$k$的光滑近似又是怎么样的呢？下面让我们一起来探讨一下这个问题。</p><h2>问题描述</h2><p>设向量$\boldsymbol{x}=(x_1,x_2,\cdots,x_n)\in\mathbb{R}^n$，简单起见我们假设它们两两不相等，即$i\neq j \Leftrightarrow x_i\neq x_j$。记$\Omega_k(\boldsymbol{x})$为$\boldsymbol{x}$最大的$k$个分量的下标集合，即$|\Omega_k(\boldsymbol{x})|=k$以及$\forall i\in \Omega_k(\boldsymbol{x}), j \not\in \Omega_k(\boldsymbol{x})\Rightarrow x_i > x_j$。我们定义Top-$k$算子$\mathcal{T}_k$为$\mathbb{R}^n\mapsto\{0,1\}^n$的映射：<br />
\begin{equation}<br />
[\mathcal{T}_k(\boldsymbol{x})]_i = \left\{\begin{aligned}1,\,\, i\in \Omega_k(\boldsymbol{x}) \\ 0,\,\, i \not\in \Omega_k(\boldsymbol{x})\end{aligned}\right.<br />
\end{equation}<br />
说白了，如果$x_i$属于最大的$k$个元素之一，那么对应的位置变成1，否则变成0，最终结果是一个Multi-Hot向量，比如$\mathcal{T}_2([3,2,1,4]) = [1,0,0,1]$。</p><p class="more"><a href="https://spaces.ac.cn/archives/10373" title="Softmax后传：寻找Top-K的光滑近似">[...]</a></p>
]]></content:encoded>
<pubDate>Thu, 19 Sep 2024 15:09:00 +0800</pubDate>
</item>
<item>
<title>深入理解矩阵低秩近似：伪逆的理论与应用</title>
<link>https://spaces.ac.cn/archives/10366</link>
<guid>https://spaces.ac.cn/archives/10366</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文介绍了矩阵低秩近似中的伪逆概念，探讨其广义逆矩阵的定义及应用。</p><br /><br /><p><strong>摘要：</strong> 矩阵的低秩近似虽然概念易懂，但内容广泛，相关研究中常出现新技巧，令人感到陌生。本文首篇关注伪逆，即广义逆矩阵，是逆矩阵对不可逆矩阵的推广。在低秩近似中，伪逆为优化问题提供重要工具，尤其在数据降维和特征提取中具有广泛应用。伪逆不仅可用于求解线性方程，还能帮助我们理解和构建更高效的模型。如图所示，这一概念与实际应用密切相关，深化了对矩阵处理技术的理解。<img alt="伪逆示意图" src="图片链接1" />随着 LoRA 等技术的兴起，低秩近似的应用正逐渐增多，使得这一数学工具变得愈加重要。<img alt="低秩近似应用示意图" src="图片链接2" /></p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://spaces.ac.cn/archives/10366" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Sun, 15 Sep 2024 16:53:00 +0800</pubDate>
</item>
<item>
<title>多模态位置编码研究：从RoPE到RoPE-3D的演变</title>
<link>https://spaces.ac.cn/archives/10352</link>
<guid>https://spaces.ac.cn/archives/10352</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">探讨多模态LLM中的位置编码，分析传统1D RoPE及其在2D和3D序列中的推广，从而提出更理想的方案。</p><br /><br /><p><strong>摘要：</strong> 本文探讨了多模态语言模型（LLM）中位置编码的重要性，指出目前尚未达成共识，尤其在多模态模型中。已有的主流位置编码方法是RoPE（相对位置编码），其原设计仅适用于一维序列（RoPE-1D）。为了拓展至其他维度，本文讨论了如何将RoPE推广至二维（RoPE-2D），以适应图像等数据形式，并进一步推导出RoPE-3D用于视频等三维序列。通过对这个问题的深度梳理，作者希望提出更为理想的解决方案。更多内容请参考[原文图示](http://example.com/image1)。此外，文章中首次提到的RoPE-Tie方案虽有其价值，但仍需细化与发展，以期为多模态LLM领域提供贡献。关于RoPE的详细介绍，读者可参考相关文献。当前多模态模型的发展亟待建立统一的方法论，以推动整个领域的进步和应用。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://spaces.ac.cn/archives/10352" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 06 Sep 2024 17:57:00 +0800</pubDate>
</item>
<item>
<title>探讨Causal Attention中的位置编码问题</title>
<link>https://spaces.ac.cn/archives/10347</link>
<guid>https://spaces.ac.cn/archives/10347</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文探讨Causal Attention中位置编码的作用及NoPE模型的优缺点。</p><br /><br /><p><strong>摘要：</strong> 众所周知，目前主流的LLM都是基于Causal Attention的Decoder-only模型。虽然已经有不少研究表明，Causal Attention可以在不使用额外的位置编码的情况下取得良好效果，但仍然有许多主流模型（如RoPE、ALIBI等）依然加入了位置编码。本文从三个角度分析这一现象：首先，位置编码在Attention中的作用是为了解决序列中单词的顺序问题；其次，NoPE的Causal Attention通过自适应的方式在计算过程中实现了位置编码；最后，NoPE所实现的位置编码在信息传递的准确性和效率上存在一定不足。整体来看，尽管NoPE在某些情境下能够工作，但主流模型仍选择使用额外的位置编码，可能是出于对模型性能的进一步优化考虑。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://spaces.ac.cn/archives/10347" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Sun, 01 Sep 2024 15:09:00 +0800</pubDate>
</item>
<item>
<title>解决MathJax与Marked的兼容性问题</title>
<link>https://spaces.ac.cn/archives/10332</link>
<guid>https://spaces.ac.cn/archives/10332</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文探讨了MathJax与Markdown解析器Marked之间的兼容性问题，并给出了解决方案。</p><br /><br /><p><strong>摘要：</strong> 在我们引入MathJax解析LaTeX公式后，遇到了与Markdown解析器Marked之间的兼容性问题。Markdown是一种轻量级的标记语言，通常在展示前需要转为HTML格式。尽管部分问题源于笔者的严格要求，但我们追求完美的解决方案是值得努力的。通过合理的配置和调整，我们可以实现MathJax与Marked之间的无缝协作，确保渲染后的文档保持美观和准确。最终，这将提升用户体验，让文档在科学和学术写作中更具吸引力。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://spaces.ac.cn/archives/10332" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 26 Aug 2024 11:03:00 +0800</pubDate>
</item>
<item>
<title>让MathJax更好地兼容谷歌翻译和延时加载</title>
<link>https://spaces.ac.cn/archives/10320</link>
<guid>https://spaces.ac.cn/archives/10320</guid>
<content:encoded><![CDATA[
<div>很早之前，就有读者提出希望把Cool Papers上面的数学公式渲染一下，因为很多偏数学的论文，它们的摘要甚至标题上都带有LaTeX代码写的数学公式，如果不把这些公式渲染出来，那么看上去就像是一...</div>
]]></content:encoded>
<pubDate>Thu, 15 Aug 2024 20:24:00 +0800</pubDate>
</item>
<item>
<title>“Cool Papers + 站内搜索”的一些新尝试</title>
<link>https://spaces.ac.cn/archives/10311</link>
<guid>https://spaces.ac.cn/archives/10311</guid>
<content:encoded><![CDATA[
<div>在《Cool Papers更新：简单搭建了一个站内检索系统》这篇文章中，我们介绍了Cool Papers新增的站内搜索系统。搜索系统的目的，自然希望能够帮助用户快速找到他们需要的论文。然而，如何...</div>
]]></content:encoded>
<pubDate>Mon, 12 Aug 2024 16:51:00 +0800</pubDate>
</item>
<item>
<title>概率分布优化问题的探索与分析</title>
<link>https://spaces.ac.cn/archives/10289</link>
<guid>https://spaces.ac.cn/archives/10289</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文章探讨了如何在概率空间中优化目标函数，并提出新的分析和计算方法。</p><br /><br /><p><strong>摘要：</strong> 本文讨论了在概率空间中进行优化的复杂性，以及传统的无约束优化方法如求导与梯度下降在处理概率分布时的局限。由于概率分布的输入特性，直接求解梯度零点可能导致不再是有效的概率分布，因此需要探索新的优化方法来确保结果的合理性。作者分享了自己在学习概率分布优化过程中的所思所感，并希望通过整理总结为读者提供参考。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://spaces.ac.cn/archives/10289" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 06 Aug 2024 14:52:00 +0800</pubDate>
</item>
<item>
<title>对齐全量微调！这是我看过最精彩的LoRA改进（二）</title>
<link>https://spaces.ac.cn/archives/10266</link>
<guid>https://spaces.ac.cn/archives/10266</guid>
<content:encoded><![CDATA[
<p>前两周笔者写了<a href="https://kexue.fm/archives/10226" target="_blank">《对齐全量微调！这是我看过最精彩的LoRA（一）》</a>（当时还没有编号“一”），里边介绍了一个名为“LoRA-GA”的LoRA变体，它通过梯度SVD来改进LoRA的初始化，从而实现LoRA与全量微调的对齐。当然，从理论上来讲，这样做也只能尽量对齐第一步更新后的$W_1$，所以当时就有读者提出了“后面的$W_2,W_3,\cdots$不管了吗？”的疑问，当时笔者也没想太深入，就单纯觉得对齐了第一步后，后面的优化也会严格一条较优的轨迹走。</p><p>有趣的是，LoRA-GA才出来没多久，arXiv上就新出了<a href="https://arxiv.org/abs/2407.18242" target="_blank">《LoRA-Pro: Are Low-Rank Adapters Properly Optimized?》</a>，其所提的LoRA-Pro正好能回答这个问题！LoRA-Pro同样是想着对齐全量微调，但它对齐的是每一步梯度，从而对齐整条优化轨迹，这正好是跟LoRA-GA互补的改进点。</p><h2>对齐全量</h2><p>本文接着上一篇文章的记号和内容进行讲述，所以这里仅对上一节的内容做一个简单回顾，不再详细重复介绍。LoRA的参数化方式是<br />
\begin{equation}W = (W_0 - A_0 B_0) + AB\end{equation}</p><p class="more"><a href="https://spaces.ac.cn/archives/10266" title="对齐全量微调！这是我看过最精彩的LoRA改进（二）">[...]</a></p>
]]></content:encoded>
<pubDate>Mon, 29 Jul 2024 16:31:00 +0800</pubDate>
</item>
<item>
<title>会话分析任务的系统化研究与应用前景</title>
<link>https://arxiv.org/abs/2409.14195</link>
<guid>https://arxiv.org/abs/2409.14195</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文系统化了会话分析任务，明确其四个关键步骤，探讨行业应用与未来研究方向。</p><br /><br /><p><strong>摘要：</strong> 随着大型语言模型的发展，会话日志的积累日益增多，会话分析（CA）成为获取关键商业洞察的手段。本文定义了CA任务，并系统梳理相关研究，指出CA的四个关键步骤：会话场景重建、深入归因分析、针对性训练以及基于训练生成对话。我们还展示了相关基准，讨论了行业与学术面临的挑战，以及未来研究方向。目前，大部分研究集中在浅层对话元素的分析上，亟需提高分析深度。借助大型语言模型，最新的研究逐渐向因果关系与战略任务发展，呈现出复杂和高级的研究趋势。这些经验和洞察将在商业运营中，尤其是针对会话日志的分析上，有广泛的应用价值。<img alt="会话分析示意图" src="your_image_link_here" /></p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2409.14195" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 27 Sep 2024 11:20:10 GMT</pubDate>
</item>
<item>
<title>隐性指令调优：语言模型的指令跟随能力探析</title>
<link>https://arxiv.org/abs/2409.14254</link>
<guid>https://arxiv.org/abs/2409.14254</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">研究发现语言模型可通过隐性调优实现指令跟随，且不依赖于指令-响应对训练。</p><br /><br /><p><strong>摘要：</strong> 本研究探讨了隐性指令调优在语言模型中的应用。首先发现，训练仅基于响应，而无需对应的指令，仍能实现指令跟随，说明预训练模型已具备潜在的指令-响应映射。其次，即使是在狭域数据上进行指令-响应训练，仍能产生广泛的指令跟随行为，如从诗歌生成食谱。当指令与狭域微调内容相去甚远时，模型的响应往往不再遵循微调领域的风格。为解释隐性指令调优，研究者假设简单的分布变化可促进指令跟随。通过手动编写一种规则驱动的语言模型，并与预训练模型结合，研究者发现只需缓慢增加序列结束概率、惩罚重复、均匀调整15个单词的概率即可实现指令跟随。综上所述，那些未专门设计为实现指令跟随的适应性调优也可以隐性地发挥这一作用。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2409.14254" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 27 Sep 2024 10:24:59 GMT</pubDate>
</item>
<item>
<title>Structured-GraphRAG：提升自然语言查询中的信息检索效率</title>
<link>https://arxiv.org/abs/2409.17580</link>
<guid>https://arxiv.org/abs/2409.17580</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">Structured-GraphRAG通过知识图谱提升信息检索有效性，适用于复杂数据集和自然语言查询。</p><br /><br /><p><strong>摘要：</strong> 本文提出了Structured-GraphRAG框架，旨在提升自然语言查询中对复杂结构数据集的信息检索能力。传统的数据检索方法，如顺序搜索和基于索引的检索，往往在处理复杂且相互连接的数据结构时表现不佳，导致结果不完整或误导。Structured-GraphRAG利用多个知识图谱，以结构化的形式展示数据，捕捉实体之间的复杂关系，从而实现对信息的更细致和全面的检索。通过将响应置于结构化格式中，该图形化方法减少了语言模型输出中的错误风险，提高了结果的可靠性。本文通过与最新发布的方法进行比较，展示了Structured-GraphRAG的有效性，研究发现，该框架显著提升了查询处理效率并缩短了响应时间。尽管案例研究集中于足球数据，但该框架的设计广泛适用，可为数据分析提供强大工具，并提升各类结构化领域的语言模型应用。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2409.17580" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 27 Sep 2024 07:22:46 GMT</pubDate>
</item>
<item>
<title>基于聚类的令牌池化方法以降低ColBERT向量存储需求</title>
<link>https://arxiv.org/abs/2409.14683</link>
<guid>https://arxiv.org/abs/2409.14683</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出了一种聚类池化方法，显著降低ColBERT索引的存储需求，性能几乎不受影响。</p><br /><br /><p><strong>摘要：</strong> 在本文中，我们介绍了一种简单的基于聚类的令牌池化方法，以大幅减少ColBERT方法中的向量存储数量。通过这一方法，可将ColBERT索引的空间和内存占用减少50%，且几乎不影响检索性能。此外，该方法支持进一步的向量数量削减，达到66%-75%之间，而在大多数数据集上性能降级保持在5%以下。重要的是，该方法无需进行架构改变或查询时处理，可以作为简单的替代方法在任何类似ColBERT模型的索引阶段使用。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2409.14683" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 27 Sep 2024 04:54:39 GMT</pubDate>
</item>
<item>
<title>提升潜在扩散模型生成高频细节的像素空间监督方法</title>
<link>https://arxiv.org/abs/2409.17565</link>
<guid>https://arxiv.org/abs/2409.17565</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">通过在后训练过程中增加像素空间监督，显著提升潜在扩散模型的生成质量。</p><br /><br /><p><strong>摘要：</strong> 潜在扩散模型（LDMs）在图像生成领域取得了显著进展。虽然LDM在压缩的潜在空间中进行训练与部署更为高效，但仍存在高频细节与复杂构图生成不佳的问题。我们认为，这部分由于训练过程中的潜在空间分辨率较低。为了解决这一问题，我们提出在后训练过程中增加像素空间监督，以更好地保留高频细节。实验结果显示，在最先进的DiT transformer和U-Net扩散模型下，增加像素空间目标能够显著提升监督质量微调和偏好基础后训练的效果，尤其在视觉质量和视觉缺陷指标上有大幅改善。同时，文本对齐质量保持不变。<img alt="Sample Image 1" src="image_link_1" /><img alt="Sample Image 2" src="image_link_2" /></p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2409.17565" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 27 Sep 2024 02:58:25 GMT</pubDate>
</item>
<item>
<title>LLaVA-3D：一种高效的三维场景理解框架</title>
<link>https://arxiv.org/abs/2409.18125</link>
<guid>https://arxiv.org/abs/2409.18125</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">LLaVA-3D结合2D理解能力与3D场景理解，采用3D Patch表示，提高训练速度及任务性能。</p><br /><br /><p><strong>摘要：</strong> 本文提出了一种名为LLaVA-3D的框架，旨在提升三维场景理解能力，同时不损害二维理解性能。LLaVA-3D利用了LLaVA的强大二维理解先验，通过引入一种简单有效的3D Patch表示，将2D CLIP特征与3D空间位置相连接。通过将3D Patch集成到2D大规模多模态模型中，并进行二维和三维视觉-语言指令的联合调优，LLaVA-3D实现了统一的架构。实验结果表明，LLaVA-3D在训练3D视觉-语言数据集时收敛速度比现有的3D大规模多模态模型快3.5倍。此外，LLaVA-3D在多个3D任务上表现出色，并且在二维图像理解和视觉-语言对话能力方面，性能与LLaVA相当。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2409.18125" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 27 Sep 2024 02:29:44 GMT</pubDate>
</item>
<item>
<title>Lotus：基于扩散模型的视觉基础模型在密集预测任务中的应用</title>
<link>https://arxiv.org/abs/2409.18124</link>
<guid>https://arxiv.org/abs/2409.18124</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">Lotus模型通过直接预测标注和简化扩散过程，提升了在零-shot情境下的深度和法线估计性能。</p><br /><br /><p><strong>摘要：</strong> Lotus是一种新型的扩散基础视觉模型，其通过直接预测标注而非噪声来提升密集预测任务的性能。针对现有扩散模型在图像生成和密集预测之间的差异，Lotus重构了扩散过程为单步过程，简化了优化流程并显著提升了推理速度。同时，Lotus引入了一种新的调优策略——细节保持器，使得预测结果更加准确和细致。经过验证，Lotus在多个数据集上实现了深度和法线估计的最先进表现，而且在不增加训练数据或模型容量的情况下，效率提升达到数百倍。其研究为提高密集预测任务中的零-shot泛化提供了新的思路和解决方案。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2409.18124" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 27 Sep 2024 02:19:47 GMT</pubDate>
</item>
<item>
<title>机器人模仿人类操作新物体的方法</title>
<link>https://arxiv.org/abs/2409.18121</link>
<guid>https://arxiv.org/abs/2409.18121</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">该研究提出了机器人观察人类演示操作的方法，使用4D可微分部件模型来实现对象的三维运动恢复与模仿。</p><br /><br /><p><strong>摘要：</strong> 本研究开发了机器人观看和模仿（RSRD）的方法，使机器人能够通过观看人类的单视角RGB演示，学习操控新物体。首先提出了4D可微分部件模型（4D-DPM），利用可微分渲染从单一视频中恢复三维部分运动。该分析合成方法采用部分中心特征场进行迭代优化，应用几何正则化器，仅使用单一视频恢复三维运动。在获得4D重建后，机器人规划双手臂动作，复制演示的物体轨迹。通过将演示表示为部分中心轨迹，RSRD侧重于复制演示的预期行为，同时考虑到机器人的形态限制，而非单纯重现手部运动。研究评估了4D-DPM在真实标注的3D部分轨迹上的跟踪准确性，以及RSRD在9个物体上各进行10次试验的物理执行表现。其中每个阶段的平均成功率为87%，在90次试验中的总端到端成功率为60%。值得注意的是，这一切只使用了从大型预训练视觉模型中提取的特征场，而无需任何任务特定的训练、微调、数据集收集或标注。项目页面：<a href="https://robot-see-robot-do.github.io">https://robot-see-robot-do.github.io</a></p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2409.18121" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 27 Sep 2024 02:03:23 GMT</pubDate>
</item>
<item>
<title>EMOVA：情感全方位的语音助手</title>
<link>https://arxiv.org/abs/2409.18042</link>
<guid>https://arxiv.org/abs/2409.18042</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">EMOVA通过分离语音语义和声学特征，实现语音生成与视觉理解的优越表现。</p><br /><br /><p><strong>摘要：</strong> EMOVA（EMotionally Omni-present Voice Assistant）是一个新型的情感语音助手，旨在弥补现有大型语言模型在语音与视觉理解上的不足。通过语义-声学分离的语音分词器，EMOVA显著提升了视觉-语言和语音能力，且超越了传统的双模态对齐模型。此外，EMOVA还引入了轻量级风格模块，实现灵活的语音风格控制，例如情感和音调调节。这一成果实现了在视觉-语言及语音基准测试上达到最先进的性能，并首次支持具有生动情感的全模态对话能力，标志着在开放源代码社区中对多模态模型的进一步发展。<img alt="EMOVA示意图" src="原文中的图片链接" /></p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2409.18042" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 27 Sep 2024 01:28:22 GMT</pubDate>
</item>
<item>
<title>MaskLLM：一种用于大语言模型的可学习剪枝方法</title>
<link>https://arxiv.org/abs/2409.17481</link>
<guid>https://arxiv.org/abs/2409.17481</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">MaskLLM通过学习掩码分布，在LLMs中实现了半结构化稀疏性，显著降低了推理时的计算开销。</p><br /><br /><p><strong>摘要：</strong> 该研究提出了MaskLLM，一种可学习剪枝方法，实现在大型语言模型（LLMs）中引入半结构化稀疏性（2:4稀疏性），以减少推理的计算负担。MaskLLM通过Gumbel Softmax采样，将N:M模式显式建模为可学习的分布，避免了新重要性标准的开发。该方法在大规模数据集上进行端到端训练，展现出两个显著优势：一是高质量的掩码，能有效扩展至大数据集并学习准确掩码；二是可转移性，通过概率建模掩码分布，可以实现跨领域或任务的稀疏性迁移。研究使用2:4稀疏性评估了MaskLLM在多种LLM（包括LLaMA-2、Nemotron-4和GPT-3，参数量从843M到15B不等）上的表现，结果显示其显著优于现有方法。具体而言，虽然领先的方法在Wikitext上达到的困惑度（PPL）大于10，而Dense模型的PPL为5.12，但MaskLLM通过学习掩码，并保持权重不变，取得了显著更低的6.72 PPL。此外，MaskLLM的可学习特性允许为下游任务或领域定制无损应用2:4稀疏性。代码可在 <a href="https://github.com/NVlabs/MaskLLM">这里</a>获取。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2409.17481" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 27 Sep 2024 01:18:19 GMT</pubDate>
</item>
<item>
<title>GemFilter：一种加速长文本输入处理的新方法</title>
<link>https://arxiv.org/abs/2409.17422</link>
<guid>https://arxiv.org/abs/2409.17422</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">GemFilter通过初级层筛选和压缩输入令牌，提高LLM推理速度与内存效率。</p><br /><br /><p><strong>摘要：</strong> 本研究提出GemFilter，一种新的算法，通过使用LLM的早期层作为过滤器，选择和压缩输入令牌，从而显著减少后续处理的上下文长度。GemFilter在速度和内存效率方面相较于现有技术（如标准注意力和SnapKV/H2O）显示出显著改善，尤其是在Needle in a Haystack任务中表现优异，达到了2.4倍的速度提升以及30%的GPU内存使用减少。此外，GemFilter在LongBench挑战中与其他方法表现相当，且无需训练，简单可广泛适用于不同的LLM。更重要的是，GemFilter提供的可解释性使人们可以检查所选输入序列，从而增强了对LLM内部机制的理解，推动了对LLM设计和推理的进一步优化。更多信息可访问 [GemFilter项目页面](https://github.com/SalesforceAIResearch/GemFilter)。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2409.17422" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 27 Sep 2024 01:15:22 GMT</pubDate>
</item>
<item>
<title>Disco4D：基于单幅图像的4D人体生成与动画新框架</title>
<link>https://arxiv.org/abs/2409.17280</link>
<guid>https://arxiv.org/abs/2409.17280</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">Disco4D通过高斯建模，实现单幅图像下的4D人体生成与动画，增强了细节与灵活性。</p><br /><br /><p><strong>摘要：</strong> 我们提出了Disco4D，这是一个创新的高斯点云框架，用于从单幅图像生成和动画化4D人类形象。与现有方法不同，Disco4D独特地将衣物（通过高斯模型表示）与人体（采用SMPL-X模型）解耦，从而显著提高了生成细节和灵活性。其技术创新包括：1）Disco4D能够高效地将衣物高斯模型与SMPL-X高斯模型进行拟合；2）它采用扩散模型增强3D生成过程，如对输入图像中不可见的遮挡部分进行建模；3）它为每个衣物高斯学习了身份编码，以便于衣物资产的分离与提取。此外，Disco4D自然支持具有生动动态的4D人类动画。大量实验表明，Disco4D在4D人类生成与动画任务中优于其他方法。我们的可视化结果可以在 [Disco4D官网](https://disco-4d.github.io/) 中查看。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2409.17280" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 27 Sep 2024 01:10:00 GMT</pubDate>
</item>
</channel>
</rss>