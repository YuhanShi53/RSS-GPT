<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>Huggingface Daily Papers</title>
<link>https://huggingface.co/papers</link>

<item>
<title>xGen-MM-Vid：高效捕捉视频时序信息的多模态语言模型</title>
<link>https://arxiv.org/abs/2410.16267</link>
<guid>https://arxiv.org/abs/2410.16267</guid>
<content:encoded><![CDATA[

  <div><p style=color:gray;>xGen-MM-Vid 采用时序编码器高效处理视频信息，具有小模型高准确率的优势。</p><br><br><p><strong>摘要：</strong> xGen-MM-Vid（BLIP-3-Video）是一种为视频设计的多模态语言模型，特别着重于高效捕捉多个帧的时序信息。该模型引入了'时序编码器'，除去传统的视觉标记器，通过将多个帧的标记序列映射为一组紧凑的视觉标记，从而显著减少视觉标记的数量（例如，使用32个标记而不是4608个）。研究探索了包括可学习的时空池化和诸如Token Turing Machines等序列模型的不同类型的时序编码器。实验结果表明，BLIP-3-Video在视频问答任务中的准确率与更大规模的最先进模型（如34B参数模型）相当，同时模型仅有4B参数，且通过使用更少的视觉标记实现了更高的效率。该项目的官方网站为 https://www.salesforceairesearch.com/opensource/xGen-MM-Vid/index.html。</p><br><br><p><em>使用 gpt-4o-mini 生成 </em></p><a href=https://arxiv.org/abs/2410.16267 target="_blank">查看原文</a></div>

]]></content:encoded>
<pubDate>Wed, 23 Oct 2024 14:05:28 GMT</pubDate>
<pubDate>Wed, 23 Oct 2024 14:05:28 GMT</pubDate>
</item>
<item>
<title>增强视觉语言模型的推理能力：基于详细理由的训练与强化学习</title>
<link>https://arxiv.org/abs/2410.16198</link>
<guid>https://arxiv.org/abs/2410.16198</guid>
<content:encoded><![CDATA[

  <div><p style=color:gray;>本研究通过细化训练数据和强化学习提升视觉语言模型的推理能力。</p><br><br><p><strong>摘要：</strong> 在视觉语言模型（VLMs）中，链式推理（CoT）对于提升可解释性和可信度至关重要。然而，目前的训练方法缺乏丰富的CoT推理数据，主要依赖于短小的注释和最低限度的推理。我们展示了仅用短答案训练VLM在需要更详细回应的推理任务中的泛化能力不足。为了解决此问题，我们提出了一种双重方法。首先，利用GPT-4o模型提取推理过程，从而丰富训练数据，并对VLM进行微调，提升其CoT性能。其次，我们应用强化学习进一步校准推理质量。具体而言，通过将模型生成的推理链与注释的短答案进行比较，构建正负样本对，进而使用Direct Preference Optimization算法来提升模型的推理能力。实验结果显示，在基准数据集上CoT推理有显著提升，并且在直接答案预测的泛化能力上也表现良好。本工作强调在训练中融入详细推理的重要性，并利用强化学习来增强VLM的推理能力。</p><br><br><p><em>使用 gpt-4o-mini 生成 </em></p><a href=https://arxiv.org/abs/2410.16198 target="_blank">查看原文</a></div>

]]></content:encoded>
<pubDate>Wed, 23 Oct 2024 13:48:55 GMT</pubDate>
<pubDate>Wed, 23 Oct 2024 13:48:55 GMT</pubDate>
</item>

<item>
<title>数学推理参数的隔离与干预：Math Neurosurgery 方法</title>
<link>https://arxiv.org/abs/2410.16930</link>
<guid>https://arxiv.org/abs/2410.16930</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出一种新的方法 MathNeuro，用于隔离大语言模型中的数学推理参数，以改进模型的数学表现。</p><br /><br /><p><strong>摘要：</strong> 数学推理是大型语言模型（LLM）研究的关键领域，但关于其在模型参数中的编码及是否可独立于其他技能进行干预的研究较少。为了改善数学能力而不影响模型的其他功能，我们提出了数学神经外科（Math Neurosurgery，MathNeuro）方法。该方法通过前向传播，利用权重和激活值计算参数重要性，从而识别数学专用参数。MathNeuro通过删除非数学行为中重要的参数，成功地剔除了LLM的数学推理能力，但保留了其一般语言能力。我们的实验表明，在GSM8K数据集上，按照MathNeuro识别的参数进行修剪，能够提升预训练或指令调优的LLM性能4%-17%。此外，MathNeuro在数据利用效率方面表现良好，只需一个样本即可有效识别数学专用参数。此研究展示了未来在数学专用参数干预领域的潜力。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.16930" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 23 Oct 2024 09:15:06 GMT</pubDate>
</item>
<item>
<title>减轻长距离视觉-指令交互影响的新方法：同心因果注意力</title>
<link>https://arxiv.org/abs/2410.15926</link>
<guid>https://arxiv.org/abs/2410.15926</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">研究揭示RoPE在LVLM中导致视觉信息误导的问题，并提出同心因果注意力（CCA）作为解决方案。</p><br /><br /><p><strong>摘要：</strong> 近年来，大型视觉语言模型（LVLM）表现出卓越的零样本对话和推理能力，尤其是在处理多模态查询时。然而，它们仍然面临着物体幻觉的问题，即生成的文本回应与输入图像不一致。我们的初步研究表明，物体幻觉与RoPE（旋转位置编码）密切相关，RoPE作为一种广泛采用的位置信息建模设计，因其长期衰减特性，使得LVLM在视觉线索与指令标记之间的距离较大时更易出现幻觉。此外，我们观察到在多模态对齐中颠倒视觉标记的顺序会产生相似的效果。测试结果显示，RoPE的长期衰减对捕捉视觉与指令交互带来挑战。为此，我们提出了一种简单而有效的定位对齐策略——同心因果注意力（CCA），旨在减轻RoPE的长期衰减影响，进一步缩短视觉标记与指令标记之间的相对距离。通过CCA，视觉标记能够更好地与指令标记交互，从而增强模型的感知能力，降低物体幻觉的发生率。我们的定位对齐方法在多个物体幻觉基准测试中显著优于现有的幻觉缓解策略。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.15926" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 23 Oct 2024 08:54:06 GMT</pubDate>
</item>
<item>
<title>自我引导优化：一种无人工标注的偏好信号生成方法</title>
<link>https://arxiv.org/abs/2410.17131</link>
<guid>https://arxiv.org/abs/2410.17131</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文介绍了一种新算法SSO，能够无人工干预生成高质量的偏好信号，提升自动化对齐效率。</p><br /><br /><p><strong>摘要：</strong> 本文提出了一种新算法，自我引导优化（Self-Steering Optimization, SSO），旨在通过最小化人工干预生成高质量的偏好信号，以提升自动化对齐的效果。SSO在迭代训练过程中依据预定义原则自动生成偏好信号，进而消除了对人工标注的需求。该算法在保持选择与拒绝响应之间准确间隔的同时，确保它们均符合当前策略模型的学习能力。SSO不仅支持策略模型的在线和离线训练，还能增强奖励模型的训练效果。我们通过两个基础模型Qwen2和Llama3.1验证了SSO的有效性，结果表明SSO在整个迭代训练过程中产生了准确的、符合政策的偏好信号。SSO在没有任何人工标注或外部模型的情况下，在六个主观或客观基准上显著提升了性能。此外，通过SSO生成的偏好数据还显著改善了奖励模型在Rewardbench上的表现。我们的研究为偏好优化提供了一种可扩展的方法，为更高效、更有效的自动化对齐奠定了基础。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.17131" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 23 Oct 2024 05:49:09 GMT</pubDate>
</item>
<item>
<title>SpectroMotion：结合3D高斯点云与物理基础渲染的动态高光场景重建新方法</title>
<link>https://arxiv.org/abs/2410.17249</link>
<guid>https://arxiv.org/abs/2410.17249</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">提出了一种新的方法，结合3D Gaussian Splatting与物理基础渲染，重建动态高光场景。</p><br /><br /><p><strong>摘要：</strong> 本研究介绍了SpectroMotion，一种新颖的方法，将3D Gaussian Splatting (3DGS)、物理基础渲染 (PBR)和变形场结合，以重建动态高光场景。以往扩展3DGS的方法在准确表示高光表面方面存在不足。我们的创新在于引入了一种残差校正技术，用于动态变形过程中的表面法线计算，并配备了适应时变光照条件的可变形环境贴图。此外，我们实施了一种粗到细的训练策略，显著提升了场景几何和高光颜色预测的质量。实验表明，我们的模型在动态高光对象的视图合成上优于以往方法，并且是现有3DGS方法中唯一能够合成真实世界动态高光场景的技术，尤其在渲染复杂、动态和高光场景方面表现出色。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.17249" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 23 Oct 2024 04:41:54 GMT</pubDate>
</item>
<item>
<title>PyramidDrop：提高大型视觉语言模型效率的视觉冗余降低策略</title>
<link>https://arxiv.org/abs/2410.17247</link>
<guid>https://arxiv.org/abs/2410.17247</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出PyramidDrop策略，有效减少LVLM中的视觉冗余，显著提升训练和推理效率。</p><br /><br /><p><strong>摘要：</strong> 随着大型视觉语言模型（LVLM）在图像输入信息表达中的广泛应用，传统方法往往需要大量的图像token，这增加了计算成本，尤其在输入图像分辨率提高时，计算需求呈现平方级增长，影响了训练和推理的效率。虽然有研究通过在模型初期减少图像token数量的方法进行了尝试，但这些方法往往导致重要信息的丢失，从而降低了模型性能。本研究通过实证分析发现，LVLM在浅层模型中需要所有视觉token，而在深层模型中，token的冗余性逐渐增加。基于此，我们提出了PyramidDrop策略，该策略在每个阶段结束时按预定义比例丢弃部分图像token，形成金字塔式的视觉token结构，这一过程基于轻量级的相似性计算，时间开销可以忽略不计。大量实验表明，PyramidDrop可以将LLaVA-NeXT的训练时间提升40%，推理FLOPs减少55%，且性能与对比方法相当。此外，PyramidDrop还可以作为推理加速的即插即用策略，具备更优的性能和更低的推理成本。我们希望PyramidDrop所提供的洞察与方法能够启发未来的研究，深入探讨图像token在LVLM中的作用。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.17247" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 23 Oct 2024 04:36:27 GMT</pubDate>
</item>
<item>
<title>JMMMU：首个针对日语的大规模多模态模型基准测试</title>
<link>https://arxiv.org/abs/2410.17250</link>
<guid>https://arxiv.org/abs/2410.17250</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文介绍了JMMMU，一个针对日语多模态模型的基准测试，探讨了文化对模型性能的影响。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了JMMMU（Japanese MMMU），这是第一个旨在评估大型多模态模型（LMMs）在日本文化背景下的专家级任务的大规模日语基准。为了便于全面的文化意识评估，JMMMU包含两个互补的子集：（i）文化无关（CA）子集，选择文化独立的主题（例如，数学）并翻译成日语，使其能够与其英语对应物MMMU进行逐一比较；（ii）文化特定（CS）子集，包含新创作的主题，反映日本文化背景。通过CA子集的测试，我们观察到在日语环境下许多LMMs的性能出现下降，这主要归因于语言差异。使用CS子集则揭示了模型对日本文化的理解不足。此外，结合这两个子集，我们发现一些LMMs在CA子集中表现良好，而在CS子集中表现不佳，这表明它们对日语的理解存在很多表面化的问题，缺乏深度的文化理解。我们希望这一工作不仅能够推动LMM在日语领域的表现，同时也为打造高标准和文化多样性的多语言LMM开发基准提供指导。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.17250" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 23 Oct 2024 03:52:20 GMT</pubDate>
</item>
<item>
<title>EvoPress：一种适应性动态压缩的广义框架</title>
<link>https://arxiv.org/abs/2410.14649</link>
<guid>https://arxiv.org/abs/2410.14649</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出了新框架EvoPress，实现LLM动态压缩，优化精度与效率。</p><br /><br /><p><strong>摘要：</strong> 随着大规模语言模型（LLMs）计算成本的增加，LLM压缩方法如量化、稀疏化和结构化剪枝盛行。然而，当前的方法往往依据启发式规则评估各层对模型性能的影响，这些假设如误差单调性，未必适用于实际情况。本文提出了EvoPress，一种新的动态压缩框架，具有可证明的收敛性及低样本和评估复杂性。研究表明，误差单调性在LLMs中并不成立，导致某些压缩模型的总体层级误差和低于其他模型，却表现更差。EvoPress通过动态调整不同层的压缩水平，达到了优化后的压缩效果。我们在Llama、Mistral和Phi模型上进行了实验，结果显示EvoPress在结构剪枝、非结构稀疏性和动态位宽量化等多个压缩方法上设定了新的最优结果。代码已公开于GitHub上，促进更多研究者在该领域的探索。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.14649" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 23 Oct 2024 02:56:38 GMT</pubDate>
</item>
<item>
<title>MiniPLM：高效灵活的知识蒸馏框架用于预训练语言模型</title>
<link>https://arxiv.org/abs/2410.17215</link>
<guid>https://arxiv.org/abs/2410.17215</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">MiniPLM通过精炼训练数据分布，提升小型语言模型的性能与效率。</p><br /><br /><p><strong>摘要：</strong> 知识蒸馏（KD）被广泛用于通过大型教师语言模型（LM）训练小型高性能学生LM。尽管KD在微调过程中有效，但其在预训练阶段面临效率、灵活性和有效性等挑战。现有的方法通常因在线教师推理导致高计算成本，或要求教师与学生LM之间的标记匹配，此外，还可能导致教师生成的训练数据难度和多样性丧失。为了应对这些问题，我们提出了MiniPLM框架，通过精炼训练数据分布以融入教师的知识，从而实现学生LM的预训练。MiniPLM通过离线教师LM推理提高效率，让多种学生LM能够在不增加训练时间成本的情况下进行KD；同时，MiniPLM仅在训练语料库上操作，增强了跨模型家族的灵活性。此外，MiniPLM通过利用大模型与小模型之间的差异，提升了训练数据的难度和多样性，帮助学生LM获取更加多样化和复杂的知识。大量实验表明，MiniPLM在9个广泛使用的下游任务上提升了学生LM的性能，改善了语言建模能力，并减少了预训练计算量。MiniPLM的优势还体现在大规模预训练的可扩展性上，我们的模型、代码和数据可在 https://github.com/thu-coai/MiniPLM获取。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.17215" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 23 Oct 2024 02:38:05 GMT</pubDate>
</item>
<item>
<title>寻找模仿阈值：对文本到图像模型版权侵权的研究</title>
<link>https://arxiv.org/abs/2410.15002</link>
<guid>https://arxiv.org/abs/2410.15002</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本研究探讨文本到图像模型在模仿概念时的训练阈值，以及其对版权和隐私的影响。</p><br /><br /><p><strong>摘要：</strong> 本文研究了文本到图像模型的训练数据集中概念频率与模型模仿能力之间的关系，提出了寻找模仿阈值（Finding the Imitation Threshold, FIT）这一新问题。该研究聚焦于人脸和艺术风格两个领域，通过创建四个数据集并评估三种文本到图像模型，探讨了训练数据量对模仿能力的影响。结果表明，这些模型的模仿阈值范围在200到600张图像之间，具体取决于领域和模型。模仿阈值的发现为版权侵权的实证基础提供了支持，同时也为希望遵循版权和隐私法律的文本到图像模型开发者提供了指导原则。本研究发布的代码和数据可在 https://github.com/vsahil/MIMETIC-2.git 获得，项目网站则可访问 https://how-many-van-goghs-does-it-take.github.io。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.15002" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 15:55:59 GMT</pubDate>
</item>
<item>
<title>Agent-to-Sim (ATS)：从视频学习3D代理的交互行为模型</title>
<link>https://arxiv.org/abs/2410.16259</link>
<guid>https://arxiv.org/abs/2410.16259</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">ATS框架通过视频观察学习3D代理的自然行为，支持真实到仿真转移。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了Agent-to-Sim (ATS)框架，该框架通过随机录像收集，学习3D代理（如动物和人类）的交互行为模型。与以往依赖于标记跟踪和多视角摄像头的方法不同，ATS通过在单一环境中 طول时间（例如一个月）记录的非侵入式视频观察，获取自然行为数据。为了实现持续的3D跟踪，ATS开发了一种粗到细的登记方法，能够在一个规范的3D空间中持续跟踪代理和摄像头，从而构建一个完整的、持久的时空4D表示。利用从4D重建中获取的代理感知和运动的配对数据，ATS训练生成代理行为的模型。这一框架支持从视频录制到互动行为模拟器的真实到仿真转移，展示了在宠物（如猫、狗和兔子）及人类的实验结果，这些结果均基于智能手机拍摄的单目RGBD视频。此项研究为无创3D代理行为分析提供了新方法。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.16259" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 15:28:31 GMT</pubDate>
</item>
<item>
<title>简约模型与上下文学习：关联探索与改进建议</title>
<link>https://arxiv.org/abs/2410.14086</link>
<guid>https://arxiv.org/abs/2410.14086</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文探讨了简约模型在上下文学习中的重要性，提出了通过预先编码法优化学习过程的方法。</p><br /><br /><p><strong>摘要：</strong> 文章探讨了机器学习中通用性的目标，以及在实践中观察到的简单模型常常能够更好地泛化的现象，即奥卡姆剃刀原则。尽管简单模型的重要性显而易见，当前的大多数机器学习方法仅仅关注于最小化训练误差，偶尔通过正则化或架构设计间接促进简约性。在这篇文章中，我们将奥卡姆剃刀原则与上下文学习联系起来，深入分析了某些序列模型（如Transformer）在推理时从过去的观察中学习的能力。特别是，我们展示了用于训练上下文学习者的下一个标记预测损失与一种称为预先编码（prequential coding）的数据压缩技术是直接等价的，最小化此损失实际上等同于同时最小化训练误差与基于上下文隐含学习的模型复杂性。我们的理论和实证实验不仅为上下文学习提供了规范性的分析，也揭示了现有上下文学习方法的不足之处，并提出了改进建议。代码已在 https://github.com/3rdCore/PrequentialCode 提供。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.14086" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 12:21:20 GMT</pubDate>
</item>
<item>
<title>基于动态深度的混合层跳过模型</title>
<link>https://arxiv.org/abs/2410.13184</link>
<guid>https://arxiv.org/abs/2410.13184</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出了一种通过Router-Tuning和MindSkip优化Mixture of Depths的训练成本和性能。</p><br /><br /><p><strong>摘要：</strong> 传统的Transformer模型在处理每个输入标记时分配固定的计算资源，造成低效和不必要的计算。为了解决这一问题，本文提出了Mixture of Depths (MoD)的动态深度调整方法，通过跳过不重要的层来提高计算效率。然而，现有的MoD方法仍需进一步探索，主要面临两个挑战：(1) 由于需要训练整个模型及其路由器，导致高昂的训练成本；(2) 跳过重要层可能导致性能下降。为应对第一个问题，本文提出了Router-Tuning方法，仅在小数据集上微调路由器，从而显著降低全模型训练的计算开销。针对第二个挑战，本文提出了MindSkip，采用动态深度的注意力机制，确保在保留模型性能的同时，显著提升计算和内存效率。通过大量实验，验证了我们的方法在实现竞争性结果的同时，显著提高了计算效率，如21%的速度提升和仅0.2%的性能下降。相关代码已在https://github.com/CASE-Lab-UMD/Router-Tuning发布。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.13184" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 12:16:10 GMT</pubDate>
</item>
<item>
<title>Hallucination Detox: Sensitive Neuron Dropout (SeND) for Large Language Model Training</title>
<link>https://arxiv.org/abs/2410.15460</link>
<guid>https://arxiv.org/abs/2410.15460</guid>
<content:encoded><![CDATA[
As large language models (LLMs) become increasingly deployed across various industries, concerns regarding their reliability, particularly due to hallucinations-outputs that are factually inaccurate or irrelevant to user input-have grown. Our research investigates the relationship between the training process and the emergence of hallucinations to address a key gap in existing research that focuses primarily on post hoc detection and mitigation strategies. Using models from the Pythia suite (70M-12B parameters) and several hallucination detection metrics, we analyze hallucination trends throughout training and explore LLM internal dynamics. We introduce SEnsitive Neuron Dropout (SeND), a novel training protocol designed to mitigate hallucinations by reducing variance during training. SeND achieves this by deterministically dropping neurons with significant variability on a dataset, referred to as Sensitive Neurons. In addition, we develop an unsupervised hallucination detection metric, Efficient EigenScore (EES), which approximates the traditional EigenScore in 2x speed. This efficient metric is integrated into our protocol, allowing SeND to be both computationally scalable and effective at reducing hallucinations. Our empirical evaluation demonstrates that our approach improves LLM reliability at test time by up to 40% compared to normal training while also providing an efficient method to improve factual accuracy when adapting LLMs to domains such as Wikipedia and Medical datasets.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 11:59:59 GMT</pubDate>
</item>
<item>
<title>Ichigo：一种基于混合模态的语音与文本处理模型</title>
<link>https://arxiv.org/abs/2410.15316</link>
<guid>https://arxiv.org/abs/2410.15316</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文介绍了Ichigo，一个混合模态模型，通过统一的transformer架构高效处理语音和文本。</p><br /><br /><p><strong>摘要：</strong> Large Language Models（LLMs）在自然语言处理领域取得了显著突破。然而，将其应用于语音任务依然面临挑战，特别是在音频和文本模态的整合方面。本文提出了Ichigo，一种混合模态模型，能够无缝处理交替序列的语音和文本。Ichigo采用了令牌化的早期融合方法，将语音量化为离散令牌，并对语音和文本模态使用统一的transformer架构。这种方法使得跨模态的联合推理与生成成为可能，而无需单独的适配器。我们详细介绍了包括在多语言语音识别数据集上进行预训练和在精心策划的指令数据集上进行微调的综合训练方法。实验结果显示，Ichigo在语音问答基准测试中表现出色，超越了现有的开源语音语言模型，同时与级联系统的结果相当。值得注意的是，Ichigo的首次令牌生成延迟仅为111毫秒，显著低于其他现有模型。我们的方法不仅推动了多模态人工智能的发展，也为小型研究团队有效贡献于开源语音语言模型提供了框架。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.15316" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 11:40:31 GMT</pubDate>
</item>
<item>
<title>基于大型语言模型的连续马尔可夫决策过程动态预测</title>
<link>https://arxiv.org/abs/2410.11711</link>
<guid>https://arxiv.org/abs/2410.11711</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出了一种利用预训练大型语言模型进行连续马尔可夫决策过程动态预测的方法。</p><br /><br /><p><strong>摘要：</strong> 随着大型语言模型（LLMs）零-shot 能力的不断提升，其应用领域已扩展至自然语言处理之外的多个领域。在强化学习中，尽管 LLMs 在文本环境中得到了广泛应用，但其在连续状态空间中的整合仍然尚未得到充分研究。本文探讨如何利用预训练的 LLMs 进行连续马尔可夫决策过程的动态预测。我们确定了处理多元数据和引入控制信号这两个关键挑战，这些挑战限制了 LLMs 在此设置下的潜力，并提出了解决方案——解耦式上下文学习（Disentangled In-Context Learning, DICL）。我们在模型驱动策略评估和数据增强的离线强化学习两个设置中展示了该方法的概念性应用，并提供了对相关方法的理论分析。实验结果进一步验证了我们的方法能够生成良好校准的置信度估计。代码已发布在 https://github.com/abenechehab/dicl。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.11711" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 08:05:14 GMT</pubDate>
</item>
<item>
<title>Alchemy：通过符号变换合成形式化定理的框架</title>
<link>https://arxiv.org/abs/2410.15748</link>
<guid>https://arxiv.org/abs/2410.15748</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出Alchemy，一个通过符号变换合成形式化定理的框架，显著扩充Mathlib中的定理数量。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了一种名为Alchemy的通用框架，该框架旨在通过符号变换构建形式化定理，以解决神经定理证明（NTP）面临的数据稀缺问题。聚焦于Mathlib中的候选定理，Alchemy识别出所有可以应用于这些定理的可调用定理，并通过将相关术语替换为其等价形式或前提进行变换，从而显著增加定理数量，将Mathlib中的定理数量从11万增长至600万。此外，本文对扩充后的语料库进行了持续预训练和监督微调，实验结果表明该方法的有效性，在Leandojo基准上实现了5%的绝对性能提升，并在具有一定出分布的数据集miniF2F上提升了2.5%的绝对性能。最后，本文还对合成数据的组成和训练范式进行了全面分析，为强大的定理证明器的开发提供了有价值的指导。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.15748" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 06:55:29 GMT</pubDate>
</item>
<item>
<title>面向长指令的长距离依赖样本选择框架 GATEAU</title>
<link>https://arxiv.org/abs/2410.15633</link>
<guid>https://arxiv.org/abs/2410.15633</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出 GATEAU 框架，通过优质长样本提升长指令的理解能力。</p><br /><br /><p><strong>摘要：</strong> 本文探讨了大规模语言模型处理长指令时面临的长上下文对齐挑战，提出了GATEAU这一新框架。该框架旨在识别具有重要长距离依赖关系的优质样本。现有研究通过合成长指令样本扩展数据集，但缺乏确保数据质量的明确策略可能会引入低质量样本。GATEAU通过两种方法实现样本选择：Homologous Models' Guidance (HMG) 和 Contextual Awareness Measurement (CAM)。HMG利用同源模型的困惑度评分测量生成响应的难度，评估由于长距离依赖关系导致的挑战；CAM则评估模型注意力如何集中于重要片段，以理解长输入上下文的难度。实验结果表明，GATEAU能够有效识别出富含长距离依赖关系的样本，基于这些样本训练的模型在指令跟随和长上下文理解能力方面表现更优。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.15633" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 04:46:20 GMT</pubDate>
</item>
<item>
<title>AutoTrain Advanced：简化训练自定义数据集的开源工具</title>
<link>https://arxiv.org/abs/2410.15735</link>
<guid>https://arxiv.org/abs/2410.15735</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">AutoTrain Advanced 是一款开源无代码工具，可用于不同任务的模型训练与微调。</p><br /><br /><p><strong>摘要：</strong> 随着开源模型的进步，在自定义数据集上训练（或微调）模型已成为开发特定工业或开源应用解决方案的重要部分。然而，目前尚无单一工具可以简化不同类型模态或任务的训练过程。因此，AutoTrain（又称 AutoTrain Advanced）的出现至关重要。AutoTrain Advanced 是一个开源、无代码工具/库，旨在为各种任务训练（或微调）模型，包括大型语言模型（LLM）微调、文本分类/回归、标记分类、序列到序列任务、句子变换器微调、视觉语言模型（VLM）微调、图像分类/回归以及表格数据的分类和回归任务。该库提供了针对自定义数据集模型训练的最佳实践。AutoTrain Advanced 可在完全本地模式或云机器上使用，并与 Hugging Face Hub 上共享的数万个模型及其变体兼容，从而为用户提供了灵活高效的模型训练解决方案。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.15735" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 04:10:40 GMT</pubDate>
</item>
<item>
<title>预训练蒸馏：扩大知识蒸馏在大语言模型中的应用</title>
<link>https://arxiv.org/abs/2410.16215</link>
<guid>https://arxiv.org/abs/2410.16215</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文探讨了在预训练阶段应用知识蒸馏的方法，验证了模型间的学习效能。</p><br /><br /><p><strong>摘要：</strong> 知识蒸馏（KD）旨在将大教师模型的知识传递给更小的学生模型。以往在大语言模型（LLMs）领域的KD研究主要集中在后训练阶段，学生LLM直接从教师模型生成的指令及相应响应中学习。本文通过在LLMs的预训练阶段扩展KD，提出了预训练蒸馏（PD）的方法。首先，我们使用GLM-4-9B作为教师LLM进行了一项初步实验，验证了PD在1.9B参数的学生LLM上的有效性。考虑到蒸馏的关键影响因素，我们系统地探讨了预训练蒸馏中的设计空间，包括四个方面：logits处理、损失选择、缩放法则及离线或在线logits。我们的广泛实验探索了预训练蒸馏的设计空间，找到了更优的配置及一些有趣的结论，如更大的学生LLM通常能更从预训练蒸馏中受益，而更大的教师LLM并不一定能保证更好的效果。我们希望本研究对未来的预训练蒸馏实践提供指导。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.16215" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 04:09:39 GMT</pubDate>
</item>
<item>
<title>SAM2Long：面向复杂长视频的改进训练自由视频目标分割策略</title>
<link>https://arxiv.org/abs/2410.16268</link>
<guid>https://arxiv.org/abs/2410.16268</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">SAM2Long策略通过约束树搜索选择最佳分割路径，有效减少了错误积累，提高了长视频目标分割性能。</p><br /><br /><p><strong>摘要：</strong> Segment Anything Model 2 (SAM 2)在图像和视频的目标分割领域表现出色，但其贪婪选择记忆设计导致了错误积累问题，限制了在复杂长视频中的性能。为此，我们提出了SAM2Long，一个改进的训练自由视频目标分割策略。该策略考虑帧内分割不确定性，并通过约束树搜索选择多条分割路径中的最佳视频级别结果。在实际操作中，我们对整个视频保持固定数量的分割路径。每帧提出多个掩码，根据现有路径创建不同候选分支，然后选择累计得分较高的固定数量分支作为下一帧的新路径。在处理完最后一帧后，选择累计得分最高的路径作为最终分割结果。得益于其启发式搜索设计，SAM2Long在处理遮挡和物体重现方面表现出色，能够有效地对复杂长视频中的对象进行分割和跟踪。实验结果表明，SAM2Long在24组对比中平均提高了3.0个点，在SA-V和LVOS等长视频目标分割基准上提升了多达5.3个点。代码已在https://github.com/Mark12Ding/SAM2Long发布。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.16268" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 03:38:14 GMT</pubDate>
</item>
<item>
<title>RM-Bench: Benchmarking Reward Models of Language Models with Subtlety and Style</title>
<link>https://arxiv.org/abs/2410.16184</link>
<guid>https://arxiv.org/abs/2410.16184</guid>
<content:encoded><![CDATA[
Reward models are critical in techniques like Reinforcement Learning from Human Feedback (RLHF) and Inference Scaling Laws, where they guide language model alignment and select optimal responses. Despite their importance, existing reward model benchmarks often evaluate models by asking them to distinguish between responses generated by models of varying power. However, this approach fails to assess reward models on subtle but critical content changes and variations in style, resulting in a low correlation with policy model performance. To this end, we introduce RM-Bench, a novel benchmark designed to evaluate reward models based on their sensitivity to subtle content differences and resistance to style biases. Extensive experiments demonstrate that RM-Bench strongly correlates with policy model performance, making it a reliable reference for selecting reward models to align language models effectively. We evaluate nearly 40 reward models on RM-Bench. Our results reveal that even state-of-the-art models achieve an average performance of only 46.6%, which falls short of random-level accuracy (50%) when faced with style bias interference. These findings highlight the significant room for improvement in current reward models. Related code and data are available at https://github.com/THU-KEG/RM-Bench.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 02:51:09 GMT</pubDate>
</item>
<item>
<title>FrugalNeRF：高效的少样本神经辐射场框架</title>
<link>https://arxiv.org/abs/2410.16271</link>
<guid>https://arxiv.org/abs/2410.16271</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">FrugalNeRF通过跨尺度几何适配方案优化少样本NeRF，提升3D重建精度和训练效率。</p><br /><br /><p><strong>摘要：</strong> 神经辐射场（NeRF）在少样本场景下面临显著挑战，主要表现在过拟合及高保真渲染所需的长训练时间。现有方法如FreeNeRF和SparseNeRF虽然采用了频率正则化或预训练先验，但在复杂调度和偏差问题上仍显得无力。为此，我们提出了FrugalNeRF，这是一种新的少样本NeRF框架，通过在多个尺度间共享权重体素，高效地表示场景细节。我们的关键贡献是一种跨尺度几何适配方案，该方案基于重投影误差选择伪地面真实深度，从而在不依赖外部学习先验的情况下引导训练，充分利用训练数据。同时，FrugalNeRF也可集成预训练的先验，提升质量而不影响收敛速度。在LLFF、DTU和RealEstate-10K数据集上的实验表明，FrugalNeRF在超越其他少样本NeRF方法的同时，显著减少了训练时间，是一种实用的高效准确的3D场景重建解决方案。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.16271" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 02:26:36 GMT</pubDate>
</item>
<item>
<title>Meta-Chunking: 基于深层语义关系的文本分块方法</title>
<link>https://arxiv.org/abs/2410.12788</link>
<guid>https://arxiv.org/abs/2410.12788</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出Meta-Chunking概念，通过两种新策略提升RAG在知识密集任务中的表现。</p><br /><br /><p><strong>摘要：</strong> 本文提出了Meta-Chunking的概念，以填补Retrieval-Augmented Generation (RAG) 中文本分块的重要缺失，影响知识密集型任务的质量。Meta-Chunking是介于句子与段落之间的一种分块方法，涉及段落内具有深层次语言逻辑关系的一系列句子。为此，本文设计了两种基于大语言模型（LLMs）的分块策略：Margin Sampling Chunking和Perplexity Chunking。前者利用LLMs对连续句子进行二元分类，以判断是否需要分割，基于边际抽样获得的概率差异做出决策；后者通过分析困惑度分布的特征精确识别文本分块边界。考虑到不同文本的复杂性，本文还提出了一种将Meta-Chunking与动态合并相结合的策略，以实现细粒度和粗粒度文本分块之间的平衡。在11个数据集上进行的实验表明，Meta-Chunking能够更有效地提升基于RAG的单跳和多跳问答性能。例如，在2WikiMultihopQA数据集上，Meta-Chunking的表现比相似分块高出1.32，同时时间消耗仅为45.8%。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.12788" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 02:24:32 GMT</pubDate>
</item>
<item>
<title>Pangea：面向多语言和多文化背景的多模态大语言模型</title>
<link>https://arxiv.org/abs/2410.16153</link>
<guid>https://arxiv.org/abs/2410.16153</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文介绍了Pangea及其多语言多模态训练数据集PangeaIns，展示了在跨文化情境下的评估优势。</p><br /><br /><p><strong>摘要：</strong> 尽管近年来多模态大型语言模型（MLLMs）取得了显著进展，但其开发主要集中在英语和西方中心的数据集与任务上，导致世界大部分语言和文化背景被忽视。本文提出了Pangea，这是一个多语言多模态的LLM，基于PangeaIns训练，后者是一个多达600万条指令的多样化数据集，涵盖39种语言。PangeaIns的特点包括：1）高质量的英语指令，2）精心机器翻译的指令，以及3）具有文化相关性的多模态任务，以确保跨文化的覆盖。为全面评估模型的能力，我们引入了PangeaBench，这是一个涵盖47种语言的综合评估套件，包含14个数据集。结果显示，Pangea在多语言环境和多样文化背景下显著超越现有的开放源代码模型。消融研究进一步揭示了英语数据比例、语言普及度和多模态训练样本数量对整体性能的重要性。我们全面开源我们的数据、代码和训练检查点，以促进包容性和强大的多语言MLLM的发展，推动更广泛的语言和文化范围的公平性和可及性。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.16153" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 02:07:31 GMT</pubDate>
</item>
<item>
<title>跨语言自动评估套件：Hercule的设计与实现</title>
<link>https://arxiv.org/abs/2410.13394</link>
<guid>https://arxiv.org/abs/2410.13394</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出了CIA套件，包含Hercule模型和Recon测试集，以实现多语言评估。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了跨语言自动评估(CIA)套件及其组成部分，包括评估模型Hercule和多语言测试集Recon。此框架旨在解决当前自然语言处理(NLP)领域在非英语语言中的评估挑战。测试集包含500条人类注释的指令，涵盖多种任务能力，并提供六种语言的人类评分。这一套件可以用于基准评估通用多语言大型语言模型(LLMs)，并促成评估模型的元评估。Hercule模型通过学习使用英语参考答案为目标语言的响应评分，克服了在低资源场景中目标语言参考答案不足的问题。实验结果表明，Hercule模型在与人工评判对比中，表现出更高的一致性，显示了其在见未见语言上的零样本评估能力。这项研究是对跨语言评估的首次全面探讨，提出了一种可扩展且有效的多语言评估方法。所有代码、数据集和模型将在公开平台上发布，以推动该领域的进一步研究。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.13394" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 01:37:42 GMT</pubDate>
</item>
<item>
<title>PUMA：赋能统一的多模态大语言模型的多粒度视觉生成</title>
<link>https://arxiv.org/abs/2410.13861</link>
<guid>https://arxiv.org/abs/2410.13861</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">PUMA提出了一种统一的多模态大语言模型框架，适应不同的图像生成任务的粒度需求。</p><br /><br /><p><strong>摘要：</strong> 近年来，多模态基础模型在视觉-语言理解方面取得了显著进展。而多模态大语言模型（MLLM）在视觉内容生成方面也展现出潜力。然而，现有研究在统一的MLLM框架内对不同图像生成任务的粒度需求关注不足，从文本到图像生成所需的多样性，到图像操作所需的精准可控性。在此背景下，我们提出了PUMA，赋能统一的MLLM与多粒度视觉生成。PUMA将多粒度视觉特征统一作为MLLM的输入和输出，有效解决了不同图像生成任务的粒度需求。经过多模态预训练和任务特定的指令调优，PUMA在各种多模态任务中表现出色。这项工作为实现真正统一的MLLM迈出了重要一步，使其能够适应各种视觉任务的粒度需求。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.13861" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 01:33:52 GMT</pubDate>
</item>
<item>
<title>CompassJudger-1：开源全能评估模型及其基准测试</title>
<link>https://arxiv.org/abs/2410.16256</link>
<guid>https://arxiv.org/abs/2410.16256</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文介绍了CompassJudger-1，首个开源通用评估模型，及其新创建的JudgerBench基准。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了CompassJudger-1，这是首个开源的全能评估模型，旨在提升大型语言模型（LLMs）的评估效率和准确性。针对主观评估方法的人力资源消耗和重复性不足的问题，CompassJudger-1提供了多项功能，包括单一评分、双模型比较、格式化评估和生成反馈等。此外，为了评估不同评估模型的能力，文章还建立了JudgerBench，这是一个新的基准，涵盖多种主观评估任务和广泛主题。发布CompassJudger-1和JudgerBench旨在促进研究社区的合作，加速LLM评估方法的发展。这些工具的开源能够为研究者提供全面的解决方案，灵活适应各种评估需求。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.16256" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 01:25:17 GMT</pubDate>
</item>
<item>
<title>融合上下文信息的综合语音标记器DM-Codec的研究</title>
<link>https://arxiv.org/abs/2410.15017</link>
<guid>https://arxiv.org/abs/2410.15017</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">提出DM-Codec模型，通过上下文信息的引入，显著提高语音标记的准确性和质量。</p><br /><br /><p><strong>摘要：</strong> 近年来，语音语言模型的快速发展在语音标记化和合成方面取得了显著进步。然而，将复杂的、多维度的语音属性精准映射到离散标记中依然具有挑战性。现有语音表示通常分为来自音频编解码器的声学标记和来自自监督学习模型的语义标记。尽管近期有尝试将声学和语义标记统一，但却忽视了上下文表示在全面语音建模中的重要作用。我们的实证研究表明，缺乏上下文表示使得语音转录中的字错误率（WER）和信息丢失（WIL）升高。为了解决这些局限，我们提出了两种新的蒸馏方法：1）一种语言模型（LM）引导的蒸馏方法，融合上下文信息；2）一种结合LM与自监督语音模型（SM）引导的蒸馏技术，将声学、语义和上下文等多模态表示有效蒸馏为综合语音标记器，命名为DM-Codec。DM-Codec架构采用简化的编码器-解码器框架，配备残差向量量化器（RVQ），并在训练过程中融入LM与SM。实验结果表明，DM-Codec在LibriSpeech基准数据集上显著优于现有最先进的语音标记化模型，将WER减少了最多13.46%，WIL下降了9.82%，并将语音质量提升了5.84%，可懂度改善了1.85%。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.15017" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 01:20:41 GMT</pubDate>
</item>
<item>
<title>Baichuan Alignment：提升AI模型对齐技术的深入分析</title>
<link>https://arxiv.org/abs/2410.14940</link>
<guid>https://arxiv.org/abs/2410.14940</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文分析Baichuan系列模型的对齐技术，为AI研究提供重要见解。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了Baichuan Alignment，这是一项对Baichuan系列模型所采用的对齐技术的详细分析，旨在为AI研究提供宝贵的见解。研究探讨了对齐过程中的关键组成部分，包括优化方法、数据策略、能力增强和评估过程。该过程分为三个主要阶段：Prompt Augmentation System (PAS)、Supervised Fine-Tuning (SFT)和Preference Alignment。文中详细记录了遇到的问题、应用的解决方案及所做的改进。通过与已有基准的比较，展示了Baichuan Alignment带来的技术进步。Baichuan-Instruct为内部模型，而Qwen2-Nova-72B和Llama3-PBM-Nova-70B则是基于Qwen2-72B和Llama-3-70B的优化指令版本。Baichuan-Instruct在核心能力方面表现出显著提升，用户体验提升幅度在17%至28%之间，并且在专业基准上表现优异。在开源基准评估中，Qwen2-Nova-72B和Llama3-PBM-Nova-70B在几乎所有数据集上均超越了其官方的指令版本。本文旨在澄清对齐过程中的关键技术，促进社区对这一领域的更深入理解。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.14940" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 01:17:50 GMT</pubDate>
</item>
<item>
<title>SemiEvol：一种半监督微调框架用于大规模语言模型的适应性</title>
<link>https://arxiv.org/abs/2410.14745</link>
<guid>https://arxiv.org/abs/2410.14745</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本研究介绍SemiEvol框架，通过半监督方式有效利用标记和未标记数据进行大语言模型的微调。</p><br /><br /><p><strong>摘要：</strong> 随着大规模语言模型（LLMs）的广泛应用，监督微调（SFT）成为了适应特定领域或任务的关键。然而，现实应用中可用的标记数据极为有限，这对SFT的效果造成了很大挑战。因此，需要一种高效利用标记和未标记数据的微调框架。为此，本文提出了一个名为SemiEvol的半监督微调框架，通过传播和选择的方式进行LLM的适应性调整。在知识传播方面，SemiEvol采用了双层次的方法，通过权重内传播和上下文内传播将标记数据的知识传递给未标记数据。在知识选择方面，框架结合了协同学习机制，选择更高质量的伪响应样本。我们在七个通用或特定领域的数据集上使用GPT-4o-mini和Llama-3.1进行了实验，结果显示模型在目标数据上的性能得到了显著提升。此外，我们将SemiEvol与SFT和自进化方法进行了比较，突显了其在混合数据场景下的实用性。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.14745" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:58:50 GMT</pubDate>
</item>
<item>
<title>利用大型语言模型评估认知行为疗法的潜力：CBT-BENCH基准的提出</title>
<link>https://arxiv.org/abs/2410.13218</link>
<guid>https://arxiv.org/abs/2410.13218</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文探讨利用大型语言模型辅助心理治疗的潜力，并提出CBT-BENCH基准，以评估其在认知行为疗法中的应用。</p><br /><br /><p><strong>摘要：</strong> 本文探讨当前患者需求与可用心理健康支持之间的显著差距，重点分析大型语言模型（LLMs）在专业心理治疗中的潜在应用。为此，本文提出了一种新的基准——CBT-BENCH，旨在系统性评估认知行为疗法（CBT）辅助。这一基准包含三个任务层次：第一层是基本CBT知识获取，通过选择题进行评估；第二层为认知模型理解，包括认知扭曲分类、主要核心信念分类和细粒度核心信念分类；第三层为治疗响应生成，主要任务是生成对患者发言的响应。这些任务涵盖了CBT的关键要素，可以通过人工智能的帮助得到增强，同时构建了一种能力要求的层级结构，从基本知识的复述到参与真实的治疗对话。我们对代表性的LLMs在这个基准上的表现进行了评估。实验结果表明，虽然LLMs在复述CBT知识方面表现良好，但在需要深度分析患者认知结构和生成有效响应的复杂真实场景中，它们的能力仍有不足，这为未来的研究指明了方向。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.13218" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:40:03 GMT</pubDate>
</item>
<item>
<title>Shakti：为边缘设备优化的高效语言模型</title>
<link>https://arxiv.org/abs/2410.11331</link>
<guid>https://arxiv.org/abs/2410.11331</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">Shakti是一款针对资源受限环境优化的语言模型，适用于边缘设备和多领域应用。</p><br /><br /><p><strong>摘要：</strong> Shakti是一款拥有25亿参数的语言模型，专为资源受限的环境优化而设计，适合在边缘设备如智能手机、可穿戴设备和物联网系统中运行。它结合了高性能的自然语言处理（NLP）和优化的效率与精确度，理想适用于计算资源和内存有限的实时人工智能应用。Shakti支持多种地方语言及领域特定任务，在医疗、金融和客户服务等行业中表现出色。基准评估表明，Shakti在保持低延迟和设备上高效性的同时，其表现与更大型模型相竞争，使其成为边缘人工智能领域的领先解决方案。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.11331" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 14:19:02 GMT</pubDate>
</item>
<item>
<title>灵活视觉变换器 FiTv2：一种针对任意分辨率图像生成的变换器架构</title>
<link>https://arxiv.org/abs/2410.13925</link>
<guid>https://arxiv.org/abs/2410.13925</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本研究提出了灵活视觉变换器FiTv2，旨在解决图像生成中的分辨率限制问题。</p><br /><br /><p><strong>摘要：</strong> 自然界是分辨率无限的，在此背景下，现有的扩散模型（如扩散变换器）往往面临处理非培训域图像分辨率的挑战。为了解决这个问题，我们将图像概念化为具有动态大小的标记序列，而非传统的固定分辨率网格。这种视角促进了一种灵活的培训策略，可以在培训和推理过程中无缝适应各种长宽比，从而提高分辨率泛化能力并消除因图像裁剪引入的偏差。在此基础上，我们提出了灵活视觉变换器FiT，专为生成无约束分辨率和长宽比的图像而设计。我们进一步改进FiT至FiTv2，引入了几个创新设计，包括Query-Key向量标准化、AdaLN-LoRA模块、修正的流调度程序和Logit-Normal采样器。FiTv2在精心调整的网络结构支持下，展现出2倍于FiT的收敛速度，并通过先进的无培训外推技术，实现了在分辨率外推和多样分辨率生成方面的显著适应性。此外，我们对FiTv2模型的可扩展性进行探索，发现较大的模型展现出更好的计算效率。最终，我们提出了一种高效的后培训策略，旨在为高分辨率生成调整预训练模型。综合实验表明FiTv2在广泛分辨率下的出色性能。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.13925" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 13:46:40 GMT</pubDate>
</item>
<item>
<title>Mini-Omni2：一款多模态视觉音频助手</title>
<link>https://arxiv.org/abs/2410.11190</link>
<guid>https://arxiv.org/abs/2410.11190</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">Mini-Omni2 是一款能够实时响应视觉和音频查询的多模态助手，具备强大的交互能力。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了 Mini-Omni2，一款能够处理视觉和音频查询的多模态助手。Mini-Omni2 结合了预训练的视觉和听觉编码器，确保在各个单一模态中的性能。通过提出三阶段的训练流程，本研究旨在对齐各个模态，最终使语言模型可以处理多模态输入和输出。Mini-Omni2 在经过有限数据集的训练后，展示出在响应用户查询方面的灵活性。我们还引入了一种基于命令的中断机制，以增强用户与助手之间的互动。Mini-Omni2 是对 GPT-4o 功能的一种接近再现，旨在为后续研究提供有价值的见解。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.11190" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 13:21:46 GMT</pubDate>
</item>
<item>
<title>混合自回归变换器（HART）：一种高效的图像生成模型</title>
<link>https://arxiv.org/abs/2410.10812</link>
<guid>https://arxiv.org/abs/2410.10812</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">混合自回归变换器（HART）通过混合标记器有效提高图像生成质量和效率。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了一种混合自回归视觉生成模型——混合自回归变换器（HART），其能够直接生成1024x1024像素的图像，生成质量可与扩散模型相媲美。现有的自回归（AR）模型面临因离散标记器的图像重建质量差以及训练成本高昂而导致的限制。为了解决这些问题，我们提出了混合标记器，该标记器将自编码器的连续潜空间分解为两个组件：代表整体视觉内容的离散标记和代表残余细节的连续标记。离散组件由可扩展分辨率的离散自回归模型建模，而连续组件则通过仅37M参数的轻量级残留扩散模块进行学习。与仅使用离散标记器的VAR模型相比，我们的混合方法在MJHQ-30K数据集上将重建FID从2.11提升至0.30，生成FID也从7.85提高至5.38，提升幅度达31%。HART在FID和CLIP分数上也超过了最先进的扩散模型，其吞吐量提高4.5至7.7倍，计算量减少6.9至13.4倍。代码已开源，链接为https://github.com/mit-han-lab/hart。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.10812" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 13:15:53 GMT</pubDate>
</item>
<item>
<title>BiGR：一种基于紧凑二进制潜在代码的条件图像生成模型</title>
<link>https://arxiv.org/abs/2410.14672</link>
<guid>https://arxiv.org/abs/2410.14672</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">BiGR是一种新型条件图像生成模型，利用二进制潜在代码实现高效的图像生成与表征。</p><br /><br /><p><strong>摘要：</strong> 我们提出了一种新颖的条件图像生成模型BiGR，使用紧凑的二进制潜在代码进行生成训练，旨在提升生成与表征能力。BiGR是首个在同一框架内统一生成与判别的条件生成模型。该模型具有二进制分词器、掩蔽建模机制和用于二进制编码预测的二进制转码器。此外，我们还引入了一种新颖的熵排序采样方法，以实现高效的图像生成。广泛的实验验证了BiGR在生成质量（以FID-50k衡量）和表征能力（通过线性探测精度证明）方面的优越性能。此外，BiGR在各种视觉任务中的零-shot泛化能力也得到了展示，实现了图像修复、扩展、编辑、插值和丰富等应用，无需结构调整。我们的研究结果表明，BiGR有效地统一了生成和判别任务，为该领域的进一步发展奠定了基础。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.14672" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 13:05:25 GMT</pubDate>
</item>
<item>
<title>Montessori-Instruct：针对学生学习过程的合成数据框架</title>
<link>https://arxiv.org/abs/2410.14208</link>
<guid>https://arxiv.org/abs/2410.14208</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本研究提出了一种新型合成数据框架，以优化学生语言模型的学习过程。</p><br /><br /><p><strong>摘要：</strong> 本研究提出了Montessori-Instruct，这是一种新型合成数据框架，旨在通过教师语言模型的合成数据能力，针对学生语言模型的学习过程进行定制。我们利用合成训练数据点对学生的局部数据影响，以表征学生的学习偏好。然后，采用直接偏好优化（Direct Preference Optimization, DPO）训练教师模型，以生成更符合学生学习偏好的合成数据。实验证明，在Alpaca Eval和MT-Bench上使用Llama3-8B-Instruct（教师）和Llama3-8B（学生）的组合，Montessori-Instruct相较于标准合成方法表现出显著的提升，分别提高了18.35%和46.24%。我们的算法还超越了由更强大的教师模型GPT-4o合成的数据。进一步分析表明，教师学习能力的提升使得能生成对学生更具影响力的训练数据，从而提升学生的学习效果，局部数据影响的优势也有助于准确测量学生的偏好。此外，Montessori-Instruct在不同学生模型上的稳健性表现良好。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.14208" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 12:58:48 GMT</pubDate>
</item>
<item>
<title>平衡式说服训练：提升模型对正负说服的适应性</title>
<link>https://arxiv.org/abs/2410.14596</link>
<guid>https://arxiv.org/abs/2410.14596</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本研究提出了平衡式说服训练（PBT），提升模型对正负说服的适应性，增强其在多代理辩论中的表现。</p><br /><br /><p><strong>摘要：</strong> 大型语言模型（LLMs）在面对对立的对话者时易受到说服，这可能带来风险。本文首次探讨了如何增强模型抵抗负面说服的能力，同时强调模型也应能接受有益的正面说服。单纯优化某一类说服会导致模型在另一类上的表现不佳。为此，我们引入了平衡式说服训练（PBT），通过多代理递归对话树创建数据，并通过偏好优化训练模型，以恰当地接受说服。PBT在抵御误信息和应对挑战方面表现良好，同时在包含正负说服的整体数据上提升了模型表现。尤其是在多代理辩论中，PBT模型表现出更好的合作性。在没有PBT的情况下，强模型和弱模型的组合在表现上不稳定，其表现受呈现顺序影响。然而，PBT使得团队合作更平稳，强模型能 consistently 提升弱模型的表现。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.14596" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 12:28:08 GMT</pubDate>
</item>
<item>
<title>大语言模型的自我预测：内省能力的探索</title>
<link>https://arxiv.org/abs/2410.13787</link>
<guid>https://arxiv.org/abs/2410.13787</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本研究探讨了大语言模型是否具备内省能力，实验结果表明经过微调的模型可以更好地预测自身行为。</p><br /><br /><p><strong>摘要：</strong> 本研究旨在探索大语言模型（LLMs）的内省能力，即模型是否能够获取并报告其内部状态所反映的知识，从而增强模型的可解释性。我们通过微调模型，使其能够预测在假设场景下自己行为的特征。例如，当输入为P时，模型会预测其输出是倾向短期还是长期选项。如果模型M1具备内省能力，它在预测自身行为方面应优于模型M2，即使M2在训练上更为强大。我们的实验使用了GPT-4、GPT-4o和Llama-3模型，结果表明，经过微调的模型M1在自我预测中表现优于其他模型，并且即使在我们故意修改其真实行为后，M1仍能准确预测自身行为。然而，尽管在简单任务上成功获取内省能力，在更复杂的任务或需要超出训练分布的推广能力上，我们的探索则表现不佳。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.13787" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 11:27:51 GMT</pubDate>
</item>
<item>
<title>训练方法对神经网络层重要性的影响</title>
<link>https://arxiv.org/abs/2410.14470</link>
<guid>https://arxiv.org/abs/2410.14470</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">研究表明，训练方法影响神经网络不同层的关键性，改善的训练方式增加了早期层的重要性。</p><br /><br /><p><strong>摘要：</strong> 本研究探讨了在恒定架构和训练数据的情况下，不同训练管道对神经网络决策函数中各层参数重要性的影响。通过对多种ImageNet-1k分类模型的实验评估，我们发现训练方法显著影响各层对任务的重要性。例如，改进的训练策略和自监督训练提升了早期层的关键性，而较少利用深层层次。相反，像对抗训练这样的策略则显示出与之相反的趋势。这些初步结果进一步扩展了以往研究，提供了对神经网络内部机制更加细致的理解。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.14470" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 08:23:59 GMT</pubDate>
</item>
<item>
<title>视觉语言模型的挑战：自然图像中的对抗样本研究</title>
<link>https://arxiv.org/abs/2410.14669</link>
<guid>https://arxiv.org/abs/2410.14669</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文探讨了视觉语言模型在自然图像和人类易答问题上的不足，提出自然基准评估方法。</p><br /><br /><p><strong>摘要：</strong> 近年来，视觉语言模型（VLMs）在复杂的视觉问答（VQA）基准测试中取得了显著进展。然而，本研究显示，VLMs 在处理普通图像和人类易于回答的问题时仍面临挑战，这类样本被称为自然对抗样本。我们发现，通过使用 CLIP 和 ChatGPT 等现成模型，相对简单地生成这些 VQA 样本。为此，我们提出了一种半自动的方法，收集了一个新的基准数据集，NaturalBench，包含 10,000 个经过人类验证的 VQA 样本。该基准设计优先考虑视觉元素，通过将每个问题与两幅不同答案的图像配对，有效防止了模型的盲目解答，提升了挑战性。对 53 个先进的 VLMs 的评估结果显示，包括 LLaVA-OneVision、Cambrian-1、Llama3.2-Vision、Molmo、Qwen2-VL 和 GPT-4o 在内的模型相较于人类表现，落后 50%-70%。分析表明，NaturalBench 的难点主要体现在组合性和偏见两个方面，这些发现为后续研究提供了启示。此外，借助我们的方法，NaturalBench 的框架也可应用于多样的数据源，包括长标题和非英语语言，展示了其动态评估 VLMs 的潜力。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.14669" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 06:33:45 GMT</pubDate>
</item>
<item>
<title>DAWN：非自回归扩散模型的动态头像生成框架</title>
<link>https://arxiv.org/abs/2410.13726</link>
<guid>https://arxiv.org/abs/2410.13726</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">DAWN框架通过非自回归扩散模型生成高质量动态头像视频，解决了传统方法的生成速度慢和错误积累等问题。</p><br /><br /><p><strong>摘要：</strong> DAWN（Dynamic frame Avatar With Non-autoregressive diffusion）是一种创新的框架，旨在通过单一的肖像和语音音频生成生动而逼真的动态视频。传统的扩散基础的动态头像生成方法大多数依赖于自回归策略，导致在生成过程中效用有限、错误累积和生成速度较慢等问题。为了克服这些挑战，DAWN提出了一套新的生成方式，其主要由两个组件组成：音频驱动的整体面部动态生成和音频驱动的头部姿态和眨眼生成。大量实验表明，DAWN能生成真实且生动的视频，同时具有准确的口型运动和自然的姿态/眨眼动作。此外，DAWN实现了高速度生成，并显示出强大的外推能力，能够确保高质量长期视频的稳定生成。这一成果展示了DAWN在动态头像视频生成领域的巨大潜力和影响力，也期待其能够引发在扩散模型中的更多非自回归方法的探索。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.13726" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 06:31:06 GMT</pubDate>
</item>
<item>
<title>关于强化学习中人为反馈的边际损失问题及其影响</title>
<link>https://arxiv.org/abs/2410.13828</link>
<guid>https://arxiv.org/abs/2410.13828</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文探讨了边际损失方法在语言模型对齐中的不足及其带来的潜在问题。</p><br /><br /><p><strong>摘要：</strong> 本文探讨了强化学习从人为反馈（RLHF）在语言模型对齐中的主导地位，特别是边际损失方法的不足之处。我们发现，这种方法在偏好和反偏好响应的单独理想行为上存在不足，可能导致两种不良后果：一是不偏好的响应（如不安全响应）的概率增加，二是理想的偏好响应的概率降低。这种现象的根源在于边际损失将偏好概率的变化与反偏好概率的梯度耦合，阻碍了偏好概率的提高。因此，我们提出了“梯度纠缠”的概念，阐明了在对齐语言模型时，偏好和反偏好对数概率的梯度内积相对单独梯度范数过大时，梯度纠缠的问题会变得显著。我们理论上探讨了这种内积为何会导致训练动态的差异，并通过实证研究验证了这些发现。最后，本文为改进边际损失法设计了潜在算法方案，以缓解此类不足，从而提升语言模型对齐的效果。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.13828" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 05:50:33 GMT</pubDate>
</item>
<item>
<title>用户中心的金融专业能力评估基准：UCFE</title>
<link>https://arxiv.org/abs/2410.14059</link>
<guid>https://arxiv.org/abs/2410.14059</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文介绍UCFE基准，评估大型语言模型在复杂金融任务中的表现，结合人类专家反馈。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了UCFE（User-Centric Financial Expertise）基准，这是一个创新框架，旨在评估大型语言模型（LLMs）处理复杂现实金融任务的能力。UCFE基准采用了一种混合方法，结合了人类专家评估和动态、任务特定的交互，以模拟不断发展的金融场景的复杂性。首先，我们进行了包含804名参与者的用户研究，收集他们对金融任务的反馈。其次，根据这些反馈，我们创建了包含广泛用户意图和交互的数据集。该数据集作为基准测试12个LLM服务的基础，采用了LLM-as-Judge方法论。我们的结果显示基准分数与人类偏好之间存在显著的一致性，Pearson相关系数为0.78，验证了UCFE数据集和我们评估方法的有效性。UCFE基准不仅揭示了LLM在金融领域的潜力，还提供了一个评估其性能和用户满意度的稳健框架。基准数据集和评估代码已公开。 </p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.14059" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 05:46:41 GMT</pubDate>
</item>
<item>
<title>DPLM-2：一种多模态蛋白质基础模型</title>
<link>https://arxiv.org/abs/2410.13782</link>
<guid>https://arxiv.org/abs/2410.13782</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">DPLM-2是一个多模态蛋白质模型，实现了序列和结构的联合生成。</p><br /><br /><p><strong>摘要：</strong> 本文提出了DPLM-2，一种多模态蛋白质基础模型，扩展了离散扩散蛋白质语言模型（DPLM），同时考虑了序列和结构。为了实现结构学习，3D坐标通过无查找量化的标记器转换为离散标记。DPLM-2在实验和高质量合成结构数据上进行训练，学习序列与结构的联合分布及其边际和条件分布。我们还实施了高效的预热策略，以利用大规模进化数据与经过预训练的基于序列的蛋白质语言模型的结构归纳偏差之间的关联。实证评估表明，DPLM-2能够同时生成高度兼容的氨基酸序列及其对应的3D结构，消除了两阶段生成方法的需要。同时，DPLM-2在多种条件生成任务中表现出竞争力，包括折叠、反折叠及 scaffolding 与多模态基序输入，并为预测任务提供结构感知表示。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.13782" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 05:42:52 GMT</pubDate>
</item>
<item>
<title>机器生成文本检测器的评估方法研究</title>
<link>https://arxiv.org/abs/2410.14677</link>
<guid>https://arxiv.org/abs/2410.14677</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">随着LLMs的发展，生成文本质量显著提高，机器生成文本检测器的可靠性亟待加强。</p><br /><br /><p><strong>摘要：</strong> 本文探讨了在自回归大型语言模型（LLMs）快速发展的背景下，机器生成文本检测器的评估方法。尽管许多检测器在基准数据集上表现出高达99.9%的识别质量，但在实际应用中，检测器的性能显著下降。这引发了关于现有检测器的可信度及其高评分是否受到评估数据集质量低下的影响的讨论。为此，本文强调了发展稳健且高质量的生成数据评估方法的必要性，以抵御未来模型的偏见和低泛化能力。我们系统性地回顾了致力于AI生成内容检测的比赛数据集，并提出了评估含有AI生成片段的数据集质量的方法。此外，我们还讨论了利用高质量生成数据来提升检测模型训练和训练数据集本身质量的可能性。我们希望通过本研究，增进对人类与机器文本之间动态关系的理解，同时支持在日益自动化的世界中信息的完整性。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.14677" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 05:20:23 GMT</pubDate>
</item>
<item>
<title>基于学习门控的稀疏注意力机制SeerAttention</title>
<link>https://arxiv.org/abs/2410.13276</link>
<guid>https://arxiv.org/abs/2410.13276</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">SeerAttention通过学习门控机制自适应选择重要块，实现了稀疏注意力的动态捕捉，提升了长上下文处理效率。</p><br /><br /><p><strong>摘要：</strong> Attention是现代大语言模型（LLMs）的基础，但其平方复杂性限制了效率和扩展性，尤其是在长上下文窗口中。本文提出了SeerAttention，一种新型注意力机制，通过引入可学习的门控，动态选择注意力图中的重要块，达成块级稀疏化。这种方法有效平衡了准确性与加速性能。为了高效地学习该门控网络，作者开发了一种定制的FlashAttention实现，能够以最低开销提取块级注意力图的真实值。在后训练阶段，SeerAttention显著超过了现有的基于静态或启发式的稀疏注意力方法，且更能灵活适应不同的上下文长度和稀疏比例。在长上下文微调中，SeerAttention在32k的上下文长度下，可以实现90%的稀疏率，且仅有最小的困惑度损失，相较FlashAttention-2实现了5.67倍的加速。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.13276" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 05:11:11 GMT</pubDate>
</item>
<item>
<title>利用KeyNMF研究中国媒体中的信息动态：以2024年欧洲议会选举为例</title>
<link>https://arxiv.org/abs/2410.12791</link>
<guid>https://arxiv.org/abs/2410.12791</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出了一种新的主题建模方法KeyNMF，并应用于研究中国媒体的信息动态。</p><br /><br /><p><strong>摘要：</strong> 本研究探讨了中华人民共和国（PRC）通过华人媒体干预欧洲选举的问题，特别是针对2024年欧洲议会选举。论文首先提出了一种新颖的主题建模方法KeyNMF，该方法结合了变换器（transformer）基础的上下文嵌入模型，实现了对静态和动态主题的有效建模。通过基准评估，验证了KeyNMF在多种中国数据集和指标上具有竞争力。接着，我们将KeyNMF与现有复杂系统信息动态描述方法结合，形成了一条研究信息动态的完整流程。本文应用该流程于五个新闻网站的数据，专注于2024年欧洲议会选举前的时间段。研究方法和结果表明，KeyNMF在研究中国媒体中的信息动态方面表现出色，为后续更广泛的研究奠定了基础。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.12791" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 05:00:34 GMT</pubDate>
</item>
<item>
<title>世界模型增强的自主网络代理研究</title>
<link>https://arxiv.org/abs/2410.13232</link>
<guid>https://arxiv.org/abs/2410.13232</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本研究提出一种世界模型增强的自主网络代理，以改善长时间任务中的决策能力。</p><br /><br /><p><strong>摘要：</strong> 大型语言模型（LLMs）在构建自主代理方面引起了广泛关注，但当前基于LLM的网络代理在长时间任务中的表现仍然不尽如人意，常常导致例如重复购买不可退票的机票等错误。相比之下，人类能够通过对潜在结果（例如失去金钱）的意识，避免这类不可逆转的错误，这种能力被称为“世界模型”。本研究首先通过初步分析确认了当前LLM（如GPT-4o、Claude-3.5-Sonnet等）缺乏世界模型。随后，我们提出了一种世界模型增强（WMA）的网络代理，它通过模拟动作结果来改善决策能力。为了解决将LLM训练为世界模型时面临的挑战，如观察之间的重复元素和冗长HTML输入，我们提出了一种聚焦过渡的观测抽象，其中预测目标是自由形式的自然语言描述，专门突出时间步之间的重要状态差异。在WebArena和Mind2Web上的实验表明，我们的世界模型提高了代理的策略选择能力且无需训练，同时展示出我们的代理在成本和时间上的效率相较于近期基于树搜索的代理。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.13232" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 04:41:07 GMT</pubDate>
</item>
<item>
<title>自我演化的AI训练：借助扩散模型改善低质量数据学习</title>
<link>https://arxiv.org/abs/2410.13674</link>
<guid>https://arxiv.org/abs/2410.13674</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">通过扩散课程(DisCL)方法，提高深度神经网络在长期分类和低质量数据学习中的表现。</p><br /><br /><p><strong>摘要：</strong> 低质量或稀缺数据为深度神经网络的训练带来了显著挑战。虽然经典的数据增强方法无法生成足够多样化的新数据，但扩散模型为通过文本引导生成高质量和多样化的合成数据开辟了新途径。然而，仅依赖文本引导无法控制合成图像与原始图像的相似性，可能导致不合分布的数据，从而损害模型性能。为了克服这一限制，本文研究了图像引导，以实现合成图像和真实图像之间的插值范围。强图像引导生成的图像与训练数据相似但难以学习，而弱图像引导的合成图像则便于模型学习但导致与原始数据的分布差距增大。生成的全谱数据使我们能够构建一种新颖的“扩散课程(DisCL)”，该方法根据训练阶段调整图像合成的引导水平，识别并集中关注模型的难样本，并评估合成图像的最有效指导水平以提高困难数据学习。在长尾分类和低质量数据学习等挑战性任务中应用DisCL，能够通过低引导图像进行高质量特征的学习，从而为学习可能在多样性或质量上较弱的高引导图像进行热身。大量实验表明，在iWildCam数据集上，应用DisCL后OOD和ID宏观准确率分别提升2.7%和2.1%；在ImageNet-LT上，DisCL将基础模型的尾类准确率从4.4%提高到23.64%，并在全类准确率上提升4.02%。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.13674" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 02:09:52 GMT</pubDate>
</item>
<item>
<title>MagicTailor：组件可控的个性化文本到图像生成</title>
<link>https://arxiv.org/abs/2410.13370</link>
<guid>https://arxiv.org/abs/2410.13370</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文介绍了MagicTailor框架，解决文本到图像生成中组件可控个性化面临的挑战。</p><br /><br /><p><strong>摘要：</strong> 本文提出了一种新颖的任务——组件可控的个性化，旨在提升文本到图像（T2I）模型生成图像的精细化控制能力。尽管现有方法通过参考图像实现了概念的复制，但在组件的细粒度定制方面仍显不足。该任务面临两大挑战：语义污染导致个性化概念被不必要的视觉元素干扰，语义不均衡则造成概念与组件之间的学习失调。为了解决这些难题，我们设计了MagicTailor框架，利用动态掩模退化（Dynamic Masked Degradation, DM-Deg）技术动态干扰不必要的视觉语义，同时采用双流平衡（Dual-Stream Balancing, DS-Bal）建立一种平衡的学习模式，以优化所需视觉语义的学习效果。通过广泛的比较、消融和分析，MagicTailor在这一挑战性任务中表现出色，并展示了其在实际应用中的潜力，为更细致和富有创意的图像生成奠定了基础。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.13370" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 01:06:41 GMT</pubDate>
</item>
<item>
<title>o1模型在推理能力提升中的研究：对比测试时计算方法的深入分析</title>
<link>https://arxiv.org/abs/2410.13639</link>
<guid>https://arxiv.org/abs/2410.13639</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文探讨o1模型在推理任务中的表现，并与现有方法进行对比，揭示其推理模式和性能优势。</p><br /><br /><p><strong>摘要：</strong> 随着大型语言模型（LLMs）的不断演进，面临的复杂任务越来越多，加大了研究的关注力度。OpenAI的o1模型展示了通过测试时计算（Test-time Compute）策略来显著提升推理能力的潜力。本文旨在深入探讨o1的推理模式，并与其他现存的测试时计算方法（如BoN、Step-wise BoN、Agent Workflow和Self-Refine）进行比较，基于OpenAI的GPT-4o在多个推理基准测试（数学、编码和常识推理）上的表现进行分析。研究结果首先表明，o1模型在大多数数据集上取得了最佳性能。其次，对于多样化响应搜索方法（如BoN），我们发现奖励模型的能力以及搜索空间限制了方法的上限。第三，在将问题拆分成多个子问题的策略中，Agent Workflow由于其领域特定的系统提示在规划推理过程时表现优于Step-wise BoN。最后，我们总结了o1的六种推理模式，并对多个推理基准进行了详细分析。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.13639" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 22:29:50 GMT</pubDate>
</item>
<item>
<title>探索视觉自回归模型的规模化问题：连续与离散代币、随机与固定生成顺序的影响</title>
<link>https://arxiv.org/abs/2410.13863</link>
<guid>https://arxiv.org/abs/2410.13863</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文研究了文本到图像生成中自回归模型规模化的问题，发现连续代币模型表现更佳，随机生成顺序优于固定顺序。</p><br /><br /><p><strong>摘要：</strong> 本文探讨了文本到图像生成中自回归模型的规模化问题，重点关注两个关键因素：模型使用离散代币还是连续代币，以及代币是否采用随机或固定的栅格顺序生成。通过实证结果发现，尽管所有模型在验证损失方面都有良好的规模效应，但它们在评估性能（如FID、GenEval分数和视觉质量）上呈现出不同趋势。使用连续代币的模型比使用离散代币的模型在视觉质量上显著优越。此外，生成顺序和注意力机制也对GenEval评分有显著影响，随机顺序模型的GenEval评分显著高于栅格顺序模型。在这些发现的启发下，我们训练了Fluid，一个基于连续代币的随机顺序自回归模型。Fluid 10.5B模型在MS-COCO 30K上达到了新的零-shot FID 6.16的状态，整体GenEval评分为0.69。我们希望这些发现和结果能够鼓励未来进一步缩小视觉和语言模型之间的规模差距。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.13863" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 18:31:49 GMT</pubDate>
</item>
<item>
<title>JudgeBench：评估LLM基础评判模型的新基准</title>
<link>https://arxiv.org/abs/2410.12784</link>
<guid>https://arxiv.org/abs/2410.12784</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">提出JudgeBench评估框架，以客观方式评估LLM基础评判者的能力。</p><br /><br /><p><strong>摘要：</strong> 随着LLM（大语言模型）基础评判者在模型评估中的应用日益广泛，其自身的可靠性问题却鲜有关注。现有评估基准多集中在评判与人类偏好的对齐，常常忽视了更具挑战性的任务中众包人类偏好带来的局限。为此，本文提出了一种新颖的评估框架，旨在客观地评估LLM基础评判者。基于这一框架，我们推出了JudgeBench，作为一项新基准，用于在知识、推理、数学和编码等领域评估LLM基础评判者的能力。JudgeBench通过将现有的困难数据集转换为带有客观正确性偏好的挑战响应对，利用一套新颖的管道进行构建。我们的综合评估结果显示，JudgeBench相较于以往基准提供了更具挑战性的任务，许多强大的模型（如GPT-4o）表现仅略高于随机猜测。总的来说，JudgeBench为日益先进的LLM基础评判者的评估提供了一套可靠平台。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.12784" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 17:25:57 GMT</pubDate>
</item>
<item>
<title>WorldCuisines：多元文化的视觉问答基准</title>
<link>https://arxiv.org/abs/2410.12705</link>
<guid>https://arxiv.org/abs/2410.12705</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">WorldCuisines是一个针对多语言和多文化的视觉问答基准，包含超过100万个饮食相关的数据点。</p><br /><br /><p><strong>摘要：</strong> Vision Language Models (VLMs) 在处理文化特定知识时面临挑战，尤其是对于非英语语言和缺失代表性的文化背景。为此，我们推出了WorldCuisines，这是一个针对多语言和多文化的视觉理解基准。该基准包含一个视觉问答（VQA）数据集，涵盖30种语言和方言，跨越9个语言家族，并拥有超过100万的数据点，是迄今为止最大规模的多文化VQA基准。数据集任务包括识别菜品名称及其来源。我们提供了两种规模的评估数据集（12k和60k实例）以及一个训练数据集（100万实例）。我们的研究表明，虽然VLMs在正确的地理上下文中表现较好，但在敌对上下文中和预测特定地方菜系及语言时却存在困难。为了支持未来的研究，我们还发布了一个包含注释食品条目和图像的知识库，配合VQA数据一起提供。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.12705" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 14:10:54 GMT</pubDate>
</item>
<item>
<title>Open Materials 2024: 大规模开放数据集及预训练模型的发布</title>
<link>https://arxiv.org/abs/2410.12771</link>
<guid>https://arxiv.org/abs/2410.12771</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">我们发布了OMat24数据集和EquiformerV2模型，以推动AI辅助材料科学的发展。</p><br /><br /><p><strong>摘要：</strong> 随着对新材料发现与设计能力的日益重视，人工智能（AI）在材料科学中的应用得到广泛关注。为了解决材料发现中的数据短缺问题，我们推出了Open Materials 2024 (OMat24)大规模开放数据集及一系列预训练模型。OMat24包含超过1.1亿个集中于结构和组成多样性的密度泛函理论（DFT）计算。我们的EquiformerV2模型在Matbench Discovery排行榜上实现了最先进的性能，能够以高达0.9的F1分数和每个原子20 meV的精度预测基态稳定性和形成能。我们还探讨了模型规模、辅助去噪目标以及微调对不同数据集（包括OMat24、MPtraj和Alexandria）上性能的影响。OMat24数据集和模型的开放发布将使研究界能够在我们的研究基础上继续开展工作，推动AI辅助材料科学的进一步进展。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.12771" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 13:03:29 GMT</pubDate>
</item>
<item>
<title>推进语音大语言模型的五级发展路线图与评估基准</title>
<link>https://arxiv.org/abs/2410.13268</link>
<guid>https://arxiv.org/abs/2410.13268</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出一套五级路线图，旨在指导语音大语言模型的发展，并设计评估基准以揭示其当前局限性。</p><br /><br /><p><strong>摘要：</strong> 随着大型语言模型（LLMs）的成功，结合语音和音频数据的努力日益增多，旨在创建能够处理文本和非文本输入的一般基础模型。最近的进展，如GPT-4o，突显了端到端语音LLMs的潜力，这种模型可以保留非语义信息和世界知识，以实现更深层次的语音理解。为了引导语音LLMs的发展，本文提出了一种五级路线图，涵盖从基础的自动语音识别（ASR）到能够整合非语义信息和抽象声学知识以完成复杂任务的先进超人模型。此外，我们设计了SAGI基准，标准化了各个任务在这五个级别上的关键方面，以揭示利用抽象声学知识和能力完整性的挑战。研究结果显示在处理副语言线索和抽象声学知识方面存在不足，并提出了未来的研究方向。本论文概述了推进语音LLMs的路线图，引入了评估基准，并提供了对其当前局限性和潜能的关键见解。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.13268" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 12:46:43 GMT</pubDate>
</item>
<item>
<title>MobA：基于多模态大语言模型的移动助手</title>
<link>https://arxiv.org/abs/2410.13757</link>
<guid>https://arxiv.org/abs/2410.13757</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">MobA是一种新型移动助手，通过多模态大语言模型提升理解与规划能力，解决复杂指令处理问题。</p><br /><br /><p><strong>摘要：</strong> 当前移动助手因依赖系统API以及对复杂用户指令和多样化界面的理解能力有限而面临挑战。为此，我们提出MobA，这是一种新型的移动助手，采用多模态大语言模型（MLLM），通过复杂的两级代理架构增强理解和规划能力。高层的全局代理（Global Agent, GA）负责理解用户命令、追踪历史记忆并规划任务，而低层的局部代理（Local Agent, LA）根据GA提供的子任务和记忆，预测详细行动（以函数调用形式呈现）。集成的反思模块则提高了任务完成的效率，使系统能处理未见过的复杂任务。在真实评估中，MobA在任务执行效率和完成率方面表现出了显著改善，彰显了基于MLLM的移动助手的潜力。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.13757" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 09:41:59 GMT</pubDate>
</item>
<item>
<title>gamma-MoD: 提升多模态大语言模型计算效率的新策略</title>
<link>https://arxiv.org/abs/2410.13859</link>
<guid>https://arxiv.org/abs/2410.13859</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">提出gamma-MoD策略，通过激活度指标优化大语言模型计算，显著提高效率。</p><br /><br /><p><strong>摘要：</strong> 尽管多模态大语言模型（MLLMs）取得了显著进展，但其高计算成本仍是实际应用的障碍。受到自然语言处理中的深度混合（MoD）启发，本文旨在从“激活token”的角度解决这一问题。我们的关键见解是，如果大多数token在层计算中是冗余的，则可以通过MoD层直接跳过。然而，直接将MLLMs的密集层转换为MoD层会导致性能显著下降。为了解决这一问题，我们提出了一种名为gamma-MoD的创新MoD适应策略。在gamma-MoD中，提出了一种新指标：注意力图的排序（ARank），以引导MLLM中MoD的部署。通过ARank，我们能够有效识别哪些层是冗余的并应替换为MoD层。基于ARank，我们进一步提出两种新设计，以最大化MLLM的计算稀疏性，同时保持性能，即共享视角-语言路由器和掩码路由学习。通过这些设计，超过90%的MLLM稠密层可以有效转换为MoD层。为了验证我们的方法，我们将其应用于三种流行的MLLM，并在9个基准数据集上进行了广泛的实验。实验结果不仅验证了gamma-MoD对现有MLLM的显著效率提升，还确认了其在不同MLLM上的泛化能力。例如，gamma-MoD可以在略微性能下降（-1.5%）的情况下，将LLaVA-HR的训练和推理时间分别减少31.0%和53.2%。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.13859" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 08:06:48 GMT</pubDate>
</item>
<item>
<title>基于高质量数据的长输出能力模型调优研究</title>
<link>https://arxiv.org/abs/2410.10210</link>
<guid>https://arxiv.org/abs/2410.10210</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本研究探讨了调优模型以实现长输出能力的方法，强调数据质量的重要性。</p><br /><br /><p><strong>摘要：</strong> 随着大型语言模型的快速发展，它们在生成长输出方面的能力存在显著差异。近期研究表明，模型在对齐训练过程中缺乏长输出数据是导致这一不平衡的主要原因。为了解决这一问题，我们尝试通过用填补数据缺口的数据重新对齐基础模型，从而使模型在接到指令时能够生成长篇输出。本文探讨了数据质量在模型长输出调优过程中的影响，以及如何从人类对齐的模型（如指令或聊天模型）出发进行调优。通过精心的数据策划，我们展示了在仅用少量训练数据实例和计算资源的情况下，能够实现与我们调优模型相似的性能提升。此外，我们通过尝试将我们的调优方案应用于几种不同模型，评估了此方法的通用性。研究结果表明，尽管不同模型在未经过调整时生成长输出的能力差异较大，但通过高质量数据和轻量计算资源进行调优的方法，能够在我们实验的所有模型中一致性地实现显著改善。我们公开了用于调优长写作能力的数据集、模型调优和评估的实现方案以及微调后的模型，这些都可供公众访问。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.10210" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 08:01:07 GMT</pubDate>
</item>
<item>
<title>无指导自回归视觉生成的条件对比对齐方法</title>
<link>https://arxiv.org/abs/2410.09347</link>
<guid>https://arxiv.org/abs/2410.09347</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">提出Condition Contrastive Alignment，提升自回归视觉生成性能，减少对指导抽样的依赖。</p><br /><br /><p><strong>摘要：</strong> Classifier-Free Guidance (CFG) 是提高视觉生成模型样本质量的重要技术。然而，在自回归（AR）多模态生成中，CFG导致语言和视觉内容之间设计不一致，违背了对不同模态进行统一设计的理念。为了解决这个问题，我们提出Condition Contrastive Alignment (CCA) 方法，旨在促进高性能的无指导自回归视觉生成，并分析其与指导抽样方法的理论联系。不同于通过改变抽样过程以达到理想抽样分布的指导方法，CCA直接对预训练模型进行微调，以适应相同的分布目标。实验结果表明，CCA能够在仅进行一个epoch的微调（相当于约1%的预训练周期）后，显著增强所有测试模型的无指导性能，其表现与指导抽样方法相当。这大大减少了AR视觉生成中的指导抽样需求，并将采样成本降低了一半。此外，通过调整训练参数，CCA能够在样本多样性与真实性之间实现类似于CFG的权衡。这一研究实验性地确认了语言目标对齐与视觉目标指导方法之间的紧密理论联系，从而统一了两个之前独立的研究领域。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.09347" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 07:42:08 GMT</pubDate>
</item>
<item>
<title>TransAgent：通过多源知识蒸馏提升视觉-语言基础模型</title>
<link>https://arxiv.org/abs/2410.12183</link>
<guid>https://arxiv.org/abs/2410.12183</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">TransAgent 框架通过多源知识蒸馏提升 CLIP 等视觉-语言基础模型在多样化数据上的表现。</p><br /><br /><p><strong>摘要：</strong> 视觉-语言基础模型（如 CLIP）在迁移学习方面展现了巨大的潜力，得益于大规模的图像-文本预训练。然而，目标域数据在下游任务中可能与预训练阶段存在较大差异，这使得模型的泛化能力受到限制。为了解决这一问题，我们提出了一个通用且简洁的 TransAgent 框架，它以统一的方式传输孤立代理的知识，有效引导 CLIP 模型通过多源知识蒸馏进行泛化。通过该框架，我们灵活地与 11 个异构代理进行合作，增强视觉-语言基础模型，而在推理阶段没有额外的成本。最终，TransAgent 在 11 个视觉识别数据集上达到了最先进的性能。在相同的低样本设置下，它在平均上比流行的 CoOp 超出约 10%，在包含较大领域偏移的 EuroSAT 数据集上则超过了 20%。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.12183" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 07:10:06 GMT</pubDate>
</item>
<item>
<title>Long-LRM：基于3D高斯重建的长序列图像大场景重建模型</title>
<link>https://arxiv.org/abs/2410.12781</link>
<guid>https://arxiv.org/abs/2410.12781</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">Long-LRM是一种高效的3D高斯重建模型，能快速重建大场景。</p><br /><br /><p><strong>摘要：</strong> Long-LRM是一种通用的3D高斯重建模型，能够从长序列的输入图像中重建大场景。该模型可处理32张960x540分辨率的源图像，且在单个A100 80G GPU上仅需1.3秒。我们的架构结合了最新的Mamba2模块和经典的Transformer模块，使得能够处理比以往更多的tokens，同时通过高效的token合并和高斯剪枝步骤来平衡质量和效率。与之前只能处理1到4张输入图像并仅能重建小部分大场景的前馈模型不同，Long-LRM在一次前馈步骤中便可重建整个场景。在DL3DV-140和Tanks and Temples等大规模场景数据集上，我们的方法在性能上可与基于优化的方法相媲美，同时效率提升两个数量级。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.12781" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 06:59:14 GMT</pubDate>
</item>
<item>
<title>中文图像含义理解基准CII-Bench的提出与评估</title>
<link>https://arxiv.org/abs/2410.13854</link>
<guid>https://arxiv.org/abs/2410.13854</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">CII-Bench评估多模态大语言模型对中文图像的高阶理解能力，揭示其在传统文化理解方面的不足。</p><br /><br /><p><strong>摘要：</strong> 随着多模态大语言模型（MLLM）能力的不断提升，对其高阶感知和理解能力的评估需求日益增加。然而，目前仍缺乏针对中文视觉内容的MLLM高阶评估工作。为填补这一空白，我们提出了中文图像含义理解基准（CII-Bench），旨在评估MLLM在中文图像上的高阶感知和理解能力。CII-Bench在若干方面独树一帜：首先，基准中的图像来自中文互联网，并经过人工审查，相关答案也由人工精心撰写。此外，CII-Bench还纳入了代表中国传统文化的图像，如著名的中国传统绘画，能够深刻反映模型对中国传统文化的理解。通过对多种MLLM在CII-Bench上的广泛实验，我们发现MLLM的表现与人类存在显著差距，最高准确率为64.4%，而人类平均准确率为78.2%。同时，MLLM在理解中国传统文化图像时表现较差，反映出其高阶语义理解的局限性及对中国传统文化知识的欠缺。最后，研究发现大多数模型在提示中加入图像情感线索时准确率有所提升。我们相信CII-Bench将促进MLLM对中文语义及中文特定图像的更好理解，推动通用人工智能（AGI）的进程。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.13854" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 06:54:13 GMT</pubDate>
</item>
<item>
<title>基于检索增强个性化的多模态大语言模型框架</title>
<link>https://arxiv.org/abs/2410.13360</link>
<guid>https://arxiv.org/abs/2410.13360</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">提出了检索增强个性化框架（RAP），实现多模态语言模型的个性化助手。 </p><br /><br /><p><strong>摘要：</strong> 本文介绍了一种检索增强个性化（RAP）框架，用于提升多模态大语言模型（MLLMs）的个性化能力。RAP通过三个步骤实现个性化助手的创建：首先，设计键值数据库存储用户相关信息，例如姓名、头像等；其次，通过多模态检索器在用户发起对话时从数据库中检索相关信息；最后，将输入查询和检索到的相关信息输入到多模态语言模型中，以生成个性化的知识增强响应。与以往方法不同，RAP支持实时的概念编辑，通过更新外部数据库以适应用户需求。此外，为了提升生成质量和与用户特定信息的一致性，本文设计了一个数据收集管道，并创建了用于个性化训练的专用数据集。通过该数据集，训练了一系列个性化的多模态助手模型。RAP-MLLMs能够在无须额外微调的情况下，凭借大规模的预训练数据集，推广到无限的视觉概念。该模型在个性化图像描述、问答和视觉识别等多种任务中展示了出色的灵活性和生成质量。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.13360" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 06:47:51 GMT</pubDate>
</item>
<item>
<title>MuVi: Video-to-Music Generation with Semantic Alignment and Rhythmic Synchronization</title>
<link>https://arxiv.org/abs/2410.12957</link>
<guid>https://arxiv.org/abs/2410.12957</guid>
<content:encoded><![CDATA[
Generating music that aligns with the visual content of a video has been a challenging task, as it requires a deep understanding of visual semantics and involves generating music whose melody, rhythm, and dynamics harmonize with the visual narratives. This paper presents MuVi, a novel framework that effectively addresses these challenges to enhance the cohesion and immersive experience of audio-visual content. MuVi analyzes video content through a specially designed visual adaptor to extract contextually and temporally relevant features. These features are used to generate music that not only matches the video's mood and theme but also its rhythm and pacing. We also introduce a contrastive music-visual pre-training scheme to ensure synchronization, based on the periodicity nature of music phrases. In addition, we demonstrate that our flow-matching-based music generator has in-context learning ability, allowing us to control the style and genre of the generated music. Experimental results show that MuVi demonstrates superior performance in both audio quality and temporal synchronization. The generated music video samples are available at https://muvi-v2m.github.io.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 06:33:00 GMT</pubDate>
</item>
<item>
<title>Do LLMs Have Political Correctness? Analyzing Ethical Biases and Jailbreak Vulnerabilities in AI Systems</title>
<link>https://arxiv.org/abs/2410.13334</link>
<guid>https://arxiv.org/abs/2410.13334</guid>
<content:encoded><![CDATA[
Although large language models (LLMs) demonstrate impressive proficiency in various tasks, they present potential safety risks, such as `jailbreaks', where malicious inputs can coerce LLMs into generating harmful content. To address these issues, many LLM developers have implemented various safety measures to align these models. This alignment involves several techniques, including data filtering during pre-training, supervised fine-tuning, reinforcement learning from human feedback, and red-teaming exercises. These methods often introduce deliberate and intentional biases similar to Political Correctness (PC) to ensure the ethical behavior of LLMs. In this paper, we delve into the intentional biases injected into LLMs for safety purposes and examine methods to circumvent these safety alignment techniques. Notably, these intentional biases result in a jailbreaking success rate in GPT-4o models that differs by 20% between non-binary and cisgender keywords and by 16% between white and black keywords, even when the other parts of the prompts are identical. We introduce the concept of PCJailbreak, highlighting the inherent risks posed by these safety-induced biases. Additionally, we propose an efficient defense method PCDefense, which prevents jailbreak attempts by injecting defense prompts prior to generation. PCDefense stands as an appealing alternative to Guard Models, such as Llama-Guard, that require additional inference cost after text generation. Our findings emphasize the urgent need for LLM developers to adopt a more responsible approach when designing and implementing safety measures.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 06:13:36 GMT</pubDate>
</item>
<item>
<title>Janus: Decoupling Visual Encoding for Unified Multimodal Understanding and Generation</title>
<link>https://arxiv.org/abs/2410.13848</link>
<guid>https://arxiv.org/abs/2410.13848</guid>
<content:encoded><![CDATA[
In this paper, we introduce Janus, an autoregressive framework that unifies multimodal understanding and generation. Prior research often relies on a single visual encoder for both tasks, such as Chameleon. However, due to the differing levels of information granularity required by multimodal understanding and generation, this approach can lead to suboptimal performance, particularly in multimodal understanding. To address this issue, we decouple visual encoding into separate pathways, while still leveraging a single, unified transformer architecture for processing. The decoupling not only alleviates the conflict between the visual encoder's roles in understanding and generation, but also enhances the framework's flexibility. For instance, both the multimodal understanding and generation components can independently select their most suitable encoding methods. Experiments show that Janus surpasses previous unified model and matches or exceeds the performance of task-specific models. The simplicity, high flexibility, and effectiveness of Janus make it a strong candidate for next-generation unified multimodal models.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 04:23:02 GMT</pubDate>
</item>
<item>
<title>MixEval-X: Any-to-Any Evaluations from Real-World Data Mixtures</title>
<link>https://arxiv.org/abs/2410.13754</link>
<guid>https://arxiv.org/abs/2410.13754</guid>
<content:encoded><![CDATA[
Perceiving and generating diverse modalities are crucial for AI models to effectively learn from and engage with real-world signals, necessitating reliable evaluations for their development. We identify two major issues in current evaluations: (1) inconsistent standards, shaped by different communities with varying protocols and maturity levels; and (2) significant query, grading, and generalization biases. To address these, we introduce MixEval-X, the first any-to-any real-world benchmark designed to optimize and standardize evaluations across input and output modalities. We propose multi-modal benchmark mixture and adaptation-rectification pipelines to reconstruct real-world task distributions, ensuring evaluations generalize effectively to real-world use cases. Extensive meta-evaluations show our approach effectively aligns benchmark samples with real-world task distributions and the model rankings correlate strongly with that of crowd-sourced real-world evaluations (up to 0.98). We provide comprehensive leaderboards to rerank existing models and organizations and offer insights to enhance understanding of multi-modal evaluations and inform future research.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 03:48:45 GMT</pubDate>
</item>
<item>
<title>MoH: Multi-Head Attention as Mixture-of-Head Attention</title>
<link>https://arxiv.org/abs/2410.11842</link>
<guid>https://arxiv.org/abs/2410.11842</guid>
<content:encoded><![CDATA[
In this work, we upgrade the multi-head attention mechanism, the core of the Transformer model, to improve efficiency while maintaining or surpassing the previous accuracy level. We show that multi-head attention can be expressed in the summation form. Drawing on the insight that not all attention heads hold equal significance, we propose Mixture-of-Head attention (MoH), a new architecture that treats attention heads as experts in the Mixture-of-Experts (MoE) mechanism. MoH has two significant advantages: First, MoH enables each token to select the appropriate attention heads, enhancing inference efficiency without compromising accuracy or increasing the number of parameters. Second, MoH replaces the standard summation in multi-head attention with a weighted summation, introducing flexibility to the attention mechanism and unlocking extra performance potential. Extensive experiments on ViT, DiT, and LLMs demonstrate that MoH outperforms multi-head attention by using only 50%-90% of the attention heads. Moreover, we demonstrate that pre-trained multi-head attention models, such as LLaMA3-8B, can be further continue-tuned into our MoH models. Notably, MoH-LLaMA3-8B achieves an average accuracy of 64.0% across 14 benchmarks, outperforming LLaMA3-8B by 2.4% by utilizing only 75% of the attention heads. We believe the proposed MoH is a promising alternative to multi-head attention and provides a strong foundation for developing advanced and efficient attention-based models.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 03:16:53 GMT</pubDate>
</item>
<item>
<title>SBI-RAG: Enhancing Math Word Problem Solving for Students through Schema-Based Instruction and Retrieval-Augmented Generation</title>
<link>https://arxiv.org/abs/2410.13293</link>
<guid>https://arxiv.org/abs/2410.13293</guid>
<content:encoded><![CDATA[
Many students struggle with math word problems (MWPs), often finding it difficult to identify key information and select the appropriate mathematical operations.Schema-based instruction (SBI) is an evidence-based strategy that helps students categorize problems based on their structure, improving problem-solving accuracy. Building on this, we propose a Schema-Based Instruction Retrieval-Augmented Generation (SBI-RAG) framework that incorporates a large language model (LLM).Our approach emphasizes step-by-step reasoning by leveraging schemas to guide solution generation. We evaluate its performance on the GSM8K dataset, comparing it with GPT-4 and GPT-3.5 Turbo, and introduce a "reasoning score" metric to assess solution quality. Our findings suggest that SBI-RAG enhances reasoning clarity and problem-solving accuracy, potentially providing educational benefits for students
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 02:59:02 GMT</pubDate>
</item>
<item>
<title>LoLDU: Low-Rank Adaptation via Lower-Diag-Upper Decomposition for Parameter-Efficient Fine-Tuning</title>
<link>https://arxiv.org/abs/2410.13618</link>
<guid>https://arxiv.org/abs/2410.13618</guid>
<content:encoded><![CDATA[
The rapid growth of model scale has necessitated substantial computational resources for fine-tuning. Existing approach such as Low-Rank Adaptation (LoRA) has sought to address the problem of handling the large updated parameters in full fine-tuning. However, LoRA utilize random initialization and optimization of low-rank matrices to approximate updated weights, which can result in suboptimal convergence and an accuracy gap compared to full fine-tuning. To address these issues, we propose LoLDU, a Parameter-Efficient Fine-Tuning (PEFT) approach that significantly reduces trainable parameters by 2600 times compared to regular PEFT methods while maintaining comparable performance. LoLDU leverages Lower-Diag-Upper Decomposition (LDU) to initialize low-rank matrices for faster convergence and orthogonality. We focus on optimizing the diagonal matrix for scaling transformations. To the best of our knowledge, LoLDU has the fewest parameters among all PEFT approaches. We conducted extensive experiments across 4 instruction-following datasets, 6 natural language understanding (NLU) datasets, 8 image classification datasets, and image generation datasets with multiple model types (LLaMA2, RoBERTa, ViT, and Stable Diffusion), providing a comprehensive and detailed analysis. Our open-source code can be accessed at https://github.com/SKDDJ/LoLDU{https://github.com/SKDDJ/LoLDU}.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 02:30:02 GMT</pubDate>
</item>
<item>
<title>VidPanos: Generative Panoramic Videos from Casual Panning Videos</title>
<link>https://arxiv.org/abs/2410.13832</link>
<guid>https://arxiv.org/abs/2410.13832</guid>
<content:encoded><![CDATA[
Panoramic image stitching provides a unified, wide-angle view of a scene that extends beyond the camera's field of view. Stitching frames of a panning video into a panoramic photograph is a well-understood problem for stationary scenes, but when objects are moving, a still panorama cannot capture the scene. We present a method for synthesizing a panoramic video from a casually-captured panning video, as if the original video were captured with a wide-angle camera. We pose panorama synthesis as a space-time outpainting problem, where we aim to create a full panoramic video of the same length as the input video. Consistent completion of the space-time volume requires a powerful, realistic prior over video content and motion, for which we adapt generative video models. Existing generative models do not, however, immediately extend to panorama completion, as we show. We instead apply video generation as a component of our panorama synthesis system, and demonstrate how to exploit the strengths of the models while minimizing their limitations. Our system can create video panoramas for a range of in-the-wild scenes including people, vehicles, and flowing water, as well as stationary background features.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 02:17:13 GMT</pubDate>
</item>
<item>
<title>Movie Gen: A Cast of Media Foundation Models</title>
<link>https://arxiv.org/abs/2410.13720</link>
<guid>https://arxiv.org/abs/2410.13720</guid>
<content:encoded><![CDATA[
We present Movie Gen, a cast of foundation models that generates high-quality, 1080p HD videos with different aspect ratios and synchronized audio. We also show additional capabilities such as precise instruction-based video editing and generation of personalized videos based on a user's image. Our models set a new state-of-the-art on multiple tasks: text-to-video synthesis, video personalization, video editing, video-to-audio generation, and text-to-audio generation. Our largest video generation model is a 30B parameter transformer trained with a maximum context length of 73K video tokens, corresponding to a generated video of 16 seconds at 16 frames-per-second. We show multiple technical innovations and simplifications on the architecture, latent spaces, training objectives and recipes, data curation, evaluation protocols, parallelization techniques, and inference optimizations that allow us to reap the benefits of scaling pre-training data, model size, and training compute for training large scale media generation models. We hope this paper helps the research community to accelerate progress and innovation in media generation models. All videos from this paper are available at https://go.fb.me/MovieGenResearchVideos.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 02:16:45 GMT</pubDate>
</item>
<item>
<title>BenTo: Benchmark Task Reduction with In-Context Transferability</title>
<link>https://arxiv.org/abs/2410.13804</link>
<guid>https://arxiv.org/abs/2410.13804</guid>
<content:encoded><![CDATA[
Evaluating large language models (LLMs) is costly: it requires the generation and examination of LLM outputs on a large-scale benchmark of various tasks. This paper investigates how to efficiently reduce the tasks used to benchmark LLMs without affecting the evaluation quality. Our study reveals that task transferability and relevance provide critical information to identify the most representative subset of tasks via optimizing a facility location function. We propose a practically efficient metric for estimating the transferability between two tasks via in-context learning (ICL). By analyzing the pairwise transferability, we can reduce tasks in a modern LLM benchmark (e.g., MMLU or FLAN) to 5% while inducing only a &lt;4% difference to the evaluation on the original benchmark. Compared to prior works, our method is training-free, gradient-free, and highly efficient requiring ICL only.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 01:58:57 GMT</pubDate>
</item>
<item>
<title>PopAlign: Diversifying Contrasting Patterns for a More Comprehensive Alignment</title>
<link>https://arxiv.org/abs/2410.13785</link>
<guid>https://arxiv.org/abs/2410.13785</guid>
<content:encoded><![CDATA[
Alignment of large language models (LLMs) involves training models on preference-contrastive output pairs to adjust their responses according to human preferences. To obtain such contrastive pairs, traditional methods like RLHF and RLAIF rely on limited contrasting patterns, such as varying model variants or decoding temperatures. This singularity leads to two issues: (1) alignment is not comprehensive; and thereby (2) models are susceptible to jailbreaking attacks. To address these issues, we investigate how to construct more comprehensive and diversified contrasting patterns to enhance preference data (RQ1) and verify the impact of the diversification of contrasting patterns on model alignment (RQ2). For RQ1, we propose PopAlign, a framework that integrates diversified contrasting patterns across the prompt, model, and pipeline levels, introducing six contrasting strategies that do not require additional feedback labeling procedures. Regarding RQ2, we conduct thorough experiments demonstrating that PopAlign significantly outperforms existing methods, leading to more comprehensive alignment.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 01:39:45 GMT</pubDate>
</item>
<item>
<title>MedMobile: A mobile-sized language model with expert-level clinical capabilities</title>
<link>https://arxiv.org/abs/2410.09019</link>
<guid>https://arxiv.org/abs/2410.09019</guid>
<content:encoded><![CDATA[
Language models (LMs) have demonstrated expert-level reasoning and recall abilities in medicine. However, computational costs and privacy concerns are mounting barriers to wide-scale implementation. We introduce a parsimonious adaptation of phi-3-mini, MedMobile, a 3.8 billion parameter LM capable of running on a mobile device, for medical applications. We demonstrate that MedMobile scores 75.7% on the MedQA (USMLE), surpassing the passing mark for physicians (~60%), and approaching the scores of models 100 times its size. We subsequently perform a careful set of ablations, and demonstrate that chain of thought, ensembling, and fine-tuning lead to the greatest performance gains, while unexpectedly retrieval augmented generation fails to demonstrate significant improvements
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 01:31:56 GMT</pubDate>
</item>
<item>
<title>Harnessing Webpage UIs for Text-Rich Visual Understanding</title>
<link>https://arxiv.org/abs/2410.13824</link>
<guid>https://arxiv.org/abs/2410.13824</guid>
<content:encoded><![CDATA[
Text-rich visual understanding-the ability to process environments where dense textual content is integrated with visuals-is crucial for multimodal large language models (MLLMs) to interact effectively with structured environments. To enhance this capability, we propose synthesizing general multimodal instructions from webpage UIs using text-based large language models (LLMs). Despite lacking direct visual input, text-based LLMs are able to process structured text representations from webpage accessibility trees. These instructions are then paired with UI screenshots to train multimodal models. We introduce MultiUI, a dataset containing 7.3 million samples from 1 million websites, covering diverse multimodal tasks and UI layouts. Models trained on MultiUI not only excel in web UI tasks-achieving up to a 48\% improvement on VisualWebBench and a 19.1\% boost in action accuracy on a web agent dataset Mind2Web-but also generalize surprisingly well to non-web UI tasks and even to non-UI domains, such as document understanding, OCR, and chart interpretation. These results highlight the broad applicability of web UI data for advancing text-rich visual understanding across various scenarios.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 01:04:36 GMT</pubDate>
</item>
<item>
<title>DreamVideo-2: Zero-Shot Subject-Driven Video Customization with Precise Motion Control</title>
<link>https://arxiv.org/abs/2410.13830</link>
<guid>https://arxiv.org/abs/2410.13830</guid>
<content:encoded><![CDATA[
Recent advances in customized video generation have enabled users to create videos tailored to both specific subjects and motion trajectories. However, existing methods often require complicated test-time fine-tuning and struggle with balancing subject learning and motion control, limiting their real-world applications. In this paper, we present DreamVideo-2, a zero-shot video customization framework capable of generating videos with a specific subject and motion trajectory, guided by a single image and a bounding box sequence, respectively, and without the need for test-time fine-tuning. Specifically, we introduce reference attention, which leverages the model's inherent capabilities for subject learning, and devise a mask-guided motion module to achieve precise motion control by fully utilizing the robust motion signal of box masks derived from bounding boxes. While these two components achieve their intended functions, we empirically observe that motion control tends to dominate over subject learning. To address this, we propose two key designs: 1) the masked reference attention, which integrates a blended latent mask modeling scheme into reference attention to enhance subject representations at the desired positions, and 2) a reweighted diffusion loss, which differentiates the contributions of regions inside and outside the bounding boxes to ensure a balance between subject and motion control. Extensive experimental results on a newly curated dataset demonstrate that DreamVideo-2 outperforms state-of-the-art methods in both subject customization and motion control. The dataset, code, and models will be made publicly available.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 01:04:28 GMT</pubDate>
</item>
<item>
<title>MMed-RAG: Versatile Multimodal RAG System for Medical Vision Language Models</title>
<link>https://arxiv.org/abs/2410.13085</link>
<guid>https://arxiv.org/abs/2410.13085</guid>
<content:encoded><![CDATA[
Artificial Intelligence (AI) has demonstrated significant potential in healthcare, particularly in disease diagnosis and treatment planning. Recent progress in Medical Large Vision-Language Models (Med-LVLMs) has opened up new possibilities for interactive diagnostic tools. However, these models often suffer from factual hallucination, which can lead to incorrect diagnoses. Fine-tuning and retrieval-augmented generation (RAG) have emerged as methods to address these issues. However, the amount of high-quality data and distribution shifts between training data and deployment data limit the application of fine-tuning methods. Although RAG is lightweight and effective, existing RAG-based approaches are not sufficiently general to different medical domains and can potentially cause misalignment issues, both between modalities and between the model and the ground truth. In this paper, we propose a versatile multimodal RAG system, MMed-RAG, designed to enhance the factuality of Med-LVLMs. Our approach introduces a domain-aware retrieval mechanism, an adaptive retrieved contexts selection method, and a provable RAG-based preference fine-tuning strategy. These innovations make the RAG process sufficiently general and reliable, significantly improving alignment when introducing retrieved contexts. Experimental results across five medical datasets (involving radiology, ophthalmology, pathology) on medical VQA and report generation demonstrate that MMed-RAG can achieve an average improvement of 43.8% in the factual accuracy of Med-LVLMs. Our data and code are available in https://github.com/richard-peng-xia/MMed-RAG.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:55:13 GMT</pubDate>
</item>
<item>
<title>A Unified View of Delta Parameter Editing in Post-Trained Large-Scale Models</title>
<link>https://arxiv.org/abs/2410.13841</link>
<guid>https://arxiv.org/abs/2410.13841</guid>
<content:encoded><![CDATA[
Post-training has emerged as a crucial paradigm for adapting large-scale pre-trained models to various tasks, whose effects are fully reflected by delta parameters (i.e., the disparity between post-trained and pre-trained parameters). While numerous studies have explored delta parameter properties via operations like pruning, quantization, low-rank approximation, and extrapolation, a unified framework for systematically examining these characteristics has been lacking. In this paper, we propose a novel perspective based on Riemann sum approximation of the loss function to elucidate delta parameter editing operations. Our analysis categorizes existing methods into three classes based on their post-editing performance: competitive, decreased, and improved, explaining how they are expressed by the Riemann sum approximation term and how they alter the model performance. Extensive experiments on both visual and language models, including ViT, LLaMA 3, Qwen 2, and Mistral, corroborate our theoretical findings. Furthermore, we introduce extensions to existing techniques like DARE and BitDelta, highlighting their limitations in leveraging the properties of delta parameters and reorganizing them into general expressions to enhance the applicability and effectiveness of delta parameter editing in post-trained models.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:51:24 GMT</pubDate>
</item>
<item>
<title>AERO: Softmax-Only LLMs for Efficient Private Inference</title>
<link>https://arxiv.org/abs/2410.13060</link>
<guid>https://arxiv.org/abs/2410.13060</guid>
<content:encoded><![CDATA[
The pervasiveness of proprietary language models has raised privacy concerns for users' sensitive data, emphasizing the need for private inference (PI), where inference is performed directly on encrypted inputs. However, current PI methods face prohibitively higher communication and latency overheads, primarily due to nonlinear operations. In this paper, we present a comprehensive analysis to understand the role of nonlinearities in transformer-based decoder-only language models. We introduce AERO, a four-step architectural optimization framework that refines the existing LLM architecture for efficient PI by systematically removing nonlinearities such as LayerNorm and GELU and reducing FLOPs counts. For the first time, we propose a Softmax-only architecture with significantly fewer FLOPs tailored for efficient PI. Furthermore, we devise a novel entropy regularization technique to improve the performance of Softmax-only models. AERO achieves up to 4.23times communication and 1.94times latency reduction. We validate the effectiveness of AERO by benchmarking it against the state-of-the-art.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:45:35 GMT</pubDate>
</item>
<item>
<title>Retrospective Learning from Interactions</title>
<link>https://arxiv.org/abs/2410.13852</link>
<guid>https://arxiv.org/abs/2410.13852</guid>
<content:encoded><![CDATA[
Multi-turn interactions between large language models (LLMs) and users naturally include implicit feedback signals. If an LLM responds in an unexpected way to an instruction, the user is likely to signal it by rephrasing the request, expressing frustration, or pivoting to an alternative task. Such signals are task-independent and occupy a relatively constrained subspace of language, allowing the LLM to identify them even if it fails on the actual task. This creates an avenue for continually learning from interactions without additional annotations. We introduce ReSpect, a method to learn from such signals in past interactions via retrospection. We deploy ReSpect in a new multimodal interaction scenario, where humans instruct an LLM to solve an abstract reasoning task with a combinatorial solution space. Through thousands of interactions with humans, we show how ReSpect gradually improves task completion rate from 31% to 82%, all without any external annotation.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:43:05 GMT</pubDate>
</item>
<item>
<title>Failing Forward: Improving Generative Error Correction for ASR with Synthetic Data and Retrieval Augmentation</title>
<link>https://arxiv.org/abs/2410.13198</link>
<guid>https://arxiv.org/abs/2410.13198</guid>
<content:encoded><![CDATA[
Generative Error Correction (GEC) has emerged as a powerful post-processing method to enhance the performance of Automatic Speech Recognition (ASR) systems. However, we show that GEC models struggle to generalize beyond the specific types of errors encountered during training, limiting their ability to correct new, unseen errors at test time, particularly in out-of-domain (OOD) scenarios. This phenomenon amplifies with named entities (NEs), where, in addition to insufficient contextual information or knowledge about the NEs, novel NEs keep emerging. To address these issues, we propose DARAG (Data- and Retrieval-Augmented Generative Error Correction), a novel approach designed to improve GEC for ASR in in-domain (ID) and OOD scenarios. We augment the GEC training dataset with synthetic data generated by prompting LLMs and text-to-speech models, thereby simulating additional errors from which the model can learn. For OOD scenarios, we simulate test-time errors from new domains similarly and in an unsupervised fashion. Additionally, to better handle named entities, we introduce retrieval-augmented correction by augmenting the input with entities retrieved from a database. Our approach is simple, scalable, and both domain- and language-agnostic. We experiment on multiple datasets and settings, showing that DARAG outperforms all our baselines, achieving 8\% -- 30\% relative WER improvements in ID and 10\% -- 33\% improvements in OOD settings.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:25:05 GMT</pubDate>
</item>
<item>
<title>FlatQuant: Flatness Matters for LLM Quantization</title>
<link>https://arxiv.org/abs/2410.09426</link>
<guid>https://arxiv.org/abs/2410.09426</guid>
<content:encoded><![CDATA[
Recently, quantization has been widely used for the compression and acceleration of large language models~(LLMs). Due to the outliers in LLMs, it is crucial to flatten weights and activations to minimize quantization error with the equally spaced quantization points. Prior research explores various pre-quantization transformations to suppress outliers, such as per-channel scaling and Hadamard transformation. However, we observe that these transformed weights and activations can still remain steep and outspread. In this paper, we propose FlatQuant (Fast and Learnable Affine Transformation), a new post-training quantization approach to enhance flatness of weights and activations. Our approach identifies optimal affine transformations tailored to each linear layer, calibrated in hours via a lightweight objective. To reduce runtime overhead, we apply Kronecker decomposition to the transformation matrices, and fuse all operations in FlatQuant into a single kernel. Extensive experiments show that FlatQuant sets up a new state-of-the-art quantization benchmark. For instance, it achieves less than 1% accuracy drop for W4A4 quantization on the LLaMA-3-70B model, surpassing SpinQuant by 7.5%. For inference latency, FlatQuant reduces the slowdown induced by pre-quantization transformation from 0.26x of QuaRot to merely 0.07x, bringing up to 2.3x speedup for prefill and 1.7x speedup for decoding, respectively. Code is available at: https://github.com/ruikangliu/FlatQuant.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:05:54 GMT</pubDate>
</item>
<item>
<title>From Commands to Prompts: LLM-based Semantic File System for AIOS</title>
<link>https://arxiv.org/abs/2410.11843</link>
<guid>https://arxiv.org/abs/2410.11843</guid>
<content:encoded><![CDATA[
Large language models (LLMs) have demonstrated significant potential in the development of intelligent applications and systems such as LLM-based agents and agent operating systems (AIOS). However, when these applications and systems interact with the underlying file system, the file system still remains the traditional paradigm: reliant on manual navigation through precise commands. This paradigm poses a bottleneck to the usability of these systems as users are required to navigate complex folder hierarchies and remember cryptic file names. To address this limitation, we propose an LLM-based semantic file system ( LSFS ) for prompt-driven file management. Unlike conventional approaches, LSFS incorporates LLMs to enable users or agents to interact with files through natural language prompts, facilitating semantic file management. At the macro-level, we develop a comprehensive API set to achieve semantic file management functionalities, such as semantic file retrieval, file update monitoring and summarization, and semantic file rollback). At the micro-level, we store files by constructing semantic indexes for them, design and implement syscalls of different semantic operations (e.g., CRUD, group by, join) powered by vector database. Our experiments show that LSFS offers significant improvements over traditional file systems in terms of user convenience, the diversity of supported functions, and the accuracy and efficiency of file operations. Additionally, with the integration of LLM, our system enables more intelligent file management tasks, such as content summarization and version comparison, further enhancing its capabilities.
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 23:07:33 GMT</pubDate>
</item>
<item>
<title>FLARE: Faithful Logic-Aided Reasoning and Exploration</title>
<link>https://arxiv.org/abs/2410.11900</link>
<guid>https://arxiv.org/abs/2410.11900</guid>
<content:encoded><![CDATA[
Modern Question Answering (QA) and Reasoning approaches based on Large Language Models (LLMs) commonly use prompting techniques, such as Chain-of-Thought (CoT), assuming the resulting generation will have a more granular exploration and reasoning over the question space and scope. However, such methods struggle with generating outputs that are faithful to the intermediate chain of reasoning produced by the model. On the other end of the spectrum, neuro-symbolic methods such as Faithful CoT (F-CoT) propose to combine LLMs with external symbolic solvers. While such approaches boast a high degree of faithfulness, they usually require a model trained for code generation and struggle with tasks that are ambiguous or hard to formalise strictly. We introduce Faithful Logic-Aided Reasoning and Exploration (\ours), a novel interpretable approach for traversing the problem space using task decompositions. We use the LLM to plan a solution, soft-formalise the query into facts and predicates using a logic programming code and simulate that code execution using an exhaustive multi-hop search over the defined space. Our method allows us to compute the faithfulness of the reasoning process w.r.t. the generated code and analyse the steps of the multi-hop search without relying on external solvers. Our methods achieve SOTA results on 7 out of 9 diverse reasoning benchmarks. We also show that model faithfulness positively correlates with overall performance and further demonstrate that {\ours} allows pinpointing the decisive factors sufficient for and leading to the correct answer with optimal reasoning during the multi-hop search.
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 21:59:33 GMT</pubDate>
</item>
<item>
<title>语言模型校准：应对RLHF中的过度自信现象</title>
<link>https://arxiv.org/abs/2410.09724</link>
<guid>https://arxiv.org/abs/2410.09724</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文探讨了模型过度自信的原因，并提出两种强化学习变种以改善模型校准。</p><br /><br /><p><strong>摘要：</strong> 本文研究语言模型的校准问题，特别是强化学习中的人类反馈（RLHF）如何导致模型在自身响应上的过度自信现象。我们指出，RLHF训练的奖励模型在实际响应质量与高置信度分数之间存在固有偏差。为此，本文提出了两种改进的近端策略优化（PPO）方法：PPO-M和PPO-C。PPO-M通过在奖励模型训练中整合显式置信度分数来校准奖励模型，而PPO-C则是在PPO过程中根据当前奖励与过去奖励的移动平均差异调节奖励分数。这两种方法可以无缝集成到现有的PPO流程中，且不需要额外的黄金标签。我们在Llama3-8B和Mistral-7B模型上，对六个多样化的数据集进行了评估，包括多选择题和开放式生成。实验结果表明，这两种方法能有效减少校准误差，同时维持与标准PPO相当的性能，并且在开放式对话场景中不影响模型能力。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.09724" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 14:29:03 GMT</pubDate>
</item>
<item>
<title>优化潜在空间的图像生成模型：DiGIT的探索</title>
<link>https://arxiv.org/abs/2410.12490</link>
<guid>https://arxiv.org/abs/2410.12490</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本研究提出DiGIT，提升图像自回归生成模型的性能，首次 outperform LDMs。</p><br /><br /><p><strong>摘要：</strong> 本文探讨了潜在空间在图像生成模型中的稳定性，特别是自回归模型与潜在扩散模型（LDMs）和掩模图像模型（MIMs）之间的差异。尽管自回归模型在自然语言处理（NLP）中表现卓越，但在图像生成领域存在明显劣势。为解决这一问题，提出了一种简单有效的离散图像标记器（DiGIT），旨在稳定图像生成中的潜在空间。通过实验验证，DiGIT 在图像理解和生成上均显著提升了自回归模型的性能，显示出基于下一个标记预测原则的优势。值得注意的是，DiGIT 的实现首次使自回归图像模型超越了 LDMs，并展示了随模型规模扩大而带来的显著改进。这一发现强调了优化潜在空间和离散标记化的结合对于推动图像生成模型能力的潜力。代码可在 https://github.com/DAMO-NLP-SG/DiGIT 中获取。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.12490" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 13:58:54 GMT</pubDate>
</item>
<item>
<title>ChroKnowBench：评估大规模语言模型的时间知识积累</title>
<link>https://arxiv.org/abs/2410.09870</link>
<guid>https://arxiv.org/abs/2410.09870</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">提出ChroKnowBench基准和ChroKnowledge框架，以评估大规模语言模型的时间知识及其更新效果。</p><br /><br /><p><strong>摘要：</strong> 本研究提出了ChroKnowBench，一个用于评估大规模语言模型（LLMs）时间知识积累的新基准数据集，旨在解决知识的累积性质与时间依赖性。该基准涵盖多个领域，区分了随着时间演变的知识（如科学发现、修订法律）与不变的知识（如数学真理、公理事实）。基于此基准，研究者们引入了ChroKnowledge（Chronological Categorization of Knowledge），一个用于评价和更新LLMs非参数时间知识的采样框架。评估结果显示，模型在提取时间知识的能力上与训练数据格式有关，并且往往在时间边界处出现知识回忆的截断。为此，研究者提出了ChroKnowPrompt，通过逐步引导模型穿越时间跨度，来有效地引发时间知识的提取。结果表明，该框架在生物医学领域和通用领域成功更新了整体知识，分别提升了11.9%和2.8%。该非参数方法适用于开源模型和专有LLMs，确保了其全面适用性，展示了通过此方法提取内在时间知识的潜力。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.09870" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 11:56:11 GMT</pubDate>
</item>
<item>
<title>可控安全对齐框架：满足多样化安全需求的语言模型适应性</title>
<link>https://arxiv.org/abs/2410.08968</link>
<guid>https://arxiv.org/abs/2410.08968</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">提出可控安全对齐（CoSA）框架，使语言模型根据安全配置灵活适应用户需求。</p><br /><br /><p><strong>摘要：</strong> 当前大型语言模型（LLM）的安全对齐方法采用一刀切的方式，模型对任何被提供者认定为不安全的内容拒绝交互。这种方法在面对不同文化和地区的社会规范时缺乏灵活性。此外，由于用户的安全需求各不相同，静态的安全标准可能过于严格，影响模型的实用性，并且重新对齐的成本也较高。为此，我们提出可控安全对齐（CoSA）框架，旨在在不重新训练的情况下，使模型适应多样化的安全要求。CoSA通过将安全配置作为系统提示的一部分，使模型遵循自由形式的自然语言描述来调整安全行为。通过在推理过程中由授权用户修改安全配置，可以简单地调整模型的安全行为。我们还提出了CoSAlign，一种数据中心的方法，使得LLM能够轻松适应多样化的安全配置。此外，我们设计了一个新颖的可控性评估协议，考虑了有用性和配置安全，并将其总结为CoSA评分。我们构建了CoSApien，这是一个包含真实世界LLM用例及其评估提示的人类创作基准。实验证明，CoSAlign在可控性方面相较强基线，包括上下文对齐，获得了显著提升。我们的框架鼓励更好地表现和适应多元化的人类价值观，从而增加LLM的实用性。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.08968" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 11:46:21 GMT</pubDate>
</item>
<item>
<title>动态词汇头（DyVo）提升稀疏检索模型的实体识别效果</title>
<link>https://arxiv.org/abs/2410.07722</link>
<guid>https://arxiv.org/abs/2410.07722</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本研究通过动态词汇头（DyVo）与维基百科概念结合，提升了稀疏检索模型对实体的识别与检索能力。</p><br /><br /><p><strong>摘要：</strong> 学习型稀疏检索（LSR）模型使用预训练变换器的词汇，但往往将实体拆分成不合理的片段，从而降低检索准确性，并限制模型吸纳最新的世界知识。为此，本研究通过结合维基百科的概念和实体，增强了LSR的词汇，从而更有效地解决歧义并保持与不断发展的知识保持同步。我们的方法核心在于动态词汇（DyVo）头，该头利用现有实体嵌入和实体检索组件，识别与查询或文档相关的实体。DyVo头用于生成实体权重，随后将这些权重与词片权重合并，以创建高效编码和检索的联合表征，并使用倒排索引进行检索。实验结果显示，在三个富含实体的文档排序数据集上，DyVo模型的表现显著优于最先进的基线模型。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.07722" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 10:24:44 GMT</pubDate>
</item>
<item>
<title>特征在不同文本领域之间的稳定性与转变研究</title>
<link>https://arxiv.org/abs/2410.12391</link>
<guid>https://arxiv.org/abs/2410.12391</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">研究特征如何在不同文本领域的模型中出现、消失和持续。</p><br /><br /><p><strong>摘要：</strong> 本文研究了特征在不同领域文本的模型中的表现及其稳定性，聚焦于对一个基础的一层Transformer语言模型进行适应和测试。该基础模型是基于BabyLM语料库和来自The Stack的Python代码集训练的。我们将该基础模型适应于两个新的文本领域：TinyStories和Lua编程语言。随后，通过球面线性插值方法将这两个模型合并。我们的探索旨在揭示在小规模模型和稀疏自编码器的典型迁移学习场景中，特征的稳定性和转变过程。这为理解不同领域间特征的演变提供了更深入的见解，进而有助于提高迁移学习和模型适应能力。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.12391" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 10:10:35 GMT</pubDate>
</item>
<item>
<title>通过逆向强化学习解读大型语言模型的隐性奖励函数</title>
<link>https://arxiv.org/abs/2410.12491</link>
<guid>https://arxiv.org/abs/2410.12491</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本研究运用逆向强化学习解析毒性对齐的LLM隐性奖励，探讨模型大小与可解释性等关键问题。</p><br /><br /><p><strong>摘要：</strong> 本文提出了一种新的方法，通过逆向强化学习(Inverse Reinforcement Learning, IRL)恢复大型语言模型(LLMs)的隐性奖励函数，以理解它们的决策过程。研究聚焦于毒性对齐的LLM，采用多种规模的模型进行实验，提取奖励模型的预测准确率达到80.40%。分析中揭示了奖励函数的非可识别性、模型规模与可解释性之间的关系以及RLHF过程中的潜在问题。结果表明，通过IRL提取的奖励模型能够用于新LLM的微调，在毒性基准测试上实现了相当或更优的性能。这项工作为理解和改进大型语言模型的对齐提供了新的视角，并且对这些强大系统的负责任开发与部署具有重要意义。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.12491" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 08:37:56 GMT</pubDate>
</item>
<item>
<title>神经形态变换（NeuMeta）：自适应神经网络的连续权重学习</title>
<link>https://arxiv.org/abs/2410.11878</link>
<guid>https://arxiv.org/abs/2410.11878</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">NeuMeta提出了一种新学习范式，实现自适应神经网络，并在不同配置下无缝生成权重。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了一种新的学习范式，即神经形态变换（NeuMeta），旨在构建可自我变换的神经网络。与为不同架构或规模制造单独模型不同，NeuMeta直接学习神经网络的连续权重流形。训练后，可以直接从流形中为任何大小的网络采样权重，甚至在先前未见过的配置中，无需重新训练。为了实现这一雄心勃勃的目标，NeuMeta将神经隐式函数作为超网络进行训练，接受模型空间内的坐标作为输入，并生成相应的不变权重值。训练过程中，发现最终性能与学习流形的平滑性密切相关。为提高平滑性，我们采用了两种策略：首先，通过解决最短哈密顿路径问题对权重矩阵进行置换以实现模型内部平滑性。其次，在训练隐式函数时对输入坐标添加噪声，以确保不同大小的模型均表现一致。因此，NeuMeta在合成多种网络配置的参数方面显示出良好效果。我们的广泛测试表明，NeuMeta在图像分类、语义分割和图像生成任务中，即使在75%的压缩率下，也能保持全尺寸性能。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.11878" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 08:23:01 GMT</pubDate>
</item>
<item>
<title>基于连续时间的生成模型的稳定训练与快速采样</title>
<link>https://arxiv.org/abs/2410.11081</link>
<guid>https://arxiv.org/abs/2410.11081</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">提出一种新方法，优化基于扩散的生成模型，在连续时间上实现稳定快速采样。</p><br /><br /><p><strong>摘要：</strong> 一致性模型（Consistency Models, CMs）是一类强大的基于扩散的生成模型，旨在实现快速采样。虽然现有的CMs大多采用离散时间步训练，这带来了额外的超参数并易受到离散化误差影响。但连续时间形式可以缓解这些问题，然而其成功受到训练不稳定性的限制。为了解决这一问题，我们提出了一个简化的理论框架，用于统一以前的扩散模型和CMs的参数化，找出了不稳定性的根本原因。在此分析的基础上，我们引入了扩散过程参数化、网络架构和训练目标的关键改进。这些改变使我们能够在前所未有的规模上训练连续时间CMs，达到1.5亿参数在ImageNet 512x512上。我们的训练算法仅使用两个采样步骤，即在CIFAR-10上实现了2.06的FID分数，在ImageNet 64x64上为1.48，在ImageNet 512x512上为1.88，FID分数与最佳扩散模型之间的差距缩小到10%以内。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.11081" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 07:42:04 GMT</pubDate>
</item>
<item>
<title>WorldMedQA-V：多语言多模态医疗基准测试数据集</title>
<link>https://arxiv.org/abs/2410.12722</link>
<guid>https://arxiv.org/abs/2410.12722</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">WorldMedQA-V是一个更新的多语言多模态基准数据集，旨在评估医疗领域的视觉语言模型。</p><br /><br /><p><strong>摘要：</strong> 随着多模态/视觉语言模型（VLMs）在全球医疗环境中的广泛应用，确保其安全性、有效性和公平性变得日益重要。本研究提出了WorldMedQA-V，一个更新的多语言多模态基准测试数据集，旨在评估VLMs在医疗领域的表现。该数据集包括568个标记的多项选择题和568个医学图像，覆盖来自巴西、以色列、日本和西班牙的四个国家，提供了原语言及经过本地临床医生验证的英文翻译。我们还提供了常见开源和闭源模型的基准性能测试结果，涵盖本地语言和英文翻译，并针对模型在有无图像的情况下的表现进行了对比。WorldMedQA-V基准旨在更好地匹配AI系统与其所处的多样化医疗环境，促进更公平、高效和具代表性的应用。该数据集为未来在多语言和多模态的医疗场景中的模型发展和应用提供了重要的基准依据。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.12722" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 07:19:55 GMT</pubDate>
</item>
<item>
<title>Large Language Model Evaluation via Matrix Nuclear-Norm</title>
<link>https://arxiv.org/abs/2410.10672</link>
<guid>https://arxiv.org/abs/2410.10672</guid>
<content:encoded><![CDATA[
As large language models (LLMs) continue to evolve, efficient evaluation metrics are vital for assessing their ability to compress information and reduce redundancy. While traditional metrics like Matrix Entropy offer valuable insights, they are computationally intensive for large-scale models due to their \( O(n^3) \) time complexity with Singular Value Decomposition (SVD). To mitigate this issue, we introduce the Matrix Nuclear-Norm, which not only serves as a metric to quantify the data compression proficiency of LLM but also provides a convex approximation of matrix rank to capture both predictive discriminability and diversity. By employing the \( L_{1,2}-norm \) to further approximate the nuclear norm, we can effectively assess the model's information compression capabilities. This approach reduces the time complexity to \( O(n^2) \) and eliminates the need for SVD computation. Consequently, the Matrix Nuclear-Norm achieves speeds 8 to 24 times faster than Matrix Entropy for the CEREBRAS-GPT model as sizes increase from 111M to 6.7B. This performance gap becomes more pronounced with larger models, as validated in tests with other models like Pythia. Additionally, evaluations on benchmarks and model responses confirm that our proposed Matrix Nuclear-Norm is a reliable, scalable, and efficient tool for assessing LLMs' performance, striking a balance between accuracy and computational efficiency. The code is available at https://github.com/MLGroupJLU/MatrixNuclearNorm.
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 05:44:04 GMT</pubDate>
</item>
<item>
<title>VidEgoThink：评估自我视角视频理解能力的综合基准</title>
<link>https://arxiv.org/abs/2410.11623</link>
<guid>https://arxiv.org/abs/2410.11623</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">VidEgoThink基准评估自我视角视频理解能力，揭示多模态大语言模型在此领域的局限性。</p><br /><br /><p><strong>摘要：</strong> 近年来，多模态大语言模型（MLLMs）的进步为具身人工智能应用开辟了新方向。在之前工作EgoThink的基础上，我们提出了VidEgoThink，这是一个用于评估自我视角视频理解能力的综合基准。为了弥合MLLMs与具身AI低级控制之间的差距，我们设计了四个相互关联的关键任务：视频问答、层次规划、视觉定位和奖励建模。为降低手动标注成本，我们基于Ego4D数据集开发了一种自动数据生成管道，利用GPT-4o的先验知识和多模态能力，随后三位人工标注者过滤生成的数据，以确保多样性和质量，最终形成了VidEgoThink基准。我们对三种类型的模型进行了广泛实验：基于API的MLLMs、开源图像基MLLMs和开源视频基MLLMs。实验结果表明，包括GPT-4o在内的所有MLLMs在自我视角视频理解相关任务上表现较差。这些发现表明，基础模型仍需重大进展才能有效应用于具身人工智能中的第一人称场景。总体而言，VidEgoThink反映了将MLLMs应用于自我视角视觉的研究趋势，旨在实现与人类能力相似的主动观察与互动，探究复杂现实环境中的行为。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.11623" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 05:23:48 GMT</pubDate>
</item>
<item>
<title>ZipVL：针对大规模视觉语言模型的高效推理框架</title>
<link>https://arxiv.org/abs/2410.08584</link>
<guid>https://arxiv.org/abs/2410.08584</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">ZipVL通过动态重要令牌比例分配策略，提高大规模视觉语言模型的推理效率，减小计算和内存瓶颈。</p><br /><br /><p><strong>摘要：</strong> 本文提出了ZipVL，一个高效的推理框架，旨在解决大规模视觉语言模型（LVLMs）在预填充阶段的计算瓶颈和解码阶段的内存瓶颈。ZipVL采用动态重要令牌比例分配策略，该比例依据层特定的注意力分数分布自适应确定，以优化较低复杂性任务的效率，同时保持高复杂性任务的表现。我们通过标准化注意力分数选择重要令牌，并仅对这些重要令牌执行注意力机制，从而加速预填充阶段。此外，在解码阶段，我们对键值（KV）缓存采用混合精度量化，对重要令牌的缓存使用高位量化，对不太重要的缓存应用低位量化。实验结果显示，ZipVL能够将预填充阶段的速度提升2.6倍，同时将GPU内存使用减少50.0%，在LongVA-7B模型上，在Video-MME基准上仅有0.2%的准确率下降，从而有效增强了LVLMs的生成效率。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.08584" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 03:40:12 GMT</pubDate>
</item>
<item>
<title>多模态模型中的幻觉问题研究：挑战与前景</title>
<link>https://arxiv.org/abs/2410.12787</link>
<guid>https://arxiv.org/abs/2410.12787</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">该研究系统分析了大规模多模态模型中的幻觉现象，提出评估基准并探讨解决方案。</p><br /><br /><p><strong>摘要：</strong> 近期大规模多模态模型（LMMs）的进展显著提升了在多种任务中的表现，且仍在持续研究如何整合视频和音频等附加模态。然而，现有LMMs仍然易受幻觉影响，即实际的多模态输入与生成的文本输出之间的差异，这限制了它们在各种实际场景中的应用。本研究首次系统性地调查了涉及语言、视觉和音频这三种最常见模态的LMMs中的幻觉现象。我们的研究揭示了两个关键原因：对单一模态先验的过度依赖及模态间虚假的关联。为了解决这些挑战，我们推出了基准The Curse of Multi-Modalities (CMM)，全面评估LMMs中的幻觉，并深入分析其根本问题。研究结果突显出关键脆弱点，包括模态整合的不平衡和来自训练数据的偏见，强调了平衡的跨模态学习和增强幻觉减轻策略的必要性。基于我们的观察和发现，我们提出了可能增强LMMs可靠性的研究方向。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.12787" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 02:21:58 GMT</pubDate>
</item>
<item>
<title>HumanEval-V：评估大型多模态模型的视觉理解与编程能力的基准</title>
<link>https://arxiv.org/abs/2410.12381</link>
<guid>https://arxiv.org/abs/2410.12381</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">HumanEval-V是一个新基准，评估大型多模态模型的编码与视觉推理能力。</p><br /><br /><p><strong>摘要：</strong> 随着大型语言模型（LLMs）在编码任务上的评估成为人工智能进步的重要工具，视觉感知能力的引入使得大型多模态模型（LMMs）变得愈发重要。然而，目前对于LMMs在视觉推理和代码生成方面的评估基准相对缺乏，为此我们提出了HumanEval-V。该基准包含108个精心设计的初级Python编码任务，来源于CodeForces和Stack Overflow，并经过适当调整以保证其独创性。每个任务都包括视觉元素和预定义的函数签名，模型需要基于这些内容生成代码解决方案，并通过手工编写的测试用例进行评估。在对19个先进的LMM进行评测后，我们发现目前LMM在视觉推理和编码能力上存在显著挑战，与商用模型如GPT-4o相比，其通过率仅为13%（pass@1）和36.4%（pass@10），而一些开源模型的通过率更低于4%。这些结果为未来的研究指明了增强LMM能力的关键方向。我们的代码和基准已开源，链接为：https://github.com/HumanEval-V/HumanEval-V-Benchmark。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.12381" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 01:49:58 GMT</pubDate>
</item>
<item>
<title>跨模态时间理解的新模型与数据集研究</title>
<link>https://arxiv.org/abs/2410.12109</link>
<guid>https://arxiv.org/abs/2410.12109</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出OCTAV数据集及OMCAT模型，提升音视频跨模态时间理解的能力。</p><br /><br /><p><strong>摘要：</strong> 大型语言模型（LLMs）在文本生成与理解方面取得了显著进展，最近的研究扩展到了整合视觉和音频输入的多模态LLMs。然而，这些模型在细粒度的跨模态时间理解，特别是在音频与视频流之间相关事件的关联上仍然面临挑战。为了解决这些问题，我们提出了两个关键贡献：一个新的数据集OCTAV（Omni Context and Temporal Audio Video），旨在捕捉音视频之间的事件过渡；以及OMCAT（Omni Context Aware Transformer）模型，该模型利用RoTE（Rotary Time Embeddings），对RoPE进行创新扩展，提升了时间锚定任务的时效性和计算效率。通过强大的三阶段训练管道——特征对齐、指令调优和OCTAV特定训练——OMCAT在跨模态时间理解上表现卓越。我们的模型在音频视觉问答（AVQA）任务和OCTAV基准上展现了先进的性能，并通过全面的实验和消融研究验证了其在时间推理和跨模态对齐方面的显著提升。我们的数据集和代码将公开发布，演示页面链接为：https://om-cat.github.io。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.12109" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 01:18:30 GMT</pubDate>
</item>
<item>
<title>ProSA：评估大型语言模型提示敏感性的框架</title>
<link>https://arxiv.org/abs/2410.12405</link>
<guid>https://arxiv.org/abs/2410.12405</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">ProSA框架评估大型语言模型在不同提示下的性能敏感性，提出新的度量指标并揭示其内在机制。</p><br /><br /><p><strong>摘要：</strong> 大型语言模型（LLMs）在多项任务中展现出令人印象深刻的能力，但其表现对所使用的提示高度敏感。这种可变性给准确评估和用户满意度带来了挑战。目前的研究常常忽视实例级提示变异及其对主观评估的影响。为了解决这些问题，我们提出了ProSA框架，该框架旨在评估和理解LLMs的提示敏感性。ProSA引入了一种新的敏感性度量指标PromptSensiScore，并利用解码置信度来阐明其内在机制。我们的广泛研究涵盖多项任务，揭示提示敏感性在不同数据集和模型间的波动状况，发现较大的模型表现出更强的鲁棒性。此外，我们观察到少量示例能够缓解这一敏感性问题，主观评估也受到提示敏感性的影响，特别是在复杂的推理任务中。值得注意的是，模型的更高置信度与提示鲁棒性之间呈正相关。我们相信这项工作将成为研究LLMs提示敏感性的重要工具。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.12405" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 01:00:15 GMT</pubDate>
</item>
<item>
<title>基于模型亲缘关系的高效语言模型合并策略</title>
<link>https://arxiv.org/abs/2410.12613</link>
<guid>https://arxiv.org/abs/2410.12613</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">提出模型亲缘关系，优化大语言模型合并策略，提升性能。</p><br /><br /><p><strong>摘要：</strong> 本文提出了模型亲缘关系（Model Kinship）的概念，旨在衡量大型语言模型（LLMs）之间的相似性和相关性。通过综合实证分析，我们发现模型亲缘关系与模型合并后性能增益之间存在一定的关系，这可以帮助我们在选择候选模型时做出更明智的判断。基于这一发现，我们提出了一种新的合并策略——基于模型亲缘关系的Top-k贪婪合并。这种方法在基准数据集上的表现更佳，并且我们发现利用模型亲缘关系作为标准可以促进持续的模型合并，缓解模型进化过程中的性能退化（局部最优）问题。此外，模型亲缘关系还可以帮助我们摆脱陷阱，实现更有效的模型演化。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.12613" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 00:55:42 GMT</pubDate>
</item>
<item>
<title>DocLayout-YOLO：一种高速高准确率的文档布局分析方法</title>
<link>https://arxiv.org/abs/2410.12628</link>
<guid>https://arxiv.org/abs/2410.12628</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文介绍了一种名为DocLayout-YOLO的新方法，旨在提升文档布局分析的速度和准确性。</p><br /><br /><p><strong>摘要：</strong> 在文档理解系统中，文档布局分析至关重要，但面临速度与准确性之间的权衡。针对这一问题，本文提出DocLayout-YOLO，一种通过文档特定优化在预训练和模型设计上提高准确性并保持速度优势的新方法。我们提出Mesh-candidate BestFit算法，将文档合成视为二维装箱问题，从而生成大规模、多样化的DocSynth-300K数据集，实现稳健的文档预训练。使用DocSynth-300K进行预训练显著提升了各种文档类型的微调性能。在模型优化方面，我们提出了Global-to-Local可控感受野模块，能够更好地处理文档元素的多尺度变化。此外，为验证不同文档类型的性能，我们引入了复杂且具挑战性的基准测试DocStructBench。大量实验证明，DocLayout-YOLO在速度和准确性方面均表现优异。代码、数据和模型可在https://github.com/opendatalab/DocLayout-YOLO获取。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.12628" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 00:44:41 GMT</pubDate>
</item>
<item>
<title>长文本对齐的文本到图像生成模型的优化方法 LongAlign</title>
<link>https://arxiv.org/abs/2410.11817</link>
<guid>https://arxiv.org/abs/2410.11817</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出LongAlign方法，通过分段编码和偏好优化提高长文本的图像生成对齐效果。</p><br /><br /><p><strong>摘要：</strong> 随着文本到图像（T2I）扩散模型的快速发展，它们能够根据给定文本生成前所未有的结果。然而，对于长文本的输入，现有的编码方法（如CLIP）面临限度，导致生成的图像与长文本的对齐变得具有挑战性。为了解决这些问题，本文提出了LongAlign方法，包括一种分段级编码方法，用于处理长文本，以及一种分解的偏好优化方法，以实现有效的对齐训练。在分段级编码中，长文本被拆分为多个段落并单独处理，从而克服了预训练编码模型的最大输入长度限制。在偏好优化方面，我们提供了基于CLIP的分解偏好模型来微调扩散模型。我们深入研究了CLIP-based偏好模型的评分机制，并发现偏好分数可以分解为两个组件：一个与文本相关的部分用于测量T2I对齐程度，另一个与文本无关的部分评估人类偏好的其他视觉方面。通过提出重加权策略，分配这两个组件不同的权重，我们减少了过拟合现象，提高了对齐效果。经过大约20小时的微调，512x512的Stable Diffusion (SD) v1.5显著超越了PixArt-alpha和Kandinsky v2.2等更强大的基础模型。相关代码已发布于https://github.com/luping-liu/LongAlign。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.11817" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 00:20:12 GMT</pubDate>
</item>
<item>
<title>限制因素与问题影响：语言智能体规划能力的挑战</title>
<link>https://arxiv.org/abs/2410.12409</link>
<guid>https://arxiv.org/abs/2410.12409</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文研究语言智能体在自主规划中面临的限制因素及其影响，包括约束条件作用有限与问题效应减弱。</p><br /><br /><p><strong>摘要：</strong> 自主规划自人工智能诞生以来一直是一个重要研究领域。早期的规划智能体主要针对特定任务提供精准解决方案，但缺乏通用能力。随着大型语言模型（LLMs）及其强大推理能力的出现，自动生成合适方案的兴趣重新涌现。然而，现有研究表明，目前的语言智能体仍未达到人类级别的规划能力，OpenAI的o1模型在复杂真实世界规划基准上仅获得15.6%的成绩。本文探讨了阻碍语言智能体实现人类级规划的深层次原因，并通过特征归因研究识别了两个关键因素：约束条件的有限作用和问题的减弱影响。虽然目前的解决策略在一定程度上减轻了这些挑战，但并未完全解决，显示出智能体在达到人类级智能方面仍然任重道远。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.12409" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 00:09:59 GMT</pubDate>
</item>
<item>
<title>MultiVENT 2.0：多语言事件驱动的视频检索基准</title>
<link>https://arxiv.org/abs/2410.11619</link>
<guid>https://arxiv.org/abs/2410.11619</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">MultiVENT 2.0是一个大型多语言视频检索基准，涵盖218,000个新闻视频和3,906个事件查询，挑战现有的多模态视频检索系统。</p><br /><br /><p><strong>摘要：</strong> 随着从大规模多模态集合中有效提取和综合信息的需求日益增长，现有的视频检索数据集受到范围限制，主要关注将模糊描述性的查询与小规模、专业编辑的英语视频进行匹配。为了解决这一问题，我们推出了MultiVENT 2.0，这是一个大型多语言事件驱动的视频检索基准，包含超过218,000个新闻视频和3,906个针对特定世界事件的查询。这些查询特别针对视频中的视觉内容、音频、嵌入文本和文本元数据的信息，要求系统充分利用所有这些来源以成功完成任务。初步结果表明，当前最先进的视觉-语言模型在这一任务上面临很大挑战，而其他方法虽然显示出一定的潜力，但仍不足以有效应对这一问题。这些发现突显了建立更强大的多模态检索系统的必要性，有效的视频检索是实现多模态内容理解和生成任务的关键一步。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.11619" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 16 Oct 2024 16:08:59 GMT</pubDate>
</item>
<item>
<title>EchoPrime：一种多视角视频基础模型用于全面心脏超声学解读</title>
<link>https://arxiv.org/abs/2410.09704</link>
<guid>https://arxiv.org/abs/2410.09704</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">EchoPrime通过多视角视频分析，实现精确的心脏超声自动化评估。</p><br /><br /><p><strong>摘要：</strong> Echocardiography是评估心脏结构和功能的最广泛使用的影像学方法，而人工智能（AI）在其应用中具有潜在优势。然而，目前大多数echocardiography AI模型仅限于单一视角和单一任务，未能利用全面检查中多个视角的互补信息，从而限制了其性能和应用范围。为了解决这一问题，我们提出了EchoPrime，这是一种经过训练的多视角、视角信息驱动的视频基础模型，基于1200万个视频-报告对进行训练。EchoPrime使用对比学习建立针对所有标准视角的统一嵌入模型，并具备对常见和罕见疾病的表示。它通过视角分类与视角驱动的解剖注意模型整合视频特定解释，准确映射超声波视角与解剖结构之间的关系。通过增强信息检索，EchoPrime整合全面研究中的所有超声波视频，实现全面的临床解读。在来自两个独立医疗系统的数据集中，EchoPrime在23个心脏形态和功能的多样化基准上达到了最先进的性能，超越了任务特定方法和以前的基础模型。经过严格的临床评估，EchoPrime可以帮助医生自动化地初步评估全面超声心动图。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.09704" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 16 Oct 2024 13:31:06 GMT</pubDate>
</item>
<item>
<title>NesTools：评估大型语言模型的嵌套工具学习能力的新基准</title>
<link>https://arxiv.org/abs/2410.11805</link>
<guid>https://arxiv.org/abs/2410.11805</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出NesTools，评估大型语言模型的嵌套工具学习能力，用于填补相关研究空白。</p><br /><br /><p><strong>摘要：</strong> 随着大型语言模型（LLMs）与工具学习的结合在现实应用中取得了显著成果，嵌套工具学习的能力成为研究的重点。然而，目前的研究仍然比较薄弱，现有基准缺乏相关的数据实例。为了应对这一问题，本文提出了NesTools，以填补在综合嵌套工具学习评估中的空白。NesTools采用了一种新颖的自动数据生成方法，构建了大规模的嵌套工具调用，涵盖多种嵌套结构。通过人工审查和细化，生成的数据集质量高，且与真实场景密切相关。因此，NesTools可以作为评估LLMs嵌套工具学习能力的新基准。我们在22个LLMs上进行了广泛的实验，并提供了详细的分析，结果显示当前LLMs在复杂的嵌套工具学习任务中的表现仍然存在不足之处。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.11805" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 16 Oct 2024 12:59:44 GMT</pubDate>
</item>
<item>
<title>Agent-as-a-Judge框架：针对智能体系统的新评估方法</title>
<link>https://arxiv.org/abs/2410.10934</link>
<guid>https://arxiv.org/abs/2410.10934</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出Agent-as-a-Judge框架，针对智能体系统的评估提供新的思路和方法。</p><br /><br /><p><strong>摘要：</strong> 当今的评估技术对智能体系统的评估显得不足，常常只关注最终结果，而忽略了智能体系统解决问题的逐步过程，或者需要过多的人工劳动。为此，我们提出了Agent-as-a-Judge框架，利用智能体系统相互评估的方式，作为LLM-as-a-Judge框架的自然延伸，结合了能够为整个任务解决过程提供中间反馈的智能体特征。我们将该框架应用于代码生成任务，开发了名为DevAI的新基准，包含55个真实的自动化AI开发任务以及365个分层用户需求的详细手动注释。通过Agent-as-a-Judge基准测试了三种流行的智能体系统，结果显示其表现远超LLM-as-a-Judge，与人类评估基线同样可靠。总体而言，Agent-as-a-Judge为现代智能体系统的发展提供了富有意义和可靠的奖励信号，实现动态和可扩展的自我改进，标志着该领域的一个重要进步。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.10934" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 16 Oct 2024 12:41:48 GMT</pubDate>
</item>
<item>
<title>基于COCO的互动图像抠图数据集与方法研究</title>
<link>https://arxiv.org/abs/2410.06593</link>
<guid>https://arxiv.org/abs/2410.06593</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出COCO-Matting数据集及SEMat方法，以改善交互式自然图像抠图性能。</p><br /><br /><p><strong>摘要：</strong> 近期的研究尝试将强大的交互式分割模型如SAM适应于交互式抠图，并通过合成抠图数据集进行微调。然而，基于合成数据训练的模型在复杂及遮挡场景中表现不佳。为了解决这一挑战，本文提出了一个基于COCO数据集的新抠图数据集COCO-Matting。具体来说，COCO-Matting的构建包括配件融合和从语义分割掩码到抠图标签的转换，选取复杂的真实世界图像并将其语义分割掩码转换为抠图标签。构建的COCO-Matting包含38,251个在复杂自然场景下的人物实例级α遮罩。此外，现有的基于SAM的抠图方法从冻结的SAM中提取中间特征和掩码，仅通过端到端的抠图损失训练一个轻量级的抠图解码器，未能充分挖掘预训练SAM的潜力。因此，本文提出了SEMat，通过改革网络架构和训练目标以提升性能。新提出的特征对齐变压器能够提取细粒度的边缘和透明特征，而抠图对齐解码器则旨在细分抠图特定对象，并将粗糙掩码转换为高精度的抠图。通过在七个多样化数据集上的广泛实验，证明了本方法的卓越性能，验证了其在交互自然图像抠图中的有效性。此外，我们将代码、模型和数据集开源于 https://github.com/XiaRho/SEMat。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.06593" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 16 Oct 2024 11:19:09 GMT</pubDate>
</item>
<item>
<title>基于LLMtimesMapReduce框架的长文本处理研究</title>
<link>https://arxiv.org/abs/2410.09342</link>
<guid>https://arxiv.org/abs/2410.09342</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出LLMtimesMapReduce框架，通过分块和聚合策略提升长文本处理能力。</p><br /><br /><p><strong>摘要：</strong> 随着长文本处理需求的增加，扩大大型语言模型（LLMs）的上下文窗口成为重要的研究领域。本文提出了一种新颖的训练无关框架——LLMtimesMapReduce，利用分而治之的策略实现全面的文档理解。该框架将整个文档分割为多个部分供大语言模型处理，然后将中间答案聚合以生成最终输出。面对长文本处理中的难点，特别是分割文本可能导致重要的长距离信息丢失的问题，提出了两类干扰信息的分类，包括块间依赖和块间冲突。为此，本文设计了一个结构化信息协议来处理块间依赖，并引入了上下文置信度校准机制以解决块间冲突。实验结果表明，LLMtimesMapReduce在性能上优于多个代表性的开源和商业长上下文LLMs，并适用于多种模型。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.09342" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 16 Oct 2024 10:23:09 GMT</pubDate>
</item>
<item>
<title>互惠增强效应：文本分类中词级与文本级分类的协同关系</title>
<link>https://arxiv.org/abs/2410.09745</link>
<guid>https://arxiv.org/abs/2410.09745</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本研究通过实验证实互惠增强效应在文本分类中的有效性，展示词级信息对文本级分类的提升作用。</p><br /><br /><p><strong>摘要：</strong> 本研究探讨了互惠增强效应（Mutual Reinforcement Effect, MRE），阐述词级与文本级分类在文本分类任务中的协同关系及其相互促进的可能性。以往研究中未能充分证明这一机制，因此我们通过实验证实了MRE理论的有效性。我们在21个MRE混合数据集上进行实验，发现模型的表现受到MRE影响。在实验中，我们对比了不同的模型微调实验，结果确认了MRE的存在。此外，我们将MRE扩展到提示学习中，利用词级信息作为语言化工具来提升模型对文本级分类标签的预测能力。在最后的实验中，F1-score在21个MRE混合数据集中有18个超过了基线值，这进一步验证了词级信息提高了语言模型对整体文本理解的效果。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.09745" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 16 Oct 2024 09:54:44 GMT</pubDate>
</item>
<item>
<title>SimBa：通过注入简约偏差来提升深度强化学习的网络规模</title>
<link>https://arxiv.org/abs/2410.09754</link>
<guid>https://arxiv.org/abs/2410.09754</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">SimBa架构通过简约偏差提高深度强化学习的样本效率，表现超过多种深度RL算法。</p><br /><br /><p><strong>摘要：</strong> 近年来，计算机视觉（CV）和自然语言处理（NLP）的进展主要得益于网络参数的扩展，虽然传统理论认为大规模网络容易过拟合。然而，这些大型网络通过集成简约偏差组件来指导模型趋向于简单且可泛化的解决方案。在深度强化学习（RL）领域，针对网络设计与扩展的研究相对较少。因此，我们提出了SimBa，一种通过注入简约偏差来扩展深度RL参数的架构。SimBa包含三个关键组件：（i）观察标准化层，通过运行统计量标准化输入，（ii）残差前馈块，为输入到输出提供线性路径，以及（iii）层归一化，用于控制特征幅度。通过将SimBa集成到各类深度RL算法中，包括离策略、在策略和无监督方法，样本效率得到了显著提高。此外，仅仅将SimBa架构应用于软演员评论家（SAC），即能在DMC、MyoSuite和HumanoidBench等环境中匹敌或超越当前最先进的深度RL方法，展现出SimBa在多样化强化学习算法和环境中的广泛适应性与有效性。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.09754" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 16 Oct 2024 09:31:13 GMT</pubDate>
</item>
<item>
<title>MoE LLMs在嵌入模型中的应用研究</title>
<link>https://arxiv.org/abs/2410.10814</link>
<guid>https://arxiv.org/abs/2410.10814</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">研究表明Mixture-of-Experts LLMs在嵌入任务中表现出色，无需进一步微调。</p><br /><br /><p><strong>摘要：</strong> 本文探讨了Mixture-of-Experts（MoE）大语言模型（LLMs）作为嵌入模型的潜力。尽管传统的解码器架构限制了LLMs在嵌入任务上的表现，我们的研究显示MoE中的专家路由器可以作为一种即插即用的嵌入模型，能够在多个嵌入任务上取得令人满意的效果，而无需进行进一步的微调。通过对MoE路由权重（RW）和隐藏状态（HS）的深入分析，我们发现RW在处理输入提示时更具鲁棒性，并且更侧重于高层语义。借此分析动机，我们提出了MoEE模型，该模型结合了RW和HS，这一组合在性能上优于单独使用其中任何一个。我们还探索了它们的结合方式及提示策略，发现RW和HS的相似性加权和优于它们连接后的相似性。最后，我们在Massive Text Embedding Benchmark（MTEB）的20个数据集上进行了6项嵌入任务的实验，结果表明MoEE在LLM基础的嵌入任务上实现了显著的性能提升，无需进一步微调。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.10814" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 16 Oct 2024 07:49:01 GMT</pubDate>
</item>
<item>
<title>扩散模型的高效性综述：理论与实践</title>
<link>https://arxiv.org/abs/2410.11795</link>
<guid>https://arxiv.org/abs/2410.11795</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文综述扩散模型的设计原则与高效应用，助力模型应用与研究。</p><br /><br /><p><strong>摘要：</strong> 扩散模型作为近年来备受关注的生成模型，展示了在图像合成、视频生成、分子设计、3D场景渲染及多模态生成等多种生成任务中的卓越优势。其成功归功于渐进式设计原则以及高效的架构、训练、推理和部署方法论。然而，目前尚缺乏一项综合深入的综述来总结这些原则和实践，为快速理解与应用扩散模型提供帮助。因此，本文从高效性角度出发，梳理了现有的研究和实践，重点关注架构设计、模型训练、快速推理和可靠部署的深刻原则和高效做法，旨在以读者友好的方式指导进一步理论研究、算法迁移及新场景下的模型应用。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.11795" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 16 Oct 2024 07:46:08 GMT</pubDate>
</item>
<item>
<title>LVD-2M：用于长视频生成的新型长拍视频数据集</title>
<link>https://arxiv.org/abs/2410.10816</link>
<guid>https://arxiv.org/abs/2410.10816</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文介绍了一个新数据集LVD-2M，旨在促进长视频生成模型的研究。</p><br /><br /><p><strong>摘要：</strong> 随着视频生成模型的不断发展，长视频生成的研究受到越来越多的关注。现有的视频生成模型通常依赖于短视频数据集，而获取高质量的长视频数据集则成为这一领域发展的障碍。本文提出了LVD-2M数据集，旨在推动长视频生成研究。该数据集的四个关键特性包括：每个视频至少持续10秒、无场景切割的长拍视频、丰富的动态内容和临时密集的字幕。为了实现这一目标，本文介绍了一种新颖的筛选高质量长拍视频的流程与临时密集字幕生成的分层视频标注管道。通过定义一系列定量评估视频质量的指标，如场景切割、动态程度和语义质量，成功过滤出高质量的长拍视频。在此基础上，创建了包括200万个视频的LVD-2M数据集。每个视频的时长超过10秒，且配有临时密集的字幕。进一步通过微调视频生成模型，验证了LVD-2M在长视频生成中的有效性。希望该工作能为长视频生成的未来研究作出重大贡献。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.10816" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 16 Oct 2024 06:15:43 GMT</pubDate>
</item>
<item>
<title>RoboDual：协同的通用与专业政策机器人系统</title>
<link>https://arxiv.org/abs/2410.08001</link>
<guid>https://arxiv.org/abs/2410.08001</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">RoboDual通过通用与专业政策的结合，提升了多任务处理的效率与精度。</p><br /><br /><p><strong>摘要：</strong> 随着对多功能机器人系统需求的增加，RoboDual应运而生，结合了通用策略和专业策略的优势。通用策略利用大量跨体数据实现广泛适应和高层次推理，而专业策略则针对特定领域数据进行优化，拥有更高的任务精准度和效率。然而，通用策略在推理效率和训练成本上存在不足。RoboDual通过采用基于扩散变压器的专业政策，进行多步动作预测，依赖于视觉-语言-行动（VLA）通用政策所提供的高层任务理解和离散化动作输出。在实际应用中，RoboDual较OpenVLA提高了26.7%的性能，在CALVIN任务上提高了12%。尽管只使用了5%的示范数据，RoboDual依然保持强劲表现，并在实际部署中实现了3.8倍的控制频率提升。代码将公开分享，项目页面可访问：https://opendrivelab.com/RoboDual/。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.08001" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 16 Oct 2024 04:20:04 GMT</pubDate>
</item>
<item>
<title>What Matters in Transformers? Not All Attention is Needed</title>
<link>https://arxiv.org/abs/2406.15786</link>
<guid>https://arxiv.org/abs/2406.15786</guid>
<content:encoded><![CDATA[
While scaling Transformer-based large language models (LLMs) has demonstrated promising performance across various tasks, it also introduces redundant architectures, posing efficiency challenges for real-world deployment. Despite some recognition of redundancy in LLMs, the variability of redundancy across different architectures in transformers, such as MLP and Attention layers, is under-explored. In this work, we investigate redundancy across different modules within Transformers, including Blocks, MLP, and Attention layers, using a similarity-based metric. Surprisingly, despite the critical role of attention layers in distinguishing transformers from other architectures, we found that a large portion of these layers exhibit excessively high similarity and can be pruned without degrading performance. For instance, Llama-2-70B achieved a 48.4\% speedup with only a 2.4\% performance drop by pruning half of the attention layers. Furthermore, by tracing model checkpoints throughout the training process, we observed that attention layer redundancy is inherent and consistent across training stages. Additionally, we further propose a method that jointly drops Attention and MLP layers, allowing us to more aggressively drop additional layers. For instance, when dropping 31 layers (Attention + MLP), Llama-2-13B still retains 90\% of the performance on the MMLU task. Our work provides valuable insights for future network architecture design. The code is released at: https://github.com/Shwai-He/LLM-Drop.
]]></content:encoded>
<pubDate>Wed, 16 Oct 2024 03:14:52 GMT</pubDate>
</item>
<item>
<title>动态修正解码方法（DeCo）在多模态大型语言模型中的应用</title>
<link>https://arxiv.org/abs/2410.11779</link>
<guid>https://arxiv.org/abs/2410.11779</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出了一种动态修正解码方法（DeCo），有效减少多模态大型语言模型的幻觉现象。</p><br /><br /><p><strong>摘要：</strong> 多模态大型语言模型（MLLMs）常常出现幻觉现象，但其背后的原因尚不明确。本文通过实证分析发现，尽管MLLMs在最终输出中错误生成对象，但它们能在前几层识别视觉对象。我们推测这是由于语言模型强烈的知识优先性抑制了视觉信息，从而导致幻觉现象。基于此，我们提出了一种新颖的动态修正解码方法（DeCo），该方法可以自适应地选择合适的前几层，并将知识按比例整合到最终层，以调整输出的logits。DeCo是模型无关的，可以与多种经典解码策略无缝结合，并应用于不同的MLLMs。在广泛使用的基准上，我们评估了DeCo，结果表明其能够显著降低幻觉率，相比基线表现出改善，展示了其减轻幻觉的潜力。代码可在 https://github.com/zjunlp/DeCo 获取。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.11779" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 16 Oct 2024 01:56:29 GMT</pubDate>
</item>
<item>
<title>MTU-Bench：一种多粒度的大语言模型工具使用基准</title>
<link>https://arxiv.org/abs/2410.11710</link>
<guid>https://arxiv.org/abs/2410.11710</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">MTU-Bench通过多样化场景和无需GPT或人类评估的基础指标，提升大语言模型的工具使用能力评估。</p><br /><br /><p><strong>摘要：</strong> 本文提出了一种多粒度工具使用基准，称为MTU-Bench，旨在针对大语言模型（LLMs）的工具使用能力进行评估。现有的工具使用基准存在评估场景不足和高昂的评估成本等局限性。为了克服这些问题，MTU-Bench覆盖了五种工具使用场景，包括单轮单工具、单轮多工具、多轮单工具、多轮多工具以及超出分布的任务。此外，MTU-Bench的所有评估指标均基于预测结果与真实值的比较，无需依赖GPT或人类评估。该基准数据集通过转换现有高质量数据集，模拟了真实世界的工具使用场景。我们还提出了一个指令数据集MTU-Instruct，以增强现有LLMs的工具使用能力。通过实验结果表明，MTU-Bench在评估工具使用能力方面有效，相关的代码和数据将会在GitHub上公开。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.11710" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 16 Oct 2024 01:14:22 GMT</pubDate>
</item>
<item>
<title>SecCodePLT：全面评估代码生成AI安全风险的平台</title>
<link>https://arxiv.org/abs/2410.11096</link>
<guid>https://arxiv.org/abs/2410.11096</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文介绍SecCodePLT平台，全面评估代码生成AI的安全风险，包括不安全编码和网络攻击的可行性。</p><br /><br /><p><strong>摘要：</strong> 已有研究确立了多个基准，揭示了代码生成AI（Code GenAI）的安全风险，主要集中在两个方面：模型生成不安全代码的潜力和其在网络攻击中的应用效用。虽然现有基准取得了显著进展，但仍有进一步改进的机会。目前的一些基准主要关注模型提供攻击建议的能力，而忽视了生成可执行攻击的能力。此外，大多数基准过于依赖静态评估指标，而动态指标如通过测试案例的能力可能更为准确。而专家验证的基准虽然提供了高质量数据，但多以小规模运作。为了解决这些问题，我们开发了SecCodePLT，这是一个统一且全面的评估平台，用于检测代码生成AI的风险。在不安全编码方面，我们推出了一种新数据创建方法，将专家与自动生成结合，确保数据质量的同时实现大规模生成。我们还将样本与测试案例关联，以进行代码相关的动态评估。在网络攻击有用性方面，我们设置了真实的评估环境，并构建样本以引导模型生成实际攻击，同时在该环境中应用动态指标。经过广泛实验，我们展示了SecCodePLT在安全相关性上优于现有的SOTA基准CyberSecEval，并能更好地识别SOTA模型面临的不安全编码和网络攻击有用性方面的风险。最后，我们将SecCodePLT应用于SOTA代码代理Cursor，首次识别出该高级编码代理的非平凡安全风险。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.11096" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 16 Oct 2024 01:10:40 GMT</pubDate>
</item>
<item>
<title>利用多语言大模型解决低资源语言医疗数据稀缺问题</title>
<link>https://arxiv.org/abs/2410.10626</link>
<guid>https://arxiv.org/abs/2410.10626</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">研究提出了一种新型的MoE路由方法，以提高多语言医疗模型对低资源语言的适应性。</p><br /><br /><p><strong>摘要：</strong> 在医疗领域，多语言大模型（LLMs）可以打破语言障碍，提高医疗服务的获取率，但数据稀缺问题依然突出，特别是在低资源语言中。为了解决这一挑战，本文首先构建了一个高质量的医疗数据集，并进行了质量分析。接着，我们从多语言视角探索LLMs的内部信息流，采用专家混合（MoE）模块化。技术上，我们提出了一种新型的MoE路由方法，利用语言特定的专家与跨语言路由。受电路理论的启发，我们的路由分析揭示了一种信息流机制：早期层集中跨语言信息流，而后期层则表现出语言特定的分歧。基于此，我们发展了后MoE架构，仅在后期层应用稀疏路由，同时保持其他层的密集性。实验结果表明，该方法提升了多语言模型对其他语言的泛化能力，同时保持了解释性。最后，为了高效扩展模型至50种语言，我们引入了语言家族专家的概念，借助语言学先验，能够在不增加额外参数的情况下扩展语言数量。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.10626" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 16 Oct 2024 01:01:31 GMT</pubDate>
</item>
<item>
<title>基于空间和角度高斯表示的实时高质量照明与视图合成</title>
<link>https://arxiv.org/abs/2410.11419</link>
<guid>https://arxiv.org/abs/2410.11419</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出了一种结合高斯表示和三重溅射过程的技术，实现多视角图像的实时照明与视图合成。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了一种基于空间和角度高斯表示的技术，以及一种三重溅射过程，旨在实现实时、高质量的新照明和视图合成。为了描述复杂的外观，我们为每个空间高斯引入了一种效果良好的反射函数，即兰伯特反射与角度高斯的混合模型。生成自阴影的过程是通过将所有空间高斯溅射向光源，并计算阴影值，随后利用小型多层感知网络进行精细化处理。此外，为了补偿全局照明等其他效果，我们训练了另一个网络，以计算和添加每个空间高斯对应的RGB元组。本文展示的结果在30个样本上进行了验证，样本涵盖了几何形状（从坚固到松散）和外观（从半透明到各向异性）的广泛变化，并使用了多种输入数据，包括合成/重建对象的渲染图像、手持相机拍摄的照片、以及来自专业灯台的图像。我们在单个普通GPU上的训练时间为40-70分钟，并达到了每秒90帧的渲染速度。与现有技术相比，我们的结果在质量和性能上均表现优异。代码和数据已公开。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.11419" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 16 Oct 2024 00:26:35 GMT</pubDate>
</item>
<item>
<title>探索去规范化解码器中激活函数的优化</title>
<link>https://arxiv.org/abs/2410.09637</link>
<guid>https://arxiv.org/abs/2410.09637</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本研究发现ReLU在去LayerNorm模型中超越GELU，改善学习动态和信息保留。</p><br /><br /><p><strong>摘要：</strong> 本研究探讨了在去LayerNorm的解码器中选择激活函数的问题，发现ReLU在性能上显著优于GELU。传统上，变换器模型偏爱GELU，但我们的实证研究显示ReLU在这类架构中提供了8.2%的困惑度改善。我们分析了GELU在早期层中所产生的熵过载现象，导致注意力头的表现能力未能充分利用。这表明，像GELU这样平滑的激活函数不适合去LayerNorm架构，而ReLU的几何特性则在缺乏LayerNorm的情况下改善学习动态和信息保留。这项研究为优化具有显著挑战的变换器架构提供了重要见解。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.09637" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 15 Oct 2024 20:33:34 GMT</pubDate>
</item>
<item>
<title>大语言模型中的语言结构与内部电路的对应关系研究</title>
<link>https://arxiv.org/abs/2410.09223</link>
<guid>https://arxiv.org/abs/2410.09223</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本研究探讨大语言模型如何处理不同语言的形态句法过程，发现共享电路与语言特异组件的共存。</p><br /><br /><p><strong>摘要：</strong> 本研究通过对大语言模型(LLMs)的机制解释工具，探讨其内部结构与语言的形态句法过程之间的关系。我们主要提出两个问题：第一，当两种语言使用相同的形态句法过程时，LLMs是否使用共享的内部电路处理这些过程？第二，当两种语言采用不同的形态句法过程时，LLMs是否使用不同的内部电路？针对英语和中文的多语言及单语言模型，我们分析了涉及两项任务的内部电路。研究结果表明，模型在处理相同句法过程时，无论是在何种语言中，均使用相同的电路，甚至在完全独立训练的单语言模型中也是如此。此外，我们还发现多语言模型在处理某些特有的语言过程（例如形态标记）时，会运用语言特定的组件（如注意力头和前馈网络）。这些结果为大语言模型在同时建模多种语言时，如何在利用共通结构与保留语言差异之间进行权衡提供了新的见解。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.09223" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 15 Oct 2024 14:32:40 GMT</pubDate>
</item>
<item>
<title>VisRAG：面向多模态文档的视觉-语言检索增强生成</title>
<link>https://arxiv.org/abs/2410.10594</link>
<guid>https://arxiv.org/abs/2410.10594</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出了VisRAG，一个基于视觉-语言模型的检索增强生成系统，用于多模态文档的处理。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了VisRAG，一个解决现有基于文本的检索增强生成（RAG）系统局限的新方法。传统RAG系统无法有效利用多模态文档中的视觉信息，因此我们提出了VisRAG，通过直接使用视觉-语言模型（VLM）处理文档。这一新颖的流程避免了在文本解析过程中可能引起的信息丢失，从而最大限度地保留了原始文档中的信息。我们收集了开放源代码和合成数据来训练VisRAG中的检索器，探索多种生成方法。实验结果显示，VisRAG在检索和生成两个阶段均优于传统的文本基础RAG，整体性能提升幅度达到25-39%。进一步的分析表明，VisRAG在利用训练数据方面表现出色，并展现出强大的泛化能力，成为多模态文档RAG的有前景的解决方案。我们的代码和数据已在GitHub上公开。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.10594" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 15 Oct 2024 13:58:17 GMT</pubDate>
</item>
<item>
<title>提升大型语言模型推理能力的训练方法</title>
<link>https://arxiv.org/abs/2410.10630</link>
<guid>https://arxiv.org/abs/2410.10630</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出一种新的训练方法，使大型语言模型具备推理能力，从而提高指令响应效果。</p><br /><br /><p><strong>摘要：</strong> 随着大型语言模型（LLMs）在指令跟随能力的广泛应用，如何使其具备更好的推理能力成为研究的重点。本文提出了一种新的训练方法，通过迭代搜索和优化程序，探索可能的思维生成空间，使现有模型在没有额外人类数据的情况下学习思考能力。对此，每个指令的思维候选方案使用一个判别模型进行评分，并通过偏好优化进行改进。研究显示，这种新方法在AlpacaEval和Arena-Hard等基准测试中表现优越，同时还在非推理类任务（如营销、健康和一般知识）上取得改善。该方法为大型语言模型的训练提供了新的视角，证明了思考能力在多种任务中的重要性。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.10630" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 15 Oct 2024 13:51:05 GMT</pubDate>
</item>
<item>
<title>MMCOMPOSITION：评估大规模视觉-语言模型的组合能力的新基准</title>
<link>https://arxiv.org/abs/2410.09733</link>
<guid>https://arxiv.org/abs/2410.09733</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出MMCOMPOSITION基准，以评估视觉-语言模型的组合能力，发现GPT-4o在此方面表现不佳。</p><br /><br /><p><strong>摘要：</strong> 随着大规模视觉-语言模型（VLM）的出现，跨模态理解取得了显著进步，促进了图像和视频标注、视觉问答和跨模态检索等任务的精确集成。尽管VLM具有优越的能力，研究者对其组合能力的理解仍然不够全面。现有基准仅从对象、关系和属性的粗略角度评估组合性，忽视了对对象交互、计数和复杂构图的深层次推理。然而，组合能力是促进VLM跨模态推理和理解的关键能力。为此，我们提出了MMCOMPOSITION，一个新的人类标注基准，旨在全面和准确地评估VLM的组合能力。通过MMCOMPOSITION，我们能够量化和探索主流VLM的组合能力。令人惊讶的是，实验发现GPT-4o的组合能力低于最佳开源模型，同时分析了其背后的原因。我们的实验分析揭示了VLM在细粒度组合感知和推理方面的局限性，并指出了VLM设计和训练的改进方向。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.09733" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 15 Oct 2024 12:32:30 GMT</pubDate>
</item>
<item>
<title>LiveXiv：基于科学ArXiv论文的可扩展实时基准测试</title>
<link>https://arxiv.org/abs/2410.10783</link>
<guid>https://arxiv.org/abs/2410.10783</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">LiveXiv是一个自动生成科学论文视觉问答对的基准测试，评估多模态模型的真实能力。</p><br /><br /><p><strong>摘要：</strong> LiveXiv是一个新的基准测试，旨在通过科学ArXiv论文评估多模态模型的能力。它通过实时访问领域特定的手稿，在没有人工干预的情况下，自动生成视觉问答对（VQA）。提议的方案利用手稿中的图表和数据向量，采用高效的评估方法，使用有限数量模型的结果来估计所有模型的表现，从而降低整体评估费用。该基准的首个版本对多种开放和私有的大型多模态模型（LMMs）进行了基准测试，展现了独特的挑战性并揭示了模型的真实能力，避免了测试数据污染。为了保证高质量，研究团队还收集并评估了经过人工验证的子集，与自动注释的结果进行对比，发现性能差异小于2.5%。该数据集已在HuggingFace上公开，并且代码也将提供。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.10783" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 15 Oct 2024 04:40:56 GMT</pubDate>
</item>
<item>
<title>问题树（ToP）：解决复杂推理任务的新方法</title>
<link>https://arxiv.org/abs/2410.06634</link>
<guid>https://arxiv.org/abs/2410.06634</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本研究提出问题树（ToP），在复杂任务中表现优于现有方法。</p><br /><br /><p><strong>摘要：</strong> 本研究提出一种新方法——问题树（Tree of Problems，ToP），旨在处理可分解为相同子任务的复杂问题。尽管大语言模型（LLMs）在许多任务中表现卓越，尤其是在上下文学习方面，链式思考（Chain-of-Thought，CoT）提示在复杂推理中也取得了良好结果，但仍存在一些挑战。为了解决这些困难，树状思维（Tree of Thoughts，ToT）和图形思维（Graph of Thoughts，GoT）提出了将复杂问题划分为子问题的思路。我们假设，问题树作为ToT的简化版本，能够更有效地处理可以划分为相同子任务的复杂任务。我们的实证结果显示，ToP在多个复杂推理任务上超越了ToT和GoT的表现，同时也优于CoT。研究所用的所有代码已公开，方便其他研究者使用和验证。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.06634" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 15 Oct 2024 04:34:39 GMT</pubDate>
</item>
<item>
<title>基于动态最优控制的矩形流模型图像反演与编辑</title>
<link>https://arxiv.org/abs/2410.10792</link>
<guid>https://arxiv.org/abs/2410.10792</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出了一种新方法，通过动态最优控制进行矩形流模型的图像反演和编辑。</p><br /><br /><p><strong>摘要：</strong> 本文针对生成模型中的两个关键任务：图像反演与编辑，提出了一种基于矩形流（Rectified Flows, RFs）的框架。尽管扩散模型在图像生成领域取得了显著成功，但其反演过程中由于漂移和扩散的非线性特性导致了忠实性和可编辑性问题。现有的扩散模型反演方法往往需要额外参数的训练或测试时对潜变量的优化，这在实际操作中成本高昂。矩形流提供了一种有前景的替代方案，但其反演方法尚未得到充分研究。我们提出的一种RF反演方法，基于动态最优控制，通过线性二次调节器导出。我们证明了所得到的向量场等价于一个矩形的随机微分方程。此外，我们将该框架扩展为Flux的随机采样器。我们的反演方法在零-shot反演和编辑任务中表现出色，在笔触到图像合成和语义图像编辑方面优于现有方法，且大规模人类评估结果验证了其用户偏好的有效性。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.10792" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 15 Oct 2024 03:10:41 GMT</pubDate>
</item>
<item>
<title>长时记忆评估框架：提升聊天助手的记忆能力</title>
<link>https://arxiv.org/abs/2410.10813</link>
<guid>https://arxiv.org/abs/2410.10813</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出LongMemEval基准，评估聊天助手的长时记忆能力，探索优化设计以提升记忆召回与问答表现。</p><br /><br /><p><strong>摘要：</strong> 近期的大型语言模型（LLM）驱动的聊天助手系统已集成内存组件，以跟踪用户与助手之间的对话历史，从而实现更准确和个性化的响应。然而，它们在持续交互中的长期记忆能力仍未得到充分探索。本文介绍了LongMemEval，这是一个综合性基准，旨在评估聊天助手五种核心的长期记忆能力：信息提取、多会话推理、时间推理、知识更新和弃权。LongMemEval包含500个精心策划的问题，嵌入可自由扩展的用户-助手对话历史中，给现有的长期记忆系统带来了重大挑战。实验结果显示，商业聊天助手和长上下文LLM在持续交互中的信息记忆准确率下降了30%。我们提出一个统一框架，将长期记忆设计分解为四个设计选择，涵盖索引、检索和读写阶段。基于关键实验洞察，提出几种内存设计方案，包括会话分解以优化值粒度、事实增强键扩展以增强索引结构，以及时间感知查询扩展以改进搜索范围。实验结果表明，这些优化显著提高了在LongMemEval上的记忆召回率和后续问答表现。总体而言，本研究为推动基于LLM的聊天助手长期记忆能力提供了宝贵的资源和指导。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.10813" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 15 Oct 2024 03:01:29 GMT</pubDate>
</item>
<item>
<title>TemporalBench：评估视频中的细粒度时间理解的新基准</title>
<link>https://arxiv.org/abs/2410.10818</link>
<guid>https://arxiv.org/abs/2410.10818</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文介绍了TemporalBench，一个新的基准，用于评估视频的细粒度时间理解能力。</p><br /><br /><p><strong>摘要：</strong> 理解细粒度时间动态对于多模态视频的理解和生成至关重要。由于缺乏细粒度时间标注，现有视频基准多类似静态图像基准，无法有效评估模型的时间理解能力。为此，本文介绍了TemporalBench，一个专为评估视频的细粒度时间理解而设计的新基准。TemporalBench包含约10,000对视频问答对，源于约2,000个高质量的人类标注，这些标注详细描述了视频片段中的时间动态。该基准提供了一个独特的测试平台，以评估各种时间理解和推理能力，如动作频率、运动幅度、事件顺序等，支持视频问答、视频字幕生成、短视频和长视频理解等多项任务，以及多种模型，如多模态视频嵌入模型和文本生成模型。结果显示，诸如GPT-4o等最先进模型在TemporalBench上的问答准确率仅为38.5%，表明人类与AI在时间理解上存在显著差距（约30%）。此外，我们注意到多选QA的一个关键缺陷，即大型语言模型（LLMs）能够检测负面描述中的微妙变化，并将中心化描述作为预测线索，因此我们提出了多个二元准确度（MBA）来纠正这种偏差。我们希望TemporalBench能够促进研究，提高模型的时间推理能力。数据集和评估代码将公开发布。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.10818" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 15 Oct 2024 02:16:22 GMT</pubDate>
</item>
<item>
<title>自主操作的改进型3D扩散政策（iDP3）在多样化环境下的应用</title>
<link>https://arxiv.org/abs/2410.10803</link>
<guid>https://arxiv.org/abs/2410.10803</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文介绍了一种改进型3D扩散政策（iDP3），使人形机器人在多样环境中自主执行技能。</p><br /><br /><p><strong>摘要：</strong> 自主操作的人形机器人一直是机器人研究者追求的目标。然而，由于获取可泛化技能的难度，自主操作的人形机器人往往只能在特定的场景中进行有效操作。近年来，3D视动政策（如3D Diffusion Policy, DP3）的进展为拓展这些能力到多样化环境提供了希望。然而，3D视动政策通常依赖于相机标定和点云分割，这对移动机器人（如人形机器人）的应用造成了挑战。为了解决这些问题，本文提出了一种新的3D视动政策——改进型3D扩散政策（iDP3），它利用自我中心的3D视觉表示，消除了上述限制。我们展示了iDP3能够使全尺寸人形机器人在多样的真实场景中自主执行技能，并使用仅在实验室收集的数据进行训练。相关视频可以在: https://humanoid-manipulation.github.io 获取。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.10803" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 15 Oct 2024 02:14:57 GMT</pubDate>
</item>
<item>
<title>Cavia：一种可控相机的多视角视频生成框架</title>
<link>https://arxiv.org/abs/2410.10774</link>
<guid>https://arxiv.org/abs/2410.10774</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">Cavia框架实现了从输入图像生成多个时空一致的视频，支持精确控制相机运动与物体运动。</p><br /><br /><p><strong>摘要：</strong> 近年来，图像到视频生成领域取得了显著突破，但生成帧在3D一致性和相机可控性方面仍存在未解决的问题。尽管有研究尝试将相机控制融入生成过程中，但结果往往仅限于简单轨迹，或缺乏对同一场景的多条独特相机路径生成一致视频的能力。为了解决这些限制，我们提出了Cavia，这是一种新颖的相机可控、多视角视频生成框架，能够将输入图像转换为多个时空一致的视频。我们的框架将空间和时间注意力模块扩展为视角集成注意力模块，从而提高视角和时间一致性。这种灵活的设计允许与多种策划数据源进行联合训练，包括场景级静态视频、对象级合成多视角动态视频以及现实世界单目动态视频。到目前为止，Cavia是首个允许用户精确指定相机运动的同时获得物体运动的系统。大量实验表明，Cavia在几何一致性和感知质量上优于最先进的方法。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.10774" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 15 Oct 2024 01:58:29 GMT</pubDate>
</item>
<item>
<title>Animate-X：针对各种角色类型的通用动画框架</title>
<link>https://arxiv.org/abs/2410.10306</link>
<guid>https://arxiv.org/abs/2410.10306</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出了Animate-X通用动画框架，以提高对人形和拟人角色的动画效果。</p><br /><br /><p><strong>摘要：</strong> 随着过去几年动画技术的进步，通过参考图像和目标姿势序列生成高质量视频的角色图像动画取得了显著进展。然而，现有大部分方法仅适用于人类形象，难以在游戏和娱乐行业使用的拟人角色上进行有效泛化。深入分析认为，这一局限性源于对运动建模的不足，导致无法理解驱动视频的动作模式，从而将姿势序列僵硬地施加于目标角色。为此，本文提出了Animate-X，一个基于LDM的通用动画框架，能够处理各种角色类型（统称为X），包括拟人角色。为增强运动表现，我们引入了Pose Indicator，旨在通过隐式与显式方式捕捉驱动视频的综合运动模式。隐式方式利用CLIP视觉特征提取运动的整体模式和动作间的时间关系，而显式方式则通过预先模拟推理过程中可能出现的输入来增强LDM的泛化能力。此外，我们还提出了一个新的动画拟人基准（A^2Bench）来评估Animate-X在通用动画图像上的性能。广泛实验结果验证了Animate-X相对于现有最先进方法的优越性和有效性。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.10306" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 15 Oct 2024 01:34:40 GMT</pubDate>
</item>
<item>
<title>MEGA-Bench：一种大规模多模态评估套件</title>
<link>https://arxiv.org/abs/2410.10563</link>
<guid>https://arxiv.org/abs/2410.10563</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">MEGA-Bench 是一项涵盖 505 个现实任务的多模态评估套件， 提供多样化的输出格式和细致的模型评估。</p><br /><br /><p><strong>摘要：</strong> MEGA-Bench 是一个新建立的评估套件，旨在将多模态评估扩展到超过 500 个现实世界任务，以应对用户日常使用中的高度异质性需求。我们的目标是优化高质量数据样本的收集，涵盖多样且丰富的多模态任务，同时实现成本有效且准确的模型评估。我们从 16 位专家注释员处收集了 505 个现实任务，共计超过 8000 个样本，以广泛覆盖多模态任务空间。不同于 MMMU、MMBench 和 MMT-Bench 通过标准多项选择题统一这些问题，MEGA-Bench 接纳了多种输出格式，包括数字、短语、代码、LaTeX、坐标、JSON 和自由格式等。为适应这些格式，我们开发了超过 40 种指标来评估这些任务。MEGA-Bench 还提供跨多个维度（如应用、输入类型、输出格式和技能）进行细致的能力报告，使用户能够深入交互和可视化模型能力。我们在 MEGA-Bench 上评估了多种前沿的视觉语言模型，以了解它们在这些维度上的能力。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.10563" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 15 Oct 2024 01:21:36 GMT</pubDate>
</item>
<item>
<title>TVBench: Redesigning Video-Language Evaluation</title>
<link>https://arxiv.org/abs/2410.07752</link>
<guid>https://arxiv.org/abs/2410.07752</guid>
<content:encoded><![CDATA[
Large language models have demonstrated impressive performance when integrated with vision models even enabling video understanding. However, evaluating these video models presents its own unique challenges, for which several benchmarks have been proposed. In this paper, we show that the currently most used video-language benchmarks can be solved without requiring much temporal reasoning. We identified three main issues in existing datasets: (i) static information from single frames is often sufficient to solve the tasks (ii) the text of the questions and candidate answers is overly informative, allowing models to answer correctly without relying on any visual input (iii) world knowledge alone can answer many of the questions, making the benchmarks a test of knowledge replication rather than visual reasoning. In addition, we found that open-ended question-answering benchmarks for video understanding suffer from similar issues while the automatic evaluation process with LLMs is unreliable, making it an unsuitable alternative. As a solution, we propose TVBench, a novel open-source video multiple-choice question-answering benchmark, and demonstrate through extensive evaluations that it requires a high level of temporal understanding. Surprisingly, we find that most recent state-of-the-art video-language models perform similarly to random performance on TVBench, with only Gemini-Pro and Tarsier clearly surpassing this baseline.
]]></content:encoded>
<pubDate>Tue, 15 Oct 2024 01:06:10 GMT</pubDate>
</item>
<item>
<title>大规模数据选择在监督微调中的关键性研究</title>
<link>https://arxiv.org/abs/2410.09335</link>
<guid>https://arxiv.org/abs/2410.09335</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文探讨了大量数据选择在监督微调中的重要性，强调多样性优于单纯的高质量数据。</p><br /><br /><p><strong>摘要：</strong> 本研究分析了在大规模数据集中进行监督微调（SFT）时，如何选择代表性的训练数据以提高模型性能。我们在200万样本的数据集中复现了多种自评分方法，发现这些方法普遍无法显著优于随机选择。特别是在 SFT 过程中，数据选择的多样性显得尤为重要，而不仅仅是关注数据的高质量。此外，我们还探讨了当前方法的局限性，解释了它们在大规模数据集中的低效表现。经过分析，我们发现通过令牌长度对数据进行过滤是一种稳定且高效的改进方法，尤其对相对较弱的基础模型（如 Llama3）来说，训练长文本数据时表现出显著的优势。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.09335" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 15 Oct 2024 00:50:02 GMT</pubDate>
</item>
<item>
<title>LOKI: 评估大型多模态模型Synthetic Data检测能力的新基准</title>
<link>https://arxiv.org/abs/2410.09732</link>
<guid>https://arxiv.org/abs/2410.09732</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">LOKI是一个新颖的基准，评估大型多模态模型在合成数据检测中的能力和局限性。</p><br /><br /><p><strong>摘要：</strong> 随着AI生成内容的快速发展，互联网将面临大量合成数据的挑战，真实与合成内容的区分变得愈发困难。因此，合成数据检测受到了广泛关注，尤其是大型多模态模型（LMMs）在此任务中的表现引起了极大的兴趣。LMMs能够为其真实性判断提供自然语言解释，从而增强合成内容检测的可解释性。为此，我们提出了LOKI这一新基准，旨在评估LMMs在多种模态中检测合成数据的能力。LOKI涵盖视频、图像、3D、文本和音频等多种模态，包含18K个细致策划的问题，涵盖26个子类别并设有明确的难度等级。该基准不仅包括粗粒度判断和多项选择题，还包含细粒度的异常选择与解释任务，从而对LMMs进行全面分析。我们在LOKI上对22个开源LMM和6个闭源模型进行了评估，突显了它们作为合成数据检测器的潜力，同时也揭示了LMM能力开发中的一些局限性。更多信息请访问 https://opendatalab.github.io/LOKI/ 。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.09732" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 15 Oct 2024 00:49:53 GMT</pubDate>
</item>
<item>
<title>VIF-RAG：提高检索增强生成系统指令跟随对齐的自动化框架</title>
<link>https://arxiv.org/abs/2410.09584</link>
<guid>https://arxiv.org/abs/2410.09584</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">VIF-RAG 提出了一个用于提升 RAG 系统指令跟随对齐的新方法，包含自动化、可扩展的合成管道和 FollowRAG 基准。</p><br /><br /><p><strong>摘要：</strong> 随着大规模语言模型（LLMs）的发展，检索增强生成（RAG）系统在多种应用中表现出色，但指令跟随（IF）对齐的研究尚不充分。为了解决这个问题，我们提出了 VIF-RAG，这是首个自动化、可扩展且可验证的合成管道，旨在提升 RAG 系统中的指令跟随对齐。该方法首先手动构建一组较小的原子指令，并发展组合规则以合成和验证复杂指令。随后，我们利用监督模型进行指令重写，同时生成代码以自动化验证指令质量。最后，我们整合指令和大量 RAG 数据样本，自动化生成超过 10 万条高质量的 VIF-RAG-QA 数据集。此外，为了填补 RAG 系统指令跟随自动评估的空白，我们推出了 FollowRAG 基准，包括约 3000 个测试样本，涵盖 22 类一般指令约束和四个知识密集型 QA 数据集。我们展示了 VIF-RAG 在多个通用指令约束下显著提升 LLM 性能，并就实现 RAG 系统中的 IF 对齐提供了实用见解。我们的代码和数据集已公开发布。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.09584" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 15 Oct 2024 00:40:06 GMT</pubDate>
</item>
<item>
<title>MMIE：评估大型视觉语言模型的交错多模态理解与生成的基准</title>
<link>https://arxiv.org/abs/2410.10139</link>
<guid>https://arxiv.org/abs/2410.10139</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文介绍了MMIE，一个大型知识密集型基准，用于评估大型视觉语言模型的交错多模态理解与生成能力。</p><br /><br /><p><strong>摘要：</strong> 在交错多模态理解与生成（Interleaved Multimodal Comprehension and Generation）的研究领域，尽管已有显著进展，但评估这一能力仍显不足。现有基准在数据规模、范围和评估深度上存在局限，评估指标往往成本高、偏见明显，缺乏实用性的可靠性。为了解决这些挑战，我们提出MMIE，这是一套大型知识密集型基准，旨在评估大型视觉语言模型（LVLMs）在交错多模态理解与生成方面的能力。MMIE包含20K精心策划的多模态查询，涵盖3个类别、12个领域和102个子领域，包括数学、编程、物理、文学、健康和艺术等。它支持交错的输入与输出，提供多项选择和开放式问题格式，以评估不同的能力。此外，我们提出了一种可靠的自动评估指标，利用经过人类标注数据和系统评估标准微调的评分模型，旨在减少偏见，提高评估准确性。大量实验展示了我们的基准和指标在全面评估交错LVLMs方面的有效性。具体而言，我们评估了八个LVLMs，结果表明，甚至是最好的模型也还有显著改进的空间，多数仅取得中等结果。我们相信MMIE将推动交错LVLMs的发展。我们将公开发布我们的基准和代码，网址为https://mmie-bench.github.io/。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.10139" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 15 Oct 2024 00:30:53 GMT</pubDate>
</item>
<item>
<title>针对大型语言模型的数学推理能力的奥林匹亚级基准测试</title>
<link>https://arxiv.org/abs/2410.07985</link>
<guid>https://arxiv.org/abs/2410.07985</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出了一个专门评估大型语言模型奥林匹亚级数学推理能力的基准，包含4428个高难度数学问题。</p><br /><br /><p><strong>摘要：</strong> 随着大型语言模型（LLMs）在数学推理能力方面取得显著突破，现有基准如GSM8K和MATH在模型解决这些问题时精确度已达到94.8%，这表明这些基准已无法有效挑战模型。为此，我们提出了一个全面且复杂的基准，专门设计用于评估LLMs在奥林匹亚级数学推理方面的能力。与现有的奥林匹亚相关基准不同，我们的数据集专注于数学，包含4428个经过严格人类标注的竞赛级问题。这些问题被细致地分类为33个子领域，并跨越10个不同的难度等级，使得我们能够全面评估模型在奥林匹亚数学推理表现方面的能力。此外，我们还基于这一基准进行了深入分析。实验结果显示，即使是最先进的模型，如OpenAI o1-mini和OpenAI o1-preview，在处理高度挑战性的奥林匹亚级问题时仍面临显著困难，其准确率分别为60.54%和52.55%。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.07985" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 15 Oct 2024 00:06:51 GMT</pubDate>
</item>
<item>
<title>基于计划去噪的离散扩散框架DDPD</title>
<link>https://arxiv.org/abs/2410.06264</link>
<guid>https://arxiv.org/abs/2410.06264</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出了DDPD框架，通过规划与去噪结合，实现了更高效的生成过程。</p><br /><br /><p><strong>摘要：</strong> 离散扩散方法在标准基准上取得了最佳性能，接近或超越了自回归模型。本文介绍了一种新颖的离散扩散框架——计划去噪的离散扩散（DDPD），它将生成过程分为两个模型：规划者和去噪器。在推理时，规划者通过识别最需要去噪的位置（包括初始损坏位置和需要进一步细化的位置）来选择下一个去噪位置。这种计划与去噪的方法使得在生成过程中能够更高效地重建，通过迭代识别和以最佳顺序去噪来处理损坏。DDPD在语言建模基准上表现优于传统的仅有去噪器的掩蔽扩散方法，在text8、OpenWebText和ImageNet 256x256的基于令牌的生成任务中取得了优越结果。值得注意的是，在语言建模中，DDPD显著缩小了扩散和自回归方法在生成困惑度上的性能差距。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.06264" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 20:35:31 GMT</pubDate>
</item>
<item>
<title>Synth-SONAR：基于扩散模型与GPT提示的声纳图像合成框架</title>
<link>https://arxiv.org/abs/2410.08612</link>
<guid>https://arxiv.org/abs/2410.08612</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本研究提出Synth-SONAR框架，利用扩散模型和GPT提示生成高质量声纳图像，提升数据多样性和现实感。</p><br /><br /><p><strong>摘要：</strong> 声纳图像合成对水下探索、海洋生物学和国防等应用至关重要。然而，传统方法往往依赖昂贵且大量的数据采集，影响数据质量和多样性。为了解决这些问题，本研究提出了一种新的声纳图像合成框架，Synth-SONAR，结合了扩散模型和GPT提示。Synth-SONAR的创新点主要体现在三个方面：首先，利用基于生成的AI风格注入技术和公开可用的真实/模拟数据，生成最大规模的声纳数据集。其次，构建了一个双重文本条件的声纳扩散模型层次，可以合成高质量和多样性的粗略与精细声纳图像。第三，采用高级（粗略）和低级（详细）文本基础的声纳生成方法，有效利用视觉语言模型（VLMs）和GPT提示中的高级语义信息。在推理过程中，该方法从文本提示中生成多样化且真实的声纳图像，首次将GPT提示应用于声纳图像合成。Synth-SONAR在生产高质量合成声纳数据集方面实现了最新的领先成绩，显著提升了数据的多样性和真实感。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.08612" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 18:14:02 GMT</pubDate>
</item>
<item>
<title>GenARM：一种有效的自回归奖励模型用于无重训练的大型语言模型对齐</title>
<link>https://arxiv.org/abs/2410.08193</link>
<guid>https://arxiv.org/abs/2410.08193</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">GenARM通过自回归奖励模型实现有效的无训练对齐，支持多目标和弱到强的指导。</p><br /><br /><p><strong>摘要：</strong> 大型语言模型（LLMs）展现了令人印象深刻的能力，但需要与人类偏好进行谨慎对齐。传统的训练时方法使用人类偏好数据集对LLMs进行微调，成本高昂且难以处理多样化用户偏好。而测试时对齐方法则通过奖励模型（RMs）指导冻结的LLMs，避免了重新培训的需求。目前的测试时方法依赖于轨迹级奖励模型，旨在评估完整响应，这在需要从部分响应计算下一个标记奖励的自回归文本生成中显得不够合适。为此，我们提出了GenARM，这一测试时对齐方法利用自回归奖励模型——一种新型的奖励参数化设计，能够预测下一个标记的奖励，从而促进高效且有效的自回归生成。我们从理论上证明，这种参数化可以在KL正则化的强化学习框架内可证明地引导冻结LLMs朝向由传统RMs能够实现的任何分布。实验结果表明，GenARM显著优于现有的测试时对齐基准，并且与训练时方法的性能相匹配。此外，GenARM支持高效的弱到强指导，使得较大的LLMs能够与较小的RMs进行对齐，而无需承担训练大模型的高成本。同时，GenARM还支持多目标对齐，实时调整偏好维度之间的权衡，满足多样化用户偏好的需求。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.08193" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 17:04:55 GMT</pubDate>
</item>
<item>
<title>利用简单分层方法提高大型语言模型生成的多样性</title>
<link>https://arxiv.org/abs/2410.09038</link>
<guid>https://arxiv.org/abs/2410.09038</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出SimpleStrat方法，利用语言模型对输出进行分层，从而提高生成内容的多样性和质量。</p><br /><br /><p><strong>摘要：</strong> 在生成多样化响应方面，大型语言模型（LLMs）扮演着重要角色，尤其在规划搜索和合成数据生成等应用中。传统方法依赖于提高温度来增强多样性，然而，研究表明这不仅导致个体生成质量下降，而且其效果依赖于模型预测概率与真实答案分布的相似性。为了克服这一问题，本文提出了一种新的方法——SimpleStrat，通过语言模型自身对生成空间进行分层，在推理时随机选择一个层级并从中抽取样本。此外，为了衡量生成结果的多样性，本文引入了CoverageQA数据集，该数据集由多个同样合理的答案组成的模糊问题构成，利用Kullback-Leibler散度（KL散度）来评估输出分布与有效答案的均匀分布之间的差异。在对比评估中，使用SimpleStrat方法在召回率方面比GPT-4o提高了0.05，而相较于Llama 3则在KL散度上减少了0.36，展现了该方法在提高生成多样性和质量上的有效性。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.09038" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 16:35:17 GMT</pubDate>
</item>
<item>
<title>MiRAGeNews数据集：对抗AI生成假新闻的多模态检测</title>
<link>https://arxiv.org/abs/2410.09045</link>
<guid>https://arxiv.org/abs/2410.09045</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本研究推出MiRAGeNews数据集，旨在检测AI生成的假新闻，提高内容真实性。使用此数据集训练的多模态检测器效果显著。</p><br /><br /><p><strong>摘要：</strong> 随着虚假新闻内容的泛滥和AI生成图像技术的迅速发展，AI生成的假新闻内容变得更加危险。为此，我们提出了MiRAGeNews数据集，该数据集包含12,500对高质量的真实和AI生成的图像-标题配对，使用了最先进的生成模型。我们的研究表明，这一数据集对人类的检测能力构成了显著挑战（F-1为60%），同时对当前最先进的多模态大语言模型的检测性能也很低（F-1小于24%）。基于该数据集，我们训练了一种多模态检测器（MiRAGe），在来自域外图像生成器和新闻发布者的图像-标题配对任务上，F-1提高了5.1%，超越了现有的基线方法。我们将代码和数据公开发布，以助力后续对AI生成内容的检测研究。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.09045" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 13:41:24 GMT</pubDate>
</item>
<item>
<title>I-Max框架：提升文本到图像RFTs的分辨率潜力</title>
<link>https://arxiv.org/abs/2410.07536</link>
<guid>https://arxiv.org/abs/2410.07536</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文介绍I-Max框架，利用新的Projected Flow策略和推理工具，提升RFTs在分辨率扩展中的稳定性和图像细节质量。</p><br /><br /><p><strong>摘要：</strong> 本文探讨了Rectified Flow Transformers（RFTs）在扩展生成分辨率方面的挑战，尤其是数据质量和训练成本的问题。针对现有的无调优分辨率外推方法，往往在生成稳定性方面存在不足，我们提出了I-Max框架。I-Max框架包括两大特性：首先是最新的Projected Flow策略，旨在实现更稳定的分辨率外推；其次是一个先进的推理工具包，可帮助模型知识向更高分辨率的泛化。通过在Lumina-Next-2K和Flux.1-dev数据集上的实验，结果表明I-Max能够有效提升分辨率外推的稳定性，并带来图像细节的增强和伪影的修正，证实了无调优分辨率外推的实际应用价值。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.07536" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 12:22:47 GMT</pubDate>
</item>
<item>
<title>ZeroComp：一种有效的零样本3D物体合成方法</title>
<link>https://arxiv.org/abs/2410.08168</link>
<guid>https://arxiv.org/abs/2410.08168</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">ZeroComp通过使用ControlNet和Stable Diffusion实现无配对图像的3D物体合成。</p><br /><br /><p><strong>摘要：</strong> 本文提出了一种名为ZeroComp的有效零样本3D物体合成方法，该方法在训练过程中不需要配对的复合场景图像。ZeroComp利用ControlNet对内在图像进行条件处理，并结合Stable Diffusion模型以利用其场景先验，这两者共同运作为一个高效的渲染引擎。在训练阶段，ZeroComp使用基于几何、反射率和遮蔽的内在图像，完全不依赖于含有复合物体的场景的图像配对。训练完成后，ZeroComp能够无缝地将虚拟3D物体集成到场景中，并调整光照，使复合效果更加真实。为了验证ZeroComp的效果，我们开发了一个高质量评估数据集，结果显示其在定量和人类感知基准测试中均优于依赖显式照明估计和生成技术的方法。此外，ZeroComp在真实和户外图像合成上也展现出潜力，即使其训练数据仅限于合成的室内数据，依然能够有效实现图像合成。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.08168" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 11:29:03 GMT</pubDate>
</item>
<item>
<title>Mentor-KD：多步推理能力的知识蒸馏方法</title>
<link>https://arxiv.org/abs/2410.09037</link>
<guid>https://arxiv.org/abs/2410.09037</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出Mentor-KD方法，通过中介模型增强CoT标注与软标签提供，以有效蒸馏LLMs的推理能力。 </p><br /><br /><p><strong>摘要：</strong> 随着大语言模型（LLMs）在复杂任务中表现出的卓越性能，Chain-of-Thought（CoT）提示法已成为主要研究方向。近年来，有研究提出了一种推理蒸馏（Reasoning Distillation）的方法，通过对LLM教师生成的多步推理进行微调，以转移其推理能力。然而，现有方法在蒸馏集中存在两大挑战：1）数据质量不足，2）软标签提供不充分。为了解决这些问题，本文提出了Mentor-KD方法，旨在有效蒸馏LLMs的多步推理能力至小型语言模型。具体而言，我们利用一个中介模型，进行特定任务的微调，以增强CoT注释的数量和质量，并在推理蒸馏过程中为学生模型提供软标签。通过广泛的实验，我们验证了Mentor-KD在各种模型和复杂推理任务中的有效性，显示出该方法在提升推理能力方面的潜力。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.09037" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 09:26:42 GMT</pubDate>
</item>
<item>
<title>SAE Match：基于稀疏自编码器的神经网络层间特征对齐</title>
<link>https://arxiv.org/abs/2410.07656</link>
<guid>https://arxiv.org/abs/2410.07656</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出SAE Match，通过折叠参数最小化均方误差，实现神经网络层间特征的有效对齐。</p><br /><br /><p><strong>摘要：</strong> 理解深度神经网络中特征在不同层之间的演变是机械可解释性中的一个基本挑战，尤其是由于多义性和特征叠加使得这一过程更加复杂。尽管稀疏自编码器（SAEs）已被用来从单个层中提取可解释特征，但不同层之间的特征对齐仍然是一个开放的问题。在本文中，我们提出了一种新颖的数据无关的方法SAE Match，用于对齐神经网络不同层的SAE特征。我们的方法通过最小化SAEs的折叠参数之间的均方误差来匹配特征，这一技术在编码器和解码器权重中引入激活阈值，以解决特征尺度差异的问题。通过对Gemma 2语言模型的广泛实验，我们证明了我们的方法能够有效捕捉特征在不同层间的演变，从而提高特征匹配质量。我们还展示了特征在多个层中持续存在，并且我们的方法能够近似不同层之间的隐藏状态。我们的工作推动了对神经网络中特征动态的理解，并为机械可解释性研究提供了一种新的工具。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.07656" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 08:07:48 GMT</pubDate>
</item>
<item>
<title>DA-Code：针对代理的数据科学任务的代码生成基准</title>
<link>https://arxiv.org/abs/2410.07331</link>
<guid>https://arxiv.org/abs/2410.07331</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">DA-Code是一个评估LLMs在数据科学任务上的代码生成能力的基准，涵盖复杂数据处理的实际任务。</p><br /><br /><p><strong>摘要：</strong> 我们介绍了DA-Code，一个专门设计用来评估LLMs在代理数据科学任务中的代码生成能力的基准。DA-Code的设计包含三个核心要素。首先，任务具有内在挑战性，要求高级编码技能，特别是在上下文处理和计划方面。其次，DA-Code中的所有示例均基于真实且多样的数据，涵盖各种复杂的数据整理和分析任务。最后，为了完成这些任务，模型必须使用复杂的数据科学编程语言，以进行精细化的数据处理并得出结论。我们在一个可控和可执行的环境中搭建了这个基准，确保它与现实世界的数据分析场景相一致，并具备可扩展性。评估套件经过注释者的精心设计，以确保评估的准确性和稳健性。我们开发了DA-Agent基准线并进行了实验，结果表明，尽管基线在现有框架中表现更好，但当前最佳的LLMs准确率仅为30.5%，仍大有提升空间。我们将在https://da-code-bench.github.io发布我们的基准。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.07331" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 07:27:37 GMT</pubDate>
</item>
<item>
<title>多智能体协作数据选择机制在大型语言模型预训练中的应用</title>
<link>https://arxiv.org/abs/2410.08102</link>
<guid>https://arxiv.org/abs/2410.08102</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">提出一种多智能体协作框架，以提高大型语言模型预训练的数据效率。</p><br /><br /><p><strong>摘要：</strong> 大型语言模型（LLMs）预训练的有效数据选择至关重要。虽然已有多种方法致力于提升数据效率，但很少有研究关注这些方法之间的固有冲突，以实现最优数据选择。为了解决这一问题，我们提出了一种新颖的多智能体协作数据选择机制。在该框架中，每种数据选择方法作为独立代理工作，设计了一个代理控制台，以动态整合所有代理在整个LLM训练过程中的信息。我们通过广泛的实证研究评估了我们的多智能体框架。实验结果表明，我们的方法显著提高了数据效率，加速了LLM训练的收敛，并在多个语言模型基准上实现了平均10.5%的性能提升，相比于最先进的方法。有了这样的机制，数据选择的冲突问题得以更好地解决，进一步推动了大型语言模型的研究和应用。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.08102" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 04:56:36 GMT</pubDate>
</item>
<item>
<title>StructRAG：基于结构化知识增强大语言模型的推理能力</title>
<link>https://arxiv.org/abs/2410.08815</link>
<guid>https://arxiv.org/abs/2410.08815</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本研究提出StructRAG框架，通过结构化知识增强LLMs在知识密集任务中的推理能力。</p><br /><br /><p><strong>摘要：</strong> Retrieval-augmented generation (RAG) 是一种增强大型语言模型 (LLMs) 在知识密集任务中表现的关键方法，但现有RAG方法在处理知识密集推理任务时面临挑战。这是因为相关信息往往散布不均，使得现有方法难以准确识别关键信息并进行全局推理。为了解决这个问题，本文提出了一种新框架StructRAG，它基于人类在处理知识密集推理任务时将原始信息转换为多种结构化知识的认知理论，能够识别适合特定任务的最佳结构类型，将原始文档重构为该结构格式，并基于结果结构推理出答案。在各种知识密集任务上的广泛实验表明，StructRAG在复杂情境中表现出色，达到了最先进的性能，展示了其在复杂现实世界应用中增强LLMs作为有效解决方案的潜力。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.08815" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 04:14:19 GMT</pubDate>
</item>
<item>
<title>通过KV预测减少变换器模型的首次输出时间</title>
<link>https://arxiv.org/abs/2410.08391</link>
<guid>https://arxiv.org/abs/2410.08391</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">我们提出KV预测方法，通过辅助模型生成KV缓存，提高变换器模型的推理效率。</p><br /><br /><p><strong>摘要：</strong> 推理过程中的prompt处理步骤通常会消耗大量时间，尤其是在边缘设备上使用亿级参数模型时。为了解决首次输出时间（TTFT）过长的问题，我们提出了一种名为KV预测的新方法。通过使用一个小型辅助模型处理prompt，生成近似的KV缓存，从而减少基模型在自回归生成时对计算资源的需求。该方法在维持相对准确性的同时显著提高了效率，相比基线方法，KV预测在TriviaQA上准确度提升了15%-50%，在HumanEval的Python代码补全任务中提升了最多30%。此外，我们在Apple M2 Pro CPU上进行了基准测试，验证了FLOPs的改善直接转化为TTFT的速度提升。本研究展示了在多种TTFT计算预算下的有效性，为变换器模型的应用提供了新的可能。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.08391" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 02:41:21 GMT</pubDate>
</item>
<item>
<title>VITask：提升大型视觉语言模型任务适应性的框架</title>
<link>https://arxiv.org/abs/2410.06456</link>
<guid>https://arxiv.org/abs/2410.06456</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">VITask通过集成任务特定模型，提升视觉语言模型的任务适应能力，展示在医学诊断中的有效性。</p><br /><br /><p><strong>摘要：</strong> 该研究提出了一种名为VITask的创新框架，旨在提升大型视觉语言模型（VLMs）在特定任务中的适应能力。由于预训练与微调之间的领域差异，传统VLMs在任务特定应用中往往表现不佳。VITask通过引入任务特定模型（TSMs）并实施三种关键策略，即示例提示（EP）、响应分布对齐（RDA）和对比响应调整（CRT），有效改善任务特定表现。EP使TSM特征能够引导VLMs，而RDA则在推理过程中通过借鉴示例提示模型的经验，使VLMs能够适应而不需TSMs。CRT进一步优化了正确图像-响应对的排名，从而降低了生成不当响应的风险。在12个医学诊断数据集和9种成像模式下的实验结果表明，VITask的表现超越了传统的指令调优VLMs和TSMs，证明了其有效整合两种模型互补特性的能力。此外，VITask在TSM集成的灵活性和对不完整指令的鲁棒性方面也展现了实际优势，成为任务特定VLM微调的多功能和高效解决方案。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.06456" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 02:10:18 GMT</pubDate>
</item>
<item>
<title>增强大型语言模型的长度控制与复制粘贴能力</title>
<link>https://arxiv.org/abs/2410.07035</link>
<guid>https://arxiv.org/abs/2410.07035</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">提出新的方法提升大型语言模型的长度控制与复制粘贴能力，显著改进性能。</p><br /><br /><p><strong>摘要：</strong> 大型语言模型（LLMs）在角色扮演、创意写作、数学推理和编码等领域显示出强大的能力，然而在长度控制方面仍然面临挑战。这一问题主要源于模型在生成文本时缺乏位置意识，导致难以遵循特定的长度限制。为了解决这一问题，我们提出了两种新方法：PositionID Prompting和PositionID Fine-Tuning，使模型能够持续监控和管理生成文本的长度。此外，我们还引入了PositionID CP Prompting，使LLMs能够准确地执行复制和粘贴操作。为了评估长度控制和复制粘贴功能，我们开发了两个基准测试。实验结果表明，我们的方法显著提高了模型对长度限制的遵守程度和复制粘贴的准确性，同时不牺牲响应质量。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.07035" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 02:03:18 GMT</pubDate>
</item>
<item>
<title>Meissonic：高效的非自回归文本到图像建模</title>
<link>https://arxiv.org/abs/2410.08261</link>
<guid>https://arxiv.org/abs/2410.08261</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">Meissonic 提升非自回归图像建模，生成高质量、高分辨率图像。</p><br /><br /><p><strong>摘要：</strong> 在视觉生成领域，扩散模型如 Stable Diffusion 取得了重要进展，但其和自回归语言模型的根本不同，使得统一语言-视觉模型的开发面临挑战。针对这一问题，我们提出了 Meissonic，它将非自回归的遮蔽图像建模（MIM）文本到图像生成技术提升至与先进扩散模型（如 SDXL）相当的水平。通过综合采用一系列架构创新、先进的位置信息编码策略以及优化的采样条件，Meissonic 显著提高了 MIM 的性能和效率。同时，我们利用高质量的训练数据，集成了基于人类偏好评分的信息微调条件，并采用特征压缩层来进一步提升图像的真实感和分辨率。我们的模型不仅在生成高质量、高分辨率图像方面与现有模型如 SDXL 相匹配，且往往超过其性能。大量实验验证了 Meissonic 的能力，展示了它作为文本到图像合成新标准的潜力。我们发布了一个能够生成 1024x1024 分辨率图像的模型检查点。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.08261" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 01:19:46 GMT</pubDate>
</item>
<item>
<title>Baichuan-Omni：首个开源7B多模态大语言模型</title>
<link>https://arxiv.org/abs/2410.08565</link>
<guid>https://arxiv.org/abs/2410.08565</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本研究提出Baichuan-Omni，这是一个开源的7B多模态大语言模型，具备图像、视频、音频与文本的处理能力。</p><br /><br /><p><strong>摘要：</strong> 在本文中，我们介绍了Baichuan-Omni，首个开源的7B多模态大语言模型（MLLM），它能够同时处理和分析图像、视频、音频和文本等多种信息模式，以提供先进的多模态交互体验及出色的性能。我们提出了一种有效的多模态训练方案，从7B模型开始，经过两个阶段的多模态对齐和多任务微调，以处理音频、图像、视频和文本等多种模式。这一方法使语言模型具备有效处理视觉和音频数据的能力。Baichuan-Omni在多个全模态和多模态基准测试中表现出色。我们的目标是希望这一贡献为开放源代码社区提供一个具有竞争力的基准，促进多模态理解和实时交互的进步。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.08565" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 00:29:48 GMT</pubDate>
</item>
<item>
<title>基于语义得分蒸馏采样的复杂3D内容生成研究</title>
<link>https://arxiv.org/abs/2410.09009</link>
<guid>https://arxiv.org/abs/2410.09009</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出了一种新的SDS方法，SemanticSDS，通过语义嵌入提高复杂3D场景生成的表现力和准确性。</p><br /><br /><p><strong>摘要：</strong> 生成高质量的3D资产仍然是计算机图形学和视觉研究中的关键挑战。由于3D数据的稀缺，当前的前沿方法利用预训练的2D扩散先验，通过得分蒸馏采样（SDS）进行优化。尽管技术有所进步，然而，制作複杂3D场景及多个物体或复杂交互仍然困难。为了解决这一问题，近期方法逐渐引入了框或布局引导，但这些布局引导的组合方法通常在提供细粒度控制方面表现不佳，较为粗糙且缺乏表现力。为此，我们提出了一种新的得分蒸馏采样方法——语义得分蒸馏采样（SemanticSDS），旨在有效提高组合文本到3D生成的表现力与准确性。我们的做法整合了新的语义嵌入，这些嵌入在不同渲染视图间保持一致，并且能够清晰地区分不同的物体和部分。通过将这些嵌入转化为一个语义图，我们引导了区域特定的SDS过程，从而实现精确的优化与组合生成。通过利用显式的语义引导，我们的方法解锁了现有预训练扩散模型的组合能力，在复杂物体和场景的3D内容生成方面达到了优秀的质量。实验结果表明，我们的SemanticSDS框架在生成尖端复杂3D内容方面非常有效。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.09009" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 00:24:03 GMT</pubDate>
</item>
<item>
<title>SuperCorrect：一种改进小型模型推理能力的两阶段框架</title>
<link>https://arxiv.org/abs/2410.09008</link>
<guid>https://arxiv.org/abs/2410.09008</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">我们提出SuperCorrect框架，通过大模型的监督，提高小模型的推理与自我纠错能力。</p><br /><br /><p><strong>摘要：</strong> 近年来，大型语言模型（LLMs）如GPT-4和PaLM在推理任务中表现出显著的改进。然而，较小的模型例如Llama-3-8B和DeepSeekMath-Base在复杂数学推理中仍面临挑战，尤其在独立检测和纠正推理错误方面。为了解决这一问题，我们提出了一个名为SuperCorrect的创新两阶段框架，利用大型教师模型来监督和纠正小型学生模型的推理和反思过程。在第一阶段，我们从教师模型中提取层次化的高层次和详细思维模板，以指导学生模型更好地引导细致的推理思考。在第二阶段，我们引入跨模型的协作直接偏好优化（DPO）方法，以增强学生模型的自我纠错能力，学生模型在训练过程中跟随教师的纠正轨迹。这个跨模型DPO方法教会学生模型有效定位和解决错误思维，突破思维瓶颈，获取新的技能和知识，从而应对挑战性的问题。大量实验证明，SuperCorrect优于以前的方法，尤其是我们的SuperCorrect-7B模型在MATH和GSM8K基准上分别比DeepSeekMath-7B提升了7.8%/5.3%和比Qwen2.5-Math-7B提升了15.1%/6.3%，在所有7B模型中达到了新的SOTA性能。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.09008" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 00:22:21 GMT</pubDate>
</item>
<item>
<title>EvolveDirector：基于公共资源训练文本到图像生成模型的框架</title>
<link>https://arxiv.org/abs/2410.07133</link>
<guid>https://arxiv.org/abs/2410.07133</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">EvolveDirector框架利用公共API生成的数据训练文本到图像生成模型，显著降低数据需求，实现优越的生成能力。</p><br /><br /><p><strong>摘要：</strong> 随着生成模型的快速进步，文本到图像生成表现出惊人的内容创作能力。然而，大多数先进模型依赖于专有数据，并提供有限的开放API，限制了其在下游任务中的应用。为探讨利用公共资源训练一个可与先进模型媲美的文本到图像生成模型的可行性，我们提出了EvolveDirector框架。该框架通过公共API与先进模型交互，获得文本-图像数据对以训练基础模型。实验显示，尽管通过生成数据训练的模型能接近先进模型的生成能力，但需要大量的样本（1000万个或更多），这会带来高昂的时间和计算资源成本，尤其是API调用费用。为了解决这一问题，EvolveDirector利用预训练的大型视觉-语言模型（VLM）来指导基础模型的演化，持续评估基础模型，并通过判别、扩展、删除和变异等操作动态更新和优化训练数据集。实验结果表明，这种方法显著减少了所需的数据量。EvolveDirector还能够在面对多个高级模型时选择其生成的最佳样本，以学习强大且均衡的能力。最终训练出的模型Edgen显示出优于这些先进模型的效果。代码和模型权重可在https://github.com/showlab/EvolveDirector获取。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.07133" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 00:17:02 GMT</pubDate>
</item>
<item>
<title>利用加速偏好优化加快人类反馈下的强化学习</title>
<link>https://arxiv.org/abs/2410.06293</link>
<guid>https://arxiv.org/abs/2410.06293</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出了一种加速偏好优化框架，结合动量技术加速大语言模型的对齐。</p><br /><br /><p><strong>摘要：</strong> 强化学习中的人类反馈（RLHF）正在成为对齐大型语言模型（LLM）的重要工具。直接偏好优化（DPO）是一种流行的方法，它将RLHF视为一个政策优化问题，而不显式估计奖励函数。此方法克服了两步法所面临的稳定性和效率问题，并展示了可以通过动量技术加速RLHF的潜力。本文首次表明，迭代偏好优化方法可以视为一种近端点方法。基于此观察，提出了一种通用的加速偏好优化（APO）框架，统一了许多现有的偏好优化算法，并采用Nesterov动量技术加速LLM的对齐过程。理论上，APO能够实现比标准迭代偏好优化方法（包括DPO和自我博弈偏好优化（SPPO））更快的收敛速度。实证结果显示，APO在AlpacaEval 2.0基准上相较于DPO、迭代DPO及其他强基线表现出更强的优越性。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.06293" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 23:06:15 GMT</pubDate>
</item>
<item>
<title>Data Advisor：提升数据生成质量的增强LLM方法</title>
<link>https://arxiv.org/abs/2410.05269</link>
<guid>https://arxiv.org/abs/2410.05269</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">提出Data Advisor，优化LLM生成数据，提高数据质量与覆盖率，特别针对安全对齐问题。</p><br /><br /><p><strong>摘要：</strong> 在大型语言模型 (LLM) 对齐中，数据是至关重要的元素。尽管近期研究探讨了使用LLM进行高效数据收集，但LLM生成的数据常常存在质量问题，如缺乏代表性、某些方面的缺失以及低质量数据点。为了解决这些问题，我们提出了Data Advisor，这是一种增强的LLM方法，用于生成符合特定特征的数据集。Data Advisor基于一组预定义原则，监控生成数据的状态，识别当前数据集的弱点，并据此建议下一轮数据生成的策略。Data Advisor可轻松集成到现有的数据生成方法中，以提升数据的质量和覆盖率。在对三种代表性LLM（即Mistral、Llama2和Falcon）进行的安全对齐实验中，Data Advisor显示了提升模型安全性与应对各种细粒度安全问题的有效性，同时不牺牲模型的实用性。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.05269" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 19:05:54 GMT</pubDate>
</item>
<item>
<title>基于神经符号学习的LLM世界模型对齐与探索</title>
<link>https://arxiv.org/abs/2410.07484</link>
<guid>https://arxiv.org/abs/2410.07484</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出WALL-E代理，通过规则学习对LLM进行环境对齐，显著提升在Minecraft和ALFWorld等开放世界中的探索效率与成功率。</p><br /><br /><p><strong>摘要：</strong> 本文探讨了大语言模型（LLMs）作为模型基础代理的世界模型的潜力，尽管存在LLMs的先验知识与特定环境动态之间的差距，我们的研究表明，这些差距可以通过对LLM与其部署环境进行对齐来弥补。这种“世界对齐”可以通过在LLMs上进行规则学习高效实现。由于LLMs具有丰富的先验知识，通常只需少量额外规则即可使LLM预测与实定环境动态一致。为此，本文提出了一种神经符号方法，通过比较代理探索的轨迹与世界模型预测，诱导、更新和修剪规则，从而以无梯度的方式学习这些规则。最终的世界模型由LLM及学习的规则组成。我们的具身LLM代理“WALL-E”基于模型预测控制（MPC）构建，通过基于精确世界模型优化前瞻性动作，MPC显著提高了探索和学习效率。与现有LLM代理相比，WALL-E的推理只需少量主规则，而不是将冗长的缓冲轨迹纳入LLM输入。在Minecraft和ALFWorld的开放世界挑战中，WALL-E相比现有方法有更高的成功率，且重规划时间和使用的tokens更少。在Minecraft中，WALL-E的成功率超过基线15-30%，重规划轮次减少8-20轮，使用的tokens仅为60-80%。在ALFWorld中，其成功率在仅6次迭代后飙升至95%的新纪录。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.07484" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 17:14:49 GMT</pubDate>
</item>
<item>
<title>向量-内联学习：扩展大型语言模型的能力</title>
<link>https://arxiv.org/abs/2410.05629</link>
<guid>https://arxiv.org/abs/2410.05629</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文探讨大型语言模型如何通过轻量级投影器处理连续向量，实现向量-内联学习能力。</p><br /><br /><p><strong>摘要：</strong> 大型语言模型（LLMs）在文本数据的上下文学习（ICL）能力方面表现出色。本文探索了这些能力是否可以扩展到来自不同领域的连续向量，这些向量是通过黑箱预训练编码器获得的。我们通过轻量级投影器将输入数据与LLM的嵌入空间对齐，发现LLMs能够有效地处理和学习这些投影向量，称之为向量-内联学习（Vector-ICL）。尤其值得注意的是，使用通用语言建模目标对投影器进行预训练可以实现Vector-ICL，而任务特定的微调则进一步提升了性能。我们在各种任务和模态上进行了实验，包括文本重建、数值函数回归、文本分类、摘要生成、分子描述、时间序列分类、图分类和fMRI解码。结果表明，Vector-ICL在许多情况下超越了少量样本的ICL和领域特定模型或微调。我们还进行了分析和案例研究，表明LLMs在处理向量表示方面的潜力超越了传统的基于标记的范式。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.05629" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 16:04:02 GMT</pubDate>
</item>
<item>
<title>Zebra：一种新型生成自回归变换器用于解决时间依赖性参数偏微分方程</title>
<link>https://arxiv.org/abs/2410.03437</link>
<guid>https://arxiv.org/abs/2410.03437</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">Zebra 是一款不需梯度适应的新型变换器，能够灵活应对各种参数 PDE，展示卓越的性能。</p><br /><br /><p><strong>摘要：</strong> 解决时间依赖性参数偏微分方程（PDEs）是一项具有挑战性的任务，因为模型必须适应系数、强迫项和边界条件等参数的变化。数据驱动的神经网络求解器通常依赖于从PDE参数分布中采样的数据进行训练，以期在新的实例上实现泛化，或依靠基于梯度的适应和元学习，隐式编码来自观察的数据动态。然而，这通常会增加推理复杂性。受到大型语言模型（LLMs）在上下文学习能力的启发，我们提出了Zebra，一种新型生成自回归变换器，旨在解决参数PDEs，而无需在推理时进行梯度适应。Zebra通过在预训练和推理过程中利用上下文信息，能够动态适应新任务，条件依赖于包含上下文轨迹或先前状态的输入序列。这种方法使得Zebra能够灵活处理任意大小的上下文输入，并通过采样多个解轨迹支持不确定性量化。我们在多种挑战性的PDE场景中评估了Zebra，展示了其适应性、鲁棒性以及相较于现有方法的优越性能。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.03437" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 15:11:34 GMT</pubDate>
</item>
<item>
<title>DART：一种新型的非马尔可夫扩散模型</title>
<link>https://arxiv.org/abs/2410.08159</link>
<guid>https://arxiv.org/abs/2410.08159</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">DART提出了一种统一自回归与扩散框架的图像生成模型，提升了训练与推理效率。</p><br /><br /><p><strong>摘要：</strong> 扩散模型已成为视觉生成的主流方法，但其基于马尔可夫过程的特性限制了模型充分利用生成轨迹的能力，导致在训练和推理时效率低下。为此，本文提出了一种新的模型DART，基于变换器架构，将自回归（AR）和扩散过程结合在一个非马尔可夫的框架内。DART通过空间和光谱的方式迭代去噪图像块，采用与标准语言模型相同的架构。DART不依赖于图像量化，增强了图像建模的有效性，保持了灵活性。同时，DART能够在一个统一模型中无缝地训练文本和图像数据。我们的实验结果表明，DART在类别条件和文本到图像生成任务上表现出色，提供了一种可扩展、高效的替代方案。通过这一统一框架，DART为高质量图像合成设立了新的基准。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.08159" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 13:56:02 GMT</pubDate>
</item>
<item>
<title>大型语言模型的任务超叠现象及其内在机制研究</title>
<link>https://arxiv.org/abs/2410.05603</link>
<guid>https://arxiv.org/abs/2410.05603</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文探讨大型语言模型在单次推理过程中同时执行多个不同任务的能力，称为任务超叠现象。</p><br /><br /><p><strong>摘要：</strong> 本文研究了大型语言模型（LLMs）在上下文学习（ICL）方面的一个惊人现象：模型能够在单次推理调用中同时执行多个计算上独立的ICL任务，这一能力被称为‘任务超叠’。我们提供了针对不同LLM家族和规模的实证证据，表明即使在模型训练时仅学习一个任务，也能出现这一现象。此外，我们提供了理论解释，认为这一能力在变换器的表达能力范围内。我们还探讨了LLMs如何在超叠过程中内部组合任务向量的机制。研究表明，较大的模型能够并行解决更多ICL任务，并更好地校准其输出分布。这些发现为LLMs潜在能力提供了新的见解，进一步支持了‘LLMs作为模拟器的超叠’的观点，并引发了关于实现同时任务执行的机制的思考。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.05603" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 13:27:35 GMT</pubDate>
</item>
<item>
<title>自动化基准测试中的作弊现象及其影响</title>
<link>https://arxiv.org/abs/2410.07137</link>
<guid>https://arxiv.org/abs/2410.07137</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">研究显示，常量输出模型可在自动化基准测试中作弊，表现异常优异，呼吁开发反作弊机制。</p><br /><br /><p><strong>摘要：</strong> 本文探讨了在自动化大语言模型（LLM）基准测试中存在的作弊问题。研究表明，即使是一个始终输出固定响应（与输入无关）的“空模型”，也能在多个基准测试上取得高分，如在 AlpacaEval 2.0 上获得 86.5% 的 LC 胜率，在 Arena-Hard-Auto 上获得 83.0 分，而在 MT-Bench 上获得 9.55 分。这些作弊输出展示出了可转移性，因为假设测试指令是私有且不可访问的。尽管本研究主要作为概念验证，但某些对手可以利用 LLM 生成更不易察觉的作弊回复，从而从高胜率和推广影响中不道德地获利。因此，本文呼吁开发可靠的反作弊机制，以确保自动化基准测试的可信度及其在评估语言模型时的有效性。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.07137" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 12:28:45 GMT</pubDate>
</item>
<item>
<title>LPZero：自动设计零成本代理的框架</title>
<link>https://arxiv.org/abs/2410.04808</link>
<guid>https://arxiv.org/abs/2410.04808</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">LPZero是一个框架，能够自动设计零成本（ZC）代理，提升NLP任务中的性能和排名一致性。</p><br /><br /><p><strong>摘要：</strong> 在神经架构搜索（NAS）面临的大量计算开销的背景下，零成本（ZC）代理作为一种有前途的方法逐渐受到关注。然而，现有的ZC代理往往依赖于专家知识，且存在显著的试错成本，尤其在自然语言处理（NLP）任务中，许多ZC代理无法超越简单基线表现。为了解决这些问题，我们提出了一个新颖的框架LPZero，这是首个能够为各种任务自动设计ZC代理的系统，且其排名一致性优于人工设计的代理。具体而言，我们将ZC代理建模为符号方程，并整合了一个统一的代理搜索空间，该空间涵盖了由预定义的数学符号构成的现有ZC代理。LPZero利用遗传编程进行启发式搜索，以找到最佳的符号组合。同时，我们提出了一种基于规则的剪枝策略（RPS），该策略可以预先消除不太有前景的代理，从而降低代理降低性能的风险。通过对FlexiBERT、GPT-2和LLaMA-7B的广泛实验，LPZero在下游任务中的排名能力和性能均优于现有方法。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.04808" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 12:09:02 GMT</pubDate>
</item>
<item>
<title>GLOV：利用大语言模型优化视觉语言模型的隐式优化方法</title>
<link>https://arxiv.org/abs/2410.06154</link>
<guid>https://arxiv.org/abs/2410.06154</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出GLOV方法，利用大语言模型作为隐式优化器提升视觉任务性能。</p><br /><br /><p><strong>摘要：</strong> 在这项研究中，我们提出了一种新颖的方法（GLOV），使大语言模型（LLMs）能够作为隐式优化器，提升视觉语言模型（VLMs）在下游视觉任务中的表现。通过对下游任务描述的元提示，GLOV查询出适合的VLM提示（如使用CLIP进行零-shot分类），并根据适应性函数获得的纯度度量对这些提示进行排名。在每个优化步骤中，排名后的提示及其准确性作为上下文示例被送入LLM，帮助LLM了解下游VLM所偏爱的文本提示类型。此外，我们在每个优化步骤中明确引导LLM生成过程，通过将来自上一步中正负解的嵌入差异向量添加至网络的中间层，从而在下一步的生成过程中引导LLM朝向下游VLM所偏好的语言类型。这一策略显著提升了下游视觉任务的表现。我们在16个多样化的数据集上全面评估了GLOV，使用两类VLM（即双编码器模型如CLIP和编码器-解码器模型如LLaVa），结果显示，所发现的解决方案能在识别性能上提升高达15.0%和57.5%（平均分别提升3.8%和21.6%）。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.06154" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 07:34:00 GMT</pubDate>
</item>
<item>
<title>WorFBench：一个用于评估工作流生成能力的统一基准</title>
<link>https://arxiv.org/abs/2410.07869</link>
<guid>https://arxiv.org/abs/2410.07869</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出了WorFBench工作流生成基准及WorFEval评估协议，揭示LLM在序列和图规划间的能力差异。</p><br /><br /><p><strong>摘要：</strong> 大型语言模型（LLMs）在解决推理和规划任务方面取得了显著进展，其中将复杂问题分解为可执行工作流是关键步骤。现有的工作流评估框架存在局限，不能全面反映LLM的能力。为此，我们引入了WorFBench，这是一种统一的工作流生成基准，涵盖多样化场景和复杂图形工作流结构。同时，我们提出了WorFEval，一种系统的评估协议，利用子序列和子图匹配算法来准确量化LLM代理的工作流生成能力。通过对不同类型的LLMs进行综合评估，我们发现LLM代理在序列规划能力和图规划能力之间存在显著差距，即使是GPT-4，二者之间的差距约为15%。此外，我们训练了两个开源模型，并评估了它们在持出任务上的泛化能力。值得注意的是，生成的工作流能够提高下游任务的表现，使得推理过程所需时间减少，从而达到更优秀的性能。代码和数据集将发布于https://github.com/zjunlp/WorFBench。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.07869" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 06:48:20 GMT</pubDate>
</item>
<item>
<title>基于运动先验的变形3D高斯点云重建框架MotionGS</title>
<link>https://arxiv.org/abs/2410.07707</link>
<guid>https://arxiv.org/abs/2410.07707</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本研究提出了MotionGS，一个通过运动先验引导变形的3D高斯点云重建框架，显著提升动态场景重建效果。</p><br /><br /><p><strong>摘要：</strong> 动态场景重建在3D视觉领域一直是一个长期挑战。最近，3D高斯点云技术的兴起为这一问题提供了新的视角。尽管后续工作迅速将静态3D高斯扩展到动态场景，但往往缺乏对物体运动的明确约束，导致优化困难和性能下降。为了解决这些问题，本文提出了一个新颖的变形3D高斯点云框架——MotionGS，旨在探索明确的运动先验以引导3D高斯的变形。具体而言，我们首先引入了一种光流解耦模块，该模块将光流解耦为相机流和运动流，分别对应于相机移动和物体运动。然后，运动流可以有效约束3D高斯的变形，从而模拟动态物体的运动。此外，还提出了一种相机姿态优化模块，以交替优化3D高斯和相机姿态，减轻不准确相机姿态的影响。在单目动态场景中的广泛实验验证了MotionGS在定性和定量结果上都超越了最新的技术。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.07707" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 06:17:59 GMT</pubDate>
</item>
<item>
<title>基于数学推理和代码生成的数学继续预训练方法</title>
<link>https://arxiv.org/abs/2410.08196</link>
<guid>https://arxiv.org/abs/2410.08196</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出了一种新的数学继续预训练方法，通过生成代码和推理步骤提升语言模型的数学能力。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了一种新的数学继续预训练方法，通过生成数学代码及其相应的推理步骤，提升大型语言模型的数学推理能力。最初，我们构建了一个高质量的数学继续预训练数据集，融合了数学相关的网络数据、使用数学包的代码、数学教科书以及合成数据。接着，我们通过提取LaTeX表达式、这些表达式所需的条件及其结果，生成推理步骤。基于提取的信息，我们生成了相应的代码，以准确捕捉数学推理过程。在每个推理步骤后附加生成的代码，形成了自然语言推理步骤与其对应代码的配对数据。将这些数据与原始数据集结合，形成了一个包含19.2B标记的高性能数学预训练语料库，命名为MathCode-Pile。使用该语料库训练几种流行的基础模型显著提升了它们的数学能力，最终形成了MathCoder2模型系列。为了确保透明性和易于重现，我们将所有数据处理和训练代码开源，代码可在https://github.com/mathllm/MathCoder2获取。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.08196" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 04:16:58 GMT</pubDate>
</item>
<item>
<title>SFTMix: 基于Mixup的指令调优方法研究</title>
<link>https://arxiv.org/abs/2410.05248</link>
<guid>https://arxiv.org/abs/2410.05248</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本研究提出SFTMix，通过Mixup正则化提高指令调优性能，降低对高质量数据集的依赖。</p><br /><br /><p><strong>摘要：</strong> 在大型语言模型（LLMs）交互驱动任务的指令调优阶段，通常通过下一个标记预测（NTP）损失对指令-响应对进行训练。以往旨在提升指令调优表现的研究往往强调需要更高质量的监督微调（SFT）数据集，这通常伴随高昂的数据过滤成本或人工标注的劳动力。然而，这些方法未能充分利用数据集的内在特性，导致高计算和劳动成本，限制了可扩展性和性能提升。本文提出了SFTMix，一种新颖的策略，通过Mixup正则化提升指令调优性能，而无需精心策划的数据集。我们观察到LLMs在语义表示空间中的信心不均匀，认为不同信心水平的示例在指令调优过程中应发挥不同角色。在此基础上，SFTMix利用训练动态识别不同信心水平的示例，减轻对高信心示例的过拟合，同时增强对低信心示例的学习信号。这一方法显著提升了在多种指令跟随和医疗领域特定SFT任务中的表现，证明了SFTMix对不同LLM家族的适应性以及对任何规模数据集的可扩展性。全面的消融研究进一步验证了SFTMix设计选择的稳健性，强调其在语言处理应用中提升性能的通用性。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.05248" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 03:19:15 GMT</pubDate>
</item>
<item>
<title>Agent S: 基于多模态大语言模型的自主交互框架</title>
<link>https://arxiv.org/abs/2410.08164</link>
<guid>https://arxiv.org/abs/2410.08164</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">Agent S 是一种开放的自主代理框架，可通过GUI自动化复杂任务，实现人机交互的变革。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了Agent S，一个开放的自主代理框架，旨在通过图形用户界面与计算机进行自主交互，从而实现人机交互的变革，自动化复杂和多步骤的任务。Agent S解决了自动化计算机任务的三个主要挑战：获取领域特定知识、规划长期任务及处理动态非均匀界面。为此，Agent S 引入了经验增强层次规划，能够在多个层次上从外部知识搜索和内部经验检索中学习，从而促进高效的任务规划和子任务执行。此外，Agent S 采用了代理-计算机接口（ACI），更好地充分发挥基于多模态大语言模型（MLLMs）的GUI代理的推理和控制能力。根据OSWorld基准的评估结果，Agent S 在成功率上超过了基线水平9.37%，实现了83.6%的相对改进，并且取得了新的最先进成果。全面分析展示了各个组件的有效性，并为未来的改进提供了洞见。此外，Agent S 在新发布的WindowsAgentArena基准上展现出良好的广泛泛化能力。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.08164" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 03:06:26 GMT</pubDate>
</item>
<item>
<title>大语言与视觉模型（LLVMs）的感知能力研究</title>
<link>https://arxiv.org/abs/2410.04751</link>
<guid>https://arxiv.org/abs/2410.04751</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文系统探讨了LLVMs在感知任务中的表现及其内在机制。</p><br /><br /><p><strong>摘要：</strong> 本文系统地研究了大语言与视觉模型（LLVMs），特别是它们在基础感知任务（如MMVP）上的低表现。通过对几种LLVMs家族（如LLaVA）的10个评估基准进行评估，我们发现多个有趣的特性：1）即便视觉块序列随机排列，它们仍以全局方式处理图像；2）在解决数学问题时，模型并不总是需要详细的数字信息；3）交叉模态的对齐在复杂推理任务中存在过拟合现象，从而导致模型失去部分视觉编码器的原始感知能力；4）模型较低层次的表示空间（低于25%）在性能和增强视觉理解中起着关键作用。基于这些观察，本文提出了未来改进LLVMs及构建更具挑战性评估基准的潜在方向。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.04751" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 03:01:45 GMT</pubDate>
</item>
<item>
<title>AlphaLLM-CPL：一种基于MCTS行为蒸馏的自我改进框架</title>
<link>https://arxiv.org/abs/2410.06508</link>
<guid>https://arxiv.org/abs/2410.06508</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出AlphaLLM-CPL框架，利用MCTS生成的轨迹对LLM进行自我改进，显著提升推理能力。</p><br /><br /><p><strong>摘要：</strong> 在本文中，我们提出了一种新的框架，AlphaLLM-CPL，用于通过蒙特卡洛树搜索（MCTS）行为蒸馏来提升大语言模型（LLM）的推理能力。尽管现有的蒸馏方法利用MCTS生成的轨迹，但仍然未能充分利用这些丰富的信息，限制了LLM推理性能的提升。AlphaLLM-CPL引入了两个关键创新：首先，它从共享同一父节点的子节点构造逐步轨迹对，以提供更有效的逐步信息用于MCTS行为蒸馏。其次，AlphaLLM-CPL采用了课程偏好学习，在每个离线训练周期中动态调整轨迹对的训练顺序，优先考虑关键学习步骤，从而减轻过拟合。通过在数学推理任务上的实验结果表明，AlphaLLM-CPL显著优于以往的MCTS行为蒸馏方法，极大地提升了LLM的推理能力。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.06508" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 02:06:42 GMT</pubDate>
</item>
<item>
<title>自回归视频扩散模型的进展及应用</title>
<link>https://arxiv.org/abs/2410.08151</link>
<guid>https://arxiv.org/abs/2410.08151</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出扩展现有视频扩散模型的方法，实现长达1分钟的视频生成。</p><br /><br /><p><strong>摘要：</strong> 当前最前沿的视频扩散模型在生成高质量视频方面表现出色。然而，由于计算限制，这些模型通常只能生成时长约为10秒（240帧）的视频。本文展示了如何在不改变现有架构的情况下，将这些模型自然扩展为自回归视频扩散模型。我们的关键思想是为潜在帧分配逐渐增加的噪声水平，而不是使用单一的噪声水平，从而允许潜在帧之间的细粒度条件及注意窗口之间的大重叠。这种渐进的视频去噪方法使我们的模型在自回归生成视频帧时，能够避免质量下降或突发场景变化。我们在长视频生成任务上取得了最先进的结果，生成了长达1分钟（1440帧、24帧每秒）的视频。本文视频可在https://desaixie.github.io/pa-vdm/上查看。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.08151" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 02:02:23 GMT</pubDate>
</item>
<item>
<title>大卷积核在现代卷积神经网络设计中的应用</title>
<link>https://arxiv.org/abs/2410.08049</link>
<guid>https://arxiv.org/abs/2410.08049</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出大卷积核作为设计现代卷积神经网络（ConvNets）的新范式，并引入UniRepLKNet架构。</p><br /><br /><p><strong>摘要：</strong> 本文提出了大卷积核作为现代卷积神经网络（ConvNets）设计的新范式。研究表明，使用少量大卷积核，而非堆叠多个小卷积核，可能是一种更优的设计策略。我们提出了一套专门针对大卷积核ConvNets的架构设计指南，以优化其效率和性能。UniRepLKNet架构的设计原则特别强调大卷积核ConvNets在无需深层堆叠的情况下捕捉广泛空间信息的能力。实验结果表明，该模型在ImageNet上达到了88.0%的准确率，ADE20K数据集上获得了55.6%的mIoU，以及在COCO检测上取得了56.4%的AP，表现出显著的可扩展性及在多种场景下的优异性能，包括时间序列预测、音频、点云及视频识别。与视觉Transformer相比，大卷积核ConvNets具有更大的有效感受野和更高的形状偏置，克服了小卷积核CNN的纹理偏置。这些结果展示了大卷积核ConvNets的通用建模能力。所有代码和模型已在https://github.com/AILab-CVC/UniRepLKNet上公开，促进社区的进一步研究与发展。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.08049" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 01:49:57 GMT</pubDate>
</item>
<item>
<title>简化和扩展扩散模型 rectification 的新策略</title>
<link>https://arxiv.org/abs/2410.07303</link>
<guid>https://arxiv.org/abs/2410.07303</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">我们提出了 Rectified Diffusion，简化了 rectification 方法并验证其在 Stable Diffusion 上的效果。</p><br /><br /><p><strong>摘要：</strong> 扩散模型在视觉生成方面取得了显著进展，但由于解决生成常微分方程（ODE）的计算密集性，生成速度仍然较慢。本文提出的 Rectified Diffusion 方法，通过使用预训练的扩散模型获取噪声和样本的匹配对，简化了训练程序。我们认为，以往方法中包含的流匹配和 v 预测等组件并非必要，主要目标应是实现一阶近似 ODE 路径，而非强求路径的直线性。我们的方法不再局限于流匹配模型，而是广泛适用于各种扩散模型。经过在 Stable Diffusion v1-5 和 Stable Diffusion XL 上的验证，我们的方法不仅降低了训练成本，还提升了性能。我们的代码已开放在 GitHub 上。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.07303" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 01:27:35 GMT</pubDate>
</item>
<item>
<title>基于偏好学习的多模态轨迹检索增强方法</title>
<link>https://arxiv.org/abs/2410.03450</link>
<guid>https://arxiv.org/abs/2410.03450</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文提出MART方法，通过偏好学习优化轨迹检索，提升机器人在未见场景中的任务成功率。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了一种新方法MLLM as ReTriever (MART)，旨在提升机器人执行复杂任务的能力。当前的检索方法多关注表面相似性，未充分考虑轨迹对特定任务的有效性。MART利用交互数据，通过偏好学习对大型语言模型（MLLM）进行微调，使检索过程能够更好地评估和优先选择适用于未见任务的轨迹。为进一步加强理解，文章引入Trajectory Abstraction机制，利用MLLM的摘要能力将轨迹用更少的符号表示，并保留关键身分信息，这帮助代理更好地抓住轨迹中的重要里程碑。实验结果显示，在不同环境下，MART方法显著提升了代理在未见场景中的任务成功率，表明其在多模态轨迹检索与代理行为的研究中具有重要意义。所有基准任务集和模拟器代码修改将公开发布。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.03450" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 01:21:00 GMT</pubDate>
</item>
<item>
<title>PrefixQuant：一种高效的稀疏化量化技术用于大型语言模型的推理加速</title>
<link>https://arxiv.org/abs/2410.05265</link>
<guid>https://arxiv.org/abs/2410.05265</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">PrefixQuant通过离线隔离高频稀疏令牌，实现了高效的静态量化，显著提升推理速度与准确性。</p><br /><br /><p><strong>摘要：</strong> 量化在大型语言模型（LLM）部署中尤为重要，因为它能提高内存效率和推理速度。目前的激活量化方法主要处理通道级别的离群点，往往忽视令牌级别的离群点，因此依赖于昂贵的每令牌动态量化技术。为了解决这个问题，我们提出了PrefixQuant，一种独特的技术，能够离线识别高频离群令牌，并将其前缀存储在KV缓存中，从而防止推理时生成离群令牌，并简化量化。根据我们的知识，PrefixQuant首次实现了高效的每张量静态量化，超过了昂贵的每令牌动态量化。以W4A4KV4（4位权重、4位激活和4位KV缓存）上的Llama-3-8B为例，PrefixQuant结合每张量静态量化实现了7.43的WikiText2困惑度以及71.08%的常识推理任务平均准确率，分别比之前的动态量化方法QuaRot提升了0.98困惑度与5.98准确率。此外，使用PrefixQuant的W4A4量化模型的推理速度比FP16模型快1.60至2.81倍，相较于QuaRot模型快1.2至1.3倍。我们的代码已发布在https://github.com/ChenMnZ/PrefixQuant。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.05265" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 01:13:37 GMT</pubDate>
</item>
<item>
<title>Optima：提升大语言模型多智能体系统通信效率与任务有效性的框架</title>
<link>https://arxiv.org/abs/2410.08115</link>
<guid>https://arxiv.org/abs/2410.08115</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">Optima通过提高通信效率和任务有效性，解决大语言模型多智能体系统中的关键挑战。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了Optima，一个新颖的框架，旨在解决大语言模型（LLM）基础的多智能体系统（MAS）面临的低通信效率、较差的可扩展性和缺乏有效参数更新优化方法等关键挑战。Optima通过对LLM进行训练，采用迭代的生成、排名、选择和训练模式，结合一个平衡任务性能、 tokens 效率和交流可读性的奖励函数，大幅增强了通信效率和任务有效性。我们探索了多种强化学习算法，包括监督微调（Supervised Fine-Tuning）、直接偏好优化（Direct Preference Optimization）及其混合方法，提供了它们的有效性与效率权衡的深入见解。此外，我们结合受蒙特卡洛树搜索启发的技术生成DPO数据，将对话回合视为树节点，以探索多样的互动路径。在信息不对称问答和复杂推理等常见多智能体任务上评估后，Optima相较于单智能体基线和基于Llama 3 8B的传统MAS表现出一致而显著的提升，在需要大量信息交换的任务中实现了多达2.8倍的性能提升，同时消耗的tokens少于10%。此外，Optima的效率提升为更有效利用推理计算开辟了新可能，推动了推理时间的规模法则的改进。通过解决大语言模型基础多智能体系统中的基本挑战，Optima展示了朝着可扩展、高效和有效的多智能体系统发展的潜力。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.08115" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 01:11:50 GMT</pubDate>
</item>
<item>
<title>重复训练示例在变压器模型中的效益研究</title>
<link>https://arxiv.org/abs/2410.07041</link>
<guid>https://arxiv.org/abs/2410.07041</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">研究表明，在固定训练步数下，重复训练的示例效果优于单次使用的示例。</p><br /><br /><p><strong>摘要：</strong> 本文研究了变压器模型在算法生成数据集上的性能表现，重点关注训练示例重复使用的问题。在处理最大公约数、模乘法和矩阵特征值这三种数学问题时，我们发现，在固定的训练步数下，使用重复的示例的小规模训练集的模型性能优于使用单次示例的大规模训练集的模型。这表明，重复训练的益处超越了数据多样性带来的优势。此外，我们还展示了两集训练的方法，即对小随机子集的重复使用与对训练集其余部分的正常采样相结合，可以加速学习并提升模型性能。这项研究在受控环境下提供了关于深度学习中泛化与记忆之间尚不清晰的相互关系的洞察。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.07041" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 00:59:17 GMT</pubDate>
</item>
<item>
<title>基于局部对抗负例损失的视觉语言模型增强方法</title>
<link>https://arxiv.org/abs/2410.05210</link>
<guid>https://arxiv.org/abs/2410.05210</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本研究提出了一种新方法FSC-CLIP，通过局部硬负例损失提升视觉语言模型的组合理解能力，保持多模态任务表现。</p><br /><br /><p><strong>摘要：</strong> 本文提出了一种新方法——Fine-grained Selective Calibrated CLIP (FSC-CLIP)，旨在提升预训练视觉语言模型（VLMs）的组合理解能力，同时不影响零-shot多模态任务的性能。传统的微调方法通常在提高组合推理的同时降低多模态能力，其主要原因是使用全局硬负例（HN）损失，导致图像和文本的全局表示受到影响。这种全局HN损失会推送与原始文本高度相似的HN文本，从而损害模型的多模态表示。为克服这一限制，FSC-CLIP整合了局部硬负例损失和选择性校准正则化。这些创新提供了精细的负向监督，同时保持了模型的表示完整性。我们的广泛评估显示，FSC-CLIP在多项组合性和多模态任务基准上不仅达到了与最先进模型相当的组合能力，而且保持了强大的多模态能力。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.05210" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 00:47:13 GMT</pubDate>
</item>
<item>
<title>DICE：用于可控编辑的离散反演方法</title>
<link>https://arxiv.org/abs/2410.08207</link>
<guid>https://arxiv.org/abs/2410.08207</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">DICE是首个用于离散扩散模型的精确反演方法，支持灵活的内容编辑。</p><br /><br /><p><strong>摘要：</strong> 离散扩散模型在图像生成和掩蔽语言建模等任务中取得了成功，但在可控内容编辑方面存在局限性。我们提出了DICE（Discrete Inversion for Controllable Editing），这是第一个支持离散扩散模型（包括多项式扩散和掩蔽生成模型）的精确反演方法。通过在反向扩散过程中记录噪声序列和掩蔽模式，DICE实现了对离散数据的准确重建和灵活编辑，无需预定义掩蔽或注意力操作。我们在图像和文本领域展示了DICE的有效性，并在VQ-Diffusion、Paella和RoBERTa等模型上进行了评估。结果显示，DICE在提高编辑能力的同时，也保持了高数据保真度，为离散空间中的精细内容操控提供了新的机遇。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://arxiv.org/abs/2410.08207" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 00:32:24 GMT</pubDate>
</item>
</channel>
</rss>