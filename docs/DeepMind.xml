<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>Google DeepMind Blog</title>
<link>https://deepmind.google/discover/blog/</link>

<item>
<title>Google Gemini 2.5 Flash版正式上线，开发者可开始构建</title>
<link>https://deepmind.google/discover/blog/introducing-gemini-2-5-flash/</link>
<guid>https://deepmind.google/discover/blog/introducing-gemini-2-5-flash/</guid>
<content:encoded><![CDATA[

  <div><p style=color:gray;>Google发布Gemini 2.5 Flash版，助力开发者构建更多创新应用。</p><br><br><p><strong>摘要：</strong> Google Gemini 2.5 Flash版本的推出标志着人工智能工具在开发领域的进一步升级。此版本旨在为开发者提供更强大的功能支持，帮助他们更高效地创建和测试模型。Gemini 2.5 Flash不仅优化了运行速度，还增强了与现有开发工具的兼容性，使开发者能够更加专注于创新。此外，Google还提供了丰富的资源和教程，帮助开发者快速上手并充分利用新版本的优势。这一版本的发布对开发者社区具有重要意义，它不仅提升了开发效率，还推动了人工智能技术的应用场景扩展。</p><br><br><p><em>使用 qwen-turbo 生成 </em></p><a href=https://deepmind.google/discover/blog/introducing-gemini-2-5-flash/ target="_blank">查看原文</a></div>

]]></content:encoded>
<pubDate>Thu, 17 Apr 2025 19:02:00 +0000</pubDate>
<pubDate>Thu, 17 Apr 2025 19:02:00 +0000</pubDate>
</item>
<item>
<title>Gemini Advanced新增视频生成功能，支持文本转动态视频</title>
<link>https://deepmind.google/discover/blog/generate-videos-in-gemini-and-whisk-with-veo-2/</link>
<guid>https://deepmind.google/discover/blog/generate-videos-in-gemini-and-whisk-with-veo-2/</guid>
<content:encoded><![CDATA[

  <div><p style=color:gray;>Gemini用户现可利用Veo 2将文本提示转化为高质量动态视频。</p><br><br><p><strong>摘要：</strong> Google最近推出了Gemini Advanced的新功能，允许用户通过Veo 2模型将文本描述转化为高分辨率动态视频。该功能提供八秒长的720p视频，适用于多种场景和风格，例如奇幻场景、现实主义画面等。用户只需在Gemini界面选择Veo 2并输入具体描述即可生成视频。此功能已向全球范围内的Google One AI Premium订阅用户开放，同时Whisk Animate也支持图像到视频的转换。Google采取了多项措施保障生成内容的安全性，如数字水印及内容审核机制。这一功能不仅提升了创意表达的可能性，还增强了视频分享的便捷性。</p><br><br><p><em>使用 qwen-turbo 生成 </em></p><a href=https://deepmind.google/discover/blog/generate-videos-in-gemini-and-whisk-with-veo-2/ target="_blank">查看原文</a></div>

]]></content:encoded>
<pubDate>Tue, 15 Apr 2025 17:00:00 +0000</pubDate>
<pubDate>Tue, 15 Apr 2025 17:00:00 +0000</pubDate>
</item>
<item>
<title>Google AI助力解读海豚交流：DolphinGemma项目进展</title>
<link>https://deepmind.google/discover/blog/dolphingemma-how-google-ai-is-helping-decode-dolphin-communication/</link>
<guid>https://deepmind.google/discover/blog/dolphingemma-how-google-ai-is-helping-decode-dolphin-communication/</guid>
<content:encoded><![CDATA[

  <div><p style=color:gray;>谷歌AI模型DolphinGemma帮助科学家分析并尝试理解海豚的复杂交流模式。</p><br><br><p><strong>摘要：</strong> DolphinGemma是谷歌开发的一项AI项目，旨在通过学习海豚的自然声学数据来解析其沟通方式，最终目标是实现人类与海豚之间的双向互动。该项目基于野生大西洋宽吻海豚数十年的观察数据，结合谷歌先进的音频处理技术，构建了一个参数约为4亿的AI模型。DolphinGemma不仅能够识别海豚声音中的重复模式和潜在结构，还支持通过合成声音建立初步的共享词汇表。此外，与乔治亚理工学院合作研发的CHAT系统进一步探索了通过人工合成声调引导海豚行为的可能性。未来，谷歌计划将DolphinGemma开源，以促进全球范围内的相关研究合作。这一进展标志着跨物种交流领域的重要突破。</p><br><br><p><em>使用 qwen-turbo 生成 </em></p><a href=https://deepmind.google/discover/blog/dolphingemma-how-google-ai-is-helping-decode-dolphin-communication/ target="_blank">查看原文</a></div>

]]></content:encoded>
<pubDate>Mon, 14 Apr 2025 17:00:00 +0000</pubDate>
<pubDate>Mon, 14 Apr 2025 17:00:00 +0000</pubDate>
</item>

<item>
<title>Taking a responsible path to AGI</title>
<link>https://deepmind.google/discover/blog/taking-a-responsible-path-to-agi/</link>
<guid>https://deepmind.google/discover/blog/taking-a-responsible-path-to-agi/</guid>
<content:encoded><![CDATA[
We’re exploring the frontiers of AGI, prioritizing technical safety, proactive risk assessment, and collaboration with the AI community.
]]></content:encoded>
<pubDate>Wed, 02 Apr 2025 13:31:00 +0000</pubDate>
</item>
<item>
<title>Evaluating potential cybersecurity threats of advanced AI</title>
<link>https://deepmind.google/discover/blog/evaluating-potential-cybersecurity-threats-of-advanced-ai/</link>
<guid>https://deepmind.google/discover/blog/evaluating-potential-cybersecurity-threats-of-advanced-ai/</guid>
<content:encoded><![CDATA[
Our framework enables cybersecurity experts to identify which defenses are necessary—and how to prioritize them
]]></content:encoded>
<pubDate>Wed, 02 Apr 2025 13:30:00 +0000</pubDate>
</item>
<item>
<title>Gemini 2.5：我们最新的AI思维模型</title>
<link>https://deepmind.google/discover/blog/gemini-2-5-our-most-intelligent-ai-model/</link>
<guid>https://deepmind.google/discover/blog/gemini-2-5-our-most-intelligent-ai-model/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">Gemini 2.5是我们最新的智能AI模型，具备增强的推理和编码能力。</p><br /><br /><p><strong>摘要：</strong> Gemini 2.5是Google最新推出的AI思维模型，旨在解决日益复杂的问题。其首个实验版本2.5 Pro在多个基准测试中表现突出，展现强大的推理和编码能力。Gemini 2.5通过结合增强的基础模型和改进后的后期训练，达到新的性能水平，强调其在逻辑分析、决策能力等方面的优越性。此模型能够处理文本、音频、图像和视频等多种信息来源，具有较长的上下文窗口，为开发者和企业提供了广泛的应用可能性，并将在未来几周内提供使用的定价信息。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/gemini-2-5-our-most-intelligent-ai-model/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 25 Mar 2025 17:00:36 +0000</pubDate>
</item>
<item>
<title>探索Gemini 2.0闪电原生图像生成技术</title>
<link>https://deepmind.google/discover/blog/experiment-with-gemini-20-flash-native-image-generation/</link>
<guid>https://deepmind.google/discover/blog/experiment-with-gemini-20-flash-native-image-generation/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文章介绍了Gemini 2.0的新图像生成技术。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了Google最新推出的Gemini 2.0闪电原生图像生成技术。作为AI领域的重要进展，Gemini 2.0旨在通过创新算法实现更高效、更高质量的图像生成，适用于各类应用场景。文章中提到的技术细节和应用示例展示了这一技术的潜力，并强调了其在推动图像生成领域发展的重要性。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/experiment-with-gemini-20-flash-native-image-generation/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 14:58:00 +0000</pubDate>
</item>
<item>
<title>Gemini Robotics：将AI引入物理世界</title>
<link>https://deepmind.google/discover/blog/gemini-robotics-brings-ai-into-the-physical-world/</link>
<guid>https://deepmind.google/discover/blog/gemini-robotics-brings-ai-into-the-physical-world/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">Gemini Robotics让AI具备物理环境中的应用能力，提升机器人的交互性和灵活性。</p><br /><br /><p><strong>摘要：</strong> Google DeepMind推出了基于Gemini 2.0的Gemini Robotics和Gemini Robotics-ER两个新模型，旨在提升机器人在物理世界中的应用能力。Gemini Robotics是一个高级的视觉-语言-动作模型，能够通过‘具身推理’来理解和反应周围环境，这使其能够执行更复杂的任务，如精细操作和物体操控。而Gemini Robotics-ER则增强了空间理解能力，可以与现有控制系统相结合，实现更高级的机器人功能。通过与多个合作伙伴的测试，Google希望在确保安全的前提下，加快机器人应用的可行性和有效性。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/gemini-robotics-brings-ai-into-the-physical-world/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 15:00:18 +0000</pubDate>
</item>
<item>
<title>Gemma 3：基于Gemini 2.0的全新开放模型发布</title>
<link>https://deepmind.google/discover/blog/introducing-gemma-3/</link>
<guid>https://deepmind.google/discover/blog/introducing-gemma-3/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">Gemma 3是最新的轻量级开放模型，支持140种语言，适用于单个GPU或TPU运行。</p><br /><br /><p><strong>摘要：</strong> Gemma 3是谷歌推出的一款新型轻量级开放模型，旨在实现高效且负责任的人工智能应用。它在包括文本和视觉推理能力在内的多种应用场景中表现出色，支持超过140种语言，提供128k-token的上下文窗口，适用于单个GPU或TPU运行。Gemma 3的多种尺寸选择（1B到27B）允许开发者根据特定硬件需求进行调整。此外，新模型还推出了量化版本，以提高响应速度并减少计算需求。同时，谷歌还发布了ShieldGemma 2，一个基于Gemma 3的图像安全检查工具，旨在促进负责任的AI开发。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/introducing-gemma-3/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 08:00:00 +0000</pubDate>
</item>
<item>
<title>开始使用 Gemini 2.0 Flash 和 Flash-Lite</title>
<link>https://deepmind.google/discover/blog/start-building-with-gemini-20-flash-and-flash-lite/</link>
<guid>https://deepmind.google/discover/blog/start-building-with-gemini-20-flash-and-flash-lite/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">介绍 Gemini 2.0 Flash 和 Flash-Lite 的建设指南。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了 Gemini 2.0 Flash 和 Flash-Lite 的新特性及其应用开发指南，旨在帮助开发者利用这些工具进行高效的应用开发。通过详细的步骤和实例，指导用户快速上手，提升开发效率和应用表现。文章还强调了在不同平台上使用这些工具的优势，为开发者提供了切实可行的建议。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/start-building-with-gemini-20-flash-and-flash-lite/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 18:02:12 +0000</pubDate>
</item>
<item>
<title>Gemini 2.0模型更新：Flash、Flash-Lite和Pro实验版发布</title>
<link>https://deepmind.google/discover/blog/gemini-2-0-is-now-available-to-everyone/</link>
<guid>https://deepmind.google/discover/blog/gemini-2-0-is-now-available-to-everyone/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">Gemini 2.0发布新模型，包括Flash、Flash-Lite和Pro版本，为开发者提供更强大的性能与效率。</p><br /><br /><p><strong>摘要：</strong> Gemini 2.0已向所有人开放，推出多个新模型，包括高效的2.0 Flash和成本效益高的Flash-Lite。此外，2.0 Pro实验版也即将推出，具备最强大的编码性能和处理复杂提示的能力。新模型均具备多模态输入，能在大规模上下文中进行推理，以满足开发者的高效需求。同时，Google DeepMind通过改进的安全性措施，继续致力于确保这些新模型的安全使用。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/gemini-2-0-is-now-available-to-everyone/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 05 Feb 2025 16:00:00 +0000</pubDate>
</item>
<item>
<title>更新前沿安全框架：加强人工智能开发中的安全措施</title>
<link>https://deepmind.google/discover/blog/updating-the-frontier-safety-framework/</link>
<guid>https://deepmind.google/discover/blog/updating-the-frontier-safety-framework/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">更新前沿安全框架，以应对人工智能发展的安全挑战。</p><br /><br /><p><strong>摘要：</strong> 谷歌深度学习更新了前沿安全框架(Frontier Safety Framework)，以强化在人工智能(AGI)发展过程中的安全协议。该框架旨在识别与先进人工智能模型相关的严重风险，并制定相应的安全缓解措施。更新内容包括对关键能力水平(CCLs)的安全级别建议、部署缓解程序的改进以及对欺骗性对齐风险的前瞻性应对。为确保新技术的安全性，开发者需要共同合作建立行业标准，推动安全能力的提升。此框架的实施是应对人工智能研发中潜在危害的关键步骤，强调了全球范围内的协作与责任。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/updating-the-frontier-safety-framework/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 04 Feb 2025 16:41:00 +0000</pubDate>
</item>
<item>
<title>引入FACTS Grounding基准评估大语言模型的真实度</title>
<link>https://deepmind.google/discover/blog/facts-grounding-a-new-benchmark-for-evaluating-the-factuality-of-large-language-models/</link>
<guid>https://deepmind.google/discover/blog/facts-grounding-a-new-benchmark-for-evaluating-the-factuality-of-large-language-models/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文介绍了FACTS Grounding基准，用于评估大语言模型的实际表现和事实准确性。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了FACTS Grounding，一个用于评估大语言模型（LLMs）在回答过程中事实准确性的全新基准，旨在减少模型生成假信息的现象。FACTS Grounding基准提供了1,719个样本实例，要求LLMs生成详尽的、基于指定文档的信息性回答。此外，文章还推出了在线排行榜，展示各大模型在基准测试中的表现。通过多个前沿LLM评估模型的结合，确保评分的客观性与公正性。随着该领域的进展，FACTS Grounding基准将不断更新，以激励行业整体提高技术水平。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/facts-grounding-a-new-benchmark-for-evaluating-the-factuality-of-large-language-models/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 17 Dec 2024 15:29:45 +0000</pubDate>
</item>
<item>
<title>谷歌推出Veo 2、Imagen 3新版本及最新实验Whisk</title>
<link>https://deepmind.google/discover/blog/state-of-the-art-video-and-image-generation-with-veo-2-and-imagen-3/</link>
<guid>https://deepmind.google/discover/blog/state-of-the-art-video-and-image-generation-with-veo-2-and-imagen-3/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">谷歌宣布推出视频生成模型Veo 2和图像生成模型Imagen 3的新版本及实验工具Whisk。</p><br /><br /><p><strong>摘要：</strong> 谷歌近日正式推出了视频生成模型Veo的升级版本Veo 2，以及图像生成模型Imagen 3的最新版本。这两个模型在生成高质量视频和图像方面达到了行业领先水平。Veo 2能够更准确地理解现实世界的物理规律和人类的动作表达，支持用户创建复杂的镜头和场景，分辨率高达4K。而Imagen 3则在艺术风格的多样性和细节表现上有所提升，能够更好地遵循用户的创意提示。与此同时，谷歌还介绍了新实验工具Whisk，结合Imagen 3的能力，使用户能够通过图像创造和混合新的视觉想法。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/state-of-the-art-video-and-image-generation-with-veo-2-and-imagen-3/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 16 Dec 2024 17:01:16 +0000</pubDate>
</item>
<item>
<title>Google发布Gemini 2.0：迈向代理时代的新AI模型</title>
<link>https://deepmind.google/discover/blog/introducing-gemini-20-our-new-ai-model-for-the-agentic-era/</link>
<guid>https://deepmind.google/discover/blog/introducing-gemini-20-our-new-ai-model-for-the-agentic-era/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">Google推出Gemini 2.0，为代理时代提供创新的AI解决方案。</p><br /><br /><p><strong>摘要：</strong> Google DeepMind发布了Gemini 2.0，这一新AI模型旨在应对代理时代的挑战。Gemini 2.0在多模态能力上实现了重要突破，支持原生图像和音频输出，并具备工具使用能力。开发者和受信任的测试人员可以立即访问Gemini 2.0 Flash实验模型，未来将扩展到更多产品中。Gemini 2.0不仅提升了搜索功能，还推动了众多项目的发展，如Project Astra和Project Mariner，旨在创建更加智能的AI助手。此外，Google将安全与责任放在首位，致力于确保新技术的安全使用。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/introducing-gemini-20-our-new-ai-model-for-the-agentic-era/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 11 Dec 2024 15:30:40 +0000</pubDate>
</item>
<item>
<title>Google DeepMind在NeurIPS 2024的创新与研究展示</title>
<link>https://deepmind.google/discover/blog/google-deepmind-at-neurips-2024/</link>
<guid>https://deepmind.google/discover/blog/google-deepmind-at-neurips-2024/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">Google DeepMind将在NeurIPS 2024展示新型AI代理和3D内容生成技术。</p><br /><br /><p><strong>摘要：</strong> Google DeepMind将在即将举行的NeurIPS 2024大会上展示其在智能适应AI代理、3D场景生成和大型语言模型训练方面的最新研究。两篇由DeepMind研究人员主导的论文将获得大会认可，研究涵盖如何通过自然语言命令进行数字任务，以及如何利用多样的控制数据集提升AI代理的适应性和表现。同时，DeepMind将介绍一系列3D生成与模拟技术，以提高内容创建效率，展示如CAT3D等系统在图像转3D方面的突破。此外，DeepMind还将探讨大型语言模型的训练方法、数据优化算法和规划任务的有效性，为AI研究与应用注入新动力。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/google-deepmind-at-neurips-2024/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 05 Dec 2024 17:45:00 +0000</pubDate>
</item>
<item>
<title>GenCast：新一代高精度气象预测模型</title>
<link>https://deepmind.google/discover/blog/gencast-predicts-weather-and-the-risks-of-extreme-conditions-with-sota-accuracy/</link>
<guid>https://deepmind.google/discover/blog/gencast-predicts-weather-and-the-risks-of-extreme-conditions-with-sota-accuracy/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">GenCast通过AI提高气象预测精度，尤其在极端天气方面。</p><br /><br /><p><strong>摘要：</strong> GenCast是一种新型AI气象预测模型，采用概率集成预测方式，显著提升了气象预报的准确性和及时性，尤其是在极端天气事件的预测上。与现有顶尖操作系统相比，GenCast在高达15天的预测中表现更优，准确率达97.2%。该模型利用过去四十年的历史气象数据进行训练，可以同时生成多种可能的天气情境，为决策者提供更全面的天气信息。此外，GenCast的预测性能对如热浪和强风等极端天气的预警能力尤为重要，有助于及时采取预防措施，保障公众安全。Google将该模型开放，以促进气象界的广泛合作与研究发展。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/gencast-predicts-weather-and-the-risks-of-extreme-conditions-with-sota-accuracy/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 15:59:52 +0000</pubDate>
</item>
<item>
<title>Genie 2：大规模基础世界模型的推出</title>
<link>https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/</link>
<guid>https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">Genie 2是一个可生成多样化3D环境的大规模基础世界模型。</p><br /><br /><p><strong>摘要：</strong> Google DeepMind推出了Genie 2，一个能够生成多样化可控3D环境的基础世界模型。该模型基于单一的提示图像，支持人类或AI代理的交互，能够模拟虚拟世界并预测其他代理的行为，具有制作复杂场景和物理效果的能力。Genie 2极大提升了训练和评估AI代理的环境多样性，预计将推进通用人工智能的研究。此外，Genie 2具有快速原型设计的潜力，可以将概念艺术转变为交互环境，从而加速创作过程。通过生成新的交互场景与任务，Genie 2为未来AI模型的训练提供了更丰富的背景与挑战。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 14:23:00 +0000</pubDate>
</item>
<item>
<title>AlphaQubit：谷歌量子计算错误纠正的新突破</title>
<link>https://deepmind.google/discover/blog/alphaqubit-tackles-one-of-quantum-computings-biggest-challenges/</link>
<guid>https://deepmind.google/discover/blog/alphaqubit-tackles-one-of-quantum-computings-biggest-challenges/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">谷歌的AlphaQubit通过AI技术提高量子计算的错误识别与纠正能力。</p><br /><br /><p><strong>摘要：</strong> AlphaQubit是谷歌开发的一种基于AI的量子错误纠正解码器，旨在解决量子计算中普遍存在的错误问题。量子计算机在处理某些复杂问题时具有巨大的潜力，但其对噪声的敏感性限制了其应用。AlphaQubit结合了谷歌DeepMind的机器学习和Quantum AI的错误纠正专长，准确识别量子错误，从而提升量子计算的可靠性与持续性。经过广泛的训练和测试，AlphaQubit在有效性和准确性方面超越了之前的解码器，为量子计算的实用化发展铺平了道路。尽管仍面临速度和规模的挑战，团队正在结合机器学习与量子错误纠正的创新，推动可持续量子计算的实现。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/alphaqubit-tackles-one-of-quantum-computings-biggest-challenges/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 20 Nov 2024 18:00:00 +0000</pubDate>
</item>
<item>
<title>人工智能在科学发现中的变革力量</title>
<link>https://deepmind.google/discover/blog/the-ai-for-science-forum-a-new-era-of-discovery/</link>
<guid>https://deepmind.google/discover/blog/the-ai-for-science-forum-a-new-era-of-discovery/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">论坛聚焦人工智能在科学进步和全球问题中的变革潜力。</p><br /><br /><p><strong>摘要：</strong> 人工智能科学论坛强调了人工智能在科学发现及应对全球挑战方面的重要性与潜力。该论坛呼吁科学界、政策制定者和行业领袖之间的合作，以推动人工智能技术的发展和应用。通过有效的协同努力，人工智能能够为各类科学研究提供创新的方法与工具，从而加速科学进步，并提供解决全球性问题的途径。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/the-ai-for-science-forum-a-new-era-of-discovery/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 19:57:43 +0000</pubDate>
</item>
<item>
<title>推动音频生成技术的前沿发展</title>
<link>https://deepmind.google/discover/blog/pushing-the-frontiers-of-audio-generation/</link>
<guid>https://deepmind.google/discover/blog/pushing-the-frontiers-of-audio-generation/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">文章介绍了Google DeepMind在音频生成领域的最新研究与技术进展。</p><br /><br /><p><strong>摘要：</strong> Google DeepMind在音频生成技术上取得了显著进展，开发出能够生成自然对话的模型，提升了人机交互的自然度和直观性。通过将不同的输入（如文本和语调控制）转化为高质量自然语音，该技术的应用遍及Google的众多产品。新推出的功能支持生成多说话人的长对话，使复杂内容更加易于访问和理解。研究结合了音频编解码和语言建模技术，确保生成音频在快速生成的同时依然保持优质的音质。DeepMind致力于做出更自然、更具表现力的音频生成模型，以期推动音频技术的进一步发展和应用。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/pushing-the-frontiers-of-audio-generation/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 30 Oct 2024 15:00:07 +0000</pubDate>
</item>
<item>
<title>新一代生成式人工智能工具开启音乐创作之门</title>
<link>https://deepmind.google/discover/blog/new-generative-ai-tools-open-the-doors-of-music-creation/</link>
<guid>https://deepmind.google/discover/blog/new-generative-ai-tools-open-the-doors-of-music-creation/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">Google DeepMind推出新的生成式AI工具，使音乐创作更为便捷和可及。</p><br /><br /><p><strong>摘要：</strong> Google DeepMind于2024年发布了新的生成式人工智能工具，旨在提升音乐创作的便捷性和可达性。此次更新包括MusicFX DJ、Music AI Sandbox和YouTube Shorts，借助与音乐行业各方的密切合作，以确保这些工具的设计能够促进创意表达。MusicFX DJ让用户能够实时生成音乐，通过混合文本提示，玩家可以创造独特的音乐风格，且新增的控制功能使得音乐生成更为直观。此外，Music AI Sandbox为音乐创作者提供了一套实验性工具，增强了音乐制作的工作流程。YouTube的Dream Track实验则允许创作者生成高质量的伴奏音乐。这些创新不仅提升了音乐音质，也确保生成的内容具备高效的创作流程，为新一代音乐家开辟了更多的创作空间。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/new-generative-ai-tools-open-the-doors-of-music-creation/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 23 Oct 2024 16:53:55 +0000</pubDate>
</item>
<item>
<title>德米斯·哈萨比斯与约翰·贾姆珀获诺贝尔化学奖</title>
<link>https://deepmind.google/discover/blog/demis-hassabis-john-jumper-awarded-nobel-prize-in-chemistry/</link>
<guid>https://deepmind.google/discover/blog/demis-hassabis-john-jumper-awarded-nobel-prize-in-chemistry/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">德米斯·哈萨比斯和约翰·贾姆珀因开发AlphaFold而共同获得2024年诺贝尔化学奖。该系统革新了蛋白质结构预测。</p><br /><br /><p><strong>摘要：</strong> 2024年10月9日，谷歌DeepMind的联合创始人和首席执行官德米斯·哈萨比斯及谷歌DeepMind主任约翰·贾姆珀因开发AlphaFold而共同荣获诺贝尔化学奖。AlphaFold是一种突破性的人工智能系统，能够根据氨基酸序列预测蛋白质的三维结构。此前，蛋白质结构的预测是一项复杂且耗时的工作。AlphaFold的预测结果已通过公开渠道发布，使来自190个国家的200多万名科学家和研究人员获得了强有力的工具，从而推动了新发现。2021年发表的相关论文成为被引用最多的之一。哈萨比斯在获奖后表示，获得诺贝尔奖是他一生中最大的荣耀，并感谢相关团队的努力。贾姆珀也强调了AI在科学研究中的重要性，指出AlphaFold的成就让计算生物学的潜力得以实现。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/demis-hassabis-john-jumper-awarded-nobel-prize-in-chemistry/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 09 Oct 2024 11:45:00 +0000</pubDate>
</item>
<item>
<title>AlphaChip如何变革计算机芯片设计</title>
<link>https://deepmind.google/discover/blog/how-alphachip-transformed-computer-chip-design/</link>
<guid>https://deepmind.google/discover/blog/how-alphachip-transformed-computer-chip-design/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">AlphaChip利用AI技术革命性地加速了计算机芯片的设计流程，优化了多代TPU芯片布局。</p><br /><br /><p><strong>摘要：</strong> 2020年，Google DeepMind推出了AlphaChip，这是一种基于强化学习的芯片布局设计方法。通过将芯片布局设计视作一项游戏，AlphaChip能在数小时内生成超越人类设计的芯片布局，而这一过程往往需要数周甚至数月。AlphaChip特别适用于设计Google的TPU（张量处理单元），使得高效的AI加速器设计成为可能。该方法不仅提高了设计效率和芯片性能，还已经在Alphabet旗下的多个芯片项目中得到了应用。未来，AlphaChip的潜力将扩展到整个芯片设计周期的各个阶段，推动更加快速、便宜和高效能的芯片设计。AlphaChip的成功也激励了包括MediaTek在内的外部组织进行相关的研究与开发，为芯片设计领域带来了新的生机。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/how-alphachip-transformed-computer-chip-design/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 26 Sep 2024 14:08:00 +0000</pubDate>
</item>
<item>
<title>更新生产就绪的Gemini模型，降低1.5 Pro定价，提高速率限制等</title>
<link>https://deepmind.google/discover/blog/updated-production-ready-gemini-models-reduced-15-pro-pricing-increased-rate-limits-and-more/</link>
<guid>https://deepmind.google/discover/blog/updated-production-ready-gemini-models-reduced-15-pro-pricing-increased-rate-limits-and-more/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">Gemini API和Google AI Studio发布了更新，降低了1.5 Pro定价，并提高了速率限制。</p><br /><br /><p><strong>摘要：</strong> 在2024年9月24日，Google的Gemini API和Google AI Studio团队宣布了一系列更新，包括生产就绪的Gemini模型、降低1.5 Pro的定价以及增加速率限制。这些变化旨在增强用户体验，提供更具竞争力的产品选择，支持开发者在人工智能应用领域的创新。新版本的Gemini模型旨在提高性能和可用性，使其更加适合生产环境，同时降低的定价使更多用户能够使用该服务。增加的速率限制则为开发者提供了更多的调用与使用自由，进一步推动了开发者生态的活跃。这些更新标志着Google在AI领域的持续投入和进步，预计将对开发者社区产生积极影响。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/updated-production-ready-gemini-models-reduced-15-pro-pricing-increased-rate-limits-and-more/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 24 Sep 2024 16:03:03 +0000</pubDate>
</item>
<item>
<title>谷歌深度学习：赋能YouTube创作者与生成式AI</title>
<link>https://deepmind.google/discover/blog/empowering-youtube-creators-with-generative-ai/</link>
<guid>https://deepmind.google/discover/blog/empowering-youtube-creators-with-generative-ai/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">谷歌将推出生成式AI技术，帮助YouTube创作者轻松生成短视频和背景图，激发创意潜能。</p><br /><br /><p><strong>摘要：</strong> 谷歌深度学习团队于2024年9月18日发布了一项新技术，旨在通过生成式AI赋能YouTube创作者。这项技术将通过Dream Screen平台，允许创作者生成短视频背景和六秒独立视频短片，从而帮助他们实现创意视野。创作者首先输入文本提示，Dream Screen利用Imagen 3生成四个不同的图像供选择，随后Veo会基于选定的图像制作高质量的视频。预计在2025年，创作者还将在Dream Screen中能够创建六秒的独立短片。此外，所有生成的内容将被水印标识，以帮助识别AI生成的作品。谷歌希望通过这些新技术，激励更多人以鲜活、变革性的方式实现自己的创意。未来，谷歌将继续改进生成式AI模型，致力于为每个人开启创意的可能性。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/empowering-youtube-creators-with-generative-ai/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 18 Sep 2024 14:30:06 +0000</pubDate>
</item>
<item>
<title>谷歌DeepMind机器人灵巧性的最新进展</title>
<link>https://deepmind.google/discover/blog/advances-in-robot-dexterity/</link>
<guid>https://deepmind.google/discover/blog/advances-in-robot-dexterity/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">DeepMind推出两个新的AI系统，显著提升机器人在复杂高灵巧任务中的表现。</p><br /><br /><p><strong>摘要：</strong> 谷歌DeepMind的机器人团队近期推出了两个新AI系统：ALOHA Unleashed和DemoStart，以帮助机器人学习并执行复杂的高灵巧任务。ALOHA Unleashed支持双臂操作，使得机器人能够通过学习人类示范，成功完成诸如系鞋带、挂衣物和修理机器人的任务，而DemoStart则通过强化学习算法，使机器人在模拟环境中学会复杂技巧，显著减少所需示范次数。这两个系统结合了模拟与现实反馈的优越性，推动了机器人在灵巧操作上的进展，朝着让机器人能高效完成更广泛任务的目标迈进。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/advances-in-robot-dexterity/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 12 Sep 2024 14:00:00 +0000</pubDate>
</item>
<item>
<title>AlphaProteo：前沿人工智能系统设计新型蛋白质，用于生物医学研究</title>
<link>https://deepmind.google/discover/blog/alphaproteo-generates-novel-proteins-for-biology-and-health-research/</link>
<guid>https://deepmind.google/discover/blog/alphaproteo-generates-novel-proteins-for-biology-and-health-research/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">AlphaProteo利用人工智能设计出具特定靶向的新型蛋白质，有望推动药物研发和疾病研究。</p><br /><br /><p><strong>摘要：</strong> AlphaProteo是一个新型人工智能系统，能够生成具有高强度结合能力的蛋白质，这些蛋白质能够与特定靶标分子结合，进而推动药物设计、疾病理解和生物传感器开发等多个领域的研究。该系统通过分析蛋白质数据，能够创建成功结合特定靶标蛋白的新型结合体。AlphaProteo在七种测试靶标上表现出比现有方法高出3至300倍的结合亲和力和更高的实验成功率。经过实验验证后，与外部研究机构的合作证实了AlphaProteo生成的结合体在阻止病毒感染以及其生物功能中的有效性。尽管有较大的成功率，AlphaProteo在针对一些极具挑战性的靶标时仍存在局限性。该系统的进展表明，这项技术将有潜力为基础生命科学研究和生物医学应用带来重要变革。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/alphaproteo-generates-novel-proteins-for-biology-and-health-research/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 05 Sep 2024 15:00:00 +0000</pubDate>
</item>
<item>
<title>FermiNet：从第一原理研究量子物理和化学</title>
<link>https://deepmind.google/discover/blog/ferminet-quantum-physics-and-chemistry-from-first-principles/</link>
<guid>https://deepmind.google/discover/blog/ferminet-quantum-physics-and-chemistry-from-first-principles/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">FermiNet 为量子化学提供了一种新方法，利用深度学习精确模拟电子状态及分子激发态。</p><br /><br /><p><strong>摘要：</strong> FermiNet 是一种基于深度学习的神经网络架构，旨在解决量子力学的基本方程，进而推动计算化学的进步。它能够准确描述大规模电子集合的量子态，为研究化学反应以及新材料的探索提供了强大工具。文章回顾了量子力学的发展历程，分析了传统方法在电子态代表方面的局限性，提出 FermiNet 通过引入反对称性来高效解决电子状态表示问题。同时，FermiNet 在处理从基态到激发态的转变中，也展现了显著的优势。2024 年的最新研究表明，FermiNet 在对于激发态的能量计算中表现出超过传统方法的精确度。这一进展为理解物质与光的相互作用提供了新的视角，将有助于未来技术的发展如太阳能电池和LED。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/ferminet-quantum-physics-and-chemistry-from-first-principles/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 22 Aug 2024 19:00:00 +0000</pubDate>
</item>
<item>
<title>新一代非洲人才利用前沿人工智能应对科学挑战</title>
<link>https://deepmind.google/discover/blog/a-new-generation-of-african-talent-brings-cutting-edge-ai-to-scientific-challenges/</link>
<guid>https://deepmind.google/discover/blog/a-new-generation-of-african-talent-brings-cutting-edge-ai-to-scientific-challenges/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">非洲新一代的AI人才致力于利用人工智能解决食品安全、医疗及宇宙探索等科学挑战。</p><br /><br /><p><strong>摘要：</strong> Google DeepMind致力于支持非洲下一代人工智能领导者，促进全球AI社区的多样性和包容性。通过与非洲数学科学中心(AIMS)的合作，该组织为杰出的本地学生提供全额奖学金和先进研究的机会。第一届毕业生在南非开普敦的AIMS校园举行的毕业典礼上分享了他们在AI研究中的经验。Béria Chingnabé Kalpélbé希望利用AI提升农业可持续性，Olivier Mahumawon Adjagba专注于利用AI改进登革热传播模型，Diffo Mboudjiho Annette Dariose则期望通过AI探索宇宙。该计划不仅鼓励学生进行科学发现，还推动当地社区及全球的进步。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/a-new-generation-of-african-talent-brings-cutting-edge-ai-to-scientific-challenges/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 05 Aug 2024 12:00:00 +0000</pubDate>
</item>
<item>
<title>生成性人工智能误用现状的分析与应对</title>
<link>https://deepmind.google/discover/blog/mapping-the-misuse-of-generative-ai/</link>
<guid>https://deepmind.google/discover/blog/mapping-the-misuse-of-generative-ai/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">研究分析生成性人工智能的误用方式，助力技术的安全与责任使用。</p><br /><br /><p><strong>摘要：</strong> 这篇文章分析了生成性人工智能（AI）在2019年至2024年间的误用方式，为安全和负责任的技术建设提供指导。通过对近200条媒体报道的汇总，研究者们识别并分类了生成性AI的常见误用策略，包括利用生成性AI进行的欺诈、操控以及侵犯他人形象等行为。研究指出，恶意行为者可利用消费者级的生成性AI工具进行剽窃和诈骗，而这类行为的可接触性显著增加了信息操控的难度与影响力。此外，文章还探讨了非恶意的生成性AI应用例，包括在政治活动中的模糊真实性与透明度的界限。为了应对潜在的滥用，文章建议提升公众的生成性AI素养，完善相应的技术与政策。通过对生成性AI滥用的理解，研究旨在为政策制定者和工业领域提供相应的安全评估和缓解策略。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/mapping-the-misuse-of-generative-ai/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 02 Aug 2024 10:50:58 +0000</pubDate>
</item>
<item>
<title>Gemma Scope：帮助安全社区深入理解语言模型的内部运作</title>
<link>https://deepmind.google/discover/blog/gemma-scope-helping-the-safety-community-shed-light-on-the-inner-workings-of-language-models/</link>
<guid>https://deepmind.google/discover/blog/gemma-scope-helping-the-safety-community-shed-light-on-the-inner-workings-of-language-models/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">Gemma Scope 提供了用于语言模型可解释性的稀疏自编码器工具，助力研究人员理解语言模型的内部特征。</p><br /><br /><p><strong>摘要：</strong> Gemma Scope 是一套开放的稀疏自编码器工具，旨在帮助研究人员更好地理解谷歌 DeepMind 的语言模型 Gemma 2 的内部工作原理。借助这些自编码器，研究人员能够将语言模型的激活输出分解为一小部分特征，从而揭示模型如何处理文本输入。尽管最初的可解释性研究面临将特征与每个神经元对应的挑战，但稀疏自编码器通过发现实际使用的特征，弥补了这一缺陷。Gemma Scope 包含超过 400 个稀疏自编码器和超过 3000 万个学习特征，推动了对语言模型如何演变和相互作用的深入研究。此次发布希望能促进对大型模型的可解释性研究，帮助解决如幻觉和安全性风险等问题。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/gemma-scope-helping-the-safety-community-shed-light-on-the-inner-workings-of-language-models/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 31 Jul 2024 15:59:19 +0000</pubDate>
</item>
<item>
<title>人工智能在国际数学奥林匹克竞赛中的突破性进展</title>
<link>https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/</link>
<guid>https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">深度学习模型AlphaProof和AlphaGeometry 2在国际数学奥林匹克竞赛中表现优异，解决问题达银奖水平。</p><br /><br /><p><strong>摘要：</strong> Google DeepMind最新研发的AI模型AlphaProof和AlphaGeometry 2在2024年国际数学奥林匹克竞赛（IMO）中取得了显著成就，解决了六个问题中的四个，达到银奖标准。IMO是全球最具声望的青少年数学比赛，每年吸引顶尖数学天才能耗费数千小时进行准备。AlphaProof系统通过形式化的数学语言训练，并结合强化学习策略，成功地解决了包括最难题在内的代数和数论问题。AlphaGeometry 2则在几何问题上表现出色，显著提高了解题的速度和精准度。尽管尚有两个组合问题未能解决，但整体得分达到28分，接近金奖门槛。此成果显示了人工智能在数学推理领域的新突破，未来AI工具将与数学家协作，更高效地探索复杂问题和证明。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 25 Jul 2024 15:29:00 +0000</pubDate>
</item>
<item>
<title>谷歌DeepMind在ICML 2024的研究展示</title>
<link>https://deepmind.google/discover/blog/google-deepmind-at-icml-2024/</link>
<guid>https://deepmind.google/discover/blog/google-deepmind-at-icml-2024/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">谷歌DeepMind将在ICML 2024展示超过80篇研究论文，探讨AGI、多模态生成AI及其它前沿技术。</p><br /><br /><p><strong>摘要：</strong> 2024年国际机器学习大会（ICML）将于7月21日至27日在奥地利维也纳召开，谷歌DeepMind将展示超过80篇研究论文，并展示其多模态生成AI模型及教育AI模型等。会议将探讨人工智能的未来发展，包括人工通用智能（AGI）的定义，一种分类框架将在会上介绍，涵盖从非AI计算器到新兴AI模型的不同系统。此外，DeepMind还将讨论如何高效、负责任地扩展AI系统，包括快速评估新场景的创新方法，以及基于博弈论的调整大型语言模型与人类偏好的策略。最后，研究小组还将展示生成视频和音频的新技术，以及一种能够基于文本指令检索更丰富关系图像的系统，为AI社区提供新的创意和工具。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/google-deepmind-at-icml-2024/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 19 Jul 2024 10:00:00 +0000</pubDate>
</item>
<item>
<title>生成视频音频技术的最新进展</title>
<link>https://deepmind.google/discover/blog/generating-audio-for-video/</link>
<guid>https://deepmind.google/discover/blog/generating-audio-for-video/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">Google DeepMind最新研究展示了通过视频生成音频的前沿技术V2A，结合自然语言提示生成丰富音效。</p><br /><br /><p><strong>摘要：</strong> Google DeepMind的Generative Media团队在生成视频音频（V2A）技术领域取得了重要进展。该技术通过分析视频像素和自然语言文本提示，为静音视频生成与情节相匹配的丰富声轨，从而实现音画同步。V2A技术可以与视频生成模型配对，为视频生成戏剧性的音乐、真实的音效或对话。同时，V2A能够为传统素材（如档案录像和默片）产生声轨，扩大了创作的可能性。用户可以通过定义‘正面提示’或‘负面提示’来精确控制生成的音频，实现快速实验和选择最合适的音轨。尽管V2A在生成音频的质量方面受到视频输入质量的影响，团队仍在进行进一步研究以克服现有局限性，改善与口型运动的同步。与此同时，Google DeepMind还承诺以负责任的方式开发和部署AI技术，确保V2A技术对创作社区产生积极影响。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/generating-audio-for-video/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 17 Jun 2024 16:00:00 +0000</pubDate>
</item>
<item>
<title>展望AI首尔峰会：推动全球前沿AI安全合作</title>
<link>https://deepmind.google/discover/blog/looking-ahead-to-the-ai-seoul-summit/</link>
<guid>https://deepmind.google/discover/blog/looking-ahead-to-the-ai-seoul-summit/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">AI首尔峰会将继续推动国际间的前沿AI安全合作，确保技术进步带来的利益最大化。</p><br /><br /><p><strong>摘要：</strong> AI首尔峰会旨在基于前一年度英国Bletchley Park的国际AI安全峰会，促进全球合作以应对前沿AI的潜在风险。自峰会以来，AI领域持续创新，包括Google DeepMind在生物分子领域的重大突破和AI助手的进展。然而，快速发展的AI技术引发了新的安全挑战，需要国际社会共同努力解决。峰会将关注建立共识，以应对未来潜在风险，并倡导制定全球标准来评估和管理这些风险。此外，峰会鼓励各国在安全测试和治理框架方面推进协调行动，以避免各国之间的治理碎片化。最终，AI首尔峰会有望成为全球AI安全治理的常设平台，推动社会最大化受益于AI技术。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/looking-ahead-to-the-ai-seoul-summit/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 20 May 2024 07:00:00 +0000</pubDate>
</item>
<item>
<title>前沿安全框架介绍</title>
<link>https://deepmind.google/discover/blog/introducing-the-frontier-safety-framework/</link>
<guid>https://deepmind.google/discover/blog/introducing-the-frontier-safety-framework/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">谷歌DeepMind推出前沿安全框架，旨在识别和缓解未来AI模型风险。</p><br /><br /><p><strong>摘要：</strong> 谷歌DeepMind今天发布了其前沿安全框架，该框架旨在分析和减轻未来高级AI模型带来的风险。框架的核心在于识别可能引发严重伤害的AI能力，并设定“关键能力水平”(Critical Capability Levels, CCLs)。通过定期评估模型以检测是否达到这些能力水平，并实施相应的缓解计划，以确保安全和防止滥用。框架最初关注四个领域：自治、生物安全、网络安全和机器学习研发。该框架旨在与已存在的AI责任和安全措施相辅相成，并希望在2025年初实现全面实施。谷歌承诺将定期审查和完善该框架，并强调与行业、学术界及政府的协作，以制定安全评估的标准和最佳实践。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/introducing-the-frontier-safety-framework/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 17 May 2024 14:00:00 +0000</pubDate>
</item>
<item>
<title>Gemini系列模型更新：推出1.5 Flash与Project Astra</title>
<link>https://deepmind.google/discover/blog/gemini-breaks-new-ground-a-faster-model-longer-context-and-ai-agents/</link>
<guid>https://deepmind.google/discover/blog/gemini-breaks-new-ground-a-faster-model-longer-context-and-ai-agents/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">Gemini系列模型进行更新，推出新款1.5 Flash和Project Astra，人工智能助手新愿景。</p><br /><br /><p><strong>摘要：</strong> 我们很高兴地宣布关于Gemini家族模型的一系列更新。其中，新推出的1.5 Flash是我们为实现速度和效率而设计的轻量级模型，将允许用户在不牺牲性能的情况下享受更快的响应能力。此外，Project Astra则是我们对未来人工智能助手的愿景，旨在通过创新技术和改进交互方式，提升用户体验。我们致力于不断提升Gemini系列的功能，以适应不断变化的市场需求，并为用户提供更高效、更智能的工具。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/gemini-breaks-new-ground-a-faster-model-longer-context-and-ai-agents/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 14 May 2024 17:58:00 +0000</pubDate>
</item>
<item>
<title>全新发布：Veo与Imagen 3及音乐AI沙盒演示</title>
<link>https://deepmind.google/discover/blog/new-generative-media-models-and-tools-built-with-and-for-creators/</link>
<guid>https://deepmind.google/discover/blog/new-generative-media-models-and-tools-built-with-and-for-creators/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">我们推出了Veo和Imagen 3，展示高定义视频和高质量图像生成能力。同时发布音乐AI沙盒的全新演示录音。</p><br /><br /><p><strong>摘要：</strong> 我们很高兴地推出Veo，这是我们最新、最强大的生成高定义视频的模型，以及Imagen 3，这是我们最高质量的文本到图像生成模型。此外，我们还分享了使用我们的音乐AI沙盒创建的新演示录音。这些新工具将强化我们在AI创作领域的能力，让用户能够更轻松地创造出精彩的视觉和音乐作品，无论是个人创作还是商业用途。通过Veo和Imagen 3，用户现在可以在视频和图像生成方面实现更高的精度和质量，而音乐AI沙盒则为音频创作提供了更多的灵活性和创新空间。这些新品旨在推动创意产业的进步，让更多的人受益于尖端的技术。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/new-generative-media-models-and-tools-built-with-and-for-creators/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 14 May 2024 17:57:00 +0000</pubDate>
</item>
<item>
<title>Google DeepMind推出SynthID：水印AI生成文本和视频</title>
<link>https://deepmind.google/discover/blog/watermarking-ai-generated-text-and-video-with-synthid/</link>
<guid>https://deepmind.google/discover/blog/watermarking-ai-generated-text-and-video-with-synthid/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">SynthID是一种新颖的水印技术，用于标识AI生成的文本和视频，有助于识别和控制虚假信息的传播。</p><br /><br /><p><strong>摘要：</strong> Google DeepMind于2024年5月14日推出了一种新颖的水印技术SynthID，用于AI生成的文本和视频。这项技术旨在为生成内容提供可识别的标记，以应对信息传播中可能发生的误导和滥用。SynthID通过在文本生成过程中嵌入不可察觉的水印，以调节生成词汇的概率分布，从而构建与AI生成内容相关的标记。该技术在较长文本生成时表现最佳，但在对事实性问题的响应中效果较差。关于视频，SynthID为每一帧嵌入水印，确保其在视觉上不被察觉。Google计划在未来发布更详细的研究，并将SynthID开源，以推动该技术在更广泛的AI生态系统中的应用。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/watermarking-ai-generated-text-and-video-with-synthid/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 14 May 2024 17:56:00 +0000</pubDate>
</item>
<item>
<title>AlphaFold 3：深入探索生命分子的结构与相互作用</title>
<link>https://deepmind.google/discover/blog/alphafold-3-predicts-the-structure-and-interactions-of-all-lifes-molecules/</link>
<guid>https://deepmind.google/discover/blog/alphafold-3-predicts-the-structure-and-interactions-of-all-lifes-molecules/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">AlphaFold 3 是谷歌DeepMind和Isomorphic Labs开发的新AI模型，能精准预测生物分子的结构和相互作用。</p><br /><br /><p><strong>摘要：</strong> 谷歌DeepMind与Isomorphic Labs联合推出的AlphaFold 3是一个革新的人工智能模型，旨在准确预测生命分子的结构及其相互作用。AlphaFold 3不仅能解析蛋白质的结构，还能处理DNA、RNA和配体等多种生物分子，预测精度相比以往模型提高了50%以上。这一技术的提高将推动生物学的研究和药物开发，帮助科学家理解细胞内复杂的分子机制。通过AlphaFold Server，研究人员可以方便地进行非商业性研究，探索生物学的开放问题。此外，谷歌DeepMind采用负责任的方法，确保新技术的合理使用，促进科学发现。AlphaFold 3的推出，标志着科学探索的新篇章，期待其为生物学和药物开发带来的深远影响。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/alphafold-3-predicts-the-structure-and-interactions-of-all-lifes-molecules/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 08 May 2024 16:00:00 +0000</pubDate>
</item>
<item>
<title>Google DeepMind在2024年国际学习表示创新研究</title>
<link>https://deepmind.google/discover/blog/google-deepmind-at-iclr-2024/</link>
<guid>https://deepmind.google/discover/blog/google-deepmind-at-iclr-2024/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">Google DeepMind将在2024年ICLR大会上展示其在AI领域的重要研究和创新，如LLM驱动的代理和动态场景转换器等。</p><br /><br /><p><strong>摘要：</strong> 即将于2024年5月7日至11日在维也纳举行的国际学习表示（ICLR）将汇聚全球AI研究人员。Google DeepMind副总裁Raia Hadsell将发表主题演讲，回顾过去20年的AI发展。DeepMind将展示超过70篇论文，涵盖多个重要研究领域。其中，研究团队提出了新的大语言模型（LLM）代理，能够自主学习并有效执行复杂任务，并探索了如何提升LLM的解决问题能力和优化代码生成的效率。此外，Dynamic Scene Transformer（DyST）模型可以从真实世界的单摄像机视频中提取三维对象和运动表现。研究还关注机器感知中的因果推理、决策不确定性以及博弈论中的纳什均衡问题。Google DeepMind希望借此活动建立积极的AI研究社区，推动学术合作与交流。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/google-deepmind-at-iclr-2024/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 03 May 2024 13:39:00 +0000</pubDate>
</item>
<item>
<title>先进人工智能助手的伦理问题</title>
<link>https://deepmind.google/discover/blog/the-ethics-of-advanced-ai-assistants/</link>
<guid>https://deepmind.google/discover/blog/the-ethics-of-advanced-ai-assistants/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">探讨先进AI助手的潜力与风险，强调人类价值对齐的重要性。</p><br /><br /><p><strong>摘要：</strong> 文章探讨了先进人工智能助手的潜力与可能带来的风险，特别是在用户及其社会的影响。随着通用基础模型的发展，AI助手将在人们的生活中扮演重要角色，例如管理日常生活、职业、教育及社交等方面。文章强调了人类价值与AI助手之间的对齐的重要性，指出更高的自主性可能带来的意外和滥用风险。也讨论了AI助手与用户之间沟通的复杂性，强调了用户识别和保持控制的重要性。此外，为避免集体行动问题，AI助手需要有效协作。最后，文章呼吁展开更多的评估与前瞻性研究，以便更好地管理这些新技术的风险，促进其负责任的使用。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/the-ethics-of-advanced-ai-assistants/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 10:00:00 +0000</pubDate>
</item>
<item>
<title>TacticAI：足球战术的人工智能助手</title>
<link>https://deepmind.google/discover/blog/tacticai-ai-assistant-for-football-tactics/</link>
<guid>https://deepmind.google/discover/blog/tacticai-ai-assistant-for-football-tactics/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">TacticAI是一个由Google DeepMind与利物浦足球俱乐部合作开发的AI系统，旨在提供足球战术，特别是角球方面的建议。</p><br /><br /><p><strong>摘要：</strong> TacticAI是Google DeepMind与利物浦足球俱乐部合作开发的一个完整的人工智能系统，旨在为教练提供战术建议，尤其是在角球情况下。该系统结合了预测和生成模型，通过分析历史角球数据，帮助教练制定和调整战术。TacticAI采用几何深度学习的方法，将角球情况转化为图形表示，以便更好地预测角球的结果，并辅助教练设计更有效的战术。经过与足球专家的合作及验证，TacticAI的建议在90%的情况下被专家偏好，显示出其在帮助教练优化战术的潜力。该项目展示了人工智能如何在动态体育环境中创新性地应用，并对未来研究提供了新的思路。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/tacticai-ai-assistant-for-football-tactics/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 16:03:00 +0000</pubDate>
</item>
<item>
<title>深度学习在3D虚拟环境中的应用研究：可扩展可指令多世界代理SIMA</title>
<link>https://deepmind.google/discover/blog/sima-generalist-ai-agent-for-3d-virtual-environments/</link>
<guid>https://deepmind.google/discover/blog/sima-generalist-ai-agent-for-3d-virtual-environments/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文介绍了SIMA，一个能够理解自然语言并在多种3D游戏中执行任务的AI代理。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了一种新研究的成果：可扩展可指令多世界代理（SIMA）。SIMA能够理解自然语言指令，并在多个3D虚拟游戏环境中执行任务。Google DeepMind合作八家游戏开发公司，共同训练和测试SIMA在九款不同游戏中的表现。与传统的单一游戏AI相比，SIMA展示了其在复杂任务中的通用能力。这项研究不仅验证了AI系统在面对多样化环境时的学习能力，还为未来一般性AI的开发奠定了基础。SIMA模型结合了视觉和记忆功能，能够根据提供的指令进行键鼠操作，进而完成任务。这一成就为AI在更广泛的实际应用中带来了可能性，期待未来对其训练环境的进一步拓展和高级模型的开发。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/sima-generalist-ai-agent-for-3d-virtual-environments/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 13 Mar 2024 14:00:00 +0000</pubDate>
</item>
<item>
<title>谷歌推出新一代开放模型Gemma</title>
<link>https://deepmind.google/discover/blog/gemma-introducing-new-state-of-the-art-open-models/</link>
<guid>https://deepmind.google/discover/blog/gemma-introducing-new-state-of-the-art-open-models/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">谷歌推出Gemma模型，助力负责任的AI开发，提供稳定和高效的AI工具。</p><br /><br /><p><strong>摘要：</strong> 谷歌宣布推出Gemma开放模型，这是基于Gemini模型研究和技术开发的新一代轻量级开放人工智能模型。Gemma模型旨在支持开发者和研究人员负责任地构建AI应用。此次发布包括两个不同大小的模型权重，并且提供了预训练和说明调优变体。此外，谷歌还发布了与Gemma一起的工具包，以协助开发者进行安全可靠的AI应用开发，包括安全分类、调试工具和模型构建的最佳实践指南。Gemma模型支持多种主要机器学习框架，并可以在各种设备上运行，确保行业领先的性能。谷歌还为研究提供免费访问和资金支持，鼓励开发者和研究人员利用Gemma推动AI创新。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/gemma-introducing-new-state-of-the-art-open-models/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 21 Feb 2024 13:06:00 +0000</pubDate>
</item>
<item>
<title>谷歌推出下一代AI模型：Gemini 1.5</title>
<link>https://deepmind.google/discover/blog/our-next-generation-model-gemini-15/</link>
<guid>https://deepmind.google/discover/blog/our-next-generation-model-gemini-15/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">谷歌发布Gemini 1.5，具有更强的性能和长上下文理解能力，支持多种任务。</p><br /><br /><p><strong>摘要：</strong> 谷歌宣布推出其下一代AI模型Gemini 1.5，该模型在多维度上具有显著提升，包括长上下文理解的突破能力。Gemini 1.5 Pro是首个发布的版本，具有128,000个标准上下文窗口，但部分开发者和企业客户可以体验最高1,000,000个的上下文窗口。该模型采用了更高效的专家网络架构（MoE），能快速学习复杂任务并提高训练效率。通过扩展的上下文窗口，1.5 Pro能够处理大量信息，例如长达1小时的视频或超过700,000个单词的文本。此外，其在文本、代码、图像、音频和视频等评估中表现优于前代模型，展示了优秀的推理能力和多模态理解。为确保伦理和安全，谷歌对模型进行严格测试，确保负责任的发布。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/our-next-generation-model-gemini-15/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 15 Feb 2024 15:00:00 +0000</pubDate>
</item>
<item>
<title>谷歌Gemini更新：Sundar Pichai推介Ultra 1.0与Gemini Advanced</title>
<link>https://deepmind.google/discover/blog/google-gemini-update-sundar-pichai-2024/</link>
<guid>https://deepmind.google/discover/blog/google-gemini-update-sundar-pichai-2024/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">谷歌推出Gemini Advanced及Ultra 1.0，提升AI在各产品中的应用。</p><br /><br /><p><strong>摘要：</strong> 谷歌在AI领域的持续投入取得了显著进展，尤其是在搜索和其他产品中。最新发布的Ultra 1.0模型在知识和问题解决能力上超越了人类专家，特别是在57个学科的MMLU测试中表现突出。Gemini Advanced是新一代的AI产品，改进了之前的Bard，支持更复杂的推理、指令执行和创意合作。同时，Gemini模型还会应用于Google Workspace和Google Cloud，增强用户的工作效率和安全性。通过订阅新推出的AI Premium计划，用户将能够体验到Gemini的丰富功能，并将其应用于Gmail、Docs等多个平台。谷歌计划在未来几周内继续开发和推广其Gemini系列产品，开发者的参与至关重要。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/google-gemini-update-sundar-pichai-2024/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 08 Feb 2024 13:00:00 +0000</pubDate>
</item>
<item>
<title>AlphaGeometry：奥林匹克级别几何题解AI系统</title>
<link>https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/</link>
<guid>https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">AlphaGeometry是一个先进的AI系统，能够在几何题上达到与人类金牌得主相近的水平。</p><br /><br /><p><strong>摘要：</strong> AlphaGeometry是Google DeepMind推出的一种AI系统，旨在解决复杂的几何问题，表现出色，达到接近人类奥林匹克金牌选手的水平。在2024年发布的论文中，AlphaGeometry在一项包含30道奥林匹克几何题的测试中，成功解决了其中25道，而之前的最高水平仅能解决10道。这一系统结合了神经语言模型和符号推理引擎，通过生成大量合成训练数据，使AI能够从头开始学习几何。AlphaGeometry采用神经符号化方法，利用语言模型预测可能有用的新构造，以帮助推理引擎找到解决方案。通过证明和验证其解决方案的结构，AlphaGeometry展示了AI在逻辑推理和知识发现方面的提升。该系统被认为是在数学推理领域的一个重要里程碑，未来有望推动更高级和通用AI系统的发展。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 17 Jan 2024 16:00:00 +0000</pubDate>
</item>
<item>
<title>塑造先进机器人未来：Google DeepMind的突破性进展</title>
<link>https://deepmind.google/discover/blog/shaping-the-future-of-advanced-robotics/</link>
<guid>https://deepmind.google/discover/blog/shaping-the-future-of-advanced-robotics/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">Google DeepMind推出AutoRT、SARA-RT和RT-Trajectory，推动机器人技术向未来迈进，提升决策速度与环境理解能力。</p><br /><br /><p><strong>摘要：</strong> Google DeepMind于2024年发布了一系列机器人研究进展，包括AutoRT、SARA-RT和RT-Trajectory，这些创新目标是将机器人技术发展到新的高度。AutoRT结合大规模模型，用于高效收集真实世界的数据，促进机器人的学习和决策能力。SARA-RT则针对机器学习模型的效率进行了优化，使得机器人决策的速度和性能得以提升。RT-Trajectory通过在训练视频上叠加2D轨迹草图，帮助机器人更好地理解任务，并在未见任务上显著提高成功率。这些系统共同构建了更先进的机器人基础，推动机器人在复杂环境中的应用与发展。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/shaping-the-future-of-advanced-robotics/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 04 Jan 2024 11:39:00 +0000</pubDate>
</item>
<item>
<title>经过干扰的图像对人类感知的影响研究</title>
<link>https://deepmind.google/discover/blog/images-altered-to-trick-machine-vision-can-influence-humans-too/</link>
<guid>https://deepmind.google/discover/blog/images-altered-to-trick-machine-vision-can-influence-humans-too/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">研究发现，针对计算机视觉的干扰图像也会影响人类的感知，表明人机视觉存在相似性。</p><br /><br /><p><strong>摘要：</strong> 最新研究表明，经过微妙修改的数字图像，不仅能够欺骗计算机视觉系统，也会影响人类的视觉判断。研究表明，尽管人类和机器在视觉处理上存在差异，但在经过对图像的对抗性干扰时，人类判断却会受到影响。通过控制实验，研究发现，即使在像素调整未超过2级的情况下，参与者在选择与特定目标匹配的图像时，选择的偏向性显著高于偶然选择的50%概率。这一发现提示人类视觉在某种程度上受到机器视觉欺骗手段的影响，从而为AI安全性和稳定性研究提供了重要的见解，强调了深化对这些现象的理解的重要性。未来的研究应考虑如何将这些发现用于提高计算机视觉模型在实际应用中的稳健性。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/images-altered-to-trick-machine-vision-can-influence-humans-too/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 02 Jan 2024 16:00:00 +0000</pubDate>
</item>
<item>
<title>2023：人工智能与计算领域的突破性进展</title>
<link>https://deepmind.google/discover/blog/2023-a-year-of-groundbreaking-advances-in-ai-and-computing/</link>
<guid>https://deepmind.google/discover/blog/2023-a-year-of-groundbreaking-advances-in-ai-and-computing/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">2023年，谷歌DeepMind在人工智能产品与技术上取得显著进展，推动了多个应用领域的发展。</p><br /><br /><p><strong>摘要：</strong> 2023年，谷歌DeepMind在人工智能（AI）和计算的研究及其实际应用上取得了令人瞩目的进展。该年中，生成式AI引发了全球关注，相关应用在图像、音乐和文本创作等方面展现了非凡的创造力。DeepMind推出了多款AI模型，包括PaLM 2和Gemini等，显著提升了产品功能和用户体验。此外，研究团队在机器学习和AI领域发表了重要成果，涉及视觉任务、算法优化和多模态模型等。通过与多方合作，团队还在气候变化、医疗和科学研究等领域的应用上，展现了AI的潜力。责任和透明性的设计成为AI发展的重要议题，DeepMind致力于减少AI系统的风险，以推动更广泛的社会益处。整体而言，2023年标志着AI技术和应用领域的重大进步，为未来的发展奠定了基础。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://deepmind.google/discover/blog/2023-a-year-of-groundbreaking-advances-in-ai-and-computing/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 22 Dec 2023 13:30:00 +0000</pubDate>
</item>
<item>
<title>FunSearch: Making new discoveries in mathematical sciences using Large Language Models</title>
<link>https://deepmind.google/discover/blog/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models/</link>
<guid>https://deepmind.google/discover/blog/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models/</guid>
<content:encoded><![CDATA[
In a paper published in Nature, we introduce FunSearch, a method for searching for “functions” written in computer code, and find new solutions in mathematics and computer science. FunSearch works by pairing a pre-trained LLM, whose goal is to provide creative solutions in the form of computer code, with an automated “evaluator”, which guards against hallucinations and incorrect ideas.
]]></content:encoded>
<pubDate>Thu, 14 Dec 2023 16:00:00 +0000</pubDate>
</item>
<item>
<title>Google DeepMind at NeurIPS 2023</title>
<link>https://deepmind.google/discover/blog/google-deepmind-at-neurips-2023/</link>
<guid>https://deepmind.google/discover/blog/google-deepmind-at-neurips-2023/</guid>
<content:encoded><![CDATA[
The Neural Information Processing Systems (NeurIPS) is the largest artificial intelligence (AI) conference in the world. NeurIPS 2023 will be taking place December 10-16 in New Orleans, USA.Teams from across Google DeepMind are presenting more than 150 papers at the main conference and workshops.
]]></content:encoded>
<pubDate>Fri, 08 Dec 2023 15:01:00 +0000</pubDate>
</item>
<item>
<title>Introducing Gemini: our largest and most capable AI model</title>
<link>https://deepmind.google/discover/blog/introducing-gemini-our-largest-and-most-capable-ai-model/</link>
<guid>https://deepmind.google/discover/blog/introducing-gemini-our-largest-and-most-capable-ai-model/</guid>
<content:encoded><![CDATA[
Making AI more helpful for everyone
]]></content:encoded>
<pubDate>Wed, 06 Dec 2023 15:13:00 +0000</pubDate>
</item>
<item>
<title>Millions of new materials discovered with deep learning</title>
<link>https://deepmind.google/discover/blog/millions-of-new-materials-discovered-with-deep-learning/</link>
<guid>https://deepmind.google/discover/blog/millions-of-new-materials-discovered-with-deep-learning/</guid>
<content:encoded><![CDATA[
We share the discovery of 2.2 million new crystals  –  equivalent to nearly 800 years’ worth of knowledge. We introduce Graph Networks for Materials Exploration (GNoME), our new deep learning tool that dramatically increases the speed and efficiency of discovery by predicting the stability of new materials.
]]></content:encoded>
<pubDate>Wed, 29 Nov 2023 16:04:00 +0000</pubDate>
</item>
<item>
<title>Transforming the future of music creation</title>
<link>https://deepmind.google/discover/blog/transforming-the-future-of-music-creation/</link>
<guid>https://deepmind.google/discover/blog/transforming-the-future-of-music-creation/</guid>
<content:encoded><![CDATA[
Announcing our most advanced music generation model and two new AI experiments, designed to open a new playground for creativity
]]></content:encoded>
<pubDate>Thu, 16 Nov 2023 07:20:00 +0000</pubDate>
</item>
<item>
<title>Empowering the next generation for an AI-enabled world</title>
<link>https://deepmind.google/discover/blog/empowering-the-next-generation-for-an-ai-enabled-world/</link>
<guid>https://deepmind.google/discover/blog/empowering-the-next-generation-for-an-ai-enabled-world/</guid>
<content:encoded><![CDATA[
Experience AI's course and resources are expanding on a global scale
]]></content:encoded>
<pubDate>Wed, 15 Nov 2023 10:00:00 +0000</pubDate>
</item>
<item>
<title>GraphCast: AI model for faster and more accurate global weather forecasting</title>
<link>https://deepmind.google/discover/blog/graphcast-ai-model-for-faster-and-more-accurate-global-weather-forecasting/</link>
<guid>https://deepmind.google/discover/blog/graphcast-ai-model-for-faster-and-more-accurate-global-weather-forecasting/</guid>
<content:encoded><![CDATA[
We introduce GraphCast, a state-of-the-art AI model able to make medium-range weather forecasts with unprecedented accuracy
]]></content:encoded>
<pubDate>Tue, 14 Nov 2023 15:00:00 +0000</pubDate>
</item>
<item>
<title>A glimpse of the next generation of AlphaFold</title>
<link>https://deepmind.google/discover/blog/a-glimpse-of-the-next-generation-of-alphafold/</link>
<guid>https://deepmind.google/discover/blog/a-glimpse-of-the-next-generation-of-alphafold/</guid>
<content:encoded><![CDATA[
Progress update: Our latest AlphaFold model shows significantly improved accuracy and expands coverage beyond proteins to other biological molecules, including ligands.
]]></content:encoded>
<pubDate>Tue, 31 Oct 2023 13:00:00 +0000</pubDate>
</item>
<item>
<title>Evaluating social and ethical risks from generative AI</title>
<link>https://deepmind.google/discover/blog/evaluating-social-and-ethical-risks-from-generative-ai/</link>
<guid>https://deepmind.google/discover/blog/evaluating-social-and-ethical-risks-from-generative-ai/</guid>
<content:encoded><![CDATA[
Introducing a context-based framework for comprehensively evaluating the social and ethical risks of AI systems
]]></content:encoded>
<pubDate>Thu, 19 Oct 2023 15:00:00 +0000</pubDate>
</item>
<item>
<title>Scaling up learning across many different robot types</title>
<link>https://deepmind.google/discover/blog/scaling-up-learning-across-many-different-robot-types/</link>
<guid>https://deepmind.google/discover/blog/scaling-up-learning-across-many-different-robot-types/</guid>
<content:encoded><![CDATA[
Robots are great specialists, but poor generalists. Typically, you have to train a model for each task, robot, and environment. Changing a single variable often requires starting from scratch. But what if we could combine the knowledge across robotics and create a way to train a general-purpose robot?
]]></content:encoded>
<pubDate>Tue, 03 Oct 2023 15:00:00 +0000</pubDate>
</item>
<item>
<title>A catalogue of genetic mutations to help pinpoint the cause of diseases</title>
<link>https://deepmind.google/discover/blog/a-catalogue-of-genetic-mutations-to-help-pinpoint-the-cause-of-diseases/</link>
<guid>https://deepmind.google/discover/blog/a-catalogue-of-genetic-mutations-to-help-pinpoint-the-cause-of-diseases/</guid>
<content:encoded><![CDATA[
New AI tool classifies the effects of 71 million ‘missense’ mutations.
]]></content:encoded>
<pubDate>Tue, 19 Sep 2023 13:37:00 +0000</pubDate>
</item>
<item>
<title>Identifying AI-generated images with SynthID</title>
<link>https://deepmind.google/discover/blog/identifying-ai-generated-images-with-synthid/</link>
<guid>https://deepmind.google/discover/blog/identifying-ai-generated-images-with-synthid/</guid>
<content:encoded><![CDATA[
New tool helps watermark and identify synthetic images created by Imagen
]]></content:encoded>
<pubDate>Tue, 29 Aug 2023 00:00:00 +0000</pubDate>
</item>
<item>
<title>RT-2: New model translates vision and language into action</title>
<link>https://deepmind.google/discover/blog/rt-2-new-model-translates-vision-and-language-into-action/</link>
<guid>https://deepmind.google/discover/blog/rt-2-new-model-translates-vision-and-language-into-action/</guid>
<content:encoded><![CDATA[
Robotic Transformer 2 (RT-2) is a novel vision-language-action (VLA) model that learns from both web and robotics data, and translates this knowledge into generalised instructions for robotic control.
]]></content:encoded>
<pubDate>Fri, 28 Jul 2023 00:00:00 +0000</pubDate>
</item>
<item>
<title>Using AI to fight climate change</title>
<link>https://deepmind.google/discover/blog/using-ai-to-fight-climate-change/</link>
<guid>https://deepmind.google/discover/blog/using-ai-to-fight-climate-change/</guid>
<content:encoded><![CDATA[
AI is a powerful technology that will transform our future, so how can we best apply it to help combat climate change and find sustainable solutions?
]]></content:encoded>
<pubDate>Fri, 21 Jul 2023 00:00:00 +0000</pubDate>
</item>
<item>
<title>Google DeepMind’s latest research at ICML 2023</title>
<link>https://deepmind.google/discover/blog/google-deepmind-research-at-icml-2023/</link>
<guid>https://deepmind.google/discover/blog/google-deepmind-research-at-icml-2023/</guid>
<content:encoded><![CDATA[
Exploring AI safety, adaptability, and efficiency for the real world
]]></content:encoded>
<pubDate>Thu, 20 Jul 2023 00:00:00 +0000</pubDate>
</item>
<item>
<title>Developing reliable AI tools for healthcare</title>
<link>https://deepmind.google/discover/blog/codoc-developing-reliable-ai-tools-for-healthcare/</link>
<guid>https://deepmind.google/discover/blog/codoc-developing-reliable-ai-tools-for-healthcare/</guid>
<content:encoded><![CDATA[
We’ve published our joint paper with Google Research in Nature Medicine, which proposes CoDoC (Complementarity-driven Deferral-to-Clinical Workflow), an AI system that learns when to rely on predictive AI tools or defer to a clinician for the most accurate interpretation of medical images.
]]></content:encoded>
<pubDate>Mon, 17 Jul 2023 00:00:00 +0000</pubDate>
</item>
<item>
<title>Exploring institutions for global AI governance</title>
<link>https://deepmind.google/discover/blog/exploring-institutions-for-global-ai-governance/</link>
<guid>https://deepmind.google/discover/blog/exploring-institutions-for-global-ai-governance/</guid>
<content:encoded><![CDATA[
New white paper investigates models and functions of international institutions that could help manage opportunities and mitigate risks of advanced AI.
]]></content:encoded>
<pubDate>Tue, 11 Jul 2023 00:00:00 +0000</pubDate>
</item>
<item>
<title>RoboCat: A self-improving robotic agent</title>
<link>https://deepmind.google/discover/blog/robocat-a-self-improving-robotic-agent/</link>
<guid>https://deepmind.google/discover/blog/robocat-a-self-improving-robotic-agent/</guid>
<content:encoded><![CDATA[
Robots are quickly becoming part of our everyday lives, but they’re often only programmed to perform specific tasks well. While harnessing recent advances in AI could lead to robots that could help in many more ways, progress in building general-purpose robots is slower in part because of the time needed to collect real-world training data. Our latest paper introduces a self-improving AI agent for robotics, RoboCat, that learns to perform a variety of tasks across different arms, and then self-generates new training data to improve its technique.
]]></content:encoded>
<pubDate>Tue, 20 Jun 2023 00:00:00 +0000</pubDate>
</item>
<item>
<title>YouTube: Enhancing the user experience</title>
<link>https://deepmind.google/discover/blog/youtube-enhancing-the-user-experience/</link>
<guid>https://deepmind.google/discover/blog/youtube-enhancing-the-user-experience/</guid>
<content:encoded><![CDATA[
It’s all about using our technology and research to help enrich people’s lives. Like YouTube — and its mission to give everyone a voice and show them the world.
]]></content:encoded>
<pubDate>Fri, 16 Jun 2023 14:55:00 +0000</pubDate>
</item>
<item>
<title>Google Cloud: Driving digital transformation</title>
<link>https://deepmind.google/discover/blog/google-cloud-driving-digital-transformation/</link>
<guid>https://deepmind.google/discover/blog/google-cloud-driving-digital-transformation/</guid>
<content:encoded><![CDATA[
Google Cloud empowers organizations to digitally transform themselves into smarter businesses. It offers cloud computing, data analytics, and the latest artificial intelligence (AI) and machine learning tools.
]]></content:encoded>
<pubDate>Wed, 14 Jun 2023 14:51:00 +0000</pubDate>
</item>
<item>
<title>MuZero, AlphaZero, and AlphaDev: Optimizing computer systems</title>
<link>https://deepmind.google/discover/blog/muzero-alphazero-and-alphadev-optimizing-computer-systems/</link>
<guid>https://deepmind.google/discover/blog/muzero-alphazero-and-alphadev-optimizing-computer-systems/</guid>
<content:encoded><![CDATA[
How MuZero, AlphaZero, and AlphaDev are optimizing the computing ecosystem that powers our world of devices.
]]></content:encoded>
<pubDate>Mon, 12 Jun 2023 14:41:00 +0000</pubDate>
</item>
<item>
<title>AlphaDev discovers faster sorting algorithms</title>
<link>https://deepmind.google/discover/blog/alphadev-discovers-faster-sorting-algorithms/</link>
<guid>https://deepmind.google/discover/blog/alphadev-discovers-faster-sorting-algorithms/</guid>
<content:encoded><![CDATA[
New algorithms will transform the foundations of computing
]]></content:encoded>
<pubDate>Wed, 07 Jun 2023 00:00:00 +0000</pubDate>
</item>
<item>
<title>An early warning system for novel AI risks</title>
<link>https://deepmind.google/discover/blog/an-early-warning-system-for-novel-ai-risks/</link>
<guid>https://deepmind.google/discover/blog/an-early-warning-system-for-novel-ai-risks/</guid>
<content:encoded><![CDATA[
New research proposes a framework for evaluating general-purpose models against novel threats
]]></content:encoded>
<pubDate>Thu, 25 May 2023 00:00:00 +0000</pubDate>
</item>
<item>
<title>DeepMind’s latest research at ICLR 2023</title>
<link>https://deepmind.google/discover/blog/deepminds-latest-research-at-iclr-2023/</link>
<guid>https://deepmind.google/discover/blog/deepminds-latest-research-at-iclr-2023/</guid>
<content:encoded><![CDATA[
Next week marks the start of the 11th International Conference on Learning Representations (ICLR), taking place 1-5 May in Kigali, Rwanda. This will be the first major artificial intelligence (AI) conference to be hosted in Africa and the first in-person event since the start of the pandemic. Researchers from around the world will gather to share their cutting-edge work in deep learning spanning the fields of AI, statistics and data science, and applications including machine vision, gaming and robotics. We’re proud to support the conference as a Diamond sponsor and DEI champion.
]]></content:encoded>
<pubDate>Thu, 27 Apr 2023 00:00:00 +0000</pubDate>
</item>
<item>
<title>How can we build human values into AI?</title>
<link>https://deepmind.google/discover/blog/how-can-we-build-human-values-into-ai/</link>
<guid>https://deepmind.google/discover/blog/how-can-we-build-human-values-into-ai/</guid>
<content:encoded><![CDATA[
Drawing from philosophy to identify fair principles for ethical AI...
]]></content:encoded>
<pubDate>Mon, 24 Apr 2023 00:00:00 +0000</pubDate>
</item>
<item>
<title>Announcing Google DeepMind</title>
<link>https://deepmind.google/discover/blog/announcing-google-deepmind/</link>
<guid>https://deepmind.google/discover/blog/announcing-google-deepmind/</guid>
<content:encoded><![CDATA[
DeepMind and the Brain team from Google Research will join forces to accelerate progress towards a world in which AI helps solve the biggest challenges facing humanity.
]]></content:encoded>
<pubDate>Thu, 20 Apr 2023 00:00:00 +0000</pubDate>
</item>
<item>
<title>Competitive programming with AlphaCode</title>
<link>https://deepmind.google/discover/blog/competitive-programming-with-alphacode/</link>
<guid>https://deepmind.google/discover/blog/competitive-programming-with-alphacode/</guid>
<content:encoded><![CDATA[
Solving novel problems and setting a new milestone in competitive programming.
]]></content:encoded>
<pubDate>Thu, 08 Dec 2022 00:00:00 +0000</pubDate>
</item>
<item>
<title>AI for the board game Diplomacy</title>
<link>https://deepmind.google/discover/blog/ai-for-the-board-game-diplomacy/</link>
<guid>https://deepmind.google/discover/blog/ai-for-the-board-game-diplomacy/</guid>
<content:encoded><![CDATA[
Successful communication and cooperation have been crucial for helping societies advance throughout history. The closed environments of board games can serve as a sandbox for modelling and investigating interaction and communication – and we can learn a lot from playing them. In our recent paper, published today in Nature Communications, we show how artificial agents can use communication to better cooperate in the board game Diplomacy, a vibrant domain in artificial intelligence (AI) research, known for its focus on alliance building.
]]></content:encoded>
<pubDate>Tue, 06 Dec 2022 00:00:00 +0000</pubDate>
</item>
<item>
<title>Mastering Stratego, the classic game of imperfect information</title>
<link>https://deepmind.google/discover/blog/mastering-stratego-the-classic-game-of-imperfect-information/</link>
<guid>https://deepmind.google/discover/blog/mastering-stratego-the-classic-game-of-imperfect-information/</guid>
<content:encoded><![CDATA[
Game-playing artificial intelligence (AI) systems have advanced to a new frontier.
]]></content:encoded>
<pubDate>Thu, 01 Dec 2022 00:00:00 +0000</pubDate>
</item>
<item>
<title>DeepMind’s latest research at NeurIPS 2022</title>
<link>https://deepmind.google/discover/blog/deepminds-latest-research-at-neurips-2022/</link>
<guid>https://deepmind.google/discover/blog/deepminds-latest-research-at-neurips-2022/</guid>
<content:encoded><![CDATA[
NeurIPS is the world’s largest conference in artificial intelligence (AI) and machine learning (ML), and we’re proud to support the event as Diamond sponsors, helping foster the exchange of research advances in the AI and ML community. Teams from across DeepMind are presenting 47 papers, including 35 external collaborations in virtual panels and poster sessions.
]]></content:encoded>
<pubDate>Fri, 25 Nov 2022 00:00:00 +0000</pubDate>
</item>
<item>
<title>Building interactive agents in video game worlds</title>
<link>https://deepmind.google/discover/blog/building-interactive-agents-in-video-game-worlds/</link>
<guid>https://deepmind.google/discover/blog/building-interactive-agents-in-video-game-worlds/</guid>
<content:encoded><![CDATA[
Most artificial intelligence (AI) researchers now believe that writing computer code which can capture the nuances of situated interactions is impossible. Alternatively, modern machine learning (ML) researchers have focused on learning about these types of interactions from data. To explore these learning-based approaches and quickly build agents that can make sense of human instructions and safely perform actions in open-ended conditions, we created a research framework within a video game environment.Today, we’re publishing a paper [INSERT LINK] and collection of videos, showing our early steps in building video game AIs that can understand fuzzy human concepts – and therefore, can begin to interact with people on their own terms.
]]></content:encoded>
<pubDate>Wed, 23 Nov 2022 00:00:00 +0000</pubDate>
</item>
<item>
<title>Benchmarking the next generation of never-ending learners</title>
<link>https://deepmind.google/discover/blog/benchmarking-the-next-generation-of-never-ending-learners/</link>
<guid>https://deepmind.google/discover/blog/benchmarking-the-next-generation-of-never-ending-learners/</guid>
<content:encoded><![CDATA[
Learning how to build upon knowledge by tapping 30 years of computer vision research
]]></content:encoded>
<pubDate>Tue, 22 Nov 2022 00:00:00 +0000</pubDate>
</item>
<item>
<title>Best practices for data enrichment</title>
<link>https://deepmind.google/discover/blog/best-practices-for-data-enrichment/</link>
<guid>https://deepmind.google/discover/blog/best-practices-for-data-enrichment/</guid>
<content:encoded><![CDATA[
Building a responsible approach to data collection with the Partnership on AI...
]]></content:encoded>
<pubDate>Wed, 16 Nov 2022 00:00:00 +0000</pubDate>
</item>
<item>
<title>The pursuit of AI education—past, present, and future</title>
<link>https://deepmind.google/discover/blog/the-pursuit-of-ai-educationpast-present-and-future/</link>
<guid>https://deepmind.google/discover/blog/the-pursuit-of-ai-educationpast-present-and-future/</guid>
<content:encoded><![CDATA[
Meet Sylvia Christie, our education partnerships manager who’s played a leading role in expanding our scholarship programme, which is marking its five-year anniversary.
]]></content:encoded>
<pubDate>Tue, 08 Nov 2022 00:00:00 +0000</pubDate>
</item>
<item>
<title>Stopping malaria in its tracks</title>
<link>https://deepmind.google/discover/blog/stopping-malaria-in-its-tracks/</link>
<guid>https://deepmind.google/discover/blog/stopping-malaria-in-its-tracks/</guid>
<content:encoded><![CDATA[
Developing a vaccine that could save hundreds of thousands of lives
]]></content:encoded>
<pubDate>Thu, 13 Oct 2022 15:00:00 +0000</pubDate>
</item>
<item>
<title>Measuring perception in AI models</title>
<link>https://deepmind.google/discover/blog/measuring-perception-in-ai-models/</link>
<guid>https://deepmind.google/discover/blog/measuring-perception-in-ai-models/</guid>
<content:encoded><![CDATA[
Perception – the process of experiencing the world through senses – is a significant part of intelligence. And building agents with human-level perceptual understanding of the world is a central but challenging task, which is becoming increasingly important in robotics, self-driving cars, personal assistants, medical imaging, and more. So today, we’re introducing the Perception Test, a multimodal benchmark using real-world videos to help evaluate the perception capabilities of a model.
]]></content:encoded>
<pubDate>Wed, 12 Oct 2022 00:00:00 +0000</pubDate>
</item>
<item>
<title>How undesired goals can arise with correct rewards</title>
<link>https://deepmind.google/discover/blog/how-undesired-goals-can-arise-with-correct-rewards/</link>
<guid>https://deepmind.google/discover/blog/how-undesired-goals-can-arise-with-correct-rewards/</guid>
<content:encoded><![CDATA[
As we build increasingly advanced artificial intelligence (AI) systems, we want to make sure they don’t pursue undesired goals. Such behaviour in an AI agent is often the result of specification gaming – exploiting a poor choice of what they are rewarded for. In our latest paper, we explore a more subtle mechanism by which AI systems may unintentionally learn to pursue undesired goals: goal misgeneralisation (GMG). GMG occurs when a system's capabilities generalise successfully but its goal does not generalise as desired, so the system competently pursues the wrong goal. Crucially, in contrast to specification gaming, GMG can occur even when the AI system is trained with a correct specification.
]]></content:encoded>
<pubDate>Fri, 07 Oct 2022 00:00:00 +0000</pubDate>
</item>
<item>
<title>Discovering novel algorithms with AlphaTensor</title>
<link>https://deepmind.google/discover/blog/discovering-novel-algorithms-with-alphatensor/</link>
<guid>https://deepmind.google/discover/blog/discovering-novel-algorithms-with-alphatensor/</guid>
<content:encoded><![CDATA[
In our paper, published today in Nature, we introduce AlphaTensor, the first artificial intelligence (AI) system for discovering novel, efficient, and provably correct algorithms for fundamental tasks such as matrix multiplication. This sheds light on a 50-year-old open question in mathematics about finding the fastest way to multiply two matrices. This paper is a stepping stone in DeepMind’s mission to advance science and unlock the most fundamental problems using AI. Our system, AlphaTensor, builds upon AlphaZero, an agent that has shown superhuman performance on board games, like chess, Go and shogi, and this work shows the journey of AlphaZero from playing games to tackling unsolved mathematical problems for the first time.
]]></content:encoded>
<pubDate>Wed, 05 Oct 2022 00:00:00 +0000</pubDate>
</item>
<item>
<title>Fighting osteoporosis before it starts</title>
<link>https://deepmind.google/discover/blog/fighting-osteoporosis-before-it-starts/</link>
<guid>https://deepmind.google/discover/blog/fighting-osteoporosis-before-it-starts/</guid>
<content:encoded><![CDATA[
Detecting signs of disease before bones start to break
]]></content:encoded>
<pubDate>Tue, 27 Sep 2022 14:16:00 +0000</pubDate>
</item>
<item>
<title>Understanding the faulty proteins linked to cancer and autism</title>
<link>https://deepmind.google/discover/blog/understanding-the-faulty-proteins-linked-to-cancer-and-autism/</link>
<guid>https://deepmind.google/discover/blog/understanding-the-faulty-proteins-linked-to-cancer-and-autism/</guid>
<content:encoded><![CDATA[
Helping uncover how protein mutations cause diseases and disorders
]]></content:encoded>
<pubDate>Mon, 26 Sep 2022 15:19:00 +0000</pubDate>
</item>
<item>
<title>Supporting the next generation of AI leaders</title>
<link>https://deepmind.google/discover/blog/supporting-the-next-generation-of-ai-leaders/</link>
<guid>https://deepmind.google/discover/blog/supporting-the-next-generation-of-ai-leaders/</guid>
<content:encoded><![CDATA[
We’re partnering with six education charities and social enterprises in the United Kingdom (UK) to co-create a bespoke education programme to help tackle the gaps in STEM education and boost existing programmes.
]]></content:encoded>
<pubDate>Mon, 26 Sep 2022 00:00:00 +0000</pubDate>
</item>
<item>
<title>Solving the mystery of how an ancient bird went extinct</title>
<link>https://deepmind.google/discover/blog/solving-the-mystery-of-how-an-ancient-bird-went-extinct/</link>
<guid>https://deepmind.google/discover/blog/solving-the-mystery-of-how-an-ancient-bird-went-extinct/</guid>
<content:encoded><![CDATA[
Creating a tool to study extinct species from 50,000 years ago
]]></content:encoded>
<pubDate>Thu, 22 Sep 2022 15:27:00 +0000</pubDate>
</item>
<item>
<title>Building safer dialogue agents</title>
<link>https://deepmind.google/discover/blog/building-safer-dialogue-agents/</link>
<guid>https://deepmind.google/discover/blog/building-safer-dialogue-agents/</guid>
<content:encoded><![CDATA[
In our latest paper, we introduce Sparrow – a dialogue agent that’s useful and reduces the risk of unsafe and inappropriate answers. Our agent is designed to talk with a user, answer questions, and search the internet using Google when it’s helpful to look up evidence to inform its responses.
]]></content:encoded>
<pubDate>Thu, 22 Sep 2022 00:00:00 +0000</pubDate>
</item>
<item>
<title>Targeting early-onset Parkinson’s with AI</title>
<link>https://deepmind.google/discover/blog/targeting-early-onset-parkinsons-with-ai/</link>
<guid>https://deepmind.google/discover/blog/targeting-early-onset-parkinsons-with-ai/</guid>
<content:encoded><![CDATA[
Predictions that  pave the way to new treatments
]]></content:encoded>
<pubDate>Wed, 21 Sep 2022 15:37:00 +0000</pubDate>
</item>
<item>
<title>How our principles helped define AlphaFold’s release</title>
<link>https://deepmind.google/discover/blog/how-our-principles-helped-define-alphafolds-release/</link>
<guid>https://deepmind.google/discover/blog/how-our-principles-helped-define-alphafolds-release/</guid>
<content:encoded><![CDATA[
Our Operating Principles have come to define both our commitment to prioritising widespread benefit, as well as the areas of research and applications we refuse to pursue. These principles have been at the heart of our decision making since DeepMind was founded, and continue to be refined as the AI landscape changes and grows. They are designed for our role as a research-driven science company and consistent with Google’s AI principles.
]]></content:encoded>
<pubDate>Wed, 14 Sep 2022 00:00:00 +0000</pubDate>
</item>
<item>
<title>Maximising the impact of our breakthroughs</title>
<link>https://deepmind.google/discover/blog/maximising-the-impact-of-our-breakthroughs/</link>
<guid>https://deepmind.google/discover/blog/maximising-the-impact-of-our-breakthroughs/</guid>
<content:encoded><![CDATA[
Colin, CBO at DeepMind, discusses collaborations with Alphabet and how we integrate ethics, accountability, and safety into everything we do.
]]></content:encoded>
<pubDate>Fri, 09 Sep 2022 00:00:00 +0000</pubDate>
</item>
<item>
<title>My journey from DeepMind intern to mentor</title>
<link>https://deepmind.google/discover/blog/my-journey-from-deepmind-intern-to-mentor/</link>
<guid>https://deepmind.google/discover/blog/my-journey-from-deepmind-intern-to-mentor/</guid>
<content:encoded><![CDATA[
Former intern turned intern manager, Richard Everett, describes his journey to DeepMind, sharing tips and advice for aspiring DeepMinders. The 2023 internship applications will open on the 16th September, please visit https://dpmd.ai/internshipsatdeepmind for more information.
]]></content:encoded>
<pubDate>Thu, 08 Sep 2022 00:00:00 +0000</pubDate>
</item>
<item>
<title>In conversation with AI: building better language models</title>
<link>https://deepmind.google/discover/blog/in-conversation-with-ai-building-better-language-models/</link>
<guid>https://deepmind.google/discover/blog/in-conversation-with-ai-building-better-language-models/</guid>
<content:encoded><![CDATA[
Our new paper, In conversation with AI: aligning language models with human values, explores a different approach, asking what successful communication between humans and an artificial conversational agent might look like and what values should guide conversation in these contexts.
]]></content:encoded>
<pubDate>Tue, 06 Sep 2022 00:00:00 +0000</pubDate>
</item>
<item>
<title>From motor control to embodied intelligence</title>
<link>https://deepmind.google/discover/blog/from-motor-control-to-embodied-intelligence/</link>
<guid>https://deepmind.google/discover/blog/from-motor-control-to-embodied-intelligence/</guid>
<content:encoded><![CDATA[
Using human and animal motions to teach robots to dribble a ball, and simulated humanoid characters to carry boxes and play football
]]></content:encoded>
<pubDate>Wed, 31 Aug 2022 00:00:00 +0000</pubDate>
</item>
<item>
<title>Advancing conservation with AI-based facial recognition of turtles</title>
<link>https://deepmind.google/discover/blog/advancing-conservation-with-ai-based-facial-recognition-of-turtles/</link>
<guid>https://deepmind.google/discover/blog/advancing-conservation-with-ai-based-facial-recognition-of-turtles/</guid>
<content:encoded><![CDATA[
We came across Zindi – a dedicated partner with complementary goals – who are the largest community of African data scientists and host competitions that focus on solving Africa’s most pressing problems. Our Science team’s Diversity, Equity, and Inclusion (DE&amp;I) team worked with Zindi to identify a scientific challenge that could help advance conservation efforts and grow involvement in AI. Inspired by Zindi’s bounding box turtle challenge, we landed on a project with the potential for real impact: turtle facial recognition.
]]></content:encoded>
<pubDate>Thu, 25 Aug 2022 00:00:00 +0000</pubDate>
</item>
<item>
<title>Discovering when an agent is present in a system</title>
<link>https://deepmind.google/discover/blog/discovering-when-an-agent-is-present-in-a-system/</link>
<guid>https://deepmind.google/discover/blog/discovering-when-an-agent-is-present-in-a-system/</guid>
<content:encoded><![CDATA[
We want to build safe, aligned artificial general intelligence (AGI) systems that pursue the intended goals of its designers. Causal influence diagrams (CIDs) are a way to model decision-making situations that allow us to reason about agent incentives. By relating training setups to the incentives that shape agent behaviour, CIDs help illuminate potential risks before training an agent and can inspire better agent designs. But how do we know when a CID is an accurate model of a training setup?
]]></content:encoded>
<pubDate>Thu, 18 Aug 2022 00:00:00 +0000</pubDate>
</item>
<item>
<title>Realising scientists are the real superheroes</title>
<link>https://deepmind.google/discover/blog/realising-scientists-are-the-real-superheroes/</link>
<guid>https://deepmind.google/discover/blog/realising-scientists-are-the-real-superheroes/</guid>
<content:encoded><![CDATA[
Meet Edgar Duéñez-Guzmán, a research engineer on our Multi-Agent Research team who’s drawing on knowledge of game theory, computer science, and social evolution to get AI agents working better together.
]]></content:encoded>
<pubDate>Thu, 11 Aug 2022 00:00:00 +0000</pubDate>
</item>
<item>
<title>The race to cure a billion people from a deadly parasitic disease</title>
<link>https://deepmind.google/discover/blog/the-race-to-cure-a-billion-people-from-a-deadly-parasitic-disease/</link>
<guid>https://deepmind.google/discover/blog/the-race-to-cure-a-billion-people-from-a-deadly-parasitic-disease/</guid>
<content:encoded><![CDATA[
Accelerating the search for life saving leishmaniasis treatments
]]></content:encoded>
<pubDate>Thu, 28 Jul 2022 16:49:00 +0000</pubDate>
</item>
<item>
<title>Tracing the evolution of proteins back to the origin of life</title>
<link>https://deepmind.google/discover/blog/tracing-the-evolution-of-proteins-back-to-the-origin-of-life/</link>
<guid>https://deepmind.google/discover/blog/tracing-the-evolution-of-proteins-back-to-the-origin-of-life/</guid>
<content:encoded><![CDATA[
Looking into a protein’s past to unlock the mysteries of life itself
]]></content:encoded>
<pubDate>Thu, 28 Jul 2022 16:30:00 +0000</pubDate>
</item>
<item>
<title>How the honeybee could help protect species around the world</title>
<link>https://deepmind.google/discover/blog/how-the-honeybee-could-help-protect-species-around-the-world/</link>
<guid>https://deepmind.google/discover/blog/how-the-honeybee-could-help-protect-species-around-the-world/</guid>
<content:encoded><![CDATA[
New insights into immunity to help protect the world’s flora
]]></content:encoded>
<pubDate>Thu, 28 Jul 2022 16:25:00 +0000</pubDate>
</item>
<item>
<title>AlphaFold transforms biology for millions around the world</title>
<link>https://deepmind.google/discover/blog/alphafold-transforms-biology-for-millions-around-the-world/</link>
<guid>https://deepmind.google/discover/blog/alphafold-transforms-biology-for-millions-around-the-world/</guid>
<content:encoded><![CDATA[
Big data that leads to discoveries that benefit everyone
]]></content:encoded>
<pubDate>Thu, 28 Jul 2022 16:19:00 +0000</pubDate>
</item>
<item>
<title>Advancing discovery of better drugs and medicine</title>
<link>https://deepmind.google/discover/blog/advancing-discovery-of-better-drugs-and-medicine/</link>
<guid>https://deepmind.google/discover/blog/advancing-discovery-of-better-drugs-and-medicine/</guid>
<content:encoded><![CDATA[
Researchers are designing more effective drugs than ever before
]]></content:encoded>
<pubDate>Thu, 28 Jul 2022 16:14:00 +0000</pubDate>
</item>
<item>
<title>Creating plastic-eating enzymes that could save us from pollution</title>
<link>https://deepmind.google/discover/blog/creating-plastic-eating-enzymes-that-could-save-us-from-pollution/</link>
<guid>https://deepmind.google/discover/blog/creating-plastic-eating-enzymes-that-could-save-us-from-pollution/</guid>
<content:encoded><![CDATA[
Helping plastics become 100% recyclable
]]></content:encoded>
<pubDate>Thu, 28 Jul 2022 16:10:00 +0000</pubDate>
</item>
<item>
<title>AlphaFold unlocks one of the greatest puzzles in biology</title>
<link>https://deepmind.google/discover/blog/alphafold-unlocks-one-of-the-greatest-puzzles-in-biology/</link>
<guid>https://deepmind.google/discover/blog/alphafold-unlocks-one-of-the-greatest-puzzles-in-biology/</guid>
<content:encoded><![CDATA[
Piecing together one of the largest molecular structures in human cells
]]></content:encoded>
<pubDate>Thu, 28 Jul 2022 15:59:00 +0000</pubDate>
</item>
<item>
<title>Accelerating the race against antibiotic resistance</title>
<link>https://deepmind.google/discover/blog/accelerating-the-race-against-antibiotic-resistance/</link>
<guid>https://deepmind.google/discover/blog/accelerating-the-race-against-antibiotic-resistance/</guid>
<content:encoded><![CDATA[
Unlocking a decade of data in minutes to help beat antibiotic resistance
]]></content:encoded>
<pubDate>Thu, 28 Jul 2022 15:48:00 +0000</pubDate>
</item>
<item>
<title>AlphaFold reveals the structure of the protein universe</title>
<link>https://deepmind.google/discover/blog/alphafold-reveals-the-structure-of-the-protein-universe/</link>
<guid>https://deepmind.google/discover/blog/alphafold-reveals-the-structure-of-the-protein-universe/</guid>
<content:encoded><![CDATA[
Today, in partnership with EMBL’s European Bioinformatics Institute (EMBL-EBI), we’re now releasing predicted structures for nearly all catalogued proteins known to science, which will expand the AlphaFold DB by over 200x - from nearly 1 million structures to over 200 million structures - with the potential to dramatically increase our understanding of biology.
]]></content:encoded>
<pubDate>Thu, 28 Jul 2022 00:00:00 +0000</pubDate>
</item>
<item>
<title>Putting the power of AlphaFold into the world’s hands</title>
<link>https://deepmind.google/discover/blog/putting-the-power-of-alphafold-into-the-worlds-hands/</link>
<guid>https://deepmind.google/discover/blog/putting-the-power-of-alphafold-into-the-worlds-hands/</guid>
<content:encoded><![CDATA[
When we announced AlphaFold 2 last December, it was hailed as a solution to the 50-year old protein folding problem. Last week, we published the scientific paper and source code explaining how we created this highly innovative system, and today we’re sharing high-quality predictions for the shape of every single protein in the human body, as well as for the proteins of 20 additional organisms that scientists rely on for their research.
]]></content:encoded>
<pubDate>Fri, 22 Jul 2022 00:00:00 +0000</pubDate>
</item>
<item>
<title>The virtuous cycle of AI research</title>
<link>https://deepmind.google/discover/blog/the-virtuous-cycle-of-ai-research/</link>
<guid>https://deepmind.google/discover/blog/the-virtuous-cycle-of-ai-research/</guid>
<content:encoded><![CDATA[
We recently caught up with Petar Veličković, a research scientist at DeepMind. Along with his co-authors, Petar is presenting his paper The CLRS Algorithmic Reasoning Benchmark at ICML 2022 in Baltimore, Maryland, USA.
]]></content:encoded>
<pubDate>Tue, 19 Jul 2022 00:00:00 +0000</pubDate>
</item>
<item>
<title>Perceiver AR: general-purpose, long-context autoregressive generation</title>
<link>https://deepmind.google/discover/blog/perceiver-ar-general-purpose-long-context-autoregressive-generation/</link>
<guid>https://deepmind.google/discover/blog/perceiver-ar-general-purpose-long-context-autoregressive-generation/</guid>
<content:encoded><![CDATA[
We develop Perceiver AR, an autoregressive, modality-agnostic architecture which uses cross-attention to map long-range inputs to a small number of latents while also maintaining end-to-end causal masking. Perceiver AR can directly attend to over a hundred thousand tokens, enabling practical long-context density estimation without the need for hand-crafted sparsity patterns or memory mechanisms.
]]></content:encoded>
<pubDate>Sat, 16 Jul 2022 00:00:00 +0000</pubDate>
</item>
<item>
<title>DeepMind’s latest research at ICML 2022</title>
<link>https://deepmind.google/discover/blog/deepminds-latest-research-at-icml-2022/</link>
<guid>https://deepmind.google/discover/blog/deepminds-latest-research-at-icml-2022/</guid>
<content:encoded><![CDATA[
Starting this weekend, the thirty-ninth International Conference on Machine Learning (ICML 2022) is meeting from 17-23 July, 2022 at the Baltimore Convention Center in Maryland, USA, and will be running as a hybrid event. Researchers working across artificial intelligence, data science, machine vision, computational biology, speech recognition, and more are presenting and publishing their cutting-edge work in machine learning.
]]></content:encoded>
<pubDate>Fri, 15 Jul 2022 00:00:00 +0000</pubDate>
</item>
<item>
<title>Intuitive physics learning in a deep-learning model inspired by developmental psychology</title>
<link>https://deepmind.google/discover/blog/intuitive-physics-learning-in-a-deep-learning-model-inspired-by-developmental-psychology/</link>
<guid>https://deepmind.google/discover/blog/intuitive-physics-learning-in-a-deep-learning-model-inspired-by-developmental-psychology/</guid>
<content:encoded><![CDATA[
Despite significant effort, current AI systems pale in their understanding of intuitive physics, in comparison to even very young children. In the present work, we address this AI problem, specifically by drawing on the field of developmental psychology.
]]></content:encoded>
<pubDate>Mon, 11 Jul 2022 00:00:00 +0000</pubDate>
</item>
<item>
<title>Human-centred mechanism design with Democratic AI</title>
<link>https://deepmind.google/discover/blog/human-centred-mechanism-design-with-democratic-ai/</link>
<guid>https://deepmind.google/discover/blog/human-centred-mechanism-design-with-democratic-ai/</guid>
<content:encoded><![CDATA[
In our recent paper, published in Nature Human Behaviour, we provide a proof-of-concept demonstration that deep reinforcement learning (RL) can be used to find economic policies that people will vote for by majority in a simple game. The paper thus addresses a key challenge in AI research - how to train AI systems that align with human values.
]]></content:encoded>
<pubDate>Mon, 04 Jul 2022 00:00:00 +0000</pubDate>
</item>
<item>
<title>Leading a movement to strengthen machine learning in Africa</title>
<link>https://deepmind.google/discover/blog/leading-a-movement-to-strengthen-machine-learning-in-africa/</link>
<guid>https://deepmind.google/discover/blog/leading-a-movement-to-strengthen-machine-learning-in-africa/</guid>
<content:encoded><![CDATA[
Avishkar Bhoopchand, a research engineer on the Game Theory and Multi-agent team, shares his journey to DeepMind and how he’s working to raise the profile of deep learning across Africa.
]]></content:encoded>
<pubDate>Thu, 23 Jun 2022 00:00:00 +0000</pubDate>
</item>
<item>
<title>BYOL-Explore: Exploration with Bootstrapped Prediction</title>
<link>https://deepmind.google/discover/blog/byol-explore-exploration-with-bootstrapped-prediction/</link>
<guid>https://deepmind.google/discover/blog/byol-explore-exploration-with-bootstrapped-prediction/</guid>
<content:encoded><![CDATA[
We present BYOL-Explore, a conceptually simple yet general approach for curiosity-driven exploration in visually-complex environments. BYOL-Explore learns a world representation, the world dynamics, and an exploration policy all-together by optimizing a single prediction loss in the latent space with no additional auxiliary objective. We show that BYOL-Explore is effective in DM-HARD-8, a challenging partially-observable continuous-action hard-exploration benchmark with visually-rich 3-D environments.
]]></content:encoded>
<pubDate>Mon, 20 Jun 2022 00:00:00 +0000</pubDate>
</item>
<item>
<title>Unlocking High-Accuracy Differentially Private Image Classification through Scale</title>
<link>https://deepmind.google/discover/blog/unlocking-high-accuracy-differentially-private-image-classification-through-scale/</link>
<guid>https://deepmind.google/discover/blog/unlocking-high-accuracy-differentially-private-image-classification-through-scale/</guid>
<content:encoded><![CDATA[
According to empirical evidence from prior works, utility degradation in DP-SGD becomes more severe on larger neural network models – including the ones regularly used to achieve the best performance on challenging image classification benchmarks. Our work investigates this phenomenon and proposes a series of simple modifications to both the training procedure and model architecture, yielding a significant improvement on the accuracy of DP training on standard image classification benchmarks.
]]></content:encoded>
<pubDate>Fri, 17 Jun 2022 00:00:00 +0000</pubDate>
</item>
</channel>
</rss>