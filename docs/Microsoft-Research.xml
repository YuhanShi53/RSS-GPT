<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>Microsoft Research</title>
<link>https://www.microsoft.com/en-us/research/</link>


<item>
<title>CLIO：一种可控制且可解释的自适应认知行为系统</title>
<link>https://www.microsoft.com/en-us/research/blog/self-adaptive-reasoning-for-science/</link>
<guid>https://www.microsoft.com/en-us/research/blog/self-adaptive-reasoning-for-science/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">CLIO提升AI在科学领域的可控性和可解释性。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了CLIO（通过现场优化的认知循环），这是一种无需额外训练即可实现自适应推理的AI系统。与传统基于强化学习的模型不同，CLIO能够在运行时生成自我反思循环，从而增强对推理过程的控制和可解释性。实验结果显示，CLIO显著提升了GPT-4.1在生物医学问题上的准确率，并表现出与顶级推理模型相当的性能。此外，CLIO具备调节不确定性的能力，使科学家能够更有效地审查和修正AI的推理路径，从而建立信任。该方法适用于多种模型，具有广泛的应用潜力，尤其在药物发现等科学领域中表现突出。</p><br /><br /><p><em>使用 qwen-turbo 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/self-adaptive-reasoning-for-science/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 06 Aug 2025 16:00:00 +0000</pubDate>
</item>
<item>
<title>微软推出自主AI代理Project Ire，提升恶意软件分类能力</title>
<link>https://www.microsoft.com/en-us/research/blog/project-ire-autonomously-identifies-malware-at-scale/</link>
<guid>https://www.microsoft.com/en-us/research/blog/project-ire-autonomously-identifies-malware-at-scale/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">Project Ire实现自主恶意软件分类，准确率高。</p><br /><br /><p><strong>摘要：</strong> 微软推出了名为Project Ire的自主AI代理系统，用于自动分析和分类软件，以提高网络安全和恶意软件检测的效率。该系统通过使用反编译器和其他工具，无需任何线索即可完全逆向工程软件文件，并判断其是否为恶意或良性。Project Ire在公开数据集上达到了0.98的精确度和0.83的召回率，成功识别了多个高级持续性威胁（APT）恶意软件样本，并将其标记为恶意。该系统能够生成详细的报告，包括证据链、代码函数摘要和技术工件，支持安全团队进行二次审查。在实际测试中，Project Ire表现出较高的准确性和较低的误报率，具有在未来部署的潜力。微软计划将Project Ire集成到Defender平台中，用于威胁检测和软件分类。</p><br /><br /><p><em>使用 qwen-turbo 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/project-ire-autonomously-identifies-malware-at-scale/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 05 Aug 2025 16:00:00 +0000</pubDate>
</item>
<item>
<title>VeriTrail：一种具有可追溯性的封闭领域幻觉检测方法</title>
<link>https://www.microsoft.com/en-us/research/blog/veritrail-detecting-hallucination-and-tracing-provenance-in-multi-step-ai-workflows/</link>
<guid>https://www.microsoft.com/en-us/research/blog/veritrail-detecting-hallucination-and-tracing-provenance-in-multi-step-ai-workflows/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">VeriTrail通过追踪生成过程检测幻觉，提升AI输出的可信度。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了VeriTrail，这是一种用于检测封闭领域幻觉的新方法，特别适用于多步骤生成过程。VeriTrail能够追踪最终输出与源文本之间的路径，并定位幻觉内容的产生位置，从而提高生成内容的透明度和可信度。文章详细描述了VeriTrail的工作原理，包括其基于有向无环图（DAG）的结构、证据选择和判决生成机制，并通过案例研究展示了其有效性。实验表明，VeriTrail在多个数据集上优于现有方法，尤其在处理复杂生成流程时表现突出。此外，VeriTrail还提供了详细的证据链，帮助用户验证判断并理解生成过程中的潜在问题。</p><br /><br /><p><em>使用 qwen-turbo 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/veritrail-detecting-hallucination-and-tracing-provenance-in-multi-step-ai-workflows/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 05 Aug 2025 16:00:00 +0000</pubDate>
</item>
<item>
<title>AI在医学教育中的变革与挑战</title>
<link>https://www.microsoft.com/en-us/research/podcast/navigating-medical-education-in-the-era-of-generative-ai/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/navigating-medical-education-in-the-era-of-generative-ai/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">AI正在重塑医学教育，改变医学生和医生的学习与实践方式。</p><br /><br /><p><strong>摘要：</strong> 文章探讨了生成式AI如何影响医学教育，包括医学生使用AI工具进行学习、临床决策和知识获取。通过与两位年轻医生Morgan Cheatham和Daniel Chen的访谈，文章分析了AI在医学培训中的实际应用，如AI辅助诊断、临床笔记生成以及对传统医学教育模式的挑战。同时，文章也讨论了AI在医学教育中可能带来的风险，如过度依赖技术而忽视批判性思维的培养。专家们强调，尽管AI为医学教育提供了新的可能性，但如何平衡技术使用与传统医学训练仍是关键问题。</p><br /><br /><p><em>使用 qwen-turbo 生成 </em></p><a href="https://www.microsoft.com/en-us/research/podcast/navigating-medical-education-in-the-era-of-generative-ai/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 20:06:32 +0000</pubDate>
</item>
<item>
<title>Xinxing Xu与微软亚洲研究院新加坡实验室推动AI现实应用</title>
<link>https://www.microsoft.com/en-us/research/blog/xinxing-xu-bridges-ai-research-and-real-world-impact-at-microsoft-research-asia-singapore/</link>
<guid>https://www.microsoft.com/en-us/research/blog/xinxing-xu-bridges-ai-research-and-real-world-impact-at-microsoft-research-asia-singapore/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">Xu致力于将AI算法应用于现实场景，推动技术落地。</p><br /><br /><p><strong>摘要：</strong> 文章介绍了Xinxing Xu在微软亚洲研究院新加坡实验室的工作，他专注于将人工智能算法从实验环境转移到实际应用中。Xu强调，只有通过真实数据和场景测试，算法才能不断优化并发挥真正价值。他曾在多个领域如医疗影像识别、建筑缺陷检测等进行研究，并与新加坡的SingHealth、NUS、NTU等机构合作，推动AI在医疗、金融、物流等行业的应用。此外，他还提出对下一代AI研究人员的建议，包括夯实理论基础、理解实际应用场景以及培养跨学科思维。微软新加坡实验室旨在成为连接全球创新与本地发展的桥梁，推动AI技术的社会化应用。</p><br /><br /><p><em>使用 qwen-turbo 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/xinxing-xu-bridges-ai-research-and-real-world-impact-at-microsoft-research-asia-singapore/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 01:30:00 +0000</pubDate>
</item>
<item>
<title>构建高效的大语言模型分类流水线</title>
<link>https://www.microsoft.com/en-us/research/blog/technical-approach-for-classifying-human-ai-interactions-at-scale/</link>
<guid>https://www.microsoft.com/en-us/research/blog/technical-approach-for-classifying-human-ai-interactions-at-scale/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">文章介绍了如何构建高吞吐量的LLM分类系统。</p><br /><br /><p><strong>摘要：</strong> 文章探讨了如何构建一个高效、可扩展的大语言模型（LLM）分类流水线，以处理海量的用户对话数据。该系统结合了PySpark和Polars的分布式计算能力，支持多模型、多任务的分类，并通过优化提示模板、动态并发控制等技术解决LLM端点延迟、模型演化和吞吐量问题。文章还讨论了多种优化策略，如批量处理、提示压缩和文本截断，以提高效率和降低成本。最终目标是实现对大规模人机交互数据的实时分析与持续系统优化。</p><br /><br /><p><em>使用 qwen-turbo 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/technical-approach-for-classifying-human-ai-interactions-at-scale/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 16:00:00 +0000</pubDate>
</item>
<item>
<title>AI治理中的测试与评估：跨领域经验与未来方向</title>
<link>https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-reflections/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-reflections/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">AI治理需结合多领域测试经验，提升模型与系统评估的严谨性。</p><br /><br /><p><strong>摘要：</strong> 文章探讨了生成式AI在治理方面的挑战与机遇，强调测试与评估作为治理工具的重要性。微软通过与基因编辑、网络安全等领域的专家合作，分析了不同领域在风险评估和测试方面的经验。文章指出，测试不仅是信任的基础，也涉及预部署与后部署的平衡，以及测试方法的标准化和可解释性。同时，强调了公私合作在推动AI治理中的关键作用，并提出未来需加强系统级评估和跨领域信息共享，以实现更负责任的AI发展。</p><br /><br /><p><em>使用 qwen-turbo 生成 </em></p><a href="https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-reflections/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 16:00:00 +0000</pubDate>
</item>
<item>
<title>提升AI协作能力：CollabLLM的多轮对话训练方法</title>
<link>https://www.microsoft.com/en-us/research/blog/collabllm-teaching-llms-to-collaborate-with-users/</link>
<guid>https://www.microsoft.com/en-us/research/blog/collabllm-teaching-llms-to-collaborate-with-users/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">研究提出CollabLLM，提升AI在多轮对话中的协作能力。</p><br /><br /><p><strong>摘要：</strong> 文章介绍了CollabLLM，一种旨在提升大型语言模型（LLMs）在多轮对话中协作能力的训练框架。传统训练方法侧重于单次响应的优化，而CollabLLM通过模拟真实对话环境，使模型学习如何提问、调整语气和适应不同情境，从而提高对话效率和用户满意度。该方法利用多轮感知奖励函数评估模型表现，并通过强化学习不断优化模型参数。实验表明，CollabLLM在文档协作任务中优于传统方法，表现出更高的任务完成质量和用户评价。</p><br /><br /><p><em>使用 qwen-turbo 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/collabllm-teaching-llms-to-collaborate-with-users/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 18:00:00 +0000</pubDate>
</item>
<item>
<title>从网络安全视角看AI治理与测试</title>
<link>https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-cybersecurity/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-cybersecurity/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">网络安全经验为AI治理提供重要参考。</p><br /><br /><p><strong>摘要：</strong> 本文探讨了从网络安全领域汲取的经验如何应用于人工智能的治理和测试。通过采访牛津大学教授Ciaran Martin和微软AI红队负责人Tori Westerhoff，文章分析了风险评估、测试标准、公私合作以及AI安全设计的重要性。强调了针对不同规模组织制定差异化标准的必要性，并指出AI安全应作为一项团队协作任务。同时，文章提到网络安全中已有的框架和语言可为AI安全提供借鉴，推动行业透明度和共同目标的形成。</p><br /><br /><p><em>使用 qwen-turbo 生成 </em></p><a href="https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-cybersecurity/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 16:00:00 +0000</pubDate>
</item>
<item>
<title>AI在医学领域的革命：从药物发现到疾病预防</title>
<link>https://www.microsoft.com/en-us/research/podcast/how-ai-will-accelerate-biomedical-research-and-discovery/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/how-ai-will-accelerate-biomedical-research-and-discovery/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">AI正在重塑医学研究和治疗，从药物发现到疾病预防。</p><br /><br /><p><strong>摘要：</strong> 本文探讨了人工智能（AI）在医学领域的快速发展及其对药物发现、疾病诊断和治疗的深远影响。通过与Daphne Koller、Noubar Afeyan和Eric Topol的访谈，文章展示了AI如何加速药物研发、优化临床试验设计，并推动个性化医疗的发展。此外，文章还讨论了AI在理解复杂生物系统、预测疾病机制以及提升医疗效率方面的潜力。随着AI技术的不断进步，其在医学领域的应用前景广阔，有望显著改善人类健康。</p><br /><br /><p><em>使用 qwen-turbo 生成 </em></p><a href="https://www.microsoft.com/en-us/research/podcast/how-ai-will-accelerate-biomedical-research-and-discovery/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 16:00:00 +0000</pubDate>
</item>
<item>
<title>从制药和医疗设备监管中学习AI测试与评估</title>
<link>https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-pharmaceuticals-and-medical-devices/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-pharmaceuticals-and-medical-devices/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">文章探讨了制药和医疗设备监管对AI测试与评估的启示。</p><br /><br /><p><strong>摘要：</strong> 文章讨论了微软通过邀请来自基因编辑和网络安全等领域的专家，研究测试和评估在AI治理中的作用。哈佛大学的Dan Carpenter分享了美国食品药品监督管理局（FDA）严格的药物审批流程如何建立公众信任和科学可信度，而哥本哈根大学的Timo Minssen则探讨了医疗设备监管的演变及其在创新与公共安全之间的平衡。微软的Chad Atalla介绍了其团队构建的基于社会科学的AI评估框架，并强调了从其他领域借鉴经验的重要性。文章还提到AI测试需要考虑社会技术系统的复杂性，并借鉴制药和医疗设备行业的成熟方法，以确保AI的安全性和有效性。</p><br /><br /><p><em>使用 qwen-turbo 生成 </em></p><a href="https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-pharmaceuticals-and-medical-devices/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 07 Jul 2025 16:00:00 +0000</pubDate>
</item>
<item>
<title>从基因编辑看AI治理：测试与评估在技术监管中的作用</title>
<link>https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-genome-editing/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-genome-editing/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">基因编辑与AI治理面临相似的挑战，需通过测试与评估实现负责任的发展。</p><br /><br /><p><strong>摘要：</strong> 本文探讨了微软如何借鉴基因编辑领域的治理经验，以应对生成式AI所带来的挑战。文章邀请了基因编辑法律与伦理专家R. Alta Charo和微软AI治理负责人Daniel Kluttz，讨论了如何通过风险评估、多机构协作和国际协调来制定更有效的AI治理框架。Charo强调，基因编辑治理并非针对技术本身，而是针对其具体应用场景，这种理念同样适用于AI治理。Kluttz则介绍了微软在敏感AI应用和新兴技术方面的管理实践，包括对高风险系统的内部审查、定制化治理要求以及对部署后数据的持续追踪。文章指出，AI治理需要在创新与安全之间找到平衡，并从其他领域汲取经验，以构建更加稳健和灵活的监管体系。</p><br /><br /><p><em>使用 qwen-turbo 生成 </em></p><a href="https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-genome-editing/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 30 Jun 2025 16:00:17 +0000</pubDate>
</item>
<item>
<title>全球首个多模态双语放射报告数据集PadChest-GR发布</title>
<link>https://www.microsoft.com/en-us/research/blog/padchest-gr-a-bilingual-grounded-radiology-reporting-benchmark-for-chest-x-rays/</link>
<guid>https://www.microsoft.com/en-us/research/blog/padchest-gr-a-bilingual-grounded-radiology-reporting-benchmark-for-chest-x-rays/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">PadChest-GR是首个多模态双语放射报告数据集，推动AI与放射科医生协作。</p><br /><br /><p><strong>摘要：</strong> PadChest-GR是由西班牙阿尔瓦拉多大学、微软研究院等机构联合开发的全球首个多模态、双语句子级放射报告数据集。该数据集包含4,555例胸部X光检查，提供西班牙语和英语的详细描述及精确的空间标注，旨在提升AI在放射学报告中的准确性和可解释性。该数据集为MAIRA-2模型提供了支持，展示了人类与AI协作如何通过反馈循环改进模型性能。研究团队通过与医院和AI平台合作，确保了数据的质量和一致性，推动了放射学报告生成技术的发展，并鼓励学术界进一步利用该数据集进行创新研究。</p><br /><br /><p><em>使用 qwen-turbo 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/padchest-gr-a-bilingual-grounded-radiology-reporting-benchmark-for-chest-x-rays/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 26 Jun 2025 16:08:25 +0000</pubDate>
</item>
<item>
<title>AI测试与评估：从科学与工业中学习</title>
<link>https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-science-and-industry/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-science-and-industry/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">微软探讨AI测试与评估在治理中的作用。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了微软如何通过跨领域专家（如基因编辑和网络安全）研究AI测试与评估作为治理工具的潜力。Amanda Craig Deckard讨论了AI治理面临的挑战，强调测试在建立信任和风险管理中的重要性。文章还提到不同领域的经验可以为AI发展提供借鉴，并指出需要多方合作推动AI政策与标准的发展。微软致力于构建灵活框架，促进产业、学术界和政府之间的协作，以应对AI带来的广泛影响。</p><br /><br /><p><em>使用 qwen-turbo 生成 </em></p><a href="https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-science-and-industry/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 23 Jun 2025 16:38:09 +0000</pubDate>
</item>
<item>
<title>AI评估框架的跨领域经验与治理挑战</title>
<link>https://www.microsoft.com/en-us/research/blog/learning-from-other-domains-to-advance-ai-evaluation-and-testing/</link>
<guid>https://www.microsoft.com/en-us/research/blog/learning-from-other-domains-to-advance-ai-evaluation-and-testing/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">AI评估需借鉴其他技术领域的治理经验，以提升可靠性与信任度。</p><br /><br /><p><strong>摘要：</strong> 文章探讨了生成式AI快速发展带来的治理挑战，指出当前在评估AI模型和系统方面存在显著差距。通过分析航空、网络安全、金融、基因编辑等八个领域的案例，研究发现评估框架需在安全、效率和创新之间做出权衡，并强调测试方法的严谨性、标准化和结果可解释性。文章还提出，AI评估应结合具体应用场景，建立灵活且适应性强的治理机制，以应对快速变化的技术环境。此外，微软发布了相关播客和案例研究，分享专家见解并推动更可靠、可信的AI评估方法。</p><br /><br /><p><em>使用 qwen-turbo 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/learning-from-other-domains-to-advance-ai-evaluation-and-testing/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 23 Jun 2025 16:35:06 +0000</pubDate>
</item>
<item>
<title>深度学习突破密度泛函理论精度：迈向计算化学新时代</title>
<link>https://www.microsoft.com/en-us/research/blog/breaking-bonds-breaking-ground-advancing-the-accuracy-of-computational-chemistry-with-deep-learning/</link>
<guid>https://www.microsoft.com/en-us/research/blog/breaking-bonds-breaking-ground-advancing-the-accuracy-of-computational-chemistry-with-deep-learning/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">通过深度学习大幅提升密度泛函理论的准确性。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了一项利用深度学习方法显著提高密度泛函理论（DFT）精度的研究成果。传统DFT的交换关联泛函（XC）函数存在局限性，影响了预测实验结果的能力。研究团队通过生成大量高精度数据并设计专用深度学习架构，首次实现了接近化学精度的预测。这一突破将加速分子与材料设计从实验室转向计算机模拟，对药物、电池等领域具有深远意义。研究还展示了新开发的Skala泛函在多个基准测试中的优异表现，其成本效益和广泛适用性令人期待。</p><br /><br /><p><em>使用 qwen-turbo 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/breaking-bonds-breaking-ground-advancing-the-accuracy-of-computational-chemistry-with-deep-learning/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 18 Jun 2025 10:01:47 +0000</pubDate>
</item>
<item>
<title>人工智能推理能力提升：方法与进展</title>
<link>https://www.microsoft.com/en-us/research/blog/new-methods-boost-reasoning-in-small-and-large-language-models/</link>
<guid>https://www.microsoft.com/en-us/research/blog/new-methods-boost-reasoning-in-small-and-large-language-models/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">研究者提出多种策略提升AI推理能力，涵盖数学问题求解及跨领域泛化。</p><br /><br /><p><strong>摘要：</strong> 本文探讨了如何通过改进架构设计、引入数学推理技术和增强泛化能力来提高语言模型的推理能力。针对小型模型，rStar-Math 和 Logic-RL 框架分别通过模拟深度推理和强化逻辑训练展现优异表现。同时，LIPS 和 auto-formalization 框架解决了自然语言数学问题到机器可读格式的转换难题，并提升了推理准确性。此外，CoR 和 CPL 方法促进了AI在多领域间的泛化能力，使模型更接近人类灵活的思考方式。尽管如此，AI在精确性和避免幻觉方面仍需进一步突破，特别是在医疗和科研等关键领域。</p><br /><br /><p><em>使用 qwen-turbo 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/new-methods-boost-reasoning-in-small-and-large-language-models/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 16:00:00 +0000</pubDate>
</item>
<item>
<title>人工智能革命在医学中的新进展与挑战</title>
<link>https://www.microsoft.com/en-us/research/podcast/how-ai-is-reshaping-the-future-of-healthcare-and-medical-research/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/how-ai-is-reshaping-the-future-of-healthcare-and-medical-research/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">探讨人工智能在医疗领域的应用现状及未来发展趋势。</p><br /><br /><p><strong>摘要：</strong> 本文基于近期对微软联合创始人比尔·盖茨和OpenAI研究负责人塞巴斯蒂安·布贝克的访谈，回顾了自《医学中的AI革命》一书出版以来，AI在医疗领域的发展情况。文章聚焦于AI如何协助医生处理行政工作、辅助诊断，以及在欠发达地区提供医疗服务的可能性。此外，还讨论了AI在医疗发现与医疗交付中的区别，以及当前技术面临的局限性和未来发展方向，如基准测试的重要性及监管问题。</p><br /><br /><p><em>使用 qwen-turbo 生成 </em></p><a href="https://www.microsoft.com/en-us/research/podcast/how-ai-is-reshaping-the-future-of-healthcare-and-medical-research/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 12 Jun 2025 16:17:04 +0000</pubDate>
</item>
<item>
<title>微软将重写SymCrypt库至Rust并引入形式化验证</title>
<link>https://www.microsoft.com/en-us/research/blog/rewriting-symcrypt-in-rust-to-modernize-microsofts-cryptographic-library/</link>
<guid>https://www.microsoft.com/en-us/research/blog/rewriting-symcrypt-in-rust-to-modernize-microsofts-cryptographic-library/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">微软计划将加密库SymCrypt重写为Rust语言并加入形式化验证。</p><br /><br /><p><strong>摘要：</strong> 随着老旧编码实践和内存不安全语言如C带来的软件风险加剧，微软决定将其开源加密库SymCrypt重写为内存安全的语言Rust，并结合形式化验证工具提升安全性。目前，该库主要基于C语言开发，支持多种算法，包括AES-GCM、SHA、ECDSA及量子抗性算法ML-KEM和ML-DSA。通过采用Rust语言和Aeneas等工具进行形式化验证，微软希望避免实现错误、数据损坏等问题，并防止侧信道攻击。同时，为了保持向后兼容性，微软还将继续支持C语言API，并通过Rust-to-C编译器转换已验证的Rust代码为C代码。此外，微软还扩展了Revizor工具用于分析二进制代码中的潜在漏洞，确保代码符合预期行为。这一举措标志着高可靠性软件发展的重要里程碑。</p><br /><br /><p><em>使用 qwen-turbo 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/rewriting-symcrypt-in-rust-to-modernize-microsofts-cryptographic-library/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 10 Jun 2025 16:00:00 +0000</pubDate>
</item>
<item>
<title>BenchmarkQED：大规模自动化RAG基准测试工具</title>
<link>https://www.microsoft.com/en-us/research/blog/benchmarkqed-automated-benchmarking-of-rag-systems/</link>
<guid>https://www.microsoft.com/en-us/research/blog/benchmarkqed-automated-benchmarking-of-rag-systems/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">介绍BenchmarkQED工具，用于评估RAG模型性能。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了BenchmarkQED，一个用于大规模自动化检索增强生成（RAG）模型基准测试的新工具套件。BenchmarkQED包括查询生成、评估和数据集准备组件，支持对不同数据集和指标的严格、可重复的测试。该工具与开源GraphRAG库结合使用，允许用户跨模型、指标和数据集进行系统性评估。通过对比实验，发现LazyGraphRAG在多项质量指标上显著优于其他竞争方法。此外，文中还介绍了AutoQ和AutoE等组件，分别用于合成查询和自动化评估框架，以及AutoD在数据采样和摘要中的应用。这些工具共同推动了RAG系统的基准驱动开发。</p><br /><br /><p><em>使用 qwen-turbo 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/benchmarkqed-automated-benchmarking-of-rag-systems/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 05 Jun 2025 16:00:00 +0000</pubDate>
</item>
<item>
<title>人工智能重塑医疗领域：专家视角与未来展望</title>
<link>https://www.microsoft.com/en-us/research/podcast/what-ais-impact-on-individuals-means-for-the-health-workforce-and-industry/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/what-ais-impact-on-individuals-means-for-the-health-workforce-and-industry/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">专家探讨AI如何影响医疗工作、教育及社会系统。</p><br /><br /><p><strong>摘要：</strong> 本文通过微软研究总裁彼得·李的播客系列，深入分析了人工智能在医疗领域的应用现状与潜在影响。播客邀请了埃森·莫利克和阿兹姆·阿扎尔两位专家，讨论AI如何改变医疗服务提供者的工作方式、患者体验以及组织系统的运作模式。两位嘉宾强调，虽然AI提高了个人工作效率，但其对整个组织效率的影响仍需进一步探索。此外，他们还探讨了消费者化医疗的趋势、监管挑战及AI在个性化医疗中的潜力。</p><br /><br /><p><em>使用 qwen-turbo 生成 </em></p><a href="https://www.microsoft.com/en-us/research/podcast/what-ais-impact-on-individuals-means-for-the-health-workforce-and-industry/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 29 May 2025 15:13:48 +0000</pubDate>
</item>
<item>
<title>FrodoKEM：后量子加密的保守设计选择</title>
<link>https://www.microsoft.com/en-us/research/blog/frodokem-a-conservative-quantum-safe-cryptographic-algorithm/</link>
<guid>https://www.microsoft.com/en-us/research/blog/frodokem-a-conservative-quantum-safe-cryptographic-algorithm/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">FrodoKEM是一种基于未结构化格的后量子加密机制。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了FrodoKEM，一种基于未结构化格的后量子加密密钥封装协议。尽管相比基于结构化格的算法如ML-KEM，FrodoKEM具有更高的安全性和更强的抗攻击能力，但其运行时间和带宽消耗显著增加。文章还探讨了FrodoKEM的设计原理及其在后量子密码学中的地位，强调其在应对未来潜在攻击时的稳健性。此外，文章还提到FrodoKEM已被多个国际标准化组织采纳，显示了其在后量子世界中作为长期加密解决方案的潜力。</p><br /><br /><p><em>使用 qwen-turbo 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/frodokem-a-conservative-quantum-safe-cryptographic-algorithm/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 27 May 2025 16:00:00 +0000</pubDate>
</item>
<item>
<title>零样本学习在单细胞生物学中的局限性研究</title>
<link>https://www.microsoft.com/en-us/research/podcast/abstracts-zero-shot-models-in-single-cell-biology-with-alex-lu/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/abstracts-zero-shot-models-in-single-cell-biology-with-alex-lu/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">研究发现零样本基础模型在单细胞生物学中的表现不如传统方法。</p><br /><br /><p><strong>摘要：</strong> 本研究由微软研究院的高级研究员Alex Lu主导，探讨了零样本基础模型在单细胞生物学中的应用潜力。通过对比新提出的单细胞基础模型与传统机器学习及统计方法，研究发现这些新模型在生物发现的关键任务上表现不佳，建议进行更严格的评估与研究。该研究不仅对生物学家的工具选择有直接影响，还为未来改进此类AI模型提供了方向。</p><br /><br /><p><em>使用 qwen-turbo 生成 </em></p><a href="https://www.microsoft.com/en-us/research/podcast/abstracts-zero-shot-models-in-single-cell-biology-with-alex-lu/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 22 May 2025 15:58:00 +0000</pubDate>
</item>
<item>
<title>微软研究团队推出突破性AI模型Aurora重塑环境预测</title>
<link>https://www.microsoft.com/en-us/research/podcast/abstracts-aurora-with-megan-stanley-and-wessel-bruinsma/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/abstracts-aurora-with-megan-stanley-and-wessel-bruinsma/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">微软研发出基于AI的新模型Aurora，显著提升天气及环境领域预测能力。</p><br /><br /><p><strong>摘要：</strong> 在微软研究播客《Abstracts》的一集中，高级研究员Megan Stanley和Wessel Bruinsma介绍了他们关于环境预测的开创性工作。他们开发的名为Aurora的AI模型不仅革新了天气预报，还扩展到空气污染、热带气旋及海洋波浪等其他环境预测领域。通过预训练和微调的方法，Aurora展示了卓越的泛化能力，能够在多个领域实现最先进的预测性能。这一技术的引入标志着环境预测领域的重大进步，并可能大幅缩短相关应用的开发周期。然而，研究团队也指出了Aurora的局限性，如仅提供确定性预测及对数据同化的依赖，并展望了未来改进的方向和潜在应用。</p><br /><br /><p><em>使用 qwen-turbo 生成 </em></p><a href="https://www.microsoft.com/en-us/research/podcast/abstracts-aurora-with-megan-stanley-and-wessel-bruinsma/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 21 May 2025 15:22:51 +0000</pubDate>
</item>
<item>
<title>微软研究协作系列：AI赋能医疗健康领域的创新与实践</title>
<link>https://www.microsoft.com/en-us/research/podcast/collaborators-healthcare-innovation-to-impact/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/collaborators-healthcare-innovation-to-impact/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">微软探讨如何通过跨领域协作加速AI在医疗健康中的应用。</p><br /><br /><p><strong>摘要：</strong> 本文聚焦于微软如何通过跨公司合作缩短科研成果转化为实际应用的时间，尤其是在医疗健康领域，利用AI提升临床效率及患者结局。文中介绍了多模态AI框架如何嵌入临床工作流，以及由首席科学家和副总裁领导的研究团队如何通过技术与临床专业知识结合，将AI突破转化为挽救生命的创新解决方案。此外，还提到AI代理和多智能体系统的潜力，以及如何通过微软生产力工具如Teams实现这一愿景。</p><br /><br /><p><em>使用 qwen-turbo 生成 </em></p><a href="https://www.microsoft.com/en-us/research/podcast/collaborators-healthcare-innovation-to-impact/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 20 May 2025 20:39:01 +0000</pubDate>
</item>
<item>
<title>Magentic-UI：人机协作的新研究原型</title>
<link>https://www.microsoft.com/en-us/research/blog/magentic-ui-an-experimental-human-centered-web-agent/</link>
<guid>https://www.microsoft.com/en-us/research/blog/magentic-ui-an-experimental-human-centered-web-agent/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">Magentic-UI是一个新的人机协作开源原型，旨在帮助研究人员探索人机交互和AI代理监督机制。</p><br /><br /><p><strong>摘要：</strong> Magentic-UI是由微软研究团队推出的一个开源研究原型，旨在通过人机协作的方式协助用户完成基于浏览器的任务。该系统采用模块化设计，由多个专业化代理组成，包括Orchestrator、WebSurfer、Coder和FileSurfer。这些代理协同工作，支持用户进行任务规划、实时反馈、安全控制及计划学习等功能。Magentic-UI在GAIA基准测试中的表现表明，结合人类反馈可以显著提升自主代理的准确性。此外，系统还具备强大的安全性措施，如访问列表管理、随时中断执行、沙盒隔离等，以保障操作的安全性和可靠性。作为研究工具，Magentic-UI为探索人机交互、安全机制和个性化学习等问题提供了平台。</p><br /><br /><p><em>使用 qwen-turbo 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/magentic-ui-an-experimental-human-centered-web-agent/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 19 May 2025 16:00:11 +0000</pubDate>
</item>
<item>
<title>重新审视医疗领域的人工智能革命</title>
<link>https://www.microsoft.com/en-us/research/podcast/the-ai-revolution-in-medicine-revisited-coauthor-roundtable-reflecting-on-real-world-of-doctors-developers-patients-and-policymakers/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/the-ai-revolution-in-medicine-revisited-coauthor-roundtable-reflecting-on-real-world-of-doctors-developers-patients-and-policymakers/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">微软研究总裁彼得·李回顾了他与他人合著的关于AI影响医疗的书籍。</p><br /><br /><p><strong>摘要：</strong> 本书作者之一彼得·李与同事探讨了两年前出版的《医学的人工智能革命》一书中的预测，分析了实际进展与预期之间的差距。他们讨论了AI在临床实践中的应用，如病历记录和患者沟通，并强调了安全性和公平性等问题。此外，他们还提到AI的价值观问题及未来医生的角色。</p><br /><br /><p><em>使用 qwen-turbo 生成 </em></p><a href="https://www.microsoft.com/en-us/research/podcast/the-ai-revolution-in-medicine-revisited-coauthor-roundtable-reflecting-on-real-world-of-doctors-developers-patients-and-policymakers/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 15 May 2025 16:15:59 +0000</pubDate>
</item>
<item>
<title>基于能力评估的AI模型测试框架ADeLe</title>
<link>https://www.microsoft.com/en-us/research/blog/predicting-and-explaining-ai-model-performance-a-new-approach-to-evaluation/</link>
<guid>https://www.microsoft.com/en-us/research/blog/predicting-and-explaining-ai-model-performance-a-new-approach-to-evaluation/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">研究团队开发了ADeLe框架，用于预测AI模型在新任务上的表现并解释原因。</p><br /><br /><p><strong>摘要：</strong> 微软与合作机构的研究人员在AFMR资助下，开发了一种名为ADeLe的新方法，通过评估AI模型的认知和知识能力，预测其在未知任务中的表现并解释原因。该框架利用18种认知及知识能力的测量尺度，生成任务需求与模型能力的匹配分析，揭示当前AI基准测试存在的局限性，如仅覆盖有限难度范围等。此外，ADeLe还展示了大型语言模型在不同能力上的优劣势，表明增加模型规模对性能提升有限。最后，ADeLe能有效预测模型在特定任务中的表现，为AI可靠性评估提供了新工具，未来可扩展至多模态和具身AI领域，推动AI评估科学化发展。</p><br /><br /><p><em>使用 qwen-turbo 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/predicting-and-explaining-ai-model-performance-a-new-approach-to-evaluation/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 12 May 2025 16:00:00 +0000</pubDate>
</item>
<item>
<title>通过深度学习探索无机晶体热传导极限</title>
<link>https://www.microsoft.com/en-us/research/podcast/abstracts-heat-transfer-and-deep-learning-with-hongxia-hao-and-bing-lv/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/abstracts-heat-transfer-and-deep-learning-with-hongxia-hao-and-bing-lv/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">利用AI技术发现新型高效热导材料，挑战现有设计规则。</p><br /><br /><p><strong>摘要：</strong> 微软研究院的高级研究员Hongxia Hao和德州大学达拉斯分校物理副教授Bing Lv在本研究中，通过深度学习技术探索无机晶体的热传导极限，发现超过硅性能的新材料，并提出新的设计理念以应对高效率电子器件和可持续能源的挑战。研究不仅验证了钻石作为热导率基准的地位，还发现了如锰钒等具有潜力的新材料，为物理学和材料科学提供了新见解。未来的研究方向将涉及极端条件下的材料探索及低热导率材料的设计。本研究标志着AI成为科学发现的重要伙伴，开启了全新高性能化合物的设计路径。</p><br /><br /><p><em>使用 qwen-turbo 生成 </em></p><a href="https://www.microsoft.com/en-us/research/podcast/abstracts-heat-transfer-and-deep-learning-with-hongxia-hao-and-bing-lv/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 08 May 2025 16:00:00 +0000</pubDate>
</item>
<item>
<title>微软研究新进展：复合AI系统、因果验证及推理模型优化</title>
<link>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-may-7-2025/</link>
<guid>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-may-7-2025/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文介绍了复合AI系统的资源效率改进及因果验证技术的新突破。</p><br /><br /><p><strong>摘要：</strong> 本文探讨了复合AI系统架构的效率提升方案，提出Murakkab系统，通过重新设计工作流显著提高资源利用率。同时，文中还介绍了用于分布式系统验证的智能随意验证技术，并展示了其在保密联盟框架中的应用效果。此外，Phi-4-reasoning推理模型家族通过监督微调和强化学习提升了复杂推理能力，而ARTIST范式则通过引入自主决策和工具集成增强了大型语言模型的动态推理能力。这些研究共同推动了AI系统的性能与实用性。</p><br /><br /><p><em>使用 qwen-turbo 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-may-7-2025/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 07 May 2025 23:25:04 +0000</pubDate>
</item>
<item>
<title>人工智能助力核聚变研究迈向可持续能源未来</title>
<link>https://www.microsoft.com/en-us/research/blog/microsoft-fusion-summit-explores-how-ai-can-accelerate-fusion-research/</link>
<guid>https://www.microsoft.com/en-us/research/blog/microsoft-fusion-summit-explores-how-ai-can-accelerate-fusion-research/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">AI技术被用于加速核聚变研究，推动清洁能源发展。</p><br /><br /><p><strong>摘要：</strong> 核聚变作为清洁无限能源的追求是人类科学史上最具雄心的目标之一。微软研究院举办的首届融合峰会探讨了如何利用人工智能（AI）加速核聚变研究。会议展示了AI在等离子体控制、材料设计和反应堆优化中的应用潜力，并讨论了全球合作的重要性。通过与国际热核聚变实验堆（ITER）等项目的协作，AI有望在模型设计和实验优化中发挥关键作用，为实现核聚变商业化铺平道路。</p><br /><br /><p><em>使用 qwen-turbo 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/microsoft-fusion-summit-explores-how-ai-can-accelerate-fusion-research/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 07 May 2025 16:00:00 +0000</pubDate>
</item>
<item>
<title>社会AI：研究挑战与机遇</title>
<link>https://www.microsoft.com/en-us/research/podcast/abstracts-societal-ai-with-xing-xie/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/abstracts-societal-ai-with-xing-xie/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">探讨AI系统对人类社会影响的研究报告。</p><br /><br /><p><strong>摘要：</strong> 这份由微软研究院发布的白皮书《社会AI：研究挑战与机遇》聚焦于大型语言模型对教育、经济及文化等领域的深远影响。通过全球范围内的对话与协作，该研究旨在构建跨学科合作框架，解决AI价值对齐、安全性评估等关键问题，并提出未来研究方向。白皮书强调了技术与社会科学结合的重要性，呼吁各界共同应对AI的社会化转型带来的挑战。</p><br /><br /><p><em>使用 qwen-turbo 生成 </em></p><a href="https://www.microsoft.com/en-us/research/podcast/abstracts-societal-ai-with-xing-xie/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 05 May 2025 16:01:00 +0000</pubDate>
</item>
<item>
<title>微软提出社会人工智能研究框架 推动负责任的AI发展</title>
<link>https://www.microsoft.com/en-us/research/blog/societal-ai-building-human-centered-ai-systems/</link>
<guid>https://www.microsoft.com/en-us/research/blog/societal-ai-building-human-centered-ai-systems/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">微软发布白皮书探讨AI如何更好地满足社会需求，提出社会人工智能研究框架。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了微软研究亚洲团队发起的社会人工智能（Societal AI）研究项目，该项目旨在通过跨学科合作探讨AI对教育、医疗、公共政策等领域的深远影响。该研究提出了三大原则——和谐、协同与韧性，并列出了十个关键研究问题，涵盖技术和社会层面的挑战，强调跨学科协作的重要性。这项工作标志着AI发展从单纯的技术进步转向更加关注人类价值和社会需求的阶段。</p><br /><br /><p><em>使用 qwen-turbo 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/societal-ai-building-human-centered-ai-systems/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 05 May 2025 16:00:00 +0000</pubDate>
</item>
<item>
<title>医疗领域的人工智能革命再探：专家探讨伦理与应用</title>
<link>https://www.microsoft.com/en-us/research/podcast/laws-norms-and-ethics-for-ai-in-health/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/laws-norms-and-ethics-for-ai-in-health/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">专家探讨人工智能在医疗领域的应用及其伦理问题。</p><br /><br /><p><strong>摘要：</strong> 本文聚焦于人工智能在医疗领域的最新发展与挑战，通过微软研究播客系列《医学的人工智能革命，重访》中的对话，三位专家——Laura Adams、Vardit Ravitsky 和 Roxana Daneshjou 分别从医疗、伦理和技术角度深入分析了AI在医疗中的应用现状与未来方向。他们讨论了如何负责任地实施AI技术，强调了治理框架的重要性，并提出了关于患者知情同意与隐私保护的伦理考量。同时，专家们还分享了他们在减少AI偏见和提升模型透明度方面的研究成果及实践案例。</p><br /><br /><p><em>使用 qwen-turbo 生成 </em></p><a href="https://www.microsoft.com/en-us/research/podcast/laws-norms-and-ethics-for-ai-in-health/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 01 May 2025 16:00:00 +0000</pubDate>
</item>
<item>
<title>微软研究前沿进展：因果推理、LLMs增强及多领域应用</title>
<link>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-april-21-2025/</link>
<guid>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-april-21-2025/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">微软在CHI 2025和ICLR 2025展示最新研究，涵盖因果推理、LLMs增强等。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了微软在CHI 2025和ICLR 2025上的多项研究进展，包括因果推理与大语言模型（LLMs）的结合、提升LLMs安全性和鲁棒性的增强技术、人机协作对AI能力的影响分析，以及一款高效紧凑型语音质量评估模型Distill-MOS。此外，还涉及AI工具对知识工作的影响、应对农村医疗挑战的技术合作，以及AI在医疗保健领域的多样化应用。这些研究展示了微软在推动人工智能技术进步及其社会影响方面的持续努力。</p><br /><br /><p><em>使用 qwen-turbo 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-april-21-2025/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 23 Apr 2025 16:00:00 +0000</pubDate>
</item>
<item>
<title>微软研究：AI如何提升人类认知与工作效率</title>
<link>https://www.microsoft.com/en-us/research/blog/the-future-of-ai-in-knowledge-work-tools-for-thought-at-chi-2025/</link>
<guid>https://www.microsoft.com/en-us/research/blog/the-future-of-ai-in-knowledge-work-tools-for-thought-at-chi-2025/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">微软研究探讨AI如何改变工作中的思考方式并支持不同认知任务。</p><br /><br /><p><strong>摘要：</strong> 本文综述了微软研究团队关于AI对人类认知影响的最新成果，包括AI如何改变工作中的思考模式、支持知识工作者的批判性思维，以及如何通过设计促进更高效的决策过程。此外，还介绍了三个原型系统用于辅助认知任务，同时探索AI在会议管理及多样化问题解决中的应用。这些研究旨在帮助定义AI在支持人类思维方面的角色，促进多学科合作以推动下一代AI工具的发展。</p><br /><br /><p><em>使用 qwen-turbo 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/the-future-of-ai-in-knowledge-work-tools-for-thought-at-chi-2025/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 18 Apr 2025 16:00:00 +0000</pubDate>
</item>
<item>
<title>重新审视医学领域的人工智能革命</title>
<link>https://www.microsoft.com/en-us/research/podcast/the-ai-revolution-in-medicine-revisited-empowering-patients-and-healthcare-consumers-in-the-age-of-generative-ai/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/the-ai-revolution-in-medicine-revisited-empowering-patients-and-healthcare-consumers-in-the-age-of-generative-ai/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">微软研究总裁彼得·李探讨了AI在医疗领域的应用及其对患者的影响。</p><br /><br /><p><strong>摘要：</strong> 本文通过彼得·李与两位嘉宾的对话，探讨了人工智能如何改变患者的参与度和数字健康商业模式。戴夫·德布隆卡特分享了他作为癌症幸存者利用AI工具如ChatGPT的经验，而克里斯蒂娜·法尔则讨论了AI在女性健康、儿科和老年护理中的影响。他们还探讨了消费者趋势及现金支付医疗的趋势，强调了患者自主权的重要性。</p><br /><br /><p><em>使用 qwen-turbo 生成 </em></p><a href="https://www.microsoft.com/en-us/research/podcast/the-ai-revolution-in-medicine-revisited-empowering-patients-and-healthcare-consumers-in-the-age-of-generative-ai/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 17 Apr 2025 23:10:09 +0000</pubDate>
</item>
<item>
<title>Engagement, user expertise, and satisfaction: Key insights from the Semantic Telemetry Project</title>
<link>https://www.microsoft.com/en-us/research/blog/engagement-user-expertise-and-satisfaction-key-insights-from-the-semantic-telemetry-project/</link>
<guid>https://www.microsoft.com/en-us/research/blog/engagement-user-expertise-and-satisfaction-key-insights-from-the-semantic-telemetry-project/</guid>
<content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img alt="The image features four white icons on a gradient background that transitions from blue on the left to green on the right. The first icon is a network or molecule structure with interconnected nodes. The second icon is a light bulb, symbolizing an idea or innovation. The third icon is a checklist with three items and checkmarks next to each item. The fourth icon consists of two overlapping speech bubbles, representing communication or conversation." class="wp-image-1136384" height="1182" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Semantic-Telemetry-2-BlogHeroFeature-1400x788-1.jpg" width="2100" /></figure>



<p>The <a href="https://www.microsoft.com/en-us/research/project/semantic-telemetry/" rel="noreferrer noopener" target="_blank">Semantic Telemetry Project</a> aims to better understand complex, turn-based human-AI interactions in Microsoft Copilot using a new data science approach.&nbsp;</p>



<p>This understanding is crucial for recognizing how individuals utilize AI systems to address real-world tasks. It provides actionable insights, enhances key use cases , and identifies opportunities for system improvement.</p>



<p>In a recent <a href="https://www.microsoft.com/en-us/research/blog/semantic-telemetry-understanding-how-users-interact-with-ai-systems/?msockid=0f3bfc3f6f3464c71ab7e9906e196520">blog post</a>, we shared our approach for classifying chat log data using large language models (LLMs), which allows us to analyze these interactions at scale and in near real time. We also introduced two of our LLM-generated classifiers: Topics and Task Complexity. </p>



<p>This blog post will examine how our suite of LLM-generated classifiers can serve as early indicators for user engagement and highlight how usage and satisfaction varies based on AI and user expertise.</p>



<p><strong>The key findings from our research are:&nbsp;</strong></p>



<ul class="wp-block-list">
<li>When users engage in more professional, technical, and complex tasks, they are more likely to continue utilizing the tool and increase their level of interaction with it.&nbsp;</li>



<li>Novice users currently engage in simpler tasks, but their work is gradually becoming more complex over time.&nbsp;</li>



<li>More expert users are satisfied with AI responses only where AI expertise is on par with their own expertise on the topic, while novice users had low satisfaction rates regardless of AI expertise.&nbsp;</li>
</ul>



<p>Read on for more information on these findings. Note that all analyses were conducted on anonymous Copilot in Bing interactions containing no personal information.&nbsp;</p>



<div class="wp-block-msr-immersive-section alignfull row has-background has-lighter-gray-background-color has-text-color has-black-color wp-block-msr-immersive-section" style="padding-bottom: 0; padding-top: 0;">
	
	<div class="container">
		<div class="wp-block-msr-immersive-section__inner wp-block-msr-immersive-section__inner--narrow">
			<hr class="wp-block-separator has-alpha-channel-opacity" />



<p><em>Classifiers mentioned in article:&nbsp;</em></p>



<p><strong>Knowledge work classifier</strong>: Tasks that involve creating artifacts related to information work typically requiring creative and analytical thinking. Examples include strategic business planning, software design, and scientific research.&nbsp;</p>



<p><a href="https://www.microsoft.com/en-us/research/blog/semantic-telemetry-understanding-how-users-interact-with-ai-systems/?msockid=0f3bfc3f6f3464c71ab7e9906e196520" rel="noreferrer noopener" target="_blank"><strong>Task complexity classifier</strong></a>: Assesses the cognitive complexity of a task if a user performs it without the use of AI. We group into two categories: <em>low complexity</em> and <em>high complexity</em>.&nbsp;</p>



<p><strong>Topics classifier</strong>: A single label for the primary topic of the conversation.</p>



<p><strong>User expertise: </strong>Labels the user’s expertise on the primary topic within the conversation as one of the following categories: Novice (no familiarity with the topic), Beginner (little prior knowledge or experience), Intermediate (some basic knowledge or familiarity with the topic), Proficient (can apply relevant concepts from conversation), and Expert (deep and comprehensive understanding of the topic).&nbsp;</p>



<p><strong>AI expertise: </strong>Labels the AI agent expertise based on the same criteria as user expertise above.&nbsp;</p>



<p><strong>User satisfaction: </strong>A 20-question satisfaction/dissatisfaction rubric that the LLM evaluates to create an aggregate score for overall user satisfaction.&nbsp;</p>



<hr class="wp-block-separator has-alpha-channel-opacity" />		</div>
	</div>

	</div>



<h2 class="wp-block-heading" id="what-keeps-bing-chat-users-engaged">What keeps Bing Chat users engaged?&nbsp;</h2>



<p>We conducted a study of a random sample of 45,000 anonymous Bing Chat users during May 2024. The data was grouped into three cohorts based on user activity over the course of the month:&nbsp;</p>



<ul class="wp-block-list">
<li><em>Light </em>(1 active chat session per week)&nbsp;</li>



<li><em>Medium</em> (2-3 active chat sessions per week)&nbsp;</li>



<li><em>Heavy</em> (4+ active chat sessions per week)&nbsp;</li>
</ul>



<p><strong>The key finding is that </strong><strong><em>heavy users</em></strong><strong> are doing more professional, complex work.</strong>&nbsp;</p>



<p>We utilized our <strong>knowledge work classifier</strong> to label the chat log data as relating to knowledge work tasks. What we found is knowledge work tasks were higher in all cohorts, with the highest percentage in <em>heavy users</em>.&nbsp;</p>



<figure class="wp-block-image aligncenter size-full"><img alt="Bar chart illustrating knowledge work distribution across three engagement cohorts: light, medium, and heavy. The chart shows that all three cohorts engage in more knowledge work compared to the 'Not knowledge work' and 'Both' categories, with heavy users performing the most knowledge work. " class="wp-image-1136247" height="1429" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Figure_1_Engagement-Knowledge-Work.png" width="2308" /><figcaption class="wp-element-caption"><em>Figure 1: Knowledge work based on engagement cohort</em></figcaption></figure>



<p>Analyzing task complexity, we observed that users with higher engagement frequently perform the highest number of tasks with high complexity, while users with lower engagement performed more tasks with low complexity.&nbsp;</p>



<figure class="wp-block-image aligncenter size-full"><img alt="Bar chart illustrating task complexity distribution across three engagement cohorts: light, medium, and heavy. The chart shows all three cohorts perform more high complexity tasks than low complexity tasks, with heavy users performing the greatest number of high complexity tasks. " class="wp-image-1136248" height="1087" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Figure_2_Engagement-task-complexity.png" width="1798" /><figcaption class="wp-element-caption"><em>Figure 2: High complexity and low complexity tasks by engagement cohort+</em>&nbsp;</figcaption></figure>



<p>Looking at the overall data, we can filter on heavy users and see higher numbers of chats where the user was performing <em>knowledge work</em> tasks. Based on task complexity, we see that most <em>knowledge work </em>tasks seek to apply a solution to an existing problem, primarily within <em>programming and scripting</em>. This is in line with our top overall topic, <em>technology</em>, which we discussed in the previous post.&nbsp;</p>



<figure class="wp-block-image aligncenter size-full"><img alt="Tree diagram illustrating how heavy users are engaging with Bing Chat. The visual selects the most common use case for heavy users: knowledge work, “apply” complexity and related topics.  " class="wp-image-1136249" height="1219" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Figure_3_Engagement-heavy-users-tree-view.png" width="2161" /><figcaption class="wp-element-caption"><em>Figure 3: Heavy users tree diagram</em>&nbsp;</figcaption></figure>



<p>In contrast, <em>light users</em> tended to do more <em>low complexity </em>tasks (<a href="https://www.microsoft.com/en-us/research/blog/semantic-telemetry-understanding-how-users-interact-with-ai-systems/?msockid=061a2f481be2670621233a8a1a5866f2">“Remember”</a>), using Bing Chat like a traditional search engine and engaging more in topics like <em>business and finance </em>and <em>computers and electronics.</em></p>



<figure class="wp-block-image aligncenter size-large"><img alt="Tree diagram illustrating how light users are engaging with Bing Chat. The visual selects the most common use case for light users: knowledge work, “remember” complexity and related topics. " class="wp-image-1136250" height="580" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Figure_4_Engagement-light-users-tree-view-1024x580.png" width="1024" /><figcaption class="wp-element-caption"><em>Figure 4: Light users tree diagram</em>&nbsp;</figcaption></figure>



<h2 class="wp-block-heading" id="novice-queries-are-becoming-more-complex">Novice queries are becoming more complex&nbsp;</h2>



<p>We looked at Bing Chat data from January through August 2024 and we classified chats using our <strong>User Expertise</strong> classifier. When we looked at how the different user expertise groups were using the tool for professional tasks, we discovered that proficient and expert users tend to do more professional tasks with high complexity in topics like <em>programming and scripting, professional writing and editing</em>, <em>and physics and chemistry</em>.&nbsp;</p>



<figure class="wp-block-image aligncenter size-full"><img alt="Bar chart illustrating top topics for proficient and expert users with programming and scripting (18.3%), professional writing and editing (10.4%), and physics and chemistry (9.8%) as top three topics. " class="wp-image-1136251" height="1135" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Figure_5_Proficent-Expert-top-topics.png" width="1576" /><figcaption class="wp-element-caption"><em>Figure 5: Top topics for proficient/expert users</em>&nbsp;</figcaption></figure>



<figure class="wp-block-image aligncenter size-full"><img alt="Bar chart showing task complexity for proficient and expert users. The chart shows a greater number of high complexity chats than low complexity chats, with the highest percentage in categories “Understand” (30.8%) and “Apply” (29.3%). " class="wp-image-1136252" height="667" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Figure_6_Proficent-expert-task-complexity.png" width="1329" /><figcaption class="wp-element-caption"><em>Figure 6: Task complexity for proficient/expert</em>&nbsp;</figcaption></figure>



<figure class="wp-block-image aligncenter size-full"><img alt="Bar chart illustrating top topics for novice users with business and finance (12.5%), education and learning (10.0%), and computers and electronics (9.8%) as top three topics. " class="wp-image-1136253" height="1386" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Figure_7_Novice-top-topics.png" width="1882" /><figcaption class="wp-element-caption"><em>Figure 7: Top topics for novices</em>&nbsp;</figcaption></figure>



<p>In contrast, novice users engaged more in professional tasks relating to <em>business and finance</em> and <em>education and learning, </em>mainly using the tool to recall information.</p>



<figure class="wp-block-image aligncenter size-full"><img alt="Bar chart showing task complexity for novice users. The chart shows a greater number of low complexity chats than high complexity chats, with the highest percentage in categories “Remember” (48.6%). " class="wp-image-1136254" height="799" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Figure_8_novice-task-complexity.png" width="1588" /><figcaption class="wp-element-caption"><em>Figure 8: Task complexity for novices</em>&nbsp;</figcaption></figure>



<p>However, novices are targeting increasingly more complex tasks over time. Over the eight-month period, we see the percentage of high complexity tasks rise from about 36% to 67%, revealing that novices are learning and adapting quickly (see Figure 9).&nbsp;</p>



<figure class="wp-block-image aligncenter size-large"><img alt="Line chart showing weekly percentage of high complexity chats for novice users from January-August 2024. The line chart starts at 35.9% in January and ends at 67.2% in August.  " class="wp-image-1136255" height="672" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Figure_9_weekly-high-complexity-novice-1024x672.png" width="1024" /><figcaption class="wp-element-caption"><em>Figure 9: High complexity for novices Jan-Aug 2024</em>&nbsp;</figcaption></figure>



<h2 class="wp-block-heading" id="how-does-user-satisfaction-vary-according-to-expertise">How does user satisfaction vary according to expertise?&nbsp;</h2>



<p>We classified both the user expertise and AI agent expertise for anonymous interactions in Copilot in Bing. We compared the level of user and AI agent expertise with our <strong>user satisfaction classifier</strong>.&nbsp;</p>



<p><strong>The key takeaways are:</strong>&nbsp;</p>



<ul class="wp-block-list">
<li>Experts and proficient users are only satisfied with AI agents with similar expertise (expert/proficient).&nbsp;</li>



<li>Novices are least satisfied, regardless of the expertise of the AI agent.&nbsp;</li>
</ul>



<figure class="wp-block-image aligncenter size-full"><img alt="Table illustrating user satisfaction based on expertise level of user and agent. Each row if the table is the user expertise group (novice, beginner, intermediate, proficient, expert) and on the columns is AI expertise group (novice, beginner, intermediate, proficient, expert). The table illustrates that novice users are least satisfied overall and expert/proficient users are satisfied with AI expertise of proficient/expert.  " class="wp-image-1136256" height="859" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Figure_10_Sat-by-User-AI.png" width="2548" /><figcaption class="wp-element-caption"><em>Figure 10: Copilot in Bing satisfaction intersection of AI expertise and User expertise (August-September 2024)</em>&nbsp;</figcaption></figure>



<h2 class="wp-block-heading" id="conclusion">Conclusion</h2>



<p>Understanding these metrics is vital for grasping user behavior over time and relating it to real-world business indicators. Users are finding value from complex professional knowledge work tasks, and novices are quickly adapting to the tool and finding these high value use-cases. By analyzing user satisfaction in conjunction with expertise levels, we can tailor our tools to better meet the needs of different user groups. Ultimately, these insights can help improve user understanding across a variety of tasks.&nbsp;&nbsp;</p>



<p>In our next post, we will examine the engineering processes involved in LLM-generated classification.</p>
<span class="sr-only" id="label-external-link">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/blog/engagement-user-expertise-and-satisfaction-key-insights-from-the-semantic-telemetry-project/">Engagement, user expertise, and satisfaction: Key insights from the Semantic Telemetry Project</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
<pubDate>Mon, 14 Apr 2025 19:00:00 +0000</pubDate>
</item>
<item>
<title>Debug-gym: an environment for AI coding tools to learn how to debug code like programmers</title>
<link>https://www.microsoft.com/en-us/research/blog/debug-gym-an-environment-for-ai-coding-tools-to-learn-how-to-debug-code-like-programmers/</link>
<guid>https://www.microsoft.com/en-us/research/blog/debug-gym-an-environment-for-ai-coding-tools-to-learn-how-to-debug-code-like-programmers/</guid>
<content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img alt="A graphic with a gradient background transitioning from blue on the left to pink on the right. The graphic features a white outline of a computer monitor with code brackets on the screen, an arrow pointing downwards into the monitor, and another arrow curving around to point upwards towards a magnifying glass with a bug icon inside it." class="wp-image-1136365" height="1182" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/NEWDeBug-BlogHeroFeature-1400x788-1.jpg" width="2100" /></figure>



<p>The ongoing proliferation of AI coding tools is not only boosting developers’ efficiency, it also signals a future where AI will generate a growing share of all new code. <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.freethink.com/robots-ai/github-copilot" rel="noreferrer noopener" target="_blank">GitHub CEO Thomas Dohmke<span class="sr-only"> (opens in new tab)</span></a> predicted as much in 2023, when he said that &#8220;sooner than later, 80% of the code is going to be written by Copilot.&#8221;&nbsp;&nbsp;</p>



<p>Both large and small software companies are already heavily using AI to generate code. <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.youtube.com/watch?v=coojA-odaTk&amp;t=861s" rel="noreferrer noopener" target="_blank">Y Combinator’s Garry Tan<span class="sr-only"> (opens in new tab)</span></a> noted that 95% of code for a quarter of Y Combinator’s latest batch of startups was written by large language models.</p>



<p>In fact, <strong>most developers spend the majority of their time debugging code,</strong> not writing it. As maintainers of popular open-source repositories, this resonates with us. But what if an AI tool could propose fixes for hundreds of open issues, and all we had to do was approve them before merging? This was what motivated us to maximize the potential time savings from AI coding tools by teaching them to debug code.&nbsp;</p>



<p>By debugging we mean the interactive, iterative process to fix code. Developers typically hypothesize why their code crashed, then gather evidence by stepping through the program and examining variable values. They often use debugging tools like pdb (Python debugger) to assist in gathering information. This process is repeated until the code is fixed.</p>



<p>Today&#8217;s AI coding tools boost productivity and excel at suggesting solutions for bugs based on available code and error messages. However, unlike human developers, these tools don&#8217;t seek additional information when solutions fail, leaving some bugs unaddressed, as you can see in this simple <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://microsoft.github.io/debug-gym/" rel="noreferrer noopener" target="_blank">demo of how a mislabeled column stumps today’s coding tools<span class="sr-only"> (opens in new tab)</span></a>. This may leave users feeling like AI coding tools don’t understand the full context of the issues they are trying to solve.&nbsp;</p>



<h2 class="wp-block-heading" id="introducing-debug-gym">Introducing debug-gym</h2>



<p>A natural research question emerges: <strong>to what degree can LLMs use interactive debugging tools such as pdb?</strong> To explore this question, we released <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://microsoft.github.io/debug-gym/" rel="noreferrer noopener" target="_blank"><strong>debug-gym</strong><span class="sr-only"> (opens in new tab)</span></a> – an environment that allows code-repairing agents to access tools for active information-seeking behavior. Debug-gym expands an agent’s action and observation space with feedback from tool usage, enabling setting breakpoints, navigating code, printing variable values, and creating test functions. Agents can interact with tools to investigate code or rewrite it, if confident. We believe interactive debugging with proper tools can empower coding agents to tackle real-world software engineering tasks and is central to LLM-based agent research. The fixes proposed by a coding agent with debugging capabilities, and then approved by a human programmer, will be grounded in the context of the relevant codebase, program execution and documentation, rather than relying solely on guesses based on previously seen training data.</p>



<figure class="wp-block-image aligncenter size-full"><img alt="Figure 1: Diagram demonstrating the code-repairing process in outline. Left: conventional code-repairing system; right: additional tools enabled by debug-gym." class="wp-image-1136156" height="488" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/DeBug_intro_diagram_v2.png" width="1503" /><figcaption class="wp-element-caption">Figure 1: Diagram demonstrating the code-repairing process in outline. In most existing approaches (shown in <strong>black</strong>), an agent rewrites its code conditioned on error messages obtained from executing the code. debug-gym equips the agent with additional tools such as pdb (shown in <strong>red</strong>), so it can interactively seek necessary information from the semantic space hidden behind the code and therefore have better code-repairing performance.</figcaption></figure>



<p>Debug-gym is designed and developed to:</p>



<ul class="wp-block-list">
<li><strong>Handle repository-level information</strong>: the full repository is available to agents in debug-gym, allowing them to navigate and edit files.</li>



<li><strong>Be robust and safe</strong>: to safeguard both the system and the development process, debug-gym runs code within sandbox Docker containers. This isolates the runtime environment, preventing harmful actions while still allowing thorough testing and debugging.&nbsp;&nbsp;</li>



<li><strong>Be easily extensible</strong>: debug-gym was conceived with extensibility in mind and provides practitioners with the possibility of easily adding new tools.&nbsp;&nbsp;</li>



<li><strong>Be text-based</strong>: debug-gym represents observation information in structured text (e.g., JSON format) and defines a simple syntax for text actions, making the environment fully compatible with modern LLM-based agents.</li>
</ul>



<p>With debug-gym, researchers and developers can specify a folder path to work with any custom repository to evaluate their debugging agent&#8217;s performance. Additionally, debug-gym includes three coding benchmarks to measure LLM-based agents’ performance in interactive debugging: Aider for simple function-level code generation, Mini-nightmare for short, hand-crafted buggy code examples, and SWE-bench for real-world coding problems requiring a comprehensive understanding of a large codebase and a solution in the format of a GitHub pull request.</p>



<p>To learn more about debug-gym and start using it to train your own debugging agents, please refer to the <a href="https://www.microsoft.com/en-us/research/publication/debug-gym-a-text-based-environment-for-interactive-debugging/" rel="noreferrer noopener" target="_blank">technical report<span class="sr-only"> (opens in new tab)</span></a> and <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/debug-gym" rel="noreferrer noopener" target="_blank">GitHub<span class="sr-only"> (opens in new tab)</span></a>.&nbsp;</p>



<h2 class="wp-block-heading" id="early-experimentation-promising-signal">Early experimentation: promising signal</h2>



<p>For our initial attempt to validate that LLMs perform better on coding tests when they have access to debugging tools, we built a simple prompt-based agent and provided it with access to the following debug tools: eval, view, pdb, rewrite, and listdir. We used nine different LLMs as the backbone for our agent. Detailed results can be found in the <a href="https://www.microsoft.com/en-us/research/publication/debug-gym-a-text-based-environment-for-interactive-debugging/">technical report<span class="sr-only"> (opens in new tab)</span></a><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/pdf/2503.21557" rel="noreferrer noopener" target="_blank">.<span class="sr-only"> (opens in new tab)</span></a></p>



<p>Even with debugging tools, our simple prompt-based agent rarely solves more than half of the <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.swebench.com/lite.html" rel="noreferrer noopener" target="_blank">SWE-bench <span class="sr-only"> (opens in new tab)</span></a>Lite issues. We believe this is due to the scarcity of data representing sequential decision-making behavior (e.g., debugging traces) in the current LLM training corpus. However, the significant performance improvement (as shown in the most promising results in the graph below) validates that this is a promising research direction.&nbsp;</p>



<figure class="wp-block-image aligncenter size-full"><img alt="Figure 2: The success rate represents the percentage of the 300 SWE-bench Lite issues resolved, comparing between agents with and without debugging tools." class="wp-image-1136159" height="974" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/DeBug_froggy_bar_chart.png" width="1934" /><figcaption class="wp-element-caption">Figure 2: The success rate represents the percentage of the 300 SWE-bench Lite issues resolved. The green bars indicate the performance of the agent with debugging tools, while the gray bars show the performance of the agent without debugging tools. Note that both agents use the same backbone LLM to make decisions and propose code edits.</figcaption></figure>



	<div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide">
		

		<p class="msr-promo__label text-gray-800 text-center text-uppercase">
		<span class="px-4 bg-white display-inline-block font-weight-semibold small">Microsoft research podcast</span>
	</p>
	
	<div class="row pt-3 pb-4 align-items-center">
						<div class="msr-promo__media col-12 col-md-5">
				<a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/podcast/collaborators-silica-in-space-with-richard-black-and-dexter-greene/" target="_blank">
					<img alt="Headshots of Richard Black and Dexter Greene for the Microsoft Research Podcast" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2024/09/Richard-and-Dexter_Collaborators_Hero_Feature_No_Text_1400x788-1.jpg" />
				</a>
			</div>
			
			<div class="msr-promo__content p-3 px-5 col-12 col-md">

									<h2 class="h4">Collaborators: Silica in space with Richard Black and Dexter Greene</h2>
				
								<p class="large">College freshman Dexter Greene and Microsoft research manager Richard Black discuss how technology that stores data in glass is supporting students as they expand earlier efforts to communicate what it means to be human to extraterrestrials.</p>
				
								<div class="wp-block-buttons justify-content-center justify-content-md-start">
					<div class="wp-block-button">
						<a class="btn btn-brand glyph-append glyph-append-chevron-right" href="https://www.microsoft.com/en-us/research/podcast/collaborators-silica-in-space-with-richard-black-and-dexter-greene/" target="_blank">
							Listen now						</a>
					</div>
				</div>
							</div><!--/.msr-promo__content-->
	</div><!--/.msr-promo__inner-wrap-->
<span class="sr-only" id="label-external-link">Opens in a new tab</span>	</div><!--/.msr-promo-->
	


<h2 class="wp-block-heading" id="future-work">Future work</h2>



<p>We believe that training or fine-tuning LLMs can enhance their interactive debugging abilities. This requires specialized data, such as trajectory data that records agents interacting with a debugger to gather information before suggesting a fix. Unlike conventional reasoning problems, interactive debugging involves generating actions at each step that trigger feedback from the environment. This feedback helps the agent make new decisions, requiring dense data like the problem description and the sequence of actions leading to the solution.&nbsp;</p>



<p>Our plan is to fine-tune an info-seeking model specialized in gathering the necessary information to resolve bugs. The goal is to use this model to actively build relevant context for a code generation model. If the code generation model is large, there is an opportunity to build a smaller info-seeking model that can provide relevant information to the larger one, e.g., a generalization of retrieval augmented generation (RAG), thus saving AI inference costs. The data collected during the reinforcement learning loop to train the info-seeking model can also be used to fine-tune larger models for interactive debugging.</p>



<p>We are open-sourcing debug-gym to facilitate this line of research. We encourage the community to help us advance this research towards building interactive debugging agents and, more generally, agents that can seek information by interacting with the world on demand.</p>



<h2 class="wp-block-heading" id="acknowledgements">Acknowledgements</h2>



<p>We thank Ruoyao Wang for their insightful discussion on building interactive debugging agents, Chris Templeman and Elaina Maffeo for their team coaching, Jessica Mastronardi and Rich Ciapala for their kind support in project management and resource allocation, and Peter Jansen for providing valuable feedback for the technical report.</p>
<span class="sr-only" id="label-external-link">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/blog/debug-gym-an-environment-for-ai-coding-tools-to-learn-how-to-debug-code-like-programmers/">Debug-gym: an environment for AI coding tools to learn how to debug code like programmers</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
<pubDate>Thu, 10 Apr 2025 16:00:00 +0000</pubDate>
</item>
<item>
<title>Research Focus: Week of April 7, 2025</title>
<link>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-april-7-2025/</link>
<guid>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-april-7-2025/</guid>
<content:encoded><![CDATA[
<p class="has-text-align-center"><strong>In this issue:</strong></p>



<p>We introduce a new dataset designed to assist renewable energy infrastructure planners, a new method for denoising MRI imagery, and an AI tool for analyzing distant galaxies. Check out our latest research and other updates.&nbsp;</p>



<figure class="wp-block-image size-full"><img alt="Research Focus -- Week of April 7" class="wp-image-1136071" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/RF59-BlogHeroFeature-1400x788-1.jpg" width="1401" /></figure>



<h2 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-e734c6e9609233ab051742bb3beeed63" id="new-research">NEW RESEARCH</h2>



<h3 class="wp-block-heading h2" id="global-renewables-watch-a-temporal-dataset-of-solar-and-wind-energy-derived-from-satellite-imagery">Global Renewables Watch: A Temporal Dataset of Solar and Wind Energy Derived from Satellite Imagery</h3>



<figure class="wp-block-image size-full"><img alt="A 2-panel figure. The left panel shows a global map with the distribution of 86,410 solar PV installations points and 375,197 onshore windmills points detected by our models in 2024 Q2. The right panel shows satellite imagery with annotated solar and wind installations over the village of Farmsum in the Dutch province of Groningen. " class="wp-image-1136208" height="899" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Global-Renewables-Watch-FIG1-1-scaled.jpg" width="2560" /></figure>



<p>Siting renewable energy infrastructure requires careful consideration of the potential impact on ecosystems, cultural and historical resources, agriculture, and scenic landscapes. To help policymakers, researchers, and other stakeholders assess strategies for deployment, researchers from Microsoft, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.nature.org/en-us/" rel="noreferrer noopener" target="_blank">The Nature Conservancy<span class="sr-only"> (opens in new tab)</span></a>, and <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.planet.com/" rel="noreferrer noopener" target="_blank">Planet<span class="sr-only"> (opens in new tab)</span></a> present a comprehensive global temporal dataset of commercial solar photovoltaic (PV) farms and onshore wind turbines.</p>



<p>The researchers built the dataset by training deep learning-based segmentation models on high-resolution satellite imagery and then deploying them on over 13 trillion pixels of images covering the world. The final spatial dataset includes 375,197 individual wind turbines and 86,410 solar photovoltaic installations. For each detected feature, they estimate the construction date and the preceding land use type, and aggregate their findings to the country level, along with estimates of total power capacity.</p>



<div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-1 wp-block-buttons-is-layout-flex">
<div class="wp-block-button is-style-outline is-style-outline--1"><a class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/global-renewables-watch-a-temporal-dataset-of-solar-and-wind-energy-derived-from-satellite-imagery/">Read the paper</a></div>
</div>



<hr class="wp-block-separator has-alpha-channel-opacity is-style-dots" />



<h2 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-9a2357e04d6b68359937ec2fcc67b1a5" id="new-research-1">NEW RESEARCH</h2>



<h3 class="wp-block-heading h2" id="snraware-improved-deep-learning-mri-denoising-with-snr-unit-training-and-g-factor-map-augmentation">SNRAware: Improved Deep Learning MRI Denoising with SNR Unit Training and G-factor Map Augmentation</h3>



<p>This research proposes a new training method, SNRAware, to improve the ability of deep learning models to denoise—or remove unwanted random variations—from MRI images. MRI images can suffer from high levels of noise when scanning is accelerated with parallel imaging or when data are acquired using lower cost, low-field MRI systems. &nbsp;</p>



<p>The researchers tested SNRAware on 14 different models, including ones based on transformer and convolutional architectures. The proposed training scheme improved the performance of all the tested models. This broad applicability means that the method is flexible and can be applied to different kinds of models without redesigning them. The testing showed SNRAware significantly improves the quality and clinical utility of MRI images while preserving important diagnostic details.</p>



<figure class="wp-block-image size-full"><img alt="The movies correspond to the example in Figure 1b. The ground-truth clean 
image is the single one on the left.  The first row are the noisy samples. The second 
row are the SNR images. " class="wp-image-1136115" height="648" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/SNRAware.gif" width="1152" /></figure>



<div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-2 wp-block-buttons-is-layout-flex">
<div class="wp-block-button is-style-outline is-style-outline--2"><a class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/snraware-improved-deep-learning-mri-denoising-with-snr-unit-training-and-g-factor-map-augmentation/">Read the paper</a></div>
</div>



<hr class="wp-block-separator has-alpha-channel-opacity is-style-dots" />



<h2 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-8580525ca5a22a10ee7a4694b8f59445" id="new-research-2">NEW RESEARCH</h2>



<h3 class="wp-block-heading h2" id="can-ai-unlock-the-mysteries-of-the-universe">Can AI unlock the mysteries of the universe? </h3>



<figure class="wp-block-image aligncenter size-full"><img alt="An astronomer’s workflow involves using a space telescope to observe a large number galaxies. Astronomers identify “interesting” phenomena and attempt to explain them through a series of physical models." class="wp-image-1136077" height="627" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/galaxies_analysis-TWLIFB-1200x627-1.jpg" width="1200" /></figure>



<p>Analyzing the physical properties of individual galaxies is a fundamental skill in astronomy. It requires a thorough understanding of galaxy formation theories and the ability to interpret vast amounts of observational data. However, even for seasoned astronomers, this process can be time-consuming and labor-intensive. To help astronomers accelerate this fundamental process, researchers from Microsoft and external colleagues introduce <a href="https://www.microsoft.com/en-us/research/publication/interpreting-multi-band-galaxy-observations-with-large-language-model-based-agents/">Mephisto,</a> research designed to analyze extremely distant galaxies observed by the James Webb Space Telescope (JWST).</p>



<p>Mephisto analyzes photometric data from distant galaxies, proposing physical models and interacting with <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://cigale.lam.fr/" rel="noreferrer noopener" target="_blank">Code Investigating Galaxy Emission<span class="sr-only"> (opens in new tab)</span></a>, a commonly used galaxy spectral simulation program. Mephisto can detect discrepancies between models and observational data, identifies potential instrumental errors or limitations in the models, iteratively adjusts parameters, and generates multiple explanations for the observational data.</p>



<div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-3 wp-block-buttons-is-layout-flex">
<div class="wp-block-button is-style-outline is-style-outline--3"><a class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/articles/can-ai-unlock-the-mysteries-of-the-universe/">Read the article</a></div>
</div>



<hr class="wp-block-separator has-alpha-channel-opacity is-style-dots" />



<h2 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-7f9ceb7f278a1e69211971cf8e80d961" id="applied-ai">APPLIED AI</h2>



<h3 class="wp-block-heading h2" id="japan-airlines-new-ai-app-will-make-it-easier-for-cabin-attendants-to-report-inflight-events-with-microsoft-s-phi-4-small-language-model">Japan Airlines’ new AI app will make it easier for cabin attendants to report inflight events with Microsoft’s Phi-4 small language model</h3>



<p>Japan Airlines (JAL) is using technology developed by Microsoft Research to deploy an AI app that helps flight crews communicate more effectively with ground staff when something unexpected comes up during a flight.</p>



<p>The JAL-AI Report is being developed using Microsoft’s Phi-4 small language model (SLM), which requires less computing power than the large language models (LLMs) most generative AI tools run on, so it can be used offline on a device for specific tasks.</p>



<p>Cabin attendants who have tried it say it can slash the time for writing operation reports by up to two thirds, say, from one hour to 20 minutes, or from 30 minutes to 10 for simpler cases.</p>



<div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-4 wp-block-buttons-is-layout-flex">
<div class="wp-block-button is-style-outline is-style-outline--4"><a class="wp-block-button__link wp-element-button" href="https://news.microsoft.com/source/asia/features/japan-airlines-new-ai-app-will-make-it-easier-for-cabin-attendants-to-report-inflight-events-with-microsofts-phi-4-small-language-model/" rel="noreferrer noopener" target="_blank">Read the story</a></div>
</div>



<hr class="wp-block-separator has-alpha-channel-opacity is-style-dots" />



<div class="wp-block-msr-immersive-section alignfull row wp-block-msr-immersive-section" style="padding-bottom: 64px; padding-top: 64px;">
	
	<div class="container">
		<div class="wp-block-msr-immersive-section__inner">
			<div class="wp-block-msr-cards msr-cards msr-cards--default mt-4 has-text-align-left">
	<div class="msr-cards__inner">
					<div class="heading-wrapper">
				<h2 class="mb-5 ">Microsoft Research | In case you missed it</h2>
			</div>
		
		<div class="row row-cols-1 row-cols-sm-2 row-cols-lg-3">
	<div class="msr-cards__card msr-cards__card--default col">
	<div class="card has-spectrum-border-top__hover material-card h-100 p-0">

		
		<div class="card-body bg-white p-4 pt-3">
							<h3 class="h5">
					<a class="text-decoration-none text-black" href="https://www.ft.com/content/73492128-5822-4bb2-b953-64217eb303e4">
						<span>AI weather forecast project eyes access through desktop computers</span>&nbsp;<span class="glyph-prepend glyph-prepend-small glyph-prepend-chevron-right"></span>
					</a>
				</h3>
										<div class="card__description card__citation small">
					<p>Financial Times | March 20, 2025</p><p>Aardvark Weather uses AI to deliver accurate forecasts in just minutes from a desktop computer. Developed by scientists at the University of Cambridge, with support from the Alan Turing Institute, Microsoft Research, and the European Centre for Medium-Range Weather Forecasts, this technology is tens of times faster than existing methods and requires only a fraction of the computing power.</p>				</div>
			
					</div>
	</div>
</div>
<div class="msr-cards__card msr-cards__card--default col">
	<div class="card has-spectrum-border-top__hover material-card h-100 p-0">

		
		<div class="card-body bg-white p-4 pt-3">
							<h3 class="h5">
					<a class="text-decoration-none text-black" href="https://www.youtube.com/watch?v=rfyS_rLOKUc">
						<span>Director of Microsoft Research talks AI for science (what it really means)</span>&nbsp;<span class="glyph-prepend glyph-prepend-small glyph-prepend-chevron-right"></span>
					</a>
				</h3>
										<div class="card__description card__citation small">
					<p>The Deep View | March 11, 2025</p><p>Chris Bishop, Director, AI for Science, Microsoft Research, discusses what AI is doing for science. This interview dives into how AI is accelerating discovery of new techniques and findings, the benefits of foundation models like Aurora, MatterGen’s capabilities, and AI’s impact on scientists.</p>				</div>
			
					</div>
	</div>
</div>
<div class="msr-cards__card msr-cards__card--default col">
	<div class="card has-spectrum-border-top__hover material-card h-100 p-0">

		
		<div class="card-body bg-white p-4 pt-3">
							<h3 class="h5">
					<a class="text-decoration-none text-black" href="https://archive.ph/I6K88#selection-1571.0-1571.79">
						<span>Microsoft’s Christopher Bishop: Scientific discovery is AI’s killer application</span>&nbsp;<span class="glyph-prepend glyph-prepend-small glyph-prepend-chevron-right"></span>
					</a>
				</h3>
										<div class="card__description card__citation small">
					<p>Financial Times | April 3, 2025</p><p>Christopher Bishop runs Microsoft’s AI for Science research unit, which applies the powerful technology to the natural sciences. Bishop sees the mission of the lab, which was founded in 2022, as accelerating scientific discovery using the technology.</p><p>In this conversation with the Financial Times’ AI editor Madhumita Murgia, he explains why he believes scientific discovery will prove to be the single most important application of the technology.</p>				</div>
			
					</div>
	</div>
</div>
<div class="msr-cards__card msr-cards__card--default col">
	<div class="card has-spectrum-border-top__hover material-card h-100 p-0">

		
		<div class="card-body bg-white p-4 pt-3">
							<h3 class="h5">
					<a class="text-decoration-none text-black" href="https://podcasts.apple.com/us/podcast/innovation-to-impact-ft-dr-matthew-lungren-dr-jonathan/id1552066046?i=1000698934775">
						<span>Innovation to Impact (ft. Dr M &#8211; DGTL Voices with Ed Marx)</span>&nbsp;<span class="glyph-prepend glyph-prepend-small glyph-prepend-chevron-right"></span>
					</a>
				</h3>
										<div class="card__description card__citation small">
					<p>DGTL Voices with Ed Marx | March 12, 2025</p><p>Matthew Lungren, Chief Scientific Officer, Microsoft Health and Life Sciences, and Jonathan Carlson, Managing Director, Microsoft Health Futures, discuss AI&#8217;s transformative impact on radiology and the importance of collaboration in research and product development. They highlight how healthcare organizations can leverage Microsoft&#8217;s resources for innovation, emphasizing Microsoft&#8217;s progress in developing radiology-specific multimodal models and its broader work in healthcare.</p>				</div>
			
					</div>
	</div>
</div>
<div class="msr-cards__card msr-cards__card--default col">
	<div class="card has-spectrum-border-top__hover material-card h-100 p-0">

		
		<div class="card-body bg-white p-4 pt-3">
							<h3 class="h5">
					<a class="text-decoration-none text-black" href="https://www.bbc.co.uk/sounds/play/w3ct5wnm">
						<span>Tech Life &#8211; The doctor will see you now</span>&nbsp;<span class="glyph-prepend glyph-prepend-small glyph-prepend-chevron-right"></span>
					</a>
				</h3>
										<div class="card__description card__citation small">
					<p>BBC Sounds | March 4, 2025</p><p>An update from the live trials in Ghana of Microsoft Research&#8217;s Holoportation 3D telemedicine technology. BBC&#8217;s Tech Life speaks to lead researcher Spencer Fowers, as well as a patient and doctor benefiting from the portable kit.</p><p>Related video: <a href="https://newsroom.ap.org/editorial-photos-videos/detail?itemid=997c14f31e214dd1b9c7a09af8a79d27" rel="noreferrer noopener" target="_blank">3D telemedicine offers help to sick Ghanaians in remote locations</a></p>				</div>
			
					</div>
	</div>
</div>
<div class="msr-cards__card msr-cards__card--default col">
	<div class="card has-spectrum-border-top__hover material-card h-100 p-0">

		
		<div class="card-body bg-white p-4 pt-3">
							<h3 class="h5">
					<a class="text-decoration-none text-black" href="https://spectrum.ieee.org/ai-video-games">
						<span>Microsoft Unveils New AI Model to Edit Video Games</span>&nbsp;<span class="glyph-prepend glyph-prepend-small glyph-prepend-chevron-right"></span>
					</a>
				</h3>
										<div class="card__description card__citation small">
					<p>IEEE Spectrum | March 11, 2025</p><p>Lead researcher Katja Hoffman discusses Microsoft&#8217;s Muse, a transformer model with 1.6 billion parameters trained on 500,000 hours of player data that can generate gameplay examples from a single screenshot.</p>				</div>
			
					</div>
	</div>
</div>
<div class="msr-cards__card msr-cards__card--default col">
	<div class="card has-spectrum-border-top__hover material-card h-100 p-0">

		
		<div class="card-body bg-white p-4 pt-3">
							<h3 class="h5">
					<a class="text-decoration-none text-black" href="https://news.nus.edu.sg/nus-microsoft-research-asia-advance-ai-research-cultivate-computing-talent/">
						<span>National University of Singapore collaborates with Microsoft Research Asia to advance AI research and cultivate computing talent</span>&nbsp;<span class="glyph-prepend glyph-prepend-small glyph-prepend-chevron-right"></span>
					</a>
				</h3>
										<div class="card__description card__citation small">
					<p>NUS News | April 2, 2025</p><p>The National University of Singapore (NUS) has signed a five-year collaboration agreement with Microsoft Research Asia for a Joint PhD Supervision Program, bringing together NUS&#8217;s academic and research excellence with Microsoft Research Asia’s global leadership in AI, computing research, and industrial applications to cultivate talent. As part of this collaboration, NUS and Microsoft Research Asia will nurture PhD students through the Industrial Postgraduate Program, supported by the Singapore Economic Development Board (EDB). This initiative will help to cultivate interdisciplinary, high-caliber tech professionals and drive the integration of AI technology across industries.</p>				</div>
			
					</div>
	</div>
</div>
<div class="msr-cards__card msr-cards__card--default col">
	<div class="card has-spectrum-border-top__hover material-card h-100 p-0">

		
		<div class="card-body bg-white p-4 pt-3">
							<h3 class="h5">
					<a class="text-decoration-none text-black" href="https://www.theverge.com/microsoft/643246/microsoft-50-business-model-cloud-ai">
						<span>How Microsoft made it through 50 years</span>&nbsp;<span class="glyph-prepend glyph-prepend-small glyph-prepend-chevron-right"></span>
					</a>
				</h3>
										<div class="card__description card__citation small">
					<p>The Verge | April 4, 2025</p><p>A lot has changed since Microsoft was founded, but in many ways, the company’s core business model and ethos remain the same: make software that everyone needs and get it installed everywhere. Adapting to change, including the ongoing AI transformation, has always played an important role in the company&#8217;s success.</p>				</div>
			
					</div>
	</div>
</div>
</div>

					<div class="justify-content-center text-center mb-4">
				<a class="btn btn-outline-primary glyph-append glyph-append-small glyph-append-chevron-right msr-cards__cta" href="https://www.microsoft.com/en-us/research/news-and-awards/">
					View more news and awards				</a>
			</div>
			</div>
</div>		</div>
	</div>

	</div>
<span class="sr-only" id="label-external-link">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-april-7-2025/">Research Focus: Week of April 7, 2025</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
<pubDate>Wed, 09 Apr 2025 16:00:00 +0000</pubDate>
</item>
<item>
<title>Real-world healthcare AI development and deployment—at scale</title>
<link>https://www.microsoft.com/en-us/research/podcast/the-ai-revolution-in-medicine-revisited-real-world-healthcare-ai-development-and-deployment-at-scale/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/the-ai-revolution-in-medicine-revisited-real-world-healthcare-ai-development-and-deployment-at-scale/</guid>
<content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img alt="AI Revolution podcast | Episode 2 - Real-world healthcare AI development and deployment—at scale | outline illustration of Seth Hain, Peter Lee, Dr. Matthew Lungren" class="wp-image-1135817" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Episode2-Peter-Seth-Matt-AIRevolution_Hero_Feature_No_Text_1400x788-1.jpg" width="1401" /></figure>


<div class="wp-block-msr-podcast-container my-4">
	
</div>



<p>Two years ago, OpenAI’s GPT-4 kick-started a new era in AI. In the months leading up to its public release, Peter Lee, president of Microsoft Research, cowrote a book full of optimism for the potential of advanced AI models to transform the world of healthcare. What has happened since? In this special podcast series, <em>The AI Revolution in Medicine, Revisited</em>, Lee revisits the book, exploring how patients, providers, and other medical professionals are experiencing and using generative AI today while examining what he and his coauthors got right—and what they didn’t foresee.&nbsp;</p>



<p>In this episode, <a href="https://www.microsoft.com/en-us/research/people/mlungren/" rel="noreferrer noopener" target="_blank">Dr. Matthew Lungren<span class="sr-only"> (opens in new tab)</span></a> and <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.linkedin.com/in/seth-hain-12760647/" rel="noreferrer noopener" target="_blank">Seth Hain<span class="sr-only"> (opens in new tab)</span></a>, leaders in the implementation of healthcare AI technologies and solutions at scale, join Lee to discuss the latest developments. Lungren, the chief scientific officer at Microsoft Health and Life Sciences, explores the creation and deployment of generative AI for automating clinical documentation and administrative tasks like clinical note-taking. Hain, the senior vice president of R&amp;D at the healthcare software company Epic, focuses on the opportunities and challenges of integrating AI into electronic health records at global scale, highlighting AI-driven workflows, decision support, and Epic’s Cosmos project, which leverages aggregated healthcare data for research and clinical insights.&nbsp;</p>



<hr class="wp-block-separator has-alpha-channel-opacity" />



<h2 class="wp-block-heading h5" id="learn-more">Learn more:</h2>



<p><a href="https://www.microsoft.com/en-us/industry/blog/healthcare/2025/03/03/meet-microsoft-dragon-copilot-your-new-ai-assistant-for-clinical-workflow/?msockid=35739e94ab6c69d41b738b93aa076831" rel="noreferrer noopener" target="_blank">Meet Microsoft Dragon Copilot: Your new AI assistant for clinical workflow</a>&nbsp;<br />Microsoft Industry Blog | March 2025&nbsp;</p>



<p><a href="https://www.microsoft.com/en-us/industry/blog/healthcare/2024/10/10/unlocking-next-generation-ai-capabilities-with-healthcare-ai-models/" rel="noreferrer noopener" target="_blank">Unlocking next-generation AI capabilities with healthcare AI models</a>&nbsp;<br />Microsoft Industry Blog | October 2024&nbsp;</p>



<p><a href="https://www.microsoft.com/en-us/research/articles/multimodal-generative-ai-the-next-frontier-in-precision-health/" rel="noreferrer noopener" target="_blank">Multimodal Generative AI: the Next Frontier in Precision Health</a>&nbsp;<br />Microsoft Research Forum | March 2024&nbsp;</p>



<p><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.linkedin.com/learning/an-introduction-to-how-generative-ai-will-transform-healthcare" rel="noreferrer noopener" target="_blank">An Introduction to How Generative AI Will Transform Healthcare with Dr. Matthew Lungren<span class="sr-only"> (opens in new tab)</span></a>&nbsp;<br />LinkedIn Learning&nbsp;</p>



<p><a href="https://www.microsoft.com/en-us/research/video/ai-for-precision-health/" rel="noreferrer noopener" target="_blank">AI for Precision Health</a>&nbsp;<br />Video | July 2023&nbsp;</p>



<p><a href="https://www.microsoft.com/en-us/research/publication/chexnet-radiologist-level-pneumonia-detection-on-chest-x-rays-with-deep-learning/" rel="noreferrer noopener" target="_blank">CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning</a>&nbsp;<br />Publication | December 2017&nbsp;</p>



<p><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://cosmos.epic.com/" rel="noreferrer noopener" target="_blank">Epic Cosmos<span class="sr-only"> (opens in new tab)</span></a>&nbsp;<br />Homepage</p>



<p><a href="https://www.microsoft.com/en-us/research/publication/the-ai-revolution-in-medicine-gpt-4-and-beyond/" rel="noreferrer noopener" target="_blank">The AI Revolution in Medicine: GPT-4 and Beyond</a>&nbsp;<br />Book | April 2023</p>



<section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast">
	<div class="subscribe-to-podcast__inner border-top border-bottom border-width-2">
		<h2 class="h5 subscribe-to-podcast__heading">
			Subscribe to the <a href="https://www.microsoft.com/en-us/research/podcast">Microsoft Research Podcast</a>:		</h2>
		<ul class="subscribe-to-podcast__list list-unstyled">
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://itunes.apple.com/us/podcast/microsoft-research-a-podcast/id1318021537?mt=2" rel="noreferrer noopener" target="_blank">
						<svg class="subscribe-to-podcast__svg" fill="black" viewBox="0 0 32 32" xmlns="http://www.w3.org/2000/svg">  <path d="M7.12 0c-3.937-0.011-7.131 3.183-7.12 7.12v17.76c-0.011 3.937 3.183 7.131 7.12 7.12h17.76c3.937 0.011 7.131-3.183 7.12-7.12v-17.76c0.011-3.937-3.183-7.131-7.12-7.12zM15.817 3.421c3.115 0 5.932 1.204 8.079 3.453 1.631 1.693 2.547 3.489 3.016 5.855 0.161 0.787 0.161 2.932 0.009 3.817-0.5 2.817-2.041 5.339-4.317 7.063-0.812 0.615-2.797 1.683-3.115 1.683-0.12 0-0.129-0.12-0.077-0.615 0.099-0.792 0.192-0.953 0.64-1.141 0.713-0.296 1.932-1.167 2.677-1.911 1.301-1.303 2.229-2.932 2.677-4.719 0.281-1.1 0.244-3.543-0.063-4.672-0.969-3.595-3.907-6.385-7.5-7.136-1.041-0.213-2.943-0.213-4 0-3.636 0.751-6.647 3.683-7.563 7.371-0.245 1.004-0.245 3.448 0 4.448 0.609 2.443 2.188 4.681 4.255 6.015 0.407 0.271 0.896 0.547 1.1 0.631 0.447 0.192 0.547 0.355 0.629 1.14 0.052 0.485 0.041 0.62-0.072 0.62-0.073 0-0.62-0.235-1.199-0.511l-0.052-0.041c-3.297-1.62-5.407-4.364-6.177-8.016-0.187-0.943-0.224-3.187-0.036-4.052 0.479-2.323 1.396-4.135 2.921-5.739 2.199-2.319 5.027-3.543 8.172-3.543zM16 7.172c0.541 0.005 1.068 0.052 1.473 0.14 3.715 0.828 6.344 4.543 5.833 8.229-0.203 1.489-0.713 2.709-1.619 3.844-0.448 0.573-1.537 1.532-1.729 1.532-0.032 0-0.063-0.365-0.063-0.803v-0.808l0.552-0.661c2.093-2.505 1.943-6.005-0.339-8.296-0.885-0.896-1.912-1.423-3.235-1.661-0.853-0.161-1.031-0.161-1.927-0.011-1.364 0.219-2.417 0.744-3.355 1.672-2.291 2.271-2.443 5.791-0.348 8.296l0.552 0.661v0.813c0 0.448-0.037 0.807-0.084 0.807-0.036 0-0.349-0.213-0.683-0.479l-0.047-0.016c-1.109-0.885-2.088-2.453-2.495-3.995-0.244-0.932-0.244-2.697 0.011-3.625 0.672-2.505 2.521-4.448 5.079-5.359 0.547-0.193 1.509-0.297 2.416-0.281zM15.823 11.156c0.417 0 0.828 0.084 1.131 0.24 0.645 0.339 1.183 0.989 1.385 1.677 0.62 2.104-1.609 3.948-3.631 3.005h-0.015c-0.953-0.443-1.464-1.276-1.475-2.36 0-0.979 0.541-1.828 1.484-2.328 0.297-0.156 0.709-0.235 1.125-0.235zM15.812 17.464c1.319-0.005 2.271 0.463 2.625 1.291 0.265 0.62 0.167 2.573-0.292 5.735-0.307 2.208-0.479 2.765-0.905 3.141-0.589 0.52-1.417 0.667-2.209 0.385h-0.004c-0.953-0.344-1.157-0.808-1.553-3.527-0.452-3.161-0.552-5.115-0.285-5.735 0.348-0.823 1.296-1.285 2.624-1.291z"></svg>
						<span class="subscribe-to-podcast__link-text">Apple Podcasts</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://subscribebyemail.com/www.blubrry.com/feeds/microsoftresearch.xml" rel="noreferrer noopener" target="_blank">
						<svg class="subscribe-to-podcast__svg" fill="none" viewBox="0 0 32 32" xmlns="http://www.w3.org/2000/svg"><path d="M6.4 6a2.392 2.392 0 00-2.372 2.119L16 15.6l11.972-7.481A2.392 2.392 0 0025.6 6H6.4zM4 10.502V22.8a2.4 2.4 0 002.4 2.4h19.2a2.4 2.4 0 002.4-2.4V10.502l-11.365 7.102a1.2 1.2 0 01-1.27 0L4 10.502z" fill="currentColor"></svg>
						<span class="subscribe-to-podcast__link-text">Email</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://subscribeonandroid.com/www.blubrry.com/feeds/microsoftresearch.xml" rel="noreferrer noopener" target="_blank">
						<svg class="subscribe-to-podcast__svg" fill="none" viewBox="0 0 32 32" xmlns="http://www.w3.org/2000/svg"><path d="M12.414 4.02c-.062.012-.126.023-.18.06a.489.489 0 00-.12.675L13.149 6.3c-1.6.847-2.792 2.255-3.18 3.944h13.257c-.388-1.69-1.58-3.097-3.179-3.944l1.035-1.545a.489.489 0 00-.12-.675.492.492 0 00-.675.135l-1.14 1.68a7.423 7.423 0 00-2.55-.45c-.899 0-1.758.161-2.549.45l-1.14-1.68a.482.482 0 00-.494-.195zm1.545 3.824a.72.72 0 110 1.44.72.72 0 010-1.44zm5.278 0a.719.719 0 110 1.44.719.719 0 110-1.44zM8.44 11.204A1.44 1.44 0 007 12.644v6.718c0 .795.645 1.44 1.44 1.44.168 0 .33-.036.48-.09v-9.418a1.406 1.406 0 00-.48-.09zm1.44 0V21.76c0 .793.646 1.44 1.44 1.44h10.557c.793 0 1.44-.647 1.44-1.44V11.204H9.878zm14.876 0c-.169 0-.33.035-.48.09v9.418c.15.052.311.09.48.09a1.44 1.44 0 001.44-1.44v-6.719a1.44 1.44 0 00-1.44-1.44zM11.8 24.16v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84zm5.759 0v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84z" fill="currentColor"></svg>
						<span class="subscribe-to-podcast__link-text">Android</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://open.spotify.com/show/4ndjUXyL0hH1FXHgwIiTWU" rel="noreferrer noopener" target="_blank">
						<svg class="subscribe-to-podcast__svg" fill="none" viewBox="0 0 32 32" xmlns="http://www.w3.org/2000/svg"><path d="M16 4C9.383 4 4 9.383 4 16s5.383 12 12 12 12-5.383 12-12S22.617 4 16 4zm5.08 17.394a.781.781 0 01-1.086.217c-1.29-.86-3.477-1.434-5.303-1.434-1.937.002-3.389.477-3.403.482a.782.782 0 11-.494-1.484c.068-.023 1.71-.56 3.897-.562 1.826 0 4.365.492 6.171 1.696.36.24.457.725.217 1.085zm1.56-3.202a.895.895 0 01-1.234.286c-2.338-1.457-4.742-1.766-6.812-1.747-2.338.02-4.207.466-4.239.476a.895.895 0 11-.488-1.723c.145-.041 2.01-.5 4.564-.521 2.329-.02 5.23.318 7.923 1.995.419.26.547.814.286 1.234zm1.556-3.745a1.043 1.043 0 01-1.428.371c-2.725-1.6-6.039-1.94-8.339-1.942h-.033c-2.781 0-4.923.489-4.944.494a1.044 1.044 0 01-.474-2.031c.096-.023 2.385-.55 5.418-.55h.036c2.558.004 6.264.393 9.393 2.23.497.292.663.931.371 1.428z" fill="currentColor"></svg>
						<span class="subscribe-to-podcast__link-text">Spotify</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://www.blubrry.com/feeds/microsoftresearch.xml" rel="noreferrer noopener" target="_blank">
						<svg class="subscribe-to-podcast__svg" fill="none" viewBox="0 0 32 32" xmlns="http://www.w3.org/2000/svg"><path d="M6.667 4a2.676 2.676 0 00-2.612 2.13v.003c-.036.172-.055.35-.055.534v18.666c0 .183.019.362.055.534v.003a2.676 2.676 0 002.076 2.075h.002c.172.036.35.055.534.055h18.666A2.676 2.676 0 0028 25.333V6.667a2.676 2.676 0 00-2.13-2.612h-.003A2.623 2.623 0 0025.333 4H6.667zM8 8h1.333C17.42 8 24 14.58 24 22.667V24h-2.667v-1.333c0-6.618-5.382-12-12-12H8V8zm0 5.333h1.333c5.146 0 9.334 4.188 9.334 9.334V24H16v-1.333A6.674 6.674 0 009.333 16H8v-2.667zM10 20a2 2 0 11-.001 4.001A2 2 0 0110 20z" fill="currentColor"></svg>
						<span class="subscribe-to-podcast__link-text">RSS Feed</span>
					</a>
				</li>
					</ul>
	</div>
</section>


<div class="wp-block-msr-show-more">
	<div class="bg-neutral-100 p-5">
		<div class="show-more-show-less">
			<div>
				<span>
					

<h2 class="wp-block-heading" id="transcript">Transcript</h2>



<p>[MUSIC] &nbsp;</p>



<p>[BOOK PASSAGE]  &nbsp;</p>



<p><strong>PETER LEE:</strong> “It&#8217;s hard to convey the huge complexity of today&#8217;s healthcare system. Processes and procedures, rules and regulations, and financial benefits and risks all interact, evolve, and grow into a giant edifice of paperwork that is well beyond the capability of any one human being to master. This is where the assistance of an AI like GPT-4 can be not only useful—but crucial.”&nbsp;&nbsp;&nbsp;</p>



<p>[END OF BOOK PASSAGE] &nbsp;</p>



<p>[THEME MUSIC] &nbsp;</p>



<p>This is <em>The AI Revolution in Medicine, Revisited</em>. I’m your host, Peter Lee. &nbsp;</p>



<p>Shortly after OpenAI&#8217;s GPT-4 was publicly released, Carey Goldberg, Dr. Zak Kohane, and I published <em>The AI Revolution in Medicine </em>to help educate the world of healthcare and medical research about the transformative impact this new generative AI technology could have. But because we wrote the book when GPT-4 was still a secret, we had to speculate. Now, two years later, what did we get right, and what did we get wrong?  &nbsp;</p>



<p>In this series, we’ll talk to clinicians, patients, hospital administrators, and others to understand the reality of AI in the field and where we go from here.</p>



				</span>
				<span class="show-more-show-less-toggleable-content" id="show-more-show-less-toggle-1">
					



<p>[THEME MUSIC FADES]&nbsp;</p>



<p>The passage I read at the top there is from Chapter 7 of the book, “The Ultimate Paperwork Shredder.”&nbsp;&nbsp;</p>



<p>Paperwork plays a particularly important role in healthcare. It helps convey treatment information that supports patient care, and it’s also used to help demonstrate that providers are meeting regulatory responsibilities, among other things. But if we’re being honest, it’s taxing—for everyone—and it’s a big contributor to the burnout our clinicians are experiencing today. Carey, Zak, and I identified this specific pain point as one of the best early avenues to pursue as far as putting generative AI to good work in the healthcare space. &nbsp;</p>



<p>In this episode, I’m excited to welcome Dr. Matt Lungren and Seth Hain to talk about matching technological advancements in AI to clinical challenges, such as the paperwork crisis, to deliver solutions in the clinic and in the health system back office. &nbsp;</p>



<p>Matt is the chief scientific officer for Microsoft Health and Life Sciences, where he focuses on translating cutting-edge technology, including generative AI and cloud services, into innovative healthcare applications. He&#8217;s a clinical interventional radiologist and a clinical machine learning researcher doing collaborative research and teaching as an adjunct professor at Stanford University. His scientific work has led to more than 200 publications, including work on new computer vision and natural language processing approaches for healthcare. &nbsp;</p>



<p>Seth is senior vice president of research and development at Epic, a leading healthcare software company specializing in electronic health record systems, also known as <em>EHR</em>, as well as other solutions for connecting clinicians and patients. During his 19 years at Epic, Seth has worked on enhancing the core analytics and other technologies in Epic&#8217;s platforms as well as their applications across medicine,<strong> </strong>bringing together his graduate training in mathematics and his dedication to better health. &nbsp;</p>



<p>I&#8217;ve had the pleasure of working closely with both Matt and Seth. Matt, as a colleague here at Microsoft, really focused on our health and life sciences business. And Seth, as a collaborator at Epic, as we embark on the questions of how to integrate and deploy generative AI into clinical applications at scale.  &nbsp;</p>



<p>[TRANSITION MUSIC]&nbsp;</p>



<p>Here&#8217;s my conversation with Dr. Matt Lungren: &nbsp;</p>



<p><strong>LEE:</strong> Matt, welcome. It&#8217;s just great to have you here.&nbsp;</p>



<p><strong>MATTHEW LUNGREN:</strong> Thanks so much, Peter. Appreciate being here.&nbsp;</p>



<p><strong>LEE:</strong> So, I&#8217;d like to just start just talking about you. You know, I had mentioned your role as the chief scientific officer for Microsoft Health and Life Sciences. Of course, that&#8217;s just a title. So, what the heck is that? What is your job exactly? And, you know, what does a typical day at work look like for you?&nbsp;</p>



<p><strong>LUNGREN: </strong>So, really what you could boil my work down to is essentially cross collaboration, right. We have a very large company, lots of innovation happening all over the place, lots of partners that we work with and then obviously this sort of healthcare mission.</p>



<p>And so, what innovations, what kind of advancements are happening that can actually solve clinical problems, right, and sort of kind of direct that. And we can go into some examples, you know, later. But then the other direction, too, is important, right. So, identifying problems that may benefit from a technologic application or solution and kind of translating that over into the, you know, pockets of innovation saying, “Hey, if you kind of tweaked it this way, this is something that would really help, you know, the clinical world.”&nbsp;&nbsp;</p>



<p>And so, it&#8217;s really a bidirectional role. So, my day to day is … every day is a little different, to be honest with you. Some days it&#8217;s very much in the science and learning about new techniques. On the other side, though, it can be very much in the clinic, right. So, what are the pain points that we&#8217;re seeing? Where are the gaps in the solutions that we&#8217;ve already rolled out? And, you know, again, what can we do to make healthcare better broadly?&nbsp;</p>



<p><strong>LEE:</strong> So, you know, I think of you as a technologist, and, Matt, you and I actually are colleagues working together here at Microsoft. But you also do spend time in the clinic still, as well, is that right?&nbsp;</p>



<p><strong>LUNGREN:</strong> You know, initially it was kind of a … very much a non-negotiable for me … in sort of taking an industry role. I think like a lot of, you know, physicians, you know, we&#8217;re torn with the idea of like, hey, I spent 20 years training. I love what I do, you know, with a lot of caveats there in terms of some of the administrative burden and some of the hassle sometimes. But for the most part, I love what I do, and there&#8217;s no greater feeling than using something that you trained years to do and actually see the impact on a human life. It&#8217;s unbelievable, right.&nbsp;&nbsp;</p>



<p>So, I think part of me was just, like, I didn&#8217;t want to let that part of my identity go. And frankly, as I often say, to this day, I walk by a fax machine in our office <em>today</em>, like in 2025.&nbsp;&nbsp;</p>



<p>So just to be extra clear, it really grounds me in, like, yes, I love the possibilities. I love thinking about what we can do. But also, I have a very stark understanding of the reality on the ground, both in terms of the technology but also the burnout, right. The challenges that we&#8217;re facing in taking care of patients has gotten, you know, much, much more difficult in the last few years, and, you know, I like to think it keeps my perspective, yeah.&nbsp;</p>



<p><strong>LEE: </strong>You know, I think some listeners to this podcast might be surprised that we have doctors on staff in technical roles at Microsoft. How do you explain that to people?&nbsp;</p>



<p><strong>LUNGREN:</strong> [LAUGHS] Yeah, no, yeah, it is interesting. I would say that, you know, from, you know, the legacy Nuance world, it wasn&#8217;t so far-fetched that you have physicians that were power users and eventually sort of, you know, became, “Hey, listen, I think this is a strategic direction; you should take it&#8221; or whatever. And certainly maybe in the last, I want to say, five years or so, I&#8217;ve seen more and more physicians who have, you know, taken the time, sometimes on their own, to learn some of the AI capabilities, learn some of the principles and concepts; and frankly, some are, you know, even coding solutions and leading companies.</p>



<p>So, I do think that that has shifted a bit in terms of like, “Hey, doctor, this is your lane, and over here, you know, here&#8217;s a technical person.” And I think that&#8217;s fused quite a bit more.&nbsp;&nbsp;</p>



<p>But yeah, it is an unusual thing, I think, in sort of how we&#8217;ve constructed what at least my group does. But again, I can&#8217;t see any other way around some of the challenges.&nbsp;&nbsp;</p>



<p>I think, you know, an anecdote I’d like to tell you, when I was running the AIMI [Artificial Intelligence in Medicine and Imaging] Center, you know, we were bringing the medical school together with the computer science department, right, at Stanford. And I remember one day a student, you know, very smart, came into my office, you know, a clinical day or something, and he&#8217;s like, is there just, like, a book or something where I can just learn medicine? Because, like, I feel like there&#8217;s a lot of, like, translation you have to do for me.&nbsp;&nbsp;</p>



<p>It really raised an important insight, which is that you can learn the, you know, medicine, so to speak. You know, go to med school; you know, take the test and all that. But it really … you don&#8217;t really understand the practice of medicine until you are doing that.&nbsp;&nbsp;</p>



<p>And in fact, I even push it a step further to say after training those first two or three years of … <em>you</em> are the responsible person; you can turn around, and there&#8217;s no one there. Like, you are making a decision. Getting used to that and then having a healthy respect for that actually I think provides the most educational value of anything in healthcare.&nbsp;&nbsp;</p>



<p><strong>LEE: </strong>You know, I think what you&#8217;re saying is so important because as I reflect on my own journey. Of course, I&#8217;m a computer scientist. I don&#8217;t have medical training, although at this point, I feel confident that I could pass a Step 1 medical exam.&nbsp;&nbsp;</p>



<p><strong>LUNGREN: </strong>I have no doubt. [LAUGHS]&nbsp;</p>



<p><strong>LEE:</strong> But I think that the tech industry, because of people like you, have progressed tremendously in having a more sophisticated and nuanced understanding of what actually goes on in clinic and also what goes on in the boardrooms of healthcare delivery organizations. And of course, at the end of the day, I think that&#8217;s really been your role.&nbsp;&nbsp;</p>



<p>So roughly speaking, your job as an executive at a big tech company has been to understand what the technology platforms need to be, particularly with respect to machine learning, AI, and cloud computing, to best support healthcare. And so maybe let&#8217;s start <em>pre</em>-GPT-4, <em>pre</em>-ChatGPT, and tell us a little bit, you know, about maybe some of your proudest moments in getting advanced technologies like AI into the clinic.&nbsp;</p>



<p><strong>LUNGREN:</strong> You know, when I first started, so remember, like you go all the way back to about 2013, right, my first faculty job, and, you know, we&#8217;re building a clinical program and I, you know, I had a lot of interest in public health and building large datasets for pop [population] health, etc. But I was doing a lot of that, you know, sort of labeling to get those insights manually, right. So, like, I was the person that you&#8217;d probably look at now and say, “What are you doing?” Right?&nbsp;&nbsp;</p>



<p>So … but I had a complete random encounter with Andrew Ng, who I didn&#8217;t know at the time, at Stanford. And I, you know, went to one of the seminars that he was holding at the Gates building, and, you know, they were talking about their performance on ImageNet. You know, cat and dog and, you know, tree, bush, whatever. And I remember sitting in kind of the back, and I think I maybe had my scrubs on at the time and just kind of like, what? Like, why … like, this … we could use this in healthcare, you know. [LAUGHS]&nbsp;&nbsp;</p>



<p>But for me, it was a big moment. And I was like, this is huge, right. And as you remember, the deep learning really kind of started to show its stuff with, you know, Fei-Fei Li&#8217;s ImageNet stuff.</p>



<p>So anyway, we started the collaboration that actually became <strong>a NIDUS</strong>. And one of the first things we worked on, we just said, “Listen, one of the most common medical imaging examinations in the world is the chest x-ray.” Right? Two, three billion are done every year in the world, and so is that not a great place to start?</p>



<p>And of course, we had a very democratizing kind of mission. As you know, Andrew has done a lot of work in that space, and I had similar ambitions. And so, we really started to focus on bringing the, you know, the sort of the clinical and the CS together and see what could be done.&nbsp;&nbsp;</p>



<p>So, we did <a href="https://www.microsoft.com/en-us/research/publication/chexnet-radiologist-level-pneumonia-detection-on-chest-x-rays-with-deep-learning/" rel="noreferrer noopener" target="_blank">CheXNet</a>. And this is, remember this is around the time when, like, Geoffrey Hinton was saying things like we should stop training radiologists, and all this stuff was going on. [LAUGHTER] So there&#8217;s a lot of hype, and this is the narrow AI days just to remind the audience.&nbsp;&nbsp;</p>



<p><strong>LEE:</strong> How did you feel about that since you <em>are</em> a radiologist?&nbsp;</p>



<p><strong>LUNGREN:</strong> Well, it was so funny. So, Andrew is obviously very prolific on social media, and I was, who am I, right? So, I remember he tagged me. Well, first he said, “Matt, you need to get a Twitter account.” And I said OK. And he tagged me on the very first post of our, what we call, CheXNet that was kind of like the “Hello, World!” for this work.&nbsp;&nbsp;</p>



<p>And I remember it was a clinical day. I had set my phone, as you do, outside the OR. I go in. Do my procedure. You know, hour or so, come back, my phone&#8217;s dead. I&#8217;m like, oh, that&#8217;s weird. Like I had a decent charge. So, you know, I plug it in. I turn it on. I had like hundreds of thousands of notifications because Andrew had tweeted out to his millions or whatever about CheXNet.&nbsp;&nbsp;</p>



<p>And so, then of course, as you point out, I go to RSNA that year, which is our large radiology conference, and that Geoffrey Hinton quote had come out. And everyone&#8217;s looking at me like, “What are you doing, Matt?” You know, like, are you coming after our specialty? I&#8217;m like, “No, no,” that&#8217;s, [LAUGHS] you know, it&#8217;s a way to interpret it, but you have to take a much longer horizon view, right.&nbsp;&nbsp;</p>



<p><strong>LEE:</strong> Well, you know, we&#8217;re going to, just as an enticement for listeners to this podcast to listen to the very end, I&#8217;m going to pin you down toward the end on your assessment of whether Geoffrey Hinton will eventually be proven right or not. [LAUGHTER] But let&#8217;s take our time to get there.&nbsp;&nbsp;</p>



<p>Now let&#8217;s go ahead and enter the generative AI era. When we were first exposed to what we now know of as GPT-4—this was before it was disclosed to the world—a small number of people at Microsoft and Microsoft Research were given access in order to do some technical assessment.&nbsp;&nbsp;</p>



<p>And, Matt, you and I were involved very early on in trying to assess what might this technology mean for medicine.<strong> </strong>Tell us, you know, what was the first encounter with this new technology like for you?&nbsp;&nbsp;</p>



<p><strong>LUNGREN:</strong> It was the weirdest thing, Peter. Like … I joined that summer, so the summer before, you know, the actual GPT came out. I had literally no idea what I was getting into.&nbsp;&nbsp;</p>



<p>So, I started asking it questions, you know, kind of general stuff, right. Just, you know, I was like, oh, all right, it&#8217;s pretty good. And so, then I would sort of go a little deeper. And eventually I got to the point where I&#8217;m asking questions that, you know, maybe there&#8217;s three papers on it in my community, and remember I&#8217;m a sub-sub specialist, right, <em>pediatric interventional radiology</em>. And the things that we do in vascular malformations and, you know, rare cancers are really, really strange and not very commonly known.&nbsp;&nbsp;</p>



<p>And I kind of walked away from that—first I said, can I have this thing, right? [LAUGHS]&nbsp;&nbsp;</p>



<p>But then I, you know, I don&#8217;t want to sound dramatic, but I didn&#8217;t sleep that well, if I&#8217;m being honest, for the first few nights. Partially because I couldn&#8217;t tell anybody, except for the few that I knew were involved, and partially because I just couldn&#8217;t wrap my head around how we went from what I was doing in LSTMs [long short-term memory networks], right, which was state of the artish at the time for NLP [natural language processing].&nbsp;&nbsp;</p>



<p>And all of a sudden, I have this thing that is broadly, you know, domain experts, you know, representations of knowledge that there&#8217;s no way you could think of it would be in distribution for a normal approach to this.&nbsp;&nbsp;</p>



<p>And so, I really struggled with it, honestly. Interpersonally, like, I would be like, uh, well, let&#8217;s not work on that. They&#8217;re like, why not? You were just excited about it last week. I&#8217;m like, I don&#8217;t know. I think that we could think of another approach later.<strong> </strong>[LAUGHS]&nbsp;&nbsp;</p>



<p>And so yeah, when we were finally able to really look at some of the capabilities and really think clearly, it was really clear that we had a massive opportunity on our hands to impact healthcare in a way that was never possible before.&nbsp;</p>



<p><strong>LEE: </strong>Yeah, and at that time you were still a part of Nuance. Nuance, I think, was in the process of being acquired by Microsoft. Is that right?&nbsp;&nbsp;</p>



<p><strong>LUNGREN:</strong> That’s right.&nbsp;&nbsp;</p>



<p><strong>LEE:</strong> And so, of course, this was also a technology that would have profound and very direct implications for Nuance. How did you think about that?&nbsp;</p>



<p><strong>LUNGREN:</strong> Nuance, for those in the audience who don&#8217;t know, for 25 years was, sort of, <em>the</em> medical speech-to-text thing that all, you know, physicians used. But really the brass ring had always been … and I want to say going back to like 2013, 2014, Nuance had tried to figure out, OK, we see this pain point. Doctors are typing on their computers while they&#8217;re trying to talk to their patients, right.&nbsp;&nbsp;</p>



<p>We should be able to figure out a way to get that ambient conversation turned into text that then, you know, accelerates the doctor … takes all the important information. That&#8217;s a really hard problem, right. You&#8217;re having a conversation with a patient about their knee pain, but you&#8217;re also talking about, you know, their cousin&#8217;s wedding and their next vacation and their dog is sick or whatever and all that gets recorded, right.&nbsp;&nbsp;</p>



<p>And so, then you have to have the intelligence/context to be able to tease out what&#8217;s important for a note. And then it has to be at the performance level that a physician who, again, 20 years of training and education plus a huge, huge amount of, you know, need to get through his cases efficiently, that&#8217;s a really difficult problem.&nbsp;&nbsp;</p>



<p>And so, for a long time, there was a human-in-the-loop aspect to doing this because you needed a human to say, “This transcript&#8217;s great, but here&#8217;s actually what needs to go on the note.” And that can&#8217;t scale, as you know.&nbsp;&nbsp;</p>



<p>When the GPT-4, you know, model kind of, you know, showed what it was capable of, I think it was an immediate light bulb because there was no … you can ask any physician in your life, anyone in the audience, you know, what are your … what is the biggest pain point when you go to see your doctor? Like, “Oh, they don&#8217;t talk to me. They don&#8217;t look me in the eye. They&#8217;re rushing around trying to finish a note.”&nbsp;&nbsp;</p>



<p>If we could get that off their plate, that&#8217;s a huge unlock, Peter. And I think that, again, as you know, it&#8217;s now led to so much more. But that was kind of the initial, I think, reaction.&nbsp;</p>



<p><strong>LEE: </strong>And so, maybe that gets us into our next set of questions, our next topic, which is about the book and all the predictions we made in the book. Because Carey, Zak, and I—actually we did make a prediction that this technology would have a huge impact on this problem of clinical note-taking.&nbsp;&nbsp;</p>



<p>And so, you&#8217;re just right in the middle of that. You&#8217;re directly hands-on creating, I think, what is probably the most popular early product for doing exactly that. So, were we right? Were we wrong? What else do we need to understand about this?&nbsp;</p>



<p><strong>LUNGREN:</strong> No, you were right on. I think in the book, I think you called it like a paper shredder or something. I think you used a term like that. That&#8217;s exactly where the activity is right now and the opportunity.&nbsp;&nbsp;</p>



<p>I&#8217;ve even taken that so far as to say that when folks are asking about what the technology is capable of doing, we say, well, listen, it&#8217;s going to save time before it saves lives. It&#8217;ll do both. But right now, it&#8217;s about saving time.&nbsp;&nbsp;</p>



<p>It&#8217;s about peeling back the layers of the onion that if you, you know, put me in where I started medicine in 2003, and then fast-forward and showed me a day in the life of 2025, I would be shocked at what I was doing that <em>wasn&#8217;t</em> related to patient care, right. So, all of those layers that have been stacked up over the years, we can start finding ways to peel that back. And I think that&#8217;s exactly what we&#8217;re seeing.</p>



<p>And to your point, I think you mentioned this, too, which is, well, sure, we can do this transcript, and we can turn a note, but then we can do other things, right. We can summarize that in the patient&#8217;s language or education level of choice. We can pend orders. We can eventually get to a place of decision support. So, “Hey, did you think about this diagnosis, doctor?” Like those kinds of things.&nbsp;&nbsp;</p>



<p>And all those things, I think you highlighted beautifully, and again, it sounds like with, you know, a lot of, right, just kind of guesswork and prediction, but those things are actually happening every single day <em>right now</em>.&nbsp;&nbsp;</p>



<p><strong>LEE:</strong> Well, so now, you know, in this episode, we&#8217;re really trying to understand, you know, where the technology industry is in delivering these kinds of things. And so from your perspective, you know, in the business that you&#8217;re helping to run here at Microsoft, you know, what are the things that are actually shipping as product versus things that clinicians are doing, let&#8217;s say, off label, just by using, say, ChatGPT on their personal mobile devices, and then what things aren&#8217;t happening?&nbsp;</p>



<p><strong>LUNGREN:</strong> Yeah. I&#8217;ll start with the shipping part because I think you, again, you know my background, right. Academic clinician, did a lot of research, hadn&#8217;t had a ton of <em>product</em> experience.&nbsp;&nbsp;</p>



<p>In other words, like, you know, again, I&#8217;m happy to show you what benchmarks we beat or a new technique or, you know, get a grant to do all this, or even frankly, you know, talk about startups. But to actually have an audience that is accustomed to a certain level of performance for the solutions that they use, to be able to deliver something new at that same level of expectation, wow, that&#8217;s a big deal.  </p>



<p>And again, this is part of the learning by, you know, kind of being around this environment that we have, which is we have this, you know, incredibly focused, very experienced clinical product team, right.</p>



<p>And then I think on the other side, to your point about the general-purpose aspect of this, it&#8217;s no secret now, right, that, you know, this is a useful technology in a lot of different medical applications. And let&#8217;s just say that there&#8217;s a lot of knowledge that can be used, particularly by the physician community. And I think the <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://informatics.bmj.com/content/31/1/e101102" rel="noreferrer noopener" target="_blank">most recent survey I saw</a> was from the British Medical Journal, which said, hey, you know, which doctors are using … are you willing to tell us, you know, what you&#8217;re doing? And it turns out that folks are, what, 30% or so said that they were using it regularly in clinic <a href="#ftn_1">[1]</a>. And again, this is the general, this is the API or whatever off the shelf.</p>



<p>And then frankly, when they ask what they&#8217;re using it for, tends to be things like, “Hey, differential, like, help me fill in my differential or suggest … ” and to me, I think what that created, at least—and you&#8217;re starting to see this trend really accelerate in the US especially—is, well, listen, we can&#8217;t have everybody pulling out their laptops and potentially exposing, you know, patient information by accident or something to a public API.&nbsp;&nbsp;</p>



<p>We have to figure this out, and so brilliantly, I think NYU [New York University] was one of the first. Now I think there&#8217;s 30 plus institutions that said, listen, “OK, we know this is useful to the entire community in the healthcare space.” Right?<strong> </strong>We know the administrators and nurses and everybody thinks this is great.&nbsp;&nbsp;</p>



<p>We can&#8217;t allow this sort of to be a very loosey-goosey approach to this, right, given this sort of environment. So, what we&#8217;ll do is we&#8217;ll set up a HIPAA-compliant instance to allow anyone in the community—you know, in the health system—to use the models, and then whatever, the newest model comes, it gets hosted, as well.  </p>



<p>And what&#8217;s cool about that—and that&#8217;s happened now a lot of places—is that at the high level … first of all, people get to use it and experiment and learn. But at the high level, they&#8217;re actually seeing what are the common use cases. Because you could ask 15 people and you might get super long lists, and it may not help you decide what to operationalize in your health system.&nbsp;&nbsp;</p>



<p><strong>LEE: </strong>But let me ask you about that. When you observe that, are there times when you think, “Oh, some specific use cases that we&#8217;re observing in that sort of organic way need to be taken into specialized applications and made into products?” Or is it best to keep these things sort of, you know, open-chat-interface types of general-purpose platform?&nbsp;&nbsp;</p>



<p><strong>LUNGREN:</strong> Honestly, it&#8217;s both, and that&#8217;s exactly what we&#8217;re seeing. I&#8217;m most familiar with Stanford, kind of, the work that Nigam Shah leads on this. But he, he basically, … you know, there&#8217;s a really great paper that is coming out in JAMA, but basically saying, “Here&#8217;s what our workforce is using it for. Here are the things in the literature that would suggest what would be popular.”&nbsp;&nbsp;</p>



<p>And some of those line up, like helping with a clinical diagnosis or documentation, but some of them don&#8217;t. But for the most part, the stuff that flies to the top, those are opportunities to operationalize and productize, etc. And I think that&#8217;s exactly what we&#8217;re seeing.&nbsp;</p>



<p><strong>LEE: </strong>So, let&#8217;s get into some of the specific predictions. We&#8217;ve, I think, beaten note-taking to death here. But there&#8217;s other kinds of paperwork, like filling out prior authorization request forms or referral letters, an after-visit note or summary to give instructions to patients, and so on. And these were all things that we were making guesses in our book might be happening. What&#8217;s the reality there?&nbsp;</p>



<p><strong>LUNGREN:</strong> I&#8217;ve seen every single one of those. In fact, I&#8217;ve probably seen a dozen startups too, right, doing exactly those things. And, you know, we touched a little bit on translation into the actual clinic. And that&#8217;s actually another thing that I used to kind of underappreciate, which is that, listen, you can have a computer scientist and a physician or nurse or whatever, like, give the domain expertise, and you think you&#8217;re ready to build something.&nbsp;&nbsp;</p>



<p>The health IT [LAUGHS] is another part of that Venn diagram that&#8217;s so incredibly critical, and then exactly how are you going to bring that into the system. That&#8217;s a whole new ballgame.&nbsp;</p>



<p>And so I do want to do a callout because the collaboration that we have with Epic is monumental because here, you have the system of record that most physicians, at least in the US, use. And they&#8217;re going to use an interface and they&#8217;re going to have an understanding of, hey, we know these are pain points, and so I think there&#8217;s some really, really cool, you know, new innovations that are coming out of the relationship that we have with Epic. And certainly the audience may be familiar with those, that I think will start to knock off a lot of the things that you predicted in your book relatively soon.&nbsp;</p>



<p><strong>LEE: </strong>I think most of the listeners to this podcast will know what Epic is. But for those that are unfamiliar with the health industry, and especially the technology foundation, Epic is probably the largest provider of electronic health record systems. And, of course, in collaboration with you and your team, they&#8217;ve been integrating generative AI quite a bit. Are there specific uses that Epic is making and deploying that get you particularly excited?&nbsp;</p>



<p><strong>LUNGREN:</strong> First of all, the ambient note generation, by the way, is integrated into Epic now. So like, you know, it&#8217;s not another screen, another thing for physicians. So that&#8217;s a huge, huge unlock in terms of the translation.</p>



<p>But then Epic themselves, so they have, I guess, on the last roadmap that they talked [about], more than 60, but the one that&#8217;s kind of been used now is this inbox response.&nbsp;</p>



<p>So again, maybe someone might not be familiar with, why is it such a big deal? Well, if you&#8217;re a physician, you already have, you know, 20 patients to see that day and you got all those notes to do, and then Jevons paradox, right. So if you give me better access to my doctor, well, maybe I won&#8217;t make an appointment. I&#8217;m just going to send him a note and this is kind of this inbox, right.&nbsp;&nbsp;</p>



<p>So then at the end of my day, I got to get all my notes done. And then I got to go through all the inbox messages I&#8217;ve received from all of my patients and make sure that they&#8217;re not like having chest pain and they&#8217;re blowing it off or something.&nbsp;&nbsp;</p>



<p>Now that&#8217;s a lot of work and the cold start problem of like, OK, I to respond to them. So Epic has leveraged this system to say, “Let me just draft a note for you,” understanding the context of, you know, what&#8217;s going on with the patient, etc. And you can edit that and sign it, right. So you can accelerate some of those … so that&#8217;s probably one I&#8217;m most excited about. But there&#8217;s so many right now.&nbsp;</p>



<p><strong>LEE: </strong>Well, I think I need to let you actually state the name of the clinical note-taking product that you&#8217;re associated with. Would you like to do that? [LAUGHS]&nbsp;</p>



<p><strong>LUNGREN:</strong> [LAUGHS] Sure. Yeah, it&#8217;s called DAX Copilot <a href="#ftn_2">[2]</a>. And for the record, it is the fastest-growing copilot in the Microsoft ecosystem. We&#8217;re very proud of that. Five hundred institutions already are using it, and millions of notes have already been created with it. And the feedback has been tremendous.</p>



<p><strong>LEE: </strong>So, you sort of referred to this a little bit, you know, this idea of AI being a second set of eyes. So, doctor makes some decisions in diagnosis or kind of working out potential treatments or medication decisions. And in the book, you know, we surmise that, well, AI might not replace the doctor doing those things. It could but might not. But AI could possibly reduce errors if doctors and nurses are making decisions by just looking at those decisions and just checking them out. Is that happening at all, and what do you see the future there?&nbsp;</p>



<p><strong>LUNGREN:</strong> Yeah, I would say, you know, that&#8217;s kind of the jagged edge of innovation, right, where sometimes the capability gets ahead of the ability to, you know, operationalize that. You know, part of that is just related to the systems. The evidence has been interesting on this. So, like, you know this, our colleague Eric Horvitz has been doing a lot of work in sort of looking at physician, physician with GPT-4, let&#8217;s say, and then GPT-4 alone for a whole variety of things. You know, we&#8217;ve been saying to the world for a long time, particularly in the narrow AI days, that AI plus human is better than either alone. We&#8217;re not really seeing that bear out really that well yet in some of the research.&nbsp;&nbsp;</p>



<p>But it is a signal to me and to the use case you&#8217;re suggesting, which is that if we let this system, in the right way, kind of handle a lot of the safety-net aspects of what we do but then also potentially take on some of the things that maybe are not that challenging or at least somewhat simple.&nbsp;&nbsp;</p>



<p>And of course, this is really an interesting use case in my world, in the vision world, which is that we know these models are multimodal, right. They can process images and text. And what does that look like for pathologists or radiologists, where we do have a certain percentage of the things we look at in a given day are normal, right? Or as close to normal as you can imagine. So is there a way to do that? And then also, by the way, have a safety net.&nbsp;&nbsp;</p>



<p>And so I think that this is an extremely active area right now. I don&#8217;t think we&#8217;ve figured out exactly how to have the human and AI model interact in this space yet. But I know that there&#8217;s a lot of attempts at it right now.&nbsp;</p>



<p><strong>LEE:</strong> Yeah, I think, you know, this idea of a true copilot, you know, a true collaborator, you know, I think is still something that&#8217;s coming. I think we&#8217;ve had a couple of decades of people being trained to think of computers as question-answering machines. Ask a question, get an answer. Provide a document, get a summary. And so on.&nbsp;&nbsp;</p>



<p>But the idea that something might actually be this second set of eyes just assisting you all day continuously, I think, is a new mode of interaction. And we haven&#8217;t quite figured that out.&nbsp;&nbsp;</p>



<p>Now, in preparation for this podcast, Matt, you said that you actually used AI to assist you in getting ready. [LAUGHS] Would you like to share what you learned by doing that?&nbsp;</p>



<p><strong>LUNGREN:</strong> Yeah, it&#8217;s very funny. So, like, you may have heard <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.oneusefulthing.org/p/detecting-the-secret-cyborgs" rel="noreferrer noopener" target="_blank">this term coined by Ethan Mollick called the “secret cyborg,”<span class="sr-only"> (opens in new tab)</span></a> which is sort of referring to the phenomena of folks using GPT, realizing it can actually help them a ton in all kinds of parts of their work, but not necessarily telling anybody that they&#8217;re using it, right.&nbsp;&nbsp;</p>



<p>And so in a similar secret cyborgish way, I was like, “Well, listen, you know, I haven&#8217;t read your book in like a year. I recommend it to everybody. And [I need] just a refresher.” So what I did was I took your book, I put it into GPT-4, OK, and asked it to sort of talk about the predictions that you made.&nbsp;&nbsp;</p>



<p>And then I took that and put it in the stronger reasoning model—in this case, the “deep research” that you may have just seen or heard of and the audience from OpenAI—and asked it to research all the current papers, you know, and blogs and whatever else and tell me like what was right, what was wrong in terms of the predictions. [LAUGHS]&nbsp;&nbsp;</p>



<p>So it, actually, it was an incredible thing. It&#8217;s a, like, what, six or seven pages. It probably would have taken me two weeks, frankly, to do this amount of work.&nbsp;&nbsp;</p>



<p><strong>LEE: </strong>I&#8217;ll be looking forward to reading that in the New England Journal of Medicine shortly.&nbsp;</p>



<p><strong>LUNGREN:</strong> [LAUGHS] That&#8217;s right. Yeah, no, don&#8217;t, before this podcast comes out, I&#8217;ll submit it as an opinion piece. No. [LAUGHS] But, yeah, but I think on balance, incredibly insightful views. And I think part of that was, you know, your team that got together really had a lot of different angles on this. But, you know, and I think the only area that was, like, which I&#8217;ve observed as well, it&#8217;s just, man, this can do a lot for education.&nbsp;&nbsp;</p>



<p>We haven&#8217;t seen … I don&#8217;t think we&#8217;re looking at this as a tutor. To your point, we&#8217;re kind of looking at it as a transactional in and out. But as we&#8217;ve seen in all kinds of data, both in low-, middle-income countries and even in Harvard, using this as a tutor can really accelerate your knowledge and in profound ways.&nbsp;&nbsp;</p>



<p>And so that is probably one area where I think your prediction was maybe slightly even further ahead of the curve because I don&#8217;t think folks have really grokked that opportunity yet.&nbsp;</p>



<p><strong>LEE: </strong>Yeah, and for people who haven&#8217;t read the book, you know, the guess was that you might use this as a training aid if you&#8217;re an aspiring doctor. For example, you can ask GPT-4 to pretend to be a patient that presents a certain way and that you are the doctor that this patient has come to see. And so you have an interaction. And then when you say end of encounter, you ask GPT-4 to assess how well you did. And we thought that this might be a great training aid, and to your point, it seems not to have materialized.&nbsp;&nbsp;</p>



<p><strong>LUNGREN:</strong> There&#8217;s some sparks. You know, with, like, communication, end-of-life conversations that no physician loves to have, right. It&#8217;s very, very hard to train someone in those. I&#8217;ve seen some work done, but you&#8217;re right. It&#8217;s not quite hit mainstream yet.&nbsp;</p>



<p><strong>LEE:</strong> On the subject of things that we missed, one thing that you&#8217;ve been very, very involved in in the last several months has been in shipping products that are multimodal. So that was something I think that we missed completely. What is the current state of affairs for multimodal, you know, healthcare AI, medical AI?&nbsp;</p>



<p><strong>LUNGREN:</strong> Yeah, the way I like to explain it—and first of all, no fault to you, but this is not an area that, like, we were just so excited about the text use cases that I can&#8217;t fault you. But yeah, I mean, so if we look at healthcare, right, how we take care of patients today, as you know, the vast majority of the data in terms of just data itself is actually not in text, right. It&#8217;s going be in pathology and genomics and radiology, etc.&nbsp;&nbsp;</p>



<p>And it seems like an opportunity here to watch this huge curve just goes straight up in the general reasoning and frankly medical competency and capabilities of the models that are coming and continue to come but then to see that it&#8217;s not as proficient for medical-specific imaging and video and, you know, other data types. And that gap is, kind of, what I describe as the multimodal medical AI gap.&nbsp;&nbsp;</p>



<p>We&#8217;re probably in GPT-2 land, right, for this other modality types versus the, you know, we&#8217;re now at o3, who knows where we&#8217;re going to go. At least in our view, we can innovate in that space.&nbsp;&nbsp;</p>



<p>How do we help bring those innovations to the broader community to close that gap and see some of these use cases really start to accelerate in the multimodal world?&nbsp;&nbsp;</p>



<p>And I think we&#8217;ve taken a pretty good crack at that. A lot of that is credit to the innovative work. I mean, MSR [Microsoft Research] was two or three years ahead of everyone else on a lot of this. And so how do we package that up in a way that the community can actually access and use? And so, we took a lot of what your group had done in, let&#8217;s just say, radiology or pathology in particular, and say, “OK, well, let&#8217;s put this in an ecosystem of other models.” Other groups can participate in this, but let&#8217;s put it in a platform where maybe I&#8217;m really competent in radiology or pathology. How do I connect those things together? How do I bring the general reasoner knowledge into a multimodal use case?&nbsp;&nbsp;</p>



<p>And I think that&#8217;s what we&#8217;ve done pretty well so far. We have a lot of work to do still, but this is very, very exciting. We&#8217;re seeing just such a ton of interest in building with the tools that we put out there.&nbsp;</p>



<p><strong>LEE:</strong> Well, I think how rapidly that&#8217;s advancing has been a surprise to me. So I think we&#8217;re running short on time. So two last questions to wrap up this conversation. The first one is, as we think ahead on AI in medicine, what do you think will be the biggest changes or make the biggest differences two years from now, five years from now, 10 years from now?</p>



<p><strong>LUNGREN:</strong> This is really tough. OK. I think the two-year timeframe, I think we will have some autonomous agent-based workflows for a lot of the &#8230; what I would call undifferentiated heavy lifting in healthcare.&nbsp;&nbsp;</p>



<p>And this is happening in, you know, the pharmaceutical industry, the payer … every aspect is sort of looking at their operations at a macro level: where are these big bureaucratic processes that largely involve text and where can we shrink those down and really kind of unlock a lot of our workforce to do things that might be more meaningful to the business? I think that&#8217;s my safe one.&nbsp;&nbsp;</p>



<p>Going five years out, you know, I have a really difficult time grappling with this seemingly shrinking timeline to AGI [artificial general intelligence] that we hear from people who I would respect and certainly know more than me. And in that world, I think there&#8217;s only been <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://ai.nejm.org/doi/abs/10.1056/AIp2400559" rel="noreferrer noopener" target="_blank">one paper that I&#8217;ve seen that has attempted to say, what does that mean in healthcare<span class="sr-only"> (opens in new tab)</span></a> when we have this?&nbsp;&nbsp;</p>



<p>And the fact is, I actually don&#8217;t know. [LAUGHS] I wonder whether there&#8217;ll still be a gap in some modalities. Maybe there&#8217;ll be the ability to do new science, and all kinds of interesting things will come of that.&nbsp;&nbsp;</p>



<p>But then if you go all the way to your 10-year, I do feel like we&#8217;re going to have systems that are acting autonomously in a variety of capacities, if I&#8217;m being honest.&nbsp;&nbsp;</p>



<p>What I would like to see if I have any influence on some of this is, can we start to celebrate the closing of hospitals instead of opening them? Meaning that, can we actually start to address—at a personal, individual level—care? And maybe that&#8217;s outside the home, maybe that&#8217;s, you know, in a way that doesn&#8217;t have to use so many resources and, frankly, really be very reactive instead of proactive.&nbsp;&nbsp;</p>



<p>I really want to see that. That&#8217;s been the vision of precision medicine for, geez, 20-plus years. I feel like we&#8217;re getting close to that being something we can really tackle.&nbsp;</p>



<p><strong>LEE: </strong>So, we talked about Geoff Hinton and his famous prediction that we would soon not have human radiologists. And of course, maybe he got the date wrong. So, let&#8217;s reset the date to 2028. So, Matt, do you think Geoff is right or wrong?&nbsp;</p>



<p><strong>LUNGREN:</strong> [LAUGHS] Yeah, so the way … I&#8217;m not going to dodge the question, but let me just answer this a different way.&nbsp;&nbsp;</p>



<p>We have a clear line of sight to go from images to draft reports. That is unmistakable. And that&#8217;s now in 2025. How it will be implemented and what the implications of that will be, I think, will be heavily dependent on the health system or the incentive structure for where it&#8217;s deployed.&nbsp;&nbsp;</p>



<p>So, if I&#8217;m trying to take a step back, back to my global health days, man, that can&#8217;t come fast enough. Because, you know, you have entire health systems, you know, in fact entire countries that have five, you know, medical imaging experts for the whole country, but they still need this to you know take care of patients.&nbsp;&nbsp;</p>



<p>Zooming in on today&#8217;s crisis in the US, right, we have the burnout crisis just as much as the doctors who are seeing patients and write notes. We can&#8217;t keep up with the volume. In fact, we&#8217;re not training folks fast enough, so there is a push pull; there may be a flip to your point of autonomous reads across some segments of what we do.&nbsp;&nbsp;</p>



<p>By 2028, I think that&#8217;s a reasonable expectation that we&#8217;ll have some form of that. Yes.&nbsp;</p>



<p><strong>LEE: </strong>I tend to agree, and I think things get reshaped, but it seems very likely that even far into the future we&#8217;ll have humans wanting to take care of other humans and be taken care of by humans.&nbsp;&nbsp;</p>



<p>Matt, this has been a fantastic conversation, and, you know, I feel it&#8217;s always a personal privilege to have a chance to work with someone like you so keep it up.&nbsp;</p>



<p>[TRANSITION MUSIC]&nbsp;</p>



<p><strong>LUNGREN: </strong>Thank you so much, Peter. Thanks for having me.&nbsp;</p>



<p><strong>LEE:</strong> I&#8217;m always so impressed when I talk to Matt, and I feel lucky that we get a chance to work together here at Microsoft. You know, one of the things that always strikes me whenever I talk to him is just how disruptive generative AI has been to a business like Nuance. Nuance has had clinical note-taking as part of their product portfolio for a long, long time. And so, you know, when generative AI comes along, it&#8217;s not only an opportunity for them, but also a threat because in a sense, it opens up the possibility of almost anyone being able to make clinical note-taking capabilities into products.&nbsp;&nbsp;</p>



<p>It&#8217;s really interesting how Matt&#8217;s product, DAX Copilot, which since the time that we had our conversation has expanded into a full healthcare workflow product called <a href="https://www.microsoft.com/en-us/health-solutions/clinical-workflow/dragon-copilot">Dragon Copilot</a>, has really taken off in the marketplace and how many new competing AI products have also hit the market, and all in just two years, because of generative AI.&nbsp;&nbsp;</p>



<p>The other thing, you know, that I always think about is just how important it is for these kinds of systems to work together and especially how they integrate into the electronic health record systems. This is something that Carey, Zak, and I didn&#8217;t really realize fully when we wrote our book. But you know, when you talk to both Matt and Seth, of course, we see how important it is to have that integration.&nbsp;&nbsp;</p>



<p>Finally, what a great example of yet another person who is both a surgeon and a tech geek. [LAUGHS] People sometimes think of healthcare as moving very slowly when it comes to new technology, but people like Matt are actually making it happen much more quickly than most people might expect.&nbsp;&nbsp;</p>



<p>Well, anyway, as I mentioned, we also had a chance to talk to Seth Hain, and so here&#8217;s my conversation with Seth:</p>



<p><strong>LEE:</strong> Seth, thank you so much for joining.&nbsp;&nbsp;</p>



<p><strong>SETH HAIN:</strong> Well, Peter, it&#8217;s such an exciting time to sit down and talk about this topic. So much has changed in the last two years. Thanks for inviting me.&nbsp;&nbsp;</p>



<p><strong>LEE:</strong> Yeah, in fact, I think in a way both of our lives have been upended in many ways by the emergence of AI. [LAUGHTER]&nbsp;&nbsp;</p>



<p>The traditional listeners of the Microsoft Research Podcast, I think for the most part, aren&#8217;t steeped in the healthcare industry. And so maybe we can just start with two things. One is, what is Epic, really? And then two, what is your job? What does the senior vice president for R&amp;D at Epic do every day?&nbsp;</p>



<p><strong>HAIN:</strong> Yeah, well, let&#8217;s start with that first question. So, what is Epic? Most people across the world experience Epic through something we call MyChart. They might use it to message their physician. They might use it to check the lab values after they&#8217;ve gotten a recent test. But it&#8217;s an app on their phone, right, for connecting in with their doctors and nurses and really making them part of the care team.&nbsp;&nbsp;</p>



<p>But the software we create here at Epic goes beyond that. It&#8217;s what runs in the clinic, what runs at the bedside, in the back office to help facilitate those different pieces of care, from collecting vital information at the bedside to helping place orders if you&#8217;re coming in for an outpatient visit, maybe with a kiddo with an earache, and capturing that note and record of what happened during that encounter, all the way through back-office encounters, back-office information for interacting with payers as an example.&nbsp;&nbsp;</p>



<p>And so, we provide a suite of software that health systems and increasingly a broader set of the healthcare ecosystem, like payers and specialty diagnostic groups, use to connect with that patient at the center around their care.&nbsp;</p>



<p>And my job is to help our applications across the company take advantage of those latest pieces of technology to help improve the efficiency of folks like clinicians in the exam room when you go in for a visit. We&#8217;ll get into, I imagine, some use cases like ambient conversations, capturing that conversation in the exam room to help drive some of that documentation.&nbsp;&nbsp;</p>



<p>But then providing that platform for those teams to build those and then strategize around what to create next to help both the physicians be efficient and also the health systems. But then ultimately continuing to use those tools to advance the science of medicine.&nbsp;</p>



<p><strong>LEE:</strong> Right. You know, one thing that I explain to fellow technologists is that I think today health records are almost entirely digital. I think the last figures I saw is well over 99% of all health records are digital.&nbsp;&nbsp;</p>



<p>But in the year 2001, fewer than 15% of health records were digital. They were literally in folders on paper in storerooms, and if you&#8217;re old enough, you might even remember seeing those storerooms.&nbsp;&nbsp;</p>



<p>So, it&#8217;s been quite a journey. Epic and Epic&#8217;s competitors—though I think Epic is really the most important company—have really moved the entire infrastructure of record keeping and other communications in healthcare to a digital foundation.&nbsp;&nbsp;</p>



<p>And I think one thing we&#8217;ll get into, of course, one of the issues that has really become, I think, a problem for doctors and nurses is the kind of clerical or paperwork, record-keeping, burden. And for that reason, Epic and Epic systems end up being a real focus of attention. And so, we&#8217;ll get into that in a bit here.&nbsp;&nbsp;</p>



<p><strong>HAIN:</strong> And I think that hits, just to highlight it, on both sides. There is both the need to capture documentation; there&#8217;s also the challenge in reviewing it.&nbsp;&nbsp;</p>



<p><strong>LEE:</strong> Yes.&nbsp;&nbsp;</p>



<p><strong>HAIN: </strong>The average medical record these days is somewhere between the length of <em>Fahrenheit 451</em> and <em>To Kill a Mockingbird</em>. [LAUGHTER] So there&#8217;s a fair amount of effort going in on that review side, as well.&nbsp;</p>



<p><strong>LEE: </strong>Yeah, indeed. So much to get into there. But I would like to talk about encounters with AI. So obviously, I think there are two eras here: before the emergence of ChatGPT and what we now call of as generative AI and afterwards. And so, let&#8217;s take the former.&nbsp;&nbsp;</p>



<p>Of course, you&#8217;ve been thinking about machine learning and health data probably for decades. Do you have a memory of how you got into this? Why did you get an interest in data analytics and machine learning in the first place?&nbsp;</p>



<p><strong>HAIN: </strong>Well, my background, as you noted, is in mathematics before I came to Epic. And the sort of patterns and what could emerge were always part of what drove that. Having done development and kind of always been around computers all my life, it was a natural transition as I came here.&nbsp;&nbsp;</p>



<p>And I started by really focusing on, how do we scale systems for the very largest organizations, making sure they are highly available and also highly responsive? Time is critical in these contexts in regards to rapidly getting information to doctors and nurses.&nbsp;&nbsp;</p>



<p>And then really in the, say, in the 2010s, there started to be an emergence of capabilities from a storage and compute perspective where we could begin to build predictive analytics models. And these were models that were very focused, right. It predicted the likelihood somebody would show up for an appointment. It predicted the likelihood that somebody may fall during an inpatient stay, as an example.&nbsp;&nbsp;</p>



<p>And I think a key learning during that time period was thinking through the full workflow. What information was available at that point in time, right? At the moment somebody walks into the ED [emergency department], you don&#8217;t have a full picture to predict the likelihood that they may deteriorate during an inpatient encounter.&nbsp;&nbsp;</p>



<p>And in addition to what information was available was, what can you do about it? And a key part of that was how do we help get the right people in the right point in time at the bedside to make an assessment, right? It was a human-in-the-loop type of workflow where, for example, you would predict deterioration in advance and have a nurse come to the bedside or a physician come to the bedside to assess.&nbsp;&nbsp;</p>



<p>And I think that combination of narrowly focused predictive models with an understanding that to have them make an impact you had to think through the full workflow of where a human would make a decision was a key piece.&nbsp;</p>



<p><strong>LEE: </strong>Obviously there is a positive human impact. And so, for sure, part of the thought process for these kinds of capabilities comes from that.<strong>&nbsp;</strong>&nbsp;</p>



<p>But Epic is also a business, and you have to worry about, you know, what are doctors and clinics and healthcare systems willing to buy. And so how do you balance those two things, and do those two things ever come into conflict as you&#8217;re imagining what kinds of new capabilities and features and products to create?&nbsp;</p>



<p><strong>HAIN:</strong> Two, sort of, two aspects I think really come to mind. First off, generally speaking, we see analytics and AI as a <em>part</em> of the application. So, in that sense, it&#8217;s not something we license separately. We think that those insights and those pieces of data are part of what makes the application meaningful and impactful.&nbsp;&nbsp;</p>



<p>At the scale that many of these health systems operate and the number of patients that they care for, as well as having tens of thousands of users in the system daily, one needs to think about the compute overhead …&nbsp;</p>



<p><strong>LEE: </strong>Yes.&nbsp;</p>



<p><strong>HAIN:</strong> … that these things cause. And so, in that regard, there is always a ROI assessment that is taking place to some degree around, what happens if this runs at full scale? And in a way, that really got accelerated as we went into the generative AI era.&nbsp;&nbsp;</p>



<p><strong>LEE:</strong> Right. OK. So, you mentioned generative AI. What was the first encounter, and what was that experience for you?</p>



<p><strong>HAIN:</strong> So, in the winter of ’22 and into 2023, I started experimenting alongside you with what we at that time called DV3, or Davinci 3, and eventually became GPT-4. And immediately, a few things became obvious. The tool was highly general purpose. One was able to, in putting in a prompt, have it sort of convert into the framing and context of a particular clinical circumstance and reason around that context. But I think the other thing that started to come to bear in that context was there was a fair amount of latent knowledge inside of it that was very, very different than anything we&#8217;d seen before. And, you know, there&#8217;s some examples from the <a href="https://www.microsoft.com/en-us/research/publication/sparks-of-artificial-general-intelligence-early-experiments-with-gpt-4/?msockid=12da2addb70263b40f2e3f57b6c56288" rel="noreferrer noopener" target="_blank">Sparks of AGI paper from Microsoft Research</a>, where a series of objects end up getting stacked together in the optimal way to build height. Just given the list of objects, it seems to have a understanding of physical space that it intuited from the training processes we hadn&#8217;t seen anywhere. So that was an entirely new capability that programmers now had access to.&nbsp;&nbsp;</p>



<p><strong>LEE: </strong>Well in fact, you know, I think that winter of 2022, and we&#8217;ll get into this, one of your projects that you&#8217;ve been running for quite a few years is something called <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://cosmos.epic.com/" rel="noreferrer noopener" target="_blank">Cosmos<span class="sr-only"> (opens in new tab)</span></a>, which I find exceptionally interesting. And I was motivated to understand whether this type of technology could have an impact there.  </p>



<p>And so, I had to receive permission from both OpenAI and Microsoft to provide you with early access.&nbsp;&nbsp;</p>



<p>When I did first show this technology to you, you must have had an emotional response, either skepticism or … I can&#8217;t imagine you just trusted, you know, trusted me to the extent of believing everything I was telling you.&nbsp;</p>



<p><strong>HAIN:</strong> I think there&#8217;s always a question of, what is it actually, right? It&#8217;s often easy to create demos. It&#8217;s often easy to show things in a narrow circumstance. And it takes getting your hands on it and really spending your 10,000 hours digging in and probing it in different ways to see just how general purpose it was.&nbsp;&nbsp;</p>



<p>And so, the skepticism was really around, how applicable can this be broadly? And I think the second question—and we&#8217;re starting to see this play out now in some of the later models—was, is this just a language thing? Is it narrowly only focused on that? Or can we start to imagine other modalities really starting to factor into this? How will it impact basic sciences? Those sorts of things.</p>



<p>On a personal note, I mean, I had, at that point, now they&#8217;re now 14 and 12, two kids that I wondered, what did this mean for them? What is the right thing for them to be studying? And so I remember sleepless nights on that topic, as well.&nbsp;</p>



<p><strong>LEE: </strong>OK, so now you get early access to this technology; you&#8217;re able to do some experimentation. I think one of the things that impressed me is just less than four months later at the major health tech industry conference, HIMSS, which also happened timing-wise to take place just after the public disclosure of GPT-4, Epic showed off some early prototype applications of generative AI. And so, describe what those were, and how did you choose what to try to do there?&nbsp;</p>



<p><strong>HAIN:</strong> Yeah, and we were at that point, we actually had the very first users live on that prototype, on that early version.&nbsp;&nbsp;</p>



<p>And the key thing we&#8217;d focused on—we started this development in very, very late December, January of 2023—was a problem that its origins really were during the pandemic.&nbsp;&nbsp;</p>



<p>So, during the pandemic, we started to see patients increasingly messaging their providers, nurses, and clinicians through MyChart, that patient portal I mentioned with about 190 million folks on it. And as you can imagine, that was a great opportunity in the context of COVID to limit the amount of direct contact between providers and patients while still getting their questions answered.&nbsp;&nbsp;</p>



<p>But what we found as we came out of the pandemic was that folks preferred it regardless. And that messaging volume had stayed very, very high and was a time-consuming effort for folks.&nbsp;&nbsp;</p>



<p>And so, the first use case we came out with was a draft message in the context of the message from the patient and understanding of their medical history using that medical record that we talked about.&nbsp;&nbsp;</p>



<p>And the nurse or physician using the tool had two options. They could either click to start with that draft and edit it and then hit send, or they could go back to the old workflow and start with a blank text box and write it from their own memory as they preferred.</p>



<p>And so that was that very first use case. There were many more that we had started from a development perspective, but, yeah, we had that rolling out right in March of 2023 there with the first folks.&nbsp;</p>



<p><strong>LEE: </strong>So, I know from our occasional discussions that some things worked very well. In fact, this is a real product now for Epic. And it seems to be really a very, very popular feature now. I know from talking to you that a lot of things have been harder. And so, I&#8217;d like to dive into that. As a developer, tech developer, you know, what&#8217;s been easy, what&#8217;s been hard, what&#8217;s in your mind still is left to do in terms of the development of AI?&nbsp;</p>



<p><strong>HAIN: </strong>Yeah. You know, the first thing that comes to mind sort of starting foundationally, and we hinted at this earlier in our conversation, was at that point in time, it was kind of per a message, rather compute-intensive to run these. And so, there were always trade-offs we were making in regards to how many pieces of information we would send into the model and how much would we request back out of it.&nbsp;&nbsp;</p>



<p>The result of that was that while kind of theoretically or even from a research perspective, we could achieve certain outcomes that were quite advanced, one had to think about, where you make those trade-offs from a scalability perspective as you wanted to roll that out to lot of folks. So …&nbsp;</p>



<p><strong>LEE:</strong> Were you charging your customers more money for this feature?&nbsp;</p>



<p><strong>HAIN:</strong> Yeah, essentially the way that we handle that is there&#8217;s compute that&#8217;s required. As I mentioned, the feature is just part of our application. So, it&#8217;s just what they get with an upgrade.&nbsp;&nbsp;</p>



<p>But that compute overhead is something that we needed to pass through to them. And so, it was something, particularly given both the staffing challenges, but also the margin pressures that health systems are feeling today, we wanted to be very cautious and careful about.&nbsp;</p>



<p><strong>LEE:</strong> And let&#8217;s put that on the stack because I do want to get into, from the selling perspective, that challenge and how you perceive health systems as a customer making those trade-offs. But let&#8217;s continue on the technical side here.&nbsp;</p>



<p><strong>HAIN:</strong> Yeah. On the technical side, it was a consideration, right. We needed to be thoughtful about how we used them. But going up a layer in the stack, at that time, there&#8217;s a lot of conversation in the industry around something called RAG, or <em>retrieval-augmented generation</em>.&nbsp;&nbsp;</p>



<p>And the idea was, could you pull the relevant bits, the relevant pieces of the chart, into that prompt, that information you shared with the generative AI model, to be able to increase the usefulness of the draft that was being created? And that approach ended up proving and continues to be to some degree, although the techniques have greatly improved, somewhat brittle, right. You have a general-purpose technology that is drafting the response.&nbsp;</p>



<p>But in many ways, you needed to, for a variety of pragmatic reasons, have somewhat brittle capability in regards to what you pulled into that approach. It tended to be pretty static. And I think this becomes one of the things that, looking forward, as these models have gotten a lot more efficient, we are and will continue to improve upon because, as you get a richer and richer amount of information into the model, it does a better job of responding.&nbsp;&nbsp;</p>



<p>I think the third thing, and I think this is going to be something we&#8217;re going to continue to work through as an industry, was helping users understand and adapt to these circumstances. So many folks when they hear AI think, it will just magically do everything perfectly.&nbsp;&nbsp;</p>



<p>And particularly early on with some of those challenges we&#8217;re talking about, it doesn&#8217;t. You know, if it&#8217;s helpful 85% of the time, that&#8217;s great, but it&#8217;s not going to be 100% of the time. And it&#8217;s interesting as we started, we do something we call immersion, where we always make sure that developers are right there elbow to elbow with the users of the software.&nbsp;</p>



<p>And one of the things that I realized through that experience with some of the very early organizations like UCSD [UC San Diego] or University of Wisconsin here in Madison was that even when I&#8217;m responding to an email or a physician is responding to one of these messages from a patient, depending on the patient and depending on the person, they respond differently.&nbsp;&nbsp;</p>



<p>In that context, there&#8217;s opportunity to continue to mimic that behavior as we go forward more deeply. And so, you learn a lot about, kind of, human behavior as you&#8217;re putting these use cases out into the world.&nbsp;</p>



<p><strong>LEE: </strong>So, you know, this increasing burden of electronic communications between doctors, nurses, and patients is centered in one part of Epic. I think that&#8217;s called your in-basket application, if I understand correctly.&nbsp;&nbsp;</p>



<p><strong>HAIN:</strong> That&#8217;s correct.&nbsp;</p>



<p><strong>LEE:</strong> But that also creates, I think, a reputational risk and challenge for Epic because as doctors feel overburdened by this and they&#8217;re feeling burnt out—and as we know, that&#8217;s a big issue—then they point to, you know, “Oh, I&#8217;m just stuck in this Epic system.”&nbsp;&nbsp;</p>



<p>And I think a lot of the dissatisfaction about the day-to-day working lives of doctors and nurses then focuses on Epic. And so, to what extent do you see technologies like generative AI as, you know, a solution to that or contributing either positively or negatively to this?&nbsp;</p>



<p><strong>HAIN:</strong> You know, earlier I made the comment that in December, as we started to explore this technology, we realized there were a class of problems that now might have solutions that never did before.&nbsp;&nbsp;</p>



<p>And as we&#8217;ve started to dig into those—and we now have about 150 different use cases that are under development, many of which are live across … we&#8217;ve got about 350 health systems using them—one of the things we&#8217;ve started to find is that physicians, nurses, and others start to react to saying it&#8217;s helping them move forward with their job.&nbsp;&nbsp;</p>



<p>And examples of this, obviously the draft of the in-basket message response is one, but using ambient voice recognition as a kind of new input into the software so that when a patient and a physician sit down in the exam room, the physician can start a recording and that conversation then ends up getting translated or summarized, if you will, including using medical jargon, into the note in the framework that the physician would typically write.&nbsp;&nbsp;</p>



<p>Another one of those circumstances where they then review it, don&#8217;t need to type it out from scratch, for example, …&nbsp;&nbsp;</p>



<p><strong>LEE:</strong> Right.&nbsp;</p>



<p><strong>HAIN:</strong> … and can quickly move forward.&nbsp;&nbsp;</p>



<p>I think looking forward, you know, you brought up Cosmos earlier. It&#8217;s a suite of applications, but at its core is a dataset of about 300 million de-identified patients. And so using generative AI, we built research tools on top of it. And I bring that up because it’s a precursor of how that type of deep analytics can be put into context at the point of care. That&#8217;s what we see this technology more deeply enabling in the future.&nbsp;</p>



<p><strong>LEE:</strong> Yeah, when you are creating … so you said there are about 150 sort of integrations of generative AI going into different parts of Epic&#8217;s software products.&nbsp;&nbsp;</p>



<p>When you are doing those developments and then you&#8217;re making a decision that something is going to get deployed, one thing that people might worry about is, well, these AI systems hallucinate. They have biases. There are unclear accountabilities, you know, maybe patient expectations.&nbsp;&nbsp;</p>



<p>For example, if there&#8217;s a note drafted by AI that&#8217;s sent to a patient, does the patient have a right to know what was written by AI and what was written by the human doctor? So, can we run through how you have thought about those things?&nbsp;&nbsp;</p>



<p><strong>HAIN:</strong> I think one thing that is important context to set here for folks, and I think it’s often a point of confusion when I&#8217;m chatting with folks in public, is that their interaction with generative AI is typically through a chatbot, right. It&#8217;s something like ChatGPT or Bing or one of these other products where they&#8217;re essentially having a back-and-forth conversation.&nbsp;</p>



<p><strong>LEE: </strong>Right.&nbsp;</p>



<p><strong>HAIN: </strong>And that is a dramatically different experience than how we think it makes sense to embed into an enterprise set of applications.&nbsp;&nbsp;</p>



<p>So, an example use case may be in the back office, there are folks that are <em>coding</em> encounters. So, when a patient comes in, right, they have the conversation with the doctor, the doctor documents it, that encounter needs to be billed for, and those folks in the back-office associate to that encounter a series of codes that provide information about how that billing should occur.</p>



<p>So, one of the things we did from a workflow perspective was add a selector pane to the screen that uses generative AI to suggest a likely code. Now, this suggestion runs the risk of hallucination. So, the question is, how do you build into the workflow additional checks that can help the user do that?&nbsp;&nbsp;</p>



<p>And so in this context, we always include a citation back to the part of the medical record that justifies or supports that code. So quickly on hover, the user can see, does this make sense before selecting it? And it&#8217;s those types of workflow pieces that we think are critical to using this technology as an aid to helping people make decisions faster, right. It&#8217;s similar to drafting documentation that we talked about earlier.&nbsp;&nbsp;</p>



<p>And it&#8217;s interesting because there&#8217;s a series of patterns that are … going back to the <em>AI Revolution</em> book you folks wrote two years ago. Some of these are really highlighted there, right. This idea of things like a universal translator is a common pattern that we ended up applying across the applications. And in my mind, translation, this may sound a little bit strange, but summarization is an example of translating a very long series of information in a medical record into the context that an ED physician might care about, where they have three or four minutes to quick review that very long chart.&nbsp;&nbsp;</p>



<p>And so, in that perspective, and back to your earlier comment, we added the summary into the workflow but always made sure that the full medical record was available to that user, as well. So, a lot of what we&#8217;ve done over the last couple of years has been to create a series of repeatable techniques in regards to both how to build the backend use cases, where to pull the information, feed it into the generative AI models.&nbsp;&nbsp;</p>



<p>But then I think more importantly are the user experience design patterns to help mitigate those risks you talked about and to maintain consistency across the integrated suite of applications of how those are deployed.&nbsp;&nbsp;</p>



<p><strong>LEE:</strong> You might remember from our book, we had a whole chapter on reducing paperwork, and I think that&#8217;s been a lot of what we&#8217;ve been talking about. I want to get beyond that, but before transitioning, let&#8217;s get some numbers.&nbsp;&nbsp;</p>



<p>So, you talked about messages drafted to patients, to be sent to patients. So, give a sense of the volume of what&#8217;s happening right now.&nbsp;</p>



<p><strong>HAIN:</strong> Oh, we are seeing across the 300 and, I think it&#8217;s, 48 health systems that are now using generative AI—and to be clear, we have about 500 health systems we have the privilege of working with, each with many, many hospitals—there are tens of thousands of physicians and nurses using the software. That includes drafting million-plus, for example, notes a month at this point, as well as helping to generate in a similar ballpark that number of responses to patients.&nbsp;&nbsp;</p>



<p>The thing I&#8217;m increasingly excited about is the broader set of use cases that we&#8217;re seeing folks starting to deploy now. One of my favorites has been … it&#8217;s natural that as part of, for example, a radiology workflow, in studying that image, the radiologist made note that it would be worth double checking, say in six to eight months, that the patient have this area scanned of their chest. Something looks a little bit fishy there, but there&#8217;s not &#8230;&nbsp;</p>



<p><strong>LEE:</strong> There&#8217;s not a definitive finding yet.&nbsp;</p>



<p><strong>HAIN:</strong> … there&#8217;s not a definitive finding at that point. Part of that workflow is that the patient&#8217;s physician place an order for that in the future. And so, we&#8217;re using generative AI to note that back to the physician. And with one click, allow them to place that order, helping that patient get better care.&nbsp;&nbsp;</p>



<p>That&#8217;s one example of dozens of use cases that are now live, both to help improve the care patients are getting but also help the workforce. So going back to the translation-summarization example, a nurse at the end of their shift needs to write up a summary of that shift for the next nurse for each …&nbsp;</p>



<p><strong>LEE: </strong>Right.&nbsp;</p>



<p><strong>HAIN: </strong>… each patient that they care for. Well, they&#8217;ve been documenting information in the chart over those eight or 12 hours, right.&nbsp;&nbsp;</p>



<p><strong>LEE: </strong>Yep, yep.&nbsp;</p>



<p><strong>HAIN:</strong> So, we can use that information to quickly draft that end-of-shift note for the nurse. They can verify it with those citations we talked about and make any additions or edits that they need and then complete their end of day far more efficiently.&nbsp;&nbsp;</p>



<p><strong>LEE:</strong> Right. OK. So now let&#8217;s get to Cosmos, which has been one of these projects that I think has been your baby for many years and has been something that has had a profound impact on my thinking about possibilities. So first off, what is Cosmos?&nbsp;</p>



<p><strong>HAIN: </strong>Well, just as an aside, I appreciate the thoughtful comments. There is a whole team of folks here that are really driving these projects forward. And a large part of that has been, as you brought up, both Cosmos as a foundational capability but then beginning to integrate it into applications. And that&#8217;s what those folks spend time on.&nbsp;&nbsp;</p>



<p>Cosmos is this effort across hundreds of health systems that we have the privilege of working with to build out a de-identified dataset with today—and it climbs every day—but 300 million unique patient records in it.&nbsp;&nbsp;</p>



<p>And one of the interesting things about that structure is that, for example, if I end up in a hospital in Seattle and have that encounter documented at a health system in Seattle, I still—a <em>de-identified version of me</em>—still only shows up once in Cosmos, stitching together both my information from here in Madison, Wisconsin, where Epic is at, with that extra data from Seattle. The result is these 300 million unique longitudinal records that have a deep history associated with them.&nbsp;&nbsp;</p>



<p><strong>LEE: </strong>And just to be clear, a patient record might have hundreds or even thousands of individual, I guess what you would call, clinical records or elements.&nbsp;</p>



<p><strong>HAIN: </strong>That&#8217;s exactly right. It&#8217;s the breadth of information from orders and allergies and blood pressures collected, for example, in an outpatient setting to cancer staging information that might have come through as part of an oncology visit. And it&#8217;s coming from a variety of sources. We exchange information about 10 million times a day between different health systems. And that full picture is available within Cosmos in that way of the patient.&nbsp;</p>



<p><strong>LEE:</strong> So now why? Why Cosmos?&nbsp;</p>



<p><strong>HAIN:</strong> Why Cosmos? Well, the real ultimate aim is to put a deeply informed in-context perspective at the point of care. So, as a patient, if I&#8217;m in the exam room, it&#8217;s helpful for the physician and me to know what have similar patients like me experienced in this context. What was the result of that line of treatment, for example?&nbsp;</p>



<p>Or as a doctor, if I&#8217;m looking and working through a relatively rare or strange case to me, I might be able to connect with—this as an example workflow we built called Look-Alikes—with another physician who has seen similar patients or within the workflow see a list of likely diagnoses based on patients that have been in a similar context. And so, the design of Cosmos is to put those insights into the point of care in the context of the patient.&nbsp;&nbsp;</p>



<p>To facilitate those steps there, the first phase was building out a set of research tooling. So, we see dozens of papers a year being published by the health systems that we work with. Those that participate in Cosmos have access to it to do research on it. And so they use both a series of analytical and data science tools to do that analysis and then publish research. So, building up trust that way.&nbsp;&nbsp;</p>



<p><strong>LEE:</strong> The examples you gave are, like with Look-Alikes, it&#8217;s very easy, I think, for people outside of the healthcare world to imagine how that could be useful. So now why is GPT-4 or any generative AI relevant to this?&nbsp;</p>



<p><strong>HAIN:</strong> Well, so a couple of different pieces, right. Earlier we talked about—and I think this is the most important—how generative AI is able to cast things into a specific context. And so, in that way, we can use these tools to help both identify a cohort of patients similar to you when you&#8217;re in the exam room. And then also help present that information back in a way that relates to other research and understandings from medical literature to understand what are those likely outcomes.&nbsp;&nbsp;</p>



<p>I think more broadly, these tools and generative AI techniques in the transformer architecture envision a deeper understanding of sequences of events, sequences of words. And that starts to open up broader questions about what can really be understood about patterns and sequences of events in a patient&#8217;s journey.&nbsp;&nbsp;</p>



<p>Which if you didn&#8217;t know, the name Epic, just like a great long nation&#8217;s journey is told through an epic story, is a patient&#8217;s story. So that&#8217;s where it came from.&nbsp;</p>



<p><strong>LEE:</strong> So, we&#8217;re running up against our time together. And I always like to end with a more provocative question.&nbsp;&nbsp;</p>



<p><strong>HAIN:</strong> Certainly.&nbsp;</p>



<p><strong>LEE:</strong> And for you, I wanted to raise a question that I think we had asked ourselves in the very earliest days that we were sharing Davinci 3, what we now know of as GPT-4, with each other, which is, is there a world in the future because of AI where we don&#8217;t need electronic health records anymore? Is there a world in the future without EHR?&nbsp;</p>



<p><strong>HAIN:</strong> I think it depends on how you define EHR. I see a world coming where we need to manage a hybrid workforce, where there is a combination of humans and something folks are sometimes calling <em>agents</em> working in concert together to care for more and more of our … of the country and of the world. And there is and will need to be a series of tools to help orchestrate that hybrid workforce. And I think things like EHRs will transform into helping that operate … be operationally successful.&nbsp;&nbsp;</p>



<p>But as a patient, I think there&#8217;s a very different opportunity that starts to be presented. And we&#8217;ve talked about kind of understanding things deeply in context. There&#8217;s also a real acceleration happening in science right now. And the possibility of bringing that second- and third-order effects of generative AI to the point of care, be that through the real-world evidence we were talking about with Cosmos or maybe personalized therapies that really are well matched to that individual. These generative AI techniques open the door for that, as well as the full lifecycle of managing that from a healthcare perspective all the way through monitoring after the fact.&nbsp;&nbsp;</p>



<p>And so, I think we&#8217;ll still be recording people&#8217;s stories. Their stories are relevant to them, and they can help inform the bigger picture. But I think the real question is, how do you put those in a broader context? And these tools open the door for a lot more.&nbsp;</p>



<p><strong>LEE:</strong> Well, that&#8217;s really a great vision for the future.&nbsp;&nbsp;</p>



<p>[TRANSITION MUSIC]&nbsp;</p>



<p>Seth, I always really learn so much talking to you, and thank you so much for this great chat.&nbsp;</p>



<p><strong>HAIN:</strong> Thank you for inviting me.&nbsp;&nbsp;&nbsp;</p>



<p><strong>LEE:</strong> I see Seth as someone on the very leading frontier of bringing generative AI to the clinic and into the healthcare back office and at the full scale of our massive healthcare system. It&#8217;s always impressive to me how thoughtful Seth has had to be about how to deploy generative AI into a clinical setting.&nbsp;&nbsp;</p>



<p>And, you know, one thing that sticks out—and he made such a point of this—is, you know, generative AI in the clinical setting isn&#8217;t just a chatbot. They&#8217;ve had to really think of other ways that will guarantee that the human stays in the loop. And that&#8217;s of course exactly what Carey, Zak, and I had predicted in our book. In fact, we even had a full chapter of our book entitled “Trust but Verify,” which really spoke to the need in medicine to always have a human being directly involved in overseeing the process of healthcare delivery.&nbsp;</p>



<p>One technical point that Carey, Zak, and I completely missed, on the other hand, in our book, was the idea of something that Seth brought up called RAG, which is <em>retrieval-augmented generation</em>. That&#8217;s the idea of giving AI access to a database of information and allowing it to use that database as it constructs its answers. And we heard from Seth how fundamental RAG is to a lot of the use cases that Epic is deploying. </p>



<p>And finally, I continue to find Seth&#8217;s project called Cosmos to be a source of inspiration, and I&#8217;ve continued to urge every healthcare organization that has been collecting data to consider following a similar path.&nbsp;</p>



<p>In our book, we spent a great deal of time focusing on the possibility that AI might be able to reduce or even eliminate a lot of the clerical drudgery that currently exists in the delivery of healthcare. We even had a chapter entitled “The Paperwork Shredder.” And we heard from both Matt and Seth that that has indeed been the early focus of their work.&nbsp;&nbsp;</p>



<p>But we also saw in our book the possibility that AI could provide diagnoses, propose treatment options, be a second set of eyes to reduce medical errors, and in the research lab be a research assistant. And here in Epic’s Cosmos, we are seeing just the early glimpses that perhaps generative AI can actually provide new research possibilities in addition to assistance in clinical decision making and problem solving. On the other hand, that still seems to be for the most part in our future rather than something that&#8217;s happening at any scale today.&nbsp;</p>



<p>But looking ahead to the future, we can still see the potential of AI helping connect healthcare delivery experiences to the advancement of medical knowledge. As Seth would say, the ability to connect bedside to the back office to the bench. That&#8217;s a pretty wonderful future that will take a lot of work and tech breakthroughs to make it real. But the fact that we now have a credible chance of making that dream happen for real, I think that&#8217;s pretty wonderful.&nbsp;</p>



<p>[MUSIC TRANSITIONS TO THEME]&nbsp;</p>



<p>I&#8217;d like to say thank you again to Matt and Seth for sharing their experiences and insights. And to our listeners, thank you for joining us. We have some really great conversations planned for the coming episodes, including a look at how patients are using generative AI for their own healthcare, as well as an episode on the laws, norms, and ethics developing around AI and health, and more. We hope you&#8217;ll continue to tune in.</p>



<p>Until next time.</p>



<p>[MUSIC FADES]&nbsp;</p>

				</span>
			</div>
			<button class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle" type="button">
				Show more			</button>
		</div>
	</div>
</div>



<div class="wp-block-spacer" style="height: 30px;"></div>



<p id="ftn_1">[1] According to the <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://informatics.bmj.com/content/31/1/e101102" rel="noreferrer noopener" target="_blank">survey<span class="sr-only"> (opens in new tab)</span></a>, of the 20% of respondents who said they use generative AI in clinical practice, 29% reported using the technology for patient documentation and 28% said they use it for differential diagnosis.</p>



<p id="ftn_2">[2] A month after the conversation was recorded, <a href="https://www.microsoft.com/en-us/health-solutions/clinical-workflow/dragon-copilot" rel="noreferrer noopener" target="_blank">Microsoft Dragon Copilot</a> was unveiled. Dragon Copilot combines and extends the capabilities of DAX Copilot and Dragon Medical One.</p>



<hr class="wp-block-separator has-alpha-channel-opacity is-style-end-mark" />



<div class="wp-block-buttons is-layout-flex wp-block-buttons-is-layout-flex">
<div class="wp-block-button is-style-outline is-style-outline--2"><a class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/story/the-ai-revolution-in-medicine-revisited/">AI Revolution in Medicine podcast series</a></div>
</div>
<span class="sr-only" id="label-external-link">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/podcast/the-ai-revolution-in-medicine-revisited-real-world-healthcare-ai-development-and-deployment-at-scale/">Real-world healthcare AI development and deployment—at scale</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
<pubDate>Thu, 03 Apr 2025 13:00:00 +0000</pubDate>
</item>
<item>
<title>VidTok introduces compact, efficient tokenization to enhance AI video processing</title>
<link>https://www.microsoft.com/en-us/research/blog/vidtok-introduces-compact-efficient-tokenization-to-enhance-ai-video-processing/</link>
<guid>https://www.microsoft.com/en-us/research/blog/vidtok-introduces-compact-efficient-tokenization-to-enhance-ai-video-processing/</guid>
<content:encoded><![CDATA[
<figure class="wp-block-image size-large"><img alt="Diagram showing an overview of how video tokenizers work with stages labeled as Input, Encoder, Regularizer (Latent Space), Decoder, and Output. " class="wp-image-1135333" height="576" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/03/VidTok-BlogHeroFeature-1400x788-1-1024x576.png" width="1024" /></figure>



<p>Every day, countless videos are uploaded and processed online, putting enormous strain on computational resources. The problem isn’t just the sheer volume of data—it’s how this data is structured. Videos consist of raw pixel data, where neighboring pixels often store nearly identical information. This redundancy wastes resources, making it harder for systems to process visual content effectively and efficiently.</p>



<p>To tackle this, we’ve developed a new approach to compress visual data into a more compact and manageable form. In our paper “<a href="https://www.microsoft.com/en-us/research/publication/vidtok-a-versatile-and-open-source-video-tokenizer/" rel="noreferrer noopener" target="_blank">VidTok: A Versatile and Open-Source Video Tokenizer</a>,” we introduce a method that converts video data into smaller, structured units, or <em>tokens</em>. This technique provides researchers and developers in visual world modeling—a field dedicated to teaching machines to interpret images and videos—with a flexible and efficient tool for advancing their work.&nbsp;</p>



<h2 class="wp-block-heading" id="how-vidtok-works">How VidTok works<strong></strong></h2>



<p>VidTok is a technique that converts raw video footage into a format that AI can easily work with and understand, a process called <em>video tokenization</em>. This process converts complex visual information into compact, structured tokens, as shown in Figure 1.</p>



<figure class="wp-block-image aligncenter size-full"><img alt="Diagram showing an overview of how video tokenizers work with stages labeled as Input, Encoder, Regularizer (Latent Space), Decoder, and Output. " class="wp-image-1135323" height="213" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/03/figure-1.png" width="692" /><figcaption class="wp-element-caption">Figure 1. An overview of how video tokenizers work, which form the basis of VidTok.</figcaption></figure>



<p>By simplifying videos into manageable chunks, VidTok can enable AI systems to learn from, analyze, and generate video content more efficiently. VidTok offers several potential advantages over previous solutions:</p>



<p><strong>Supports both discrete and continuous tokens.</strong> Not all AI models use the same “language” for video generation. Some perform best with continuous tokens—ideal for high-quality diffusion models—while others rely on discrete tokens, which are better suited for step-by-step generation, like language models for video. VidTok is a tokenizer that has demonstrated seamless support for both, making it adaptable across a range of AI applications.</p>



<p><strong>Operates in both causal and noncausal modes. </strong>In some scenarios, video understanding depends solely on past frames (causal), while in others, it benefits from access to both past and future frames (noncausal). VidTok can accommodate both modes, making it suitable for real-time use cases like robotics and video streaming, as well as for high-quality offline video generation.</p>



<p><strong>Efficient training with high performance.</strong> AI-powered video generation typically requires substantial computational resources. VidTok can reduce training costs by half through a two-stage training process—delivering high performance and lowering costs.</p>



	<div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide">
		

		<p class="msr-promo__label text-gray-800 text-center text-uppercase">
		<span class="px-4 bg-white display-inline-block font-weight-semibold small">Microsoft research blog</span>
	</p>
	
	<div class="row pt-3 pb-4 align-items-center">
						<div class="msr-promo__media col-12 col-md-5">
				<a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/blog/promptwizard-the-future-of-prompt-optimization-through-feedback-driven-self-evolving-prompts/" target="_blank">
					<img alt="A diagram illustrating the joint optimization process of instructions and in-context examples in PromptWizard. The figure demonstrates how the framework iteratively refines both components, integrating feedback to enhance the overall prompt effectiveness and adaptability across tasks." class="w-100 display-block" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2024/12/PromptWizard-BlogHeroFeature-1400x788-1.png" />
				</a>
			</div>
			
			<div class="msr-promo__content p-3 px-5 col-12 col-md">

									<h2 class="h4">PromptWizard: The future of prompt optimization through feedback-driven self-evolving prompts</h2>
				
								<p class="large">PromptWizard from Microsoft Research is now open source. It is designed to automate and simplify AI prompt optimization, combining iterative LLM feedback with efficient exploration and refinement techniques to create highly effective prompts in minutes.</p>
				
								<div class="wp-block-buttons justify-content-center justify-content-md-start">
					<div class="wp-block-button">
						<a class="btn btn-brand glyph-append glyph-append-chevron-right" href="https://www.microsoft.com/en-us/research/blog/promptwizard-the-future-of-prompt-optimization-through-feedback-driven-self-evolving-prompts/" target="_blank">
							Read more						</a>
					</div>
				</div>
							</div><!--/.msr-promo__content-->
	</div><!--/.msr-promo__inner-wrap-->
<span class="sr-only" id="label-external-link">Opens in a new tab</span>	</div><!--/.msr-promo-->
	


<h2 class="wp-block-heading" id="architecture">Architecture</h2>



<p>The VidTok framework builds on a classic 3D encoder-decoder structure but introduces 2D and 1D processing techniques to handle spatial and temporal information more efficiently. Because 3D architectures are computationally intensive, VidTok combines them with less resource-intensive 2D and 1D methods to reduce computational costs while maintaining video quality.</p>



<p><strong>Spatial processing.</strong> Rather than treating video frames solely as 3D volumes, VidTok applies 2D convolutions—pattern-recognition operations commonly used in image processing—to handle spatial information within each frame more efficiently.</p>



<p><strong>Temporal processing.</strong> To model motion over time, VidTok introduces the <em>AlphaBlender</em> operator, which blends frames smoothly using a learnable parameter. Combined with 1D convolutions—similar operations applied over sequences—this approach captures temporal dynamics without abrupt transitions.</p>



<p>Figure 2 illustrates VidTok’s architecture in detail.</p>



<figure class="wp-block-image aligncenter size-full"><img alt="A diagram illustrating VidTok’s architecture, which integrates 2D+1D operations instead of relying solely on 3D techniques. The left side represents the encoder pathway, starting with a 3D InputBlock, followed by multiple 2D+1D DownBlocks and AlphaBlender Temporal DownBlocks. The right side shows the decoder pathway, mirroring the encoder with 2D+1D UpBlocks and AlphaBlender Temporal UpBlocks before reaching the 3D OutputBlock. A Regularizer module is connected at the bottom.  This approach strikes a balance between computational speed and high-quality video output. " class="wp-image-1135324" height="523" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/03/VidTok_Fig2.png" width="1269" /><figcaption class="wp-element-caption">Figure 2. VidTok’s architecture. It uses a combination of 2D and 1D operations instead of solely relying on 3D techniques, improving efficiency. For smooth frame transitions, VidTok employs the AlphaBlender operator in its temporal processing modules. This approach strikes a balance between computational speed and high-quality video output.</figcaption></figure>



<h2 class="wp-block-heading" id="quantization">Quantization</h2>



<p>To efficiently compress video data, AI systems often use quantization to reduce the amount of information that needs to be stored or transmitted. A traditional method for doing this is vector quantization (VQ), which groups values together and matches them to a fixed set of patterns (known as a codebook). However, this can lead to an inefficient use of patterns and lower video quality.</p>



<p>For VidTok, we use an approach called finite scalar quantization (FSQ). Instead of grouping values, FSQ treats each value separately. This makes the compression process more flexible and accurate, helping preserve video quality while keeping the file size small. Figure 3 shows the difference between the VQ and FSQ approaches.</p>



<figure class="wp-block-image aligncenter size-full"><img alt="A diagram comparing Vector Quantization (VQ) and Finite Scalar Quantization (FSQ). VQ maps input z to a learned codebook, selecting the closest entry, while FSQ quantizes z using fixed sets independently for each value. FSQ simplifies optimization and improves training stability. " class="wp-image-1135319" height="179" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/03/image-17.png" width="831" /><figcaption class="wp-element-caption">Figure 3. VQ (left) relies on learning a codebook, while FSQ (right) simplifies the process by independently grouping values into fixed sets, making optimization easier. VidTok adopts FSQ to enhance training stability and reconstruction quality.</figcaption></figure>



<h2 class="wp-block-heading" id="training">Training</h2>



<p>Training video tokenizers requires significant computing power. VidTok uses a two-stage process:</p>



<ol class="wp-block-list">
<li>It first trains the full model on low-resolution videos.</li>



<li>Then, it fine-tunes only the decoder using high-resolution videos.</li>
</ol>



<p>This approach cuts training costs in half—from 3,072 to 1,536 GPU hours—while maintaining video quality. Older tokenizers, trained on full-resolution videos from the start, were slower and more computationally intensive.&nbsp;</p>



<p>VidTok&#8217;s method allows the model to quickly adapt to new types of videos without affecting its token distribution. Additionally, it trains on lower-frame-rate data to better capture motion, improving how it represents movement in videos.</p>



<h2 class="wp-block-heading" id="evaluating-vidtok">Evaluating VidTok</h2>



<p>VidTok&#8217;s performance evaluation using the MCL-JCV benchmark—a comprehensive video quality assessment dataset—and an internal dataset demonstrates its superiority over existing state-of-the-art models in video tokenization. The assessment, which covered approximately 5,000 videos of various types, employed four standard metrics to measure video quality:</p>



<ol class="wp-block-list">
<li>Peak Signal-to-Noise Ratio (PSNR)</li>



<li>Structural Similarity Index Measure (SSIM)</li>



<li>Learned Perceptual Image Patch Similarity (LPIPS)</li>



<li>Fréchet Video Distance (FVD)</li>
</ol>



<p>The following table and Figure 4 illustrate VidTok’s performance:</p>



<figure class="wp-block-image aligncenter size-full"><img alt="Result table showing VidTok's performance compared to other models (MAGVIT-v2, OmniTokenizer, Cosmos-DV, CV-VAE, Open-Sora-v1.2, Open-Sora-Plan-v1.2, CogVideoX, Cosmos-CV) on two datasets (MCL-JCV and Internal-Val) with metrics including PSNR, SSIM, LPIPS, and FVD." class="wp-image-1135326" height="680" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/03/table-1.png" width="1651" /><figcaption class="wp-element-caption">Table 1</figcaption></figure>



<p>The results indicate that VidTok outperforms existing models in both discrete and continuous tokenization scenarios. This improved performance is achieved even when using a smaller model or a more compact set of reference patterns, highlighting VidTok&#8217;s efficiency.</p>



<figure class="wp-block-image aligncenter size-full"><img alt="Radar charts comparing the performance of discrete and continuous tokenization methods in VidTok and state-of-the-art methods using four metrics: PSNR, SSIM, LPIPS, and FVD. Larger chart areas indicate better overall performance. " class="wp-image-1135327" height="372" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/03/figure-2.png" width="1181" /><figcaption class="wp-element-caption">Figure 4. Quantitative comparison of discrete and continuous tokenization performance in VidTok and state-of-the-art methods, evaluated using four metrics: PSNR, SSIM, LPIPS, and FVD. Larger chart areas indicate better overall performance.</figcaption></figure>



<h2 class="wp-block-heading" id="looking-ahead">Looking ahead</h2>



<p>VidTok represents a significant development in video tokenization and processing. Its innovative architecture and training approach enable improved performance across various video quality metrics, making it a valuable tool for video analysis and compression tasks. Its capacity to model complex visual dynamics could improve the efficiency of video systems by enabling AI processing on more compact units rather than raw pixels.</p>



<p>VidTok serves as a promising foundation for further research in video processing and representation. The code for VidTok is available on <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/VidTok" rel="noreferrer noopener" target="_blank">GitHub<span class="sr-only"> (opens in new tab)</span></a>, and we invite the research community to build on this work and help advance the broader field of video modeling and generation.</p>
<span class="sr-only" id="label-external-link">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/blog/vidtok-introduces-compact-efficient-tokenization-to-enhance-ai-video-processing/">VidTok introduces compact, efficient tokenization to enhance AI video processing</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
<pubDate>Wed, 02 Apr 2025 16:00:00 +0000</pubDate>
</item>
<item>
<title>Ideas: Accelerating Foundation Models Research: AI for all</title>
<link>https://www.microsoft.com/en-us/research/podcast/ideas-accelerating-foundation-models-research-ai-for-all/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/ideas-accelerating-foundation-models-research-ai-for-all/</guid>
<content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img alt="Microsoft Research Podcast | Ideas: Evelyne Viegas, Muhammed Idris, Cesar Torres" class="wp-image-1134454" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/03/AFMR_Ideas_Hero_Feature_1400x788.jpg" width="1401" /></figure>


<div class="wp-block-msr-podcast-container my-4">
	
</div>



<p>Behind every emerging technology is a great idea propelling it forward. In the Microsoft Research Podcast series <em>Ideas</em>, members of the research community at Microsoft discuss the beliefs that animate their research, the experiences and thinkers that inform it, and the positive human impact it targets.&nbsp;</p>



<p>In this episode, host Gretchen Huizinga talks with three researchers about <a href="https://www.microsoft.com/en-us/research/collaboration/accelerating-foundation-models-research/">Accelerating Foundation Models Research (AFMR)<span class="sr-only"> (opens in new tab)</span></a>, a global research network and resource platform that allows members of the larger academic community to push the boundaries of AI foundation models and explore exciting and unconventional collaborations across disciplines and institutions. <a href="https://www.microsoft.com/en-us/research/people/evelynev/">Evelyne Viegas<span class="sr-only"> (opens in new tab)</span></a>, a technical advisor at Microsoft Research, shares her vision for the program from the Microsoft perspective, while <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.uta.edu/academics/faculty/profile?user=cearto" rel="noreferrer noopener" target="_blank">Cesar Torres<span class="sr-only"> (opens in new tab)</span></a>, an assistant professor of computer science at the University of Texas at Arlington, and <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.msm.edu/about_us/FacultyDirectory/Medicine/MuhammedIdris/index.php" rel="noreferrer noopener" target="_blank">Muhammed Idris<span class="sr-only"> (opens in new tab)</span></a>, an assistant professor in the departments of medicine and public health at the Morehouse School of Medicine, tell their stories of how access to state-of-the-art foundation models is helping creative practitioners find inspiration from both their physical and virtual environments and making cancer-related health information more accessible and culturally congruent. The three recount their research journeys, including both frustrations and aspirations, and relate how AFMR resources have provided game-changing opportunities for Minority Serving Institutions and the communities they serve.&nbsp;</p>



<p> &nbsp;</p>



<hr class="wp-block-separator has-alpha-channel-opacity" />



<h2 class="wp-block-heading h5" id="learn-more-1">Learn more:</h2>



<p><a href="https://www.microsoft.com/en-us/research/collaboration/accelerating-foundation-models-research/">Accelerating Foundation Models Research</a><br />Collaboration homepage</p>



<p><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://hybridatelier.uta.edu/" rel="noreferrer noopener" target="_blank">The Hybrid Atelier<span class="sr-only"> (opens in new tab)</span></a><br />Homepage, The University of Texas at Arlington</p>



<p><a href="https://www.microsoft.com/en-us/research/blog/announcing-recipients-of-the-afmr-minority-serving-institutions-grant/" rel="noreferrer noopener" target="_blank">Announcing recipients of the AFMR Minority Serving Institutions grant</a><br />Microsoft Research Blog, January 30, 2024</p>



<p>&nbsp;<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://news.microsoft.com/source/features/ai/ai-for-all-how-access-to-new-models-is-advancing-academic-research-from-astronomy-to-education/?msockid=35739e94ab6c69d41b738b93aa076831" rel="noreferrer noopener" target="_blank">AI ‘for all’: How access to new models is advancing academic research, from astronomy to education<span class="sr-only"> (opens in new tab)</span></a><br />Microsoft Blog, March 12, 2024</p>



<p><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.press.jhu.edu/newsroom/morehouse-model-how-one-school-medicine-revolutionized-community-engagement-and-health-equity" rel="noreferrer noopener" target="_blank">The Morehouse Model: How One School of Medicine Revolutionized Community Engagement and Health Equity<span class="sr-only"> (opens in new tab)</span></a>&nbsp;<br />Book, July 10, 2020&nbsp;</p>



<section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast">
	<div class="subscribe-to-podcast__inner border-top border-bottom border-width-2">
		<h2 class="h5 subscribe-to-podcast__heading">
			Subscribe to the <a href="https://www.microsoft.com/en-us/research/podcast">Microsoft Research Podcast</a>:		</h2>
		<ul class="subscribe-to-podcast__list list-unstyled">
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://itunes.apple.com/us/podcast/microsoft-research-a-podcast/id1318021537?mt=2" rel="noreferrer noopener" target="_blank">
						<svg class="subscribe-to-podcast__svg" fill="black" viewBox="0 0 32 32" xmlns="http://www.w3.org/2000/svg">  <path d="M7.12 0c-3.937-0.011-7.131 3.183-7.12 7.12v17.76c-0.011 3.937 3.183 7.131 7.12 7.12h17.76c3.937 0.011 7.131-3.183 7.12-7.12v-17.76c0.011-3.937-3.183-7.131-7.12-7.12zM15.817 3.421c3.115 0 5.932 1.204 8.079 3.453 1.631 1.693 2.547 3.489 3.016 5.855 0.161 0.787 0.161 2.932 0.009 3.817-0.5 2.817-2.041 5.339-4.317 7.063-0.812 0.615-2.797 1.683-3.115 1.683-0.12 0-0.129-0.12-0.077-0.615 0.099-0.792 0.192-0.953 0.64-1.141 0.713-0.296 1.932-1.167 2.677-1.911 1.301-1.303 2.229-2.932 2.677-4.719 0.281-1.1 0.244-3.543-0.063-4.672-0.969-3.595-3.907-6.385-7.5-7.136-1.041-0.213-2.943-0.213-4 0-3.636 0.751-6.647 3.683-7.563 7.371-0.245 1.004-0.245 3.448 0 4.448 0.609 2.443 2.188 4.681 4.255 6.015 0.407 0.271 0.896 0.547 1.1 0.631 0.447 0.192 0.547 0.355 0.629 1.14 0.052 0.485 0.041 0.62-0.072 0.62-0.073 0-0.62-0.235-1.199-0.511l-0.052-0.041c-3.297-1.62-5.407-4.364-6.177-8.016-0.187-0.943-0.224-3.187-0.036-4.052 0.479-2.323 1.396-4.135 2.921-5.739 2.199-2.319 5.027-3.543 8.172-3.543zM16 7.172c0.541 0.005 1.068 0.052 1.473 0.14 3.715 0.828 6.344 4.543 5.833 8.229-0.203 1.489-0.713 2.709-1.619 3.844-0.448 0.573-1.537 1.532-1.729 1.532-0.032 0-0.063-0.365-0.063-0.803v-0.808l0.552-0.661c2.093-2.505 1.943-6.005-0.339-8.296-0.885-0.896-1.912-1.423-3.235-1.661-0.853-0.161-1.031-0.161-1.927-0.011-1.364 0.219-2.417 0.744-3.355 1.672-2.291 2.271-2.443 5.791-0.348 8.296l0.552 0.661v0.813c0 0.448-0.037 0.807-0.084 0.807-0.036 0-0.349-0.213-0.683-0.479l-0.047-0.016c-1.109-0.885-2.088-2.453-2.495-3.995-0.244-0.932-0.244-2.697 0.011-3.625 0.672-2.505 2.521-4.448 5.079-5.359 0.547-0.193 1.509-0.297 2.416-0.281zM15.823 11.156c0.417 0 0.828 0.084 1.131 0.24 0.645 0.339 1.183 0.989 1.385 1.677 0.62 2.104-1.609 3.948-3.631 3.005h-0.015c-0.953-0.443-1.464-1.276-1.475-2.36 0-0.979 0.541-1.828 1.484-2.328 0.297-0.156 0.709-0.235 1.125-0.235zM15.812 17.464c1.319-0.005 2.271 0.463 2.625 1.291 0.265 0.62 0.167 2.573-0.292 5.735-0.307 2.208-0.479 2.765-0.905 3.141-0.589 0.52-1.417 0.667-2.209 0.385h-0.004c-0.953-0.344-1.157-0.808-1.553-3.527-0.452-3.161-0.552-5.115-0.285-5.735 0.348-0.823 1.296-1.285 2.624-1.291z"></svg>
						<span class="subscribe-to-podcast__link-text">Apple Podcasts</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://subscribebyemail.com/www.blubrry.com/feeds/microsoftresearch.xml" rel="noreferrer noopener" target="_blank">
						<svg class="subscribe-to-podcast__svg" fill="none" viewBox="0 0 32 32" xmlns="http://www.w3.org/2000/svg"><path d="M6.4 6a2.392 2.392 0 00-2.372 2.119L16 15.6l11.972-7.481A2.392 2.392 0 0025.6 6H6.4zM4 10.502V22.8a2.4 2.4 0 002.4 2.4h19.2a2.4 2.4 0 002.4-2.4V10.502l-11.365 7.102a1.2 1.2 0 01-1.27 0L4 10.502z" fill="currentColor"></svg>
						<span class="subscribe-to-podcast__link-text">Email</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://subscribeonandroid.com/www.blubrry.com/feeds/microsoftresearch.xml" rel="noreferrer noopener" target="_blank">
						<svg class="subscribe-to-podcast__svg" fill="none" viewBox="0 0 32 32" xmlns="http://www.w3.org/2000/svg"><path d="M12.414 4.02c-.062.012-.126.023-.18.06a.489.489 0 00-.12.675L13.149 6.3c-1.6.847-2.792 2.255-3.18 3.944h13.257c-.388-1.69-1.58-3.097-3.179-3.944l1.035-1.545a.489.489 0 00-.12-.675.492.492 0 00-.675.135l-1.14 1.68a7.423 7.423 0 00-2.55-.45c-.899 0-1.758.161-2.549.45l-1.14-1.68a.482.482 0 00-.494-.195zm1.545 3.824a.72.72 0 110 1.44.72.72 0 010-1.44zm5.278 0a.719.719 0 110 1.44.719.719 0 110-1.44zM8.44 11.204A1.44 1.44 0 007 12.644v6.718c0 .795.645 1.44 1.44 1.44.168 0 .33-.036.48-.09v-9.418a1.406 1.406 0 00-.48-.09zm1.44 0V21.76c0 .793.646 1.44 1.44 1.44h10.557c.793 0 1.44-.647 1.44-1.44V11.204H9.878zm14.876 0c-.169 0-.33.035-.48.09v9.418c.15.052.311.09.48.09a1.44 1.44 0 001.44-1.44v-6.719a1.44 1.44 0 00-1.44-1.44zM11.8 24.16v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84zm5.759 0v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84z" fill="currentColor"></svg>
						<span class="subscribe-to-podcast__link-text">Android</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://open.spotify.com/show/4ndjUXyL0hH1FXHgwIiTWU" rel="noreferrer noopener" target="_blank">
						<svg class="subscribe-to-podcast__svg" fill="none" viewBox="0 0 32 32" xmlns="http://www.w3.org/2000/svg"><path d="M16 4C9.383 4 4 9.383 4 16s5.383 12 12 12 12-5.383 12-12S22.617 4 16 4zm5.08 17.394a.781.781 0 01-1.086.217c-1.29-.86-3.477-1.434-5.303-1.434-1.937.002-3.389.477-3.403.482a.782.782 0 11-.494-1.484c.068-.023 1.71-.56 3.897-.562 1.826 0 4.365.492 6.171 1.696.36.24.457.725.217 1.085zm1.56-3.202a.895.895 0 01-1.234.286c-2.338-1.457-4.742-1.766-6.812-1.747-2.338.02-4.207.466-4.239.476a.895.895 0 11-.488-1.723c.145-.041 2.01-.5 4.564-.521 2.329-.02 5.23.318 7.923 1.995.419.26.547.814.286 1.234zm1.556-3.745a1.043 1.043 0 01-1.428.371c-2.725-1.6-6.039-1.94-8.339-1.942h-.033c-2.781 0-4.923.489-4.944.494a1.044 1.044 0 01-.474-2.031c.096-.023 2.385-.55 5.418-.55h.036c2.558.004 6.264.393 9.393 2.23.497.292.663.931.371 1.428z" fill="currentColor"></svg>
						<span class="subscribe-to-podcast__link-text">Spotify</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://www.blubrry.com/feeds/microsoftresearch.xml" rel="noreferrer noopener" target="_blank">
						<svg class="subscribe-to-podcast__svg" fill="none" viewBox="0 0 32 32" xmlns="http://www.w3.org/2000/svg"><path d="M6.667 4a2.676 2.676 0 00-2.612 2.13v.003c-.036.172-.055.35-.055.534v18.666c0 .183.019.362.055.534v.003a2.676 2.676 0 002.076 2.075h.002c.172.036.35.055.534.055h18.666A2.676 2.676 0 0028 25.333V6.667a2.676 2.676 0 00-2.13-2.612h-.003A2.623 2.623 0 0025.333 4H6.667zM8 8h1.333C17.42 8 24 14.58 24 22.667V24h-2.667v-1.333c0-6.618-5.382-12-12-12H8V8zm0 5.333h1.333c5.146 0 9.334 4.188 9.334 9.334V24H16v-1.333A6.674 6.674 0 009.333 16H8v-2.667zM10 20a2 2 0 11-.001 4.001A2 2 0 0110 20z" fill="currentColor"></svg>
						<span class="subscribe-to-podcast__link-text">RSS Feed</span>
					</a>
				</li>
					</ul>
	</div>
</section>


<div class="wp-block-msr-show-more">
	<div class="bg-neutral-100 p-5">
		<div class="show-more-show-less">
			<div>
				<span>
					

<h2 class="wp-block-heading" id="transcript">Transcript</h2>



<p>[TEASER]&nbsp;</p>



<p>[MUSIC PLAYS UNDER DIALOG]&nbsp;&nbsp;</p>



<p><strong>EVELYNE VIEGAS:</strong> So AFMR is really a program which enabled us to provide access to foundation models, but it&#8217;s also a global network of researchers. And so for us, I think when we started that program, it was making sure that AI was made available to anyone and not just the few, right? And really important to hear from our academic colleagues, what they were discovering and covering and what were those questions that we&#8217;re not even really thinking about, right? So that&#8217;s how we started with AFMR.</p>



<p><strong>CESAR TORRES:</strong> One of the things that the AFMR program has allowed me to see is this kind of ability to better visualize the terrain of creativity. And it&#8217;s a little bit of a double-edged sword because when we talk about disrupting creativity and we think about tools, it&#8217;s typically the case that the tool is making something easier for us. So my big idea is to actually think about tools that are purposely making us slower, that have friction, that have errors, that have failures. To say that maybe the easiest path is not the most advantageous, but the one that you can feel the most fulfillment or agency towards.</p>



<p><strong>MUHAMMED IDRIS:</strong> For me, I think what programs like AFMR have enabled us to do is really start thinking outside the box as to how will these or how can these emerging technologies revolutionize public health? What truly would it take for an LLM to understand context? And really, I think for the first time, we can truly, truly achieve personalized, if you want to use that term, health communication.&nbsp;</p>



<p>[TEASER ENDS]&nbsp;</p>



<p>[MUSIC PLAYS]&nbsp;</p>



<p><strong>GRETCHEN HUIZINGA:</strong> You’re listening to Ideas, a Microsoft Research podcast that dives deep into the world of technology research and the profound questions behind the code. I&#8217;m Gretchen Huizinga. In this series, we&#8217;ll explore the technologies that are shaping our future and big ideas that propel them forward.</p>



				</span>
				<span class="show-more-show-less-toggleable-content" id="show-more-show-less-toggle-1">
					



<p>[MUSIC FADES]&nbsp;</p>



<p>I&#8217;m excited to share the mic today with three guests to talk about a really cool program called Accelerating Foundation Models Research, or AFMR for short. With me is Cesar Torres, an assistant professor of computer science at the University of Texas, Arlington, and the director of a program called The Hybrid Atelier. More on that soon. I&#8217;m also joined by Muhammed Idris, an assistant professor of medicine at the Morehouse School of Medicine. And finally, I welcome Evelyne Viegas, a technical advisor at Microsoft Research. Cesar, Muhammed, Evelyne, welcome to Ideas!&nbsp;</p>



<p><strong>EVELYNE VIEGAS:</strong> Pleasure.&nbsp;</p>



<p><strong>CESAR TORRES:</strong> Thank you.&nbsp;</p>



<p><strong>MUHAMMED IDRIS:</strong> Thank you.&nbsp;</p>



<p><strong>HUIZINGA: </strong>So I like to start these episodes with what I&#8217;ve been calling the “research origin story” and since there are three of you, I&#8217;d like you each to give us a brief overview of your work. And if there was one, what big idea or larger than life person inspired you to do what you&#8217;re doing today? Cesar let&#8217;s start with you and then we&#8217;ll have Muhammed and Evelyne give their stories as well. </p>



<p><strong>CESAR TORRES:</strong> Sure, thanks for having me. So, I work at the frontier of creativity especially thinking about how technology could support or augment the ways that we manipulate our world and our ideas. And I would say that the origin of why I happened into this space can really come back down to a “bring your kid to work” day. [LAUGHTER] My dad, who worked at Maquiladora, which is a factory on the border, took me over – he was an accountant – and so he first showed me the accountants and he&#8217;s like look at the amazing work that these folks are doing. But the reality is that a lot of what they do is hidden behind spreadsheets and so it wasn&#8217;t necessarily the most engaging. Suffice to say I did not go into accounting like my dad! [LAUGHTER] But then he showed us the chemical engineer in the factory, and he would tell me this chemical engineer holds the secret formula to the most important processes in the entire company. But again, it was this black box, right? And I got a little bit closer when I looked at this process engineer who was melting metal and pulling it out of a furnace making solder and I thought wow, that&#8217;s super engaging but at the same time it&#8217;s like it was hidden behind machinery and heat and it was just unattainable. And so finally I saw my future career and it was a factory line worker who was opening boxes. And the way that she opened boxes was incredible. Every movement, every like shift of weight was so perfectly coordinated. And I thought, here is the peak of human ability. [LAUGHTER] This was a person who had just like found a way to leverage her surroundings, to leverage her body, the material she was working with. And I thought, this is what I want to study. I want to study how people acquire skills. And I realized … that moment, I realized just how important the environment and visibility was to being able to acquire skills. And so from that moment, everything that I&#8217;ve done to this point has been trying to develop technologies that could get everybody to develop a skill in the same way that I saw that factory line worker that day. </p>



<p><strong>HUIZINGA:</strong> Wow, well, we&#8217;ll get to the specifics on what you&#8217;re doing now and how that&#8217;s relevant in a bit. But thank you for that. So Muhammed, what&#8217;s the big idea behind your work and how did you get to where you are today?&nbsp;</p>



<p><strong>MUHAMMED IDRIS:</strong> Yeah, no. First off, Cesar, I think it&#8217;s a really cool story. I wish I had an origin story [LAUGHTER] from when I was a kid, and I knew exactly what my life&#8217;s work was going to be. Actually, my story, I figured out my “why” much later. Actually, my background was in finance. And I started my career in the hedge fund space at a company called BlackRock, really large financial institution you might have heard of. Then I went off and I did a PhD at Penn State. And I fully intended on going back. I was going to basically be working in spreadsheets for the rest of my life. But actually during my postdoc at the time I was living in Montreal, I actually had distant relatives of mine who were coming to Montreal to apply for asylum and it was actually in helping them navigate the process, that it became clear to me, you know, the role, it was very obvious to me, the role that technology can play in helping people help themselves. And kind of the big idea that I realized is that, you know, oftentimes, you know, the world kind of provides a set of conditions, right, that strip away our rights and our dignity and our ability to really fend for ourselves. But it was so amazing to see, you know, 10-, 12-year-old kids who, just because they had a phone, were able to help their families navigate what shelter to go to, how to apply for school, and more importantly, how do they actually start the rest of their lives? And so actually at the time, I, you know, got together a few friends, and, you know, we started to think about, well, you know, all of this information is really sitting on a bulletin board somewhere. How can we digitize it? And so we put together a pretty, I would say, bad-ass team, interdisciplinary team, included developers and refugees, and we built a prototype over a weekend. And essentially what happened was we built this really cool platform called Atar. And in many ways, I would say that it was the first real solution that leveraged a lot of the natural language processing capabilities that everyone is using today to actually help people help themselves. And it did that in three really important ways. The first way is that people could essentially ask what they needed help with in natural language. And so we had some algorithms developed that would allow us to identify somebody&#8217;s intent. Taking that information then, we had a set of models that would then ask you a set of questions to understand your circumstances and determine your eligibility for resources. And then from that, we&#8217;d create a customized checklist for them with everything that they needed to know, where to go, what to bring, and who to talk to in order to accomplish that thing. And it was amazing to see how that very simple prototype that we developed over a weekend really became a lifeline for a lot of people. And so that&#8217;s really, I think, what motivated my work in terms of trying to combine data science, emerging technologies like AI and machine learning, with the sort of community-based research that I think is important for us to truly identify applications where, in my world right now, it&#8217;s really studying health disparities. </p>



<p><strong>HUIZINGA:</strong> Yeah. Evelyne, tell us how you got into doing what you&#8217;re doing as a technical advisor. What&#8217;s the big idea behind what you do and how you got here?&nbsp;</p>



<p><strong>EVELYNE VIEGAS:</strong> So as a technical advisor in Microsoft Research, I really look for ideas out there. So ideas can come from anywhere. And so think it of scanning the horizon to look for some of those ideas out there and then figuring out, are there scientific hypotheses we should be looking at? And so the idea here is, once we have identified some of those ideas, the goal is really to help nurture a healthy pipeline for potential big bets. What I do is really about “subtle science and exact art” and we discover as we do and it involves a lot of discussions and conversations working with our researchers here, our scientists, but of course with the external research community. And how I got here … well first I will say that I am so excited to be alive in a moment where AI has made it to industry because I&#8217;ve looked and worked in AI for as long as I can remember with very different approaches. And actually as important, importantly for me is really natural languages which have enabled this big evolution. People sometimes also talk about revolution in AI, via the language models. Because when I started, so I was very fortunate growing up in an environment where my family, my extended family spoke different languages, but then it was interesting to see the different idioms in those natural languages. Just to give you an example, in English you say, it rains cats and dogs. Well, in France, in French it doesn&#8217;t mean anything, right? In French, actually, it rains ropes, right? Which probably doesn&#8217;t mean anything in English. [LAUGHTER] And so I was really curious about natural languages and communication. When I went to school, being good at math, I ended up doing math, realizing very quickly that I didn&#8217;t want to do a career in math. You know, proofs all that is good in high school, doing a full career, was not my thing, math. You know, proofs, all that. It’s good in high school, but doing a full career, it was not my thing, math. But there was that class I really, really enjoyed, which was mathematical logic. And so little by little, I started discovering people working in that field. And at the same time, I was still restless with natural languages. And so I also took some classes in linguistics on the humanity university in Toulouse in France. And I stumbled on those people who were actually working in … some in linguistics, some in computer science, and then there was this lab doing computational linguistics. And then that was it for me. I was like, that&#8217;s, you know, so that&#8217;s how I ended up doing my PhD in computational linguistics. And the last aspect I&#8217;ll talk about, because in my role today, the aspect of working with a network of people, with a global network, is still so important to me, and I think for science as a whole. At the time, there was this nascent field of computational lexical semantics. And for me, it was so important to bring people together because I realized that we all had different approaches, different theories, not even in France, but across the world, and actually, I worked with somebody else, and we co-edited the first book on computational lexical semantics, where we started exposing what it meant to do lexical semantics and the relationships between words within a larger context, with a larger context of conversations, discourse, and all those different approaches. And that&#8217;s an aspect which for me to this day is so important and that was also really important to keep as we develop what we&#8217;re going to talk about today, Accelerating Foundation Models Research program.&nbsp;</p>



<p><strong>HUIZINGA:</strong> Yeah, this is fascinating because I didn&#8217;t even know all of these stories. I just knew that there were stories here and this is the first time I&#8217;m hearing them. So it&#8217;s like this discovery process and the sort of pushing on a door and having it be, well, that&#8217;s not quite the door I want. [LAUGHTER] Let&#8217;s try door number two. Let&#8217;s try door number three. Well, let&#8217;s get onto the topic of Accelerating Foundation Models Research and unpack the big idea behind that. Evelyne, I want to stay with you on this for a minute because I&#8217;m curious as to how this initiative even came to exist and what it hopes to achieve. So, maybe start out with a breakdown of the title. It might be confusing for some people, Accelerating Foundation Models Research. What is it?&nbsp;</p>



<p><strong>VIEGAS:</strong> Yeah, thank you for the question. So I think I&#8217;m going to skip quickly on accelerate research. I think people can understand it&#8217;s just like to bring …&nbsp;</p>



<p><strong>HUIZINGA:</strong> Make it faster …&nbsp;</p>



<p><strong>VIEGAS:</strong> … well, faster and deeper advances. I mean, there are some nuances there, but I think the terms like foundation models, maybe that&#8217;s where I&#8217;ll start here. So when we talk about foundation models, just think about any model which has been trained on broad data, and which actually enables you to really do any task. That&#8217;s, I think, the simplest way to talk about it. And indeed, actually people talk a lot about large language models or language models. And so think of language models as just one part, right, for those foundation models. The term was actually coined at Stanford when people started looking at GPTs, the generative pre-trained transformers, this new architecture. And so that term was coined like to go not just talk about language models, but foundation models, because actually it&#8217;s not just language models, but there are also vision models. And so there are other types of models and modalities really. And so when we started with Accelerating Foundation Models Research and from now on, I will say AFMR if that&#8217;s okay.&nbsp;</p>



<p><strong>HUIZINGA:</strong> Yeah. Not to be confused with ASMR, which is that sort of tingly feeling you get in your head when you hear a good sound, but AFMR, yes.&nbsp;</p>



<p><strong>VIEGAS:</strong> So with the AFMR, so actually I need to come a little bit before that and just remind us that actually that this is not just new. The point I was making earlier about it’s so important to engage with the external research community in academia. So Microsoft Research has been doing it for as long as I&#8217;ve been at Microsoft and I&#8217;ve been 25 years, I just did 25 in January.&nbsp;</p>



<p><strong>HUIZINGA:</strong> Congrats!&nbsp;</p>



<p><strong>VIEGAS:</strong> And so, I … thank you! &#8230;  and so, it&#8217;s really important for Microsoft Research, for Microsoft. And so we had some programs even before the GPT, ChatGPT moment where we had engaged with the external research community on a program called the Microsoft Turing Academic Program where we provided access to the Turing model, which was a smaller model than the one then developed by OpenAI. But at that time, it was very clear that we needed to be responsible, to look at safety, to look at trustworthiness of those models. And so we cannot just drink our own Kool-Aid and so we really had to work with people externally. And so we were already doing that. But that was an effort which we couldn&#8217;t scale really because to scale an effort and having multiple people that can have access to the resources, you need more of a programmatic way to be able to do that and rely on some platform, like for instance, Azure, which has security and privacy, confidentiality which enables to scale those type of efforts. And so what happens as we&#8217;re developing this program on the Turing model with a small set of academic people, then there was this ChatGPT moment in November 2022, which was the moment like the “aha moment,” I think, as I mentioned, for me, it&#8217;s like, wow, AI now has made it to industry. And so for us, it became very clear that we could not with this moment and the amount of resources needed on the compute side, access to actually OpenAI that new that GPT, at the beginning of GPT-3 and then 4 and then … So how could we build a program? First, should we, and was there interest? And academia responded “Yes! Please! Of course!” right? [LAUGHTER] I mean, what are you waiting for? So AFMR is really a program which enabled us to provide access to foundation models, but it&#8217;s also a global network of researchers. And so for us, I think when we started that program, it was making sure that AI was made available to anyone and not just the few, right? And really important to hear from our academic colleagues, what they were discovering and covering and what were those questions that we were not even really thinking about, right? So that&#8217;s how we started with AFMR. </p>



<p><strong>HUIZINGA:</strong> This is funny, again, on the podcast, you can&#8217;t see people shaking their heads, nodding in agreement, [LAUGHTER] but the two academic researchers are going, yep, that&#8217;s right. Well, Muhammed, let&#8217;s talk to you for a minute. I understand AFMR started a little more than a year ago with a pilot project that revolved around health applications, so this is a prime question for you. And since you&#8217;re in medicine, give us a little bit of a “how it started, how it&#8217;s going” from your perspective, and why it&#8217;s important for you at the Morehouse School of Medicine.&nbsp;</p>



<p><strong>IDRIS:</strong> For sure. You know, it&#8217;s something as we mentioned that really, I remember vividly is when I saw my first GPT-3 demo, and I was absolutely blown away. This was a little bit before the ChatGPT moment that Evelyne was mentioning, but just the possibilities, oh my God, were so exciting! And again, if I tie that back to the work that we were doing, where we were trying to kind of mimic what ChatGPT is today, there were so many models that we had to build, very complex architectures, edge cases that we didn&#8217;t even realize. So you could imagine when I saw that, I said, wow, this is amazing. It&#8217;s going to unlock so many possibilities. But at the same time, this demo was coming out, I actually saw a tweet about the inherent biases that were baked into these models. And I&#8217;ll never forget this. I think it was at the time he was a grad student at Stanford, and they were able to show that if you asked the model to complete a very simple sentence, a sort of joke, “Two Muslims walk into a bar …” what is it going to finish? And it was scary.&nbsp;&nbsp;</p>



<p><strong>HUIZINGA:</strong> Wow.&nbsp;</p>



<p><strong>IDRIS:</strong> Two thirds, it was about 66% of the time, the responses referenced some sort of violence, right? And that really was an “aha moment” for me personally, of course, not being that I&#8217;m Muslim, but beyond that, that there are all of these possibilities. At the same time, there&#8217;s a lot that we don&#8217;t know about how these models might operate in the real world. And of course, the first thing that this made me do as a researcher was wonder how do these emerging technologies, how may they unintentionally lead to greater health disparities? Maybe they do. Maybe they don&#8217;t. The reality is that we don&#8217;t know.&nbsp;</p>



<p><strong>HUIZINGA:</strong> Right.&nbsp;</p>



<p><strong>IDRIS: </strong>Now I tie that back to something that I&#8217;ve been fleshing out for myself, given my time here at Morehouse School of Medicine. And kind of what I believe is that, you know, the likely outcome, and I would say this is the case for really any sort of emerging technology, but let&#8217;s specifically talk about AI, machine learning, large language models, is that if we&#8217;re not intentional in interrogating how they perform, then what&#8217;s likely going to happen is that despite overall improvements in health, we&#8217;re going to see greater health disparities, right? It&#8217;s almost kind of that trickle-down economics type model, right? And it&#8217;s really this addressing of health disparities, which is at the core of the mission of Morehouse School of Medicine. It is literally the reason why I came here a few years ago. Now, the overarching goal of our program, without getting too specific, is really around evaluating the capabilities of foundation models. And those, course, as Evelyne mentioned, are large language models. And we&#8217;re specifically working on facilitating accessible and culturally congruent cancer-related health information. And specifically, we need to understand that communities that are disproportionately impacted have specific challenges around trust. And all of these are kind of obstacles to taking advantage of things like cancer screenings, which we know significantly reduce the likelihood of mortality. And it&#8217;s going very well. We have a pretty amazing interdisciplinary team. And I think we&#8217;ve been able to develop a pretty cool research agenda, a few papers and a few grants. I&#8217;d be happy to share about a little bit later.&nbsp;</p>



<p><strong>HUIZINGA:</strong> Yeah, that&#8217;s awesome. And I will ask you about those because your project is really interesting. But I want Cesar to weigh in here on sort of the goals that are the underpinning of AFMR, which is aligning AI with human values, improving AI-human interaction, and accelerating scientific discovery. Cesar, how do these goals, writ large, align with the work you&#8217;re doing at UT Arlington and how has this program helped?&nbsp;</p>



<p><strong>TORRES:</strong> Yeah, I love this moment in time that everybody&#8217;s been talking about, that GPT or large language model exposure. Definitely when I experienced it, the first thing that came to my head was, I need to get this technology into the hands of my students because it is so nascent, there&#8217;s so many open research questions, there&#8217;s so many things that can go wrong, but there&#8217;s also so much potential, right? And so when I saw this research program by Microsoft I was actually surprised. I saw that, hey, they are actually acknowledging the human element. And so the fact that there was this call for research that was looking at that human dimension was really refreshing. So like what Muhammad was saying, one of the most exciting things about these large language models is you don&#8217;t have to be a computer scientist in order to use them. And it reminded me to this moment in time within the arts when digital media started getting produced. And we had this crisis. There was this idea that we would lose all the skills that we have learned from working traditionally with physical materials and having to move into a digital canvas.&nbsp;&nbsp;</p>



<p><strong>HUIZINGA:</strong> Right.&nbsp;</p>



<p><strong>TORRES:</strong> And it&#8217;s kind of this, the birth of a new medium. And we&#8217;re kind of at this unique position to guide how this medium is produced and to make sure that people develop that virtuosity in being able to use that medium but also understand its limitations, right? And so one of the fun projects that we&#8217;ve done here has been around working with our glass shop. Specifically, we have this amazing neon-bending artists here at UTA, Jeremy Scidmore and Justin Ginsberg. We&#8217;ve been doing some collaborations with them, and we&#8217;ve been essentially monitoring how they bend glass. I run an undergraduate research program here and I’ve had undergrads try to tackle this problem of how do you transfer that skill of neon bending? And the fact is that because of AFMR, here is just kind of a way to structure that undergraduate research process so that people feel comfortable to ask those dumb questions exactly where they are. But what I think is even more exciting is that they start to see that questions like skill acquisition is still something that our AI is not able to do. And so it&#8217;s refreshing to see; it&#8217;s like the research problems have not all been solved. It just means that new ones have opened and ones that we previously thought were unattainable now have this groundwork, this foundation in order to be researched, to be investigated. And so it&#8217;s really fertile ground. And I really thank AFMR … the AFMR program for letting us have access to those grounds.&nbsp;</p>



<p><strong>HUIZINGA:</strong> Yeah. I&#8217;m really eager to get into both your projects because they&#8217;re both so cool. But Evelyne, I want you to just go on this “access” line of thought for a second because Microsoft has given grants in this program, AFMR, to several Minority Serving Institutions, or MSIs, as they&#8217;re called, including Historically Black Colleges and Universities and Hispanic Serving Institutions, so what do these grants involve? You&#8217;ve alluded to it already, but can you give us some more specifics on how Microsoft is uniquely positioned to give these and what they&#8217;re doing?&nbsp;</p>



<p><strong>VIEGAS:</strong> Yes. So the grant program, per se, is really access to resources, actually compute and API access to frontier models. So think about Azure, OpenAI … but also now actually as the program evolves, it&#8217;s also providing access to even our research models, so Phi, I mean if you … like smaller models …&nbsp;</p>



<p><strong>HUIZINGA:</strong> Yeah, P-H-I.&nbsp;</p>



<p><strong>VIEGAS:</strong> Yes, Phi! [LAUGHTER] OK! So, so it&#8217;s really about access to those resources. It&#8217;s also access to people. I was talking about this global research network and the importance of it. And I&#8217;ll come back to that specifically with the Minority Serving Institutions, what we did. But actually when we started, I think we started a bit in a naive way, thinking … we did an open call for proposals, a global one, and we got a great response. But actually at the beginning, we really had no participation from MSIs. [LAUGHTER] And then we thought, why? It&#8217;s open … it’s … and I think what we missed there, at the beginning, is like we really focused on the technology and some people who were already a part of the kind of, this global network, started approaching us, but actually a lot of people didn&#8217;t even know, didn&#8217;t think they could apply, right? And so we ended up doing a more targeted call where we provided not only access to the compute resources, access to the APIs to be able to develop applications or validate or expand the work which is being done with foundation models, but also we acknowledged that it was important, with MSIs, to also enable the students of the researchers like Cesar, Muhammed, and other professors who are part of the program so that they could actually spend the time working on those projects because there are some communities where the teaching load is really high compared to other communities or other colleges. So we already had a good sense that one size doesn&#8217;t fit all. And I think what came also with the MSIs and others, it&#8217;s like also one culture doesn&#8217;t fit all, right? So it&#8217;s about access. It&#8217;s about access to people, access to the resources and really co-designing so that we can really, really make more advances together.&nbsp;</p>



<p><strong>HUIZINGA:</strong> Yeah. Cesar let&#8217;s go over to you because big general terms don&#8217;t tell a story as well as specific projects with specific people. So your project is called, and I&#8217;m going to read this, <em>AI-Enhanced Bricolage: Augmenting Creative Decision Making in Creative Practices</em>. That falls under the big umbrella of Creativity and Design. So tell our audience, and as you do make sure to explain what bricolage is and why you work in a Hybrid Atelier, terms I&#8217;m sure are near and dear to Evelyne&#8217;s heart … the French language. Talk about that, Cesar. </p>



<p><strong>TORRES:</strong> So at UTA, I run a lab called The Hybrid Atelier. And I chose that name because “lab” is almost too siloed into thinking about scientific methods in order to solve problems. And I wanted something that really spoke to the ethos of the different communities of practice that generate knowledge. And so The Hybrid Atelier is a space, it&#8217;s a makerspace, and it&#8217;s filled with the tools and knowledge that you might find in creative practices like ceramics, glass working, textiles, polymer fabrication, 3D printing. And so every year I throw something new in there. And this last year, what I threw in there was GPT and large language models. And it has been exciting to see how it has transformed. But speaking to this specific project, I think the best way I can describe bricolage is to ask you a question: what would you do if you had a paperclip, duct tape, and a chewing gum wrapper? What could you make with that, right? [LAUGHTER] And so some of us have these MacGyver-type mentalities, and that is what Claude Lévi-Strauss<strong> </strong>kind of terms as the “bricoleur,” a person who is able to improvise solutions with the materials that they have at hand. But all too often, when we think about bricolage, it&#8217;s about the physical world. But the reality is that we very much live in a hybrid reality where we are behind our screens. And that does not mean that we cannot engage in these bricoleur activities. And so this project that I was looking at, it&#8217;s both a vice and an opportunity of the human psyche, and it&#8217;s known as “functional fixation.” And that is to say, for example, if I were to give you a hammer, you would see everything as a nail. And while this helps kind of constrain creative thought and action to say, okay, if I have this tool, I&#8217;m going to use it in this particular way. At the same time, it limits the other potential solutions, the ways that you could use a hammer in unexpected ways, whether it&#8217;s to weigh something down or like jewelers to texturize a metal piece or, I don&#8217;t know, even to use it as a pendulum &#8230; But my point here is that this is where large language models can come in because they can, from a more unbiased perspective, not having the cognitive bias of functional fixation say, hey, here is some tool, here&#8217;s some material, here&#8217;s some machine. Here are all the ways that I know people have used it. Here are other ways that it could be extended. And so we have been exploring, you know, how can we alter the physical and virtual environment in such a way so that this information just percolates into the creative practitioner’s mind in that moment when they&#8217;re trying to have that creative thought? And we&#8217;ve had some fun with it. I did a workshop at an event known as OurCS here at DFW. It&#8217;s a research weekend where we bring a couple of undergrads and expose them to research. And we found that it&#8217;s actually the case that it&#8217;s not AI that does better, and it&#8217;s also not the case that the practitioner does better! [LAUGHTER] It&#8217;s when they hybridize that you really kind of lock into the full kind of creative thought that could emerge. And so we&#8217;ve been steadily moving this project forward, expanding from our data sets, essentially, to look at the corpus of video tutorials that people have published all around the web to find the weird and quirky ways that they have extended and shaped new techniques and materials to advance creative thought. So …&nbsp;</p>



<p><strong>HUIZINGA:</strong> Wow.&nbsp;&nbsp;</p>



<p><strong>TORRES:</strong> … it&#8217;s been an exciting project to say the least.&nbsp;</p>



<p><strong>HUIZINGA:</strong> Okay, again, my face hurts because I&#8217;m grinning so hard for so long. I have to stop. No, I don&#8217;t because it&#8217;s amazing. You made me think of that movie Apollo 13 when they&#8217;re stuck up in space and this engineer comes in with a box of, we&#8217;ll call it bricolage, throws it down on the table and says, we need to make this fit into this using this, go. And they didn&#8217;t have AI models to help them figure it out, but they did a pretty good job. Okay, Cesar, that&#8217;s fabulous. I want Muhammed&#8217;s story now. I have to also calm down. It&#8217;s so much fun. [LAUGHTER]&nbsp;</p>



<p><strong>IDRIS:</strong> No, know I love it. I love it and actually to bring it back to what Evelyne was mentioning earlier about just getting different perspectives in a room, I think this is a perfect example of it. Actually, Cesar, I never thought of myself as being a creative person but as soon as you said a paperclip and was it the gum wrapper …&nbsp;</p>



<p><strong>HUIZINGA:</strong> Duct tape.&nbsp;</p>



<p><strong>IDRIS:</strong> … duct tape or gum wrapper, I thought to myself, my first internship I was able to figure out how to make two paper clips and a rubber band into a … this was of course before AirPods, right? But something that I could wrap my wires around and it was perfect! [LAUGHTER] I almost started thinking to myself, how could I even scale this, or maybe get a patent on it, but it was a paper clip … yeah. Uh, so, no, no, I mean, this is really exciting stuff, yeah.&nbsp;</p>



<p><strong>HUIZINGA:</strong> Well, Muhammed, let me tee you up because I want to actually … I want to say your project out loud …&nbsp;</p>



<p><strong>IDRIS:</strong> Please.&nbsp;</p>



<p><strong>HUIZINGA:</strong> … because it&#8217;s called <em>Advancing Culturally Congruent Cancer Communication with Foundation Models</em>. You might just beat Cesar&#8217;s long title with yours. I don&#8217;t know. [LAUGHTER] You include alliteration, which as an English major, that makes my heart happy, but it’s positioned under the Cognition and Societal Benefits bucket, whereas Cesar&#8217;s was under Creativity and Design, but I see some crossover. Evelyne&#8217;s probably grinning too, because this is the whole thing about research is how do these things come together and help? Tell us, Muhammed, about this cultury … culturally … Tell us about your project! [LAUGHTER]&nbsp;</p>



<p><strong>IDRIS:</strong> So, you know, I think again, whenever I talk about our work, especially the mission and the “why” of Morehouse School of Medicine, everything really centers around health disparities, right? And if you think about it, health disparities usually comes from one of many, but let&#8217;s focus on kind of three potential areas. You might not know you need help, right? If you know you need help, you might not know where to go. And if you end up there, you might not get the help that you need. And if you think about it, a lot of like the kind of the through line through all of these, it really comes down to health communication at the end of the day. It&#8217;s not just what people are saying, it&#8217;s how people are saying it as well. And so our project focuses right now on language and text, right? But we are, as I&#8217;ll talk about in a second, really exploring the kind of multimodal nature of communication more broadly and so, you know, I think another thing that&#8217;s important in terms of just background context is that for us, these models are more than just tools, right? We really do feel that if we&#8217;re intentional about it that they can be important facilitators for public health more broadly. And that&#8217;s where this idea of our project fitting under the bucket at benefiting society as a whole. Now, you know, the context is that over the past couple of decades, how we&#8217;ve talked about cancer, how we&#8217;ve shared health information has just changed dramatically. And a lot of this has to do with the rise, of course, of digital technologies more broadly, social media, and now there&#8217;s AI. People have more access to health information than ever before. And despite all of these advancements, of course, as I keep saying over and over again, not everyone&#8217;s benefiting equally, especially when it comes to cancer screening. Now, breast and cervical cancer, that&#8217;s what we&#8217;re focusing on specifically, are two of the leading causes of cancer-related deaths in women worldwide. And actually, black and Hispanic women in the US are at particular risk and disproportionately impacted by not just lower screening rates, but later diagnoses, and of course from that, higher mortality rates as well. Now again, an important part of the context here is COVID-19. I think there are, by some estimates, about 10 million cancer screenings that didn&#8217;t happen. And this is also happening within a context of just a massive amount of misinformation. It&#8217;s actually something that the WHO termed as an infodemic. And so our project is trying to kind of look for creative emerging technologies-based solutions for this. And I think we&#8217;re doing it in a few unique ways. Now the first way is that we&#8217;re looking at how foundation models like the GPTs but also open-source models and those that are, let&#8217;s say, specifically fine-tuned on medical texts, how do they perform in terms of their ability to generate health information? How accurate are they? How well is it written? And whether it&#8217;s actually useful for the communities that need it the most. We developed an evaluation framework, and we embedded within that some qualitative dimensions that are important to health communications. And we just wrapped up an analysis where we compared the general-purpose models, like a ChatGPT, with medical and more science-specific domain models and as you&#8217;d expect, the general-purpose models kind of produced information that was easier to understand, but that was of course at the risk of safety and more accurate responses that the medically tuned models were able to produce. Now a second aspect of our work, and I think this is really a unique part of not what I&#8217;ve called, but actually literally there&#8217;s a book called <em>The Morehouse Model</em>, is how is it that we could actually integrate communities into research? And specifically, my work is thinking about how do we integrate communities into the development and evaluation of language models? And that&#8217;s where we get the term “culturally congruent.” That these models are not just accurate, but they&#8217;re also aligned with the values, the beliefs, and even the communication styles of the communities that they&#8217;re meant to serve. One of the things that we&#8217;re thinking, you know, quite a bit about, right, is that these are not just tools to be published on and maybe put in a GitHub, you know, repo somewhere, right? That these are actually meant to drive the sort of interventions that we need within community. So of course, implementation is really key. And so for this, you know, not only do you need to understand the context within which these models will be deployed, the goal here really is to activate you and prepare you with information to be able to advocate for yourself once you actually see your doctor, right? So that again, I think is a good example of that. But you also have to keep in mind Gretchen that, you know, our goal here is, we don&#8217;t want to create greater disparities between those who have and those who don&#8217;t, right? And so for example, thinking about accessibility is a big thing and that&#8217;s been a part of our project as well. And so for example, we&#8217;re leveraging some of Azure API services for speech-to-text and we&#8217;re even going as far as trying to leverage some of the text-to-image models to develop visuals that address health literacy barriers and try to leverage these tools to truly, truly benefit health. </p>



<p><strong>HUIZINGA:</strong> One of the most delightful and sometimes surprising benefits of programs like AFMR is that the technologies developed in conjunction with people in minority communities have a big impact for people in majority communities as well, often called the Curb Cut Effect. Evelyne, I wonder if you&#8217;ve seen any of this happen in the short time that AFMR has been going?&nbsp;</p>



<p><strong>VIEGAS:</strong> Yeah, so, I&#8217;m going to focus a bit more maybe on education and examples there where we&#8217;ve seen, as Cesar was also talking about it, you know for scaling and all that. But we&#8217;ve seen a few examples of professors working with their students where English is not the first language.&nbsp;&nbsp;</p>



<p><strong>HUIZINGA:</strong> Yeah …&nbsp;</p>



<p><strong>VIEGAS:</strong> Another one I would mention is in the context of domains. So for domains, what I mean here is application domains, like not just in CS, but we&#8217;ve been working with professors who are, for instance, astronomers, or lawyers, or musicians working in universities. So they started looking actually at these LLMs as more of the “super advisor” helping them. And so it&#8217;s another way of looking at it. And actually they started focusing on, can we actually build small astronomy models, right? And I&#8217;m thinking, okay, that could … maybe also we learn something which could be potentially applied to some other domain. So these are some of the things we are seeing.&nbsp;</p>



<p><strong>HUIZINGA:</strong> Yes.&nbsp;</p>



<p><strong>VIEGAS:</strong> But I will finish with something which may, for me, kind of challenges this Curb Cut Effect to certain extent, if I understand the concept correctly, is that I think, with this technology and the way AI and foundation models work compared to previous technologies, I feel it&#8217;s kind of potentially the opposite. It&#8217;s kind of like the tail catching up with the head. But here I feel that with the foundation models, I think it&#8217;s a different way to find information and gain some knowledge. I think that actually when we look at that, these are really broad tools that now actually can be used to help customize your own curb, as it were! So kind of the other way around.&nbsp;</p>



<p><strong>HUIZINGA:</strong> Oh, interesting …&nbsp;</p>



<p><strong>VIEGAS:</strong> So I think it&#8217;s maybe there are two dimensions. It&#8217;s not just I work on something small, and it applies to everyone. I feel there is also a dimension of, this is broad, this is any tasks, and it enables many more people. I think Cesar and Muhammed made that point earlier, is you don&#8217;t have to be a CS expert or rocket scientist to start using those tools and make progress in your field. So I think that maybe there is this dimension of it.&nbsp;</p>



<p><strong>HUIZINGA:</strong> I love the way you guys are flipping my questions back on me. [LAUGHTER] So, and again, that is fascinating, you know, a custom curb, not a curb cut. Cesar, Muhammad, do you, either of you, have any examples of how perhaps this is being used in your work and you&#8217;re having accidental or serendipitous discoveries that sort of have a bigger impact than what you might&#8217;ve thought?&nbsp;</p>



<p><strong>TORRES:</strong> Well, one thing comes to mind. It&#8217;s a project that two PhD students in my lab, Adam Emerson and Shreyosi Endow have been working on. It&#8217;s around this idea of communities of practice and that is to say, when we talk about how people develop skills as a group, it&#8217;s often through some sort of tiered structure. And I&#8217;m making a tree diagram with my hands here! [LAUGHTER] And so we often talk about what it&#8217;s like for an outsider to enter from outside of the community, and just how much effort it takes to get through that gate, to go through the different rungs, through the different rites of passage, to finally be a part of the inner circle, so to speak. And one of the projects that we&#8217;ve been doing, we started to examine these known communities of practice, where they exist. But in doing this analysis, we realized that there&#8217;s a couple of folks out there that exist on the periphery. And by really focusing on them, we could start to see where the field is starting to move. And these are folks that have said, I&#8217;m neither in this community or another, I&#8217;m going to kind of pave my own way. While we&#8217;re still seeing those effects of that research go through, I think being able to monitor the communities at the fringe is a really telling sign of how we&#8217;re advancing as a society. I think shining some light into these fringe areas, it&#8217;s exactly how research develops, how it&#8217;s really just about expanding at some bleeding edge. And I think sometimes we just have to recontextualize that that bleeding edge is sometimes the group of people that we haven&#8217;t been necessarily paying attention to.&nbsp;</p>



<p><strong>HUIZINGA:</strong> Right. Love it. Muhammad, do you have a quick example … or, I mean, you don&#8217;t have to, but I just was curious.&nbsp;</p>



<p><strong>IDRIS:</strong> Yeah, maybe I&#8217;ll just give one quick example that I think keeps me excited, actually has to do with the idea of kind of small language models, right? And so, you know, I gave the example of GPT-3 and how it&#8217;s trained on the entirety of the internet and with that is kind of baked in some unfortunate biases, right? And so we asked ourselves the flip side of that question. Well, how is it that we can go about actually baking in some of the good bias, right? The cultural context that&#8217;s important to train these models on. And the reality is that we started off by saying, let&#8217;s just have focus groups. Let&#8217;s talk to people. But of course that takes time, it takes money, it takes effort. And what we quickly realized actually is there are literally generations of people who have done these focus groups specifically on breast and cervical cancer screening. And so what we actually have since done is leverage that real world data in order to actually start developing synthetic data sets that are …&nbsp;</p>



<p><strong>HUIZINGA:</strong> Ahhhh.&nbsp;&nbsp;</p>



<p><strong>IDRIS:</strong> … small enough but are of higher quality enough that allow us to address the specific concerns around bias that might not exist. And so for me, that&#8217;s a really like awesome thing that we came across that I think in trying to solve a problem for our kind of specific use case, I think this could actually be a method for developing more representative, context-aware, culturally sensitive models and I think overall this contributes to the overall safety and reliability of these large language models and hopefully can create a method for people to be able to do it as well.&nbsp;</p>



<p><strong>HUIZINGA:</strong> Yeah. Evelyne, I see why it&#8217;s so cool for you to be sitting at Microsoft Research and working with these guys … It&#8217;s about now that I pose the “what could possibly go wrong if you got everything right?” question on this podcast. And I&#8217;m really interested in how researchers are thinking about the potential downsides and consequences of their work. So, Evelyne, do you have any insights on things that you&#8217;ve discovered along the path that might make you take preemptive steps to mitigate?&nbsp;</p>



<p><strong>VIEGAS:</strong> Yeah, I think it&#8217;s coming back to actually what Muhammed was just talking about, I think Cesar, too, around data, the importance of data and the cultural value and the local value. I think an important piece of continuing to be positive for me [LAUGHTER] is to make sure that we fully understand that at the end of the day, data, which is so important to build those foundation models is, especially language models in particular, are just proxies to human beings. And I feel that it’s uh … we need to remember that it&#8217;s a proxy to humans and that we all have some different beliefs, values, goals, preferences. And so how do we take all that into account? And I think that beyond the data safety, provenance, I think there&#8217;s an aspect of “data caring.” I don&#8217;t know how to say it differently, [LAUGHTER] but it&#8217;s kind of in the same way that we care for people, how do we care for the data as a proxy to humans? And I&#8217;m thinking of, you know, when we talk about like in, especially in cases where there is no economic value, right? [LAUGHTER] And so, but there is local value for those communities. And I think actually there is cultural value across countries. So just wanted to say that there is also an aspect, I think we need to do more research on, as data as proxies to humans. And as complex humans we are, right?&nbsp;</p>



<p><strong>HUIZINGA:</strong> Right. Well, one of the other questions I like to ask on these Ideas episodes is, is about the idea of “blue sky” or “moonshot” research, kind of outrageous ideas. And sometimes they&#8217;re not so much outrageous as they are just living outside the box of traditional research, kind of the “what if” questions that make us excited. So just briefly, is there anything on your horizon, specifically Cesar and Muhammed, that you would say, in light of this program, AFMR, that you&#8217;ve had access to things that you think, boy, this now would enable me to ask those bigger questions or that bigger question. I don&#8217;t know what it is. Can you share anything on that line?&nbsp;</p>



<p><strong>TORRES:</strong> I guess from my end, one of the things that the AFMR program has allowed me to see is this kind of ability to better visualize the terrain of creativity. And it&#8217;s a little bit of a double-edged sword because when we talk about disrupting creativity and we think about tools, it&#8217;s typically the case that the tool is making something easier for us. But at the same time, if something&#8217;s easier, then some other thing is harder. And then we run into this really strange case where if everything is easy, then we are faced with the “blank canvas syndrome,” right? Like what do you even do if everything is just equally weighted with ease? And so my big idea is to actually think about tools that are purposely making us slower …&nbsp;</p>



<p><strong>HUIZINGA:</strong> Mmmmm …&nbsp;</p>



<p><strong>TORRES:</strong> … that have friction, that have errors, that have failures and really design how those moments can change our attitudes towards how we move around in space. To say that maybe the easiest path is not the most advantageous, but the one that you can feel the most fulfillment or agency towards. And so I really do think that this is hidden in the latent space of the data that we collect. And so we just need to be immersed in that data. We need to traverse it and really it becomes an infrastructure problem. And so the more that we expose people to these foundational models, the more that we&#8217;re going to be able to see how we can enable these new ways of walking through and exploring our environment.&nbsp;</p>



<p><strong>HUIZINGA:</strong> Yeah. I love this so much because I&#8217;ve actually been thinking some of the best experiences in our lives haven&#8217;t seemed like the best experiences when we went through them, right? The tough times are what make us grow. And this idea that AI makes everything accessible and easy and frictionless is what you&#8217;ve said. I&#8217;ve used that term too. I think of the people floating around in that movie WALL-E and all they have to do is pick whether I&#8217;m wearing red or blue today and which drink I want. I love this, Cesar. That&#8217;s something I hadn&#8217;t even expected you might say and boom, out of the park. Muhammad, do you have any sort of outrageous …? That was flipping it back!&nbsp;</p>



<p><strong>IDRIS:</strong> I was going to say, yeah, no, I listen, I don&#8217;t know how I could top that. But no, I mean, so it&#8217;s funny, Cesar, as you were mentioning that I was thinking about grad school, how at the time, it was the most, you know, friction-filled life experience. But in hindsight, I wouldn&#8217;t trade it in for the world. For me, you know, one of the things I&#8217;m often thinking about in my job is that, you know, what if we lived in a world where everyone had all the information that they needed, access to all the care they need? What would happen then? Would we magically all be the healthiest version of ourselves? I&#8217;m a little bit skeptical. I&#8217;m not going to lie, right? [LAUGHTER] But that&#8217;s something that I&#8217;m often thinking about. Now, bringing that back down to our project, one of the things that I find a little bit amusing is that I tend to ping-pong between, this is amazing, the capabilities are just, the possibilities are endless; and then there will be kind of one or two small things where it&#8217;s pretty obvious that there&#8217;s still a lot of research that needs to be done, right? So my whole, my big “what if” actually, I want to bring that back down to a kind of a technical thing which is, what if AI can truly understand culture, not just language, right? And so right now, right, an AI model can translate a public health message. It&#8217;s pretty straightforward from English to Spanish, right? But it doesn&#8217;t inherently understand why some Spanish speaking countries may be more hesitant about certain medical interventions. It doesn&#8217;t inherently appreciate the historical context that shapes that hesitancy or what kinds of messaging would build trust rather than skepticism, right? So there’s literal like cultural nuances. That to me is what, when I say culturally congruent or cultural context, what it is that I mean. And I think for me, I think what programs like AFMR have enabled us to do is really start thinking outside the box as to how will these, or how can these, emerging technologies revolutionize public health? What truly would it take for an LLM to understand context? And really, I think for the first time, we can truly, truly achieve personalized, if you want to use that term, health communication. And so that&#8217;s what I would say for me is like, what would that world look like?&nbsp;</p>



<p><strong>HUIZINGA:</strong> Yeah, the big animating “what if?” I love this. Go ahead, Evelyne, you had something. Please.&nbsp;</p>



<p><strong>VIEGAS:</strong> Can I expand? I cannot talk. I&#8217;m going to do like Muhammed, I cannot talk! Like that friction and the cultural aspect, but can I expand? And as I was listening to Cesar on the education, I think I heard you talk about the educational rite of passage at some point, and Muhammed on those cultural nuances. So first, before talking about “what if?” I want to say that there is some work, again, when we talk about AFMR, is the technology is all the brain power of people thinking, having crazy ideas, very creative in the research being done. And there is some research where people are looking at what it means, actually, when you build those language models and how you can take into account different language and different culture or different languages within the same culture or between different cultures speaking the same language, or … So there is very interesting research. And so it made me think, expanding on what Muhammed and Cesar were talking about, so this educational rite of passage, I don&#8217;t know if you&#8217;re aware, so in Europe in the 17th, 18th century, there was this grand tour of Europe and that was reserved to just some people who had the funds to do that grand tour of Europe, [LAUGHTER] let&#8217;s be clear! But it was this educational rite of passage where actually they had to physically go to different countries to actually get familiar and experience, experiment, philosophy and different types of politics, and … So that was kind of this “passage obligé” we say in French. I don&#8217;t know if there is a translation in English, but kind of this rite of passage basically. And so I am like, wow, what if actually we could have, thanks to the AI looking at different nuances of cultures, of languages … not just language, but in a multimodal point of viewpoint, what if we could have this “citizen of the world” rite of passage, where we … before we are really citizens of the world, we need to understand other cultures, at least be exposed to them. So that would be my “what if?” How do we make AI do that? And so without … and for anyone, right, not just people who can afford it.&nbsp;</p>



<p><strong>HUIZINGA:</strong> Well, I don&#8217;t even want to close, but we have to. And I&#8217;d like each of you to reflect a bit. I think I want to frame this in a way you can sort of pick what you&#8217;d like to talk about. But I often have a little bit of vision casting in this section. But there are some specific things I&#8217;d like you to talk about. What learnings can you share from your experience with AFMR? Or/and what&#8217;s something that strikes you as important now that may not have seemed that way when you started? And you can also, I&#8217;m anticipating you people are going to flip that and say, what wasn&#8217;t important that is now? And also, how do see yourself moving forward in light of this experience that you&#8217;ve had? So Muhammed, let&#8217;s go first with you, then Cesar, and then Evelyne, you can close the show.&nbsp;</p>



<p><strong>IDRIS:</strong> Awesome. One of the things that, that I&#8217;m often thinking about and one of the concepts I&#8217;m often reminded of, given the significance of the work that institutions like a Morehouse School of Medicine and UT Arlington and kind of Minority Serving Institutions, right, it almost feels like there is an onslaught of pushback to addressing some of these more systemic issues that we all struggle with, is what does it mean to strive for excellence, right? So in our tradition there&#8217;s a concept called Ihsan. Ihsan … you know there&#8217;s a lot of definitions of it but essentially to do more than just the bare minimum to truly strive for excellence and I think it was interesting, having spent time at Microsoft Research in Redmond as part of the AFMR program, meeting other folks who also participated in the program that, that I started to appreciate for myself the importance of this idea of the responsible design, development, and deployment of technologies if we truly are going to achieve the potential benefits. And I think this is one of the things that I could kind of throw out there as something to take away from this podcast, it&#8217;s really, don&#8217;t just think of what we&#8217;re developing as tools, but also think of them as how will they be applied in the real world? And when you&#8217;re thinking about the context within which something is going to be deployed, that brings up a lot of interesting constraints, opportunities, and just context that I think is important, again, to not just work on an interesting technology for the sake of an interesting technology, but to truly achieve that benefit for society.&nbsp;</p>



<p><strong>HUIZINGA:</strong> Hmm. Cesar.&nbsp;</p>



<p><strong>TORRES:</strong> I mean, echoing Muhammad, I think the community is really at the center of how we can move forward. I would say the one element that really struck a chord with me, and something that I very much undervalued, was the power of infrastructure and spending time laying down the proper scaffolds and steppingstones, not just for you to do what you&#8217;re trying to do, but to allow others to also find their own path. I was setting up Azure from one of my classes and it took time, it took effort, but the payoff has been incredible in … in so much the impact that I see now of students from my class sharing with their peers. And I think this culture of entrepreneurship really comes from taking ownership of where you&#8217;ve been and where you can go. But it really just, it all comes down to infrastructure. And so AFMR for me has been that infrastructure to kind of get my foot out the door and also have the ability to bring some folks along the journey with me, so …&nbsp;</p>



<p><strong>HUIZINGA:</strong> Yeah. Evelyne, how blessed are you to be working with people like this? Again, my face hurts from grinning so hard. Bring us home. What are your thoughts on this?&nbsp;</p>



<p><strong>VIEGAS:</strong> Yeah, so first of all, I mean, it&#8217;s so wonderful just here live, like listening to the feedback from Muhammed and Cesar of what AFMR brings and has the potential to bring. And first, let me acknowledge that to put a program like AFMR, it takes a village. So I&#8217;m here, the face here, or well, not the face, the voice rather! [LAUGHTER] But it&#8217;s so many people who have, at Microsoft on the engineering side, we&#8217;re just talking about infrastructure, Cesar was talking about, you know, the pain and gain of leveraging an industry-grade infrastructure like Azure and Azure AI services. So, also our policy teams, of course, our researchers. But above all, the external research community … so grateful to see. It’s, as you said, I feel super blessed and fortunate to be working on this program and really listening what we need to do next. How can we together do better? There is one thing for me, I want to end on the community, right? Muhammed talked about this, Cesar too, the human aspect, right? The technology is super important but also understanding the human aspect. And I will say, actually, my “curb cut moment” for me [LAUGHTER] was really working with the MSIs and the cohort, including Muhammed and Cesar, when they came to Redmond, and really understanding some of the needs which were going beyond the infrastructure, beyond you know a small network, how we can put it bigger and deployments ideas too, coming from the community and that&#8217;s something which actually we also try to bring to the whole of AFMR moving forward. And I will finish on one note, which for me is really important moving forward. We heard from Muhammed talking about the really importance of interdisciplinarity, right, and let us not work in silo. And so, and I want to see AFMR go more international, internationality if the word exists … [LAUGHTER]&nbsp;</p>



<p><strong>HUIZINGA:</strong> It does now!&nbsp;</p>



<p><strong>VIEGAS:</strong> It does now! But it&#8217;s just making sure that when we have those collaborations, it&#8217;s really hard actually, time zones, you know, practically it&#8217;s a nightmare! But I think there is definitely an opportunity here for all of us.&nbsp;</p>



<p><strong>HUIZINGA:</strong> Well, Cesar Torres, Muhammed Idris, Evelyne Viegas. This has been so fantastic. Thank you so much for coming on the show to share your insights on AFMR today.&nbsp;</p>



<p>[MUSIC PLAYS]&nbsp;</p>



<p><strong>TORRES:</strong> It was a pleasure.&nbsp;&nbsp;</p>



<p><strong>IDRIS:</strong> Thank you so much.&nbsp;</p>



<p><strong>VIEGAS:</strong> Pleasure.&nbsp;</p>

				</span>
			</div>
			<button class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle" type="button">
				Show more			</button>
		</div>
	</div>
</div>
<span class="sr-only" id="label-external-link">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/podcast/ideas-accelerating-foundation-models-research-ai-for-all/">Ideas: Accelerating Foundation Models Research: AI for all</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
<pubDate>Mon, 31 Mar 2025 13:00:00 +0000</pubDate>
</item>
<item>
<title>最新研究：个性化对话与地质图理解方法的进展</title>
<link>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-march-24-2025/</link>
<guid>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-march-24-2025/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文探讨了个性化对话系统以及地质图理解的新研究进展。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了几项最新研究，其中包括新方法SeCom，通过细分对话来提高个性化对话系统的连贯性和响应能力；此外，研究人员提出了PEACE，一种针对地质图理解的AI系统，利用新的GeoMap-Bench基准评估其效果。SeCom在LOCIMO和Long-MT-Bench+等长期对话基准测试中表现出显著优势，而PEACE则在地质图分析中提升了多模态大型语言模型的性能，同时为地质研究提供了更有效的工具。这些进展预示着AI在复杂对话和专业领域应用中的广阔前景。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-march-24-2025/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 26 Mar 2025 16:00:00 +0000</pubDate>
</item>
<item>
<title>AI在医疗中的革命：现状与未来展望</title>
<link>https://www.microsoft.com/en-us/research/podcast/the-ai-revolution-in-medicine-revisited-the-reality-of-generative-ai-in-the-clinic/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/the-ai-revolution-in-medicine-revisited-the-reality-of-generative-ai-in-the-clinic/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文探讨了生成性AI如何在医疗行业的临床设置中被应用，分析了其带来的挑战与机遇。</p><br /><br /><p><strong>摘要：</strong> 本文通过访谈医疗行业的专家，探讨了生成性AI在临床工作中的应用，包括其如何帮助医生减少文书工作，提高工作效率，并为患者提供更具同理心的回复。尽管AI在患者信息处理、医生回复和病历记录中取得了显著进展，但目前尚未显著节省时间。文章还探讨了AI在医疗中可能带来的伦理问题、信任问题以及未来的发展方向，特别是在医生是否会被AI取代的问题上，专家们表达了谨慎乐观的态度。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/podcast/the-ai-revolution-in-medicine-revisited-the-reality-of-generative-ai-in-the-clinic/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 20 Mar 2025 21:50:50 +0000</pubDate>
</item>
<item>
<title>应用超表面技术提升无线通信与室内定位精度</title>
<link>https://www.microsoft.com/en-us/research/blog/metasurface-unlocking-the-future-of-wireless-sensing-and-communication/</link>
<guid>https://www.microsoft.com/en-us/research/blog/metasurface-unlocking-the-future-of-wireless-sensing-and-communication/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">研究超表面技术改善无线通信与室内定位的多项创新应用。</p><br /><br /><p><strong>摘要：</strong> 随着无线通信对速度和可靠性的需求不断增加，传统系统面临效率与适应性限制。超表面作为一种新兴材料，能够以独特方式操控电磁波的传播，提升无线性能。我们的研究开发了适用于低地球轨道卫星通信、声学感测、室内全球导航卫星系统（GNSS）以及微波炉加热均匀性的超表面技术。通过部署多层超表面和引入新算法，我们在室内定位实验中实现了显著的精度提升。此外，我们提出的低成本被动超表面设计框架展示了在毫米波应用中的优势，有效克服了传统解决方案的缺陷。这些创新在无线通信与感测技术中展现了超表面的革命潜力，并为更智能的家电提供了应用前景。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/metasurface-unlocking-the-future-of-wireless-sensing-and-communication/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 19 Mar 2025 16:00:00 +0000</pubDate>
</item>
<item>
<title>Claimify：提升LLM生成文本的事实核查效率</title>
<link>https://www.microsoft.com/en-us/research/blog/claimify-extracting-high-quality-claims-from-language-model-outputs/</link>
<guid>https://www.microsoft.com/en-us/research/blog/claimify-extracting-high-quality-claims-from-language-model-outputs/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文介绍了Claimify，一种针对LLM生成文本的有效 claim 提取方法。</p><br /><br /><p><strong>摘要：</strong> 在本文中，我们探讨了大型语言模型（LLM）在生成文本时可能产出不准确内容的问题，并提出了Claimify这一新方法以提高事实核查的有效性。Claimify通过四个阶段的过程，实现对文本中的可核查内容进行提取，并确保每个提取的主张都能在源文本中获得充分支持，消除模糊性，并保持重要的上下文信息。通过案例研究，我们展示了Claimify在处理复杂文本时，相较于传统方法的显著优势，确立其在提高LLM生成文本质量评估中的重要作用。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/claimify-extracting-high-quality-claims-from-language-model-outputs/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 19 Mar 2025 16:00:00 +0000</pubDate>
</item>
<item>
<title>KBLaM：高效集成结构化知识的语言模型新方法</title>
<link>https://www.microsoft.com/en-us/research/blog/introducing-kblam-bringing-plug-and-play-external-knowledge-to-llms/</link>
<guid>https://www.microsoft.com/en-us/research/blog/introducing-kblam-bringing-plug-and-play-external-knowledge-to-llms/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">KBLaM提供了一种高效集成结构化知识的方法，增强语言模型的能力。</p><br /><br /><p><strong>摘要：</strong> KBLaM是一种新型方法，通过在预训练语言模型中集成结构化知识库，提升语言模型的效率与可扩展性。KBLaM生成连续的键值向量对，将知识直接嵌入模型的注意力层，消除了外部检索模块和昂贵的微调需求。与传统方法相比，KBLaM在处理大型知识库时展现出线性扩展性，支持动态更新而无需重新训练。KBLaM的矩形注意力机制使语言令牌可以关注知识令牌，从而显著降低计算成本，并提高模型的知识准确性和可靠性。这一方法不仅推动了AI与系统之间的共生发展，还为涉及医疗、金融等领域的可靠性需求提供了全新的解决方案。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/introducing-kblam-bringing-plug-and-play-external-knowledge-to-llms/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 18 Mar 2025 16:00:00 +0000</pubDate>
</item>
<item>
<title>微软研究：Copilot在必应中的应用与用户交互分析</title>
<link>https://www.microsoft.com/en-us/research/blog/semantic-telemetry-understanding-how-users-interact-with-ai-systems/</link>
<guid>https://www.microsoft.com/en-us/research/blog/semantic-telemetry-understanding-how-users-interact-with-ai-systems/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文探讨了Copilot在必应中的使用情况及用户与AI的交互分析。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了微软研究团队对Copilot在必应中使用情况的分析，重点关注用户与人工智能的交互行为。通过一种新的数据科学方法，利用大型语言模型（LLM）对聊天记录进行分类，研究团队发现78.9%的互动属于高复杂度任务，显示出用户在使用Copilot时进行较为复杂的工作，尤其是在技术领域。此外，移动用户倾向于进行个人相关的任务，而桌面用户则更多地进行专业工作。这一分析有助于深入理解AI如何提升用户体验，并为未来的研究方向提供了新的视角。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/semantic-telemetry-understanding-how-users-interact-with-ai-systems/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 16:00:00 +0000</pubDate>
</item>
<item>
<title>GPT-4在医疗领域的影响与反思</title>
<link>https://www.microsoft.com/en-us/research/podcast/the-ai-revolution-in-medicine-revisited-an-introduction/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/the-ai-revolution-in-medicine-revisited-an-introduction/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">该系列探讨了GPT-4对医疗行业的变革及其影响。</p><br /><br /><p><strong>摘要：</strong> 两年前，OpenAI的GPT-4发布掀起了AI时代的浪潮。微软研究总裁彼得·李与合作者分享了有关生成式AI如何改变医疗保健的观点。在一系列特别播客中，李将回顾其在早期的体验和对生成式AI的期望，包括对患者和医疗专业人士的影响。本次播客将深入实地访谈，探讨AI在临床中的实际应用、患者的体验以及对医疗科学发现的影响。李还将分享他对生成式AI的“九个阶段”的反思，从怀疑到接受，展示了AI如何促使医疗行业的重大变革。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/podcast/the-ai-revolution-in-medicine-revisited-an-introduction/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 14:00:00 +0000</pubDate>
</item>
<item>
<title>推进精准医学：生物医学数据生命周期的挑战与解决方案</title>
<link>https://www.microsoft.com/en-us/research/blog/advancing-biomedical-discovery-overcoming-data-challenges-in-precision-medicine/</link>
<guid>https://www.microsoft.com/en-us/research/blog/advancing-biomedical-discovery-overcoming-data-challenges-in-precision-medicine/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文探讨生物医学数据生命周期中的挑战及提升精准医学的建议。</p><br /><br /><p><strong>摘要：</strong> 现代生物医学研究亟需精准医疗以实现个性化治疗，但在原始数据到可操作见解的过程中面临诸多挑战。本研究通过与生物医学研究专家的深入访谈，识别了在数据收集、验证、分析及结果传播等各个阶段的主要痛点，诸如数据采购、计算环境的适应性和安全的数据共享问题。研究团队提出建立统一的生物医学数据生命周期，激励多学科合作，并制定可操作的建议，包括标准化分析流程、采用新兴技术（如生成性AI）等，以期改善数据共享和提升研究的效率与质量。最终，构建一个安全、可扩展的数据生态系统，将助力精准医学的未来。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/advancing-biomedical-discovery-overcoming-data-challenges-in-precision-medicine/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 17:00:00 +0000</pubDate>
</item>
<item>
<title>Magma：新一代多模态AI基础模型实现数字与物理任务融合</title>
<link>https://www.microsoft.com/en-us/research/blog/magma-a-foundation-model-for-multimodal-ai-agents-across-digital-and-physical-worlds/</link>
<guid>https://www.microsoft.com/en-us/research/blog/magma-a-foundation-model-for-multimodal-ai-agents-across-digital-and-physical-worlds/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">Magma是新型多模态AI模型，能在数字与物理环境中灵活执行任务。</p><br /><br /><p><strong>摘要：</strong> Magma是微软研究团队推出的多模态AI基础模型，旨在通过理解用户界面和物理环境操作，提升AI代理的任务执行能力。利用先进的Set-of-Mark (SoM) 和Trace-of-Mark (ToM) 注释技术，Magma能够有效识别操作中关键元素及其动态变化，确保AI系统在复杂任务中具备高效的理解和执行能力。通过在多种环境中的预训练，Magma展现出卓越的适应性和性能，能够执行数字界面导航与机器人操控等多项任务，推动了智能代理技术的进步及普及。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/magma-a-foundation-model-for-multimodal-ai-agents-across-digital-and-physical-worlds/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 19:08:21 +0000</pubDate>
</item>
<item>
<title>BioEmu-1：深度学习开启蛋白质结构预测新视野</title>
<link>https://www.microsoft.com/en-us/research/blog/exploring-the-structural-changes-driving-protein-function-with-bioemu-1/</link>
<guid>https://www.microsoft.com/en-us/research/blog/exploring-the-structural-changes-driving-protein-function-with-bioemu-1/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">BioEmu-1模型显著提升蛋白质结构预测效率，助力药物开发。</p><br /><br /><p><strong>摘要：</strong> BioEmu-1是一个深度学习模型，可以快速生成蛋白质的多种结构，基于大量数据集进行训练，提供了之前无法获得的结构信息。该模型能够在单个图形处理单元上每小时生成数千种蛋白质结构，相比传统的分子动力学模拟，效率提高了数十倍，显著降低了计算成本。BioEmu-1不仅预测了多种蛋白质的结构，还能够准确估算蛋白质的稳定性，为药物开发提供新的可能性。虽然BioEmu-1在许多方面显示出潜力，但开发团队也意识到其局限性，并期待科学家们的进一步试验与反馈，以推进模型的改进和应用。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/exploring-the-structural-changes-driving-protein-function-with-bioemu-1/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 20 Feb 2025 15:13:22 +0000</pubDate>
</item>
<item>
<title>首个世界与人类行动模型WHAM揭幕：变革游戏开发的生成AI</title>
<link>https://www.microsoft.com/en-us/research/blog/introducing-muse-our-first-generative-ai-model-designed-for-gameplay-ideation/</link>
<guid>https://www.microsoft.com/en-us/research/blog/introducing-muse-our-first-generative-ai-model-designed-for-gameplay-ideation/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本研究介绍了生成AI模型WHAM的开源发布，推动游戏创作的创新。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了首个世界与人类行动模型WHAM（命名为“Muse”），该生成AI模型能够生成游戏视觉、控制器动作及二者兼具。研究团队与Xbox游戏工作室协作开发了Muse，并将模型、权重及示例数据开放源代码，供研究人员使用。研究旨在探讨Muse等模型如何更好地支持人类创作，展示了该模型生成复杂且一致的游戏序列的能力。模型经过对“Bleeding Edge”游戏的丰富人类游戏数据进行训练，逐渐展现出在生成一致性、多样性及持久性方面的潜力，为游戏开发带来了新的创想与实践机会，推动游戏和AI研究的交叉融合。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/introducing-muse-our-first-generative-ai-model-designed-for-gameplay-ideation/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 16:05:46 +0000</pubDate>
</item>
<item>
<title>量子计算的新时代：Chetan Nayak与超导体的突破</title>
<link>https://www.microsoft.com/en-us/research/podcast/ideas-quantum-computing-redefined-with-chetan-nayak/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/ideas-quantum-computing-redefined-with-chetan-nayak/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">Chetan Nayak介绍了量子计算的发展及其在超导体领域的最新突破。</p><br /><br /><p><strong>摘要：</strong> 在本期微软研究播客中，技术研究员Chetan Nayak分享了量子计算的最新进展，特别是Microsoft量子团队在超导体方面的工作。他探讨了量子计算的重要性以及即使在生成式人工智能迅速发展的情况下，量子计算依然至关重要。Nayak描述了如何创造世界上首个拓扑超导体以及Majorana零模的概念，这种新型的量子比特（qubit）具有独特的性质，可以使量子计算机更加稳定和可扩展。此外，他还详细解释了测量拓扑量子比特的方法，并展望了量子计算的未来，认为在不久的将来将取得更大的突破。这一探索旨在推动量子计算机向更高的水平发展，帮助人们理解这个复杂的领域。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/podcast/ideas-quantum-computing-redefined-with-chetan-nayak/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 16:04:49 +0000</pubDate>
</item>
<item>
<title>利用AI提升印度教育可及性与效果</title>
<link>https://www.microsoft.com/en-us/research/blog/microsoft-research-and-physics-wallah-team-up-to-enhance-ai-based-tutoring/</link>
<guid>https://www.microsoft.com/en-us/research/blog/microsoft-research-and-physics-wallah-team-up-to-enhance-ai-based-tutoring/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文探讨了 AI 如何助力改善印度高等教育的可及性与质量。</p><br /><br /><p><strong>摘要：</strong> 在印度，有限的资源和地理限制对一些学生高质量高等教育形成了障碍。为了应对这一挑战，Physics Wallah 利用人工智能技术，提供更加精准和可靠的在线辅导服务，许多低收入学生因此受益。与微软研究的合作使其 AI 驱动的教育系统 Alakh AI 能够为学生提供个性化和适应性的指导，深化学习体验。AI Guru 和 Smart Doubt Engine 等工具不仅提高了学习效率，还解决了复杂的学术问题，满足学生对高质量教育的需求。通过这种创新方法，Physics Wallah 每天有约200万学生使用，极大地降低了教育成本，使更多学生有机会获得所需的学习支持。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/microsoft-research-and-physics-wallah-team-up-to-enhance-ai-based-tutoring/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 12 Feb 2025 21:01:07 +0000</pubDate>
</item>
<item>
<title>ExACT：提升自主AI代理的决策能力与适应性</title>
<link>https://www.microsoft.com/en-us/research/blog/exact-improving-ai-agents-decision-making-via-test-time-compute-scaling/</link>
<guid>https://www.microsoft.com/en-us/research/blog/exact-improving-ai-agents-decision-making-via-test-time-compute-scaling/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">ExACT增强了自主AI在复杂环境中的决策能力及学习效率。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了ExACT这一新方法，旨在提高自主AI代理在多步决策过程中的表现。通过结合反思性蒙特卡洛树搜索（R-MCTS）与探索学习技术，ExACT帮助AI代理在复杂的动态环境中更好地探索和决策。R-MCTS引入了对比反思和多智能体辩论功能，使代理能够从实际结果与预期结果中学习，从而优化决策。而探索学习则培养代理在评估状态、探索路径和有效回溯方面的能力。评估结果显示，基于GPT-4o的ExACT在多个任务中表现优异，超越了传统算法，展示了在实际应用中的潜力。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/exact-improving-ai-agents-decision-making-via-test-time-compute-scaling/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 11 Feb 2025 22:21:47 +0000</pubDate>
</item>
<item>
<title>探讨人工智能与真实世界挑战的应对：阿克夏·南比的研究之旅</title>
<link>https://www.microsoft.com/en-us/research/podcast/ideas-building-ai-for-population-scale-systems-with-akshay-nambi/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/ideas-building-ai-for-population-scale-systems-with-akshay-nambi/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文探讨了阿克夏·南比如何利用人工智能技术解决现实世界中的交通安全、教育等挑战。</p><br /><br /><p><strong>摘要：</strong> 在这一期的微软研究播客中，阿克夏·南比探讨了他在人工智能领域的研究，特别是如何将AI技术应用于应对现实世界中的复杂问题。南比强调，研究的核心在于创造能够大规模惠及人群的技术，以及面对复杂问题的挑战。他的研究涉及教育、农业、交通和能源等多个领域，尤其是在提升AI系统的质量与可靠性方面。南比当前正在开发一款名为Shiksha的数字助手，旨在帮助教师更高效地进行教学，同时他也在评估这一技术对驾驶行为和交通安全的长期影响。这些研究不仅推动了技术进步，还致力于确保技术在现实应用中的有效性与社会责任。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/podcast/ideas-building-ai-for-population-scale-systems-with-akshay-nambi/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 11 Feb 2025 04:26:10 +0000</pubDate>
</item>
<item>
<title>低位量化技术推动大型语言模型在边缘设备上的应用</title>
<link>https://www.microsoft.com/en-us/research/blog/advances-to-low-bit-quantization-enable-llms-on-edge-devices/</link>
<guid>https://www.microsoft.com/en-us/research/blog/advances-to-low-bit-quantization-enable-llms-on-edge-devices/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">低位量化技术促进大型语言模型高效运行于边缘设备。</p><br /><br /><p><strong>摘要：</strong> 大型语言模型（LLMs）在边缘设备上部署逐渐增加，虽然其能够支持高级AI和实时服务，但巨大的模型大小和计算需求限制了广泛应用。低位量化作为一种解决方案，通过混合精度矩阵乘法（mpGEMM）技术，优化内存和计算效率。本文提出了三种方法，包括基于查找表的T-MAC方法、Ladder数据类型编译器和针对低位量化的LUT Tensor Core硬件架构，旨在提升环境受限的边缘设备上运行LLMs的能力，现有评估表明这些方法显著提高了计算效率和运行速度。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/advances-to-low-bit-quantization-enable-llms-on-edge-devices/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 05 Feb 2025 17:32:32 +0000</pubDate>
</item>
<item>
<title>微软研究进展概览：多模态模型与新型记忆架构</title>
<link>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-january-27-2025/</link>
<guid>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-january-27-2025/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文介绍FLAVARS模型、管理保留内存及MacTel 2检测的新进展。</p><br /><br /><p><strong>摘要：</strong> 本文概述了三个重要研究进展：首先，FLAVARS是一种用于遥感的多模态基础模型，显著提升了视觉任务的性能和零-shot分类能力；其次，新的管理保留内存（MRM）架构针对AI推理工作负载进行了优化，解决了高带宽内存的不足；最后，利用自监督学习和集成模型，研究人员提高了对黄斑毛细血管扩张型2（MacTel 2）病的检测精度。这些研究为遥感、AI记忆管理以及医疗影像分析带来了新的技术方向，展现出微软在多领域的领先地位。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-january-27-2025/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 31 Jan 2025 17:17:08 +0000</pubDate>
</item>
<item>
<title>从程序员到漏洞猎人：Shan Lu的研究之旅</title>
<link>https://www.microsoft.com/en-us/research/podcast/ideas-bug-hunting-with-shan-lu/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/ideas-bug-hunting-with-shan-lu/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">Shan Lu探讨了AI与软件验证结合的潜力，推动漏洞检测技术进步。</p><br /><br /><p><strong>摘要：</strong> 在最新的Microsoft Research Podcast中，Shan Lu分享了她作为一名计算机科学教授和高级研究经理的经历。她曾在大学时面临编程挑战，但在导师的引导下，她发现自己对漏洞检测的兴趣并逐渐投身于这一领域。Lu在并发系统和复杂软件的漏洞检测方面已研究超过15年，她与合作者们结合传统程序分析和大型语言模型，探索如何提高代码的可靠性和准确性。她还谈到AI在降低编程和验证门槛方面的潜力，同时强调人类仍需在验证环节中保持参与，以确保生成内容的准确性和可信性。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/podcast/ideas-bug-hunting-with-shan-lu/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 23 Jan 2025 17:07:54 +0000</pubDate>
</item>
<item>
<title>微软研究2024年回顾与新研究进展</title>
<link>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-january-13-2025/</link>
<guid>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-january-13-2025/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">文章总结2024年微软研究的显著成就与新研究进展。</p><br /><br /><p><strong>摘要：</strong> 本文回顾了微软在2024年取得的诸多研究成果，着重介绍了在多方深度学习中的隐私增强研究、使用小型开源模型进行相关性评估的框架JudgeBlender，以及智能研发新工具RD-Agent等创新成果。同时，文章 congratulates Yasuyuki Matsushita 被评为IEEE计算机协会会士。通过这些研究，微软在材料发现、自动化评估和研发效率等领域展现了深厚的人工智能应用能力，推动了科学与技术的进步。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-january-13-2025/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 17 Jan 2025 17:37:58 +0000</pubDate>
</item>
<item>
<title>微软研究：MatterGen与MatterSim在材料科学中的创新应用</title>
<link>https://www.microsoft.com/en-us/research/podcast/ideas-ai-for-materials-discovery-with-tian-xie-and-ziheng-lu/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/ideas-ai-for-materials-discovery-with-tian-xie-and-ziheng-lu/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本期节目探索MatterGen与MatterSim如何促进材料科学的进步。</p><br /><br /><p><strong>摘要：</strong> 在微软研究播客中，专家讨论了两款用于材料发现的创新AI工具：MatterGen和MatterSim。MatterGen是一种生成材料的新方法，可以根据特定的应用需求创建新材料，而MatterSim则通过快速的计算模拟提升材料性质的测试效率。这两个工具协同作用，为材料科学家提供了开发新的能量、制造和可持续材料的可能性。播客中强调了如何将AI与实验科学相结合、面临的挑战以及这些技术在未来如何改变材料设计领域。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/podcast/ideas-ai-for-materials-discovery-with-tian-xie-and-ziheng-lu/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 16 Jan 2025 10:12:46 +0000</pubDate>
</item>
<item>
<title>MatterGen：革新材料发现的生成式AI工具</title>
<link>https://www.microsoft.com/en-us/research/blog/mattergen-a-new-paradigm-of-materials-design-with-generative-ai/</link>
<guid>https://www.microsoft.com/en-us/research/blog/mattergen-a-new-paradigm-of-materials-design-with-generative-ai/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">MatterGen通过生成新材料提升材料设计效率，超越传统筛选方法。</p><br /><br /><p><strong>摘要：</strong> MatterGen是一种基于生成式AI的工具，旨在提高材料发现的效率。传统材料发现通常依赖耗时的实验筛选，而MatterGen通过根据设计要求直接生成新材料，显著加速了这一过程。该工具利用先进的扩散模型，在3D几何结构上运行，能生成满足特定化学、机械、电子或磁性属性的新材料。通过对608,000种稳定材料的训练，MatterGen展示了在生成新奇、稳定材料方面的卓越性能，并与传统排除已知材料的筛选方法相比，能更有效地探索未知材料空间。实验验证显示，MatterGen生成的材料符合目标要求，代表了材料设计的新范式。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/mattergen-a-new-paradigm-of-materials-design-with-generative-ai/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 16 Jan 2025 10:05:45 +0000</pubDate>
</item>
<item>
<title>AutoGen v0.4发布：提升代理人工智能的框架与功能</title>
<link>https://www.microsoft.com/en-us/research/blog/autogen-v0-4-reimagining-the-foundation-of-agentic-ai-for-scale-extensibility-and-robustness/</link>
<guid>https://www.microsoft.com/en-us/research/blog/autogen-v0-4-reimagining-the-foundation-of-agentic-ai-for-scale-extensibility-and-robustness/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">AutoGen v0.4通过重新设计提升了代理人工智能的性能与灵活性。</p><br /><br /><p><strong>摘要：</strong> AutoGen v0.4发布，标志着代理人工智能和多智能体应用的重要进展。该更新对AutoGen库进行了全面重新设计，针对用户反馈解决了架构限制、效率不高和调试困难等问题。新框架具备异步消息传递、模块化可扩展性、内置观测与调试工具等多项功能，使得用户能够构建复杂的分布式智能体网络，并支持跨编程语言的互操作性。通过改进的开发工具，如AutoGen Studio，开发者可以快速原型化AI代理，进一步增强了用户体验。这一版本为未来的智能体应用和研究奠定了坚实基础。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/autogen-v0-4-reimagining-the-foundation-of-agentic-ai-for-scale-extensibility-and-robustness/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 14:33:09 +0000</pubDate>
</item>
<item>
<title>AIOpsLab：标准化云操作的评估框架</title>
<link>https://www.microsoft.com/en-us/research/blog/aiopslab-building-ai-agents-for-autonomous-clouds/</link>
<guid>https://www.microsoft.com/en-us/research/blog/aiopslab-building-ai-agents-for-autonomous-clouds/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文介绍了AIOpsLab，一个用于云操作的标准化评估框架。</p><br /><br /><p><strong>摘要：</strong> AIOpsLab是一个创新的评估框架，旨在提升云操作的可靠性与可用性。随着微服务和无服务器架构的广泛应用，企业面临着在开发与维护复杂IT应用过程中的诸多挑战。为了解决这些问题，AIOpsLab提供全面的解决方案，包括标准化的基准测试、故障生成器和观察能力，以便对AIOps代理进行设计、评估和优化。研究发现，标准化的操作任务和明确的观察能力是实现高效故障诊断和业务连续性的关键。AIOpsLab的开源特性使其能被广泛应用于研究与工程实践中，并在云计算领域中推动更高水平的自动化与效率。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/aiopslab-building-ai-agents-for-autonomous-clouds/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 20 Dec 2024 23:56:03 +0000</pubDate>
</item>
<item>
<title>生成性AI与民主：在全球选举年中的应用与挑战</title>
<link>https://www.microsoft.com/en-us/research/podcast/ideas-ai-and-democracy-with-madeleine-daepp-and-robert-osazuwa-ness/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/ideas-ai-and-democracy-with-madeleine-daepp-and-robert-osazuwa-ness/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">探讨生成性AI在2024年全球选举中的作用及其对民主的影响。</p><br /><br /><p><strong>摘要：</strong> 本期播客讨论了生成性AI在全球民主进程中的影响，尤其是在即将到来的2024年选举期间。研究人员Madeleine Daepp与Robert Osazuwa Ness分享了他们在台湾和印度开展的研究，分析了生成性AI如何被用于传播虚假信息和影响选举。尽管存在技术滥用的风险，Ness和Daepp也指出了AI可能在促进民主对话、强化公民参与及减少选民欺诈中的潜力。团队强调，理解生成性AI的应用并确保技术的安全使用是未来研究的关键，将为保护民主奠定基础。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/podcast/ideas-ai-and-democracy-with-madeleine-daepp-and-robert-osazuwa-ness/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 19 Dec 2024 20:00:00 +0000</pubDate>
</item>
<item>
<title>微软最新研究进展：硬件软件共设计与化学合成模型新框架</title>
<link>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-december-16-2024/</link>
<guid>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-december-16-2024/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">微软研究展示了CXL内存分层和化学合成预测的创新解决方案。</p><br /><br /><p><strong>摘要：</strong> 微软的研究团队最近提出了两项重要的研究成果。首先，NeoMem通过硬件/软件共设计方案，实现CXL内存系统的高效分层，采用NeoProf硬件单元监控内存访问，并通过Linux内核的策略提升了内存性能。其次，Chimera框架则专注于化学合成的逆合成预测，通过结合多种模型提高了合成路径预测的准确性。这些研究不仅推动了技术发展，还为各领域的应用提供了新思路，展示了用于优化复杂任务和提高工作效率的潜力。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-december-16-2024/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 18 Dec 2024 17:00:00 +0000</pubDate>
</item>
<item>
<title>AI与系统工程的共演：微软研究的前沿探索</title>
<link>https://www.microsoft.com/en-us/research/podcast/neurips-2024-the-co-evolution-of-ai-and-systems-with-lidong-zhou/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/neurips-2024-the-co-evolution-of-ai-and-systems-with-lidong-zhou/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文探讨微软研究在AI与系统工程协同演进方面的前沿成果与挑战。</p><br /><br /><p><strong>摘要：</strong> 在近期的微软研究播客中，微软公司副总裁Lidong Zhou探讨了人工智能(AI)与系统工程之间的共演关系。随着AI技术的快速进步，支持其发展的系统基础设施面临着诸多挑战，包括系统规模的不断扩大、全栈设计的复杂性以及创新步伐的加快。Zhou强调，AI不仅可以提升系统工程的效率和可靠性，还可以解决系统的优化和信任问题。通过合作，两者可以在多领域取得突破性进展。此外，Zhou提到未来计算机科学家的技能需求将向跨学科人才倾斜，要求学生不仅要精通AI，还要拥有人文学科的知识，以应对日益复杂的技术环境和挑战。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/podcast/neurips-2024-the-co-evolution-of-ai-and-systems-with-lidong-zhou/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 17 Dec 2024 18:59:30 +0000</pubDate>
</item>
<item>
<title>PromptWizard：提升AI提示优化效率的创新框架</title>
<link>https://www.microsoft.com/en-us/research/blog/promptwizard-the-future-of-prompt-optimization-through-feedback-driven-self-evolving-prompts/</link>
<guid>https://www.microsoft.com/en-us/research/blog/promptwizard-the-future-of-prompt-optimization-through-feedback-driven-self-evolving-prompts/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">PromptWizard是一个自动化框架，旨在提升AI模型的提示优化效率。</p><br /><br /><p><strong>摘要：</strong> 随着大型语言模型（LLMs）在各个行业的应用，提示优化成为其有效运作的关键。PromptWizard（PW）框架通过自动化和简化提示优化过程，从而加速了这一过程。PW结合了模型的反馈与高效的探索技术，持续生成和批判自身的提示和示例。其核心机制保证了优化过程的迭代性和自适应性，大幅提升了任务性能。PW已在超过45项任务中经过严格评估，明显优于当前的尖端技术，在精度、效率和适应性方面表现卓越。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/promptwizard-the-future-of-prompt-optimization-through-feedback-driven-self-evolving-prompts/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 17 Dec 2024 17:00:00 +0000</pubDate>
</item>
<item>
<title>GraphRAG 1.0发布：提高AI在复杂领域的应用</title>
<link>https://www.microsoft.com/en-us/research/blog/moving-to-graphrag-1-0-streamlining-ergonomics-for-developers-and-users/</link>
<guid>https://www.microsoft.com/en-us/research/blog/moving-to-graphrag-1-0-streamlining-ergonomics-for-developers-and-users/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">GraphRAG 1.0正式发布，带来多项用户友好和结构性改进。</p><br /><br /><p><strong>摘要：</strong> GraphRAG 1.0的发布标志着其在AI复杂领域应用的显著进步。此次更新包括极大简化的项目设置、增强的命令行接口、合并的API层、简化的数据模型与向量存储系统。特别是，通过新更新，CLI启动时间显著缩短，从148秒减少到2秒。此外，GraphRAG 1.0还实现了增量索引功能，降低了再索引的成本。虽然更新内容广泛且不具备向后兼容性，但该版本为用户和开发者提供了更流畅的体验，极大推动了GraphRAG的应用潜力。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/moving-to-graphrag-1-0-streamlining-ergonomics-for-developers-and-users/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 16 Dec 2024 17:00:00 +0000</pubDate>
</item>
<item>
<title>深度学习在科学发现中的变革性应用</title>
<link>https://www.microsoft.com/en-us/research/podcast/neurips-2024-ai-for-science-with-chris-bishop/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/neurips-2024-ai-for-science-with-chris-bishop/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">深度学习将驱动科学发现进入新范式，显著提升科学研究的效率。</p><br /><br /><p><strong>摘要：</strong> 微软研究团队在NeurIPS大会上探讨了深度学习在科学发现中的应用，特别是其如何加速药物研发和气候预报。Chris Bishop分析了科学发现的五个时代，强调深度学习可能代表着科学发现的第五个范式，即通过仿真生成训练数据，从而加速科学探索。他举例介绍了与全球健康药物发现研究所的合作，如何通过深度学习在五个月内找到抗结核和冠状病毒的候选分子，以及Project Aurora如何在气象预测领域实现传统方法难以匹敌的速度。Bishop指出，AI的应用不仅改变了科学问题的提出方式，更在全局范围内释放了更多创新机遇。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/podcast/neurips-2024-ai-for-science-with-chris-bishop/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Sat, 14 Dec 2024 01:47:28 +0000</pubDate>
</item>
<item>
<title>利用关系数据库评估大语言模型的自动验证基准 ERBench</title>
<link>https://www.microsoft.com/en-us/research/podcast/abstracts-neurips-2024-with-jindong-wang-and-steven-euijong-whang/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/abstracts-neurips-2024-with-jindong-wang-and-steven-euijong-whang/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">ERBench 是首个利用关系数据库自动评估 LLM 的基准，关注幻觉现象。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了 ERBench，一个基于实体-关系的自动可验证幻觉基准，致力于评估大语言模型（LLM）在生成信息时的可信度。研究者 Jindong Wang 和 Steven Whang 通过利用关系数据库的完整性约束，首次创建了能够自动评估模型推理的基准。该基准通过关键词来验证模型的答案正确性，并能生成复杂的多跳问题。研究发现，不同的 LLM 在回答问题的积极性和幻觉率上表现各异，而 ERBench 为 LLM 的思维过程提供了有效评估工具。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/podcast/abstracts-neurips-2024-with-jindong-wang-and-steven-euijong-whang/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 13 Dec 2024 14:30:00 +0000</pubDate>
</item>
<item>
<title>微软GenAI关于语言模型预训练的新研究成果</title>
<link>https://www.microsoft.com/en-us/research/podcast/abstracts-neurips-2024-with-weizhu-chen/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/abstracts-neurips-2024-with-weizhu-chen/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文讨论了微软GenAI在语言模型预训练中优化token使用效率的研究成果。</p><br /><br /><p><strong>摘要：</strong> 在最新一期的Microsoft Research播客中，微软GenAI副总裁Weizhu Chen介绍了一项重要研究——“并非所有token都是预训练所需的”。该研究提出通过区分有用token与“噪音”token，优化模型训练，提高token使用效率和模型性能。研究团队指出，有些token对模型预测造成混淆，建议在预训练过程中应优先关注重要token，并过滤掉那些难以预测的token。此外，该研究强调了数据的重要性，认为改进数据质量是建立更高效基础模型的关键。这项研究不仅为优化语言模型提供了新思路，还对各种应用场景带来了重大影响。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/podcast/abstracts-neurips-2024-with-weizhu-chen/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Sat, 07 Dec 2024 00:48:04 +0000</pubDate>
</item>
<item>
<title>探讨高维观察与潜在动态下的强化学习</title>
<link>https://www.microsoft.com/en-us/research/podcast/abstracts-neurips-2024-with-dylan-foster/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/abstracts-neurips-2024-with-dylan-foster/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文探讨如何利用现有强化学习算法解决高维观察问题。</p><br /><br /><p><strong>摘要：</strong> 本文由微软研究院的Dylan Foster介绍，探讨了在高维观察与潜在动态下的强化学习问题。研究的核心在于理解如何设计能够通过试错法快速学习的AI代理，以应对陌生环境。研究显示，虽然现有的强化学习算法在可观测的简单环境中表现优异，但面对高维观察时，算法的统计可处理性会下降。文章提出了需要额外假设才能克服这一限制的观点，并展示了在一定条件下，如何实现模块化的算法设计。这项研究为未来开发高效的强化学习算法指明了方向，并为研究者提供了新的探索空间。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/podcast/abstracts-neurips-2024-with-dylan-foster/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 06 Dec 2024 14:00:00 +0000</pubDate>
</item>
<item>
<title>CVQA：多语言文化视觉问答基准研究</title>
<link>https://www.microsoft.com/en-us/research/podcast/abstracts-neurips-2024-with-pranjal-chitale/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/abstracts-neurips-2024-with-pranjal-chitale/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">该研究提出CVQA基准，以提高多模态模型在文化多样性中的表现。</p><br /><br /><p><strong>摘要：</strong> 在本期播客中，微软研究院的Pranjal Chitale博士介绍了其研究成果——CVQA：文化多样性多语言视觉问答基准。该研究旨在弥补现有多模态数据在非英语语言和文化方面的缺失。CVQA涵盖30个国家、31种语言及超过10,000个具有文化背景的问题，这些问题均由本地讲者及文化专家合作编写。通过对多个前沿多模态模型的测试，研究发现，尽管商业模型表现优于开源模型，但后者在文化理解能力上明显不足。CVQA不仅提供了评估多模态模型文化意识的工具，也为未来研究提供了新的方向，倡导在人工智能领域中注重文化和语言多样性。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/podcast/abstracts-neurips-2024-with-pranjal-chitale/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 06 Dec 2024 14:00:00 +0000</pubDate>
</item>
<item>
<title>科技与经济交汇：Nicole Immorlica的研究之旅</title>
<link>https://www.microsoft.com/en-us/research/podcast/ideas-economics-and-computation-with-nicole-immorlica/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/ideas-economics-and-computation-with-nicole-immorlica/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">Nicole Immorlica探讨如何将计算机科学应用于经济学，以推动社会进步。</p><br /><br /><p><strong>摘要：</strong> 在这一期的Microsoft Research Podcast中，主持人Gretchen Huizinga采访了Senior Principal Research Manager Nicole Immorlica，讨论她如何通过计算机科学推动经济学的边界。Immorlica分享了她的研究历程，强调了理论在数据驱动研究中的重要性，认为理论为我们提供了洞察未来可能性的能力。她的成就包括对经典经济问题，如定价和稳定婚姻问题的贡献，使她获得了多个荣誉，包括ACM Fellow和Test of Time Award。此外，Immorlica还探讨了生成式AI对内容生态系统的影响，特别是内容创作者在新市场环境下面临的挑战。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/podcast/ideas-economics-and-computation-with-nicole-immorlica/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 05 Dec 2024 15:26:25 +0000</pubDate>
</item>
<item>
<title>微软研究亮点：多项新成果与技术进展</title>
<link>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-december-2-2024/</link>
<guid>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-december-2-2024/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">微软研究团队发布多项创新成果，涵盖安全协议和算法交易等领域。</p><br /><br /><p><strong>摘要：</strong> 微软研究系列文章介绍了几项重要的研究进展，包括适应性安全与通信本地多方计算（MPC）的新协议、云端金融交易的公平执行环境Cuttlefish，以及增强多模态表示学习的LLM2CLIP框架。此外，针对大型模型的低秩适应技术LORASC也被提出，以提高模型的表达能力和泛化能力。这些研究成果展示了微软在前沿技术领域的不断探索与创新，尤其在数据隐私、金融科技和人工智能模型的融合方面，展现出广泛的应用前景。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-december-2-2024/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 17:07:27 +0000</pubDate>
</item>
<item>
<title>微软研究在金融市场应用生成模型的最新进展</title>
<link>https://www.microsoft.com/en-us/research/blog/mars-a-unified-financial-market-simulation-engine-in-the-era-of-generative-foundation-models/</link>
<guid>https://www.microsoft.com/en-us/research/blog/mars-a-unified-financial-market-simulation-engine-in-the-era-of-generative-foundation-models/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">文章探讨了微软研究如何将生成模型应用于金融市场，提高效率与洞察力。</p><br /><br /><p><strong>摘要：</strong> 微软研究运用生成基础模型，结合域特定数据，推动金融市场的内容生成与应用，开发了大型市场模型（LMM）及金融市场仿真引擎（MarS）。这两者的结合，为金融研究人员提供了定制生成模型的能力，有助于更高效地执行预测、风险评估和交易策略优化等任务。文章详细阐述了这些模型如何利用精细的订单流数据，在捕捉市场动态的同时提供更准确的市场洞察，并讨论了在当前金融环境中，新技术如何帮助理解市场运行及增强监管能力。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/mars-a-unified-financial-market-simulation-engine-in-the-era-of-generative-foundation-models/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 17:01:25 +0000</pubDate>
</item>
<item>
<title>开创性语言模型在专业领域的性能提升</title>
<link>https://www.microsoft.com/en-us/research/blog/advances-in-run-time-strategies-for-next-generation-foundation-models/</link>
<guid>https://www.microsoft.com/en-us/research/blog/advances-in-run-time-strategies-for-next-generation-foundation-models/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">探讨o1-preview模型在医学考试中的出色表现及其背后的推理策略。</p><br /><br /><p><strong>摘要：</strong> 本文探讨了开创性语言模型o1-preview在医学考试中的表现，尤其是在MedQA基准测试中取得的96%准确率，超越了以往的Medprompt和GPT-4。文章分析了o1-preview的训练方法与推理策略，强调其在专业领域中的有效性。通过对比不同的提示方法，结果显示，个性化提示和集成是提升模型可靠性的有效策略。此外，研究指出了现有医学基准的饱和现象以及AI在临床应用中的复杂性，呼吁开发更具挑战性的基准测试和临床试验，以更深入地评估AI在医疗中的潜力和应用。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/advances-in-run-time-strategies-for-next-generation-foundation-models/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 27 Nov 2024 14:00:00 +0000</pubDate>
</item>
<item>
<title>TamGen：基于生成性AI的抗结核药物发现新方法</title>
<link>https://www.microsoft.com/en-us/research/blog/accelerating-drug-discovery-with-tamgen-a-generative-ai-approach-to-target-aware-molecule-generation/</link>
<guid>https://www.microsoft.com/en-us/research/blog/accelerating-drug-discovery-with-tamgen-a-generative-ai-approach-to-target-aware-molecule-generation/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">TamGen利用生成性AI推动抗结核药物的研发，取得显著成果。</p><br /><br /><p><strong>摘要：</strong> TamGen是由GHDDI与微软研究院联合开发的一种生成性AI工具，专注于抗结核药物的发现。该模型能够设计针对特定靶点的化合物，并在与实验室验证相结合的过程中，成功识别出多种有希望的结核蛋白酶抑制剂。研究结果表明，TamGen不仅能够生成新化合物，还能通过设计特定的分子片段优化现有候选药物，从而提高药物研发的效率。实验室测试显示，多达14种新化合物在抑制结核蛋白酶活性方面表现出色，展现了巨大的应用潜力。这项研究彰显了生成性AI在药物研发中所具有的变革潜力，预示着有效治疗耐药性传染病的新机遇。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/accelerating-drug-discovery-with-tamgen-a-generative-ai-approach-to-target-aware-molecule-generation/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 25 Nov 2024 21:02:26 +0000</pubDate>
</item>
<item>
<title>LazyGraphRAG：新一代图形增强检索机制</title>
<link>https://www.microsoft.com/en-us/research/blog/lazygraphrag-setting-a-new-standard-for-quality-and-cost/</link>
<guid>https://www.microsoft.com/en-us/research/blog/lazygraphrag-setting-a-new-standard-for-quality-and-cost/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">LazyGraphRAG通过无需预先总结，有效提升图形增强检索的性价比。</p><br /><br /><p><strong>摘要：</strong> LazyGraphRAG是一种新型的图形增强检索机制，旨在通过利用非结构化文本中的隐含关系，扩展AI系统对私有数据集的查询能力。与传统的向量RAG相比，LazyGraphRAG不仅具有较低的数据索引成本，而且在本地与全局查询中都表现出优越的性价比。具体来说，LazyGraphRAG在查询质量上与GraphRAG全球搜索相当，同时其查询成本却低于GraphRAG的700倍。LazyGraphRAG通过灵活的查询机制，能够在不同的相关性测试预算下实现高效的答案生成，适用于一次性查询、探索性分析和流数据使用场景。此外，LazyGraphRAG还将很快在开源平台上发布，进一步推动此技术的普及与应用。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/lazygraphrag-setting-a-new-standard-for-quality-and-cost/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 25 Nov 2024 17:00:00 +0000</pubDate>
</item>
<item>
<title>DNA数据存储：将科幻变为现实的研究进展</title>
<link>https://www.microsoft.com/en-us/research/podcast/ideas-the-journey-to-dna-data-storage/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/ideas-the-journey-to-dna-data-storage/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">探讨了微软研究团队在DNA数据存储领域的创新与进展。</p><br /><br /><p><strong>摘要：</strong> 微软研究团队的DNA数据存储项目致力于通过合成DNA来应对日益增长的数字数据存储需求，提供一种更可持续的备选方案。在最新的播客中，项目核心成员讨论了如何融合生命科学、工程学和计算机科学等多个领域的专长，以实现科学幻想中的技术。团队通过建立DNA数据存储联盟、开发先进的编码与解码算法以及开源错误纠正工具，推动了这一创新技术的实用化。该项目不仅开创了新型存储介质的未来，还通过生命周期评估发现其在减少碳排放和能源消耗方面的潜力，突显了其可持续性优势。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/podcast/ideas-the-journey-to-dna-data-storage/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 19 Nov 2024 14:00:00 +0000</pubDate>
</item>
<item>
<title>微软在东京开设新研究实验室聚焦AI领域</title>
<link>https://www.microsoft.com/en-us/research/blog/introducing-yasuyuki-matsushita-tackling-societal-challenges-with-ai-at-microsoft-research-asia-tokyo/</link>
<guid>https://www.microsoft.com/en-us/research/blog/introducing-yasuyuki-matsushita-tackling-societal-challenges-with-ai-at-microsoft-research-asia-tokyo/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">微软在东京设立新实验室，专注于AI和社会创新研究。</p><br /><br /><p><strong>摘要：</strong> 微软研究在东京新建实验室，聚焦身体智能、神经科学等领域，推动与日本本地学术和工业合作。实验室负责人松下康之分享了他重返微软的动机及对科技演变的看法，强调科技研究需关注社会问题，如日本老龄化带来的挑战。东京实验室将通过开放研究和与其他领域合作，培养下一代科技创新人才，推动社会进步与产业发展。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/introducing-yasuyuki-matsushita-tackling-societal-challenges-with-ai-at-microsoft-research-asia-tokyo/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 16:00:00 +0000</pubDate>
</item>
<item>
<title>BiomedParse：医学图像分析的新范式</title>
<link>https://www.microsoft.com/en-us/research/blog/biomedparse-a-foundation-model-for-smarter-all-in-one-biomedical-image-analysis/</link>
<guid>https://www.microsoft.com/en-us/research/blog/biomedparse-a-foundation-model-for-smarter-all-in-one-biomedical-image-analysis/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">BiomedParse通过统一的图像分析框架，提升医学图像的分析效率。</p><br /><br /><p><strong>摘要：</strong> BiomedParse是一种新颖的医学图像分析工具，通过将对象识别、检测和分割统一在一个框架中，促进更加全面和智慧的分析。该模型利用自然语言提示，简化了用户的输入过程，显著降低了对特定边界框的需求。此外，BiomedParse的预训练数据集源于OpenAI的GPT-4，整合了来自45个生物医学分割数据集的描述信息。通过在64种主要生物医学对象类型与9种成像模态上的广泛评估，BiomedParse在精确性和效率上都超过了以往的最佳方法，为生物医学图像分析的未来提供了新的可能性。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/biomedparse-a-foundation-model-for-smarter-all-in-one-biomedical-image-analysis/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 10:14:40 +0000</pubDate>
</item>
<item>
<title>动态全局搜索在图形增强生成中的应用</title>
<link>https://www.microsoft.com/en-us/research/blog/graphrag-improving-global-search-via-dynamic-community-selection/</link>
<guid>https://www.microsoft.com/en-us/research/blog/graphrag-improving-global-search-via-dynamic-community-selection/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文介绍了如何通过动态社区选择优化全局搜索的效果。</p><br /><br /><p><strong>摘要：</strong> 动态全局搜索方法在图形增强生成（GraphRAG）中引入了动态社区选择，通过对知识图谱结构的利用，提升了获取用户查询相关信息的效率。传统方法局限于静态搜索，常常会误检大量无关的社区报告，而动态选择则通过评估社区报告的相关性，提前剔除无关信息，从而有效降低了处理成本。实验表明，动态搜索在保持输出质量的同时，减少了近77%的总token成本，并在一些特定病例中提升了响应的细致程度和全面性。该文的实验基于AP新闻数据集，验证了动态搜索相较于静态搜索的显著优势，为未来的图形增强生成优化提供了新思路。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/graphrag-improving-global-search-via-dynamic-community-selection/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 15 Nov 2024 16:52:47 +0000</pubDate>
</item>
<item>
<title>AgentInstruct：提高小型语言模型性能的新路径</title>
<link>https://www.microsoft.com/en-us/research/blog/orca-agentinstruct-agentic-flows-can-be-effective-synthetic-data-generators/</link>
<guid>https://www.microsoft.com/en-us/research/blog/orca-agentinstruct-agentic-flows-can-be-effective-synthetic-data-generators/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文探讨了如何通过AgentInstruct生成合成数据，提升小型语言模型的性能。</p><br /><br /><p><strong>摘要：</strong> 本研究展示了如何使用合成数据对小型语言模型进行后训练，以达到以前只有大型模型才能实现的性能。通过AgentInstruct，我们采用了一种代理框架自动生成高质量、具有多样性的合成数据。这种方法有效提升了Mistral 7B模型的性能，且在多个基准测试中展现出显著的改进，例如AGIEval提高了40%。此外，文章还公开了一个包含100万对数据的小型数据集，以此促进合成数据生成及语言模型微调的研究。我们展望代理流将在模型训练生命周期中发挥越来越重要的作用，助力构建一个合成数据工厂，从而推动各行业的AI进步。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/orca-agentinstruct-agentic-flows-can-be-effective-synthetic-data-generators/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 14 Nov 2024 17:00:00 +0000</pubDate>
</item>
<item>
<title>AI2BMD：利用人工智能推动生物大分子动态模拟的突破</title>
<link>https://www.microsoft.com/en-us/research/podcast/abstracts-november-14-2024/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/abstracts-november-14-2024/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">介绍AI2BMD系统及其在生物大分子模拟中的应用和意义。</p><br /><br /><p><strong>摘要：</strong> 本文讨论了Microsoft研究团队开发的AI2BMD系统，该系统利用人工智能技术，显著提升了对生物大分子动态行为的模拟能力。AI2BMD可以广泛适用于多种蛋白质，并在药物发现、蛋白质设计和酶工程等领域展现出巨大的潜力。研究表明，此系统通过一种通用的蛋白质碎片化方法和图神经网络模型ViSNet，达成了比经典和量子分子动力学模拟更高的准确度和效率。该技术的进步，不仅为生物学研究提供了一种全新的工具，也预示着AI在复杂生物体系研究中的广泛应用前景，将推动科学研究进入一个新的时代。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/podcast/abstracts-november-14-2024/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 14 Nov 2024 15:00:00 +0000</pubDate>
</item>
<item>
<title>模块化人工智能模型的发展与优势</title>
<link>https://www.microsoft.com/en-us/research/blog/toward-modular-models-collaborative-ai-development-enables-model-accountability-and-continuous-learning/</link>
<guid>https://www.microsoft.com/en-us/research/blog/toward-modular-models-collaborative-ai-development-enables-model-accountability-and-continuous-learning/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文探讨模块化人工智能模型的优势及其在AI发展中的应用。</p><br /><br /><p><strong>摘要：</strong> 文章讨论了模块化人工智能模型在当前AI发展中的重要性，强调通过模块化设计可以提升模型的灵活性、适应性与透明度。研究团队关注于优化专家模型的训练与协调，提出了MoErging方法，旨在通过分布式开发的专家模型来解决更广泛的任务。调查对29种MoErging方法进行了分类，探讨了不同设计选择的影响，并指出模块化模型能促进隐私保护、提升模型透明度、支持针对个体需求的个人化服务。尽管模块化方法在AI发展中具有潜在的优势，基础模型的开发仍需大量的计算资源，因此研究者们期待未来在构建更高效模型方面的进一步突破。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/toward-modular-models-collaborative-ai-development-enables-model-accountability-and-continuous-learning/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 13 Nov 2024 17:30:00 +0000</pubDate>
</item>
<item>
<title>微软研究重点：前沿技术与AI驱动的编程创新</title>
<link>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-november-11-2024/</link>
<guid>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-november-11-2024/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">微软最新研究聚焦运动捕捉、AI自主云与证明导向编程等领域。</p><br /><br /><p><strong>摘要：</strong> 微软研究团队近日发表多项研究，涵盖运动捕捉、人工智能驱动的自主云服务以及证明导向编程等前沿技术。在运动捕捉领域，研究者提出了一种无标记高质量人类身体重建技术，能够稳定生成世界空间结果，并支持多种捕捉环境。而在自主云服务中，研究团队构建了一个帮助实现自我修复云的框架，旨在减少人工干预。在证明导向编程方面，研究人员探索了利用AI生成具有机器验证的程序及证明，展现出AI在编程领域的新潜力。这些研究成果不仅解决了现有技术的挑战，还提供了未来发展方向的基础。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-november-11-2024/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 13 Nov 2024 17:00:00 +0000</pubDate>
</item>
<item>
<title>云计算中的微架构隔离与侧信道攻击防护</title>
<link>https://www.microsoft.com/en-us/research/blog/preventing-side-channels-in-the-cloud/</link>
<guid>https://www.microsoft.com/en-us/research/blog/preventing-side-channels-in-the-cloud/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">探讨在云计算中防止微架构侧信道攻击的有效隔离技术。</p><br /><br /><p><strong>摘要：</strong> 文章分析了云计算环境中的安全隐患，尤其是微架构侧信道攻击。尽管有完善的体系架构隔离，仍然可能因共享微架构资源（如CPU缓存和DRAM）而导致信息泄露。为此， Microsoft Azure针对这类攻击采取了多种措施，包括核心调度和微架构清洗等。同时，研究小组提出了一种新的资源专属域设计，通过扩展私有物理线程和内存的架构抽象，确保即使在强大攻击者的情况下也能实现隔离。此外，文中介绍了与CPU厂商合作的未来微架构隔离方案，以继续提升云服务的安全性和性能。这些防护措施不仅能有效抵御当前已知的侧信道攻击，还能迎接未来可能出现的新型攻击。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/preventing-side-channels-in-the-cloud/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 17:00:00 +0000</pubDate>
</item>
<item>
<title>探讨生成式AI与提示工程的未来</title>
<link>https://www.microsoft.com/en-us/research/podcast/collaborators-prompt-engineering-with-siddharth-suri-and-david-holtz/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/collaborators-prompt-engineering-with-siddharth-suri-and-david-holtz/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文探讨生成式AI的发展及其与提示工程的密切关系。</p><br /><br /><p><strong>摘要：</strong> 本文深入探讨了生成式AI的迅猛发展及其在提示工程中的重要性。文章中的两位研究者分享了他们的研究经历和对提示工程的见解，强调了随着AI模型的进步，提示工程的重要性也在不断演变。他们通过实验发现，用户对于新模型（如DALL-E 3）的理解和互动方式比旧模型（如DALL-E 2）更为有效，且即使在缺乏指导的情况下，用户也能逐渐掌握如何更好地提示AI生成所需内容。研究指出，尽管提示工程并不需要高深的技术知识，但随着模型的进步，用户在使用时仍需不断更新和优化提示，以充分发挥新模型的潜力。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/podcast/collaborators-prompt-engineering-with-siddharth-suri-and-david-holtz/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 11 Nov 2024 14:30:00 +0000</pubDate>
</item>
<item>
<title>AI2BMD：开创生物分子动力学模拟的全新精准时代</title>
<link>https://www.microsoft.com/en-us/research/blog/from-static-prediction-to-dynamic-characterization-ai2bmd-advances-protein-dynamics-with-ab-initio-accuracy/</link>
<guid>https://www.microsoft.com/en-us/research/blog/from-static-prediction-to-dynamic-characterization-ai2bmd-advances-protein-dynamics-with-ab-initio-accuracy/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">AI2BMD通过AI技术实现了生物分子动力学的高精度模拟。</p><br /><br /><p><strong>摘要：</strong> AI2BMD（基于AI的从头生物分子动力学系统）代表了生物分子动力学模拟领域的重大突破。它通过创新的蛋白质碎片化方法和机器学习技术，实现了超过10,000个原子的全原子模拟精度，从而在计算效率和准确性之间达成了前所未有的平衡。AI2BMD不仅能够高效模拟多种生物分子的动态行为，还具有更好的与实验数据的一致性，为理解复杂的生物过程，如药物-靶标相互作用，提供了新的视角。此外，AI2BMD在药物发现领域展现出强大潜力，已经在2023年成功预测了与新冠病毒主要蛋白酶结合的化学化合物，展示了其在加速真实世界药物发现中的重要性。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/from-static-prediction-to-dynamic-characterization-ai2bmd-advances-protein-dynamics-with-ab-initio-accuracy/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 06 Nov 2024 16:03:37 +0000</pubDate>
</item>
<item>
<title>Abstracts: November 5, 2024</title>
<link>https://www.microsoft.com/en-us/research/podcast/abstracts-november-5-2024/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/abstracts-november-5-2024/</guid>
<content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img alt="Outlined illustrations of Chris Hawblitzel and Jay Lorch for the Microsoft Research Podcast, Abstracts series." class="wp-image-1099833" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/11/Chris-and-Jay_Abstracts_Hero_Feature_No_Text_1400x788.jpg" width="1400" /></figure>


<div class="wp-block-msr-podcast-container my-4">
	
</div>



<p>Members of the research community at Microsoft work continuously to advance their respective fields. <em>Abstracts</em> brings its audience to the cutting edge with them through short, compelling conversations about new and noteworthy achievements. </p>



<p>In this episode, Microsoft senior principal researchers <a href="https://www.microsoft.com/en-us/research/people/chrishaw/">Chris Hawblitzel</a> and <a href="https://www.microsoft.com/en-us/research/people/lorch/">Jay Lorch</a> join host Amber Tingle to discuss <a href="https://www.microsoft.com/en-us/research/publication/verus-a-practical-foundation-for-systems-verification/">“Verus: A Practical Foundation for Systems Verification,”</a> which received the Distinguished Artifact Award at this year’s Symposium on Operating Systems Principles, or SOSP. In their research, Hawblitzel, Lorch, and their coauthors leverage advances in programming languages and formal verification with two aims. The first aim is to help make software verification more accessible for systems developers so they can demonstrate their code will behave as intended. The second aim is to provide the research community with sound groundwork to tackle the application of formal verification to large, complex systems. </p>



<div class="wp-block-buttons is-layout-flex wp-block-buttons-is-layout-flex">
<div class="wp-block-button"><a class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/verus-a-practical-foundation-for-systems-verification/">Read the paper</a></div>
</div>



<section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast">
	<div class="subscribe-to-podcast__inner border-top border-bottom border-width-2">
		<h2 class="h5 subscribe-to-podcast__heading">
			Subscribe to the <a href="https://www.microsoft.com/en-us/research/podcast">Microsoft Research Podcast</a>:		</h2>
		<ul class="subscribe-to-podcast__list list-unstyled">
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://itunes.apple.com/us/podcast/microsoft-research-a-podcast/id1318021537?mt=2" rel="noreferrer noopener" target="_blank">
						<svg class="subscribe-to-podcast__svg" fill="black" viewBox="0 0 32 32" xmlns="http://www.w3.org/2000/svg">  <path d="M7.12 0c-3.937-0.011-7.131 3.183-7.12 7.12v17.76c-0.011 3.937 3.183 7.131 7.12 7.12h17.76c3.937 0.011 7.131-3.183 7.12-7.12v-17.76c0.011-3.937-3.183-7.131-7.12-7.12zM15.817 3.421c3.115 0 5.932 1.204 8.079 3.453 1.631 1.693 2.547 3.489 3.016 5.855 0.161 0.787 0.161 2.932 0.009 3.817-0.5 2.817-2.041 5.339-4.317 7.063-0.812 0.615-2.797 1.683-3.115 1.683-0.12 0-0.129-0.12-0.077-0.615 0.099-0.792 0.192-0.953 0.64-1.141 0.713-0.296 1.932-1.167 2.677-1.911 1.301-1.303 2.229-2.932 2.677-4.719 0.281-1.1 0.244-3.543-0.063-4.672-0.969-3.595-3.907-6.385-7.5-7.136-1.041-0.213-2.943-0.213-4 0-3.636 0.751-6.647 3.683-7.563 7.371-0.245 1.004-0.245 3.448 0 4.448 0.609 2.443 2.188 4.681 4.255 6.015 0.407 0.271 0.896 0.547 1.1 0.631 0.447 0.192 0.547 0.355 0.629 1.14 0.052 0.485 0.041 0.62-0.072 0.62-0.073 0-0.62-0.235-1.199-0.511l-0.052-0.041c-3.297-1.62-5.407-4.364-6.177-8.016-0.187-0.943-0.224-3.187-0.036-4.052 0.479-2.323 1.396-4.135 2.921-5.739 2.199-2.319 5.027-3.543 8.172-3.543zM16 7.172c0.541 0.005 1.068 0.052 1.473 0.14 3.715 0.828 6.344 4.543 5.833 8.229-0.203 1.489-0.713 2.709-1.619 3.844-0.448 0.573-1.537 1.532-1.729 1.532-0.032 0-0.063-0.365-0.063-0.803v-0.808l0.552-0.661c2.093-2.505 1.943-6.005-0.339-8.296-0.885-0.896-1.912-1.423-3.235-1.661-0.853-0.161-1.031-0.161-1.927-0.011-1.364 0.219-2.417 0.744-3.355 1.672-2.291 2.271-2.443 5.791-0.348 8.296l0.552 0.661v0.813c0 0.448-0.037 0.807-0.084 0.807-0.036 0-0.349-0.213-0.683-0.479l-0.047-0.016c-1.109-0.885-2.088-2.453-2.495-3.995-0.244-0.932-0.244-2.697 0.011-3.625 0.672-2.505 2.521-4.448 5.079-5.359 0.547-0.193 1.509-0.297 2.416-0.281zM15.823 11.156c0.417 0 0.828 0.084 1.131 0.24 0.645 0.339 1.183 0.989 1.385 1.677 0.62 2.104-1.609 3.948-3.631 3.005h-0.015c-0.953-0.443-1.464-1.276-1.475-2.36 0-0.979 0.541-1.828 1.484-2.328 0.297-0.156 0.709-0.235 1.125-0.235zM15.812 17.464c1.319-0.005 2.271 0.463 2.625 1.291 0.265 0.62 0.167 2.573-0.292 5.735-0.307 2.208-0.479 2.765-0.905 3.141-0.589 0.52-1.417 0.667-2.209 0.385h-0.004c-0.953-0.344-1.157-0.808-1.553-3.527-0.452-3.161-0.552-5.115-0.285-5.735 0.348-0.823 1.296-1.285 2.624-1.291z"></svg>
						<span class="subscribe-to-podcast__link-text">Apple Podcasts</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://subscribebyemail.com/www.blubrry.com/feeds/microsoftresearch.xml" rel="noreferrer noopener" target="_blank">
						<svg class="subscribe-to-podcast__svg" fill="none" viewBox="0 0 32 32" xmlns="http://www.w3.org/2000/svg"><path d="M6.4 6a2.392 2.392 0 00-2.372 2.119L16 15.6l11.972-7.481A2.392 2.392 0 0025.6 6H6.4zM4 10.502V22.8a2.4 2.4 0 002.4 2.4h19.2a2.4 2.4 0 002.4-2.4V10.502l-11.365 7.102a1.2 1.2 0 01-1.27 0L4 10.502z" fill="currentColor"></svg>
						<span class="subscribe-to-podcast__link-text">Email</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://subscribeonandroid.com/www.blubrry.com/feeds/microsoftresearch.xml" rel="noreferrer noopener" target="_blank">
						<svg class="subscribe-to-podcast__svg" fill="none" viewBox="0 0 32 32" xmlns="http://www.w3.org/2000/svg"><path d="M12.414 4.02c-.062.012-.126.023-.18.06a.489.489 0 00-.12.675L13.149 6.3c-1.6.847-2.792 2.255-3.18 3.944h13.257c-.388-1.69-1.58-3.097-3.179-3.944l1.035-1.545a.489.489 0 00-.12-.675.492.492 0 00-.675.135l-1.14 1.68a7.423 7.423 0 00-2.55-.45c-.899 0-1.758.161-2.549.45l-1.14-1.68a.482.482 0 00-.494-.195zm1.545 3.824a.72.72 0 110 1.44.72.72 0 010-1.44zm5.278 0a.719.719 0 110 1.44.719.719 0 110-1.44zM8.44 11.204A1.44 1.44 0 007 12.644v6.718c0 .795.645 1.44 1.44 1.44.168 0 .33-.036.48-.09v-9.418a1.406 1.406 0 00-.48-.09zm1.44 0V21.76c0 .793.646 1.44 1.44 1.44h10.557c.793 0 1.44-.647 1.44-1.44V11.204H9.878zm14.876 0c-.169 0-.33.035-.48.09v9.418c.15.052.311.09.48.09a1.44 1.44 0 001.44-1.44v-6.719a1.44 1.44 0 00-1.44-1.44zM11.8 24.16v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84zm5.759 0v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84z" fill="currentColor"></svg>
						<span class="subscribe-to-podcast__link-text">Android</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://open.spotify.com/show/4ndjUXyL0hH1FXHgwIiTWU" rel="noreferrer noopener" target="_blank">
						<svg class="subscribe-to-podcast__svg" fill="none" viewBox="0 0 32 32" xmlns="http://www.w3.org/2000/svg"><path d="M16 4C9.383 4 4 9.383 4 16s5.383 12 12 12 12-5.383 12-12S22.617 4 16 4zm5.08 17.394a.781.781 0 01-1.086.217c-1.29-.86-3.477-1.434-5.303-1.434-1.937.002-3.389.477-3.403.482a.782.782 0 11-.494-1.484c.068-.023 1.71-.56 3.897-.562 1.826 0 4.365.492 6.171 1.696.36.24.457.725.217 1.085zm1.56-3.202a.895.895 0 01-1.234.286c-2.338-1.457-4.742-1.766-6.812-1.747-2.338.02-4.207.466-4.239.476a.895.895 0 11-.488-1.723c.145-.041 2.01-.5 4.564-.521 2.329-.02 5.23.318 7.923 1.995.419.26.547.814.286 1.234zm1.556-3.745a1.043 1.043 0 01-1.428.371c-2.725-1.6-6.039-1.94-8.339-1.942h-.033c-2.781 0-4.923.489-4.944.494a1.044 1.044 0 01-.474-2.031c.096-.023 2.385-.55 5.418-.55h.036c2.558.004 6.264.393 9.393 2.23.497.292.663.931.371 1.428z" fill="currentColor"></svg>
						<span class="subscribe-to-podcast__link-text">Spotify</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://www.blubrry.com/feeds/microsoftresearch.xml" rel="noreferrer noopener" target="_blank">
						<svg class="subscribe-to-podcast__svg" fill="none" viewBox="0 0 32 32" xmlns="http://www.w3.org/2000/svg"><path d="M6.667 4a2.676 2.676 0 00-2.612 2.13v.003c-.036.172-.055.35-.055.534v18.666c0 .183.019.362.055.534v.003a2.676 2.676 0 002.076 2.075h.002c.172.036.35.055.534.055h18.666A2.676 2.676 0 0028 25.333V6.667a2.676 2.676 0 00-2.13-2.612h-.003A2.623 2.623 0 0025.333 4H6.667zM8 8h1.333C17.42 8 24 14.58 24 22.667V24h-2.667v-1.333c0-6.618-5.382-12-12-12H8V8zm0 5.333h1.333c5.146 0 9.334 4.188 9.334 9.334V24H16v-1.333A6.674 6.674 0 009.333 16H8v-2.667zM10 20a2 2 0 11-.001 4.001A2 2 0 0110 20z" fill="currentColor"></svg>
						<span class="subscribe-to-podcast__link-text">RSS Feed</span>
					</a>
				</li>
					</ul>
	</div>
</section>


<div class="wp-block-msr-show-more">
	<div class="bg-neutral-100 p-5">
		<div class="show-more-show-less">
			<div>
				<span>
					

<h2 class="wp-block-heading" id="transcript">Transcript&nbsp;</h2>



<p>[MUSIC]&nbsp;</p>



<p><strong>AMBER TINGLE: </strong>Welcome to <em>Abstracts</em>, a Microsoft Research Podcast that puts the spotlight on world-class research <em>in brief</em>. I’m Amber Tingle. In this series, members of the research community at Microsoft give us a quick snapshot—or a <em>podcast abstract</em>—of their new and noteworthy papers.&nbsp;</p>



<p>[MUSIC FADES]&nbsp;</p>



<p>Our guests today are Chris Hawblitzel and Jay Lorch. They are both senior principal researchers at Microsoft and two of the coauthors on a paper called “Verus: A Practical Foundation for Systems Verification.” This work received the Distinguished Artifact Award at the 30th Symposium on Operating Systems Principles, also known as <em>SOSP</em>, which is happening right now in Austin, Texas. Chris and Jay, thank you for joining us today for <em>Abstracts</em> and congratulations!</p>



<p><strong>JAY LORCH: </strong>Thank you for having us.&nbsp;</p>



<p><strong>CHRIS HAWBLITZEL: </strong>Glad to be here.&nbsp;</p>



<p><strong>TINGLE: </strong>Chris, let&#8217;s start with an overview. What problem does this research address, and why is Verus something that the broader research community should know about?&nbsp;</p>



				</span>
				<span class="show-more-show-less-toggleable-content" id="show-more-show-less-toggle-1">
					



<p><strong>HAWBLITZEL: </strong>So what we&#8217;re trying to address is a very simple problem where we&#8217;re trying to help developers write software that doesn&#8217;t have bugs in it. And we&#8217;re trying to provide a tool with Verus that will help developers show that their code actually behaves the way it&#8217;s supposed to; it obeys some sort of specification for what the program is supposed to do.&nbsp;</p>



<p><strong>TINGLE: </strong>How does this publication build on or differ from other research in this field, including your previous Verus-related work?&nbsp;</p>



<p><strong>HAWBLITZEL: </strong>So formal verification is a process where you write down what it is that you want your program to do in mathematical terms. So if you&#8217;re writing an algorithm to sort a list, for example, you might say that the output of this algorithm should be a new list that is a rearrangement of the elements of the old list, but now this rearrangement should be in sorted order. So you can write that down using standard mathematics. And now given that mathematical specification, the challenge is to prove that your piece of software written in a particular language, like Java or C# or Rust, actually generates an output that meets that mathematical specification. So this idea of using verification to prove that your software obeys some sort of specification, this has been around for a long time, so, you know, even Alan Turing talked about ways of doing this many, many decades ago. The challenge has always been that it&#8217;s really hard to develop these proofs for any large piece of software. It simply takes a long time for a human being to write down a proof of correctness of their software. And so what we&#8217;re trying to do is to build on earlier work in verification and recent developments in programming languages to try to make this as easy as possible and to try to make it as accessible to ordinary software developers as possible. So we&#8217;ve been using existing tools. There are automated theorem provers—one of them from Microsoft Research called Z3—where you give it a mathematical formula and ask it to prove that the formula is valid. We&#8217;re building on that. And we&#8217;re also taking a lot of inspiration from tools developed at Microsoft Research and elsewhere, like Dafny and F* and so on, that we&#8217;ve used in the past for our previous verification projects. And we&#8217;re trying to take ideas from those and make them accessible to developers who are using common programming languages. In this case, the Rust programming language is what we&#8217;re focusing on.&nbsp;</p>



<p><strong>TINGLE: </strong>Jay, could you describe your methodology for us and maybe share a bit about how you and your coauthors tested the robustness of Verus.</p>



<p><strong>LORCH: </strong>So the question we really want to answer is, <em>is</em> Verus suitable for systems programming? So that means a variety of things. Is it amenable to a variety of kinds of software that you want to build as part of a system? Is it usable by developers? Can they produce compact proofs? <em>And</em> can they get timely feedback about those proofs? Can the verifier tell you quickly that your proof is correct or, if it&#8217;s wrong, that it&#8217;s wrong and guide you to fix it? So the main two methodological techniques we used were millibenchmarks and full systems. So the millibenchmarks are small pieces of programs that have been verified by other tools in the past, and we built them in Verus and compared to what other tools would do to find whether we could improve usability. And we found generally that we could verify the same things but with more compact proofs and proofs that would give much snappier feedback. The difference between one second and 10 seconds might not seem a lot, but when you&#8217;re writing code and working with the verifier, it&#8217;s much nicer to get immediate feedback about what is wrong with your proof so you can say, oh, what about this? And it can say, oh, well, I still see a problem there. And you could say, OK, let me fix that. As opposed to waiting 10, 20 seconds between each such query<strong> </strong>to the verifier. So the millibenchmarks helped us evaluate that. And the <em>macro</em>benchmarks, the building entire systems, we built a couple of distributed systems that had been verified before—a key value store and a node replication system—to show that you could do them more effectively and with less verification time. We also built some new systems, a verified OS page table, a memory allocator, and a persistent memory append-only log.&nbsp;</p>



<p><strong>TINGLE: </strong>Chris, the paper mentions that successfully verifying system software has required—you actually use the word <em>heroic</em> to describe the developer effort. Thinking of those heroes in the developer community and perhaps others, what real-world impact do you expect Verus to have? What kind of gains are we talking about here?&nbsp;</p>



<p><strong>HAWBLITZEL: </strong>Yeah, so I think, you know, traditionally verification or this formal software verification that we&#8217;re doing has been considered a little bit of a pie-in-the-sky research agenda. Something that people have applied to small research problems but has not necessarily had a real-world impact before. And so I think it&#8217;s just, you know, recently, in the last 10 or 15 years, that we started to see a change in this and started to see verified software actually deployed in practice. So on one of our previous projects, we worked on verifying the cryptographic primitives that people use when, say, they browse the web or something and their data is encrypted. So in these cryptographic primitives, there&#8217;s a very clear specification for exactly what bytes you&#8217;re supposed to produce when you encrypt some data. And the challenge is just writing software that actually performs those operations and does so efficiently. So in one of our previous projects that we worked on called HACL* and EverCrypt, we verified some of the most commonly used and efficient cryptographic primitives for things like encryption and hashing and so on. And these are things that are actually used on a day-to-day basis. So we, kind of, took from that experience that the tools that we&#8217;re building are getting ready for prime time here. We can actually verify software that is security critical, reliability critical, and is in use. So some of the things that Jay just mentioned, like verifying, you know, persistent memory storage systems and so on, those are the things that we&#8217;re looking at next for software that would really benefit from reliability and where we can formally prove that your data that&#8217;s written to disk is read correctly back from disk and not lost during a crash, for example. So that&#8217;s the kind of software that we&#8217;re looking to verify to try to have a real-world impact.&nbsp;</p>



<p><strong>LORCH: </strong>The way I see the real-world impact, is it going to enable Microsoft to deal with a couple of challenges that are severe and increasing in scale? So the first challenge is attackers, and the second challenge is the vast scale at which we operate. There&#8217;s a lot of hackers out there with a lot of resources that are trying to get through our defenses, and every bug that we have offers them purchase, and techniques like this, that can get rid of bugs, allow us to deal with that increasing attacker capability. The other challenge we have is scale. We have billions of customers. We have vast amounts of data and compute power. And when you have a bug that you&#8217;ve <em>thoroughly</em> tested but then you run it on millions of computers over decades, those rare bugs eventually crop up. So they become a problem, and traditional testing has a lot of difficulty finding those. And this technology, which enables us to reason about the <em>infinite</em> possibilities in a finite amount of time and observe all possible ways that the system can go wrong and make sure that it can deal with them, that enables us to deal with the vast scale that Microsoft operates on today.</p>



<p><strong>HAWBLITZEL: </strong>Yeah, and I think this is an important point that differentiates us from testing. Traditionally, you find a bug when you <em>see</em> that bug happen in running software. With formal verification, we&#8217;re catching the bugs <em>before</em> you run the software at all. We&#8217;re trying to prove that on all possible inputs, on all possible executions of the software, these bugs will not happen, and it&#8217;s much cheaper to fix bugs before you&#8217;ve deployed the software that has bugs, before attackers have tried to exploit those bugs.&nbsp;</p>



<p><strong>TINGLE: </strong>So, Jay, ideally, what would you like our listeners and your fellow SOSP conference attendees to tell their colleagues about Verus? What&#8217;s the key takeaway here?&nbsp;</p>



<p><strong>LORCH: </strong>I<strong> </strong>think the key takeaway is that it is possible now to build software without bugs, to build systems code that is going to obey its specification on all possible inputs <em>always</em>. We have that technology. And this is possible <em>now</em> because a lot of technology has advanced to the point where we can use it. So for one thing, there&#8217;s advances in programming languages. People are moving from C to Rust. They&#8217;ve discovered that you can get the high performance that you want for systems code without having to sacrifice the ability to reason about ownership and lifetimes, concurrency. The other thing that we build on is advances in computer-aided theorem proving. So we can really make compact and quick-to-verify mathematical descriptions of all possible behaviors of a program and get fast answers that allow us to rapidly turn around proof challenges from developers.&nbsp;</p>



<p><strong>TINGLE: </strong>Well, finally, Chris, what are some of the open questions or future opportunities for formal software verification research, and what might you and your collaborators tackle next? I heard a few of the things earlier.&nbsp;</p>



<p><strong>HAWBLITZEL: </strong>Yes, I think despite, you know, the effort that we and many other researchers have put into trying to make these tools more accessible, trying to make them easier to use, there still is a lot of work to prove a piece of software correct, even with advanced state-of-the-art tools. And so we&#8217;re still going to keep trying to push to make that easier. Trying to figure out how to automate the process better. There&#8217;s a lot of interest right now in artificial intelligence for trying to help with this, especially if you think about artificial intelligence actually <em>writing</em> software. You ask it to write a piece of software to do a particular task, and it generates some C code or some Rust code or some Java code, and then you hope that that&#8217;s correct because it could have generated any sort of code that performs the right thing or does total nonsense. So it would be really great going forward if when we ask AI to develop software, we also expect it to create a proof that the software is correct and does what the user asked for. We’ve started working on some projects, and we found that the AI is not quite there yet for realistic code. It can do small examples this way. But I think this is still a very large challenge going forward that could have a large payoff in the future if we can get AI to develop software <em>and</em> prove that the software is correct.&nbsp;</p>



<p><strong>LORCH: </strong>Yeah, I see there&#8217;s a lot of synergy between—<em>potential</em> synergy—between AI and verification. Artificial intelligence can solve one of the key challenges of verification, namely making it easy for developers to write that code. And verification can solve one of the key challenges of AI, which is hallucinations, synthesizing code that is not correct, and Verus can verify that that code actually is correct.&nbsp;</p>



<p><strong>TINGLE: </strong>Well, Chris Hawblitzel and Jay Lorch, thank you so much for joining us today on the Microsoft Research Podcast to discuss your work on Verus.&nbsp;</p>



<p>[MUSIC]&nbsp;</p>



<p><strong>HAWBLITZEL: </strong>Thanks for having us.&nbsp;</p>



<p><strong>LORCH: </strong>Thank you.&nbsp;</p>



<p><strong>TINGLE: </strong>And to our listeners, we appreciate you, too. If you&#8217;d like to learn more about Verus, you&#8217;ll find a link to the paper at aka.ms/abstracts or you can read it on the SOSP website. Thanks for tuning in. I&#8217;m Amber Tingle, and we hope you&#8217;ll join us again for <em>Abstracts</em>.</p>



<p>[MUSIC FADES]&nbsp;</p>

				</span>
			</div>
			<button class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle" type="button">
				Show more			</button>
		</div>
	</div>
</div>
<span class="sr-only" id="label-external-link">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/podcast/abstracts-november-5-2024/">Abstracts: November 5, 2024</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 19:30:00 +0000</pubDate>
</item>
<item>
<title>利用大型语言模型检测软件系统中的重试错误</title>
<link>https://www.microsoft.com/en-us/research/podcast/abstracts-november-4-2024/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/abstracts-november-4-2024/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">研究探讨如何利用大型语言模型检测软件中的重试错误。</p><br /><br /><p><strong>摘要：</strong> 本文讨论了如何利用大型语言模型（LLM）来检测软件系统中的重试错误。研究者分析了重试机制在软件中的重要性，并指出实现重试机制的复杂性。通过研究多个开源系统，作者们识别出常见的重试问题，并提出了一种结合传统程序分析与LLM的方法来检测这些问题。本研究不仅有助于软件开发人员理解重试相关的挑战，也为将LLM应用于软件测试提供了新思路，期望能够提高软件的可靠性和稳定性。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/podcast/abstracts-november-4-2024/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 04 Nov 2024 17:30:00 +0000</pubDate>
</item>
<item>
<title>微软赞助SOSP 2024，推动计算系统研究</title>
<link>https://www.microsoft.com/en-us/research/blog/microsoft-at-sosp-2024-innovations-in-systems-research/</link>
<guid>https://www.microsoft.com/en-us/research/blog/microsoft-at-sosp-2024-innovations-in-systems-research/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">微软在SOSP 2024上展示其在计算系统研究方面的贡献。</p><br /><br /><p><strong>摘要：</strong> 微软自豪地赞助SOSP 2024，突显其在推动计算系统研究方面的承诺。该研讨会汇聚了专家，探讨操作系统、分布式系统和系统软件的创新。微软的研究展示了包括获得杰出工件奖的论文在内的七篇被接受论文，专注于增强云计算和分布式系统的安全性、效率和可扩展性。这些研究不仅丰富了理论知识，还解决了现实世界中的挑战，确保计算系统在日益复杂的环境中依然可持续、可靠和安全。文章详细介绍了微软在系统研究领域的重要突破。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/microsoft-at-sosp-2024-innovations-in-systems-research/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 04 Nov 2024 17:00:00 +0000</pubDate>
</item>
<item>
<title>AI-powered microgrids facilitate energy resilience and equity in regional communities</title>
<link>https://www.microsoft.com/en-us/research/blog/ai-powered-microgrids-facilitate-energy-resilience-and-equity-in-regional-communities/</link>
<guid>https://www.microsoft.com/en-us/research/blog/ai-powered-microgrids-facilitate-energy-resilience-and-equity-in-regional-communities/</guid>
<content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img alt="Three icons that represent (left to right) ecology and environment, economics, and technology for emerging markets." class="wp-image-1098936" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/10/MicroGrid-BlogHeroFeature-1400x788-1.jpg" width="1400" /></figure>



<p>The rise of affordable small-scale renewable energy, like rooftop solar panels, is reshaping energy systems around the world. This shift away from fossil fuel-powered grids creates new opportunities for energy distribution that prioritize decentralized energy ownership and community empowerment. Despite this progress, centralized energy systems still dominate, often failing to provide vulnerable communities with reliable, affordable renewable energy. In response, Microsoft researchers are collaborating with local communities to explore how AI can enable community-scale energy solutions focused on energy availability and equity as well as decarbonization.</p>



<h2 class="wp-block-heading" id="ai-powered-microgrids-support-resilient-communities">AI-powered microgrids support resilient communities</h2>



<p>Microgrids, small and localized energy systems, hold promise as a solution to the challenges of centralized energy systems. These microgrids can operate independently from the larger grid, providing participants with resilience and control. Figure 1 shows how these systems integrate renewable energy sources and storage to efficiently manage local energy needs.</p>



<figure class="wp-block-image aligncenter size-full"><img alt="Figure 1: The image shows a microgrid system with interconnected assets, including rooftop solar panels, battery storage locations, electric vehicle chargers, wind turbines, and large solar farms, all supporting a small community and tied to the central power grid.  " class="wp-image-1090167" height="858" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/10/microgrids-Fig1.jpg" width="1600" /><figcaption class="wp-element-caption">Figure 1. An example of the decentralized nature of a microgrid power system</figcaption></figure>



<p>AI improves energy reliability by integrating data about energy consumption, market prices, and weather forecasts, necessary when using wind and solar power, which rely on weather conditions. Advanced forecasting predicts renewable energy availability, while AI-driven analytics determine when to generate, store, or sell electricity. This increases efficiency and stabilizes the grid by balancing supply and demand.</p>



<p>When powered by AI, microgrids can also contribute to energy equity. In many rural parts of the US, flat-rate billing models are still common, often leading to unfair pricing. AI-enabled microgrids provide an alternative by allowing communities to pay only for the energy they use. By analyzing consumption patterns, AI can ensure optimized distribution that promotes equitable pricing and access. These systems also improve resilience during crises, enabling communities to manage energy distribution more effectively and reduce reliance on centralized utilities. AI allows microgrids to predict energy demands, identify system vulnerabilities, and recover quickly during outages.</p>



<h2 class="wp-block-heading" id="evaluating-ai-s-impact-on-microgrid-efficiency-and-equity">Evaluating AI&#8217;s impact on microgrid efficiency and equity</h2>



<p>To explore AI’s potential in improving efficiency and equity in energy management, a team of Microsoft researchers collaborated with community organizations on simulations and a case study. They built a tabletop simulator to test whether AI could effectively determine when to generate, store, or sell electricity based on real-time data. The AI model was optimized for resilience and efficiency, using reinforcement learning to control grid and battery processes, enabling microgrids adapt to changing energy conditions and market dynamics.</p>



<p>This simulation used a theoretical model with external data to show how an AI-driven microgrid could autonomously buy and sell energy based on strategic design parameters. By controlling when the battery is charged and discharged based on energy production and consumption patterns, the model maximized efficiency and maintained local power availability. Figure 2 shows the AI-controlled grid&#8217;s optimal decisions using open-source data from the California Independent System Operator (CAISO), serving as a proof of concept (PoC) for AI-driven microgrids operating under real-world conditions.</p>



<figure class="wp-block-image aligncenter size-full"><img alt="Figure 2 (A): Graph depicting peak and off-peak net power bought or sold over one week using simulations of the AI controller on historical CAISO data. The graph shows a direct correlation that when solar is available then more power is bought than sold, whereas, during nighttime the controller relies on stored energy in battery to power consumption, making fewer transactions  

Figure 2 (B) The graph shows battery levels on a simulated AI controller for the historical CAISO data. During peak hours, the battery discharges as reserves are sold, while solar power supplies the load. At night, the battery conserves power, minimizing purchases and optimizing reserves for daytime selling.  " class="wp-image-1090188" height="698" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/10/microgrids-Fig2.jpg" width="1600" /><figcaption class="wp-element-caption">Figure 2. (A) Peak and off-peak net power bought or sold over one week using simulations of the AI controller on historical CAISO data. (B) Peak and off-peak battery levels over one week using simulations of the AI controller on historical CAISO data.&nbsp;</figcaption></figure>



<h2 class="wp-block-heading" id="case-study-ai-powered-microgrid-for-community-energy-transition">Case study: AI-powered microgrid for community energy transition</h2>



<p>Microsoft researchers, in partnership with community-based organizations <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.linkedin.com/in/markese-bryant-85988116" rel="noreferrer noopener" target="_blank">Remix: The Soul of Innovation<span class="sr-only"> (opens in new tab)</span></a>, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://maverickiq.com/" rel="noreferrer noopener" target="_blank">Maverick IQ<span class="sr-only"> (opens in new tab)</span></a> and <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.ayikasolutions.com/" rel="noreferrer noopener" target="_blank">Ayika Solutions<span class="sr-only"> (opens in new tab)</span></a>, are designing and implementing an AI-powered microgrid system in West Atlanta. Working closely with the <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://ccogatl.org/hub/" rel="noreferrer noopener" target="_blank">Vicars Community Center (VCC) resilience hub<span class="sr-only"> (opens in new tab)</span></a>, they aim to address challenges faced by the community due to rapid development West Atlanta, like many Atlanta neighborhoods, faces rising housing prices and energy costs that disproportionately affect long-time residents. Communities relying on centralized grids are more vulnerable to outages, with slow recovery times, highlighting systemic inequalities in energy distribution.</p>



<p>The VCC resilience hub is tackling these issues by helping to establish a solar microgrid for the <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.wawa-online.org/" rel="noreferrer noopener" target="_blank">West Atlanta Watershed Alliance<span class="sr-only"> (opens in new tab)</span></a> (WAWA) community farm and surrounding neighborhoods. Microsoft researchers and collaborators are integrating AI into the microgrid to achieve energy savings, improve resilience, and create local job opportunities. Figure 3 shows the VCC resilience hub and WAWA community farm powered by the microgrid, highlighting key infrastructure for installing distributed energy resources (DERs).</p>



<figure class="wp-block-image aligncenter size-full"><img alt="Figure 3 (A) and 3 (B)  shows pictures of the VCC resilience hub, with solar panels  and batteries for energy storage 

 

Figure 3 (C) and 3 (D) shows pictures of the community farm, and volunteers at WAWA, a key center to support the future of community agriculture to be supported by the microgrid " class="wp-image-1098558" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/10/AI-Community-Solar-Fig3-BlogHeroFeature-1400x788-1.png" width="1400" /><figcaption class="wp-element-caption">Figure 3. A and B show the VCC resilience hub, with solar panels (left) and batteries for energy storage (right) &#8211; photographs by Erica Holloman-Hill. C and D show the WAWA community farm and community members holding freshly harvested crops.&nbsp;</figcaption></figure>



<h2 class="wp-block-heading" id="project-phases">Project phases</h2>



<h3 class="wp-block-heading h4" id="co-innovation-design">Co-innovation design</h3>



<p>Microsoft researchers, architects, and community partners held a participatory design session with state and utility representatives to define the project&#8217;s mission and key metrics. The CDC’s Social Vulnerability index informed the site selection, supporting the project’s diversity, equity, and inclusion goals.&nbsp;</p>



<h3 class="wp-block-heading h4" id="renewables-and-microgrid-siting">Renewables and microgrid siting</h3>



<p>A renewable siting survey conducted by community partners identified the VCC as a key resilience hub for solar panel and battery installation.</p>



<p>To deliver these benefits, the site first needed upgrades. Older homes required energy-efficiency improvements, such as electrical upgrades and better insulation, before they could be integrated into the microgrid. As a PoC, the team collaborated with community partners to modernize an older home with inefficient energy consumption. Sensors were installed to track energy usage and environmental conditions (Figure 4).</p>



<figure class="wp-block-image aligncenter size-full"><img alt="Figure 4: A graph showing estimated cost of electricity per day based on a legacy household in West Atlanta through kilowatt-hour usage between July 29, 2024 and August 13, 2023. Data validates the family’s experience about high energy bills, inefficient heating and cooling, and high humidity in the basement.  " class="wp-image-1090197" height="1151" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/10/microgrids-Fig4.jpg" width="1600" /><figcaption class="wp-element-caption">Figure 4. Estimated daily electricity costs based on a home’s kilowatt-hour usage between July 29 and August 13, 2023. The data confirms the residents’ experience of high energy bills, inefficient heating and cooling, and high humidity in the basement. Used by permission from Erica Holloman-Hill.</figcaption></figure>



<p>Students from <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://morehouse.edu/" rel="noreferrer noopener" target="_blank">Morehouse College<span class="sr-only"> (opens in new tab)</span></a> used this data to create a digital twin of the home, which provided actionable insights (Figure 5). The analysis confirmed issues like high radon levels and energy drains from outdated appliances. Guided by these findings, the team upgraded the house into a “smart home” where AI monitors energy and environmental conditions, enabling it to join the microgrid and making it eligible for <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.usgbc.org/leed" rel="noreferrer noopener" target="_blank">LEED certification<span class="sr-only"> (opens in new tab)</span></a>.</p>



<figure class="wp-block-image aligncenter size-full"><a href="https://www.microsoft.com/en-us/research/uploads/prod/2024/10/microgrids-Fig5.jpg"><img alt="Figure 5: 2 Figures showing snapshots of digital twin created for Dr. Erica Holloman-Hill’s home, provided by courtesy of Dr. Erica L Holloman-Hill, owner of Ayika Solutions Inc. The first figure shows the sensor readings of pollutants and weather in various parts of the home. The second figure shows the measurements in detail for the  basement. The detailed environmental data—including climatic conditions, appliance-level energy usage, and pollutant levels—provide actionable insights for identifying targeted areas for grid modernization. " class="wp-image-1090203" height="480" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/10/microgrids-Fig5.jpg" width="1627" /></a><figcaption class="wp-element-caption">Figure 5. Smart electrification: Snapshots of digital twin created for the PoC home. Panel A shows the digital twin for the entire home. Panel B shows detailed views for the first floor and basement, respectively. The detailed environmental data—including climatic conditions, appliance-level energy usage, and pollutant levels—provide actionable insights for identifying targeted areas for grid modernization. Used by permission from Erica Holloman-Hill.</figcaption></figure>



<h3 class="wp-block-heading h4" id="microgrid-simulation-phase">Microgrid simulation phase</h3>



<p>To prepare the AI-powered microgrid, Microsoft researchers built a simplified tabletop prototype simulating the setup using real data from the design and siting phases. This prototype demonstrated the control mechanism’s ability to manage DERs—solar panels, batteries, and appliances—and the interface between the microgrid and the larger grid. Figure 6 shows the tabletop model during prototyping.</p>



<p>Figure 7 illustrates the results of this simulation, showing power bought and sold and the battery charge-discharge profile. The AI controller made optimal buying and selling decisions, promoting efficiency and reliability.</p>



<figure class="wp-block-image aligncenter size-full"><img alt="Figure 6 (A): Graph depicting peak and off-peak net power bought or sold over one week using simulations of the AI controller on data generated during runs of tabletop microgrid model. The graph shows a direct correlation that when solar is available then more power is bought than sold, whereas, during night time the controller relies on stored energy in battery to power consumption, making fewer transactions. 

Figure 6 (B) The graph shows battery levels on a simulated microgrid controller powered by AI. During peak hours, the battery discharges as reserves are sold, while solar power supplies the load. At night, the battery conserves power, minimizing purchases and optimizing reserves for daytime selling. " class="wp-image-1090212" height="698" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/10/microgrids-Fig7.jpg" width="1600" /><figcaption class="wp-element-caption">Figure 7. (A) Peak and off-peak net power bought or sold over one week using AI-controller simulations. (B) Corresponding battery levels.</figcaption></figure>



<p>Erica Holloman-Hill, director of WAWA, CEO of Ayika Solutions and owner of the PoC home, reflected: “This study helped me understand how our home’s outdated condition affects our quality of life. Upgrading homes like mine could make a significant difference. Thanks to partnerships like this one, controlling and sharing the electricity the community generates is within reach, highlighting the potential of AI-supported technologies like microgrids for communities like ours.”</p>



<p>Building on the simulation’s success, the VCC resilience hub and local organizations are continuing to install solar panels to power the microgrid. AI will play a key role in siting and controlling the system as it expands. Efforts are also underway to establish sustainable financing models and assess homes for modernization to enable broader participation in the microgrid.</p>



<h2 class="wp-block-heading" id="ai-a-path-to-equity-and-resilience">AI: A path to equity and resilience</h2>



<p>The transition to decentralized microgrids offers new opportunities for energy efficiency, with AI playing a critical role in managing these systems. Yet additional efforts are needed for communities to fully realize these benefits. Residents of aging homes are burdened with outdated wiring, inefficient appliances, and poor insulation—factors that drive up energy costs. Their dependence on centralized grids offers little relief, underscoring the need for community-focused energy solutions.&nbsp;</p>



<p>The West Atlanta project illustrates AI’s potential to create resilient, equitable, community-driven energy systems, paving the way for a more inclusive and sustainable future. Microsoft researchers are continuing to collaborate with local organizations to promote smarter energy management.</p>



<p>For additional details, please review the <a href="https://www.microsoft.com/en-us/research/publication/ai-powered-microgrids-facilitate-energy-resilience-and-equitability-in-regional-communities/" rel="noreferrer noopener" target="_blank">project report</a>.</p>



<h2 class="wp-block-heading" id="acknowledgements">Acknowledgements</h2>



<p>I would like to thank all the collaborators on these projects: West Atlanta microgrid: Erica L. Holloman-Hill, John Jordan Jr, Markese Bryant. I also want to thank <a href="https://www.microsoft.com/en-us/research/people/kstrauss" rel="noreferrer noopener" target="_blank">Karin Strauss</a> for reviewing and providing feedback on this blog post; <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://andalibmalit.github.io/" rel="noreferrer noopener" target="_blank">Andalib Samandari</a>, the intern who supported this project; Vaishnavi Ranganathan for helping to brainstorm throughout the project; <a href="https://www.microsoft.com/en-us/research/academic-program/ai-society-fellows/" rel="noreferrer noopener" target="_blank">AI & Society Fellows</a> program for supporting projects in this domain; and Microsoft&#8217;s Datacenter Community Affairs team, Jon McKenley and Kelly Lanier Arnold for supporting the project in West Atlanta.&nbsp;</p>
<span class="sr-only" id="label-external-link">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/blog/ai-powered-microgrids-facilitate-energy-resilience-and-equity-in-regional-communities/">AI-powered microgrids facilitate energy resilience and equity in regional communities</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
<pubDate>Fri, 01 Nov 2024 20:23:48 +0000</pubDate>
</item>
<item>
<title>微软研究新进展：自动化工作流程与语言智能代理的最新研究成果</title>
<link>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-october-28-2024/</link>
<guid>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-october-28-2024/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文介绍了微软研究在自动化与语言代理领域的最新研究进展。</p><br /><br /><p><strong>摘要：</strong> 本文综述了微软研究近期的多项重要研究成果，包括针对自动化诊断的FLASH代理、语言智能代理的METAREFLECTION学习方法、以及提高LLM训练效率的Domino系统。这些研究不仅降低了操作中的人工负担，还显著提高了系统的准确性和效率。此外，文章还探讨了如何通过交互任务分解改善AI辅助数据分析的准确性和可控性，以及OmniParser在纯视觉用户界面代理中的应用。这些创新工作为未来AI技术的进一步发展奠定了基础，展示了在实际应用中提升智能代理性能的新可能性。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-october-28-2024/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Fri, 01 Nov 2024 16:16:43 +0000</pubDate>
</item>
<item>
<title>GraphRAG与DRIFT搜索的综合应用探索</title>
<link>https://www.microsoft.com/en-us/research/blog/introducing-drift-search-combining-global-and-local-search-methods-to-improve-quality-and-efficiency/</link>
<guid>https://www.microsoft.com/en-us/research/blog/introducing-drift-search-combining-global-and-local-search-methods-to-improve-quality-and-efficiency/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文探讨GraphRAG技术及DRIFT搜索如何优化信息检索。</p><br /><br /><p><strong>摘要：</strong> GraphRAG是一种利用大语言模型创建知识图谱和摘要的技术，旨在提升对私有数据集的检索增强生成（RAG）操作。其主要由索引引擎和查询引擎组成，能够处理全球性和本地性的查询。DRIFT搜索作为GraphRAG的扩展，引入了社区信息，优化了本地查询的过程，从而在确保查询的细致与精确的同时，扩展了信息的回收范围。在性能对比中，DRIFT搜索在回答的全面性和多样性方面显著优于传统的本地搜索，提供了更为丰富的响应。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/introducing-drift-search-combining-global-and-local-search-methods-to-improve-quality-and-efficiency/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 31 Oct 2024 19:23:03 +0000</pubDate>
</item>
<item>
<title>微软研究实习生分享对可持续发展的贡献与个人成长</title>
<link>https://www.microsoft.com/en-us/research/podcast/intern-insights-vaishnavi-ranganathan-with-angela-busheska/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/intern-insights-vaishnavi-ranganathan-with-angela-busheska/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">实习生Angela Busheska分享了她在微软研究的可持续项目经验与成长故事。</p><br /><br /><p><strong>摘要：</strong> 在这期微软研究播客中，实习生Angela Busheska与导师Vaishnavi Ranganathan探讨了她在实习期间参与开发TerraTrace平台的经历。该平台结合了统计学和大语言模型，用于追踪农业和林业的土地使用变化。Angela受个人经历启发投身于气候行动，并分享了与微软首席可持续官的互动以及她对申请实习的建议。她强调了实习期间与来自全球的研究人员合作的独特体验，以及通过数据分析和机器学习推动可持续农业的重要性。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/podcast/intern-insights-vaishnavi-ranganathan-with-angela-busheska/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 24 Oct 2024 15:14:56 +0000</pubDate>
</item>
<item>
<title>微软研究新进展：安全训练决策树与音频分类等论文综述</title>
<link>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-october-7-2024/</link>
<guid>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-october-7-2024/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">微软研究团队在多个领域发表创新论文，提升决策树训练和音频内容检测的效率与准确性。</p><br /><br /><p><strong>摘要：</strong> 微软研究团队最近发布了多篇新论文，涉及多个研究领域。首先，在一项关于安全训练决策树的研究中，提出了一种新的协议，有效降低了通信复杂性，显著提升了性能。其次，针对多标签音频分类的问题，提出了一种新的训练方案，通过自标记校正和数据增强技术提高了音频内容检测的准确性。此外，研究人员还开发了一种名为Revilio的神经符号系统，能将失去列边界的文本转换为结构化表格，提升了重建准确率。这些研究为决策树、音频分类和信息重构提供了重要的技术进展。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-october-7-2024/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 09 Oct 2024 16:00:00 +0000</pubDate>
</item>
<item>
<title>数据可视化创新：引入AI的Data Formulator</title>
<link>https://www.microsoft.com/en-us/research/blog/data-formulator-exploring-how-ai-can-help-analysts-create-rich-data-visualizations/</link>
<guid>https://www.microsoft.com/en-us/research/blog/data-formulator-exploring-how-ai-can-help-analysts-create-rich-data-visualizations/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">文章介绍了Data Formulator，旨在通过AI简化数据可视化过程。</p><br /><br /><p><strong>摘要：</strong> 本文介绍了Data Formulator这一新型数据可视化工具，旨在通过统一的用户界面（UI）与自然语言输入，简化数据分析师在绘制图表过程中的挑战。利用大型语言模型（LLM），用户能够从头开始创建图表或选择现有设计，并通过操作“概念编码架”来定义数据字段。Data Formulator的架构将数据转换与图表配置分离，从而提高用户体验和AI性能。尽管其提高了可视化需求的精确度，但文章也指出了在数据清理和定义分析目标等方面仍需解决的挑战，呼吁更多的研究与探索。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/data-formulator-exploring-how-ai-can-help-analysts-create-rich-data-visualizations/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 16:00:00 +0000</pubDate>
</item>
<item>
<title>RadEdit：优化生物医学视像模型的图像编辑与测试工具</title>
<link>https://www.microsoft.com/en-us/research/blog/stress-testing-biomedical-vision-models-with-radedit-a-synthetic-data-approach-for-robust-model-deployment/</link>
<guid>https://www.microsoft.com/en-us/research/blog/stress-testing-biomedical-vision-models-with-radedit-a-synthetic-data-approach-for-robust-model-deployment/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">RadEdit工具通过生成合成图像，助力生物医学模型的测试与评估。</p><br /><br /><p><strong>摘要：</strong> RadEdit是一种生物医学图像编辑工具，旨在提高生物医学视像模型的测试和评估。它通过生成合成的医学图像，模拟不同的数据集变化，帮助研究人员识别模型的潜在缺陷和偏见。该工具结合文本提示、编辑掩模和保持掩模，实现对医学图像的精确修改，克服了传统编辑技术的局限性，从而确保生物医学模型在临床环境中的可靠性和安全性。RadEdit还可以在图像分类和分割模型中进行压力测试，并为复杂的多模态任务提供支持，推动生物医学研究的进步。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/stress-testing-biomedical-vision-models-with-radedit-a-synthetic-data-approach-for-robust-model-deployment/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 30 Sep 2024 19:00:00 +0000</pubDate>
</item>
<item>
<title>Find My Things：探索个性化AI在无障碍技术中的应用</title>
<link>https://www.microsoft.com/en-us/research/podcast/abstracts-september-30-2024/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/abstracts-september-30-2024/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">Find My Things是个性化AI工具，帮助视障人士寻找个人物品。</p><br /><br /><p><strong>摘要：</strong> Find My Things是一种个性化的物体识别工具，旨在帮助盲人或低视力人士通过短视频训练AI系统找到个人物品。该工具在Seeing AI应用中推出，用户通过拍摄短视频教授识别对象。此项目体现了微软在无障碍技术方面的创新，近期还获得了Fast Company的设计创新奖提名。Find My Things不仅是AI技术的应用，更强调了用户个性化的需求和社区参与的重要性，未来将致力于将这些创新理念应用于更广泛的技术开发中。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/podcast/abstracts-september-30-2024/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Mon, 30 Sep 2024 13:02:05 +0000</pubDate>
</item>
<item>
<title>微软研究论坛：探讨多模态AI模型与计算技术的前沿</title>
<link>https://www.microsoft.com/en-us/research/blog/microsoft-research-forum-episode-4-the-future-of-multimodal-models-a-new-small-language-model-and-other-ai-updates/</link>
<guid>https://www.microsoft.com/en-us/research/blog/microsoft-research-forum-episode-4-the-future-of-multimodal-models-a-new-small-language-model-and-other-ai-updates/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">微软研究论坛探讨了多模态AI模型及其在各领域的应用潜力。</p><br /><br /><p><strong>摘要：</strong> 微软研究论坛交流了在通用人工智能时代的科学与技术前沿，重点讨论了多模态AI模型的最新进展和挑战。包括Phi-3-Vision，在语言与视觉能力的结合上表现超越大型模型，并已开放源代码。此外，论坛还介绍了一种新型模拟光计算机，能够将AI推理和硬优化的效率提高100倍。研究人员分享了关于深度学习在生物分子生成中的应用，以及AI反馈如何提升语言模型的自我改进能力。整体而言，论坛显示了AI在精确医疗、气候预测等领域的巨大潜力与挑战。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/microsoft-research-forum-episode-4-the-future-of-multimodal-models-a-new-small-language-model-and-other-ai-updates/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 26 Sep 2024 12:15:00 +0000</pubDate>
</item>
<item>
<title>微软研究聚焦：时间序列预测与信息检索新进展</title>
<link>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-september-23-2024/</link>
<guid>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-september-23-2024/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文介绍了微软在时间序列预测和信息检索领域的新研究成果。</p><br /><br /><p><strong>摘要：</strong> 本文集中介绍了微软研究团队在时间序列预测和信息检索领域的最新研究进展，包括ProbTS的时间序列预测基准测试和SynDL的大规模合成测试集。这些研究探讨了在不同预测时间范围内进行准确点预测和分布式预测的挑战，强调了开展全面比较分析的必要性。此外，研究人员还提出了利用大型语言模型生成相关性判断的能力，以增强信息检索的效率。通过这些研究，微软为未来的探索提供了方向，并展示了在大规模数据集上的应用潜力。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-september-23-2024/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Wed, 25 Sep 2024 16:00:00 +0000</pubDate>
</item>
<item>
<title>深入评估：当前AI模型能力与改进方向</title>
<link>https://www.microsoft.com/en-us/research/blog/eureka-evaluating-and-understanding-progress-in-ai/</link>
<guid>https://www.microsoft.com/en-us/research/blog/eureka-evaluating-and-understanding-progress-in-ai/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">本文探讨了AI模型的评估方法及其能力差异，提出改进建议。</p><br /><br /><p><strong>摘要：</strong> 在快速发展的AI领域，本文聚焦于评估现有最先进模型的能力和差异。虽然许多模型在标准基准测试中表现相似，但其实际能力可能存在根本区别。通过Eureka框架，研究团队对12种顶尖模型进行了深入分析，评估了语言与多模态能力，特别关注了未饱和的能力领域，以避免使用过于饱和的基准带来的误导。此外，研究揭示了模型的一致性、非确定性和向后兼容性的重要性，旨在为AI的安全与负责任的应用提供参考。最后，研究鼓励与开源社区的合作，以推动AI评估的透明与可重复性。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/eureka-evaluating-and-understanding-progress-in-ai/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 17 Sep 2024 16:00:00 +0000</pubDate>
</item>
<item>
<title>微软研究成果汇总：探索LLMs脆弱性、TTS持续时间建模及5G网络完整性保护</title>
<link>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-september-9-2024/</link>
<guid>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-september-9-2024/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">微软研究系列探讨LLMs脆弱性、TTS的持续时间建模及5G网络安全问题。</p><br /><br /><p><strong>摘要：</strong> 微软研究系列探讨多个关键领域的最新研究成果。首先，研究揭示了大语言模型（LLMs）在文本生成及自然语言处理中的广泛应用，同时强调了其在面对敌意攻击时的脆弱性。其次，针对文本转语音（TTS）系统，提出了一种基于总持续时间的建模方法，通过改进语音率调整，提高了语音质量与可懂性。最后，研究还指出了5G前传网络中对完整性保护的重要性，特别是针对潜在的网络攻击，提出了一系列有效的反制措施，确保用户体验和网络安全。这些研究不仅丰富了相关领域的知识体系，也为未来的技术发展提供了重要的指导。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-september-9-2024/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Thu, 12 Sep 2024 16:00:00 +0000</pubDate>
</item>
<item>
<title>MedFuzz：挑战医疗问答基准的假设与评估LLM的现实表现</title>
<link>https://www.microsoft.com/en-us/research/blog/medfuzz-exploring-the-robustness-of-llms-on-medical-challenge-problems/</link>
<guid>https://www.microsoft.com/en-us/research/blog/medfuzz-exploring-the-robustness-of-llms-on-medical-challenge-problems/</guid>
<content:encoded><![CDATA[
<div><p style="color: gray;">MedFuzz通过挑战假设评估LLM在现实医疗情境中的表现。</p><br /><br /><p><strong>摘要：</strong> 大型语言模型在医疗问答基准中展示了其潜力，但现有基准常常无法反映真实医疗场景的复杂性。MedFuzz是一种新兴的对抗性学习方法，通过引入更加真实的挑战，来评估这些模型在医疗领域的实际表现。该方法通过持续修改基准问题，使其违背简单化假设，从而揭示大型语言模型在应对复杂医疗情形时的脆弱性。实例研究表明，MedFuzz能够有效评估LLM在面对与刻板印象和偏见相关的患者特征时的表现，进而提高其在临床环境中的可靠性。</p><br /><br /><p><em>使用 gpt-4o-mini 生成 </em></p><a href="https://www.microsoft.com/en-us/research/blog/medfuzz-exploring-the-robustness-of-llms-on-medical-challenge-problems/" target="_blank">查看原文</a></div>
]]></content:encoded>
<pubDate>Tue, 10 Sep 2024 16:00:00 +0000</pubDate>
</item>
</channel>
</rss>