<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>Microsoft Research</title>
<link>https://www.microsoft.com/en-us/research/</link>

<item>
<title>Intern Insights: Vaishnavi Ranganathan with Angela Busheska</title>
<link>https://www.microsoft.com/en-us/research/podcast/intern-insights-vaishnavi-ranganathan-with-angela-busheska/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/intern-insights-vaishnavi-ranganathan-with-angela-busheska/</guid>
<content:encoded><![CDATA[

  <figure class="wp-block-image size-full"><img alt="Outline illustrations of Angela Busheska, an undergraduate engineering student at Lafayette College and Vaishnavi Ranganathan, a Senior Researcher at Microsoft." class="wp-image-1097145" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/10/Angela-and-Vaishnavi_Intern_Insights_Hero_Feature_No_Text_1400x788-1.jpg" width="1401" /></figure>


<div class="wp-block-msr-podcast-container my-4">
	
</div>



<p>Every year, interns from academic institutions around the world apply and grow their knowledge as members of the research community at Microsoft. In this Microsoft Research Podcast series, these students join their internship supervisors to share their experience working alongside some of the leading researchers in their respective fields.&nbsp;</p>



<p>In this episode, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://angelabusheska.com/" rel="noreferrer noopener" target="_blank">Angela Busheska</a>, an undergraduate engineering student at Lafayette College, talks to Senior Researcher <a href="https://www.microsoft.com/en-us/research/people/vnattar/?msockid=35739e94ab6c69d41b738b93aa076831">Vaishnavi Ranganathan</a> about her work on TerraTrace, a platform that brings together statistics and large language models to track land use over time for agricultural and forestry applications. Busheska discusses the personal loss that drew her to climate activism, the chain of events that led to a memorable face-to-face meeting with Microsoft’s chief sustainability officer, and her advice for going after the internship you want and making the experience count.&nbsp;</p>



<figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">

</div></figure>



<div class="wp-block-columns is-layout-flex wp-container-core-columns-is-layout-1 wp-block-columns-is-layout-flex">
<div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow">
<figure class="wp-block-image size-full"><img alt="Angela Busheska standing to the left of the Microsoft sign on the Microsoft campus in Redmond, Washington." class="wp-image-1096734" height="900" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/10/AB-Seattle.jpeg" width="1200" /><figcaption class="wp-element-caption">Angela Busheska, pictured on the Microsoft campus in Redmond, Washington, was a part of the Microsoft Research Undergraduate Research Intern Program. During her time in the internship program, she helped develop a platform for tracking land use across time for agricultural and forestry applications. </figcaption></figure>
</div>



<div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow">
<figure class="wp-block-image size-full"><img alt="Angela Busheska and Melanie Nakagawa standing in front of a fence " class="wp-image-1096740" height="1200" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/10/Bloomberg-Green-Festival.jpg" width="900" /><figcaption class="wp-element-caption">During her internship, Busheska met with Microsoft Chief Sustainability Officer Melanie Nakagawa at the Bloomberg Green Festival in Seattle and spoke with the Microsoft executive about her sustainability work.&nbsp;</figcaption></figure>
</div>
</div>



<div class="wp-block-group msr-pattern-link-list is-layout-flow wp-block-group-is-layout-flow">
<hr class="wp-block-separator has-alpha-channel-opacity" />



<h2 class="wp-block-heading h5" id="learn-more-1">Learn more:</h2>



<ul class="wp-block-list list-unstyled">
<li><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/Angelaangie-ai/terra_trace/tree/main" rel="noreferrer noopener" target="_blank">TerraTrace<span class="sr-only"> (opens in new tab)</span></a><br />GitHub repo</li>



<li><a href="https://www.microsoft.com/en-us/research/project/project-farmvibes/">Project FarmVibes</a><br />Project homepage</li>



<li><a href="https://www.microsoft.com/en-us/research/project/foodvibes/">Project FoodVibes</a><br />Project homepage</li>
</ul>



<div class="wp-block-spacer" style="height: 20px;"></div>



<section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast">
	<div class="subscribe-to-podcast__inner border-top border-bottom border-width-2">
		<h2 class="h5 subscribe-to-podcast__heading">
			Subscribe to the <a href="https://www.microsoft.com/en-us/research/podcast">Microsoft Research Podcast</a>:		</h2>
		<ul class="subscribe-to-podcast__list list-unstyled">
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://itunes.apple.com/us/podcast/microsoft-research-a-podcast/id1318021537?mt=2" rel="noreferrer noopener" target="_blank">
						<svg class="subscribe-to-podcast__svg" fill="black" viewBox="0 0 32 32" xmlns="http://www.w3.org/2000/svg">  <path d="M7.12 0c-3.937-0.011-7.131 3.183-7.12 7.12v17.76c-0.011 3.937 3.183 7.131 7.12 7.12h17.76c3.937 0.011 7.131-3.183 7.12-7.12v-17.76c0.011-3.937-3.183-7.131-7.12-7.12zM15.817 3.421c3.115 0 5.932 1.204 8.079 3.453 1.631 1.693 2.547 3.489 3.016 5.855 0.161 0.787 0.161 2.932 0.009 3.817-0.5 2.817-2.041 5.339-4.317 7.063-0.812 0.615-2.797 1.683-3.115 1.683-0.12 0-0.129-0.12-0.077-0.615 0.099-0.792 0.192-0.953 0.64-1.141 0.713-0.296 1.932-1.167 2.677-1.911 1.301-1.303 2.229-2.932 2.677-4.719 0.281-1.1 0.244-3.543-0.063-4.672-0.969-3.595-3.907-6.385-7.5-7.136-1.041-0.213-2.943-0.213-4 0-3.636 0.751-6.647 3.683-7.563 7.371-0.245 1.004-0.245 3.448 0 4.448 0.609 2.443 2.188 4.681 4.255 6.015 0.407 0.271 0.896 0.547 1.1 0.631 0.447 0.192 0.547 0.355 0.629 1.14 0.052 0.485 0.041 0.62-0.072 0.62-0.073 0-0.62-0.235-1.199-0.511l-0.052-0.041c-3.297-1.62-5.407-4.364-6.177-8.016-0.187-0.943-0.224-3.187-0.036-4.052 0.479-2.323 1.396-4.135 2.921-5.739 2.199-2.319 5.027-3.543 8.172-3.543zM16 7.172c0.541 0.005 1.068 0.052 1.473 0.14 3.715 0.828 6.344 4.543 5.833 8.229-0.203 1.489-0.713 2.709-1.619 3.844-0.448 0.573-1.537 1.532-1.729 1.532-0.032 0-0.063-0.365-0.063-0.803v-0.808l0.552-0.661c2.093-2.505 1.943-6.005-0.339-8.296-0.885-0.896-1.912-1.423-3.235-1.661-0.853-0.161-1.031-0.161-1.927-0.011-1.364 0.219-2.417 0.744-3.355 1.672-2.291 2.271-2.443 5.791-0.348 8.296l0.552 0.661v0.813c0 0.448-0.037 0.807-0.084 0.807-0.036 0-0.349-0.213-0.683-0.479l-0.047-0.016c-1.109-0.885-2.088-2.453-2.495-3.995-0.244-0.932-0.244-2.697 0.011-3.625 0.672-2.505 2.521-4.448 5.079-5.359 0.547-0.193 1.509-0.297 2.416-0.281zM15.823 11.156c0.417 0 0.828 0.084 1.131 0.24 0.645 0.339 1.183 0.989 1.385 1.677 0.62 2.104-1.609 3.948-3.631 3.005h-0.015c-0.953-0.443-1.464-1.276-1.475-2.36 0-0.979 0.541-1.828 1.484-2.328 0.297-0.156 0.709-0.235 1.125-0.235zM15.812 17.464c1.319-0.005 2.271 0.463 2.625 1.291 0.265 0.62 0.167 2.573-0.292 5.735-0.307 2.208-0.479 2.765-0.905 3.141-0.589 0.52-1.417 0.667-2.209 0.385h-0.004c-0.953-0.344-1.157-0.808-1.553-3.527-0.452-3.161-0.552-5.115-0.285-5.735 0.348-0.823 1.296-1.285 2.624-1.291z"></svg>
						<span class="subscribe-to-podcast__link-text">Apple Podcasts</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://subscribebyemail.com/www.blubrry.com/feeds/microsoftresearch.xml" rel="noreferrer noopener" target="_blank">
						<svg class="subscribe-to-podcast__svg" fill="none" viewBox="0 0 32 32" xmlns="http://www.w3.org/2000/svg"><path d="M6.4 6a2.392 2.392 0 00-2.372 2.119L16 15.6l11.972-7.481A2.392 2.392 0 0025.6 6H6.4zM4 10.502V22.8a2.4 2.4 0 002.4 2.4h19.2a2.4 2.4 0 002.4-2.4V10.502l-11.365 7.102a1.2 1.2 0 01-1.27 0L4 10.502z" fill="currentColor"></svg>
						<span class="subscribe-to-podcast__link-text">Email</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://subscribeonandroid.com/www.blubrry.com/feeds/microsoftresearch.xml" rel="noreferrer noopener" target="_blank">
						<svg class="subscribe-to-podcast__svg" fill="none" viewBox="0 0 32 32" xmlns="http://www.w3.org/2000/svg"><path d="M12.414 4.02c-.062.012-.126.023-.18.06a.489.489 0 00-.12.675L13.149 6.3c-1.6.847-2.792 2.255-3.18 3.944h13.257c-.388-1.69-1.58-3.097-3.179-3.944l1.035-1.545a.489.489 0 00-.12-.675.492.492 0 00-.675.135l-1.14 1.68a7.423 7.423 0 00-2.55-.45c-.899 0-1.758.161-2.549.45l-1.14-1.68a.482.482 0 00-.494-.195zm1.545 3.824a.72.72 0 110 1.44.72.72 0 010-1.44zm5.278 0a.719.719 0 110 1.44.719.719 0 110-1.44zM8.44 11.204A1.44 1.44 0 007 12.644v6.718c0 .795.645 1.44 1.44 1.44.168 0 .33-.036.48-.09v-9.418a1.406 1.406 0 00-.48-.09zm1.44 0V21.76c0 .793.646 1.44 1.44 1.44h10.557c.793 0 1.44-.647 1.44-1.44V11.204H9.878zm14.876 0c-.169 0-.33.035-.48.09v9.418c.15.052.311.09.48.09a1.44 1.44 0 001.44-1.44v-6.719a1.44 1.44 0 00-1.44-1.44zM11.8 24.16v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84zm5.759 0v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84z" fill="currentColor"></svg>
						<span class="subscribe-to-podcast__link-text">Android</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://open.spotify.com/show/4ndjUXyL0hH1FXHgwIiTWU" rel="noreferrer noopener" target="_blank">
						<svg class="subscribe-to-podcast__svg" fill="none" viewBox="0 0 32 32" xmlns="http://www.w3.org/2000/svg"><path d="M16 4C9.383 4 4 9.383 4 16s5.383 12 12 12 12-5.383 12-12S22.617 4 16 4zm5.08 17.394a.781.781 0 01-1.086.217c-1.29-.86-3.477-1.434-5.303-1.434-1.937.002-3.389.477-3.403.482a.782.782 0 11-.494-1.484c.068-.023 1.71-.56 3.897-.562 1.826 0 4.365.492 6.171 1.696.36.24.457.725.217 1.085zm1.56-3.202a.895.895 0 01-1.234.286c-2.338-1.457-4.742-1.766-6.812-1.747-2.338.02-4.207.466-4.239.476a.895.895 0 11-.488-1.723c.145-.041 2.01-.5 4.564-.521 2.329-.02 5.23.318 7.923 1.995.419.26.547.814.286 1.234zm1.556-3.745a1.043 1.043 0 01-1.428.371c-2.725-1.6-6.039-1.94-8.339-1.942h-.033c-2.781 0-4.923.489-4.944.494a1.044 1.044 0 01-.474-2.031c.096-.023 2.385-.55 5.418-.55h.036c2.558.004 6.264.393 9.393 2.23.497.292.663.931.371 1.428z" fill="currentColor"></svg>
						<span class="subscribe-to-podcast__link-text">Spotify</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://www.blubrry.com/feeds/microsoftresearch.xml" rel="noreferrer noopener" target="_blank">
						<svg class="subscribe-to-podcast__svg" fill="none" viewBox="0 0 32 32" xmlns="http://www.w3.org/2000/svg"><path d="M6.667 4a2.676 2.676 0 00-2.612 2.13v.003c-.036.172-.055.35-.055.534v18.666c0 .183.019.362.055.534v.003a2.676 2.676 0 002.076 2.075h.002c.172.036.35.055.534.055h18.666A2.676 2.676 0 0028 25.333V6.667a2.676 2.676 0 00-2.13-2.612h-.003A2.623 2.623 0 0025.333 4H6.667zM8 8h1.333C17.42 8 24 14.58 24 22.667V24h-2.667v-1.333c0-6.618-5.382-12-12-12H8V8zm0 5.333h1.333c5.146 0 9.334 4.188 9.334 9.334V24H16v-1.333A6.674 6.674 0 009.333 16H8v-2.667zM10 20a2 2 0 11-.001 4.001A2 2 0 0110 20z" fill="currentColor"></svg>
						<span class="subscribe-to-podcast__link-text">RSS Feed</span>
					</a>
				</li>
					</ul>
	</div>
</section>


<div class="wp-block-msr-show-more">
	<div class="bg-neutral-100 p-5">
		<div class="show-more-show-less">
			<div>
				<span>
					

<h3 class="wp-block-heading" id="transcript-1">Transcript</h3>



<p>[TEASER]&nbsp;</p>



<p>[MUSIC PLAYS UNDER DIALOGUE]&nbsp;</p>



<p><strong>ANGELA BUSHESKA: </strong>Being in New York while working with people from Seattle and Brazil allowed me to have a broad range of people that I had a chance to meet. So, like, the New York office, it is very specifically focused on economics and social aspects that I&#8217;m not an expert on, but having a lunch with these people every single day, I had a chance to learn a lot.&nbsp;Being in Seattle and meeting with interns and researchers in Seattle, I had a chance to learn how other projects came to life. With <em>our</em> meetings, I realized how FarmVibes and FoodVibes were once just, like, a small idea and now are these huge projects. So having a chance to understand the history of all the things around me was a great way to see how <em>I</em> am able to build something for the future.</p>



<p>[TEASER ENDS]</p>



<p>[MUSIC FADES]</p>



<p><strong>VAISHNAVI RANGANATHAN:</strong> Hey, everyone, welcome to <em>Intern Insights</em>, a Microsoft Research Podcast featuring some of the brilliant students who are contributing to research and advances at Microsoft as a part of the renowned internship program at Microsoft Research. I&#8217;m Dr. Vaishnavi Ranganathan, a senior researcher at Microsoft Research with a passion for leveraging sensing and wireless technology to help address global challenges in health, environment, and sustainability. Today, I&#8217;m speaking with my intern, Angela Busheska, about her work this summer and her experience as a Microsoft Research intern. Angela, welcome to the podcast. So I&#8217;ve had the pleasure of getting to know you this summer not only in the capacity as a student and researcher but also as a person. So to start with, why don&#8217;t you introduce yourself. Tell the audience a little bit about <em>yourself</em>—where you&#8217;re from, your academic background, what excites you in research, and most importantly, outside studies, what do you enjoy doing?</p>



				</span>
				<span class="show-more-show-less-toggleable-content" id="show-more-show-less-toggle-1">
					



<p><strong>ANGELA BUSHESKA: </strong>Yeah, absolutely. Thank you so much for having me. Super excited to be here and super excited to have spent three months—time flies!— as a researcher along with the project. So my name is Angela. I am originally from North Macedonia, a very small country next to Greece in the Balkans. And I spent my first, like, 16 years thinking that I would become a mathematician, really focused on math Olympiads. And then I moved to the capital city of my country, which is Skopje, North Macedonia, and that year, in 2019, we had the greatest pollution. We were, like, on the top of every single list in terms of pollution, but honestly, I didn&#8217;t care. I was like, I&#8217;m going to do, like, math Olympiads, win every medal. I moved in with my aunt, who was living very close to the city center, and she had a lot of cardiovascular difficulties. And then this air pollution clogged her blood, and she passed away. And that was the moment when I saw like, I love math, but this air pollution took my aunt, so I <em>have</em> to do something. So I made the hard decision that junior year going into senior year to cut my participation in math Olympiads after seven great years there and focus on the climate. I really just started to understand where is the pollution coming from in my area. I started to realize that fast fashion had a huge influence, and then that&#8217;s why I started, like, getting into this field, getting into research, started a climate tech nonprofit called EnRoute, where our mission is to debunk the fast fashion supply chain and let people but also corporations know what is behind their clothes. So we, kind of, help both sides. We help people with their shopping choices, but we help a lot of corporations and policy to understand either what&#8217;s behind their supply chain and change it or how to better communicate their supply chain because there&#8217;s a lot of greenwashing that is happening in this space. So it really started as a rag-tag group of teenagers, and this is my fifth year working at it. So I really had a passion for both understanding the research side of it and the nonprofit, like, getting people to learn more about it. So I think that marked really my presence. And then coming into the US in 2021, I started to study both electrical engineering and computer science just because I love this intersection of building and doing stuff in practice and a way to apply my math knowledge into real life.</p>



<p><strong>RANGANATHAN: </strong>Wow, so early in life you have such amazing goals. That&#8217;s impressive. So, Angela, we connected after Madeleine Daepp, a researcher who was involved in the intern selection process, introduced your work and your passion for sustainability to me. I saw your passion for this area and, you know, your enthusiasm in the first conversation—we were already working on ideas, right! I knew I had to work with you. But for you, there are many other internship opportunities. I would love to know what excited you the most about Microsoft Research.</p>



<p><strong>BUSHESKA: </strong>Absolutely. Yeah. So as I said, like, I started getting into this area of sustainability by myself. I really didn&#8217;t have a structured way to learn. So when I heard that there is an opportunity from people who have, like, previously worked in this area, are doctors in this area, to learn along them, that was definitely one. But also throughout my life, I had like entrepreneurship stints. I was selling lemonade when I was [LAUGHS] 6 years old; started a nonprofit. And this was a great opportunity for me to start a zero-to-one project while being an intern, which is, I would say, a once-in-a-lifetime chance. We had a chance to define the problem, see solution, try things. I was not part of just one project or building one feature. I had a chance to drive it along you and the team. So that was, I think, the main reason why.</p>



<p><strong>RANGANATHAN:</strong> I&#8217;m glad we were able to attract your attention here. [LAUGHS] Before we get into specifics on, you know, exactly what we did this summer, I&#8217;d like for us to talk a bit about your internship setup, right. I think it allowed for some really unique experiences, and, you know, I would love to have you share your internship highlights. I think there is one in particular that I&#8217;m thinking about, which I really hope you&#8217;ll share.</p>



<p><strong>BUSHESKA: </strong>Absolutely. I would say this was an internship like no other experience I&#8217;ve had in the past. So just for context, I was interning in New York while part of the team being in Brazil, part of the team—you and the other researchers—being in Redmond, a couple of other researchers, like, being technically in New York. So I had a chance to interact with all of these different time zones. Also for an additional context, I was a part of undergrad research internship group where they brought us to Seattle from New York—and also there are other interns from Boston—to spend like a week and learn more about Microsoft, Microsoft Research, the leadership. So that was an incredible opportunity. Also, I had a great opportunity prior to that to come to the team meeting to see farms in real life, interact with farmers, interact with the team in person, which was also another great opportunity. And I&#8217;ll come to the one that you&#8217;re referring [to] here [LAUGHS]. So the second time when I was, like, visiting Seattle, I remember a week prior, it was Friday, we were finishing up some stuff. You actually pointed out that I should definitely message some of the leadership people to interact with them and hear their insights. And it was EST time zone, somewhere around 8 when I left the office, and I shoot an email to the chief sustainability officer, Melanie Nakagawa. I was like, “Hey, my name is Angela. I&#8217;m a research intern. I have worked in, like, fast fashion in the past. Now I&#8217;m working with Vaishnavi and the team on this food project. I’d really love to meet you next week. [LAUGHS] I&#8217;m coming for like three days.” I sent that email. I was like, there&#8217;s no way I&#8217;m getting response from this. And then on Sunday, I traveled to Seattle. And I remember during the first day, assistant of the chief sustainability officer says, like, there is this Bloomberg Green Festival that is happening in Seattle on Thursday, and we would love for you to come and meet Melanie. It was, like, I don&#8217;t know. It was like real life or not. I really couldn&#8217;t … it took a lot of time to process. And after that, one thing additional that was a barrier was how to get into this festival because this festival had a ticket of like $300, $400. And I think that by that time everything was sold out. So I was like, I would love to, but I cannot just get into the Bloomberg Green Festival without a badge. So then I realized there is this sustainability community at Microsoft that is like 8,000 employees or something, and they got badges previously for the festival, and everyone who is working there can just get the basic badge just to get into. So I emailed a couple of people from there; they set [me up] with a badge. Huge props also to the undergraduate research team who extended my stay for a day because I was supposed to leave for New York the other day. So a couple of miracles happened there. I had a chance to go to the Bloomberg Green Festival, had a chance to meet with Melanie and her assistant, Tyler, who was working also in this area of sustainability in her presence on, like, these events. It really goes to say how an undergrad intern can, like, meet with leadership and learn from the leadership to the place and the opportunities we had during this internship. Thank you so much Melanie and Tyler for taking out the time at the Bloomberg Green Festival. I know it was a super packed day for both of you, but thank you so much for taking the time.</p>



<p><strong>RANGANATHAN: </strong>Thank you for sharing that. I want to point out something. It&#8217;s amazing how the leadership makes time and they really value every person&#8217;s work, and that&#8217;s an internship which is accounted for now, right, and you know your work is meaningful to the company. I think Microsoft is so big that people don&#8217;t realize there&#8217;s this community of 8,000 people in sustainability often, so it&#8217;s amazing. It blows my mind every single time, and kudos to you for following up on my late-night comment. [LAUGHS] Um, Angela, so this internship falls under larger efforts within Microsoft Research to establish a sustainable agriculture and food supply chain, a project that we know as FoodVibes. In your work this summer, you focus specifically on enabling technology to meet the new European Union&#8217;s regulation around deforestation-free products. Could you tell us, in your words, about these regulations and how you think the work can aid in their implementation?</p>



<p><strong>BUSHESKA: </strong>Absolutely, yeah. So the European Union’s regulation on deforestation-free products, also known as EUDR, is a legislation that will prevent food linked to deforestation to enter European Union borders<a href="#_ftn1" id="_ftnref1">[1]</a>. But how will the border officials know if something is coming from a deforested area or not? On another side, it&#8217;s also the farmers from this area who don&#8217;t know what exactly is a deforested area, especially the ones who moved after maybe an area has been deforested. So there are a lot of questions around there, and I think that getting into and understanding the problem was a huge part to continue after that in building the solution.</p>



<p><strong>RANGANATHAN: </strong>Yeah, and I believe that having a large team here really helped because we all often had discussions around many of these areas and we really valued your inputs and how you participated in these discussions, right. So through your internship, we&#8217;ve seen that there are a variety of tools, you know, and vegetation metrics at our disposal to help determine what exists on a plot of land because that&#8217;s what we want to identify. There&#8217;s, like, satellite imagery. We get the normalized difference vegetation index, and then there’s the USDA&#8217;s cropland data layer, which exists purely for the US. But, you know, we are getting an incomplete picture here, at least as it pertains to this particular use case. How do you think TerraTrace brings these pieces together, and what are some of the specific challenges or motivations of the core of your work?</p>



<p><strong>BUSHESKA: </strong>Absolutely. Yeah, I think, like, a couple of the first weeks, we tried these great machine learning models, and one thing we realized is that when we have, like, orchards, and when we had pine trees, and then when we had, like, regular forest, all of them are classified the same, which was a really great light saying, like, yeah, these are great. These are models that are trained by millions of data. They still don&#8217;t work as we want to. And also, I think that in an era where everyone is, like, training big great models, we kind of decided to take another route and say like, models are great. What if we go step by step and maybe we don&#8217;t need a full model round. Maybe we can go step by step to a certain point to try to understand deeply. And I think I&#8217;m really grateful that we took this direction because we had a chance to understand at a granular level what is actually happening. Here we had, like, we were lucky at the beginning to work with farms in Washington. We had, like, an actual farmer who was in the team who we have, like, pictures and we had all the data. So that was a great ground truth for us to understand, OK, this is how the vegetation looks on a farm. This is how the vegetation looks on a forest across years. So we had these snapshots and then from then on, we just moved along to say, well, if we know about this, what&#8217;s happening in Washington, how we can scale now to other places in the US. We looked deeply into California just because it has a lot of, like, agricultural diversity. And I think that this step-by-step level brought us to create TerraTrace. TerraTrace is a platform where one can enter, like, the coordinates of a farm and see what has been happening on a given piece of land across time. Now, TerraTrace combines a couple of different things. It combines mathematical results, combines LLMs, and combines just, like, the basic information of risk. And I think this is good just because it&#8217;s not a heavy computational platform that we have. And if we need to use it on, like, a couple of years from now on a farm, we technically can. If we need to use it, like, in a legal office, we can. Just because it doesn&#8217;t depend a lot on data and it&#8217;s, like, easily portable, which is another plus, and differentiator compared to what exists outside.</p>



<p><strong>RANGANATHAN: </strong>Do you want to share a little bit about the signature curves that you identified?</p>



<p><strong>BUSHESKA: </strong>Absolutely. So when I just, like, realized … there is a metric called NDVI (Normalized Difference Vegetation Index), which is basically measuring vegetation. It is a time series of vegetation. What we did with NDVI is we tried to, like, measure it across time on different places. And I think in coffee, it had the greatest impact. Just because there was a coffee in Vietnam, coffee in Honduras, completely two different places. And then when we analyzed and saw the shapes, we were like, wow, they are completely two different places; however, they still follow the same trend and that was a great calling to say, like, this is a greater metric. Maybe if, like, vision computer models failed, this is something that is, like, very rudimentary. You wouldn&#8217;t expect that just a very simple index would calculate that, but we saw it working for a lot of different places, and I&#8217;m particularly grateful for the places that were not together at the same place.</p>



<p><strong>RANGANATHAN: </strong>Yeah, and I think, like, looking at this, like, temporal, over-time picture is the unique aspect of what you built and that was what unlocked it for us, right. So you hinted at this. In developing the TerraTrace platform, you ended up combining large language models, or LLMs, and statistics. What did you like about this approach? What did each bring to the table? How did it contribute to your ultimate goal? Could you share a bit about?</p>



<p><strong>BUSHESKA: </strong>As I said, like, at the beginning, I&#8217;m a huge math person, and I truly believe that math has more power than we credit today for. So one thing that I started building, when I started building, I was just, how can we get as much information as possible without LLMs and then give it to the LLMs? That was kind of the approach that I started. So we have this, as you mentioned previously, crop data layer that was the base truth. So I could always go back and compare to see if it has, like, if we are doing the same thing. Then we had the signature curves that we could compare to base signature curves to understand, OK, it&#8217;s coffee or it&#8217;s a farm. And now when we were having a farm, we had a problem because corn looked the same as wheat. Multiple crops look the same. So I needed something more to differentiate what exactly is there. So by math, I managed to understand like the growth rate, the fallout rate, what is the percentage when the curve is up, how much percentage is down so every insight that we could get by just basic statistics. And after that, all this combined knowledge was given to the LLM to, kind of, just confirm that the math is right and give us, OK, greater insight into, well, your math is good, and after that, based on your math and everything the LLM knows, well, there is this probability that it&#8217;s corn and after that we came to the crop data layer to say, yep, it&#8217;s corn. Referring to corn just because this was our example demo. Also, LLMs are changing very rapidly today, so like GPT-4, GPT-4 Turbo, expecting a GPT-5, so constant development needs to be done, and I think that if something is, like, changed and doesn&#8217;t work in the platform, one thing that will always work is the statistics. So having something to always refer to was a very interesting process.</p>



<p><strong>RANGANATHAN: </strong>Yeah, I really appreciate, you know, how we had the focus on, hey, let&#8217;s do what we can with math first because, after all, this is a sustainability project, right?</p>



<p><strong>BUSHESKA: </strong>Exactly.</p>



<p><strong>RANGANATHAN:</strong> So LLMs were great at summarizing this, taking all the data and, like, giving you the outputs. I think that was a very interesting approach, too. So there are several existing pieces of work we&#8217;ve seen in this area. We&#8217;ve relied on a lot of literature in this specific application, right, that ended up havingauthors who were affiliated with Microsoft. Could you share a little bit about those works that we drew on and how we leveraged the Microsoft connections?</p>



<p><strong>BUSHESKA: </strong>Absolutely. One thing that was something I was not expecting was reading the papers and then hopping on a call with the authors. So one thing that I would credit is first we understood … there was this, like, GeoLLM group. They actually had a presentation in our weekly meeting for the group. So it was, like, me just staying in the presentation and trying to learn. And the other day, they send out like, this is a research paper; take a look at it. And after, like, we realized that the majority of the authors were in the same building as you actually, we had a great chance to, like, meet, like, with them and understand how …</p>



<p><strong>RANGANATHAN: </strong>This is SatCLIP, right?</p>



<p><strong>BUSHESKA: </strong>… <a href="https://www.microsoft.com/en-us/research/publication/satclip-global-general-purpose-location-embeddings-with-satellite-imagery/?msockid=35739e94ab6c69d41b738b93aa076831">SatCLIP<span class="sr-only"> (opens in new tab)</span></a> and <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/abs/2404.15500v1" rel="noreferrer noopener" target="_blank">GeoLLM<span class="sr-only"> (opens in new tab)</span></a>, both of them. Trying to understand, like, how they have built it, what they have built, why, how they are planning to continue, how I am able to use it. And, actually, because when you&#8217;re reading a paper and you&#8217;re reading GitHub repo, it&#8217;s one thing. [LAUGHTER] When you&#8217;re speaking with the author and seeing, like, this is why we&#8217;ve built it, here&#8217;s the limitations, be careful how you&#8217;re using it, it&#8217;s completely another thing. So I am really grateful for this situation. But also, not only, like, inside of Microsoft, we also had a chance to work with a lot of other folks. For example, we read a lot of papers from research groups in universities. And because our interns came from these universities, it was, like, great to understand from them also what they have built.</p>



<p><strong>RANGANATHAN:</strong> Nice, and the other interns whom you worked with, which we&#8217;ll come to. So for this specific work, we were motivated by the use case. What were some of your findings, and also how are you envisioning this work as a foundation for other supply-chain or even, you know, broader sustainability scenarios and even beyond those fields that you can think of?</p>



<p><strong>BUSHESKA:</strong> Yeah, so one thing that we, as a conclusion, came out from here is that signature curves are not just by look. When we tested that with a lot of different other signature curves, we realized, OK, this is true because in most of the cases, they worked. Obviously we had some failures, like citrus signature curves didn&#8217;t work because of other reasons that happened on the farm. But for most of them, we got same results on what&#8217;s happened with the signature curves with what happens actually on the farm, which is a great way to further this exploration here. Another thing that we realize from this project is now the group previously has worked on trying to understand supply chain, like having the tracking part and having this code to track along the journey, but we were missing the part on what happened on the land. And now that we have this additional way to understand what happened on the land, I think it is a full system of starting this is what happened on the land, this is what happened across the road, and this is where it is now, so that not only EUDR, but even, like, customers in the future will know where their food is coming from, which is that total part of sustainability that we want to get to. Because I think that at this point, we know the challenges, we know the climate change challenges that we are having, and the more information we have, the better decisions we and policymakers would be able to make.</p>



<p><strong>RANGANATHAN:</strong> And I think we realized this and you can chime in, Angela, but I feel that the traceability is a vehicle for data. What you build is a means to take all that data and make it meaningful to people, right. Like what does NDVI mean? I have no idea as a layperson, so you can actually get that information out. There were also a few other use cases that you gleaned out of your data input, right. Like wildfire was one of them. Would you like to share a little bit about that?</p>



<p><strong>BUSHESKA:</strong> Yes, so we were looking specifically about California, specifically about 2020, which was a season of very, very bad wildfires. And we could see by measuring this vegetation how, like, wildfires affected these regions. Like, you could see how vegetation was dropping very quickly from a great number of one to just, like, flat zero just because everything was there burned. So seeing firsthand on these curves and after that linking up to a lot of other background wildfire data was a good check-in. Like, you could see that it&#8217;s not a person deforestation; it&#8217;s a wildfire deforestation. And also it is really helpful for risk estimation as we go further along. We could see, like, this past year climate change effects are there. It&#8217;s not just like this fancy term in the future. It is there. So I think that having a chance to see in the past and having these models, it&#8217;s also giving us a preview for the future. Because ultimately we want this greater food yield so that more and more people can enjoy healthy food. So having a chance to predict the risk would help us to save more food and, yeah, care better about our planet and our people.</p>



<p><strong>RANGANATHAN:</strong> I think there&#8217;s a lot of potential. The more information you have, the more applications in sustainability you can build. This is merely, like, a footstool to launch it off, right. You’ve said one of the things you&#8217;ll miss most from your internship is the density of smart people in the building and in the company. Over the course of your internship, what did you learn? How did your actual experience compare to, like, expectations you had for it?</p>



<p><strong>BUSHESKA:</strong> I think it exceeded every single expectation that I had because I would say when you mentioned the density of smart people, it was really incredible to have—and I think that this … maybe my very interesting connection of being in New York while working with people from Seattle and Brazil allowed me to have a broad range of people that I had, like, had a chance to meet. So, like, the New York office, it is very specifically focused on economics and social aspects that I&#8217;m not an expert on, but having a lunch with these people every single day, I had a chance to learn a lot about how, like, human data is provisioned. They were building a lot of things for, like, Microsoft&#8217;s new projects and new products that are, like, the Copilot and the computers, so I had a chance to hear about those perspectives. Being in Seattle and meeting with interns and researchers in Seattle, I had a chance to learn not only about the farms perspective but also how other projects came to life. With our meetings, I realized how FarmVibes and FoodVibes were once just, like, a small idea and now are these huge projects. So having a chance to understand the history of all the things around me was a great way to see how <em>I</em> am able to build something for the future. And also maybe another thing is the collaboration that happens. As I said, I was, like, surrounded by a lot of socioeconomic people—that I am not really an expert in—but they were really great with providing me advice from an area I would never think of. So when I was speaking, like, from farms to someone who is in economics, they would raise another point on how this can hurt or help economy or to look at it from another side, which is all great perspectives to have when you&#8217;re creating a research from scratch. That&#8217;s why I really, like, referred to entrepreneurship previously because I feel like even though was an intern, I really had a chance to shape the project in a way that I would get all these insights from people and then obviously decide how to go further.</p>



<p><strong>RANGANATHAN:</strong> Yeah, and I want to add summer with interns is the highest energy level at MSR (Microsoft Research) and the best time of my year at Microsoft. So having successfully completed your internship, what advice do you have for our audience, you know, when it comes to applying for an internship like this in industry and then getting the most out of that experience?</p>



<p><strong>BUSHESKA:</strong> I would say one of the things that really maybe helped me through the process is, like, working obviously, in an area that I was really passionate about. But another thing, and especially this is coming specifically for the marginalized communities in tech—although I would say MSR is doing a great job in having this balance. But I&#8217;m coming from a liberal arts college where we have, like, two girls that are studying electrical engineering—so having this disbalance can in some ways, like, I don’t know, put you, “I&#8217;m not good enough” and all this imposter syndrome. So maybe one thing is definitely, like, reach out to people. And something that I really learned heavily from you is reach out. There is nothing you can lose. Most of the time, it is just … getting a no is maybe the hardest answer that you will get. So having a chance to ask is always a good idea. Obviously, don&#8217;t go to, like, every single executive to ask questions, even though it paid out—it paid out [LAUGHTER]—and just, like, ask for help from the people around you. Ask to learn. I realized, like, researchers <em>really</em> want to speak about what they have worked on previously. So whenever you get a chance to ask them about their past project, they&#8217;re super eager to tell you about like their grad days and how they have become what they are now. So that was also great. And in terms of applying, I think I would … when I applied for this, I was like, there&#8217;s no chance I will be able to get in. But for me, as an introvert turned into an extrovert—fun fact, I was a big introvert in the past who turned into an extrovert just because of my work—it&#8217;s like if you don&#8217;t apply, there&#8217;s a 100 percent chance that you&#8217;re not going to get in. So, like, when I interviewed, after my first interview, I was like, yeah, there is, like, no chance. Because, like, I presented the projects, but I was like, there are so many other students who I know that are working in these areas and then it happened and then I&#8217;m here recording this podcast. I remember it was Thanksgiving break when I applied for this internship. If I was like, no—if I self-rejected myself previously, yeah, this would never have happened. So I would say for all interns out there, just, like, don&#8217;t self-reject yourself. Let them reject you. [LAUGHTER] It&#8217;s my really advice.</p>



<p><strong>RANGANATHAN:</strong> And, yeah, have more confidence. I&#8217;m glad you applied and you joined us because this was a highlight of the summer for us, this was, right. So your work with Microsoft Research is one of your several projects. You&#8217;ve been involved with many other things, right. What else do you have going on? How does it contribute to the impact you&#8217;re looking to have at this point in your life?</p>



<p><strong>BUSHESKA:</strong> Yeah. So one thing that I realized in the past four years is that I started … so my, like, journey was very, I would say, interesting and not predictable just because when I, like, graduated from high school, I got trapped by all the COVID pandemic. I couldn&#8217;t fly into the US just because of all the visa regulations. It was like, OK, a gap year at home, which if you asked any of my friends before, I was never the person who would take a gap year. So staying that year really, like, without a school or official job was the chance for me to just look at and start my nonprofit, EnRoute. From then on, I worked with policy. We worked at the UN. We even went to Hollywood in March to speak about, like, fast fashion. So I realized there is no one way to make an impact. So I was really glad to join research, to join policy, and speak wherever I can. I think now I&#8217;m getting back into my senior year of college. Time flies. And something that I am, like, looking definitely into is how to continue my research in this area, where I most probably would love to be through grad school. Having a chance also to push further this project just because I think that speaking out and sharing research is one of the, like, greatest things we can do, like referring to all the other times when I was speaking on conferences. It will be magical for someone to respond with positive and negative feedback and maybe even can create a collaboration for us to move forward. So that is definitely something that I&#8217;m looking forward to. So definitely this area is something that I got in by mistake. I got in really just by … because I had that great time in my senior year to spend more time research, but it definitely something that marked my life at this point. And I think that, like, whatever route I pursue will be to fight climate change in any way or another.</p>



<p><strong>RANGANATHAN:</strong> I want to point out we are also planning to open source this and you hope to work with people, you know, to get it in the hands of people who need it and could benefit from it most, right.</p>



<p><strong>BUSHESKA:</strong> Absolutely.</p>



<p><strong>RANGANATHAN: </strong>So that&#8217;s a great direction. I think every year our undergraduate researchers set a new bar in my life expectations. And I thank you for that. This year is another bump up. So, yeah, you are a senior, Angela. What&#8217;s next for you, and what&#8217;s next for your research and work?</p>



<p><strong>BUSHESKA:</strong> Yeah, so this will be a fall really spent with a lot of applications because of, like, graduate school. Definitely something that I&#8217;m looking forward, especially graduate school in this area. So we kind of spent a lot of time living in an era of GPT wrappers, and I think when there is a product out there that is really based on research, it can make a tremendous impact. As I said, I am really a person who loves to experiment and do things. So something out there is definitely either, like, having a research that is spun out of this or having perhaps a startup down the line that is based in this area and helping millions of people around the world is definitely something I&#8217;m looking forward. Because I saw the impact when you&#8217;re helping other people, and I think that is the best thing that one person can do. So I was really excited to do it with all of you this summer and obviously continuing on to open source this project obviously for feedback but also for real use. And if we can help with something, that will be amazing. Hopefully getting these out to conferences around the world. And, yeah, see where it can take us.</p>



<p><strong>RANGANATHAN:</strong> Yeah, I have one last question for you. You had some interesting intern mentors, myself included, and then Bruno Silva, who sits in Brazil, Peder Olsen, and Solon Barocas. Do you have anything to say to all of them? [LAUGHS]</p>



<p><strong>BUSHESKA:</strong> Yeah, I would say a big thank-you for keeping up with my questions. As all the listeners can probably see, I&#8217;m a person who really speaks a lot, even more than needed sometimes. So I would say I had a great balance because I was in a time zone that was between Brazil and Redmond. So I would spend a lot of my mornings, especially in the beginning—huge shoutout to Bruno for dealing with all of my technical questions [LAUGHS]. It was my first time setting up a lot of research clusters. We should not forget also the people at Microsoft who are dealing with all of the GPUs and stuff because I think that managing all of these researchers for all the people out there is a hard job. So having a chance to communicate and also understand. Even though I study electrical engineering, I never had a chance to deeply understand how they&#8217;re used in real life. Speaking also with people from all different walks of life because Peder, my other mentor, was someone who has been really experienced in this area, so he would reference projects from I don&#8217;t know how many years, and it was, like, so fun to see the history, to see his previous experiences come to life. You don&#8217;t every single day get to have like three or four mentors from all different areas and aspects. So I&#8217;m really grateful that I had a chance to talk and also get called when things were not right so we can make them better and more correct for the people that will use this project.</p>



<p><strong>RANGANATHAN:</strong> I&#8217;ll tell them you said thank you. So, Angela, I think we are coming to a close here. Thank you so much for taking the time to share your experience with us. It&#8217;s been a pleasure to work with you, and I really look forward to seeing what the future holds for you and what amazing things you&#8217;re going to achieve. So thank you. Closing out.</p>



<p>[MUSIC]&nbsp;</p>



<p><strong>BUSHESKA:</strong> Thank you so much. Really appreciate to have this opportunity. And for everyone that is, like, working in this area, for every future intern that is doubting themselves, feel free to find me out there and, like, ask. Always happy to help people, always happy to chat sustainability with people. So thank you so much.</p>



<p>[MUSIC FADES]</p>

				</span>
			</div>
			<button class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle" type="button">
				Show more			</button>
		</div>
	</div>
</div>
</div>



<hr class="wp-block-separator has-alpha-channel-opacity" />



<p><a href="#_ftnref1" id="_ftn1">[1]<span class="sr-only"> (opens in new tab)</span></a> For more information, see <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://environment.ec.europa.eu/topics/forests/deforestation/regulation-deforestation-free-products_en" rel="noreferrer noopener" target="_blank">&#8220;Regulation on Deforestation-free products&#8221; on the European Commission website<span class="sr-only"> (opens in new tab)</span></a>.</p>
<span class="sr-only" id="label-external-link">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/podcast/intern-insights-vaishnavi-ranganathan-with-angela-busheska/">Intern Insights: Vaishnavi Ranganathan with Angela Busheska</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>

]]></content:encoded>
<pubDate>Thu, 24 Oct 2024 15:14:56 +0000</pubDate>
<pubDate>Thu, 24 Oct 2024 15:14:56 +0000</pubDate>
</item>
<item>
<title>微软研究新进展：安全培训决策树与音频内容检测</title>
<link>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-october-7-2024/</link>
<guid>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-october-7-2024/</guid>
<content:encoded><![CDATA[

  <div><p style=color:gray;>微软的研究成果提升了决策树的训练效率和音频内容检测的准确性。</p><br><br><p><strong>摘要：</strong> 微软最新研究工作集中在安全高效地训练决策树和改进音频内容检测两方面。研究者提出了一种新协议，显著降低了决策树训练的通信复杂度，达到了比当前最好方法更优的表现。此外，微软的研究团队还提出了一种创新的多标签音频分类方法，通过自我标签校正和数据增强来应对标签噪声，从而提升多音频内容检测任务的实际精度。这些研究展示了在数据隐私与准确性的平衡下，如何有效利用新技术推动机器学习领域的发展。</p><br><br><p><em>使用 gpt-4o-mini 生成 </em></p><a href=https://www.microsoft.com/en-us/research/blog/research-focus-week-of-october-7-2024/ target="_blank">查看原文</a></div>

]]></content:encoded>
<pubDate>Wed, 09 Oct 2024 16:00:00 +0000</pubDate>
<pubDate>Wed, 09 Oct 2024 16:00:00 +0000</pubDate>
</item>
<item>
<title>通过AI优化数据可视化的交互方式</title>
<link>https://www.microsoft.com/en-us/research/blog/data-formulator-exploring-how-ai-can-help-analysts-create-rich-data-visualizations/</link>
<guid>https://www.microsoft.com/en-us/research/blog/data-formulator-exploring-how-ai-can-help-analysts-create-rich-data-visualizations/</guid>
<content:encoded><![CDATA[

  <div><p style=color:gray;>文章探讨了利用AI增强数据可视化工具用户互动的潜力。</p><br><br><p><strong>摘要：</strong> 本文介绍了一项研究项目——数据制作者（Data Formulator），旨在通过结合用户界面交互和自然语言输入来简化数据可视化的过程。数据制作者允许数据分析师通过拖放数据字段和定义新字段的方式创建图表，提供了一种迭代的解决方案，能够提高工作效率。在每次创建或修改图表时，系统分为生成Vega-Lite脚本、处理数据转换和创建图表三个步骤，提升用户体验和AI性能。本文还探讨了未来发展方向，如如何利用AI清理非结构化数据，以及辅助用户设定数据分析目标的挑战。</p><br><br><p><em>使用 gpt-4o-mini 生成 </em></p><a href=https://www.microsoft.com/en-us/research/blog/data-formulator-exploring-how-ai-can-help-analysts-create-rich-data-visualizations/ target="_blank">查看原文</a></div>

]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 16:00:00 +0000</pubDate>
<pubDate>Tue, 01 Oct 2024 16:00:00 +0000</pubDate>
</item>
<item>
<title>RadEdit：一种用于改善生物医学图像编辑的工具</title>
<link>https://www.microsoft.com/en-us/research/blog/stress-testing-biomedical-vision-models-with-radedit-a-synthetic-data-approach-for-robust-model-deployment/</link>
<guid>https://www.microsoft.com/en-us/research/blog/stress-testing-biomedical-vision-models-with-radedit-a-synthetic-data-approach-for-robust-model-deployment/</guid>
<content:encoded><![CDATA[

  <div><p style=color:gray;>RadEdit通过生成合成X光图像提升生物医学图像模型的可靠性。</p><br><br><p><strong>摘要：</strong> 本研究介绍了RadEdit，一个用于改善生物医学图像编辑的工具，旨在解决数据集挑战并提高模型测试的可靠性。RadEdit利用生成图像编辑技术，模拟不同的数据集变化，帮助研究人员识别模型潜在的弱点。通过使用文本提示和二进制掩膜，RadEdit能够精确控制图像修改，确保生成的合成数据没有伪相关问题。同时，RadEdit还可以用于应对多模态任务，未来可能扩展到生成放射学报告等复杂应用。该工具为生物医学研究社区提供了显著优势，有助于在临床设置中确保模型的可靠性与安全性。</p><br><br><p><em>使用 gpt-4o-mini 生成 </em></p><a href=https://www.microsoft.com/en-us/research/blog/stress-testing-biomedical-vision-models-with-radedit-a-synthetic-data-approach-for-robust-model-deployment/ target="_blank">查看原文</a></div>

]]></content:encoded>
<pubDate>Mon, 30 Sep 2024 19:00:00 +0000</pubDate>
<pubDate>Mon, 30 Sep 2024 19:00:00 +0000</pubDate>
</item>
<item>
<title>Find My Things：帮助盲人和低视力人士的可个性化 AI 工具</title>
<link>https://www.microsoft.com/en-us/research/podcast/abstracts-september-30-2024/</link>
<guid>https://www.microsoft.com/en-us/research/podcast/abstracts-september-30-2024/</guid>
<content:encoded><![CDATA[

  <div><p style=color:gray;>Find My Things 是个性化的物品识别工具，帮助盲人识别个人物品。</p><br><br><p><strong>摘要：</strong> Find My Things 是微软研究团队开发的一款可个性化的 AI 物品识别工具，专为盲人和低视力人士设计。用户通过上传少量视频来训练 AI，以便于识别特定的个人物品，如钥匙或眼镜。该工具被纳入 Seeing AI 应用程序中，用户可以在教学阶段录制短视频，在寻找阶段根据声音和触觉提示找到物品。项目受到 Fast Company 的认可，并突显出参与式研究和社区合作的重要性，为无障碍技术的发展提供了新思路。</p><br><br><p><em>使用 gpt-4o-mini 生成 </em></p><a href=https://www.microsoft.com/en-us/research/podcast/abstracts-september-30-2024/ target="_blank">查看原文</a></div>

]]></content:encoded>
<pubDate>Mon, 30 Sep 2024 13:02:05 +0000</pubDate>
<pubDate>Mon, 30 Sep 2024 13:02:05 +0000</pubDate>
</item>
<item>
<title>微软研究论坛：多模态AI模型与计算机创新的前沿探讨</title>
<link>https://www.microsoft.com/en-us/research/blog/microsoft-research-forum-episode-4-the-future-of-multimodal-models-a-new-small-language-model-and-other-ai-updates/</link>
<guid>https://www.microsoft.com/en-us/research/blog/microsoft-research-forum-episode-4-the-future-of-multimodal-models-a-new-small-language-model-and-other-ai-updates/</guid>
<content:encoded><![CDATA[

  <div><p style=color:gray;>微软研究论坛探讨了多模态AI模型和新型计算机在不同领域的应用与挑战。</p><br><br><p><strong>摘要：</strong> 微软研究论坛持续交流了关于通用AI时代的科学与技术研究，重点讨论了先进的多模态AI模型、AI评估的高级基准以及一种全新类型的计算机。论坛中，研究人员展示了Phi-3-Vision这一开源多模态模型，并讨论了其在语言与视觉结合方面的应用潜力。与会者还探讨了多模态模型在精准健康、游戏智能等领域的转型潜力。讨论包括自我改善语言模型的挑战、新一代模拟光计算机及其提高AI推理效率的能力等。总之，论坛强调了科技创新在气候变化监测和生物分子生成等各个领域的重要性及挑战。</p><br><br><p><em>使用 gpt-4o-mini 生成 </em></p><a href=https://www.microsoft.com/en-us/research/blog/microsoft-research-forum-episode-4-the-future-of-multimodal-models-a-new-small-language-model-and-other-ai-updates/ target="_blank">查看原文</a></div>

]]></content:encoded>
<pubDate>Thu, 26 Sep 2024 12:15:00 +0000</pubDate>
<pubDate>Thu, 26 Sep 2024 12:15:00 +0000</pubDate>
</item>
<item>
<title>微软研究中心最新成果与实习机会综述</title>
<link>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-september-23-2024/</link>
<guid>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-september-23-2024/</guid>
<content:encoded><![CDATA[

  <div><p style=color:gray;>微软研究中心发布了多项新研究成果及实习机会。</p><br><br><p><strong>摘要：</strong> 微软研究中心发布了几项重要的研究成果，包括针对时间序列预测的ProbTS平台和用于信息检索的SynDL大型合成测试集合。这些研究旨在提高时间序列预测的准确性和效率，并通过合成标签降低数据集构建成本。此外，还有一项关于为大型语言模型工作负载设计智能路由器的研究，旨在提高性能和降低延迟。与此同时，微软研究中心还开放了2025年夏季本科实习生计划，邀请热爱科技的大学生申请，特别鼓励来自工程和计算机科学领域弱势群体的候选人参与。</p><br><br><p><em>使用 gpt-4o-mini 生成 </em></p><a href=https://www.microsoft.com/en-us/research/blog/research-focus-week-of-september-23-2024/ target="_blank">查看原文</a></div>

]]></content:encoded>
<pubDate>Wed, 25 Sep 2024 16:00:00 +0000</pubDate>
<pubDate>Wed, 25 Sep 2024 16:00:00 +0000</pubDate>
</item>
<item>
<title>Eureka: Evaluating and understanding progress in AI</title>
<link>https://www.microsoft.com/en-us/research/blog/eureka-evaluating-and-understanding-progress-in-ai/</link>
<guid>https://www.microsoft.com/en-us/research/blog/eureka-evaluating-and-understanding-progress-in-ai/</guid>
<content:encoded><![CDATA[

  <figure class="wp-block-image aligncenter size-full"><img alt="A summary of insights extracted by using the Eureka framework, shown via two radar charts for multimodal (left) and language (right) capabilities respectively. The radar charts show the best and worst performance observed for each capability." class="wp-image-1084362" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/09/NEWEureka-2024-BlogHeroFeature-1400x788-1.jpg" width="1400" /></figure>



<p>In the fast-paced progress of AI, the question of how to evaluate and understand capabilities of state-of-the-art models is timelier than ever. New and capable models are being released frequently, and each release promises the next big leap in frontiers of intelligence. Yet, as researchers and developers, often we ask ourselves: Are these models all comparable, if not the same, in terms of capabilities? There are, of course, strong reasons to believe they are, given that many score similarly in standard benchmarks. In addition, rankings in the numerous leaderboards do not offer a consistent and detailed explanation of why a model is ranked slightly better than others. However, if some models are fundamentally different, what are their strengths and weaknesses? More importantly, are there capabilities that are essential for making AI useful in the real world but still universally challenging for most models? Answering such questions helps us understand where we are on the frontier of AI, and what capability improvements are needed to meet the expectations that humanity and science have for safe and responsible deployments of AI models.&nbsp;</p>



<p>The prevalence of these models is dependent on our ability to mature the science of in-depth AI evaluation and measurement. In our latest open-source release and technical report <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://aka.ms/eureka-ml-insights-report" rel="noreferrer noopener" target="_blank">EUREKA: Evaluating and Understanding Large Foundation Models<span class="sr-only"> (opens in new tab)</span></a>, we start answering these questions by running an in-depth measurement analysis across 12 state-of-the-art proprietary and open-weights models. Behind this analysis stands <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/eureka-ml-insights" rel="noreferrer noopener" target="_blank">Eureka<span class="sr-only"> (opens in new tab)</span></a>, an open-source framework for standardizing evaluations of large foundation models, beyond single-score reporting and rankings. The framework currently supports both language and multimodal (text and image) data and enables developers to define custom pipelines for data processing, inference, and evaluation, with the possibility to inherit from existing pipelines and minimize development work. Eureka and all our evaluation pipelines are available as open source to foster transparent and reproducible evaluation practices. We hope to collaborate with the open-source community to share and expand current measurements for new capabilities and models.&nbsp;</p>



<h2 class="wp-block-heading" id="focus-on-challenging-and-non-saturated-capabilities">Focus on challenging and non-saturated capabilities</h2>



<p>Eureka tests models across a rich collection of fundamental language and multimodal capabilities that are challenging for even the most advanced models, but are often overlooked by standard benchmarks commonly reported in model releases. In practice, this also means that our analysis intentionally does not pivot on oversaturated benchmarks. As unconventional as this may sound, it is motivated by two reasons. First, measurement on saturated benchmarks, for which most models perform over 95%, leaves very little space for failure analysis and model comparison. Second, even though saturation may be rooted in genuine model improvements, concerns about memorization and overfitting to labeling errors lower the credibility of measurements, especially in the very high accuracy regime.&nbsp;</p>



	<div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide">
		

		<p class="msr-promo__label text-gray-800 text-center text-uppercase">
		<span class="px-4 bg-white display-inline-block font-weight-semibold small">Spotlight: On-demand video</span>
	</p>
	
	<div class="row pt-3 pb-4 align-items-center">
						<div class="msr-promo__media col-12 col-md-5">
				<a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/blog/ai-explainer-foundation-models-and-the-next-era-of-ai/" target="_blank">
					<img alt="a screenshot of a computer screen shot of a man" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/03/AIEx01_blog_hero_1400x788.png" />
				</a>
			</div>
			
			<div class="msr-promo__content p-3 px-5 col-12 col-md">

									<h2 class="h4">AI Explainer: Foundation models ​and the next era of AI</h2>
				
								<p class="large">Explore how the transformer architecture, larger models and more data, and in-context learning have helped advance AI from perception to creation.</p>
				
								<div class="wp-block-buttons justify-content-center justify-content-md-start">
					<div class="wp-block-button">
						<a class="btn btn-brand glyph-append glyph-append-chevron-right" href="https://www.microsoft.com/en-us/research/blog/ai-explainer-foundation-models-and-the-next-era-of-ai/" target="_blank">
							Watch video						</a>
					</div>
				</div>
							</div><!--/.msr-promo__content-->
	</div><!--/.msr-promo__inner-wrap-->
<span class="sr-only" id="label-external-link">Opens in a new tab</span>	</div><!--/.msr-promo-->
	


<h2 class="wp-block-heading" id="beyond-single-score-measurements-and-universal-rankings">Beyond single-score measurements and universal rankings</h2>



<p>Even though rankings and leaderboards remain the quickest way to compare models, they rarely uncover important conditions of failure. Due to overreliance on single-score aggregations of performance, the more nuanced comparative findings are hidden behind small differences between model scores aggregated across many capabilities and experimental conditions.</p>



<p>As we show in our study, the chase after these rankings has created surprising dynamics that do not necessarily lead to identical models, but to models that use different complementary skills to achieve comparable overall scores in important leaderboards. Imagine you are a triathlon athlete aiming to achieve an elite performance, which historically takes around two hours. Despite your ambition to hit this top-tier mark, you face constraints with limited time and resources for training and preparation. In practice, athletes often focus their best resources on excelling in certain disciplines while aiming for a satisfactory performance in others. They prioritize based on what they believe is most achievable given their time and experience.</p>



<p>We observe similar phenomena in the set of 12 models we study. Even if two models may score very closely for the same capability, disaggregating that performance across disciplines and input conditions shows that each model has its own complementary strengths. Identifying, measuring, and understanding these strengths for a single model is needed for planning targeted improvements. Repeating this process for a large set of models, as we do in Eureka, is needed for identifying the hypothetical frontier, guiding research and development, and creating a model that combines and delivers capabilities that build on the strengths observed in existing models.&nbsp;</p>



<h2 class="wp-block-heading" id="measuring-consistency-non-determinism-and-backward-compatibility">Measuring consistency: non-determinism and backward compatibility</h2>



<p>When people work with collaborators or when they choose tools to assist them in everyday tasks, predictability and consistency are key to a successful collaboration. Similarly, humans and application developers expect their AI assistants and models to be consistent over time for similar inputs and interactions. In our analysis, we study this under-explored angle of model performance, by focusing on two key aspects: the determinism of answer outcomes for identical examples and prompts, and the backward compatibility of model answers at the example level after a model has been updated with a new version. Lack of consistency in either of these domains would lead to breaking trust with users and application developers.&nbsp;</p>



<p>The analysis shows surprising results and opens new considerations for improvement. For example, we observe that very few large foundation models are fully deterministic and for most of them there are visible variations in the output — and most importantly in accuracy — when asked the same question several times, with generation temperature set to zero—a control that tells models to minimize randomness in generations. In addition, when comparing new model releases with earlier models from the same family, a significant amount of regress at the example level can be observed after the update, even though the overall accuracy may increase. In practice, this type of inconsistency can be frustrating for application developers who rely on prewritten examples and prompts propagated to a foundation model.&nbsp;</p>



<h2 class="wp-block-heading" id="eureka-insights">Eureka Insights</h2>



<p>Figure 1 is a high-level illustration of the current state of AI for Eureka-Bench, highlighting the best and the worst performances across various capabilities. These results reveal a nuanced picture of different models’ strengths, showing that no single model excels in all tasks. However, Claude 3.5 Sonnet, GPT-4o 2024-05-13, and Llama 3.1 405B consistently outperform others in several key areas.</p>



<figure class="wp-block-image aligncenter size-full"><img alt="A summary of insights extracted by using the Eureka framework, shown via two radar charts for multimodal (left) and language (right) capabilities respectively. The radar charts show the best and worst performance observed for each capability. " class="wp-image-1085124" height="3246" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/09/Eureka-Sept-16.png" width="5601" /><figcaption class="wp-element-caption"><em>Figure <em>1</em> &#8211; Performance of best and worse models for multimodal (left) and language (right) datasets in in Eureka-Bench. The <span style="color: #ff0000;">red</span> frontier shows the performance of the worse model, indicating the area that is already solved for the set of capabilities. The <span style="color: #008000;">green</span> frontier shows the performance of the best model, indicating the best-known result with current technology. The <span style="color: #0000FF;">blue</span> horizon between the best model and the maximum performance shows the room for improvement for mastering the capability. The best performance sets indicated in the green border include all models that perform within 2% of the best observed result.&nbsp;</em></figcaption></figure>



<h3 class="wp-block-heading" id="multimodal-capabilities">Multimodal capabilities</h3>



<p>Evaluation in Eureka reveals that state-of-the-art models are still fairly limited in their multimodal abilities, specifically when it comes to detailed image understanding (for example, localization of objects, geometric and spatial reasoning, and navigation), which is most needed in truly multimodal scenarios that require physical awareness, visual grounding, and localization.&nbsp;</p>



<ol class="wp-block-list">
<li><strong>State-of-the-art multimodal models struggle with geometric reasoning.&nbsp;</strong><br />Models perform worse in reasoning about height than about depth. Claude 3.5 Sonnet and Gemini 1.5 Pro are the best performing models for this task, with Claude 3.5 Sonnet being the most accurate model for depth ordering, and Gemini 1.5 Pro the most accurate for height ordering.&nbsp;</li>



<li><strong>Multimodal capabilities lag language capabilities.&nbsp;</strong><br />On tasks that can be described either as multimodal or as language-only, the performance of most tested models is higher for the language-only condition. GPT-4o 2024-05-13 is the only model that consistently achieves better results when presented with both vision and language information, showing therefore that it can better fuse the two data modalities.</li>



<li><strong>Complementary performance across models for fundamental multimodal skills</strong>.<br />Claude 3.5 Sonnet, GPT-4o 2024-05-13, and GPT-4 Turbo 2024-04-09 have comparable performance in multimodal question answering (MMMU). In tasks like object recognition and visual prompting, the performance of Claude 3.5 Sonnet is better or comparable to GPT-4o 2024-05-13, but Gemini 1.5 Pro outperforms them both. Finally, in tasks like object detection and spatial reasoning, GPT-4o 2024-05-13 is the most accurate model.&nbsp;</li>
</ol>



<h3 class="wp-block-heading" id="language">Language</h3>



<p>The evaluation through Eureka shows that there have been important advances from state-of-the-art models in the language capabilities of instruction following, long context question answering, information retrieval, and safety. The analysis also discovers major differences and gaps between models related to robustness to context length, factuality and grounding for information retrieval, and refusal behavior.&nbsp;</p>



<ol class="wp-block-list">
<li><strong>Faster improvements in instruction following across all model families.&nbsp;</strong><br />Instruction following is the ability to follow guidance expressed in user prompts regarding specifications related to format, style, and structure of the generated content. Among the studied language capabilities, instruction following is where most models are improving faster, potentially due to strong investments in instruction tuning processes, with most models now having an instruction following rate of higher than 75%.&nbsp;</li>



<li><strong>All models’ performance in question answering drops with longer context.</strong>&nbsp;<br />Contrary to “needle-in-a-haystack” experiments, testing state-of-the-art models on tasks that involve reasoning over long context shows significant decline in performance as context size grows. Amongst all models, GPT-4o 2024-05-13 and Llama 3.1 405B have the lowest drop in performance for longer context.</li>



<li><strong>Major gaps in factuality and grounding for information retrieval from parametric knowledge or input context.&nbsp;</strong><br />Models exhibit query fact precision rates of lower than 55%, fact recall rates of lower than 25%, and rates of irrelevant and fabricated information above 20%.&nbsp;Llama 3.1 405B, GPT-4o 2024-05-13, and Claude 3.5 Sonnet are the top performers in this area across different conditions.</li>



<li><strong>High refusal rates. Lower accuracy in detecting toxic content vs. neutral content for most models.&nbsp;</strong><br />While several models have high accuracy rates for toxicity detection, others (Gemini 1.5 Pro, Claude 3.5 Sonnet, Claude 3 Opus, and Llama 3.1 405B) exhibit low accuracy in classifying toxic content and a high refusal rate to classify toxic or neutral context, both of which make toxic content difficult to detect. During the safe language generation evaluation, models like GPT-4 1106 Preview and Mistral Large 2407 have the highest toxicity rates. GPT-4o 2024-05-13 is the only model that has both a high toxicity detection accuracy and a low toxicity score for safe language generation.&nbsp;</li>
</ol>



<h3 class="wp-block-heading" id="non-determinism">Non-determinism</h3>



<p><strong>Several models have highly non-deterministic output for identical runs.</strong> Gemini 1.5 Pro, GPT-4 1106<strong> </strong>Preview, GPT-4 Vision Preview, and GPT-4 Turbo 2024-04-09 show high non-determinism of outcomes. These results raise important questions regarding the stability of user and developer experiences when repeatedly inferencing with identical queries using the same prompt templates. Llama 3 70B, Llama 3.1 70B, and Mistral Large 2407 are almost perfectly deterministic.&nbsp;</p>



<h3 class="wp-block-heading" id="backward-compatibility">Backward compatibility</h3>



<p><strong>Backward incompatibility for shifts within the same model family is prevalent across all state-of-the-art models.</strong> This is reflected in high regression rates for individual examples and at a subcategory level. This type of regression can break trust with users and application developers during model updates. Regression varies per task and metric, but we observe several cases when it is higher than 10% across three model families (Claude, GPT, Llama), and sometimes they can dominate progress rates for whole subcategories of data.&nbsp;</p>



<h2 class="wp-block-heading" id="conclusion">Conclusion</h2>



<p>The complementary results extracted from this study highlight opportunities for improving current models across various areas, aiming to match the performance of the best model for each individual capability in this challenge set. However, several tasks in the challenge set remain difficult even for the most capable models. It is crucial to discuss and explore whether these gaps can be addressed with current technologies, architectures, and data synthesis protocols.</p>



<p>Finally, Eureka and the set of associated benchmarks are only the initial snapshot of an effort that aims at reliably measuring progress in AI. Our team is excited about further collaborations with the open-source community and research, with the goal of sharing and extending current measurements for new capabilities and models.&nbsp;</p>
<span class="sr-only" id="label-external-link">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/blog/eureka-evaluating-and-understanding-progress-in-ai/">Eureka: Evaluating and understanding progress in AI</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>

]]></content:encoded>
<pubDate>Tue, 17 Sep 2024 16:00:00 +0000</pubDate>
<pubDate>Tue, 17 Sep 2024 16:00:00 +0000</pubDate>
</item>
<item>
<title>微软研究聚焦：探索大型语言模型与语音合成的新研究动态</title>
<link>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-september-9-2024/</link>
<guid>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-september-9-2024/</guid>
<content:encoded><![CDATA[

  <div><p style=color:gray;>本文汇总微软研究团队关于大型语言模型和语音合成的最新研究成果。</p><br><br><p><strong>摘要：</strong> 本篇文章介绍了微软研究团队发布的几项关键研究，涉及大型语言模型（LLMs）在安全性方面的脆弱性、语音合成系统中的总时长感知建模等。研究表明，LLMs面临包括提示注入和越狱攻击在内的多种攻击风险，强调识别和缓解这些风险的重要性。同时，在文本转语音（TTS）研究中，提出了一种新型的总时长感知模型（TDA），能够在保证语音质量的情况下，精确调整合成语音的总时长。此外，还有针对5G前传网络安全性的研究，展示了缺乏完整性保护可能导致的严重攻击，使得网络用户的性能受到显著影响。这些研究为相关技术的发展和应用提供了重要的理论支持与实践指导。</p><br><br><p><em>使用 gpt-4o-mini 生成 </em></p><a href=https://www.microsoft.com/en-us/research/blog/research-focus-week-of-september-9-2024/ target="_blank">查看原文</a></div>

]]></content:encoded>
<pubDate>Thu, 12 Sep 2024 16:00:00 +0000</pubDate>
<pubDate>Thu, 12 Sep 2024 16:00:00 +0000</pubDate>
</item>
<item>
<title>MedFuzz：提升大语言模型在医疗问答中的实用性</title>
<link>https://www.microsoft.com/en-us/research/blog/medfuzz-exploring-the-robustness-of-llms-on-medical-challenge-problems/</link>
<guid>https://www.microsoft.com/en-us/research/blog/medfuzz-exploring-the-robustness-of-llms-on-medical-challenge-problems/</guid>
<content:encoded><![CDATA[

  <div><p style=color:gray;>MedFuzz通过挑战假设，提高大语言模型的医疗问答能力。</p><br><br><p><strong>摘要：</strong> MedFuzz是一种新兴的对抗性机器学习方法，旨在揭示大语言模型（LLMs）在医疗问答基准测试中的局限性。尽管现有的医疗基准如MedQA在效率上表现良好，但它们通常基于简化的假设，无法反映真实临床场景的复杂性。通过识别并挑战这些假设，MedFuzz将医疗问答的水平推向更真实的环境，从而更好地评估和提升LLMs的应用能力。研究显示，针对具体患者特征的考察以及不断的对抗性迭代，可以有效呈现LLMs在真实世界情境下的表现和脆弱性，为未来的医疗决策提供更可靠的工具和支持。</p><br><br><p><em>使用 gpt-4o-mini 生成 </em></p><a href=https://www.microsoft.com/en-us/research/blog/medfuzz-exploring-the-robustness-of-llms-on-medical-challenge-problems/ target="_blank">查看原文</a></div>

]]></content:encoded>
<pubDate>Tue, 10 Sep 2024 16:00:00 +0000</pubDate>
<pubDate>Tue, 10 Sep 2024 16:00:00 +0000</pubDate>
</item>

</channel>
</rss>