------------------------------------------------------
Started: 2024-10-13 17:10:56.094056
Existing_entries: 0
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1500
Summarized using gpt-4o-mini
Append: [利用加速偏好优化加快人类反馈下的强化学习](https://arxiv.org/abs/2410.06293)
Token length: 1022
Summarized using gpt-4o-mini
Append: [Data Advisor：提升数据生成质量的增强LLM方法](https://arxiv.org/abs/2410.05269)
Token length: 1603
Summarized using gpt-4o-mini
Append: [基于神经符号学习的LLM世界模型对齐与探索](https://arxiv.org/abs/2410.07484)
Token length: 1104
Summarized using gpt-4o-mini
Append: [向量-内联学习：扩展大型语言模型的能力](https://arxiv.org/abs/2410.05629)
Token length: 1300
Summarized using gpt-4o-mini
Append: [Zebra：一种新型生成自回归变换器用于解决时间依赖性参数偏微分方程](https://arxiv.org/abs/2410.03437)
Token length: 1092
Summarized using gpt-4o-mini
Append: [DART：一种新型的非马尔可夫扩散模型](https://arxiv.org/abs/2410.08159)
Token length: 1050
Summarized using gpt-4o-mini
Append: [大型语言模型的任务超叠现象及其内在机制研究](https://arxiv.org/abs/2410.05603)
Token length: 1427
Summarized using gpt-4o-mini
Append: [自动化基准测试中的作弊现象及其影响](https://arxiv.org/abs/2410.07137)
Token length: 1340
Summarized using gpt-4o-mini
Append: [LPZero：自动设计零成本代理的框架](https://arxiv.org/abs/2410.04808)
Token length: 1449
Summarized using gpt-4o-mini
Append: [GLOV：利用大语言模型优化视觉语言模型的隐式优化方法](https://arxiv.org/abs/2410.06154)
Token length: 1393
Summarized using gpt-4o-mini
Append: [WorFBench：一个用于评估工作流生成能力的统一基准](https://arxiv.org/abs/2410.07869)
Token length: 1305
Summarized using gpt-4o-mini
Append: [基于运动先验的变形3D高斯点云重建框架MotionGS](https://arxiv.org/abs/2410.07707)
Token length: 1817
Summarized using gpt-4o-mini
Append: [基于数学推理和代码生成的数学继续预训练方法](https://arxiv.org/abs/2410.08196)
Token length: 1841
Summarized using gpt-4o-mini
Append: [SFTMix: 基于Mixup的指令调优方法研究](https://arxiv.org/abs/2410.05248)
Token length: 1329
Summarized using gpt-4o-mini
Append: [Agent S: 基于多模态大语言模型的自主交互框架](https://arxiv.org/abs/2410.08164)
Token length: 1722
Summarized using gpt-4o-mini
Append: [大语言与视觉模型（LLVMs）的感知能力研究](https://arxiv.org/abs/2410.04751)
Token length: 1273
Summarized using gpt-4o-mini
Append: [AlphaLLM-CPL：一种基于MCTS行为蒸馏的自我改进框架](https://arxiv.org/abs/2410.06508)
Token length: 951
Summarized using gpt-4o-mini
Append: [自回归视频扩散模型的进展及应用](https://arxiv.org/abs/2410.08151)
Token length: 1424
Summarized using gpt-4o-mini
Append: [大卷积核在现代卷积神经网络设计中的应用](https://arxiv.org/abs/2410.08049)
Token length: 1582
Summarized using gpt-4o-mini
Append: [简化和扩展扩散模型 rectification 的新策略](https://arxiv.org/abs/2410.07303)
Token length: 1323
Summarized using gpt-4o-mini
Append: [基于偏好学习的多模态轨迹检索增强方法](https://arxiv.org/abs/2410.03450)
Token length: 1369
Summarized using gpt-4o-mini
Append: [PrefixQuant：一种高效的稀疏化量化技术用于大型语言模型的推理加速](https://arxiv.org/abs/2410.05265)
Token length: 1676
Summarized using gpt-4o-mini
Append: [Optima：提升大语言模型多智能体系统通信效率与任务有效性的框架](https://arxiv.org/abs/2410.08115)
Token length: 888
Summarized using gpt-4o-mini
Append: [重复训练示例在变压器模型中的效益研究](https://arxiv.org/abs/2410.07041)
Token length: 1161
Summarized using gpt-4o-mini
Append: [基于局部对抗负例损失的视觉语言模型增强方法](https://arxiv.org/abs/2410.05210)
Token length: 983
Summarized using gpt-4o-mini
Append: [DICE：用于可控编辑的离散反演方法](https://arxiv.org/abs/2410.08207)
append_entries: 26
Finish: 2024-10-13 17:14:57.885928
------------------------------------------------------
Started: 2024-10-13 18:01:19.275531
Existing_entries: 26
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-13 18:01:19.455683
------------------------------------------------------
Started: 2024-10-13 21:00:58.752846
Existing_entries: 26
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-13 21:00:58.923574
------------------------------------------------------
Started: 2024-10-14 00:35:45.371870
Existing_entries: 26
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-14 00:35:45.457562
------------------------------------------------------
Started: 2024-10-14 03:17:28.552221
Existing_entries: 26
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-14 03:17:28.635374
------------------------------------------------------
Started: 2024-10-14 06:11:06.727934
Existing_entries: 26
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1388
Summarized using gpt-4o-mini
Append: [VITask：提升大型视觉语言模型任务适应性的框架](https://arxiv.org/abs/2410.06456)
Token length: 1070
Summarized using gpt-4o-mini
Append: [增强大型语言模型的长度控制与复制粘贴能力](https://arxiv.org/abs/2410.07035)
Token length: 1401
Summarized using gpt-4o-mini
Append: [Meissonic：高效的非自回归文本到图像建模](https://arxiv.org/abs/2410.08261)
Token length: 1022
Summarized using gpt-4o-mini
Append: [Baichuan-Omni：首个开源7B多模态大语言模型](https://arxiv.org/abs/2410.08565)
Token length: 1608
Summarized using gpt-4o-mini
Append: [基于语义得分蒸馏采样的复杂3D内容生成研究](https://arxiv.org/abs/2410.09009)
Token length: 1754
Summarized using gpt-4o-mini
Append: [SuperCorrect：一种改进小型模型推理能力的两阶段框架](https://arxiv.org/abs/2410.09008)
Token length: 1717
Summarized using gpt-4o-mini
Append: [EvolveDirector：基于公共资源训练文本到图像生成模型的框架](https://arxiv.org/abs/2410.07133)
append_entries: 7
Finish: 2024-10-14 06:13:10.138301
------------------------------------------------------
Started: 2024-10-14 09:00:49.927237
Existing_entries: 33
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 953
Summarized using gpt-4o-mini
Append: [多智能体协作数据选择机制在大型语言模型预训练中的应用](https://arxiv.org/abs/2410.08102)
Token length: 1118
Summarized using gpt-4o-mini
Append: [StructRAG：基于结构化知识增强大语言模型的推理能力](https://arxiv.org/abs/2410.08815)
Token length: 1520
Summarized using gpt-4o-mini
Append: [通过KV预测减少变换器模型的首次输出时间](https://arxiv.org/abs/2410.08391)
append_entries: 3
Finish: 2024-10-14 09:01:20.518015
------------------------------------------------------
Started: 2024-10-14 12:13:01.745440
Existing_entries: 36
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-14 12:13:01.838307
------------------------------------------------------
Started: 2024-10-14 16:37:54.712380
Existing_entries: 36
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1023
Summarized using gpt-4o-mini
Append: [I-Max框架：提升文本到图像RFTs的分辨率潜力](https://arxiv.org/abs/2410.07536)
Token length: 1019
Summarized using gpt-4o-mini
Append: [ZeroComp：一种有效的零样本3D物体合成方法](https://arxiv.org/abs/2410.08168)
Token length: 1053
Summarized using gpt-4o-mini
Append: [Mentor-KD：多步推理能力的知识蒸馏方法](https://arxiv.org/abs/2410.09037)
Token length: 1200
Summarized using gpt-4o-mini
Append: [SAE Match：基于稀疏自编码器的神经网络层间特征对齐](https://arxiv.org/abs/2410.07656)
Token length: 1173
Summarized using gpt-4o-mini
Append: [DA-Code：针对代理的数据科学任务的代码生成基准](https://arxiv.org/abs/2410.07331)
append_entries: 5
Finish: 2024-10-14 16:38:40.822699
------------------------------------------------------
Started: 2024-10-14 17:34:59.285214
Existing_entries: 41
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 938
Summarized using gpt-4o-mini
Append: [MiRAGeNews数据集：对抗AI生成假新闻的多模态检测](https://arxiv.org/abs/2410.09045)
append_entries: 1
Finish: 2024-10-14 17:35:08.279838
------------------------------------------------------
Started: 2024-10-14 18:09:05.554135
Existing_entries: 42
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-14 18:09:05.674064
------------------------------------------------------
Started: 2024-10-14 21:00:37.323072
Existing_entries: 42
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-14 21:00:37.471781
------------------------------------------------------
Started: 2024-10-15 00:34:13.903689
Existing_entries: 42
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1116
Summarized using gpt-4o-mini
Append: [基于计划去噪的离散扩散框架DDPD](https://arxiv.org/abs/2410.06264)
Token length: 1412
Summarized using gpt-4o-mini
Append: [Synth-SONAR：基于扩散模型与GPT提示的声纳图像合成框架](https://arxiv.org/abs/2410.08612)
Token length: 1578
Summarized using gpt-4o-mini
Append: [GenARM：一种有效的自回归奖励模型用于无重训练的大型语言模型对齐](https://arxiv.org/abs/2410.08193)
Token length: 1266
Summarized using gpt-4o-mini
Append: [利用简单分层方法提高大型语言模型生成的多样性](https://arxiv.org/abs/2410.09038)
append_entries: 4
Finish: 2024-10-15 00:35:08.354631
------------------------------------------------------
Started: 2024-10-15 03:14:57.370987
Existing_entries: 46
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-15 03:14:57.533362
------------------------------------------------------
Started: 2024-10-15 06:10:28.515778
Existing_entries: 46
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1521
Summarized using gpt-4o-mini
Append: [Animate-X：针对各种角色类型的通用动画框架](https://arxiv.org/abs/2410.10306)
Token length: 1194
Summarized using gpt-4o-mini
Append: [MEGA-Bench：一种大规模多模态评估套件](https://arxiv.org/abs/2410.10563)
Summarization failed, append the original article
error: 'NoneType' object has no attribute 'group'. Line: 363.
Append: [TVBench: Redesigning Video-Language Evaluation](https://arxiv.org/abs/2410.07752)
Token length: 1337
Summarized using gpt-4o-mini
Append: [大规模数据选择在监督微调中的关键性研究](https://arxiv.org/abs/2410.09335)
Token length: 1445
Summarized using gpt-4o-mini
Append: [LOKI: 评估大型多模态模型Synthetic Data检测能力的新基准](https://arxiv.org/abs/2410.09732)
Token length: 1750
Summarized using gpt-4o-mini
Append: [VIF-RAG：提高检索增强生成系统指令跟随对齐的自动化框架](https://arxiv.org/abs/2410.09584)
Token length: 1696
Summarized using gpt-4o-mini
Append: [MMIE：评估大型视觉语言模型的交错多模态理解与生成的基准](https://arxiv.org/abs/2410.10139)
Token length: 1231
Summarized using gpt-4o-mini
Append: [针对大型语言模型的数学推理能力的奥林匹亚级基准测试](https://arxiv.org/abs/2410.07985)
append_entries: 8
Finish: 2024-10-15 06:12:23.323317
------------------------------------------------------
Started: 2024-10-15 09:01:06.479047
Existing_entries: 54
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1601
Summarized using gpt-4o-mini
Append: [LiveXiv：基于科学ArXiv论文的可扩展实时基准测试](https://arxiv.org/abs/2410.10783)
Token length: 915
Summarized using gpt-4o-mini
Append: [问题树（ToP）：解决复杂推理任务的新方法](https://arxiv.org/abs/2410.06634)
Token length: 1320
Summarized using gpt-4o-mini
Append: [基于动态最优控制的矩形流模型图像反演与编辑](https://arxiv.org/abs/2410.10792)
Token length: 1613
Summarized using gpt-4o-mini
Append: [长时记忆评估框架：提升聊天助手的记忆能力](https://arxiv.org/abs/2410.10813)
Token length: 1629
Summarized using gpt-4o-mini
Append: [TemporalBench：评估视频中的细粒度时间理解的新基准](https://arxiv.org/abs/2410.10818)
Token length: 1016
Summarized using gpt-4o-mini
Append: [自主操作的改进型3D扩散政策（iDP3）在多样化环境下的应用](https://arxiv.org/abs/2410.10803)
Token length: 1337
Summarized using gpt-4o-mini
Append: [Cavia：一种可控相机的多视角视频生成框架](https://arxiv.org/abs/2410.10774)
append_entries: 7
Finish: 2024-10-15 09:02:14.960054
------------------------------------------------------
Started: 2024-10-15 12:12:36.872253
Existing_entries: 61
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-15 12:12:36.986809
------------------------------------------------------
Started: 2024-10-15 15:00:52.415283
Existing_entries: 61
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-15 15:00:52.790455
------------------------------------------------------
Started: 2024-10-15 18:00:42.518383
Existing_entries: 61
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-15 18:00:42.627264
------------------------------------------------------
Started: 2024-10-15 21:01:00.850579
Existing_entries: 61
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1289
Summarized using gpt-4o-mini
Append: [大语言模型中的语言结构与内部电路的对应关系研究](https://arxiv.org/abs/2410.09223)
Token length: 1476
Summarized using gpt-4o-mini
Append: [VisRAG：面向多模态文档的视觉-语言检索增强生成](https://arxiv.org/abs/2410.10594)
Token length: 1111
Summarized using gpt-4o-mini
Append: [提升大型语言模型推理能力的训练方法](https://arxiv.org/abs/2410.10630)
Token length: 1570
Summarized using gpt-4o-mini
Append: [MMCOMPOSITION：评估大规模视觉-语言模型的组合能力的新基准](https://arxiv.org/abs/2410.09733)
append_entries: 4
Finish: 2024-10-15 21:01:31.996973
------------------------------------------------------
Started: 2024-10-16 00:33:52.596737
Existing_entries: 65
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-16 00:33:52.708729
------------------------------------------------------
Started: 2024-10-16 03:16:05.116811
Existing_entries: 65
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1283
Summarized using gpt-4o-mini
Append: [探索去规范化解码器中激活函数的优化](https://arxiv.org/abs/2410.09637)
append_entries: 1
Finish: 2024-10-16 03:16:11.950736
------------------------------------------------------
Started: 2024-10-16 06:01:02.163991
Existing_entries: 66
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1367
Summarized using gpt-4o-mini
Append: [MTU-Bench：一种多粒度的大语言模型工具使用基准](https://arxiv.org/abs/2410.11710)
Token length: 1794
Summarized using gpt-4o-mini
Append: [SecCodePLT：全面评估代码生成AI安全风险的平台](https://arxiv.org/abs/2410.11096)
Token length: 1460
Summarized using gpt-4o-mini
Append: [利用多语言大模型解决低资源语言医疗数据稀缺问题](https://arxiv.org/abs/2410.10626)
Token length: 1308
Summarized using gpt-4o-mini
Append: [基于空间和角度高斯表示的实时高质量照明与视图合成](https://arxiv.org/abs/2410.11419)
append_entries: 4
Finish: 2024-10-16 06:01:36.958851
------------------------------------------------------
Started: 2024-10-16 09:01:07.039308
Existing_entries: 70
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1356
Summarized using gpt-4o-mini
Append: [RoboDual：协同的通用与专业政策机器人系统](https://arxiv.org/abs/2410.08001)
Summarization failed, append the original article
error: Invalid \escape: line 4 column 179 (char 285). Line: 363.
Append: [What Matters in Transformers? Not All Attention is Needed](https://arxiv.org/abs/2406.15786)
Token length: 1121
Summarized using gpt-4o-mini
Append: [动态修正解码方法（DeCo）在多模态大型语言模型中的应用](https://arxiv.org/abs/2410.11779)
append_entries: 3
Finish: 2024-10-16 09:01:35.653736
------------------------------------------------------
Started: 2024-10-16 12:12:25.148412
Existing_entries: 73
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1339
Summarized using gpt-4o-mini
Append: [MoE LLMs在嵌入模型中的应用研究](https://arxiv.org/abs/2410.10814)
Token length: 1191
Summarized using gpt-4o-mini
Append: [扩散模型的高效性综述：理论与实践](https://arxiv.org/abs/2410.11795)
Token length: 1601
Summarized using gpt-4o-mini
Append: [LVD-2M：用于长视频生成的新型长拍视频数据集](https://arxiv.org/abs/2410.10816)
append_entries: 3
Finish: 2024-10-16 12:13:00.325377
------------------------------------------------------
Started: 2024-10-16 15:00:56.298169
Existing_entries: 76
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1776
Summarized using gpt-4o-mini
Append: [基于COCO的互动图像抠图数据集与方法研究](https://arxiv.org/abs/2410.06593)
Token length: 1243
Summarized using gpt-4o-mini
Append: [基于LLMtimesMapReduce框架的长文本处理研究](https://arxiv.org/abs/2410.09342)
Token length: 1104
Summarized using gpt-4o-mini
Append: [互惠增强效应：文本分类中词级与文本级分类的协同关系](https://arxiv.org/abs/2410.09745)
Token length: 1325
Summarized using gpt-4o-mini
Append: [SimBa：通过注入简约偏差来提升深度强化学习的网络规模](https://arxiv.org/abs/2410.09754)
append_entries: 4
Finish: 2024-10-16 15:02:09.536494
------------------------------------------------------
Started: 2024-10-16 18:01:06.580192
Existing_entries: 80
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-16 18:01:06.665630
------------------------------------------------------
Started: 2024-10-16 21:00:53.857265
Existing_entries: 80
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1716
Summarized using gpt-4o-mini
Append: [EchoPrime：一种多视角视频基础模型用于全面心脏超声学解读](https://arxiv.org/abs/2410.09704)
Token length: 1077
Summarized using gpt-4o-mini
Append: [NesTools：评估大型语言模型的嵌套工具学习能力的新基准](https://arxiv.org/abs/2410.11805)
Token length: 1230
Summarized using gpt-4o-mini
Append: [Agent-as-a-Judge框架：针对智能体系统的新评估方法](https://arxiv.org/abs/2410.10934)
append_entries: 3
Finish: 2024-10-16 21:01:33.623967
------------------------------------------------------
Started: 2024-10-17 00:33:43.255644
Existing_entries: 83
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1166
Summarized using gpt-4o-mini
Append: [MultiVENT 2.0：多语言事件驱动的视频检索基准](https://arxiv.org/abs/2410.11619)
append_entries: 1
Finish: 2024-10-17 00:33:51.739098
------------------------------------------------------
Started: 2024-10-17 03:14:03.622023
Existing_entries: 84
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-17 03:14:03.687082
------------------------------------------------------
Started: 2024-10-17 06:00:56.658104
Existing_entries: 84
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1255
Summarized using gpt-4o-mini
Append: [ProSA：评估大型语言模型提示敏感性的框架](https://arxiv.org/abs/2410.12405)
Token length: 1062
Summarized using gpt-4o-mini
Append: [基于模型亲缘关系的高效语言模型合并策略](https://arxiv.org/abs/2410.12613)
Token length: 1458
Summarized using gpt-4o-mini
Append: [DocLayout-YOLO：一种高速高准确率的文档布局分析方法](https://arxiv.org/abs/2410.12628)
Token length: 1665
Summarized using gpt-4o-mini
Append: [长文本对齐的文本到图像生成模型的优化方法 LongAlign](https://arxiv.org/abs/2410.11817)
Token length: 1390
Summarized using gpt-4o-mini
Append: [限制因素与问题影响：语言智能体规划能力的挑战](https://arxiv.org/abs/2410.12409)
append_entries: 5
Finish: 2024-10-17 06:01:30.407776
------------------------------------------------------
Started: 2024-10-17 09:00:39.029158
Existing_entries: 89
Fetching from https://rsshub.app/huggingface/daily-papers
Summarization failed, append the original article
error: Invalid \escape: line 4 column 103 (char 188). Line: 363.
Append: [Large Language Model Evaluation via Matrix Nuclear-Norm](https://arxiv.org/abs/2410.10672)
Token length: 1422
Summarized using gpt-4o-mini
Append: [VidEgoThink：评估自我视角视频理解能力的综合基准](https://arxiv.org/abs/2410.11623)
Token length: 1854
Summarized using gpt-4o-mini
Append: [ZipVL：针对大规模视觉语言模型的高效推理框架](https://arxiv.org/abs/2410.08584)
Token length: 1271
Summarized using gpt-4o-mini
Append: [多模态模型中的幻觉问题研究：挑战与前景](https://arxiv.org/abs/2410.12787)
Token length: 1899
Summarized using gpt-4o-mini
Append: [HumanEval-V：评估大型多模态模型的视觉理解与编程能力的基准](https://arxiv.org/abs/2410.12381)
Token length: 1380
Summarized using gpt-4o-mini
Append: [跨模态时间理解的新模型与数据集研究](https://arxiv.org/abs/2410.12109)
append_entries: 6
Finish: 2024-10-17 09:01:17.183413
------------------------------------------------------
Started: 2024-10-17 12:00:48.689242
Existing_entries: 95
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-17 12:00:48.840077
------------------------------------------------------
Started: 2024-10-17 15:00:33.468237
Existing_entries: 95
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1011
Summarized using gpt-4o-mini
Append: [动态词汇头（DyVo）提升稀疏检索模型的实体识别效果](https://arxiv.org/abs/2410.07722)
Token length: 693
Summarized using gpt-4o-mini
Append: [特征在不同文本领域之间的稳定性与转变研究](https://arxiv.org/abs/2410.12391)
Token length: 1037
Summarized using gpt-4o-mini
Append: [通过逆向强化学习解读大型语言模型的隐性奖励函数](https://arxiv.org/abs/2410.12491)
Token length: 1502
Summarized using gpt-4o-mini
Append: [神经形态变换（NeuMeta）：自适应神经网络的连续权重学习](https://arxiv.org/abs/2410.11878)
Token length: 1059
Summarized using gpt-4o-mini
Append: [基于连续时间的生成模型的稳定训练与快速采样](https://arxiv.org/abs/2410.11081)
Token length: 1195
Summarized using gpt-4o-mini
Append: [WorldMedQA-V：多语言多模态医疗基准测试数据集](https://arxiv.org/abs/2410.12722)
append_entries: 6
Finish: 2024-10-17 15:01:15.928914
------------------------------------------------------
Started: 2024-10-17 18:01:04.672294
Existing_entries: 101
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1908
Summarized using gpt-4o-mini
Append: [ChroKnowBench：评估大规模语言模型的时间知识积累](https://arxiv.org/abs/2410.09870)
Token length: 1613
Summarized using gpt-4o-mini
Append: [可控安全对齐框架：满足多样化安全需求的语言模型适应性](https://arxiv.org/abs/2410.08968)
append_entries: 2
Finish: 2024-10-17 18:01:18.527387
------------------------------------------------------
Started: 2024-10-17 21:01:08.606590
Existing_entries: 103
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1695
Summarized using gpt-4o-mini
Append: [语言模型校准：应对RLHF中的过度自信现象](https://arxiv.org/abs/2410.09724)
Token length: 1788
Summarized using gpt-4o-mini
Append: [优化潜在空间的图像生成模型：DiGIT的探索](https://arxiv.org/abs/2410.12490)
append_entries: 2
Finish: 2024-10-17 21:01:20.759734
------------------------------------------------------
Started: 2024-10-18 00:33:39.298857
Existing_entries: 105
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-18 00:33:39.390609
------------------------------------------------------
Started: 2024-10-18 03:14:48.880558
Existing_entries: 105
Fetching from https://rsshub.app/huggingface/daily-papers
Summarization failed, append the original article
error: 'NoneType' object has no attribute 'group'. Line: 363.
Append: [From Commands to Prompts: LLM-based Semantic File System for AIOS](https://arxiv.org/abs/2410.11843)
Summarization failed, append the original article
error: Invalid \escape: line 4 column 71 (char 169). Line: 363.
Append: [FLARE: Faithful Logic-Aided Reasoning and Exploration](https://arxiv.org/abs/2410.11900)
append_entries: 2
Finish: 2024-10-18 03:15:03.905972
------------------------------------------------------
Started: 2024-10-18 06:00:40.849342
Existing_entries: 107
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-18 06:00:40.995030
------------------------------------------------------
Started: 2024-10-18 09:00:50.409107
Existing_entries: 107
Fetching from https://rsshub.app/huggingface/daily-papers
Summarization failed, append the original article
error: Error code: 401 - {'error': {'err_code': -10004, 'message': 'Insufficient account balance. Create your own tool, for details please view 302.AI', 'message_cn': '账户余额不足，创建属于自己的工具，更多请访问 302.AI', 'message_jp': 'アカウント残高が不足しています。独自のツールを作成するには、302.AI をご覧ください。', 'type': 'api_error'}}. Line: 363.
Append: [MuVi: Video-to-Music Generation with Semantic Alignment and Rhythmic Synchronization](https://arxiv.org/abs/2410.12957)
Summarization failed, append the original article
error: Error code: 401 - {'error': {'err_code': -10004, 'message': 'Insufficient account balance. Create your own tool, for details please view 302.AI', 'message_cn': '账户余额不足，创建属于自己的工具，更多请访问 302.AI', 'message_jp': 'アカウント残高が不足しています。独自のツールを作成するには、302.AI をご覧ください。', 'type': 'api_error'}}. Line: 363.
Append: [Do LLMs Have Political Correctness? Analyzing Ethical Biases and Jailbreak Vulnerabilities in AI Systems](https://arxiv.org/abs/2410.13334)
Summarization failed, append the original article
error: Error code: 401 - {'error': {'err_code': -10004, 'message': 'Insufficient account balance. Create your own tool, for details please view 302.AI', 'message_cn': '账户余额不足，创建属于自己的工具，更多请访问 302.AI', 'message_jp': 'アカウント残高が不足しています。独自のツールを作成するには、302.AI をご覧ください。', 'type': 'api_error'}}. Line: 363.
Append: [Janus: Decoupling Visual Encoding for Unified Multimodal Understanding and Generation](https://arxiv.org/abs/2410.13848)
Summarization failed, append the original article
error: Error code: 401 - {'error': {'err_code': -10004, 'message': 'Insufficient account balance. Create your own tool, for details please view 302.AI', 'message_cn': '账户余额不足，创建属于自己的工具，更多请访问 302.AI', 'message_jp': 'アカウント残高が不足しています。独自のツールを作成するには、302.AI をご覧ください。', 'type': 'api_error'}}. Line: 363.
Append: [MixEval-X: Any-to-Any Evaluations from Real-World Data Mixtures](https://arxiv.org/abs/2410.13754)
Summarization failed, append the original article
error: Error code: 401 - {'error': {'err_code': -10004, 'message': 'Insufficient account balance. Create your own tool, for details please view 302.AI', 'message_cn': '账户余额不足，创建属于自己的工具，更多请访问 302.AI', 'message_jp': 'アカウント残高が不足しています。独自のツールを作成するには、302.AI をご覧ください。', 'type': 'api_error'}}. Line: 363.
Append: [MoH: Multi-Head Attention as Mixture-of-Head Attention](https://arxiv.org/abs/2410.11842)
Summarization failed, append the original article
error: Error code: 401 - {'error': {'err_code': -10004, 'message': 'Insufficient account balance. Create your own tool, for details please view 302.AI', 'message_cn': '账户余额不足，创建属于自己的工具，更多请访问 302.AI', 'message_jp': 'アカウント残高が不足しています。独自のツールを作成するには、302.AI をご覧ください。', 'type': 'api_error'}}. Line: 363.
Append: [SBI-RAG: Enhancing Math Word Problem Solving for Students through Schema-Based Instruction and Retrieval-Augmented Generation](https://arxiv.org/abs/2410.13293)
Summarization failed, append the original article
error: Error code: 401 - {'error': {'err_code': -10004, 'message': 'Insufficient account balance. Create your own tool, for details please view 302.AI', 'message_cn': '账户余额不足，创建属于自己的工具，更多请访问 302.AI', 'message_jp': 'アカウント残高が不足しています。独自のツールを作成するには、302.AI をご覧ください。', 'type': 'api_error'}}. Line: 363.
Append: [LoLDU: Low-Rank Adaptation via Lower-Diag-Upper Decomposition for Parameter-Efficient Fine-Tuning](https://arxiv.org/abs/2410.13618)
Summarization failed, append the original article
error: Error code: 401 - {'error': {'err_code': -10004, 'message': 'Insufficient account balance. Create your own tool, for details please view 302.AI', 'message_cn': '账户余额不足，创建属于自己的工具，更多请访问 302.AI', 'message_jp': 'アカウント残高が不足しています。独自のツールを作成するには、302.AI をご覧ください。', 'type': 'api_error'}}. Line: 363.
Append: [VidPanos: Generative Panoramic Videos from Casual Panning Videos](https://arxiv.org/abs/2410.13832)
Summarization failed, append the original article
error: Error code: 401 - {'error': {'err_code': -10004, 'message': 'Insufficient account balance. Create your own tool, for details please view 302.AI', 'message_cn': '账户余额不足，创建属于自己的工具，更多请访问 302.AI', 'message_jp': 'アカウント残高が不足しています。独自のツールを作成するには、302.AI をご覧ください。', 'type': 'api_error'}}. Line: 363.
Append: [Movie Gen: A Cast of Media Foundation Models](https://arxiv.org/abs/2410.13720)
Summarization failed, append the original article
error: Error code: 401 - {'error': {'err_code': -10004, 'message': 'Insufficient account balance. Create your own tool, for details please view 302.AI', 'message_cn': '账户余额不足，创建属于自己的工具，更多请访问 302.AI', 'message_jp': 'アカウント残高が不足しています。独自のツールを作成するには、302.AI をご覧ください。', 'type': 'api_error'}}. Line: 363.
Append: [BenTo: Benchmark Task Reduction with In-Context Transferability](https://arxiv.org/abs/2410.13804)
Summarization failed, append the original article
error: Error code: 401 - {'error': {'err_code': -10004, 'message': 'Insufficient account balance. Create your own tool, for details please view 302.AI', 'message_cn': '账户余额不足，创建属于自己的工具，更多请访问 302.AI', 'message_jp': 'アカウント残高が不足しています。独自のツールを作成するには、302.AI をご覧ください。', 'type': 'api_error'}}. Line: 363.
Append: [PopAlign: Diversifying Contrasting Patterns for a More Comprehensive Alignment](https://arxiv.org/abs/2410.13785)
Summarization failed, append the original article
error: Error code: 401 - {'error': {'err_code': -10004, 'message': 'Insufficient account balance. Create your own tool, for details please view 302.AI', 'message_cn': '账户余额不足，创建属于自己的工具，更多请访问 302.AI', 'message_jp': 'アカウント残高が不足しています。独自のツールを作成するには、302.AI をご覧ください。', 'type': 'api_error'}}. Line: 363.
Append: [MedMobile: A mobile-sized language model with expert-level clinical capabilities](https://arxiv.org/abs/2410.09019)
Summarization failed, append the original article
error: Error code: 401 - {'error': {'err_code': -10004, 'message': 'Insufficient account balance. Create your own tool, for details please view 302.AI', 'message_cn': '账户余额不足，创建属于自己的工具，更多请访问 302.AI', 'message_jp': 'アカウント残高が不足しています。独自のツールを作成するには、302.AI をご覧ください。', 'type': 'api_error'}}. Line: 363.
Append: [Harnessing Webpage UIs for Text-Rich Visual Understanding](https://arxiv.org/abs/2410.13824)
Summarization failed, append the original article
error: Error code: 401 - {'error': {'err_code': -10004, 'message': 'Insufficient account balance. Create your own tool, for details please view 302.AI', 'message_cn': '账户余额不足，创建属于自己的工具，更多请访问 302.AI', 'message_jp': 'アカウント残高が不足しています。独自のツールを作成するには、302.AI をご覧ください。', 'type': 'api_error'}}. Line: 363.
Append: [DreamVideo-2: Zero-Shot Subject-Driven Video Customization with Precise Motion Control](https://arxiv.org/abs/2410.13830)
Summarization failed, append the original article
error: Error code: 401 - {'error': {'err_code': -10004, 'message': 'Insufficient account balance. Create your own tool, for details please view 302.AI', 'message_cn': '账户余额不足，创建属于自己的工具，更多请访问 302.AI', 'message_jp': 'アカウント残高が不足しています。独自のツールを作成するには、302.AI をご覧ください。', 'type': 'api_error'}}. Line: 363.
Append: [MMed-RAG: Versatile Multimodal RAG System for Medical Vision Language Models](https://arxiv.org/abs/2410.13085)
Summarization failed, append the original article
error: Error code: 401 - {'error': {'err_code': -10004, 'message': 'Insufficient account balance. Create your own tool, for details please view 302.AI', 'message_cn': '账户余额不足，创建属于自己的工具，更多请访问 302.AI', 'message_jp': 'アカウント残高が不足しています。独自のツールを作成するには、302.AI をご覧ください。', 'type': 'api_error'}}. Line: 363.
Append: [A Unified View of Delta Parameter Editing in Post-Trained Large-Scale Models](https://arxiv.org/abs/2410.13841)
Summarization failed, append the original article
error: Error code: 401 - {'error': {'err_code': -10004, 'message': 'Insufficient account balance. Create your own tool, for details please view 302.AI', 'message_cn': '账户余额不足，创建属于自己的工具，更多请访问 302.AI', 'message_jp': 'アカウント残高が不足しています。独自のツールを作成するには、302.AI をご覧ください。', 'type': 'api_error'}}. Line: 363.
Append: [AERO: Softmax-Only LLMs for Efficient Private Inference](https://arxiv.org/abs/2410.13060)
Summarization failed, append the original article
error: Error code: 401 - {'error': {'err_code': -10004, 'message': 'Insufficient account balance. Create your own tool, for details please view 302.AI', 'message_cn': '账户余额不足，创建属于自己的工具，更多请访问 302.AI', 'message_jp': 'アカウント残高が不足しています。独自のツールを作成するには、302.AI をご覧ください。', 'type': 'api_error'}}. Line: 363.
Append: [Retrospective Learning from Interactions](https://arxiv.org/abs/2410.13852)
Summarization failed, append the original article
error: Error code: 401 - {'error': {'err_code': -10004, 'message': 'Insufficient account balance. Create your own tool, for details please view 302.AI', 'message_cn': '账户余额不足，创建属于自己的工具，更多请访问 302.AI', 'message_jp': 'アカウント残高が不足しています。独自のツールを作成するには、302.AI をご覧ください。', 'type': 'api_error'}}. Line: 363.
Append: [Failing Forward: Improving Generative Error Correction for ASR with Synthetic Data and Retrieval Augmentation](https://arxiv.org/abs/2410.13198)
Summarization failed, append the original article
error: Error code: 401 - {'error': {'err_code': -10004, 'message': 'Insufficient account balance. Create your own tool, for details please view 302.AI', 'message_cn': '账户余额不足，创建属于自己的工具，更多请访问 302.AI', 'message_jp': 'アカウント残高が不足しています。独自のツールを作成するには、302.AI をご覧ください。', 'type': 'api_error'}}. Line: 363.
Append: [FlatQuant: Flatness Matters for LLM Quantization](https://arxiv.org/abs/2410.09426)
append_entries: 20
Finish: 2024-10-18 09:01:04.850853
------------------------------------------------------
Started: 2024-10-18 12:12:12.180042
Existing_entries: 127
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1022
Summarized using gpt-4o-mini
Append: [Long-LRM：基于3D高斯重建的长序列图像大场景重建模型](https://arxiv.org/abs/2410.12781)
Token length: 1904
Summarized using gpt-4o-mini
Append: [中文图像含义理解基准CII-Bench的提出与评估](https://arxiv.org/abs/2410.13854)
Token length: 1611
Summarized using gpt-4o-mini
Append: [基于检索增强个性化的多模态大语言模型框架](https://arxiv.org/abs/2410.13360)
append_entries: 3
Finish: 2024-10-18 12:12:26.788308
------------------------------------------------------
Started: 2024-10-18 15:01:05.164358
Existing_entries: 130
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 997
Summarized using gpt-4o-mini
Append: [MobA：基于多模态大语言模型的移动助手](https://arxiv.org/abs/2410.13757)
Token length: 1640
Summarized using gpt-4o-mini
Append: [gamma-MoD: 提升多模态大语言模型计算效率的新策略](https://arxiv.org/abs/2410.13859)
Token length: 1427
Summarized using gpt-4o-mini
Append: [基于高质量数据的长输出能力模型调优研究](https://arxiv.org/abs/2410.10210)
Token length: 1470
Summarized using gpt-4o-mini
Append: [无指导自回归视觉生成的条件对比对齐方法](https://arxiv.org/abs/2410.09347)
Token length: 1337
Summarized using gpt-4o-mini
Append: [TransAgent：通过多源知识蒸馏提升视觉-语言基础模型](https://arxiv.org/abs/2410.12183)
append_entries: 5
Finish: 2024-10-18 15:01:42.129464
------------------------------------------------------
Started: 2024-10-18 18:00:41.924719
Existing_entries: 135
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1434
Summarized using gpt-4o-mini
Append: [Open Materials 2024: 大规模开放数据集及预训练模型的发布](https://arxiv.org/abs/2410.12771)
Token length: 1146
Summarized using gpt-4o-mini
Append: [推进语音大语言模型的五级发展路线图与评估基准](https://arxiv.org/abs/2410.13268)
append_entries: 2
Finish: 2024-10-18 18:00:52.699643
------------------------------------------------------
Started: 2024-10-18 21:00:43.720190
Existing_entries: 137
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1480
Summarized using gpt-4o-mini
Append: [JudgeBench：评估LLM基础评判模型的新基准](https://arxiv.org/abs/2410.12784)
Token length: 1081
Summarized using gpt-4o-mini
Append: [WorldCuisines：多元文化的视觉问答基准](https://arxiv.org/abs/2410.12705)
append_entries: 2
Finish: 2024-10-18 21:00:52.466612
------------------------------------------------------
Started: 2024-10-19 00:33:18.154426
Existing_entries: 139
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1279
Summarized using gpt-4o-mini
Append: [探索视觉自回归模型的规模化问题：连续与离散代币、随机与固定生成顺序的影响](https://arxiv.org/abs/2410.13863)
append_entries: 1
Finish: 2024-10-19 00:33:23.375445
------------------------------------------------------
Started: 2024-10-19 03:12:24.355053
Existing_entries: 140
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-19 03:12:24.532868
------------------------------------------------------
Started: 2024-10-19 06:00:44.883462
Existing_entries: 140
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1497
Summarized using gpt-4o-mini
Append: [o1模型在推理能力提升中的研究：对比测试时计算方法的深入分析](https://arxiv.org/abs/2410.13639)
append_entries: 1
Finish: 2024-10-19 06:00:51.621335
------------------------------------------------------
Started: 2024-10-19 09:00:35.455791
Existing_entries: 141
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-19 09:00:35.541518
------------------------------------------------------
Started: 2024-10-19 12:11:19.465294
Existing_entries: 141
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-19 12:11:19.568134
------------------------------------------------------
Started: 2024-10-19 15:00:23.909747
Existing_entries: 141
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-19 15:00:24.039566
------------------------------------------------------
Started: 2024-10-19 18:00:49.367750
Existing_entries: 141
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-19 18:00:49.537880
------------------------------------------------------
Started: 2024-10-19 21:00:51.454359
Existing_entries: 141
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-19 21:00:51.540823
------------------------------------------------------
Started: 2024-10-20 00:37:29.538104
Existing_entries: 141
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-20 00:37:29.662534
------------------------------------------------------
Started: 2024-10-20 03:18:38.130370
Existing_entries: 141
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-20 03:18:38.248015
------------------------------------------------------
Started: 2024-10-20 06:00:58.507365
Existing_entries: 141
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-20 06:00:58.583893
------------------------------------------------------
Started: 2024-10-20 09:00:27.062497
Existing_entries: 141
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-20 09:00:27.227918
------------------------------------------------------
Started: 2024-10-20 12:12:09.718215
Existing_entries: 141
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-20 12:12:09.801011
------------------------------------------------------
Started: 2024-10-20 15:00:43.100477
Existing_entries: 141
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-20 15:00:43.205081
------------------------------------------------------
Started: 2024-10-20 18:00:50.224926
Existing_entries: 141
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-20 18:00:50.396642
------------------------------------------------------
Started: 2024-10-20 21:01:07.479631
Existing_entries: 141
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-20 21:01:07.698831
------------------------------------------------------
Started: 2024-10-21 00:35:29.947071
Existing_entries: 141
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-21 00:35:30.085409
------------------------------------------------------
Started: 2024-10-21 03:17:54.106518
Existing_entries: 141
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-21 03:17:54.284579
------------------------------------------------------
Started: 2024-10-21 06:11:11.411711
Existing_entries: 141
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1401
Summarized using gpt-4o-mini
Append: [MagicTailor：组件可控的个性化文本到图像生成](https://arxiv.org/abs/2410.13370)
append_entries: 1
Finish: 2024-10-21 06:11:16.325726
------------------------------------------------------
Started: 2024-10-21 09:00:40.393701
Existing_entries: 142
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1762
Summarized using gpt-4o-mini
Append: [自我演化的AI训练：借助扩散模型改善低质量数据学习](https://arxiv.org/abs/2410.13674)
append_entries: 1
Finish: 2024-10-21 09:00:48.012855
------------------------------------------------------
Started: 2024-10-21 12:00:58.790313
Existing_entries: 143
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1161
Summarized using gpt-4o-mini
Append: [训练方法对神经网络层重要性的影响](https://arxiv.org/abs/2410.14470)
Token length: 1900
Summarized using gpt-4o-mini
Append: [视觉语言模型的挑战：自然图像中的对抗样本研究](https://arxiv.org/abs/2410.14669)
Token length: 1383
Summarized using gpt-4o-mini
Append: [DAWN：非自回归扩散模型的动态头像生成框架](https://arxiv.org/abs/2410.13726)
Token length: 1899
Summarized using gpt-4o-mini
Append: [关于强化学习中人为反馈的边际损失问题及其影响](https://arxiv.org/abs/2410.13828)
Token length: 1170
Summarized using gpt-4o-mini
Append: [用户中心的金融专业能力评估基准：UCFE](https://arxiv.org/abs/2410.14059)
Token length: 1799
Summarized using gpt-4o-mini
Append: [DPLM-2：一种多模态蛋白质基础模型](https://arxiv.org/abs/2410.13782)
Token length: 1376
Summarized using gpt-4o-mini
Append: [机器生成文本检测器的评估方法研究](https://arxiv.org/abs/2410.14677)
Token length: 1646
Summarized using gpt-4o-mini
Append: [基于学习门控的稀疏注意力机制SeerAttention](https://arxiv.org/abs/2410.13276)
Token length: 1279
Summarized using gpt-4o-mini
Append: [利用KeyNMF研究中国媒体中的信息动态：以2024年欧洲议会选举为例](https://arxiv.org/abs/2410.12791)
Token length: 1327
Summarized using gpt-4o-mini
Append: [世界模型增强的自主网络代理研究](https://arxiv.org/abs/2410.13232)
append_entries: 10
Finish: 2024-10-21 12:02:06.588014
------------------------------------------------------
Started: 2024-10-21 15:00:59.223800
Existing_entries: 153
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1893
Summarized using gpt-4o-mini
Append: [大语言模型的自我预测：内省能力的探索](https://arxiv.org/abs/2410.13787)
append_entries: 1
Finish: 2024-10-21 15:01:08.662994
------------------------------------------------------
Started: 2024-10-21 18:09:40.496368
Existing_entries: 154
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 712
Summarized using gpt-4o-mini
Append: [Shakti：为边缘设备优化的高效语言模型](https://arxiv.org/abs/2410.11331)
Token length: 1838
Summarized using gpt-4o-mini
Append: [灵活视觉变换器 FiTv2：一种针对任意分辨率图像生成的变换器架构](https://arxiv.org/abs/2410.13925)
Token length: 1306
Summarized using gpt-4o-mini
Append: [Mini-Omni2：一款多模态视觉音频助手](https://arxiv.org/abs/2410.11190)
Token length: 1278
Summarized using gpt-4o-mini
Append: [混合自回归变换器（HART）：一种高效的图像生成模型](https://arxiv.org/abs/2410.10812)
Token length: 1075
Summarized using gpt-4o-mini
Append: [BiGR：一种基于紧凑二进制潜在代码的条件图像生成模型](https://arxiv.org/abs/2410.14672)
Token length: 1350
Summarized using gpt-4o-mini
Append: [Montessori-Instruct：针对学生学习过程的合成数据框架](https://arxiv.org/abs/2410.14208)
Token length: 1413
Summarized using gpt-4o-mini
Append: [平衡式说服训练：提升模型对正负说服的适应性](https://arxiv.org/abs/2410.14596)
append_entries: 7
Finish: 2024-10-21 18:10:25.775042
------------------------------------------------------
Started: 2024-10-21 21:00:36.984282
Existing_entries: 161
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-21 21:00:37.126975
------------------------------------------------------
Started: 2024-10-22 00:34:27.340533
Existing_entries: 161
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-22 00:34:27.466951
------------------------------------------------------
Started: 2024-10-22 03:14:43.049187
Existing_entries: 161
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-22 03:14:43.131013
------------------------------------------------------
Started: 2024-10-22 06:00:40.122315
Existing_entries: 161
Fetching from https://rsshub.app/huggingface/daily-papers
Summarization failed, append the original article
error: 'NoneType' object has no attribute 'group'. Line: 363.
Append: [RM-Bench: Benchmarking Reward Models of Language Models with Subtlety and Style](https://arxiv.org/abs/2410.16184)
Token length: 1054
Summarized using gpt-4o-mini
Append: [FrugalNeRF：高效的少样本神经辐射场框架](https://arxiv.org/abs/2410.16271)
Token length: 1486
Summarized using gpt-4o-mini
Append: [Meta-Chunking: 基于深层语义关系的文本分块方法](https://arxiv.org/abs/2410.12788)
Token length: 1240
Summarized using gpt-4o-mini
Append: [Pangea：面向多语言和多文化背景的多模态大语言模型](https://arxiv.org/abs/2410.16153)
Token length: 1563
Summarized using gpt-4o-mini
Append: [跨语言自动评估套件：Hercule的设计与实现](https://arxiv.org/abs/2410.13394)
Token length: 1173
Summarized using gpt-4o-mini
Append: [PUMA：赋能统一的多模态大语言模型的多粒度视觉生成](https://arxiv.org/abs/2410.13861)
Token length: 1463
Summarized using gpt-4o-mini
Append: [CompassJudger-1：开源全能评估模型及其基准测试](https://arxiv.org/abs/2410.16256)
Token length: 1817
Summarized using gpt-4o-mini
Append: [融合上下文信息的综合语音标记器DM-Codec的研究](https://arxiv.org/abs/2410.15017)
Token length: 1626
Summarized using gpt-4o-mini
Append: [Baichuan Alignment：提升AI模型对齐技术的深入分析](https://arxiv.org/abs/2410.14940)
Token length: 1150
Summarized using gpt-4o-mini
Append: [SemiEvol：一种半监督微调框架用于大规模语言模型的适应性](https://arxiv.org/abs/2410.14745)
Token length: 1334
Summarized using gpt-4o-mini
Append: [利用大型语言模型评估认知行为疗法的潜力：CBT-BENCH基准的提出](https://arxiv.org/abs/2410.13218)
append_entries: 11
Finish: 2024-10-22 06:01:49.854019
------------------------------------------------------
Started: 2024-10-22 09:00:48.768171
Existing_entries: 172
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1878
Summarized using gpt-4o-mini
Append: [面向长指令的长距离依赖样本选择框架 GATEAU](https://arxiv.org/abs/2410.15633)
Token length: 1142
Summarized using gpt-4o-mini
Append: [AutoTrain Advanced：简化训练自定义数据集的开源工具](https://arxiv.org/abs/2410.15735)
Token length: 1232
Summarized using gpt-4o-mini
Append: [预训练蒸馏：扩大知识蒸馏在大语言模型中的应用](https://arxiv.org/abs/2410.16215)
Token length: 1796
Summarized using gpt-4o-mini
Append: [SAM2Long：面向复杂长视频的改进训练自由视频目标分割策略](https://arxiv.org/abs/2410.16268)
append_entries: 4
Finish: 2024-10-22 09:01:18.577872
------------------------------------------------------
Started: 2024-10-22 12:12:55.557953
Existing_entries: 176
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1078
Summarized using gpt-4o-mini
Append: [基于大型语言模型的连续马尔可夫决策过程动态预测](https://arxiv.org/abs/2410.11711)
Token length: 1411
Summarized using gpt-4o-mini
Append: [Alchemy：通过符号变换合成形式化定理的框架](https://arxiv.org/abs/2410.15748)
append_entries: 2
Finish: 2024-10-22 12:13:07.442153
------------------------------------------------------
Started: 2024-10-22 15:01:04.661055
Existing_entries: 178
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1364
Summarized using gpt-4o-mini
Append: [简约模型与上下文学习：关联探索与改进建议](https://arxiv.org/abs/2410.14086)
Token length: 1276
Summarized using gpt-4o-mini
Append: [基于动态深度的混合层跳过模型](https://arxiv.org/abs/2410.13184)
Summarization failed, append the original article
error: 'NoneType' object has no attribute 'group'. Line: 363.
Append: [Hallucination Detox: Sensitive Neuron Dropout (SeND) for Large Language Model Training](https://arxiv.org/abs/2410.15460)
Token length: 1280
Summarized using gpt-4o-mini
Append: [Ichigo：一种基于混合模态的语音与文本处理模型](https://arxiv.org/abs/2410.15316)
append_entries: 4
Finish: 2024-10-22 15:01:39.432236
------------------------------------------------------
Started: 2024-10-22 18:01:07.308263
Existing_entries: 182
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-22 18:01:07.493789
------------------------------------------------------
Started: 2024-10-22 21:01:22.546924
Existing_entries: 182
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1644
Summarized using gpt-4o-mini
Append: [寻找模仿阈值：对文本到图像模型版权侵权的研究](https://arxiv.org/abs/2410.15002)
Token length: 1115
Summarized using gpt-4o-mini
Append: [Agent-to-Sim (ATS)：从视频学习3D代理的交互行为模型](https://arxiv.org/abs/2410.16259)
append_entries: 2
Finish: 2024-10-22 21:01:37.415156
------------------------------------------------------
Started: 2024-10-23 00:33:46.986033
Existing_entries: 184
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-23 00:33:47.128121
------------------------------------------------------
Started: 2024-10-23 03:14:01.644365
Existing_entries: 184
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-23 03:14:01.847907
------------------------------------------------------
Started: 2024-10-23 06:00:48.196655
Existing_entries: 184
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-23 06:00:48.310171
------------------------------------------------------
Started: 2024-10-23 09:00:48.797729
Existing_entries: 184
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-23 09:00:48.928682
------------------------------------------------------
Started: 2024-10-23 12:12:45.107375
Existing_entries: 184
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1355
Summarized using gpt-4o-mini
Append: [自我引导优化：一种无人工标注的偏好信号生成方法](https://arxiv.org/abs/2410.17131)
Token length: 997
Summarized using gpt-4o-mini
Append: [SpectroMotion：结合3D高斯点云与物理基础渲染的动态高光场景重建新方法](https://arxiv.org/abs/2410.17249)
Token length: 1876
Summarized using gpt-4o-mini
Append: [PyramidDrop：提高大型视觉语言模型效率的视觉冗余降低策略](https://arxiv.org/abs/2410.17247)
Token length: 1440
Summarized using gpt-4o-mini
Append: [JMMMU：首个针对日语的大规模多模态模型基准测试](https://arxiv.org/abs/2410.17250)
Token length: 1646
Summarized using gpt-4o-mini
Append: [EvoPress：一种适应性动态压缩的广义框架](https://arxiv.org/abs/2410.14649)
Token length: 1602
Summarized using gpt-4o-mini
Append: [MiniPLM：高效灵活的知识蒸馏框架用于预训练语言模型](https://arxiv.org/abs/2410.17215)
append_entries: 6
Finish: 2024-10-23 12:13:19.987115
------------------------------------------------------
Started: 2024-10-23 15:00:28.676285
Existing_entries: 190
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-23 15:00:28.813041
------------------------------------------------------
Started: 2024-10-23 18:00:45.621722
Existing_entries: 190
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1283
Summarized using gpt-4o-mini
Append: [数学推理参数的隔离与干预：Math Neurosurgery 方法](https://arxiv.org/abs/2410.16930)
Token length: 1478
Summarized using gpt-4o-mini
Append: [减轻长距离视觉-指令交互影响的新方法：同心因果注意力](https://arxiv.org/abs/2410.15926)
append_entries: 2
Finish: 2024-10-23 18:01:01.990042
------------------------------------------------------
Started: 2024-10-23 21:01:00.223875
Existing_entries: 192
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 955
Summarized using gpt-4o-mini
Append: [xGen-MM-Vid：高效捕捉视频时序信息的多模态语言模型](https://arxiv.org/abs/2410.16267)
Token length: 1291
Summarized using gpt-4o-mini
Append: [增强视觉语言模型的推理能力：基于详细理由的训练与强化学习](https://arxiv.org/abs/2410.16198)
append_entries: 2
Finish: 2024-10-23 21:01:16.634407
------------------------------------------------------
Started: 2024-10-24 00:33:52.232115
Existing_entries: 194
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1331
Summarized using gpt-4o-mini
Append: [3DGS-增强器：提升3D高斯点云渲染质量的创新管道](https://arxiv.org/abs/2410.16266)
append_entries: 1
Finish: 2024-10-24 00:33:58.665625
------------------------------------------------------
Started: 2024-10-24 03:13:55.973287
Existing_entries: 195
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1003
Summarized using gpt-4o-mini
Append: [基于大型语言模型的复合人工智能系统优化研究](https://arxiv.org/abs/2410.16392)
Token length: 1025
Summarized using gpt-4o-mini
Append: [智能内窥镜技术在结肠镜检查中的前沿探索](https://arxiv.org/abs/2410.17241)
append_entries: 2
Finish: 2024-10-24 03:14:11.928364
------------------------------------------------------
Started: 2024-10-24 06:10:40.136276
Existing_entries: 197
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1631
Summarized using gpt-4o-mini
Append: [多图像增强直接偏好优化(MIA-DPO)在视觉偏好对齐中的应用](https://arxiv.org/abs/2410.17637)
Token length: 1320
Summarized using gpt-4o-mini
Append: [基于自回归语言模型的扩散语言模型构建与评估](https://arxiv.org/abs/2410.17891)
Token length: 1708
Summarized using gpt-4o-mini
Append: [面向世界模拟器的双重评估框架：WorldSimBench](https://arxiv.org/abs/2410.18072)
append_entries: 3
Finish: 2024-10-24 06:10:57.345370
------------------------------------------------------
Started: 2024-10-24 09:00:56.797737
Existing_entries: 200
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1091
Summarized using gpt-4o-mini
Append: [基于轻量级多模态应用控制的手机应用代理架构](https://arxiv.org/abs/2410.17883)
append_entries: 1
Finish: 2024-10-24 09:01:03.583182
------------------------------------------------------
Started: 2024-10-24 12:00:43.059523
Existing_entries: 201
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-24 12:00:43.158270
------------------------------------------------------
Started: 2024-10-24 15:00:51.942814
Existing_entries: 201
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1409
Summarized using gpt-4o-mini
Append: [多语言奖励模型评估基准 M-RewardBench 的构建与分析](https://arxiv.org/abs/2410.15522)
Token length: 1474
Summarized using gpt-4o-mini
Append: [基于合成数据集的直接偏好优化推动文本到图像模型的进步](https://arxiv.org/abs/2410.18013)
Token length: 1297
Summarized using gpt-4o-mini
Append: [针对多模态大语言模型的TP-Eval评估框架](https://arxiv.org/abs/2410.18071)
append_entries: 3
Finish: 2024-10-24 15:01:15.500663
------------------------------------------------------
Started: 2024-10-24 18:01:03.669765
Existing_entries: 204
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1809
Summarized using gpt-4o-mini
Append: [DynamicCity：一种动态城市四维激光雷达生成框架](https://arxiv.org/abs/2410.18084)
Token length: 969
Summarized using gpt-4o-mini
Append: [MedINST: 一种多领域多任务的生物医学指令元数据集](https://arxiv.org/abs/2410.13458)
Token length: 1144
Summarized using gpt-4o-mini
Append: [ARKit LabelMaker：首个大规模真实世界3D数据集及其语义标注](https://arxiv.org/abs/2410.13924)
append_entries: 3
Finish: 2024-10-24 18:01:28.143856
------------------------------------------------------
Started: 2024-10-24 21:00:42.550955
Existing_entries: 207
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-24 21:00:42.649308
------------------------------------------------------
Started: 2024-10-25 00:34:23.009846
Existing_entries: 207
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1282
Summarized using gpt-4o-mini
Append: [LongVU: 一种用于长视频理解的时空自适应压缩机制](https://arxiv.org/abs/2410.17434)
append_entries: 1
Finish: 2024-10-25 00:34:29.271414
------------------------------------------------------
Started: 2024-10-25 03:16:02.411213
Existing_entries: 208
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1417
Summarized using gpt-4o-mini
Append: [基于价值引导的策略引导：提升通用机器人政策的部署性能](https://arxiv.org/abs/2410.13816)
Token length: 1376
Summarized using gpt-4o-mini
Append: [大视野合成模型 (LVSM)：一种可扩展的新视角合成方法](https://arxiv.org/abs/2410.17242)
append_entries: 2
Finish: 2024-10-25 03:16:16.065174
------------------------------------------------------
Started: 2024-10-25 06:00:43.427390
Existing_entries: 210
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-25 06:00:43.510312
------------------------------------------------------
Started: 2024-10-25 09:01:04.595895
Existing_entries: 210
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1597
Summarized using gpt-4o-mini
Append: [W-Bench：评估图像水印在高级编辑技巧下的鲁棒性与VINE方法](https://arxiv.org/abs/2410.18775)
Token length: 1319
Summarized using gpt-4o-mini
Append: [多草稿投机采样的优化选择方案研究](https://arxiv.org/abs/2410.18234)
Token length: 1393
Summarized using gpt-4o-mini
Append: [ScaleQuest: 可扩展的数学推理数据合成方法](https://arxiv.org/abs/2410.18693)
Token length: 1495
Summarized using gpt-4o-mini
Append: [LOGO：通过高效偏好优化实现长上下文对齐的训练策略](https://arxiv.org/abs/2410.18533)
Token length: 1263
Summarized using gpt-4o-mini
Append: [基于分块计算的对比损失优化策略](https://arxiv.org/abs/2410.17243)
Token length: 1265
Summarized using gpt-4o-mini
Append: [STRING：提升大语言模型长上下文有效性的新方法](https://arxiv.org/abs/2410.18745)
Token length: 1256
Summarized using gpt-4o-mini
Append: [Framer：互动帧插值与创意过渡](https://arxiv.org/abs/2410.18978)
Token length: 840
Summarized using gpt-4o-mini
Append: [通过数据中心化技术提升大语言模型的奖励建模](https://arxiv.org/abs/2410.18451)
Token length: 822
Summarized using gpt-4o-mini
Append: [CCI3.0-HQ：优化数据质量的高质量汉语语料库](https://arxiv.org/abs/2410.18505)
Token length: 1540
Summarized using gpt-4o-mini
Append: [模型编辑对语言模型表现的影响评估](https://arxiv.org/abs/2410.18785)
Token length: 1179
Summarized using gpt-4o-mini
Append: [一致性模型的稳定一致性调优](https://arxiv.org/abs/2410.18958)
Token length: 1440
Summarized using gpt-4o-mini
Append: [无界：基于生成模型的无尽角色生活模拟游戏](https://arxiv.org/abs/2410.18975)
append_entries: 12
Finish: 2024-10-25 09:05:14.591110
------------------------------------------------------
Started: 2024-10-25 12:00:40.196859
Existing_entries: 222
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1916
Summarized using gpt-4o-mini
Append: [ADEM-VL：一种高效的视觉语言模型融合方法](https://arxiv.org/abs/2410.17779)
Token length: 1358
Summarized using gpt-4o-mini
Append: [为阿拉伯语大型多模态模型开发的综合评估基准——CAMEL-Bench](https://arxiv.org/abs/2410.18976)
Token length: 1452
Summarized using gpt-4o-mini
Append: [成本高效的复杂图表问答生成方法——Code-as-Intermediary Translation](https://arxiv.org/abs/2410.18798)
Token length: 1063
Summarized using gpt-4o-mini
Append: [Waffle：一种提升大型语言模型HTML结构理解能力的新策略](https://arxiv.org/abs/2410.18362)
Token length: 1584
Summarized using gpt-4o-mini
Append: [HalluEditBench：基于真实幻觉的知识编辑方法基准评估](https://arxiv.org/abs/2410.16251)
Token length: 1404
Summarized using gpt-4o-mini
Append: [基于注意力机制的人类运动生成交互编辑研究](https://arxiv.org/abs/2410.18977)
Token length: 1336
Summarized using gpt-4o-mini
Append: [大型语言模型在算术学习中的符号学习能力研究](https://arxiv.org/abs/2410.15580)
append_entries: 7
Finish: 2024-10-25 12:01:39.598921
------------------------------------------------------
Started: 2024-10-25 15:00:38.467702
Existing_entries: 229
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1165
Summarized using gpt-4o-mini
Append: [Taipan：高效处理超长上下文的混合架构](https://arxiv.org/abs/2410.18572)
Token length: 1301
Summarized using gpt-4o-mini
Append: [基于残差值的变换器：ResFormer与SVFormer](https://arxiv.org/abs/2410.17897)
append_entries: 2
Finish: 2024-10-25 15:00:50.980554
------------------------------------------------------
Started: 2024-10-25 18:00:41.652597
Existing_entries: 231
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1583
Summarized using gpt-4o-mini
Append: [数据扩展在机器人操控中的应用研究](https://arxiv.org/abs/2410.18647)
append_entries: 1
Finish: 2024-10-25 18:00:50.486086
------------------------------------------------------
Started: 2024-10-25 21:01:00.679094
Existing_entries: 232
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 634
Summarized using gpt-4o-mini
Append: [基于文本到图像扩散模型的视频对象分割方法研究](https://arxiv.org/abs/2410.18538)
Token length: 1256
Summarized using gpt-4o-mini
Append: [利用稀疏自编码器解决大语言模型中的知识冲突](https://arxiv.org/abs/2410.15999)
Token length: 1167
Summarized using gpt-4o-mini
Append: [通过对比检索头减少大型语言模型的幻觉](https://arxiv.org/abs/2410.18860)
append_entries: 3
Finish: 2024-10-25 21:01:15.696852
------------------------------------------------------
Started: 2024-10-26 00:33:14.915253
Existing_entries: 235
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1032
Summarized using gpt-4o-mini
Append: [Pantograph：基于 Lean 4 的机器辅助定理证明工具](https://arxiv.org/abs/2410.16429)
Token length: 1796
Summarized using gpt-4o-mini
Append: [ZIP-FIT：基于压缩测量任务对齐的数据选择框架](https://arxiv.org/abs/2410.18194)
Token length: 1585
Summarized using gpt-4o-mini
Append: [变压器模型及生成AI关键组件的数学问题与概率优化分析](https://arxiv.org/abs/2410.18441)
Token length: 1361
Summarized using gpt-4o-mini
Append: [异步强化学习人类反馈的研究与实践](https://arxiv.org/abs/2410.18252)
append_entries: 4
Finish: 2024-10-26 00:33:41.745713
------------------------------------------------------
Started: 2024-10-26 03:11:23.743815
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-26 03:11:23.913916
------------------------------------------------------
Started: 2024-10-26 06:00:39.381036
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-26 06:00:39.481202
------------------------------------------------------
Started: 2024-10-26 09:00:38.390047
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-26 09:00:38.562716
------------------------------------------------------
Started: 2024-10-26 12:11:35.981385
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-26 12:11:36.062345
------------------------------------------------------
Started: 2024-10-26 15:01:01.307591
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-26 15:01:01.481154
------------------------------------------------------
Started: 2024-10-26 18:01:00.930603
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-26 18:01:01.108747
------------------------------------------------------
Started: 2024-10-26 21:00:36.521227
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-26 21:00:36.680799
------------------------------------------------------
Started: 2024-10-27 00:37:19.765373
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-27 00:37:19.843331
------------------------------------------------------
Started: 2024-10-27 03:17:46.987945
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-27 03:17:47.160417
------------------------------------------------------
Started: 2024-10-27 06:00:50.996516
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-27 06:00:51.156568
------------------------------------------------------
Started: 2024-10-27 09:00:27.087205
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-27 09:00:27.245957
------------------------------------------------------
Started: 2024-10-27 12:11:06.138736
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-27 12:11:06.251998
------------------------------------------------------
Started: 2024-10-27 15:00:45.886877
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-27 15:00:46.006186
------------------------------------------------------
Started: 2024-10-27 16:53:24.315722
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-27 16:53:24.565096
------------------------------------------------------
Started: 2024-10-27 17:05:57.362623
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-27 17:05:57.461139
------------------------------------------------------
Started: 2024-10-27 17:15:50.848531
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-27 17:15:50.969125
------------------------------------------------------
Started: 2024-10-27 17:19:19.714426
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-27 17:19:19.886190
------------------------------------------------------
Started: 2024-10-27 17:27:48.236116
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-27 17:27:48.411235
------------------------------------------------------
Started: 2024-10-27 18:00:38.951843
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-27 18:00:39.081952
------------------------------------------------------
Started: 2024-10-27 21:00:40.575524
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-27 21:00:40.740796
------------------------------------------------------
Started: 2024-10-27 23:53:47.513193
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-27 23:53:47.636391
------------------------------------------------------
Started: 2024-10-28 00:36:23.436752
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-28 00:36:23.562490
------------------------------------------------------
Started: 2024-10-28 02:07:27.483847
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-28 02:07:27.582051
------------------------------------------------------
Started: 2024-10-28 02:19:20.658486
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-28 02:19:20.781491
------------------------------------------------------
Started: 2024-10-28 02:41:35.494299
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-28 02:41:35.603278
------------------------------------------------------
Started: 2024-10-28 03:18:54.870136
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1375
Summarized using gpt-4o-mini
Append: [通过未标记轨迹数据学习强化学习中的高效探索策略](https://arxiv.org/abs/2410.18076)
Token length: 837
Summarized using gpt-4o-mini
Append: [Infinity-MM: 规模化多模态指令数据集与高性能模型的突破](https://arxiv.org/abs/2410.18558)
Token length: 1289
Summarized using gpt-4o-mini
Append: [MMAU：评估多模态音频理解模型的新基准](https://arxiv.org/abs/2410.19168)
Token length: 1405
Summarized using gpt-4o-mini
Append: [基于大语言模型的ECG图像解读新工具PULSE的开发与评估](https://arxiv.org/abs/2410.19008)
append_entries: 4
Finish: 2024-10-28 03:19:13.737940
------------------------------------------------------
Started: 2024-10-28 06:00:38.852276
Existing_entries: 243
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-28 06:00:39.001576
------------------------------------------------------
Started: 2024-10-28 09:01:03.937673
Existing_entries: 243
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1647
Summarized using gpt-4o-mini
Append: [视觉-语言模型在身体决策中的应用和挑战](https://arxiv.org/abs/2410.17856)
Token length: 1158
Summarized using gpt-4o-mini
Append: [基于Prereq-Tune的LLM幻觉减少策略研究](https://arxiv.org/abs/2410.19290)
Token length: 1851
Summarized using gpt-4o-mini
Append: [结合人类反馈与语言模型提升偏好注释质量的路由框架](https://arxiv.org/abs/2410.19133)
Token length: 1294
Summarized using gpt-4o-mini
Append: [FasterCache：加速视频扩散模型推断的新策略](https://arxiv.org/abs/2410.19355)
append_entries: 4
Finish: 2024-10-28 09:01:26.509937
------------------------------------------------------
Started: 2024-10-28 12:13:28.766483
Existing_entries: 247
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "Reflection-Bench：评估大型语言模型反射能力的基准",
  "keyword": ["反射能力", "大型语言模型", "基准测试"],
  "short_summary": "本文介绍了Reflection-Bench基准，用于评估大型语言模型的反射能力。",
  "summary": "本文提出了Reflection-Bench，这是一个全面的基准测试，旨在评估大型语言模型（LLMs）在反射能力方面的表现。反射能力是智能系统与环境互动时适应信念或行为的关键能力，涉及感知、记忆、信念更新、决策、预测、反事实思维和元反思等核心认知功能。通过评估13个知名LLMs的表现，例如OpenAI o1和GPT-4，结果显示当前LLMs在反射能力上仍显不足。我们分析了这些结果的原因，并探讨了未来研究的潜在方向。Reflection-Bench为开发能与环境可靠互动的AI提供了评价工具和灵感，相关数据和代码可在https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 279 (char 431). Line: 406.
Append: [Reflection-Bench: probing AI intelligence with reflection](https://arxiv.org/abs/2410.16270)
Token length: 1086
Summarized using gpt-4o-mini
Append: [SALAD：一种基于令牌的连续表示的零-shot文本到语音模型](https://arxiv.org/abs/2410.16048)
Token length: 1675
Summarized using gpt-4o-mini
Append: [探究tokenization对大型语言模型计数能力的影响](https://arxiv.org/abs/2410.19730)
append_entries: 3
Finish: 2024-10-28 12:13:42.540786
------------------------------------------------------
Started: 2024-10-28 15:01:05.242656
Existing_entries: 250
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1500
Summarized using gpt-4o-mini
Append: [利用多视图视频学习物体动态的机器人交互框架](https://arxiv.org/abs/2410.18912)
append_entries: 1
Finish: 2024-10-28 15:01:22.092273
------------------------------------------------------
Started: 2024-10-28 18:09:27.206237
Existing_entries: 251
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1354
Summarized using gpt-4o-mini
Append: [大型语言模型中的知识冲突检测与管理](https://arxiv.org/abs/2410.16090)
Token length: 1278
Summarized using gpt-4o-mini
Append: [新闻源偏见评估方法的改进与应用](https://arxiv.org/abs/2410.17655)
Token length: 1507
Summarized using gpt-4o-mini
Append: [利用大语言模型优化数据集标注质量研究](https://arxiv.org/abs/2410.18889)
append_entries: 3
Finish: 2024-10-28 18:09:42.891270
------------------------------------------------------
Started: 2024-10-28 21:00:36.671562
Existing_entries: 254
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-28 21:00:36.953488
------------------------------------------------------
Started: 2024-10-29 00:35:08.290366
Existing_entries: 254
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-29 00:35:08.403430
------------------------------------------------------
Started: 2024-10-29 03:17:58.723048
Existing_entries: 254
Fetching from https://rsshub.app/huggingface/daily-papers
Summarization failed, append the original article
error: 'NoneType' object has no attribute 'group'. Line: 406.
Append: [Read-ME: Refactorizing LLMs as Router-Decoupled Mixture of Experts with System Co-Design](https://arxiv.org/abs/2410.19123)
append_entries: 1
Finish: 2024-10-29 03:19:57.255246
------------------------------------------------------
Started: 2024-10-29 06:00:54.754359
Existing_entries: 255
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1243
Summarized using gpt-4o-mini
Append: [MarDini：融合影片扩散模型与受限自回归的创新方法](https://arxiv.org/abs/2410.20280)
Token length: 1767
Summarized using gpt-4o-mini
Append: [基于双重策略的图像恢复研究](https://arxiv.org/abs/2410.18666)
Token length: 1299
Summarized using gpt-4o-mini
Append: [视觉搜索助手：提升视觉语言模型的信息检索能力](https://arxiv.org/abs/2410.21220)
Token length: 1193
Summarized using gpt-4o-mini
Append: [LongReward：提升长上下文模型性能的重强化学习方法](https://arxiv.org/abs/2410.21252)
Token length: 928
Summarized using gpt-4o-mini
Append: [小型语言模型的全面综述](https://arxiv.org/abs/2410.20011)
Token length: 1667
Summarized using gpt-4o-mini
Append: [LARP: 一种新型视频标记化工具提升自回归生成模型性能](https://arxiv.org/abs/2410.21264)
append_entries: 6
Finish: 2024-10-29 06:01:22.082468
------------------------------------------------------
Started: 2024-10-29 09:01:04.634435
Existing_entries: 261
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-29 09:01:04.732111
------------------------------------------------------
Started: 2024-10-29 12:00:44.806637
Existing_entries: 261
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "GPT-4o is an autoregressive omni model that accepts as input any combination of text, audio, image, and video, and generates any combination of text, audio, and image outputs. It's trained end-to-end across text, vision, and audio, meaning all inputs and outputs are processed by the same neural network. GPT-4o can respond to audio inputs in as little as 232 milliseconds, with an average of 320 milliseconds, which is similar to human response time in conversation. It matches GPT-4 Turbo performance on text in English and code, with significant improvement on text in non-English languages, while also being much faster and 50\\% cheaper in the API. GPT-4o is especially better at vision and audio understanding compared to existing models. In line with our commitment to building AI safely and consistent with our voluntary commitments to the White House, we are sharing the GPT-4o System Card, which includes our Preparedness Framework evaluations. In this System Card, we provide a detailed look at GPT-4o's capabilities, limitations, and safety evaluations across multiple categories, focusing on speech-to-speech while also evaluating text and image capabilities, and measures we've implemented to ensure the model is safe and aligned. We also include third-party assessments on dangerous capabilities, as well as discussion of potential societal impacts of GPT-4o's text and vision capabilities."}]}]Summarization failed, append the original article
error: Request timed out.. Line: 406.
Append: [GPT-4o System Card](https://arxiv.org/abs/2410.21276)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "The safe and effective deployment of Large Language Models (LLMs) involves a critical step called alignment, which ensures that the model's responses are in accordance with human preferences. Prevalent alignment techniques, such as DPO, PPO and their variants, align LLMs by changing the pre-trained model weights during a phase called post-training. While predominant, these post-training methods add substantial complexity before LLMs can be deployed. Inference-time alignment methods avoid the complex post-training step and instead bias the generation towards responses that are aligned with human preferences. The best-known inference-time alignment method, called Best-of-N, is as effective as the state-of-the-art post-training procedures. Unfortunately, Best-of-N requires vastly more resources at inference time than standard decoding strategies, which makes it computationally not viable. In this work, we introduce Speculative Rejection, a computationally-viable inference-time alignment algorithm. It generates high-scoring responses according to a given reward model, like Best-of-N does, while being between 16 to 32 times more computationally efficient."}]}]Summarization failed, append the original article
error: Request timed out.. Line: 406.
Append: [Fast Best-of-N Decoding via Speculative Rejection](https://arxiv.org/abs/2410.20290)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Neural Fields have emerged as a transformative approach for 3D scene representation in computer vision and robotics, enabling accurate inference of geometry, 3D semantics, and dynamics from posed 2D data. Leveraging differentiable rendering, Neural Fields encompass both continuous implicit and explicit neural representations enabling high-fidelity 3D reconstruction, integration of multi-modal sensor data, and generation of novel viewpoints. This survey explores their applications in robotics, emphasizing their potential to enhance perception, planning, and control. Their compactness, memory efficiency, and differentiability, along with seamless integration with foundation and generative models, make them ideal for real-time applications, improving robot adaptability and decision-making. This paper provides a thorough review of Neural Fields in robotics, categorizing applications across various domains and evaluating their strengths and limitations, based on over 200 papers. First, we present four key Neural Fields frameworks: Occupancy Networks, Signed Distance Fields, Neural Radiance Fields, and Gaussian Splatting. Second, we detail Neural Fields' applications in five major robotics domains: pose estimation, manipulation, navigation, physics, and autonomous driving, highlighting key works and discussing takeaways and open challenges. Finally, we outline the current limitations of Neural Fields in robotics and propose promising directions for future research. Project page: https://robonerf.github.io"}]}]Summarization failed, append the original article
error: Request timed out.. Line: 406.
Append: [Neural Fields in Robotics: A Survey](https://arxiv.org/abs/2410.20220)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We introduce a novel training-free spatial grounding technique for text-to-image generation using Diffusion Transformers (DiT). Spatial grounding with bounding boxes has gained attention for its simplicity and versatility, allowing for enhanced user control in image generation. However, prior training-free approaches often rely on updating the noisy image during the reverse diffusion process via backpropagation from custom loss functions, which frequently struggle to provide precise control over individual bounding boxes. In this work, we leverage the flexibility of the Transformer architecture, demonstrating that DiT can generate noisy patches corresponding to each bounding box, fully encoding the target object and allowing for fine-grained control over each region. Our approach builds on an intriguing property of DiT, which we refer to as semantic sharing. Due to semantic sharing, when a smaller patch is jointly denoised alongside a generatable-size image, the two become "semantic clones". Each patch is denoised in its own branch of the generation process and then transplanted into the corresponding region of the original noisy image at each timestep, resulting in robust spatial grounding for each bounding box. In our experiments on the HRS and DrawBench benchmarks, we achieve state-of-the-art performance compared to previous training-free spatial grounding approaches.'}]}]Summarization failed, append the original article
error: Request timed out.. Line: 406.
Append: [GrounDiT: Grounding Diffusion Transformers via Noisy Patch Transplantation](https://arxiv.org/abs/2410.20474)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "FP8 training has emerged as a promising method for improving training efficiency. Existing frameworks accelerate training by applying FP8 computation to linear layers while leaving optimizer states and activations in higher precision, which fails to fully optimize memory usage. This paper introduces COAT (Compressing Optimizer States and Activations for FP8 Training), a novel FP8 training framework designed to significantly reduce memory footprint when training large models. COAT addresses current limitations through two key innovations: (1) Dynamic Range Expansion, which aligns optimizer state distributions more closely with the FP8 representation range, thereby reducing quantization error, and (2) Mixed-Granularity Activation Quantization, which optimizes activation memory using a combination of per-tensor and per-group quantization strategies. Experiments demonstrate that COAT effectively reduces end-to-end training memory footprint by 1.54x compared to BF16 while achieving nearly lossless performance across various tasks, such as Large Language Model pretraining and fine-tuning and Vision Language Model training. COAT also achieves a 1.43x end-to-end training speedup compared to BF16, performing on par with or surpassing TransformerEngine's speedup. COAT enables efficient full-parameter training of large models on fewer GPUs, and facilitates doubling the batch size in distributed training settings, providing a practical solution for scaling large-scale model training. The code is available at https://github.com/NVlabs/COAT."}]}]Summarization failed, append the original article
error: Request timed out.. Line: 406.
Append: [COAT: Compressing Optimizer states and Activation for Memory-Efficient FP8 Training](https://arxiv.org/abs/2410.19313)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "This research tests the role of Large Language Models (LLMs) as formal second opinion tools in professional decision-making, particularly focusing on complex medical cases where even experienced physicians seek peer consultation. The work analyzed 183 challenging medical cases from Medscape over a 20-month period, testing multiple LLMs' performance against crowd-sourced physician responses. A key finding was the high overall score possible in the latest foundational models (>80% accuracy compared to consensus opinion), which exceeds most human metrics reported on the same clinical cases (450 pages of patient profiles, test results). The study rates the LLMs' performance disparity between straightforward cases (>81% accuracy) and complex scenarios (43% accuracy), particularly in these cases generating substantial debate among human physicians. The research demonstrates that LLMs may be valuable as generators of comprehensive differential diagnoses rather than as primary diagnostic tools, potentially helping to counter cognitive biases in clinical decision-making, reduce cognitive loads, and thus remove some sources of medical error. The inclusion of a second comparative legal dataset (Supreme Court cases, N=21) provides added empirical context to the AI use to foster second opinions, though these legal challenges proved considerably easier for LLMs to analyze. In addition to the original contributions of empirical evidence for LLM accuracy, the research aggregated a novel benchmark for others to score highly contested question and answer reliability between both LLMs and disagreeing human practitioners. These results suggest that the optimal deployment of LLMs in professional settings may differ substantially from current approaches that emphasize automation of routine tasks."}]}]Summarization failed, append the original article
error: Request timed out.. Line: 406.
Append: [Language Models And A Second Opinion Use Case: The Pocket Professional](https://arxiv.org/abs/2410.20636)
append_entries: 6
Finish: 2024-10-29 12:02:23.345852
------------------------------------------------------
Started: 2024-10-29 15:00:48.032151
Existing_entries: 267
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1119
Summarized using gpt-4o-mini
Append: [SGRv2：一种提高样本效率的模仿学习框架](https://arxiv.org/abs/2406.10615)
Token length: 1188
Summarized using gpt-4o-mini
Append: [文档解析的现状与挑战](https://arxiv.org/abs/2410.21169)
Token length: 1061
Summarized using gpt-4o-mini
Append: [Bielik 7B v0.1：波兰语处理的七十亿参数生成文本模型](https://arxiv.org/abs/2410.18565)
Token length: 1561
Summarized using gpt-4o-mini
Append: [AgentStore：一种创新的动态异构代理集成平台](https://arxiv.org/abs/2410.18603)
append_entries: 4
Finish: 2024-10-29 15:01:14.084119
------------------------------------------------------
Started: 2024-10-29 18:00:42.528576
Existing_entries: 271
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-29 18:00:42.859353
------------------------------------------------------
Started: 2024-10-29 21:01:03.392268
Existing_entries: 271
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1491
Summarized using gpt-4o-mini
Append: [从无标注对话中高效推导结构化工作流的研究](https://arxiv.org/abs/2410.18481)
append_entries: 1
Finish: 2024-10-29 21:01:08.078352
------------------------------------------------------
Started: 2024-10-30 00:34:26.631316
Existing_entries: 272
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1157
Summarized using gpt-4o-mini
Append: [基于双层优化的模仿学习框架改善类人机器人运动模仿](https://arxiv.org/abs/2410.01968)
Token length: 1524
Summarized using gpt-4o-mini
Append: [VideoWebArena: 评估长文本视频理解的基准测试](https://arxiv.org/abs/2410.19100)
Token length: 1472
Summarized using gpt-4o-mini
Append: [递归变换器：参数共享和性能优化的新方法](https://arxiv.org/abs/2410.20672)
append_entries: 3
Finish: 2024-10-30 00:34:42.575225
------------------------------------------------------
Started: 2024-10-30 03:15:10.629121
Existing_entries: 275
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1635
Summarized using gpt-4o-mini
Append: [EoRA：一种无训练的低秩近似模型压缩补偿方法](https://arxiv.org/abs/2410.21271)
append_entries: 1
Finish: 2024-10-30 03:15:16.587428
------------------------------------------------------
Started: 2024-10-30 06:10:59.713363
Existing_entries: 276
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1335
Summarized using gpt-4o-mini
Append: [自主多模态网络代理的开发框架](https://arxiv.org/abs/2410.19609)
Token length: 1199
Summarized using gpt-4o-mini
Append: [AutoKaggle：数据科学任务的智能协作框架](https://arxiv.org/abs/2410.20424)
Token length: 1726
Summarized using gpt-4o-mini
Append: [社交关系推理框架：结合视觉基础模型与大型语言模型](https://arxiv.org/abs/2410.21411)
Token length: 1701
Summarized using gpt-4o-mini
Append: [基于操作中心性表示的机器人视觉预训练研究](https://arxiv.org/abs/2410.22325)
Token length: 855
Summarized using gpt-4o-mini
Append: [基于在线学习流的高质量推理轨迹生成方法](https://arxiv.org/abs/2410.22304)
Token length: 1539
Summarized using gpt-4o-mini
Append: [ShadowKV：高吞吐量长上下文LLM推理系统](https://arxiv.org/abs/2410.21465)
Token length: 1459
Summarized using gpt-4o-mini
Append: [基于人机协同的视觉强化学习在复杂机器人操作中的应用](https://arxiv.org/abs/2410.21845)
append_entries: 7
Finish: 2024-10-30 06:11:31.263517
------------------------------------------------------
Started: 2024-10-30 09:00:45.928077
Existing_entries: 283
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1007
Summarized using gpt-4o-mini
Append: [CLEAR: 跨模态遗忘的新基准与挑战](https://arxiv.org/abs/2410.18057)
append_entries: 1
Finish: 2024-10-30 09:00:51.948643
------------------------------------------------------
Started: 2024-10-30 12:13:07.580210
Existing_entries: 284
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-30 12:13:07.759637
------------------------------------------------------
Started: 2024-10-30 15:00:43.738504
Existing_entries: 284
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-30 15:00:43.885364
------------------------------------------------------
Started: 2024-10-30 18:01:05.525408
Existing_entries: 284
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1781
Summarized using gpt-4o-mini
Append: [链式推理对大型语言模型性能影响的研究](https://arxiv.org/abs/2410.21333)
append_entries: 1
Finish: 2024-10-30 18:01:15.240740
------------------------------------------------------
Started: 2024-10-30 21:00:41.407714
Existing_entries: 285
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1178
Summarized using gpt-4o-mini
Append: [引入前缀共享的偏好调优新方法](https://arxiv.org/abs/2410.20305)
Token length: 1328
Summarized using gpt-4o-mini
Append: [利用相关反馈的真实文档嵌入优化稠密检索系统](https://arxiv.org/abs/2410.21242)
Token length: 1351
Summarized using gpt-4o-mini
Append: [新方法评估大语言模型的记忆化风险](https://arxiv.org/abs/2410.19482)
Token length: 1083
Summarized using gpt-4o-mini
Append: [利用RARe方法提升嵌入模型在检索任务中的性能](https://arxiv.org/abs/2410.20088)
append_entries: 4
Finish: 2024-10-30 21:01:05.379451
------------------------------------------------------
Started: 2024-10-31 00:34:52.521030
Existing_entries: 289
Fetching from https://rsshub.app/huggingface/daily-papers
Fetch error: HTTPSConnectionPool(host='rsshub.app', port=443): Read timed out. (read timeout=30)
Fetch failed from https://rsshub.app/huggingface/daily-papers
append_entries: 0
error when rendering xml, skip docs/Huggingface-Daliy-Papers
------------------------------------------------------
Started: 2024-10-31 03:16:43.086059
Existing_entries: 289
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1076
Summarized using gpt-4o-mini
Append: [视觉语言模型中任务表示的内部机制研究](https://arxiv.org/abs/2410.22330)
Token length: 1001
Summarized using gpt-4o-mini
Append: [REPOCOD：评估大型语言模型在真实代码生成中的应用](https://arxiv.org/abs/2410.21647)
append_entries: 2
Finish: 2024-10-31 03:17:56.095098
------------------------------------------------------
Started: 2024-10-31 06:00:52.068280
Existing_entries: 291
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1062
Summarized using gpt-4o-mini
Append: [CORAL: 针对多轮对话的检索增强生成基准](https://arxiv.org/abs/2410.23090)
Token length: 1547
Summarized using gpt-4o-mini
Append: [自学习假设文档嵌入法在医疗信息检索中的应用](https://arxiv.org/abs/2410.20050)
append_entries: 2
Finish: 2024-10-31 06:01:04.566401
------------------------------------------------------
Started: 2024-10-31 09:00:52.680153
Existing_entries: 293
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 872
Summarized using gpt-4o-mini
Append: [通过专家选择路由攻击Mixture-of-Experts模型以披露用户提示](https://arxiv.org/abs/2410.22884)
Token length: 1033
Summarized using gpt-4o-mini
Append: [基于xLSTM的大型重复动作模型研究](https://arxiv.org/abs/2410.22391)
append_entries: 2
Finish: 2024-10-31 09:01:03.424209
------------------------------------------------------
Started: 2024-10-31 12:12:57.569246
Existing_entries: 295
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
error when rendering xml, skip docs/Huggingface-Daliy-Papers
------------------------------------------------------
Started: 2024-10-31 15:00:47.509629
Existing_entries: 295
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1473
Summarized using gpt-4o-mini
Append: [TokenFormer：一种可扩展的变换器架构解决方案](https://arxiv.org/abs/2410.23168)
append_entries: 1
Finish: 2024-10-31 15:00:54.334670
------------------------------------------------------
Started: 2024-10-31 18:00:45.210244
Existing_entries: 296
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1482
Summarized using gpt-4o-mini
Append: [开放数据的有毒内容过滤新方法](https://arxiv.org/abs/2410.22587)
append_entries: 1
Finish: 2024-10-31 18:00:50.980023
------------------------------------------------------
Started: 2024-10-31 21:01:09.847586
Existing_entries: 297
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1101
Summarized using gpt-4o-mini
Append: [通过眼动模式解码阅读目标的可能性研究](https://arxiv.org/abs/2410.20779)
Token length: 1067
Summarized using gpt-4o-mini
Append: [REM框架：基于自然语言的视频概念分割](https://arxiv.org/abs/2410.23287)
append_entries: 2
Finish: 2024-10-31 21:01:21.717566
------------------------------------------------------
Started: 2024-11-01 00:38:02.166816
Existing_entries: 299
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1863
Summarized using gpt-4o-mini
Append: [SlowFast-VGen：一种新型双速学习系统用于长视频生成](https://arxiv.org/abs/2410.23277)
Token length: 1605
Summarized using gpt-4o-mini
Append: [大语言模型的记忆化与推理能力的复杂性](https://arxiv.org/abs/2410.23123)
append_entries: 2
Finish: 2024-11-01 00:38:11.304877
------------------------------------------------------
Started: 2024-11-01 03:23:22.060873
Existing_entries: 301
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-01 03:23:22.182255
------------------------------------------------------
Started: 2024-11-01 06:10:50.374727
Existing_entries: 301
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1415
Summarized using gpt-4o-mini
Append: [Self-Lengthen：提升大语言模型长文本生成能力的新框架](https://arxiv.org/abs/2410.23933)
Token length: 1339
Summarized using gpt-4o-mini
Append: [基于约束回译的数据生成技术提升复杂指令遵循能力](https://arxiv.org/abs/2410.24175)
Token length: 1545
Summarized using gpt-4o-mini
Append: [BenchX：统一的医学视觉语言预训练基准框架](https://arxiv.org/abs/2410.21969)
Token length: 1253
Summarized using gpt-4o-mini
Append: [从合成视频和自然图像学习有效视频表示](https://arxiv.org/abs/2410.24213)
append_entries: 4
Finish: 2024-11-01 06:11:15.491642
------------------------------------------------------
Started: 2024-11-01 09:00:43.139094
Existing_entries: 305
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1292
Summarized using gpt-4o-mini
Append: [CARE系统：提升大语言模型个性化探索能力](https://arxiv.org/abs/2410.24032)
Json decode failed:
{
  "title": "利用稀疏自编码器解析文本到图像模型的潜在特征",
  "keyword": ["稀疏自编码器", "文本到图像", "生成模型"],
  "short_summary": "研究表明稀疏自编码器可为文本到图像模型提供可解释特征。",
  "summary": "本文探讨了稀疏自编码器（SAEs）在文本到图像扩散模型（如SDXL Turbo）中的应用，旨在提取可解释的特征。通过对SDXL Turbo中去噪U-net的变换器块更新进行训练，我们发现所学习的特征不仅具有可解释性，还能因果地影响生成过程，以及揭示各个块的专业化。在研究中，我们识别出处理图像组合、添加局部细节及负责颜色、照明和风格的不同块。这项研究为更好地理解像SDXL Turbo这样的生成文本到图像模型的内部工作机制开辟了重要的第一步，并展示了SAEs在视觉领域学习特征的潜力。代码可在 https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 268 (char 398). Line: 406.
Append: [Unpacking SDXL Turbo: Interpreting Text-to-Image Models with Sparse Autoencoders](https://arxiv.org/abs/2410.22366)
Token length: 1533
Summarized using gpt-4o-mini
Append: [层级梯度分析：快思维与慢思维对大型语言模型训练的影响](https://arxiv.org/abs/2410.23743)
Json decode failed:
{
  "title": "基于单目视频的高效密集3D运动跟踪方法",
  "keyword": ["3D运动跟踪", "单目视频", "深度表示"],
  "short_summary": "提出了一种新方法实现高效密集3D运动跟踪，速度提升8倍，精确度达到了最新水平。",
  "summary": "本文介绍了一种针对单目视频进行密集3D运动跟踪的新方法\Approach，该方法可以在长序列上实现像素级别的精确跟踪。通过使用联合的全球-局部注意机制进行低分辨率跟踪，并结合基于变换器的上采样器实现高分辨率预测，\Approach的计算效率大幅提升，运行速度比以往方法快8倍，同时保持了最先进的准确性。此外，研究还探讨了深度表示对跟踪性能的影响，并确定对数深度为最佳选择。通过大量实验结果表明，\Approach在多个基准测试中表现优越，为需要在3D空间中进行细粒度长期运动跟踪的应用提供了强有力的解决方案。"
}Summarization failed, append the original article
error: Invalid \escape: line 5 column 42 (char 180). Line: 406.
Append: [DELTA: Dense Efficient Long-range 3D Tracking for any video](https://arxiv.org/abs/2410.24211)
append_entries: 4
Finish: 2024-11-01 09:01:10.566601
------------------------------------------------------
Started: 2024-11-01 12:00:54.018376
Existing_entries: 309
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1664
Summarized using gpt-4o-mini
Append: [BitStack：一种新型训练无关权重压缩方法](https://arxiv.org/abs/2410.23918)
Token length: 1056
Summarized using gpt-4o-mini
Append: [多意图任务导向对话系统的研究与实现](https://arxiv.org/abs/2410.22476)
append_entries: 2
Finish: 2024-11-01 12:01:05.081973
------------------------------------------------------
Started: 2024-11-01 15:01:09.732928
Existing_entries: 311
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1805
Summarized using gpt-4o-mini
Append: [SelfCodeAlign：透明的自我对齐代码语言模型训练管道](https://arxiv.org/abs/2410.24198)
append_entries: 1
Finish: 2024-11-01 15:01:16.445619
------------------------------------------------------
Started: 2024-11-01 18:00:48.877030
Existing_entries: 312
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-01 18:00:49.040266
------------------------------------------------------
Started: 2024-11-01 21:00:46.305646
Existing_entries: 312
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1565
Summarized using gpt-4o-mini
Append: [一种新型带有瓶颈的最小熵耦合压缩框架研究](https://arxiv.org/abs/2410.21666)
Token length: 882
Summarized using gpt-4o-mini
Append: [GlotCC：覆盖1000多种语言的清洁文本语料库](https://arxiv.org/abs/2410.23825)
Token length: 1145
Summarized using gpt-4o-mini
Append: [利用丰富语言输入提升强化学习智能体的学习能力](https://arxiv.org/abs/2410.24218)
append_entries: 3
Finish: 2024-11-01 21:01:00.872009
------------------------------------------------------
Started: 2024-11-02 00:33:33.273827
Existing_entries: 315
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 853
Summarized using gpt-4o-mini
Append: [NeuZip: 一种新型神经网络权重压缩方案](https://arxiv.org/abs/2410.20650)
Token length: 1371
Summarized using gpt-4o-mini
Append: [AAAR-1.0: 评估大语言模型在科研任务中的表现](https://arxiv.org/abs/2410.22394)
append_entries: 2
Finish: 2024-11-02 00:33:51.005140
------------------------------------------------------
Started: 2024-11-02 03:12:32.937913
Existing_entries: 317
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-02 03:12:33.021613
------------------------------------------------------
Started: 2024-11-02 06:08:58.019039
Existing_entries: 317
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-02 06:08:58.159857
------------------------------------------------------
Started: 2024-11-02 09:00:55.020260
Existing_entries: 317
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-02 09:00:55.103870
------------------------------------------------------
Started: 2024-11-02 12:00:58.832351
Existing_entries: 317
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-02 12:00:58.996827
------------------------------------------------------
Started: 2024-11-02 15:00:53.920157
Existing_entries: 317
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-02 15:00:53.981649
------------------------------------------------------
Started: 2024-11-02 18:00:46.541487
Existing_entries: 317
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-02 18:00:46.650186
------------------------------------------------------
Started: 2024-11-02 21:01:02.928188
Existing_entries: 317
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-02 21:01:03.042401
------------------------------------------------------
Started: 2024-11-03 00:37:29.054479
Existing_entries: 317
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-03 00:37:29.179877
------------------------------------------------------
Started: 2024-11-03 03:18:22.791792
Existing_entries: 317
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-03 03:18:22.880421
------------------------------------------------------
Started: 2024-11-03 06:01:09.861696
Existing_entries: 317
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-03 06:01:09.982638
------------------------------------------------------
Started: 2024-11-03 09:00:50.413159
Existing_entries: 317
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-03 09:00:50.579769
------------------------------------------------------
Started: 2024-11-03 12:00:25.932679
Existing_entries: 317
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-03 12:00:25.986016
------------------------------------------------------
Started: 2024-11-03 15:00:45.096176
Existing_entries: 317
Fetching from https://rsshub.app/huggingface/daily-papers
Fetch error: HTTPSConnectionPool(host='rsshub.app', port=443): Read timed out. (read timeout=30)
Fetch failed from https://rsshub.app/huggingface/daily-papers
append_entries: 0
error when rendering xml, skip docs/Huggingface-Daliy-Papers
------------------------------------------------------
Started: 2024-11-03 18:01:00.435880
Existing_entries: 317
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-03 18:01:00.693604
------------------------------------------------------
Started: 2024-11-03 21:00:36.521385
Existing_entries: 317
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-03 21:00:36.597407
------------------------------------------------------
Started: 2024-11-04 00:36:38.093529
Existing_entries: 317
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-04 00:36:38.205438
------------------------------------------------------
Started: 2024-11-04 03:18:24.255552
Existing_entries: 317
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-04 03:18:24.406676
------------------------------------------------------
Started: 2024-11-04 06:00:57.009539
Existing_entries: 317
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1255
Summarized using gpt-4o-mini
Append: [M2RC-EVAL: 多语言代码补全基准与数据集](https://arxiv.org/abs/2410.21157)
Json decode failed:
{
  "title": "随机自回归建模(RAR)在视觉生成中的新突破",
  "short_summary": "RAR模型在图像生成任务上创新性地达成新标杆表现。",
  "summary": "本文提出了一种随机自回归建模（RAR）方法用于视觉生成，显著提升了图像生成的性能，并与语言建模框架完全兼容。在标准自回归训练过程中，输入序列按概率r随机打乱排列，r从1线性衰减到0。这种退火训练策略使模型能够学习在所有因式分解顺序上最大化期望似然，从而有效提升了模型对双向上下文的建模能力。RAR在保持自回归建模框架完整性的同时，显著改善了图像生成的性能。在ImageNet-256基准测试中，RAR获得了1.48的FID分数，不仅超越了以往的自回归图像生成器，还优于领先的扩散基础和掩蔽变换基础方法。代码和模型将发布于https:
  "keyword": ["自回归建模", "视觉生成", "图像生成"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 281 (char 367). Line: 406.
Append: [Randomized Autoregressive Visual Generation](https://arxiv.org/abs/2411.00776)
Token length: 1581
Summarized using gpt-4o-mini
Append: [利用IC-LoRA优化文本到图像的生成能力](https://arxiv.org/abs/2410.23775)
Token length: 1389
Summarized using gpt-4o-mini
Append: [基于人类问题解决过程的双组件微调方法提升大型语言模型的科学问题解答能力](https://arxiv.org/abs/2411.00412)
append_entries: 4
Finish: 2024-11-04 06:01:15.114991
------------------------------------------------------
Started: 2024-11-04 09:01:10.576945
Existing_entries: 321
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-04 09:01:10.671481
------------------------------------------------------
Started: 2024-11-04 12:13:30.989833
Existing_entries: 321
Fetching from https://rsshub.app/huggingface/daily-papers
Fetch error: HTTPSConnectionPool(host='rsshub.app', port=443): Read timed out. (read timeout=30)
Fetch failed from https://rsshub.app/huggingface/daily-papers
append_entries: 0
error when rendering xml, skip docs/Huggingface-Daliy-Papers
------------------------------------------------------
Started: 2024-11-04 15:00:58.229243
Existing_entries: 321
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1310
Summarized using gpt-4o-mini
Append: [基于词频的embedding空间校正提升任务性能](https://arxiv.org/abs/2411.00680)
Token length: 1338
Summarized using gpt-4o-mini
Append: [引入常加速度流的图像生成新框架](https://arxiv.org/abs/2411.00322)
Token length: 840
Summarized using gpt-4o-mini
Append: [提升WikiNER语料库质量的研究](https://arxiv.org/abs/2411.00030)
Token length: 1444
Summarized using gpt-4o-mini
Append: [推出OS-Atlas：增强开源GUI代理的基础模型](https://arxiv.org/abs/2410.23218)
Token length: 994
Summarized using gpt-4o-mini
Append: [SambaMixer：一种用于锂离子电池健康状态预测的新结构化状态空间模型](https://arxiv.org/abs/2411.00233)
Token length: 995
Summarized using gpt-4o-mini
Append: [人机交互中的生成式AI应用及其用户界面设计](https://arxiv.org/abs/2410.22370)
Token length: 1102
Summarized using gpt-4o-mini
Append: [引入图推理结构的问答数据集GRS-QA](https://arxiv.org/abs/2411.00369)
Token length: 1383
Summarized using gpt-4o-mini
Append: [个性化大语言模型的使用与挑战](https://arxiv.org/abs/2411.00027)
Token length: 774
Summarized using gpt-4o-mini
Append: [高效适配器插入方案提升文本到图像模型性能](https://arxiv.org/abs/2410.22901)
append_entries: 9
Finish: 2024-11-04 15:01:49.938091
------------------------------------------------------
Started: 2024-11-04 18:00:50.259627
Existing_entries: 330
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1399
Summarized using gpt-4o-mini
Append: [CityGaussianV2：大型场景重建的新方法](https://arxiv.org/abs/2411.00771)
Token length: 1016
Summarized using gpt-4o-mini
Append: [基于扩散模型的人脸匿名化技术研究](https://arxiv.org/abs/2411.00762)
Token length: 561
Summarized using gpt-4o-mini
Append: [结合掩蔽语言建模与因果语言建模的混合训练方法](https://arxiv.org/abs/2410.24159)
append_entries: 3
Finish: 2024-11-04 18:01:08.135069
------------------------------------------------------
Started: 2024-11-04 21:01:03.035570
Existing_entries: 333
Fetching from https://rsshub.app/huggingface/daily-papers
Summarization failed, append the original article
error: 'NoneType' object has no attribute 'group'. Line: 406.
Append: [Physics in Next-token Prediction](https://arxiv.org/abs/2411.00660)
Token length: 1719
Summarized using gpt-4o-mini
Append: [TOMATO：评估多模态基础模型在视频理解中的时间推理能力](https://arxiv.org/abs/2410.23266)
append_entries: 2
Finish: 2024-11-04 21:01:17.736778
------------------------------------------------------
Started: 2024-11-05 00:33:45.853665
Existing_entries: 335
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1069
Summarized using gpt-4o-mini
Append: [Fashion-VDM：视频虚拟试穿的新方法](https://arxiv.org/abs/2411.00225)
append_entries: 1
Finish: 2024-11-05 00:33:50.487407
------------------------------------------------------
Started: 2024-11-05 03:11:28.832745
Existing_entries: 336
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1874
Summarized using gpt-4o-mini
Append: [探讨视觉语言模型的数学推理能力及DynaMath基准的开发](https://arxiv.org/abs/2411.00836)
append_entries: 1
Finish: 2024-11-05 03:11:33.566987
------------------------------------------------------
Started: 2024-11-05 06:10:19.443031
Existing_entries: 337
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-05 06:10:19.543680
------------------------------------------------------
Started: 2024-11-05 09:00:44.917981
Existing_entries: 337
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1296
Summarized using gpt-4o-mini
Append: [基于CamVid-30K数据集的3D和4D生成框架GenXD](https://arxiv.org/abs/2411.02319)
Token length: 1272
Summarized using gpt-4o-mini
Append: [Hunyuan-Large：最强大的开源Transformer专家模型](https://arxiv.org/abs/2411.02265)
Token length: 1895
Summarized using gpt-4o-mini
Append: [解码器Transformer基模型中激活稀疏性的量化研究](https://arxiv.org/abs/2411.02335)
Json decode failed:
{
  "title": "AndroidLab：系统化的安卓智能体框架",
  "keyword": ["安卓智能体", "系统框架", "开放源代码"],
  "short_summary": "AndroidLab提供了一种系统化的安卓智能体训练与评估框架。",
  "summary": "随着自主智能体在现实世界中互动的重要性日益增加，安卓智能体作为一种新兴的交互方式逐渐受到关注。现有的研究在训练和评估安卓智能体方面缺乏系统性的研究。本文提出了AndroidLab，一个系统化的安卓智能体框架，包含不同模态和动作空间的操作环境，以及一个可复现的基准。AndroidLab支持大型语言模型（LLMs）和多模态模型（LMMs）在同一动作空间中工作，基准测试涵盖了预定义的安卓虚拟设备和九个应用中的138个任务。通过使用AndroidLab环境，我们开发了安卓指令数据集并训练了六个开源的LLMs和LMMs，成功率分别从4.59%提高到21.50%（LLMs）和从1.93%提高到13.28%（LMMs）。AndroidLab已开源并可在https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 344 (char 478). Line: 406.
Append: [AndroidLab: Training and Systematic Benchmarking of Android Autonomous Agents](https://arxiv.org/abs/2410.24024)
Token length: 1457
Summarized using gpt-4o-mini
Append: [WebRL：开放LLM的在线强化学习框架](https://arxiv.org/abs/2411.02337)
Token length: 1234
Summarized using gpt-4o-mini
Append: [AdaCache：加速视频生成的自适应缓存方法](https://arxiv.org/abs/2411.02397)
Token length: 1195
Summarized using gpt-4o-mini
Append: [专用稀疏自编码器：揭示基础模型中的关键概念](https://arxiv.org/abs/2411.00743)
Token length: 1752
Summarized using gpt-4o-mini
Append: [视频生成模型对物理规律的学习与评估](https://arxiv.org/abs/2411.02385)
Token length: 1164
Summarized using gpt-4o-mini
Append: [LibMoE: 提升混合专家算法在大语言模型中的可访问性](https://arxiv.org/abs/2411.00918)
append_entries: 9
Finish: 2024-11-05 09:01:32.171287
------------------------------------------------------
Started: 2024-11-05 12:13:32.384658
Existing_entries: 346
Fetching from https://rsshub.app/huggingface/daily-papers
Summarization failed, append the original article
error: 'NoneType' object has no attribute 'group'. Line: 406.
Append: [Survey of Cultural Awareness in Language Models: Text and Beyond](https://arxiv.org/abs/2411.00860)
Summarization failed, append the original article
error: 'NoneType' object has no attribute 'group'. Line: 406.
Append: [DynaSaur: Large Language Agents Beyond Predefined Actions](https://arxiv.org/abs/2411.01747)
Summarization failed, append the original article
error: 'NoneType' object has no attribute 'group'. Line: 406.
Append: [Training-free Regional Prompting for Diffusion Transformers](https://arxiv.org/abs/2411.02395)
append_entries: 3
Finish: 2024-11-05 12:13:56.297370
------------------------------------------------------
Started: 2024-11-05 15:00:49.763018
Existing_entries: 349
Fetching from https://rsshub.app/huggingface/daily-papers
Summarization failed, append the original article
error: 'NoneType' object has no attribute 'group'. Line: 406.
Append: [Swan and ArabicMTEB: Dialect-Aware, Arabic-Centric, Cross-Lingual, and Cross-Cultural Embedding Models and Benchmarks](https://arxiv.org/abs/2411.01192)
append_entries: 1
Finish: 2024-11-05 15:00:59.310920
------------------------------------------------------
Started: 2024-11-05 18:00:44.213959
Existing_entries: 350
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1768
Summarized using gpt-4o-mini
Append: [MVPaint：一种新型的3D纹理生成与优化框架](https://arxiv.org/abs/2411.02336)
Token length: 1625
Summarized using gpt-4o-mini
Append: [PPLLaVA：一种适用于长短视频理解的新型模型](https://arxiv.org/abs/2411.02327)
Token length: 1719
Summarized using gpt-4o-mini
Append: [量化大语言模型的准确性与性能权衡研究](https://arxiv.org/abs/2411.02355)
append_entries: 3
Finish: 2024-11-05 18:00:59.495142
------------------------------------------------------
Started: 2024-11-05 21:00:57.927591
Existing_entries: 353
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-05 21:00:58.065325
------------------------------------------------------
Started: 2024-11-06 00:33:18.656904
Existing_entries: 353
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1676
Summarized using gpt-4o-mini
Append: [SALSA：改进大语言模型的强化学习人类反馈方法](https://arxiv.org/abs/2411.01798)
Token length: 951
Summarized using gpt-4o-mini
Append: [AutoVFX：基于自然语言的自动化视觉特效生成框架](https://arxiv.org/abs/2411.02394)
Token length: 884
Summarized using gpt-4o-mini
Append: [基于预训练扩散模型的高效噪声线性逆问题求解算法](https://arxiv.org/abs/2411.00359)
Token length: 1281
Summarized using gpt-4o-mini
Append: [图像目标表征 (IGOR)：跨人机学习的统一动作空间](https://arxiv.org/abs/2411.00785)
Token length: 989
Summarized using gpt-4o-mini
Append: [LoCAL：增强大型多模态模型的长文档理解能力](https://arxiv.org/abs/2411.01106)
Token length: 1065
Summarized using gpt-4o-mini
Append: [多专家提示：提升大语言模型生成效果的新方法](https://arxiv.org/abs/2411.00492)
append_entries: 6
Finish: 2024-11-06 00:33:52.279773
------------------------------------------------------
Started: 2024-11-06 03:10:46.791483
Existing_entries: 359
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-06 03:10:47.077501
------------------------------------------------------
Started: 2024-11-06 06:00:38.567518
Existing_entries: 359
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1840
Summarized using gpt-4o-mini
Append: [Zebra-Llama：针对罕见疾病的专业语言模型](https://arxiv.org/abs/2411.02657)
Token length: 1236
Summarized using gpt-4o-mini
Append: [LLaMo：基于大语言模型的分子图助手](https://arxiv.org/abs/2411.00871)
Token length: 1721
Summarized using gpt-4o-mini
Append: [动态早期退出框架：提高机器人视觉语言动作模型的效率](https://arxiv.org/abs/2411.02359)
Token length: 1559
Summarized using gpt-4o-mini
Append: [HtmlRAG：提升RAG系统知识能力的HTML利用方法](https://arxiv.org/abs/2411.02959)
append_entries: 4
Finish: 2024-11-06 06:00:57.313217
------------------------------------------------------
Started: 2024-11-06 09:00:57.023875
Existing_entries: 363
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "We study methods for efficiently aligning large language models (LLMs) with human preferences given budgeted online feedback. We first formulate the LLM alignment problem in the frame of contextual dueling bandits. This formulation, subsuming recent paradigms such as online RLHF and online DPO, inherently quests for sample-efficient algorithms that incorporate online active exploration. Leveraging insights from bandit theory, we introduce a unified algorithm based on Thompson sampling and highlight its applications in two distinct LLM alignment scenarios. The practical agent that efficiently implements this algorithm, named SEA (Sample-Efficient Alignment), is empirically validated through extensive experiments across three model scales (1B, 2.8B, 6.9B) and three preference learning algorithms (DPO, IPO, SLiC). The results demonstrate that SEA achieves highly sample-efficient alignment with oracle's preferences, outperforming recent active exploration methods for LLMs. Additionally, we release the implementation of SEA together with an efficient codebase designed for online alignment of LLMs, aiming to accelerate future research in this field."}]}]Summarization failed, append the original article
error: Error code: 503 - {'error': {'code': 503, 'message': 'Service Unavailable.', 'param': None, 'type': 'cf_service_unavailable'}}. Line: 406.
Append: [Sample-Efficient Alignment for LLMs](https://arxiv.org/abs/2411.01493)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We introduce DreamPolish, a text-to-3D generation model that excels in producing refined geometry and high-quality textures. In the geometry construction phase, our approach leverages multiple neural representations to enhance the stability of the synthesis process. Instead of relying solely on a view-conditioned diffusion prior in the novel sampled views, which often leads to undesired artifacts in the geometric surface, we incorporate an additional normal estimator to polish the geometry details, conditioned on viewpoints with varying field-of-views. We propose to add a surface polishing stage with only a few training steps, which can effectively refine the artifacts attributed to limited guidance from previous stages and produce 3D objects with more desirable geometry. The key topic of texture generation using pretrained text-to-image models is to find a suitable domain in the vast latent distribution of these models that contains photorealistic and consistent renderings. In the texture generation phase, we introduce a novel score distillation objective, namely domain score distillation (DSD), to guide neural representations toward such a domain. We draw inspiration from the classifier-free guidance (CFG) in textconditioned image generation tasks and show that CFG and variational distribution guidance represent distinct aspects in gradient guidance and are both imperative domains for the enhancement of texture quality. Extensive experiments show our proposed model can produce 3D assets with polished surfaces and photorealistic textures, outperforming existing state-of-the-art methods.'}]}]Summarization failed, append the original article
error: Error code: 503 - {'error': {'code': 503, 'message': 'Service Unavailable.', 'param': None, 'type': 'cf_service_unavailable'}}. Line: 406.
Append: [DreamPolish: Domain Score Distillation With Progressive Geometry Generation](https://arxiv.org/abs/2411.01602)
append_entries: 2
Finish: 2024-11-06 09:01:00.713728
------------------------------------------------------
Started: 2024-11-06 12:00:58.780826
Existing_entries: 365
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-06 12:00:58.862477
------------------------------------------------------
Started: 2024-11-06 15:00:45.808819
Existing_entries: 365
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1281
Summarized using gpt-4o-mini
Append: [视觉显著性与物体检测准确性的关系研究](https://arxiv.org/abs/2411.02844)
Token length: 1124
Summarized using gpt-4o-mini
Append: [基于激活传输的模型生成控制框架](https://arxiv.org/abs/2410.23054)
append_entries: 2
Finish: 2024-11-06 15:00:54.158947
------------------------------------------------------
Started: 2024-11-06 18:01:00.409874
Existing_entries: 367
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1863
Summarized using gpt-4o-mini
Append: [GarVerseLOD：高保真3D服装重建的新数据集与框架](https://arxiv.org/abs/2411.03047)
append_entries: 1
Finish: 2024-11-06 18:01:05.976195
------------------------------------------------------
Started: 2024-11-06 21:00:53.687388
Existing_entries: 368
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1136
Summarized using gpt-4o-mini
Append: [基于可变长度表示的2D图像编码解码方法](https://arxiv.org/abs/2411.02393)
Token length: 1622
Summarized using gpt-4o-mini
Append: [视觉语言模型中的输入令牌压缩与推理优化](https://arxiv.org/abs/2411.03312)
append_entries: 2
Finish: 2024-11-06 21:01:00.701184
------------------------------------------------------
Started: 2024-11-07 00:33:33.412317
Existing_entries: 370
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-07 00:33:33.542054
------------------------------------------------------
Started: 2024-11-07 03:14:16.600585
Existing_entries: 370
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-07 03:14:16.721820
------------------------------------------------------
Started: 2024-11-07 06:10:12.354644
Existing_entries: 370
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-07 06:10:12.491785
------------------------------------------------------
Started: 2024-11-07 09:00:40.179665
Existing_entries: 370
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-07 09:00:40.313950
------------------------------------------------------
Started: 2024-11-07 12:12:09.487222
Existing_entries: 370
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-07 12:12:09.607116
------------------------------------------------------
Started: 2024-11-07 15:00:59.709606
Existing_entries: 370
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1907
Summarized using gpt-4o-mini
Append: [Agent K v1.0：全自动数据科学代理的创新与应用](https://arxiv.org/abs/2411.03562)
Token length: 1015
Summarized using gpt-4o-mini
Append: [MM-Detect: 一种针对多模态大语言模型的数据污染检测框架](https://arxiv.org/abs/2411.03823)
append_entries: 2
Finish: 2024-11-07 15:01:11.144112
------------------------------------------------------
Started: 2024-11-07 18:09:06.833393
Existing_entries: 372
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "PolyCom: 新型多项式复合激活函数提升Transformer表现",
  "keyword": ["Transformer", "PolyCom", "激活函数"],
  "short_summary": "PolyCom激活函数优化Transformer性能，显著提升模型表现。",
  "summary": "本论文提出了一种新颖的多项式复合激活函数（PolyCom），旨在优化Transformer网络的动态特性。通过全面的数学分析，论文强调了PolyCom相较于其他激活函数的优越表现和提升的表达能力。实验结果表明，采用PolyCom的网络能够以最小参数近似Sobolev空间中的光滑函数，且在大型语言模型的预训练配置上展现出更高的准确性和收敛速度。此外，实验还显示了PolyCom在捕捉高阶数据交互方面的优势，相较于传统激活函数，PolyCom显著提高了性能指标。研究成果及代码可访问https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 261 (char 420). Line: 406.
Append: [Polynomial Composition Activations: Unleashing the Dynamics of Large Language Models](https://arxiv.org/abs/2411.03884)
Token length: 1083
Summarized using gpt-4o-mini
Append: [自我一致性偏好优化：提升模型推理能力的新方法](https://arxiv.org/abs/2411.04109)
append_entries: 2
Finish: 2024-11-07 18:09:21.083876
------------------------------------------------------
Started: 2024-11-07 21:00:55.372600
Existing_entries: 374
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1884
Summarized using gpt-4o-mini
Append: [探索o1-preview模型在医学挑战基准上的表现](https://arxiv.org/abs/2411.03590)
append_entries: 1
Finish: 2024-11-07 21:00:59.370382
------------------------------------------------------
Started: 2024-11-08 00:33:27.495793
Existing_entries: 375
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-08 00:33:27.600549
------------------------------------------------------
Started: 2024-11-08 03:11:30.043745
Existing_entries: 375
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1511
Summarized using gpt-4o-mini
Append: [推出TIP-I2V：首个大规模图像到视频生成用户提示数据集](https://arxiv.org/abs/2411.04709)
Token length: 956
Summarized using gpt-4o-mini
Append: [ReCapture：基于用户视频生成新视角视频的方法](https://arxiv.org/abs/2411.05003)
append_entries: 2
Finish: 2024-11-08 03:11:39.694871
------------------------------------------------------
Started: 2024-11-08 06:10:20.498646
Existing_entries: 377
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1920
Summarized using gpt-4o-mini
Append: [GazeGen: 基于视线控制的视觉内容生成系统](https://arxiv.org/abs/2411.04335)
Token length: 1351
Summarized using gpt-4o-mini
Append: [多面化心智技能对话数据集及其在大语言模型中的应用](https://arxiv.org/abs/2411.04496)
Token length: 1334
Summarized using gpt-4o-mini
Append: [多语言环境中代码混合对信息提取的挑战与解决方案](https://arxiv.org/abs/2411.04752)
Token length: 1421
Summarized using gpt-4o-mini
Append: [DimensionX框架：从单张图像生成真实感3D和4D场景](https://arxiv.org/abs/2411.04928)
Token length: 1612
Summarized using gpt-4o-mini
Append: [OpenCoder：独特的高质量代码语言模型及其开放研究价值](https://arxiv.org/abs/2411.04905)
Token length: 1571
Summarized using gpt-4o-mini
Append: [Mixture-of-Transformers：高效的多模态大语言模型架构](https://arxiv.org/abs/2411.04996)
Token length: 1046
Summarized using gpt-4o-mini
Append: [SG-I2V：一种自我引导的可控图像到视频生成框架](https://arxiv.org/abs/2411.04989)
Token length: 1383
Summarized using gpt-4o-mini
Append: [DynaMem：动态空间语义记忆驱动的开放词汇移动操控](https://arxiv.org/abs/2411.04999)
append_entries: 8
Finish: 2024-11-08 06:11:07.632627
------------------------------------------------------
Started: 2024-11-08 09:00:41.514318
Existing_entries: 385
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 958
Summarized using gpt-4o-mini
Append: [BitNet a4.8: 高效的4-bit激活的大型语言模型](https://arxiv.org/abs/2411.04965)
Token length: 1890
Summarized using gpt-4o-mini
Append: [SVDQuant：提升扩散模型的4位量化效率](https://arxiv.org/abs/2411.05007)
append_entries: 2
Finish: 2024-11-08 09:00:57.853113
------------------------------------------------------
Started: 2024-11-08 12:00:56.282384
Existing_entries: 387
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1412
Summarized using gpt-4o-mini
Append: [长文本语言模型的上下文处理能力评估](https://arxiv.org/abs/2411.05000)
Token length: 1343
Summarized using gpt-4o-mini
Append: [VideoGLaMM：实现视频与文本的细粒度对齐](https://arxiv.org/abs/2411.04923)
append_entries: 2
Finish: 2024-11-08 12:01:03.668071
------------------------------------------------------
Started: 2024-11-08 15:00:47.826454
Existing_entries: 389
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-08 15:00:47.978854
------------------------------------------------------
Started: 2024-11-08 18:00:50.336037
Existing_entries: 389
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-08 18:00:50.501034
------------------------------------------------------
Started: 2024-11-08 21:00:58.137442
Existing_entries: 389
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1209
Summarized using gpt-4o-mini
Append: [M3SciQA: 多模态多文档科学问答基准的提出与评估](https://arxiv.org/abs/2411.04075)
Token length: 1833
Summarized using gpt-4o-mini
Append: [引入M3DocRAG框架提升文档视觉问答能力](https://arxiv.org/abs/2411.04952)
Token length: 1255
Summarized using gpt-4o-mini
Append: [Diff-2-in-1：统一的扩散模型框架用于多模态生成与视觉感知](https://arxiv.org/abs/2411.05005)
append_entries: 3
Finish: 2024-11-08 21:01:08.332085
------------------------------------------------------
Started: 2024-11-09 00:32:39.628836
Existing_entries: 392
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1507
Summarized using gpt-4o-mini
Append: [分析视觉语言的统计特性与自然语言的对比](https://arxiv.org/abs/2411.05001)
append_entries: 1
Finish: 2024-11-09 00:32:42.947922
------------------------------------------------------
Started: 2024-11-09 03:10:27.808449
Existing_entries: 393
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-09 03:10:27.906316
------------------------------------------------------
Started: 2024-11-09 06:00:39.105868
Existing_entries: 393
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-09 06:00:39.267658
------------------------------------------------------
Started: 2024-11-09 09:00:36.651014
Existing_entries: 393
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-09 09:00:36.756563
------------------------------------------------------
Started: 2024-11-09 12:00:49.293744
Existing_entries: 393
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-09 12:00:49.447056
------------------------------------------------------
Started: 2024-11-09 15:01:03.494284
Existing_entries: 393
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-09 15:01:03.645144
------------------------------------------------------
Started: 2024-11-09 18:00:41.126500
Existing_entries: 393
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-09 18:00:41.291889
------------------------------------------------------
Started: 2024-11-09 21:01:03.565610
Existing_entries: 393
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-09 21:01:03.723186
------------------------------------------------------
Started: 2024-11-10 00:36:21.938087
Existing_entries: 393
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-10 00:36:22.038221
------------------------------------------------------
Started: 2024-11-10 03:13:14.247859
Existing_entries: 393
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-10 03:13:14.397292
------------------------------------------------------
Started: 2024-11-10 06:00:40.554827
Existing_entries: 393
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-10 06:00:40.727222
------------------------------------------------------
Started: 2024-11-10 09:00:58.612947
Existing_entries: 393
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-10 09:00:58.798388
------------------------------------------------------
Started: 2024-11-10 12:10:51.162052
Existing_entries: 393
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-10 12:10:51.296592
------------------------------------------------------
Started: 2024-11-10 15:00:46.764776
Existing_entries: 393
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-10 15:00:47.001235
------------------------------------------------------
Started: 2024-11-10 18:00:59.130885
Existing_entries: 393
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-10 18:00:59.246836
------------------------------------------------------
Started: 2024-11-10 21:00:48.424978
Existing_entries: 393
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-10 21:00:48.528694
------------------------------------------------------
Started: 2024-11-11 00:34:59.742890
Existing_entries: 393
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-11 00:34:59.896504
------------------------------------------------------
Started: 2024-11-11 03:13:27.425704
Existing_entries: 393
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-11 03:13:27.547536
------------------------------------------------------
Started: 2024-11-11 06:00:42.801546
Existing_entries: 393
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1490
Summarized using gpt-4o-mini
Append: [大语言模型单元测试生成的参数高效微调研究](https://arxiv.org/abs/2411.02462)
Token length: 1504
Summarized using gpt-4o-mini
Append: [StdGEN：从单幅图像生成高质量3D角色的创新管道](https://arxiv.org/abs/2411.05738)
append_entries: 2
Finish: 2024-11-11 06:00:50.158946
------------------------------------------------------
Started: 2024-11-11 09:00:52.961159
Existing_entries: 395
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-11 09:00:53.051939
------------------------------------------------------
Started: 2024-11-11 12:13:07.362918
Existing_entries: 395
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1742
Summarized using gpt-4o-mini
Append: [利用代码注释识别技术债务的首个数据集构建与实证分析](https://arxiv.org/abs/2411.05457)
Token length: 1402
Summarized using gpt-4o-mini
Append: [DELIFT：提高大语言模型微调效率的创新算法](https://arxiv.org/abs/2411.04425)
Token length: 1457
Summarized using gpt-4o-mini
Append: [通过词汇并行与管道调度优化大语言模型训练](https://arxiv.org/abs/2411.05288)
append_entries: 3
Finish: 2024-11-11 12:13:20.724797
------------------------------------------------------
Started: 2024-11-11 15:00:45.833235
Existing_entries: 398
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-11 15:00:45.941805
------------------------------------------------------
Started: 2024-11-11 18:00:34.918432
Existing_entries: 398
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1762
Summarized using gpt-4o-mini
Append: [LLM2CLIP：利用大型语言模型提升CLIP的多模态表示学习](https://arxiv.org/abs/2411.04997)
append_entries: 1
Finish: 2024-11-11 18:00:38.866854
------------------------------------------------------
Started: 2024-11-11 21:01:00.624624
Existing_entries: 399
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1353
Summarized using gpt-4o-mini
Append: [现代语言模型的语义枢纽假设](https://arxiv.org/abs/2411.04986)
append_entries: 1
Finish: 2024-11-11 21:01:05.445445
------------------------------------------------------
Started: 2024-11-12 00:33:01.191000
Existing_entries: 400
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1420
Summarized using gpt-4o-mini
Append: [RaVL：基于局部特征的视觉语言模型鲁棒性提升方法](https://arxiv.org/abs/2411.04097)
append_entries: 1
Finish: 2024-11-12 00:33:04.637206
------------------------------------------------------
Started: 2024-11-12 03:09:56.123355
Existing_entries: 401
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1559
Summarized using gpt-4o-mini
Append: [CAD-MLLM：基于多模态输入的统一计算机辅助设计生成系统](https://arxiv.org/abs/2411.04954)
Token length: 1214
Summarized using gpt-4o-mini
Append: [LaTent Reasoning Optimization：提升大语言模型推理能力的框架](https://arxiv.org/abs/2411.04282)
append_entries: 2
Finish: 2024-11-12 03:10:02.964887
------------------------------------------------------
Started: 2024-11-12 06:01:08.475557
Existing_entries: 403
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-12 06:01:08.620926
------------------------------------------------------
Started: 2024-11-12 09:00:48.156448
Existing_entries: 403
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 512
Summarized using gpt-4o-mini
Append: [Edify Image：新一代图像生成扩散模型](https://arxiv.org/abs/2411.07126)
Token length: 1134
Summarized using gpt-4o-mini
Append: [TRACE基准与IOPO方法：提升大型语言模型复杂指令跟随能力](https://arxiv.org/abs/2411.06208)
Token length: 1383
Summarized using gpt-4o-mini
Append: [基于反事实推理的语言模型干预机制研究](https://arxiv.org/abs/2411.07180)
Token length: 1365
Summarized using gpt-4o-mini
Append: [M-LongDoc：多模态长文档问答的新基准和框架](https://arxiv.org/abs/2411.06176)
Token length: 1697
Summarized using gpt-4o-mini
Append: [金色基准：评估金融领域大型语言模型的首个综合双语基准](https://arxiv.org/abs/2411.06272)
append_entries: 5
Finish: 2024-11-12 09:01:07.620972
------------------------------------------------------
Started: 2024-11-12 12:01:04.917591
Existing_entries: 408
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1147
Summarized using gpt-4o-mini
Append: [Add-it：无须训练的语义图像编辑新方法](https://arxiv.org/abs/2411.07232)
Token length: 1828
Summarized using gpt-4o-mini
Append: [大型语言模型在博弈理论中的理性决策能力研究](https://arxiv.org/abs/2411.05990)
Token length: 1100
Summarized using gpt-4o-mini
Append: [发布中文SimpleQA基准，评估大型语言模型的 factuality 能力](https://arxiv.org/abs/2411.07140)
Token length: 1748
Summarized using gpt-4o-mini
Append: [OmniEdit：一种通用图像编辑模型](https://arxiv.org/abs/2411.07199)
append_entries: 4
Finish: 2024-11-12 12:01:23.907734
------------------------------------------------------
Started: 2024-11-12 15:01:03.186268
Existing_entries: 412
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1154
Summarized using gpt-4o-mini
Append: [深度学习水印模型WAM实现局部图像水印嵌入](https://arxiv.org/abs/2411.07231)
Token length: 1068
Summarized using gpt-4o-mini
Append: [直接偏好优化在语言模型毒性降低中的作用机制探讨](https://arxiv.org/abs/2411.06424)
Token length: 1469
Summarized using gpt-4o-mini
Append: [针对人类动作生成的新型KMM架构研究](https://arxiv.org/abs/2411.06481)
append_entries: 3
Finish: 2024-11-12 15:01:19.147786
------------------------------------------------------
Started: 2024-11-12 18:09:02.248240
Existing_entries: 415
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1526
Summarized using gpt-4o-mini
Append: [GitChameleon: 适应版本变化的Python代码生成基准](https://arxiv.org/abs/2411.05830)
Token length: 1200
Summarized using gpt-4o-mini
Append: [混合专家模型在多任务纠错中的应用与性能提升](https://arxiv.org/abs/2411.05945)
append_entries: 2
Finish: 2024-11-12 18:09:10.332686
------------------------------------------------------
Started: 2024-11-12 21:01:07.769458
Existing_entries: 417
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-12 21:01:07.910702
------------------------------------------------------
Started: 2024-11-13 00:33:52.906990
Existing_entries: 417
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1848
Summarized using gpt-4o-mini
Append: [小型蛋白语言模型的开发与性能评估](https://arxiv.org/abs/2411.05966)
Token length: 1760
Summarized using gpt-4o-mini
Append: [自回归模型在计算机视觉中的应用与挑战](https://arxiv.org/abs/2411.05902)
append_entries: 2
Finish: 2024-11-13 00:33:59.679770
------------------------------------------------------
Started: 2024-11-13 03:12:44.624970
Existing_entries: 419
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-13 03:12:44.806006
------------------------------------------------------
Started: 2024-11-13 06:00:54.361811
Existing_entries: 419
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-13 06:00:54.459495
------------------------------------------------------
Started: 2024-11-13 09:00:44.109472
Existing_entries: 419
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1710
Summarized using gpt-4o-mini
Append: [SAMPart3D：无文本提示的可扩展零-shot 3D 部件分割框架](https://arxiv.org/abs/2411.07184)
append_entries: 1
Finish: 2024-11-13 09:00:50.000369
------------------------------------------------------
Started: 2024-11-13 12:12:32.951513
Existing_entries: 420
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1300
Summarized using gpt-4o-mini
Append: [挑战传统观念：大型语言模型教学效能的新发现](https://arxiv.org/abs/2411.07133)
Token length: 985
Summarized using gpt-4o-mini
Append: [JanusFlow：统一图像理解与生成的强大框架](https://arxiv.org/abs/2411.07975)
append_entries: 2
Finish: 2024-11-13 12:12:44.350314
------------------------------------------------------
Started: 2024-11-13 15:00:52.705071
Existing_entries: 422
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1728
Summarized using gpt-4o-mini
Append: [硬件与软件平台推理方法的提出与验证](https://arxiv.org/abs/2411.05197)
Token length: 1394
Summarized using gpt-4o-mini
Append: [Wavelet潜在扩散：一种高效的3D生成模型方法](https://arxiv.org/abs/2411.08017)
append_entries: 2
Finish: 2024-11-13 15:01:07.164626
------------------------------------------------------
Started: 2024-11-13 18:01:13.981481
Existing_entries: 424
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "BLIP3-KALE数据集：结合合成描述性字幕与真实网络文本的图像-文本对",
  "keyword": ["数据集", "图像-文本", "多模态模型"],
  "short_summary": "BLIP3-KALE是一个包含2.18亿图像-文本对的数据集，提升了多模态模型的表现。",
  "summary": "BLIP3-KALE是一个包含2.18亿图像-文本对的新数据集，旨在弥合合成描述性字幕与真实网络替代文本之间的差距。KALE通过结合网络规模的替代文本来增强合成的密集图像字幕，从而生成基础于事实的图像字幕。该数据集的构建采取了两阶段的方法，利用大型视觉语言模型和语言模型创建知识增强的字幕，然后用以训练专门的视觉语言模型，从而扩展数据集规模。我们的实验显示，KALE的数据集在视觉语言任务中表现出显著的改进，有助于训练更加高效且富有知识的多模态模型。KALE数据集的详细信息可在https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 260 (char 419). Line: 406.
Append: [BLIP3-KALE: Knowledge Augmented Large-Scale Dense Captions](https://arxiv.org/abs/2411.07461)
append_entries: 1
Finish: 2024-11-13 18:01:19.975600
------------------------------------------------------
Started: 2024-11-13 21:00:49.342812
Existing_entries: 425
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 731
Summarized using gpt-4o-mini
Append: [扩散模型在视觉感知任务中的迭代计算应用](https://arxiv.org/abs/2411.08034)
Json decode failed:
{
  "title": "声学体积渲染：虚拟现实中的冲激响应合成新方法",
  "keyword": ["声学渲染", "冲激响应", "虚拟现实"],
  "short_summary": "本研究提出声学体积渲染方法，以合成虚拟现实中的精确冲激响应。",
  "summary": "本文提出了一种新的声学体积渲染（AVR）方法，旨在破解虚拟现实和增强现实中的音频合成难题。通过估算冲激响应（IR），AVR能在不同位置模拟音频传播特性并高效合成声音。本研究采用频域体积渲染与球面积分来处理时间序列信号，构建一个固有编码声波传播原则的冲激响应场。实验证明，AVR在合成新姿态的冲激响应方面，其性能显著优于现有主流方法。此外，我们还开发了AcoustiX音频模拟平台，该平台提供比现有模拟器更为准确和真实的冲激响应模拟。相关代码可在 https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 244 (char 374). Line: 406.
Append: [Acoustic Volume Rendering for Neural Impulse Response Fields](https://arxiv.org/abs/2411.06307)
append_entries: 2
Finish: 2024-11-13 21:01:00.635576
------------------------------------------------------
Started: 2024-11-14 00:33:59.075479
Existing_entries: 427
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-14 00:33:59.157126
------------------------------------------------------
Started: 2024-11-14 03:13:24.692964
Existing_entries: 427
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-14 03:13:24.831562
------------------------------------------------------
Started: 2024-11-14 06:00:43.405259
Existing_entries: 427
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-14 06:00:43.541249
------------------------------------------------------
Started: 2024-11-14 09:00:52.265992
Existing_entries: 427
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1472
Summarized using gpt-4o-mini
Append: [EgoVid-5M：用于自我中心视频生成的高质量数据集](https://arxiv.org/abs/2411.08380)
Token length: 1102
Summarized using gpt-4o-mini
Append: [特征级约束偏好优化：提升大语言模型的效率与稳定性](https://arxiv.org/abs/2411.07618)
append_entries: 2
Finish: 2024-11-14 09:00:59.676651
------------------------------------------------------
Started: 2024-11-14 12:01:00.084328
Existing_entries: 429
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 792
Summarized using gpt-4o-mini
Append: [深入探讨稀疏自编码器在控制大语言模型中的作用](https://arxiv.org/abs/2411.08790)
Token length: 1494
Summarized using gpt-4o-mini
Append: [CamemBERT新版本应对语言模型时间概念漂移](https://arxiv.org/abs/2411.08868)
Json decode failed:
{
  "title": "自我改进长文本推理的语言模型新方法",
  "keyword": ["长文本推理", "语言模型", "自我改进"],
  "short_summary": "提出一种新方法，实现语言模型在长文本推理上的自我改进。",
  "summary": "本文探讨了大型语言模型（LLMs）在长文本推理中的自我改进潜力，提出了一种新方法\ours，专门针对这一问题。该方法通过为每个问题生成多个输出，并利用最小贝叶斯风险进行评分，从而进行监督精调或偏好优化。实验结果表明，在多个领先的LLMs上，\ours方法表现出显著的有效性，Llama-3.1-8B-Instruct模型的绝对提升达4.2分。此外，\ours相比于依赖人类专家或高级模型生成的数据的先前方法，展现出了更优越的性能。这项工作预计将为长文本场景中的自我改进技术开辟新的研究方向，从而推动大型语言模型的持续进步。"
}Summarization failed, append the original article
error: Invalid \escape: line 5 column 55 (char 178). Line: 406.
Append: [Large Language Models Can Self-Improve in Long-context Reasoning](https://arxiv.org/abs/2411.08147)
append_entries: 3
Finish: 2024-11-14 12:01:12.004213
------------------------------------------------------
Started: 2024-11-14 15:00:57.972741
Existing_entries: 432
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-14 15:00:58.131730
------------------------------------------------------
Started: 2024-11-14 18:00:42.712145
Existing_entries: 432
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-14 18:00:42.868456
------------------------------------------------------
Started: 2024-11-14 21:01:07.189216
Existing_entries: 432
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1000
Summarized using gpt-4o-mini
Append: [PerceiverS架构：提升符号音乐生成的长结构与表现力](https://arxiv.org/abs/2411.08307)
Token length: 1372
Summarized using gpt-4o-mini
Append: [MVideo：提升文本到视频生成的动态动作表现](https://arxiv.org/abs/2411.08328)
append_entries: 2
Finish: 2024-11-14 21:01:13.144308
------------------------------------------------------
Started: 2024-11-15 00:36:21.639963
Existing_entries: 434
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-15 00:36:21.733307
------------------------------------------------------
Started: 2024-11-15 03:21:04.576062
Existing_entries: 434
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-15 03:21:04.697127
------------------------------------------------------
Started: 2024-11-15 06:00:49.526597
Existing_entries: 434
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1266
Summarized using gpt-4o-mini
Append: [大语言模型在临床预测中的表现：对传统机器学习模型的比较](https://arxiv.org/abs/2411.06469)
Token length: 930
Summarized using gpt-4o-mini
Append: [MagicQuill：高效的集成图像编辑系统](https://arxiv.org/abs/2411.09703)
append_entries: 2
Finish: 2024-11-15 06:00:58.180521
------------------------------------------------------
Started: 2024-11-15 09:00:56.456919
Existing_entries: 436
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1497
Summarized using gpt-4o-mini
Append: [Cut Cross-Entropy：优化大型语言模型的内存使用](https://arxiv.org/abs/2411.09009)
Token length: 1246
Summarized using gpt-4o-mini
Append: [LLaMA-Mesh：整合文本与3D网格生成的统一模型](https://arxiv.org/abs/2411.09595)
append_entries: 2
Finish: 2024-11-15 09:01:06.235488
------------------------------------------------------
Started: 2024-11-15 12:13:00.635927
Existing_entries: 438
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1290
Summarized using gpt-4o-mini
Append: [基于视觉-语言模型的用户动作提取方法研究](https://arxiv.org/abs/2411.08768)
append_entries: 1
Finish: 2024-11-15 12:13:03.816167
------------------------------------------------------
Started: 2024-11-15 15:01:07.719295
Existing_entries: 439
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1198
Summarized using gpt-4o-mini
Append: [Hermes：推动网络智能与自主运营的创新方案](https://arxiv.org/abs/2411.06490)
append_entries: 1
Finish: 2024-11-15 15:01:12.054487
------------------------------------------------------
Started: 2024-11-15 18:01:11.357159
Existing_entries: 440
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-15 18:01:11.520833
------------------------------------------------------
Started: 2024-11-15 21:00:44.097879
Existing_entries: 440
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-15 21:00:44.179278
------------------------------------------------------
Started: 2024-11-16 00:35:16.395696
Existing_entries: 440
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1108
Summarized using gpt-4o-mini
Append: [一致性模型的有效性分析与直接一致性模型的比较](https://arxiv.org/abs/2411.08954)
append_entries: 1
Finish: 2024-11-16 00:35:19.841352
------------------------------------------------------
Started: 2024-11-16 03:18:38.923601
Existing_entries: 441
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-16 03:18:39.009889
------------------------------------------------------
Started: 2024-11-16 06:01:13.259642
Existing_entries: 441
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-16 06:01:13.416140
------------------------------------------------------
Started: 2024-11-16 09:00:43.253459
Existing_entries: 441
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-16 09:00:43.358841
------------------------------------------------------
Started: 2024-11-16 12:11:37.044868
Existing_entries: 441
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-16 12:11:37.164562
------------------------------------------------------
Started: 2024-11-16 15:00:43.407630
Existing_entries: 441
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-16 15:00:43.521103
------------------------------------------------------
Started: 2024-11-16 18:00:48.653034
Existing_entries: 441
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-16 18:00:48.892321
------------------------------------------------------
Started: 2024-11-16 21:00:46.032758
Existing_entries: 441
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-16 21:00:46.190948
------------------------------------------------------
Started: 2024-11-17 00:38:40.426173
Existing_entries: 441
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-17 00:38:40.519795
------------------------------------------------------
Started: 2024-11-17 03:23:23.936577
Existing_entries: 441
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-17 03:23:24.048350
------------------------------------------------------
Started: 2024-11-17 06:01:09.398513
Existing_entries: 441
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-17 06:01:09.491505
------------------------------------------------------
Started: 2024-11-17 09:01:01.451542
Existing_entries: 441
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-17 09:01:01.602905
------------------------------------------------------
Started: 2024-11-17 12:11:38.900507
Existing_entries: 441
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-17 12:11:39.063068
------------------------------------------------------
Started: 2024-11-17 15:01:01.601708
Existing_entries: 441
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-17 15:01:01.759773
------------------------------------------------------
Started: 2024-11-17 18:00:45.353393
Existing_entries: 441
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-17 18:00:45.678800
------------------------------------------------------
Started: 2024-11-17 21:00:42.999523
Existing_entries: 441
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-17 21:00:55.160194
------------------------------------------------------
Started: 2024-11-18 00:37:43.354081
Existing_entries: 441
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-18 00:37:43.515639
------------------------------------------------------
Started: 2024-11-18 03:23:48.397694
Existing_entries: 441
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-18 03:23:48.547851
------------------------------------------------------
Started: 2024-11-18 06:00:53.509312
Existing_entries: 441
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1092
Summarized using gpt-4o-mini
Append: [基于点云结构的3D生成框架GaussianAnything](https://arxiv.org/abs/2411.08033)
Token length: 1396
Summarized using gpt-4o-mini
Append: [LLaVA-o1: 一个针对视觉语言模型的多阶段推理框架](https://arxiv.org/abs/2411.10440)
append_entries: 2
Finish: 2024-11-18 06:01:02.365556
------------------------------------------------------
Started: 2024-11-18 09:01:16.782563
Existing_entries: 443
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "NumPro: 提升视频时间定位的创新方法",
  "keyword": ["视频语言模型", "时间定位", "NumPro"],
  "short_summary": "NumPro方法有效提升了视频语言模型在时间定位任务中的表现。",
  "summary": "视频大型语言模型（Vid-LLMs）在视频内容理解和问答对话中取得了显著进展，但在需要精确时间定位的任务（视频时间定位VTG）中仍存在不足。为了解决这一问题，本文提出了一种新方法NumPro，它通过为每帧视频添加唯一数字标识，帮助Vid-LLMs将视觉理解与时间定位结合，类似于翻阅漫画面板，使得对事件时间线的"阅读"更加直观。实验结果表明，NumPro显著提升了顶级Vid-LLMs在VTG任务上的表现，而无需额外的计算成本。此外，通过在NumPro增强数据集上的微调，使VTG性能达到新的最先进水平，在时刻检索中提高了6.9%的mIoU，并在亮点检测中提高了8.5%的mAP。"
}Summarization failed, append the original article
error: Expecting ',' delimiter: line 5 column 171 (char 305). Line: 406.
Append: [Number it: Temporal Grounding Videos like Flipping Manga](https://arxiv.org/abs/2411.10332)
Token length: 1152
Summarized using gpt-4o-mini
Append: [Claude 3.5计算机使用模型的案例研究](https://arxiv.org/abs/2411.10323)
append_entries: 2
Finish: 2024-11-18 09:01:25.531375
------------------------------------------------------
Started: 2024-11-18 12:14:00.623712
Existing_entries: 445
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-18 12:14:00.732718
------------------------------------------------------
Started: 2024-11-18 15:00:51.400557
Existing_entries: 445
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-18 15:00:51.558569
------------------------------------------------------
Started: 2024-11-18 18:00:51.796206
Existing_entries: 445
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1451
Summarized using gpt-4o-mini
Append: [RAG：基于区域描述的文本到图像生成方法](https://arxiv.org/abs/2411.06558)
Token length: 880
Summarized using gpt-4o-mini
Append: [Xmodel-1.5: 一种新型多语种大模型的推出及其性能评估](https://arxiv.org/abs/2411.10083)
append_entries: 2
Finish: 2024-11-18 18:01:01.379787
------------------------------------------------------
Started: 2024-11-18 21:00:49.299707
Existing_entries: 447
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-18 21:00:49.451206
------------------------------------------------------
Started: 2024-11-19 00:36:26.274325
Existing_entries: 447
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1204
Summarized using gpt-4o-mini
Append: [MARS: 一种高效的大模型优化框架](https://arxiv.org/abs/2411.10438)
append_entries: 1
Finish: 2024-11-19 00:36:32.432990
------------------------------------------------------
Started: 2024-11-19 03:21:09.927281
Existing_entries: 448
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-19 03:21:10.013879
------------------------------------------------------
Started: 2024-11-19 06:00:54.951190
Existing_entries: 448
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 726
Summarized using gpt-4o-mini
Append: [重评估重排器在信息检索中的有效性](https://arxiv.org/abs/2411.11767)
Token length: 1081
Summarized using gpt-4o-mini
Append: [top-nsigma：一种新型的抽样方法提升推理任务表现](https://arxiv.org/abs/2411.07641)
append_entries: 2
Finish: 2024-11-19 06:01:07.287214
------------------------------------------------------
Started: 2024-11-19 09:01:02.192524
Existing_entries: 450
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1277
Summarized using gpt-4o-mini
Append: [Generative World Explorer: 基于想象的世界探索框架](https://arxiv.org/abs/2411.11844)
Token length: 1354
Summarized using gpt-4o-mini
Append: [医学领域的检索增强生成 (RAG) 系统评估框架](https://arxiv.org/abs/2411.09213)
Token length: 1228
Summarized using gpt-4o-mini
Append: [SlimLM：优化移动设备的高效小型语言模型](https://arxiv.org/abs/2411.09944)
Token length: 960
Summarized using gpt-4o-mini
Append: [统一可控视频生成方法AnimateAnything](https://arxiv.org/abs/2411.10836)
Token length: 1049
Summarized using gpt-4o-mini
Append: [验证工程：基础模型时代的新监督信号](https://arxiv.org/abs/2411.11504)
Token length: 1042
Summarized using gpt-4o-mini
Append: [Awaker2.5-VL: 为多模态大型语言模型设计的混合专家架构](https://arxiv.org/abs/2411.10669)
Token length: 1067
Summarized using gpt-4o-mini
Append: [SmoothCache: 加速Diffusion Transformers推理的模型无关技术](https://arxiv.org/abs/2411.10510)
Token length: 1556
Summarized using gpt-4o-mini
Append: [FitDiT：高保真虚拟试衣的新方法](https://arxiv.org/abs/2411.10499)
Token length: 1543
Summarized using gpt-4o-mini
Append: [BlueLM-V-3B：高效部署多模态大语言模型于移动平台的创新方案](https://arxiv.org/abs/2411.10640)
append_entries: 9
Finish: 2024-11-19 09:02:06.116633
------------------------------------------------------
Started: 2024-11-19 12:00:52.087399
Existing_entries: 459
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1213
Summarized using gpt-4o-mini
Append: [基于形状一致性的视频编辑方法StableV2V的研究](https://arxiv.org/abs/2411.11045)
Token length: 961
Summarized using gpt-4o-mini
Append: [LLäMmlein德语解码模型的创建与评估](https://arxiv.org/abs/2411.11171)
append_entries: 2
Finish: 2024-11-19 12:01:04.489983
------------------------------------------------------
Started: 2024-11-19 15:00:52.260485
Existing_entries: 461
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1347
Summarized using gpt-4o-mini
Append: [VeGaS：用于视频数据的高效编辑和重建的算法](https://arxiv.org/abs/2411.11024)
Json decode failed:
{
  "title": "大型语言模型的反馈质量与写作指南的影响研究",
  "keyword": ["大型语言模型", "反馈质量", "写作指南"],
  "short_summary": "研究显示详细的指导能提升AI反馈质量，但对信息获取能力的效果有限。",
  "summary": "随着大型语言模型（LLMs）的能力提升，它们被用作人类反馈的替代品来训练和评估其他模型。本文探讨了选择不同写作指南（"宪法"）对反馈质量的影响，使用四种不同的宪法来改善医疗访谈中的以病人为中心的沟通。通过215名人类评审者进行的配对比较研究发现，详尽的宪法在情感质量方面的效果更佳。然而，所有宪法在帮助学习更具实用性的技能（如信息收集和提供）方面均未超过基准。这些结果表明，尽管应优先考虑使用详细的宪法，但AI反馈作为奖励信号在某些领域的有效性可能存在局限性。"
}Summarization failed, append the original article
error: Expecting ',' delimiter: line 5 column 74 (char 208). Line: 406.
Append: [Evaluating the role of `Constitutions' for learning from AI feedback](https://arxiv.org/abs/2411.10168)
Token length: 908
Summarized using gpt-4o-mini
Append: [动态温度采样优化：自适应解码方法研究](https://arxiv.org/abs/2411.09661)
append_entries: 3
Finish: 2024-11-19 15:01:19.523551
------------------------------------------------------
Started: 2024-11-19 18:10:09.838180
Existing_entries: 464
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-19 18:10:10.004269
------------------------------------------------------
Started: 2024-11-19 21:00:50.824201
Existing_entries: 464
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-19 21:00:51.076804
------------------------------------------------------
Started: 2024-11-20 00:35:46.945677
Existing_entries: 464
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-20 00:35:47.096225
------------------------------------------------------
Started: 2024-11-20 03:20:10.770227
Existing_entries: 464
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-20 03:20:10.923880
------------------------------------------------------
Started: 2024-11-20 06:11:09.016534
Existing_entries: 464
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1236
Summarized using gpt-4o-mini
Append: [多语言大型语言模型的分词效率评估](https://arxiv.org/abs/2411.12240)
Token length: 1411
Summarized using gpt-4o-mini
Append: [连续值自回归图像生成模型的推测解码优化](https://arxiv.org/abs/2411.11925)
append_entries: 2
Finish: 2024-11-20 06:11:20.226126
------------------------------------------------------
Started: 2024-11-20 09:01:13.711465
Existing_entries: 466
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-20 09:01:13.775512
------------------------------------------------------
Started: 2024-11-20 12:13:14.193562
Existing_entries: 466
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1826
Summarized using gpt-4o-mini
Append: [RedPajama数据集：推动开放源语言模型的发展](https://arxiv.org/abs/2411.12372)
Token length: 798
Summarized using gpt-4o-mini
Append: [AI模型安全与风险管理研究](https://arxiv.org/abs/2411.12275)
Token length: 1377
Summarized using gpt-4o-mini
Append: [SWIFT: 一种用于动态任务学习的软体机器人手](https://arxiv.org/abs/2411.12734)
append_entries: 3
Finish: 2024-11-20 12:13:27.915540
------------------------------------------------------
Started: 2024-11-20 15:01:09.316215
Existing_entries: 469
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1406
Summarized using gpt-4o-mini
Append: [基于SEAGULL的区域质量评估方法研究](https://arxiv.org/abs/2411.10161)
Token length: 1143
Summarized using gpt-4o-mini
Append: [通过新模块提升CLIP在开集语义分割中的性能](https://arxiv.org/abs/2411.12044)
append_entries: 2
Finish: 2024-11-20 15:01:21.501512
------------------------------------------------------
Started: 2024-11-20 18:01:15.887006
Existing_entries: 471
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1231
Summarized using gpt-4o-mini
Append: [FlipSketch：简化素描动画创作的创新系统](https://arxiv.org/abs/2411.10818)
append_entries: 1
Finish: 2024-11-20 18:01:20.817809
------------------------------------------------------
Started: 2024-11-20 21:01:05.926338
Existing_entries: 472
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-20 21:01:06.036130
------------------------------------------------------
Started: 2024-11-21 00:35:42.532121
Existing_entries: 472
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-21 00:35:42.712945
------------------------------------------------------
Started: 2024-11-21 03:20:03.370718
Existing_entries: 472
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1330
Summarized using gpt-4o-mini
Append: [提高大规模多模态模型的学习能力：符号演示直接偏好优化方法](https://arxiv.org/abs/2411.11909)
append_entries: 1
Finish: 2024-11-21 03:20:07.940228
------------------------------------------------------
Started: 2024-11-21 06:00:59.650822
Existing_entries: 473
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1675
Summarized using gpt-4o-mini
Append: [WebDreamer: 利用语言模型优化网络代理的模型驱动规划](https://arxiv.org/abs/2411.06559)
Token length: 1399
Summarized using gpt-4o-mini
Append: [SageAttention2: 通过低精度矩阵乘法加速注意力计算](https://arxiv.org/abs/2411.10958)
Token length: 1451
Summarized using gpt-4o-mini
Append: [SAMURAI：面向视觉目标跟踪的SAM 2增强模型](https://arxiv.org/abs/2411.11922)
append_entries: 3
Finish: 2024-11-21 06:01:14.144063
------------------------------------------------------
Started: 2024-11-21 09:00:52.697377
Existing_entries: 476
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-21 09:00:52.779122
------------------------------------------------------
Started: 2024-11-21 12:13:27.114291
Existing_entries: 476
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1432
Summarized using gpt-4o-mini
Append: [AnchorAttention：提升长序列处理能力的解决方案](https://arxiv.org/abs/2411.13476)
Token length: 1322
Summarized using gpt-4o-mini
Append: [基于器官区域信息的放射学报告生成框架研究](https://arxiv.org/abs/2411.13025)
Token length: 1915
Summarized using gpt-4o-mini
Append: [VideoAutoArena：一种自动评估视频分析能力的新基准](https://arxiv.org/abs/2411.13281)
Token length: 1854
Summarized using gpt-4o-mini
Append: [VBench: 视频生成模型评估的综合基准](https://arxiv.org/abs/2411.13503)
append_entries: 4
Finish: 2024-11-21 12:13:48.006060
------------------------------------------------------
Started: 2024-11-21 15:01:08.136547
Existing_entries: 480
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 929
Summarized using gpt-4o-mini
Append: [StyleCodes: 开源的图像风格编码器架构](https://arxiv.org/abs/2411.12811)
append_entries: 1
Finish: 2024-11-21 15:01:12.638595
------------------------------------------------------
Started: 2024-11-21 18:01:07.612482
Existing_entries: 481
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-21 18:01:07.847590
------------------------------------------------------
Started: 2024-11-21 21:01:09.973140
Existing_entries: 481
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-21 21:01:10.063647
------------------------------------------------------
Started: 2024-11-22 00:36:42.135715
Existing_entries: 481
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1244
Summarized using gpt-4o-mini
Append: [基于 shifted power law 的模型训练损失预测策略](https://arxiv.org/abs/2411.12925)
Token length: 1331
Summarized using gpt-4o-mini
Append: [ViBe：大型文本生成视频模型的幻觉视频基准](https://arxiv.org/abs/2411.10867)
append_entries: 2
Finish: 2024-11-22 00:36:50.163173
------------------------------------------------------
Started: 2024-11-22 03:21:03.901419
Existing_entries: 483
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1028
Summarized using gpt-4o-mini
Append: [自然语言强化学习框架的探索与实现](https://arxiv.org/abs/2411.14251)
append_entries: 1
Finish: 2024-11-22 03:21:07.864879
------------------------------------------------------
Started: 2024-11-22 06:10:53.940800
Existing_entries: 484
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1226
Summarized using gpt-4o-mini
Append: [增强多模态推理能力的混合偏好优化方法](https://arxiv.org/abs/2411.10442)
Token length: 1095
Summarized using gpt-4o-mini
Append: [Hymba: 高效小型语言模型的新架构](https://arxiv.org/abs/2411.13676)
Token length: 909
Summarized using gpt-4o-mini
Append: [UltraMem：一种高效的超稀疏记忆层架构](https://arxiv.org/abs/2411.12364)
Token length: 725
Summarized using gpt-4o-mini
Append: [Marco-o1：扩展大型推理模型的能力](https://arxiv.org/abs/2411.14405)
Token length: 1650
Summarized using gpt-4o-mini
Append: [Insight-V：提升多模态语言模型推理能力的新方法](https://arxiv.org/abs/2411.14432)
Token length: 1297
Summarized using gpt-4o-mini
Append: [OpenScholar：基于文献的自然语言处理助手](https://arxiv.org/abs/2411.14199)
append_entries: 6
Finish: 2024-11-22 06:11:54.400740
------------------------------------------------------
Started: 2024-11-22 09:01:15.729214
Existing_entries: 490
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 962
Summarized using gpt-4o-mini
Append: [AIMV2：一种新型大规模视觉编码器的预训练方法](https://arxiv.org/abs/2411.14402)
Token length: 1193
Summarized using gpt-4o-mini
Append: [基于扩散变换器的图像编辑方法研究](https://arxiv.org/abs/2411.14430)
append_entries: 2
Finish: 2024-11-22 09:01:28.317725
------------------------------------------------------
Started: 2024-11-22 12:00:57.564601
Existing_entries: 492
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 927
Summarized using gpt-4o-mini
Append: [高效收集低资源语言数据的方法](https://arxiv.org/abs/2411.14343)
Token length: 1067
Summarized using gpt-4o-mini
Append: [MagicDriveDiT：一种新型高分辨率视频合成方法](https://arxiv.org/abs/2411.13807)
Token length: 1346
Summarized using gpt-4o-mini
Append: [稀疏自编码器揭示大语言模型中的幻觉机制](https://arxiv.org/abs/2411.14257)
Token length: 975
Summarized using gpt-4o-mini
Append: [改进大型语言模型的推理能力：链式思维方法的应用](https://arxiv.org/abs/2411.13082)
append_entries: 4
Finish: 2024-11-22 12:01:21.296018
------------------------------------------------------
Started: 2024-11-22 15:01:49.004731
Existing_entries: 496
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-22 15:01:49.091608
------------------------------------------------------
Started: 2024-11-22 18:01:13.085521
Existing_entries: 496
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-22 18:01:13.288738
------------------------------------------------------
Started: 2024-11-22 21:00:50.897443
Existing_entries: 496
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1138
Summarized using gpt-4o-mini
Append: [DiffusionGS：一种新型单阶段3D扩散模型](https://arxiv.org/abs/2411.14384)
append_entries: 1
Finish: 2024-11-22 21:00:59.760764
------------------------------------------------------
Started: 2024-11-23 00:35:14.744274
Existing_entries: 497
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1765
Summarized using gpt-4o-mini
Append: [DINO-X：开创性的物体中心视觉模型](https://arxiv.org/abs/2411.14347)
append_entries: 1
Finish: 2024-11-23 00:35:21.796021
------------------------------------------------------
Started: 2024-11-23 03:17:57.022287
Existing_entries: 498
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-23 03:17:57.154445
------------------------------------------------------
Started: 2024-11-23 06:01:22.374237
Existing_entries: 498
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-23 06:01:22.481046
------------------------------------------------------
Started: 2024-11-23 09:01:03.550828
Existing_entries: 498
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-23 09:01:03.668328
------------------------------------------------------
Started: 2024-11-23 12:01:04.725870
Existing_entries: 498
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-23 12:01:04.927868
------------------------------------------------------
Started: 2024-11-23 15:01:43.398573
Existing_entries: 498
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-23 15:01:43.520205
------------------------------------------------------
Started: 2024-11-23 18:01:06.754997
Existing_entries: 498
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-23 18:01:06.918699
------------------------------------------------------
Started: 2024-11-23 21:01:04.193421
Existing_entries: 498
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-23 21:01:04.368371
------------------------------------------------------
Started: 2024-11-24 00:39:09.545266
Existing_entries: 498
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-24 00:39:09.636719
------------------------------------------------------
Started: 2024-11-24 03:25:36.416734
Existing_entries: 498
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-24 03:25:36.569781
------------------------------------------------------
Started: 2024-11-24 06:01:52.088042
Existing_entries: 498
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-24 06:02:03.685949
------------------------------------------------------
Started: 2024-11-24 09:02:02.758639
Existing_entries: 498
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-24 09:02:02.840785
------------------------------------------------------
Started: 2024-11-24 12:00:52.284189
Existing_entries: 498
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-24 12:00:52.375237
------------------------------------------------------
Started: 2024-11-24 15:00:45.547216
Existing_entries: 498
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-24 15:00:45.708524
------------------------------------------------------
Started: 2024-11-24 18:00:46.514909
Existing_entries: 498
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-24 18:00:46.687367
------------------------------------------------------
Started: 2024-11-24 21:00:47.679478
Existing_entries: 498
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-24 21:00:47.845964
------------------------------------------------------
Started: 2024-11-25 00:37:40.361266
Existing_entries: 498
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-25 00:37:40.451270
------------------------------------------------------
Started: 2024-11-25 03:23:53.039366
Existing_entries: 498
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-25 03:23:53.400609
------------------------------------------------------
Started: 2024-11-25 06:00:58.167676
Existing_entries: 498
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1031
Summarized using gpt-4o-mini
Append: [风格友好的信噪比采样器：提升扩散模型的个性化艺术风格生成](https://arxiv.org/abs/2411.14793)
append_entries: 1
Finish: 2024-11-25 06:01:01.862582
------------------------------------------------------
Started: 2024-11-25 09:01:14.004932
Existing_entries: 499
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1664
Summarized using gpt-4o-mini
Append: [T"ULU 3: 开放的现代语言模型后训练技术](https://arxiv.org/abs/2411.15124)
Token length: 1446
Summarized using gpt-4o-mini
Append: [WildLMa：多环境下的四足机器人操作与规划能力研究](https://arxiv.org/abs/2411.15131)
Token length: 1152
Summarized using gpt-4o-mini
Append: [ViewExtrapolator：一种基于SVD的小说视图外推方法](https://arxiv.org/abs/2411.14208)
Token length: 1472
Summarized using gpt-4o-mini
Append: [MyTimeMachine: 结合全球年龄先验与个人照片实现个性化面部老化](https://arxiv.org/abs/2411.14521)
Token length: 1363
Summarized using gpt-4o-mini
Append: [OminiControl：高效的图像条件集成框架](https://arxiv.org/abs/2411.15098)
append_entries: 5
Finish: 2024-11-25 09:01:41.624817
------------------------------------------------------
Started: 2024-11-25 12:14:09.940222
Existing_entries: 504
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1898
Summarized using gpt-4o-mini
Append: [基于大语言模型的机器人行动规划架构研究](https://arxiv.org/abs/2411.15033)
Token length: 1567
Summarized using gpt-4o-mini
Append: [VideoEspresso：提升视频问答能力的新数据集及方法](https://arxiv.org/abs/2411.14794)
Token length: 1209
Summarized using gpt-4o-mini
Append: [无数据灵活开发大语言模型防护机制](https://arxiv.org/abs/2411.12946)
Token length: 1385
Summarized using gpt-4o-mini
Append: [CoordTok：高效视频标记化方法](https://arxiv.org/abs/2411.14762)
append_entries: 4
Finish: 2024-11-25 12:14:27.115392
------------------------------------------------------
Started: 2024-11-25 15:01:08.102704
Existing_entries: 508
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1504
Summarized using gpt-4o-mini
Append: [BALROG：评估大型语言模型与视觉语言模型能力的新基准](https://arxiv.org/abs/2411.13543)
Token length: 1154
Summarized using gpt-4o-mini
Append: [理解大型多模态模型的内部表示](https://arxiv.org/abs/2411.14982)
append_entries: 2
Finish: 2024-11-25 15:01:22.500939
------------------------------------------------------
Started: 2024-11-25 18:00:51.098728
Existing_entries: 510
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "Cloud-Adapter：提升遥感图像云分割精度的自适应方法",
  "short_summary": "本文提出Cloud-Adapter，利用视觉基础模型提高云分割的准确性和鲁棒性。",
  "summary": "云分割在遥感图像解读中是一个关键挑战，其准确性直接影响后续数据处理与分析的有效性。近期，视觉基础模型(VFM)显示出在多种视觉任务上具有强大的泛化能力。本文提出了一种名为Cloud-Adapter的参数高效自适应方法，以提升云分割的准确性和鲁棒性。该方法利用在一般域数据上预训练的VFM，这部分网络保持不变，无需额外训练。Cloud-Adapter结合了一个轻量级的空间感知模块，通过卷积神经网络(ConvNet)提取密集的空间表示，并将这些多尺度特征聚合，作为适应模块的上下文输入，调节VFM中的冻结变换层。实验结果表明，Cloud-Adapter在只使用0.6%的可训练参数的情况下，显著提高了性能，并在多种来自不同卫星源、传感器系列和土地覆盖场景的云分割数据集中实现了最新的SOTA性能。此外，源代码和预训练模型已在https:
  "keyword": ["云分割", "遥感", "视觉基础模型"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 382 (char 492). Line: 406.
Append: [Adapting Vision Foundation Models for Robust Cloud Segmentation in Remote Sensing Images](https://arxiv.org/abs/2411.13127)
Token length: 1415
Summarized using gpt-4o-mini
Append: [VideoRepair：提升文本到视频生成模型对齐度的框架](https://arxiv.org/abs/2411.15115)
append_entries: 2
Finish: 2024-11-25 18:00:59.925327
------------------------------------------------------
Started: 2024-11-25 21:00:57.218953
Existing_entries: 512
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-25 21:00:57.306187
------------------------------------------------------
Started: 2024-11-26 00:36:26.642621
Existing_entries: 512
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-26 00:36:26.745402
------------------------------------------------------
Started: 2024-11-26 03:22:40.107280
Existing_entries: 512
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-26 03:22:40.221340
------------------------------------------------------
Started: 2024-11-26 06:00:57.732899
Existing_entries: 512
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "Cautious Optimizer: 提升变压器预训练效率的新方法",
  "keyword": ["优化器", "AdamW", "深度学习"],
  "short_summary": "本文提出了一种新型的Cautious Optimizer，提升变压器预训练速度与稳定性。",
  "summary": "在深度学习的变压器预训练中，AdamW优化器已成为默认选择，但寻找更快、更稳定的替代方案一直是社区的追求。本文提出了一种简单的单行修改，称为Cautious Optimizer，例如C-AdamW和C-Lion。理论结果表明，该修改保持了Adam的哈密顿功能，并在Lyapunov分析下不破坏收敛保证。此外，这一理论洞察揭示了一整个新家族的优化器，文章选择了最简单的一个进行实证实验，显示了在Llama和MAE预训练中速度提升达1.47倍。相关代码可在https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 247 (char 403). Line: 406.
Append: [Cautious Optimizers: Improving Training with One Line of Code](https://arxiv.org/abs/2411.16085)
Token length: 1737
Summarized using gpt-4o-mini
Append: [DreamRunner：一种创新的故事视频生成方法](https://arxiv.org/abs/2411.16657)
Token length: 1459
Summarized using gpt-4o-mini
Append: [Diptych Prompting：一种新颖的零-shot图像生成方法](https://arxiv.org/abs/2411.15466)
Token length: 1773
Summarized using gpt-4o-mini
Append: [评估语言模型不确定性承认能力的新框架](https://arxiv.org/abs/2411.14486)
Token length: 1034
Summarized using gpt-4o-mini
Append: [Material Anything：自动化生成3D物体物理基础材料的统一扩散框架](https://arxiv.org/abs/2411.15138)
append_entries: 5
Finish: 2024-11-26 06:01:46.410928
------------------------------------------------------
Started: 2024-11-26 09:01:22.699507
Existing_entries: 517
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1287
Summarized using gpt-4o-mini
Append: [OneDiffusion：多任务大规模扩散模型的创新](https://arxiv.org/abs/2411.16318)
Token length: 1080
Summarized using gpt-4o-mini
Append: [VisualLens: 基于用户视觉历史的个性化推荐方法](https://arxiv.org/abs/2411.16034)
Token length: 1564
Summarized using gpt-4o-mini
Append: [引入因子化量化的新型视觉分词器FQGAN](https://arxiv.org/abs/2411.16681)
Token length: 1857
Summarized using gpt-4o-mini
Append: [深入探讨OpenAI O1模型能力复制中的知识蒸馏技术](https://arxiv.org/abs/2411.16489)
Token length: 1491
Summarized using gpt-4o-mini
Append: [SplatFlow：统一的3D生成与编辑框架](https://arxiv.org/abs/2411.16443)
Token length: 1788
Summarized using gpt-4o-mini
Append: [图序列模型GSM及其改进版本GSM++的理论与实验研究](https://arxiv.org/abs/2411.15671)
Token length: 1369
Summarized using gpt-4o-mini
Append: [语言模型的出现能力预测研究](https://arxiv.org/abs/2411.16035)
Token length: 1698
Summarized using gpt-4o-mini
Append: [全身CT预训练模型在医学图像分割中的迁移学习评估](https://arxiv.org/abs/2411.14525)
Token length: 1223
Summarized using gpt-4o-mini
Append: [大语言模型作为评判者的调查与展望](https://arxiv.org/abs/2411.16594)
Token length: 626
Summarized using gpt-4o-mini
Append: [多头混合专家模型的创新实现及其性能提升](https://arxiv.org/abs/2411.16205)
Json decode failed:
{
  "title": "开发GMAI-VL-5.5M数据集与GMAI-VL模型用于医疗视觉语言处理",
  "short_summary": "本文介绍了GMAI-VL-5.5M数据集及其在医疗AI中的应用。",
  "summary": "本文提出了GMAI-VL-5.5M，一个综合多模态医疗数据集，旨在提升医疗领域内一般人工智能（GMAI）模型的效能。通过将数百个专业医学数据集转换为精心构造的图像-文本配对，该数据集涵盖了丰富的任务、多种模态和高质量的数据。基于此数据集，我们还提出了GMAI-VL模型，该模型采用渐进的三阶段训练策略，使其在处理多模态数据和支持准确的诊断与临床决策方面表现出显著提升。实验评估显示，GMAI-VL在多项医疗任务中，如视觉问答和医学图像诊断，均取得了领先的成绩。我们的贡献包括GMAI-VL-5.5M数据集的开发、GMAI-VL模型的引入以及在多个医疗领域建立的新基准。相关代码和数据集将发布在https:
  "keyword": [
    "GMAI-VL-5.5M",
    "多模态医疗数据集",
    "医疗AI"
  ]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 317 (char 425). Line: 406.
Append: [GMAI-VL & GMAI-VL-5.5M: A Large Vision-Language Model and A Comprehensive Multimodal Dataset Towards General Medical AI](https://arxiv.org/abs/2411.14522)
Token length: 1396
Summarized using gpt-4o-mini
Append: [CRT：高效的x86到ARM汇编转译器](https://arxiv.org/abs/2411.16341)
append_entries: 12
Finish: 2024-11-26 09:04:26.307777
------------------------------------------------------
Started: 2024-11-26 12:14:11.814009
Existing_entries: 529
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1189
Summarized using gpt-4o-mini
Append: [基于文本描述的知识转移方法](https://arxiv.org/abs/2411.15611)
append_entries: 1
Finish: 2024-11-26 12:14:16.855475
------------------------------------------------------
Started: 2024-11-26 15:01:00.463892
Existing_entries: 530
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-26 15:01:00.637214
------------------------------------------------------
Started: 2024-11-26 18:10:30.789157
Existing_entries: 530
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1503
Summarized using gpt-4o-mini
Append: [IMed-361M: 新型医疗图像分割基准数据集](https://arxiv.org/abs/2411.12814)
Token length: 998
Summarized using gpt-4o-mini
Append: [隐式推理与显式推理的比较研究](https://arxiv.org/abs/2411.15862)
append_entries: 2
Finish: 2024-11-26 18:12:48.768820
------------------------------------------------------
Started: 2024-11-26 21:00:56.742594
Existing_entries: 532
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1064
Summarized using gpt-4o-mini
Append: [Find3D：一种开源世界三维零-shot部件分割模型](https://arxiv.org/abs/2411.13550)
Token length: 1154
Summarized using gpt-4o-mini
Append: [EdgeCape: 提升无类别姿态估计的关键点定位精度](https://arxiv.org/abs/2411.16665)
append_entries: 2
Finish: 2024-11-26 21:03:26.449934
------------------------------------------------------
Started: 2024-11-27 00:36:38.640270
Existing_entries: 534
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1679
Summarized using gpt-4o-mini
Append: [全语言重要基准：评估大型多模态模型的文化与语言理解能力](https://arxiv.org/abs/2411.16508)
Token length: 1432
Summarized using gpt-4o-mini
Append: [第二届大语言模型黑客松在材料科学与化学应用中的成果](https://arxiv.org/abs/2411.15221)
append_entries: 2
Finish: 2024-11-27 00:36:48.415101
------------------------------------------------------
Started: 2024-11-27 03:24:42.946169
Existing_entries: 536
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-27 03:24:43.099131
------------------------------------------------------
Started: 2024-11-27 06:00:50.865153
Existing_entries: 536
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1695
Summarized using gpt-4o-mini
Append: [ShowUI：革新图形用户界面的视觉语言模型](https://arxiv.org/abs/2411.17465)
Token length: 1410
Summarized using gpt-4o-mini
Append: [AnchorCrafter：基于扩散模型的人物与物体交互视频生成](https://arxiv.org/abs/2411.17383)
Token length: 1541
Summarized using gpt-4o-mini
Append: [FINECAPTION：提升视觉语言模型的区域构图能力](https://arxiv.org/abs/2411.15411)
Token length: 1013
Summarized using gpt-4o-mini
Append: [自监督学习在无标签3D点云中提取可转移表示的研究](https://arxiv.org/abs/2411.17467)
Token length: 1144
Summarized using gpt-4o-mini
Append: [基于扩散模型的高分辨率UV纹理生成研究](https://arxiv.org/abs/2411.14740)
Token length: 1229
Summarized using gpt-4o-mini
Append: [DreamMix：一种基于扩散模型的目标插入与属性编辑方法](https://arxiv.org/abs/2411.17223)
Token length: 780
Summarized using gpt-4o-mini
Append: [Star Attention: 提升长序列推理效率的块稀疏近似](https://arxiv.org/abs/2411.17116)
append_entries: 7
Finish: 2024-11-27 06:01:27.991748
------------------------------------------------------
Started: 2024-11-27 09:01:08.289697
Existing_entries: 543
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1731
Summarized using gpt-4o-mini
Append: [AI图像生成技术的检测挑战与新 Benchmark 的提出](https://arxiv.org/abs/2411.16754)
Token length: 1535
Summarized using gpt-4o-mini
Append: [SALOVA：增强长视频理解的段落增强视频助手](https://arxiv.org/abs/2411.16173)
Token length: 1147
Summarized using gpt-4o-mini
Append: [新型过滤-关联-压缩范式加速多模态大语言模型推理](https://arxiv.org/abs/2411.17686)
Token length: 1160
Summarized using gpt-4o-mini
Append: [SAR3D：提升3D对象生成与理解的新框架](https://arxiv.org/abs/2411.16856)
Token length: 1419
Summarized using gpt-4o-mini
Append: [多模态大语言模型的评估综述](https://arxiv.org/abs/2411.15296)
Json decode failed:
{
  "title": "低比特量化对大型语言模型的影响研究",
  "keyword": ["低比特量化", "大型语言模型", "量化性能"],
  "short_summary": "研究显示低比特量化在不同训练水平的LLM中表现差异显著。",
  "summary": "本研究揭示低比特量化对大型语言模型（LLM）的影响，发现较大规模或训练样本较少的模型在应用低比特量化时，其量化性能下降较小，而小模型则受损严重。通过研究超过1500个不同规模和训练水平的量化LLM检查点，得出了量化性能下降（QiD）与训练样本数量、模型大小及比特宽度之间的关系规律。研究提出了使用QiD测量LLM训练水平的新视角，并确定了不同规模模型完全训练所需的训练样本数量。我们的预测表明，未来预期训练超过100万亿样本的模型，在低比特量化性能上可能不尽如人意。这为低比特量化领域带来潜在挑战，强调评估量化性能时需关注模型训练水平。为推动未来研究，本文公开了使用的1500多个量化检查点，网址为 https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 321 (char 447). Line: 406.
Append: [Low-Bit Quantization Favors Undertrained LLMs: Scaling Laws for Quantized LLMs with 100T Training Tokens](https://arxiv.org/abs/2411.17691)
Token length: 1265
Summarized using gpt-4o-mini
Append: [SketchAgent：语言驱动的动态素描生成方法](https://arxiv.org/abs/2411.17673)
append_entries: 7
Finish: 2024-11-27 09:01:47.282230
------------------------------------------------------
Started: 2024-11-27 12:13:52.742274
Existing_entries: 550
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1823
Summarized using gpt-4o-mini
Append: [MolReFlect: 基于教师-学生框架的分子与描述文本对齐方法](https://arxiv.org/abs/2411.14721)
Token length: 1003
Summarized using gpt-4o-mini
Append: [利用图像到视频模型提升图像编辑精度](https://arxiv.org/abs/2411.16819)
append_entries: 2
Finish: 2024-11-27 12:14:08.230273
------------------------------------------------------
Started: 2024-11-27 15:00:47.966412
Existing_entries: 552
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1352
Summarized using gpt-4o-mini
Append: [BootComp：基于扩散模型的人像生成框架](https://arxiv.org/abs/2411.16801)
Json decode failed:
{
  "title": "VL-RewardBench：针对视觉-语言生成奖励模型的评估基准",
  "keyword": ["VL-GenRMs", "评估基准", "多模态AI"],
  "short_summary": "VL-RewardBench基准为视觉-语言生成奖励模型的评估提供了新方法。",
  "summary": "本文介绍了VL-RewardBench，一个针对视觉-语言生成奖励模型（VL-GenRMs）评估的新基准。当前的评估方法主要依赖于传统VL任务中的AI标注偏好标签，这可能导致偏见，且难以有效挑战最先进的模型。VL-RewardBench涵盖了广泛的多模态查询、视觉幻觉检测和复杂推理任务，并结合AI辅助注释流程与人工验证，精心策划了1250个高质量示例，以探测模型局限性。在对16个领先的大型视觉-语言模型进行的全面评估中，发现VL-RewardBench作为具有挑战性的试验平台，其有效性得到了验证，甚至GPT-4o的准确率仅为65.4%，而最先进的开源模型如Qwen2-VL-72B的表现也难以超过随机猜测。研究表明，VL-RewardBench的表现与MMMU-Pro准确率高度相关（Pearson"s r > 0.9），为推动VL-GenRMs的发展提供了重要参考。"
}Summarization failed, append the original article
error: Expecting ',' delimiter: line 5 column 368 (char 523). Line: 406.
Append: [VLRewardBench: A Challenging Benchmark for Vision-Language Generative Reward Models](https://arxiv.org/abs/2411.17451)
append_entries: 2
Finish: 2024-11-27 15:00:57.078198
------------------------------------------------------
Started: 2024-11-27 18:10:11.205520
Existing_entries: 554
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-27 18:10:11.387864
------------------------------------------------------
Started: 2024-11-27 21:01:05.698399
Existing_entries: 554
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-27 21:01:05.855861
------------------------------------------------------
Started: 2024-11-28 00:36:50.352834
Existing_entries: 554
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-28 00:36:50.543307
------------------------------------------------------
Started: 2024-11-28 03:24:37.559841
Existing_entries: 554
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1430
Summarized using gpt-4o-mini
Append: [Efficient Vision Mamba: 提升资源受限环境下的视觉模型性能](https://arxiv.org/abs/2411.15241)
append_entries: 1
Finish: 2024-11-28 03:24:43.629899
------------------------------------------------------
Started: 2024-11-28 06:11:18.691258
Existing_entries: 555
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1483
Summarized using gpt-4o-mini
Append: [DiffusionDrive：一种实时多模态驾驶策略生成的新模型](https://arxiv.org/abs/2411.15139)
Token length: 1112
Summarized using gpt-4o-mini
Append: [SVIP：提高推测解码效率的动态草稿长度策略](https://arxiv.org/abs/2411.18462)
Token length: 1626
Summarized using gpt-4o-mini
Append: [Collaborative Decoding：提升视觉自回归图像生成效率的新策略](https://arxiv.org/abs/2411.17787)
Token length: 1658
Summarized using gpt-4o-mini
Append: [ISG：文本与图像交叉生成的综合评估框架](https://arxiv.org/abs/2411.17188)
Token length: 1438
Summarized using gpt-4o-mini
Append: [提升扩散模型的区域实例控制：ROICtrl的提出与应用](https://arxiv.org/abs/2411.17949)
Token length: 1865
Summarized using gpt-4o-mini
Append: [ConsisID：基于频率的身份保留文本到视频生成模型](https://arxiv.org/abs/2411.17440)
Token length: 1282
Summarized using gpt-4o-mini
Append: [MARVEL-40M+: 提升文本驱动3D内容生成的全新数据集](https://arxiv.org/abs/2411.17945)
append_entries: 7
Finish: 2024-11-28 06:12:00.926994
------------------------------------------------------
Started: 2024-11-28 09:01:17.833968
Existing_entries: 562
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1109
Summarized using gpt-4o-mini
Append: [Omegance: 通过单一参数控制扩散合成的细节粒度](https://arxiv.org/abs/2411.17769)
Token length: 1485
Summarized using gpt-4o-mini
Append: [提升计算机视觉中的感知与理解能力：ChatRex模型与Rexverse-2M数据集](https://arxiv.org/abs/2411.18363)
Token length: 1909
Summarized using gpt-4o-mini
Append: [LLM驱动的GUI代理：现状与未来发展路径](https://arxiv.org/abs/2411.18279)
Token length: 1239
Summarized using gpt-4o-mini
Append: [UniPose：多模态人类姿态理解与生成框架](https://arxiv.org/abs/2411.16781)
Token length: 1579
Summarized using gpt-4o-mini
Append: [基于MedNeXt的脑肿瘤分割方法在BraTS-2024挑战中的应用](https://arxiv.org/abs/2411.15872)
Token length: 1626
Summarized using gpt-4o-mini
Append: [TemplateMath: 利用模板生成数学问题以提升大语言模型推理能力](https://arxiv.org/abs/2411.18104)
Token length: 745
Summarized using gpt-4o-mini
Append: [CAT4D：从单目视频生成动态三维场景的新方法](https://arxiv.org/abs/2411.18613)
append_entries: 7
Finish: 2024-11-28 09:01:56.095158
------------------------------------------------------
Started: 2024-11-28 12:13:55.229360
Existing_entries: 569
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1419
Summarized using gpt-4o-mini
Append: [自适应盲式图像恢复模型ABAIR的设计与应用](https://arxiv.org/abs/2411.18412)
Token length: 914
Summarized using gpt-4o-mini
Append: [DreamCache：高效个性化图像生成的新方法](https://arxiv.org/abs/2411.17786)
Token length: 1365
Summarized using gpt-4o-mini
Append: [Make-It-Animatable: 快速将任何3D人形模型变为可动画角色](https://arxiv.org/abs/2411.18197)
append_entries: 3
Finish: 2024-11-28 12:14:10.308346
------------------------------------------------------
Started: 2024-11-28 15:00:51.805250
Existing_entries: 572
Fetching from https://rsshub.app/huggingface/daily-papers
Summarization failed, append the original article
error: __init__() got an unexpected keyword argument 'proxies'. Line: 406.
Append: [3D Convex Splatting: Radiance Field Rendering with 3D Smooth Convexes](https://arxiv.org/abs/2411.14974)
Summarization failed, append the original article
error: __init__() got an unexpected keyword argument 'proxies'. Line: 406.
Append: [VideoLLM Knows When to Speak: Enhancing Time-Sensitive Video Comprehension with Video-Text Duet Interaction Format](https://arxiv.org/abs/2411.17991)
append_entries: 2
Finish: 2024-11-28 15:00:51.897535
------------------------------------------------------
Started: 2024-11-28 18:00:52.239276
Existing_entries: 574
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-28 18:00:52.325537
------------------------------------------------------
Started: 2024-11-28 21:00:42.987284
Existing_entries: 574
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1183
Summarized using gpt-4o-mini
Append: [MultiFoley：视频指导的多模态声音生成模型](https://arxiv.org/abs/2411.17698)
append_entries: 1
Finish: 2024-11-28 21:00:48.628617
------------------------------------------------------
Started: 2024-11-29 00:36:30.682446
Existing_entries: 575
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1174
Summarized using gpt-4o-mini
Append: [扩散自蒸馏：提升文本条件图像生成的控制能力](https://arxiv.org/abs/2411.18616)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Recent advancements in diffusion models have made generative image editing more accessible, enabling creative edits but raising ethical concerns, particularly regarding malicious edits to human portraits that threaten privacy and identity security. Existing protection methods primarily rely on adversarial perturbations to nullify edits but often fail against diverse editing requests. We propose FaceLock, a novel approach to portrait protection that optimizes adversarial perturbations to destroy or significantly alter biometric information, rendering edited outputs biometrically unrecognizable. FaceLock integrates facial recognition and visual perception into perturbation optimization to provide robust protection against various editing attempts. We also highlight flaws in commonly used evaluation metrics and reveal how they can be manipulated, emphasizing the need for reliable assessments of protection. Experiments show FaceLock outperforms baselines in defending against malicious edits and is robust against purification techniques. Ablation studies confirm its stability and broad applicability across diffusion-based editing algorithms. Our work advances biometric defense and sets the foundation for privacy-preserving practices in image editing. The code is available at: https://github.com/taco-group/FaceLock.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Edit Away and My Face Will not Stay: Personal Biometric Defense against Malicious Generative Editing](https://arxiv.org/abs/2411.16832)
append_entries: 2
Finish: 2024-11-29 00:36:36.537334
------------------------------------------------------
Started: 2024-11-29 03:24:03.240854
Existing_entries: 577
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-29 03:24:03.342376
------------------------------------------------------
Started: 2024-11-29 06:00:45.134477
Existing_entries: 577
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-29 06:00:45.257050
------------------------------------------------------
Started: 2024-11-29 09:01:01.635953
Existing_entries: 577
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1187
Summarized using gpt-4o-mini
Append: [Morph：一种无运动数据的物理优化框架](https://arxiv.org/abs/2411.14951)
append_entries: 1
Finish: 2024-11-29 09:01:08.828020
------------------------------------------------------
Started: 2024-11-29 12:13:17.051923
Existing_entries: 578
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1881
Summarized using gpt-4o-mini
Append: [Critic-V: 提升视觉语言模型多模态推理能力的新框架](https://arxiv.org/abs/2411.18203)
append_entries: 1
Finish: 2024-11-29 12:13:23.187735
------------------------------------------------------
Started: 2024-11-29 15:00:51.605927
Existing_entries: 579
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1268
Summarized using gpt-4o-mini
Append: [Free^2Guide: 一种无梯度框架用于文本与视频生成对齐](https://arxiv.org/abs/2411.17041)
Token length: 994
Summarized using gpt-4o-mini
Append: [LongKey：针对长文档的自动关键短语提取框架](https://arxiv.org/abs/2411.17863)
Token length: 1251
Summarized using gpt-4o-mini
Append: [VTOFF: 基于单一图像生成标准化服装图像](https://arxiv.org/abs/2411.18350)
Token length: 1338
Summarized using gpt-4o-mini
Append: [自动文本到图像生成的研究与进展](https://arxiv.org/abs/2411.17176)
append_entries: 4
Finish: 2024-11-29 15:01:17.356497
------------------------------------------------------
Started: 2024-11-29 18:00:39.285273
Existing_entries: 583
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-29 18:00:39.376720
------------------------------------------------------
Started: 2024-11-29 21:00:40.454719
Existing_entries: 583
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-29 21:00:40.768090
------------------------------------------------------
Started: 2024-11-30 00:35:35.373526
Existing_entries: 583
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-30 00:35:35.498553
------------------------------------------------------
Started: 2024-11-30 03:19:37.658166
Existing_entries: 583
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1270
Summarized using gpt-4o-mini
Append: [AfriMed-QA：首个泛非英语言医疗问题回答数据集及其在医学多选题中的表现评估](https://arxiv.org/abs/2411.15640)
append_entries: 1
Finish: 2024-11-30 03:19:44.538488
------------------------------------------------------
Started: 2024-11-30 06:00:53.575807
Existing_entries: 584
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1363
Summarized using gpt-4o-mini
Append: [SelfSplat：无姿态与无三维先验的通用三维重建模型](https://arxiv.org/abs/2411.17190)
append_entries: 1
Finish: 2024-11-30 06:01:02.314380
------------------------------------------------------
Started: 2024-11-30 09:00:36.495458
Existing_entries: 585
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-30 09:00:36.703351
------------------------------------------------------
Started: 2024-11-30 12:11:42.115692
Existing_entries: 585
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-30 12:11:42.271270
------------------------------------------------------
Started: 2024-11-30 15:00:40.085137
Existing_entries: 585
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-30 15:00:40.192919
------------------------------------------------------
Started: 2024-11-30 18:00:58.830268
Existing_entries: 585
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-30 18:00:58.996661
------------------------------------------------------
Started: 2024-11-30 21:00:27.248560
Existing_entries: 585
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-30 21:00:27.376045
------------------------------------------------------
Started: 2024-12-01 00:44:18.829290
Existing_entries: 585
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-01 00:44:18.992107
------------------------------------------------------
Started: 2024-12-01 03:36:14.086802
Existing_entries: 585
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-01 03:36:14.226372
------------------------------------------------------
Started: 2024-12-01 06:00:46.302442
Existing_entries: 585
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-01 06:00:46.465911
------------------------------------------------------
Started: 2024-12-01 09:00:33.938831
Existing_entries: 585
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-01 09:00:34.150329
------------------------------------------------------
Started: 2024-12-01 12:12:21.373134
Existing_entries: 585
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-01 12:12:21.452731
------------------------------------------------------
Started: 2024-12-01 15:00:48.611729
Existing_entries: 585
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-01 15:00:48.742681
------------------------------------------------------
Started: 2024-12-01 18:00:39.023477
Existing_entries: 585
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-01 18:00:39.135975
------------------------------------------------------
Started: 2024-12-01 21:00:42.491329
Existing_entries: 585
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-01 21:00:42.611059
------------------------------------------------------
Started: 2024-12-02 00:38:52.642597
Existing_entries: 585
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-02 00:38:52.775718
------------------------------------------------------
Started: 2024-12-02 03:29:05.591473
Existing_entries: 585
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-02 03:29:05.693475
------------------------------------------------------
Started: 2024-12-02 06:11:45.210150
Existing_entries: 585
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-02 06:11:45.308380
------------------------------------------------------
Started: 2024-12-02 09:01:10.349692
Existing_entries: 585
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1854
Summarized using gpt-4o-mini
Append: [Puzzle框架：提升大型语言模型推理效率](https://arxiv.org/abs/2411.19146)
Token length: 1309
Summarized using gpt-4o-mini
Append: [Video-Ma^2mba: 线性扩展的视频处理架构](https://arxiv.org/abs/2411.19460)
Token length: 1327
Summarized using gpt-4o-mini
Append: [TeaCache：基于时间步嵌入的高效视频生成缓存方法](https://arxiv.org/abs/2411.19108)
Token length: 1566
Summarized using gpt-4o-mini
Append: [AC3D架构：先进的3D相机控制模型](https://arxiv.org/abs/2411.18673)
Token length: 1349
Summarized using gpt-4o-mini
Append: [领域适应性提升：后训练与数据合成在多模态大语言模型中的应用](https://arxiv.org/abs/2411.19930)
Token length: 1345
Summarized using gpt-4o-mini
Append: [基于轨迹注意力的视频生成方法研究](https://arxiv.org/abs/2411.19324)
append_entries: 6
Finish: 2024-12-02 09:01:39.497978
------------------------------------------------------
Started: 2024-12-02 12:14:18.051405
Existing_entries: 591
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1332
Summarized using gpt-4o-mini
Append: [DisCoRD：通过修正流解码实现离散与连续运动的优雅结合](https://arxiv.org/abs/2411.19527)
Token length: 1173
Summarized using gpt-4o-mini
Append: [HiAR-ICL：一种高水平自动推理的新范式](https://arxiv.org/abs/2411.18478)
Token length: 1543
Summarized using gpt-4o-mini
Append: [RollingDepth：基于单幅图像的高效视频深度估计模型](https://arxiv.org/abs/2411.19189)
Token length: 1643
Summarized using gpt-4o-mini
Append: [基于大语言模型的多语言新闻分类框架](https://arxiv.org/abs/2411.19638)
Token length: 1241
Summarized using gpt-4o-mini
Append: [AlphaTablets：一种新型三维平面表示方法及其应用](https://arxiv.org/abs/2411.19950)
append_entries: 5
Finish: 2024-12-02 12:14:46.071729
------------------------------------------------------
Started: 2024-12-02 15:00:50.513391
Existing_entries: 596
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-02 15:00:57.328424
------------------------------------------------------
Started: 2024-12-02 18:10:21.085865
Existing_entries: 596
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1535
Summarized using gpt-4o-mini
Append: [逆向思维在大型语言模型中的应用与改进](https://arxiv.org/abs/2411.19865)
Token length: 1321
Summarized using gpt-4o-mini
Append: [Fam扩散模型：灵活调整高质量图像生成](https://arxiv.org/abs/2411.18552)
append_entries: 2
Finish: 2024-12-02 18:10:34.034203
------------------------------------------------------
Started: 2024-12-02 21:00:44.645389
Existing_entries: 598
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-02 21:00:44.821409
------------------------------------------------------
Started: 2024-12-03 00:38:08.362439
Existing_entries: 598
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 509
Summarized using gpt-4o-mini
Append: [视觉变换器的训练噪声令牌修剪方法](https://arxiv.org/abs/2411.18092)
Token length: 1283
Summarized using gpt-4o-mini
Append: [SpotLight：基于扩散模型的可控虚拟物体重光方法](https://arxiv.org/abs/2411.18665)
Token length: 719
Summarized using gpt-4o-mini
Append: [大型参数变换器在语音编码中的应用](https://arxiv.org/abs/2411.19842)
Token length: 1200
Summarized using gpt-4o-mini
Append: [引入时空跳跃引导法以提升视频扩散模型的生成质量](https://arxiv.org/abs/2411.18664)
append_entries: 4
Finish: 2024-12-03 00:38:35.325388
------------------------------------------------------
Started: 2024-12-03 03:28:18.345252
Existing_entries: 602
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 959
Summarized using gpt-4o-mini
Append: [MATATA：一种高效训练小型语言模型处理表格数据的方法](https://arxiv.org/abs/2411.18915)
Token length: 1718
Summarized using gpt-4o-mini
Append: [GRAPE：通过偏好对齐实现机器人政策的普适性提升](https://arxiv.org/abs/2411.19309)
append_entries: 2
Finish: 2024-12-03 03:28:28.318702
------------------------------------------------------
Started: 2024-12-03 06:00:45.319690
Existing_entries: 604
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1569
Summarized using gpt-4o-mini
Append: [VisOnlyQA: 评估大型视觉语言模型的视觉感知能力](https://arxiv.org/abs/2412.00947)
Token length: 1208
Summarized using gpt-4o-mini
Append: [Presto: 一种新型的视频扩散模型实现15秒长视频生成](https://arxiv.org/abs/2412.01316)
Token length: 1365
Summarized using gpt-4o-mini
Append: [TAPTRv3：增强长期视频跟踪的鲁棒性](https://arxiv.org/abs/2411.18671)
Token length: 1375
Summarized using gpt-4o-mini
Append: [Wavelet Flow VAE：高效视频编码的新方法](https://arxiv.org/abs/2411.17459)
append_entries: 4
Finish: 2024-12-03 06:01:05.865066
------------------------------------------------------
Started: 2024-12-03 09:00:43.331780
Existing_entries: 608
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-03 09:00:43.519522
------------------------------------------------------
Started: 2024-12-03 12:13:41.800892
Existing_entries: 608
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1032
Summarized using gpt-4o-mini
Append: [推动多语言大模型性能的本地评估基准建设](https://arxiv.org/abs/2411.19799)
Token length: 1232
Summarized using gpt-4o-mini
Append: [SOLAMI: 3D自主角色的社交智能建模框架](https://arxiv.org/abs/2412.00174)
Json decode failed:
{
  "title": "GATE OpenING：推动多模态生成模型的评估与发展",
  "keyword": ["多模态", "生成模型", "基准测试"],
  "short_summary": "GATE OpenING提供了新的基准测试以推动多模态生成方法的发展与评估。",
  "summary": "多模态大语言模型（MLLMs）在视觉理解和生成任务上取得了显著进展，但生成交错的图文内容依然是一大挑战。为了解决现有基准测试数据不足的问题，我们提出了GATE OpenING（OpenING），这是一个包含5400个高质量人类注释实例的新基准，覆盖56个现实世界任务，涉及日常场景如旅行指南、设计和头脑风暴。此外，我们还提出了IntJudge，一个用于评估开放式多模态生成方法的模型，该模型通过创新的数据处理流程进行训练，与人类判断的协议率高达82.42%，并超过了基于GPT的评估器11.34%。通过在OpenING上的广泛实验，发现当前的交错生成方法仍有很大的改善空间，为下一代模型的发展提供了关键指导。OpenING已在https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 334 (char 477). Line: 406.
Append: [GATE OpenING: A Comprehensive Benchmark for Judging Open-ended Interleaved Image-Text Generation](https://arxiv.org/abs/2411.18499)
Token length: 979
Summarized using gpt-4o-mini
Append: [FLOAT：基于流匹配生成模型的音频驱动人像视频生成方法](https://arxiv.org/abs/2412.01064)
Token length: 1332
Summarized using gpt-4o-mini
Append: [一种基于两阶段算法的大型语言模型测试时间计算的方法](https://arxiv.org/abs/2411.19477)
Token length: 1268
Summarized using gpt-4o-mini
Append: [VISTA: 视频时空增强框架提升长时长高分辨率视频理解](https://arxiv.org/abs/2412.00927)
Json decode failed:
{
  "title": "O1-CODER: 基于强化学习的编码任务模型",
  "keyword": ["O1-CODER", "强化学习", "编码"],
  "short_summary": "O1-CODER模型旨在通过RL和MCTS提升编码任务的系统思维能力。",
  "summary": "技术报告介绍了O1-CODER，一个旨在复制OpenAI o1模型的项目，专注于编码任务。该模型结合了强化学习（RL）和蒙特卡洛树搜索（MCTS），增强其系统-2思维能力。框架中包括训练测试用例生成器（TCG），用于标准化代码测试，应用MCTS生成带有推理过程的代码数据，并反复微调策略模型以首先生成伪代码，随后生成完整代码。报告还讨论了在实际应用中部署类似o1模型的机遇与挑战，建议向系统-2范式转型，并强调环境状态更新的重要性。后续版本将报告模型进展和实验结果，所有源代码、策划的数据集以及衍生模型会在 https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 275 (char 413). Line: 406.
Append: [o1-Coder: an o1 Replication for Coding](https://arxiv.org/abs/2412.00154)
Token length: 1873
Summarized using gpt-4o-mini
Append: [EfficientTAMs：轻量级视频对象分割模型的创新](https://arxiv.org/abs/2411.18933)
Token length: 1434
Summarized using gpt-4o-mini
Append: [TinyFusion：高效的扩散变换器深度剪枝方法](https://arxiv.org/abs/2412.01199)
Token length: 1266
Summarized using gpt-4o-mini
Append: [X-Prompt：提升视觉语言模型的图像生成能力](https://arxiv.org/abs/2412.01824)
Token length: 1425
Summarized using gpt-4o-mini
Append: [FlowChef：高效的受控图像生成框架](https://arxiv.org/abs/2412.00100)
Json decode failed:
{
  "title": "Open-Sora Plan：开放源代码的视频生成项目",
  "keywords": ["视频生成", "开放源代码", "高分辨率"],
  "short_summary": "Open-Sora Plan旨在通过用户输入生成高分辨率长视频。",
  "summary": "Open-Sora Plan是一个开源项目，旨在基于用户输入生成高分辨率的长时间视频。该项目包含了视频生成过程中的多个组件，如Wavelet-Flow变分自编码器、联合图像-视频去噪器和多种条件控制器。同时，我们设计了多种辅助策略以提高训练和推理的效率，并提出了一个多维数据策划管道，以获取所需的高质量数据。得益于这些高效的策略，Open-Sora Plan在定性和定量评估中都取得了令人瞩目的视频生成效果。我们希望我们的精心设计和实践经验能够激励视频生成研究社区。所有代码和模型权重已公开分享在https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 269 (char 408). Line: 406.
Append: [Open-Sora Plan: Open-Source Large Video Generation Model](https://arxiv.org/abs/2412.00131)
append_entries: 12
Finish: 2024-12-03 12:15:01.993394
------------------------------------------------------
Started: 2024-12-03 15:00:51.615338
Existing_entries: 620
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 996
Summarized using gpt-4o-mini
Append: [利用预训练音频表示进行低资源语言的在线辱骂内容检测](https://arxiv.org/abs/2412.01408)
Token length: 1696
Summarized using gpt-4o-mini
Append: [PhysGame：评估视频语言模型中的物理常识理解](https://arxiv.org/abs/2412.01800)
Token length: 1252
Summarized using gpt-4o-mini
Append: [VLsI：高效的视觉语言模型与层级蒸馏方法](https://arxiv.org/abs/2412.01822)
Token length: 1354
Summarized using gpt-4o-mini
Append: [协作实例导航任务及其动态人机交互方法](https://arxiv.org/abs/2412.01250)
Token length: 1114
Summarized using gpt-4o-mini
Append: [Switti: 高效的文本到图像生成规模化变压器](https://arxiv.org/abs/2412.01819)
Token length: 1431
Summarized using gpt-4o-mini
Append: [多模态大型语言模型的安全性问题研究与VLSBench基准构建](https://arxiv.org/abs/2411.19939)
append_entries: 6
Finish: 2024-12-03 15:01:23.409960
------------------------------------------------------
Started: 2024-12-03 18:00:50.332205
Existing_entries: 626
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "引入大型数据集促进机器学习代理模型发展",
  "keyword": ["机器学习", "数据集", "物理模拟"],
  "short_summary": "文章介绍了一个大型数据集，以促进机器学习代理模型在物理模拟中的应用。",
  "summary": "本文介绍了一个名为Well的大型数据集，旨在为机器学习代理模型提供丰富的数据支持。Well包含15TB的数值模拟数据，涵盖生物系统、流体动力学、声散射以及星际流体和超新星爆炸的磁流体动力学等多个领域，共计16个数据集。这些数据集为研究者提供了多样化的物理行为表现，能够单独使用，也可以组成更广泛的基准套件。为便于使用，本文还提供了一个统一的PyTorch接口，用于训练和评估模型。通过示例基线，展示了Well带来的新挑战和复杂动态。相关代码和数据可在GitHub上获取，网址为https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 259 (char 389). Line: 406.
Append: [The Well: a Large-Scale Collection of Diverse Physics Simulations for Machine Learning](https://arxiv.org/abs/2412.00568)
Token length: 1129
Summarized using gpt-4o-mini
Append: [通过XYZ图像实现3D一致性的视频扩散模型](https://arxiv.org/abs/2412.01821)
Token length: 645
Summarized using gpt-4o-mini
Append: [探索艺术创作中先前艺术知识的需求](https://arxiv.org/abs/2412.00176)
append_entries: 3
Finish: 2024-12-03 18:01:01.865398
------------------------------------------------------
Started: 2024-12-03 21:00:40.976670
Existing_entries: 629
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-03 21:00:41.163799
------------------------------------------------------
Started: 2024-12-04 00:37:44.288792
Existing_entries: 629
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1354
Summarized using gpt-4o-mini
Append: [基于CycleGAN的说话人验证系统情感语音数据增强方法](https://arxiv.org/abs/2412.00319)
Token length: 1138
Summarized using gpt-4o-mini
Append: [利用知识增强的提示评估大型语言模型在比例类比完成中的表现](https://arxiv.org/abs/2412.00869)
append_entries: 2
Finish: 2024-12-04 00:37:53.042181
------------------------------------------------------
Started: 2024-12-04 03:26:45.420793
Existing_entries: 631
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1399
Summarized using gpt-4o-mini
Append: [HUGSIM：高保真闭环模拟器提升自主驾驶算法评估](https://arxiv.org/abs/2412.01718)
Token length: 1399
Summarized using gpt-4o-mini
Append: [无训练方法提升文本生成图像的精确度](https://arxiv.org/abs/2411.19415)
append_entries: 2
Finish: 2024-12-04 03:27:01.244721
------------------------------------------------------
Started: 2024-12-04 06:00:52.112231
Existing_entries: 633
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1332
Summarized using gpt-4o-mini
Append: [基于掩码的引导图像分割方法研究](https://arxiv.org/abs/2411.19067)
Token length: 1893
Summarized using gpt-4o-mini
Append: [隐式过程奖励模型的训练方法及其效率提升](https://arxiv.org/abs/2412.01981)
Token length: 1302
Summarized using gpt-4o-mini
Append: [评估多模态大型语言模型的音频视觉理解能力](https://arxiv.org/abs/2412.02611)
Token length: 1267
Summarized using gpt-4o-mini
Append: [基于GSQ的视觉标记器：提高重建质量与可扩展性](https://arxiv.org/abs/2412.02632)
Token length: 1666
Summarized using gpt-4o-mini
Append: [LSceneLLM：提升3D视觉语言模型在大型场景理解中的表现](https://arxiv.org/abs/2412.01292)
Token length: 1894
Summarized using gpt-4o-mini
Append: [VGoT：面向多镜头视频生成的新架构](https://arxiv.org/abs/2412.02259)
Token length: 1676
Summarized using gpt-4o-mini
Append: [识别与奖励关键令牌的对比估计方法cDPO：提升大型语言模型推理表现](https://arxiv.org/abs/2411.19943)
append_entries: 7
Finish: 2024-12-04 06:01:27.934973
------------------------------------------------------
Started: 2024-12-04 09:00:59.818421
Existing_entries: 640
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1566
Summarized using gpt-4o-mini
Append: [OHRBench：评估OCR对RAG系统的影响](https://arxiv.org/abs/2412.02592)
Token length: 608
Summarized using gpt-4o-mini
Append: [动态并行方法提升混合CPU的AI推理性能](https://arxiv.org/abs/2411.19542)
Token length: 1488
Summarized using gpt-4o-mini
Append: [VideoLights: 一种新的视频高亮检测和时刻检索框架](https://arxiv.org/abs/2412.01558)
append_entries: 3
Finish: 2024-12-04 09:01:13.988626
------------------------------------------------------
Started: 2024-12-04 12:01:05.630676
Existing_entries: 643
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-04 12:01:05.723580
------------------------------------------------------
Started: 2024-12-04 15:00:52.604203
Existing_entries: 643
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1538
Summarized using gpt-4o-mini
Append: [多智能体大规模语言模型训练的初步探索](https://arxiv.org/abs/2412.01928)
Token length: 1384
Summarized using gpt-4o-mini
Append: [OmniCreator：统一的图像与视频生成及编辑框架](https://arxiv.org/abs/2412.02114)
append_entries: 2
Finish: 2024-12-04 15:01:10.635103
------------------------------------------------------
Started: 2024-12-04 18:10:36.794053
Existing_entries: 645
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1494
Summarized using gpt-4o-mini
Append: [GenAI系统设计模式与工业应用的探索](https://arxiv.org/abs/2412.00239)
Token length: 1372
Summarized using gpt-4o-mini
Append: [基于运动提示的视频生成模型研究](https://arxiv.org/abs/2412.02700)
Token length: 1526
Summarized using gpt-4o-mini
Append: [LLM-Oasis：评估大型语言模型事实性的创新资源](https://arxiv.org/abs/2411.19655)
append_entries: 3
Finish: 2024-12-04 18:11:13.165210
------------------------------------------------------
Started: 2024-12-04 21:00:45.315453
Existing_entries: 648
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-04 21:00:45.499398
------------------------------------------------------
Started: 2024-12-07 03:52:18.615198
Existing_entries: 648
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1295
Summarized using gpt-4o-mini
Append: [预训练语言模型任务性能的缩放规律与模型阶梯预测](https://arxiv.org/abs/2412.04403)
Token length: 1039
Summarized using gpt-4o-mini
Append: [NVILA：一款高效的视觉语言模型](https://arxiv.org/abs/2412.04468)
Token length: 892
Summarized using gpt-4o-mini
Append: [4Real-Video：新型4D视频生成框架](https://arxiv.org/abs/2412.04462)
Token length: 1471
Summarized using gpt-4o-mini
Append: [基于混合深度机制的高效多模态大语言模型](https://arxiv.org/abs/2412.04449)
Token length: 1355
Summarized using gpt-4o-mini
Append: [SynFinTabs：合成金融表格的标签数据集和模型测试](https://arxiv.org/abs/2412.04262)
Token length: 1369
Summarized using gpt-4o-mini
Append: [Vision Value Model (VisVM) 提升视觉语言模型响应质量](https://arxiv.org/abs/2412.03704)
Token length: 1341
Summarized using gpt-4o-mini
Append: [MEMO：基于记忆的情感驱动视频生成模型](https://arxiv.org/abs/2412.04448)
Token length: 865
Summarized using gpt-4o-mini
Append: [提高开放平台人类注释质量的挑战与对策](https://arxiv.org/abs/2412.04363)
Token length: 1498
Summarized using gpt-4o-mini
Append: [提升视觉语言模型理解能力的新方法](https://arxiv.org/abs/2412.04378)
Token length: 1780
Summarized using gpt-4o-mini
Append: [任何服装虚拟穿搭方法AnyDressing的创新研究](https://arxiv.org/abs/2412.04146)
Token length: 1781
Summarized using gpt-4o-mini
Append: [多语言数据集中的文化偏见及其对模型评估的影响](https://arxiv.org/abs/2412.03304)
Token length: 864
Summarized using gpt-4o-mini
Append: [改进的注意力机制：KV位移注意力提升语言模型的学习能力](https://arxiv.org/abs/2411.19574)
Json decode failed:
{
  "title": "无引导噪声精炼模型在高质量图像生成中的应用",
  "short_summary": "研究表明，精炼初始噪声可在无引导下生成高质量图像。",
  "summary": "本文探讨了在无引导方法的情况下，扩散模型生成高质量图像的可能性。研究发现，通过对扩散反演中获得的噪声进行转换，可以有效地重构高质量图像。我们聚焦于去噪流程中的初始噪声，通过将高斯噪声映射到“无引导噪声”，揭示了小幅低频成分在去噪过程中的重要性，从而消除了对引导的需求。同时，我们提出了一种新方法\ours，采用单次初始噪声精炼来替代传统引导方法。在相同的扩散管道中，该精炼噪声能够实现高质量的图像生成。我们的噪声精炼模型利用高效的噪声空间学习，实现了快速收敛，并且在仅使用50K的文本-图像配对下，展现了强大的性能。通过多种指标验证了其有效性，并分析了精炼噪声如何消除对引导的需求。",
  "keyword": [
    "扩散模型",
    "噪声精炼",
    "高质量图像生成"
  ]
}Summarization failed, append the original article
error: Invalid \escape: line 4 column 162 (char 247). Line: 406.
Append: [A Noise is Worth Diffusion Guidance](https://arxiv.org/abs/2412.03895)
Token length: 1441
Summarized using gpt-4o-mini
Append: [Marco-LLM：跨语言增强的多语言大语言模型](https://arxiv.org/abs/2412.04003)
Token length: 1170
Summarized using gpt-4o-mini
Append: [个性化多模态大语言模型概述](https://arxiv.org/abs/2412.02142)
Json decode failed:
{
  "title": "通过单义专家混合架构提升大语言模型的可解释性",
  "keyword": ["大语言模型", "稀疏自编码器", "专家架构"],
  "short_summary": "本文介绍了一种新架构，通过稀疏字典学习提升大语言模型的可解释性。",
  "summary": "理解大型语言模型（LLMs）的内部计算对于使其与人类价值观对齐至关重要，但多义性问题使得机械可解释性受到阻碍。传统的稀疏自编码器虽然试图通过稀疏字典学习解耦特征，但因依赖后期重构损失而影响了LLM的性能。为解决此问题，本文提出了"单义专家混合"（Monet）架构，直接在端到端的专家预训练中整合稀疏字典学习。该方法允许每层专家数量达到262,144，且总参数量与专家数量的平方根成正比。我们的分析表明，专家之间知识的互斥性，以及各个专家内封装的参数知识。此外，Monet架构能够在不降低整体性能的情况下，对领域、语言和有毒内容进行知识操控。我们追求透明的LLM揭示了提升专家数量对增强机械可解释性的潜力，及其本质上调整模型行为的能力。"
}Summarization failed, append the original article
error: Expecting ',' delimiter: line 5 column 130 (char 265). Line: 406.
Append: [Monet: Mixture of Monosemantic Experts for Transformers](https://arxiv.org/abs/2412.04139)
Json decode failed:
{
  "title": "基于视觉特征的对抗性引导方法NegToMe",
  "short_summary": "NegToMe通过视觉特征改善生成图像的多样性与质量。",
  "summary": "本文首次探讨了通过参考图像的视觉特征进行对抗性引导，提出了一种简单有效的无训练方法NegToMe。在逆扩散过程中，NegToMe通过选择性地分离生成图像与参考图像之间的匹配语义特征，实现对抗性引导。实验结果表明，NegToMe在保持输出图像质量的同时，显著提高了输出的多样性（种族、性别、视觉）和减少与版权内容的相似度（降低34.57%）。该方法易于实现，仅需几行代码，推理时间仅增加不到4%，且能够推广应用到不同的扩散架构中。代码可在 https:
  "keyword": [
    "对抗性引导",
    "视觉特征",
    "NegToMe"
  ]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 240 (char 327). Line: 406.
Append: [Negative Token Merging: Image-based Adversarial Feature Guidance](https://arxiv.org/abs/2412.01339)
Token length: 1314
Summarized using gpt-4o-mini
Append: [基于视觉语言模型的开放集故障检测与预防方法](https://arxiv.org/abs/2412.04455)
Token length: 1684
Summarized using gpt-4o-mini
Append: [MV-Adapter：适用于多视图图像生成的高效适配器](https://arxiv.org/abs/2412.03632)
Token length: 1666
Summarized using gpt-4o-mini
Append: [大语言模型的容量密度：评估效能与效率的新指标](https://arxiv.org/abs/2412.04315)
Token length: 957
Summarized using gpt-4o-mini
Append: [ZipAR: 一种加速自回归视觉生成的并行解码框架](https://arxiv.org/abs/2412.04062)
Token length: 1601
Summarized using gpt-4o-mini
Append: [Florence-VL：增强视觉表示的多模态大型语言模型](https://arxiv.org/abs/2412.04424)
Token length: 1231
Summarized using gpt-4o-mini
Append: [Infinity：一种高效的文本到图像自回归模型](https://arxiv.org/abs/2412.04431)
Token length: 1558
Summarized using gpt-4o-mini
Append: [Aguvis：一种基于视觉的自主GUI代理框架](https://arxiv.org/abs/2412.04454)
Token length: 1218
Summarized using gpt-4o-mini
Append: [OmniFlow：新型多模态生成模型实现任意生成任务](https://arxiv.org/abs/2412.01169)
Token length: 1069
Summarized using gpt-4o-mini
Append: [基于多模态框架的足球视频理解研究](https://arxiv.org/abs/2412.01820)
Token length: 1304
Summarized using gpt-4o-mini
Append: [评估语言模型数据生成能力的AgoraBench基准](https://arxiv.org/abs/2412.03679)
Token length: 1217
Summarized using gpt-4o-mini
Append: [基于生成模型的医学图像分割新 Paradigm](https://arxiv.org/abs/2412.04106)
Token length: 1390
Summarized using gpt-4o-mini
Append: [VisionZip：提高视觉语言模型效率的新方法](https://arxiv.org/abs/2412.04467)
Token length: 1053
Summarized using gpt-4o-mini
Append: [新型三维生成方法：结构化潜在表示与高质量资产创作](https://arxiv.org/abs/2412.01506)
Append: [HumanEdit: A High-Quality Human-Rewarded Dataset for Instruction-based Image Editing](https://arxiv.org/abs/2412.04280)
append_entries: 31
Finish: 2024-12-07 03:54:09.146827
------------------------------------------------------
Started: 2024-12-07 06:00:39.214472
Existing_entries: 679
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-07 06:00:39.415935
------------------------------------------------------
Started: 2024-12-07 09:00:53.668564
Existing_entries: 679
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-07 09:00:53.893443
------------------------------------------------------
Started: 2024-12-07 12:00:44.683942
Existing_entries: 679
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-07 12:00:44.882806
------------------------------------------------------
Started: 2024-12-07 15:01:33.938124
Existing_entries: 679
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-07 15:01:34.181181
------------------------------------------------------
Started: 2024-12-07 18:01:00.695660
Existing_entries: 679
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-07 18:01:00.921809
------------------------------------------------------
Started: 2024-12-07 21:00:38.799888
Existing_entries: 679
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-07 21:00:39.143532
------------------------------------------------------
Started: 2024-12-08 00:40:46.472246
Existing_entries: 679
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-08 00:40:46.702937
------------------------------------------------------
Started: 2024-12-08 03:29:34.311515
Existing_entries: 679
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-08 03:29:34.567409
------------------------------------------------------
Started: 2024-12-08 06:00:40.875778
Existing_entries: 679
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-08 06:00:41.090856
------------------------------------------------------
Started: 2024-12-08 09:01:08.905732
Existing_entries: 679
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-08 09:01:09.165712
------------------------------------------------------
Started: 2024-12-08 12:00:47.281143
Existing_entries: 679
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-08 12:00:47.483880
------------------------------------------------------
Started: 2024-12-08 15:00:40.870077
Existing_entries: 679
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-08 15:00:41.081521
------------------------------------------------------
Started: 2024-12-08 18:00:48.110267
Existing_entries: 679
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-08 18:00:48.317276
------------------------------------------------------
Started: 2024-12-08 21:00:40.399174
Existing_entries: 679
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-08 21:00:40.640765
------------------------------------------------------
Started: 2024-12-09 00:39:00.403928
Existing_entries: 679
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-09 00:39:00.646575
------------------------------------------------------
Started: 2024-12-09 03:30:03.645159
Existing_entries: 679
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-09 03:30:03.843481
------------------------------------------------------
Started: 2024-12-09 06:01:03.306331
Existing_entries: 679
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1673
Summarized using gpt-4o-mini
Append: [GenMAC：多智能体框架实现复杂文本到视频生成](https://arxiv.org/abs/2412.04440)
append_entries: 1
Finish: 2024-12-09 06:01:07.154241
------------------------------------------------------
Started: 2024-12-09 09:01:11.832887
Existing_entries: 680
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1175
Summarized using gpt-4o-mini
Append: [MinT：一种具有时间控制的多事件视频生成器](https://arxiv.org/abs/2412.05263)
Token length: 1105
Summarized using gpt-4o-mini
Append: [高保真室内场景重建的新方法2DGS-Room](https://arxiv.org/abs/2412.03428)
Token length: 1254
Summarized using gpt-4o-mini
Append: [基于人类反馈的文本生成视频模型对齐方法LiFT](https://arxiv.org/abs/2412.04814)
Token length: 1311
Summarized using gpt-4o-mini
Append: [InternVL 2.5：新一代多模态大语言模型](https://arxiv.org/abs/2412.05271)
Token length: 1874
Summarized using gpt-4o-mini
Append: [APOLLO：面向大规模语言模型优化的记忆高效优化器](https://arxiv.org/abs/2412.05270)
Token length: 1284
Summarized using gpt-4o-mini
Append: [构建大规模多模态指令调优数据集以提升推理能力](https://arxiv.org/abs/2412.05237)
Json decode failed:
{
  "title": "EXAONE 3.5指令调优语言模型介绍",
  "keyword": ["LG AI Research", "EXAONE 3.5", "语言模型"],
  "short_summary": "本文介绍了LG AI Research开发的EXAONE 3.5语言模型及其特点。",
  "summary": "本技术报告介绍了LG AI Research开发的EXAONE 3.5指令调优语言模型，提供了32B、7.8B和2.4B三种配置。这些模型在多个领域展现出色能力，包括在七项基准测试中实现最高的指令跟随能力，在四项基准测试中具备卓越的长文本理解能力，以及在九项通用基准中与同类前沿开放模型的竞争表现。EXAONE 3.5模型开放给任何人用于研究，用户可以从https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 198 (char 353). Line: 406.
Append: [EXAONE 3.5: Series of Large Language Models for Real-world Use Cases](https://arxiv.org/abs/2412.04862)
Token length: 1161
Summarized using gpt-4o-mini
Append: [SwiftEdit：高效的文本引导图像编辑工具](https://arxiv.org/abs/2412.04301)
Token length: 1907
Summarized using gpt-4o-mini
Append: [Moto-GPT：基于视频数据的机器人运动学习新方法](https://arxiv.org/abs/2412.04445)
append_entries: 9
Finish: 2024-12-09 09:01:45.663296
------------------------------------------------------
Started: 2024-12-09 12:14:35.457091
Existing_entries: 689
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1119
Summarized using gpt-4o-mini
Append: [对话元素建模的创新研究与基准DEMO](https://arxiv.org/abs/2412.04905)
append_entries: 1
Finish: 2024-12-09 12:14:40.109910
------------------------------------------------------
Started: 2024-12-09 15:00:47.528327
Existing_entries: 690
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-09 15:00:47.834767
------------------------------------------------------
Started: 2024-12-09 18:00:54.776694
Existing_entries: 690
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-09 18:00:55.006279
------------------------------------------------------
Started: 2024-12-09 21:00:57.733574
Existing_entries: 690
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1481
Summarized using gpt-4o-mini
Append: [提升多模态大型语言模型对复合图像理解的研究](https://arxiv.org/abs/2412.05243)
Token length: 788
Summarized using gpt-4o-mini
Append: [PanoDreamer: 一种单幅图像生成360度3D场景的新方法](https://arxiv.org/abs/2412.04827)
Token length: 1531
Summarized using gpt-4o-mini
Append: [Momentum-GS：提升3D重建一致性与准确性的动量自蒸馏方法](https://arxiv.org/abs/2412.04887)
append_entries: 3
Finish: 2024-12-09 21:01:10.090316
------------------------------------------------------
Started: 2024-12-10 00:38:06.785285
Existing_entries: 693
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1634
Summarized using gpt-4o-mini
Append: [BigDocs-7.5M：推动多模态AI在文档理解中的应用](https://arxiv.org/abs/2412.04626)
append_entries: 1
Finish: 2024-12-10 00:38:14.522977
------------------------------------------------------
Started: 2024-12-10 03:28:38.782574
Existing_entries: 694
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-10 03:28:38.953171
------------------------------------------------------
Started: 2024-12-10 06:00:55.652495
Existing_entries: 694
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1609
Summarized using gpt-4o-mini
Append: [无监督增强学习：RLZero方法实现零-shot语言到行为生成](https://arxiv.org/abs/2412.05718)
append_entries: 1
Finish: 2024-12-10 06:01:02.715447
------------------------------------------------------
Started: 2024-12-10 09:00:55.817728
Existing_entries: 695
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-10 09:00:55.974307
------------------------------------------------------
Started: 2024-12-10 12:14:10.656182
Existing_entries: 695
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1348
Summarized using gpt-4o-mini
Append: [多模态多粒度概念注释数据集 MMGiC 的构建与应用](https://arxiv.org/abs/2412.05939)
Token length: 1792
Summarized using gpt-4o-mini
Append: [See3D：基于大规模视频的视觉条件多视角扩散模型](https://arxiv.org/abs/2412.06699)
Token length: 1003
Summarized using gpt-4o-mini
Append: [基于大语言模型的隐蔽多比特文本水印嵌入方法](https://arxiv.org/abs/2412.03123)
Token length: 1495
Summarized using gpt-4o-mini
Append: [ProcessBench：数学推理错误识别能力的评估工具](https://arxiv.org/abs/2412.06559)
Token length: 1570
Summarized using gpt-4o-mini
Append: [Coconut：超越语言空间的连续思维推理范式](https://arxiv.org/abs/2412.06769)
Token length: 1465
Summarized using gpt-4o-mini
Append: [CARP：高效的粗到细自回归策略用于机器人视觉运动学习](https://arxiv.org/abs/2412.06782)
append_entries: 6
Finish: 2024-12-10 12:14:38.997915
------------------------------------------------------
Started: 2024-12-10 15:00:53.659830
Existing_entries: 701
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1589
Summarized using gpt-4o-mini
Append: [Divot: 一种基于扩散过程的视频标记器及其在视频生成中的应用](https://arxiv.org/abs/2412.04432)
append_entries: 1
Finish: 2024-12-10 15:01:04.558083
------------------------------------------------------
Started: 2024-12-10 18:01:01.173090
Existing_entries: 702
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1012
Summarized using gpt-4o-mini
Append: [基于扩散与黎曼流匹配的概率视觉地理定位方法](https://arxiv.org/abs/2412.06781)
Token length: 1087
Summarized using gpt-4o-mini
Append: [基于混合得分指导的扩散变换器运动迁移方法](https://arxiv.org/abs/2412.05355)
Token length: 934
Summarized using gpt-4o-mini
Append: [利用深度学习生成地球观测数据的特征表示](https://arxiv.org/abs/2412.05600)
Token length: 1234
Summarized using gpt-4o-mini
Append: [强化学习中智能体记忆概念的标准化与评估方法](https://arxiv.org/abs/2412.06531)
append_entries: 4
Finish: 2024-12-10 18:01:21.696000
------------------------------------------------------
Started: 2024-12-10 21:00:48.468858
Existing_entries: 706
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1378
Summarized using gpt-4o-mini
Append: [MAtCha: 高质量3D表面重建与光照片真实感视图合成的新模型](https://arxiv.org/abs/2412.06767)
Token length: 1174
Summarized using gpt-4o-mini
Append: [通过合并子优化模型提升通用大模型性能](https://arxiv.org/abs/2412.04144)
append_entries: 2
Finish: 2024-12-10 21:01:01.671351
------------------------------------------------------
Started: 2024-12-11 00:37:38.449753
Existing_entries: 708
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 828
Summarized using gpt-4o-mini
Append: [Turbo3D：超快速文本转3D系统](https://arxiv.org/abs/2412.04470)
append_entries: 1
Finish: 2024-12-11 00:37:44.594826
------------------------------------------------------
Started: 2024-12-11 03:25:58.500124
Existing_entries: 709
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-11 03:25:58.665966
------------------------------------------------------
Started: 2024-12-11 06:11:30.569419
Existing_entries: 709
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 987
Summarized using gpt-4o-mini
Append: [UniReal：统一的图像生成与编辑框架](https://arxiv.org/abs/2412.07774)
Token length: 1109
Summarized using gpt-4o-mini
Append: [推介Granite Guardian模型：提高大型语言模型的风险检测能力](https://arxiv.org/abs/2412.07724)
Token length: 1696
Summarized using gpt-4o-mini
Append: [Moxin 7B：开放源代码的大型语言模型新纪元](https://arxiv.org/abs/2412.06845)
Token length: 1418
Summarized using gpt-4o-mini
Append: [ILLUME：统一的多模态大语言模型研究](https://arxiv.org/abs/2412.06673)
append_entries: 4
Finish: 2024-12-11 06:11:56.209429
------------------------------------------------------
Started: 2024-12-11 09:00:47.103843
Existing_entries: 713
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 789
Summarized using gpt-4o-mini
Append: [DiTFlow：基于扩散转换器的视频运动传递方法](https://arxiv.org/abs/2412.07776)
Token length: 1620
Summarized using gpt-4o-mini
Append: [细粒度视觉属性适应框架的研究进展](https://arxiv.org/abs/2412.07674)
Token length: 1445
Summarized using gpt-4o-mini
Append: [一种新型的隐私保护联邦学习框架：HyperFL](https://arxiv.org/abs/2412.07187)
Token length: 1545
Summarized using gpt-4o-mini
Append: [STIV: 一种简单可扩展的视频生成框架](https://arxiv.org/abs/2412.07730)
Token length: 1466
Summarized using gpt-4o-mini
Append: [DiffSensei: 动态多角色控制的动漫生成框架](https://arxiv.org/abs/2412.07589)
Token length: 1760
Summarized using gpt-4o-mini
Append: [轻量级模型设计：提升5M规模模型性能的创新](https://arxiv.org/abs/2412.06674)
Token length: 1452
Summarized using gpt-4o-mini
Append: [基于3D轨迹的图像到视频生成物体控制方案](https://arxiv.org/abs/2412.07721)
Token length: 1659
Summarized using gpt-4o-mini
Append: [AURORA：增强多模态语言模型的视觉推理能力](https://arxiv.org/abs/2412.03548)
Token length: 1610
Summarized using gpt-4o-mini
Append: [CodeArena：一种评估代码生成模型人类偏好对齐的新基准](https://arxiv.org/abs/2412.05210)
Token length: 1304
Summarized using gpt-4o-mini
Append: [基于扩散模型的抗篡改图像水印方法研究](https://arxiv.org/abs/2412.04653)
append_entries: 10
Finish: 2024-12-11 09:01:44.205910
------------------------------------------------------
Started: 2024-12-11 12:14:01.858617
Existing_entries: 723
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1427
Summarized using gpt-4o-mini
Append: [OmniDocBench：提升文档内容提取的多源基准](https://arxiv.org/abs/2412.07626)
Token length: 1487
Summarized using gpt-4o-mini
Append: [3DTrajMaster：控制多实体3D运动的视频生成方法](https://arxiv.org/abs/2412.07759)
Token length: 1611
Summarized using gpt-4o-mini
Append: [RAPL：一种新的基于偏好的视觉奖励学习方法](https://arxiv.org/abs/2412.04835)
Token length: 1386
Summarized using gpt-4o-mini
Append: [Chimera：提升大规模多模态模型的领域特定能力](https://arxiv.org/abs/2412.05983)
Token length: 1302
Summarized using gpt-4o-mini
Append: [框架表示假说：解读与控制大型语言模型的理论框架](https://arxiv.org/abs/2412.07334)
append_entries: 5
Finish: 2024-12-11 12:14:37.704293
------------------------------------------------------
Started: 2024-12-11 15:01:00.329419
Existing_entries: 728
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-11 15:01:00.530348
------------------------------------------------------
Started: 2024-12-11 18:01:09.014690
Existing_entries: 728
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1901
Summarized using gpt-4o-mini
Append: [基于模块化方法的文本到图像生成改进](https://arxiv.org/abs/2412.06089)
Token length: 1097
Summarized using gpt-4o-mini
Append: [HARP：提升大语言模型性能的高效推理方法](https://arxiv.org/abs/2412.07282)
Token length: 912
Summarized using gpt-4o-mini
Append: [移动优化视频扩散模型MobileVD的设计与实现](https://arxiv.org/abs/2412.07583)
Token length: 949
Summarized using gpt-4o-mini
Append: [移动视频编辑优化方法研究](https://arxiv.org/abs/2412.06578)
Token length: 1134
Summarized using gpt-4o-mini
Append: [LoRA.rar：高效个性化图像生成的新方法](https://arxiv.org/abs/2412.05148)
Token length: 1431
Summarized using gpt-4o-mini
Append: [个性化AI生成反言论的效果与评估](https://arxiv.org/abs/2412.07338)
append_entries: 6
Finish: 2024-12-11 18:01:34.383024
------------------------------------------------------
Started: 2024-12-11 21:00:47.004121
Existing_entries: 734
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1687
Summarized using gpt-4o-mini
Append: [ACDiT：基于自回归和扩散的可调节多模态模型](https://arxiv.org/abs/2412.07720)
append_entries: 1
Finish: 2024-12-11 21:00:55.563394
------------------------------------------------------
Started: 2024-12-12 00:37:20.718318
Existing_entries: 735
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-12 00:37:20.926041
------------------------------------------------------
Started: 2024-12-12 03:26:46.302278
Existing_entries: 735
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-12 03:26:46.555044
------------------------------------------------------
Started: 2024-12-12 06:00:50.170128
Existing_entries: 735
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1574
Summarized using gpt-4o-mini
Append: [3DSRBench：全面评估3D空间推理能力的基准](https://arxiv.org/abs/2412.07825)
Token length: 1156
Summarized using gpt-4o-mini
Append: [构建LAION-SG数据集以提升文本到图像生成的合成能力](https://arxiv.org/abs/2412.08580)
Token length: 1326
Summarized using gpt-4o-mini
Append: [视频扩散模型在多视角一致性生成中的应用研究](https://arxiv.org/abs/2412.07760)
Token length: 1639
Summarized using gpt-4o-mini
Append: [Mogo：一种高效生成连续3D人类运动的新架构](https://arxiv.org/abs/2412.07797)
append_entries: 4
Finish: 2024-12-12 06:01:27.395995
------------------------------------------------------
Started: 2024-12-12 09:00:44.433808
Existing_entries: 739
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-12 09:00:44.624078
------------------------------------------------------
Started: 2024-12-12 12:14:09.090939
Existing_entries: 739
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 931
Summarized using gpt-4o-mini
Append: [FlowEdit：一种无反演的文本驱动图像编辑方法](https://arxiv.org/abs/2412.08629)
Token length: 1176
Summarized using gpt-4o-mini
Append: [MIT-10M: 大规模多语言图像翻译平行语料库](https://arxiv.org/abs/2412.07147)
Token length: 1089
Summarized using gpt-4o-mini
Append: [基于流场注意力机制的可控人像生成](https://arxiv.org/abs/2412.08486)
Token length: 1249
Summarized using gpt-4o-mini
Append: [StreamChat：提升大规模多模态模型对流媒体内容的交互能力](https://arxiv.org/abs/2412.08646)
Token length: 1445
Summarized using gpt-4o-mini
Append: [StyleMaster：高质量视频风格迁移方法](https://arxiv.org/abs/2412.07744)
Token length: 1506
Summarized using gpt-4o-mini
Append: [POINTS1.5：新一代视觉语言模型的创新与应用](https://arxiv.org/abs/2412.08443)
Token length: 1190
Summarized using gpt-4o-mini
Append: [通用密化方法提升高频细节的3D重建](https://arxiv.org/abs/2412.06234)
append_entries: 7
Finish: 2024-12-12 12:14:39.353901
------------------------------------------------------
Started: 2024-12-12 15:00:43.009068
Existing_entries: 746
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1614
Summarized using gpt-4o-mini
Append: [自我完善的数据飞轮：提升语言指导导航性能](https://arxiv.org/abs/2412.08467)
Token length: 1403
Summarized using gpt-4o-mini
Append: [知识感知奇异值适应方法KaSA在大语言模型调优中的应用](https://arxiv.org/abs/2412.06071)
Token length: 1113
Summarized using gpt-4o-mini
Append: [融合文本驱动的风格迁移新策略](https://arxiv.org/abs/2412.08503)
append_entries: 3
Finish: 2024-12-12 15:01:01.433441
------------------------------------------------------
Started: 2024-12-12 18:00:55.558618
Existing_entries: 749
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-12 18:00:55.757056
------------------------------------------------------
Started: 2024-12-12 21:00:49.518338
Existing_entries: 749
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1060
Summarized using gpt-4o-mini
Append: [Track4Gen：一种提高视频生成一致性的空间感知模型](https://arxiv.org/abs/2412.06016)
Token length: 1782
Summarized using gpt-4o-mini
Append: [BrowserGym生态系统：提升Web代理评估与基准测试的统一平台](https://arxiv.org/abs/2412.05467)
Token length: 1078
Summarized using gpt-4o-mini
Append: [一种新型的校准方法减少大型语言模型的幻觉现象](https://arxiv.org/abs/2412.06676)
append_entries: 3
Finish: 2024-12-12 21:01:05.463518
------------------------------------------------------
Started: 2024-12-13 00:37:54.994371
Existing_entries: 752
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-13 00:37:55.160953
------------------------------------------------------
Started: 2024-12-13 03:27:53.319070
Existing_entries: 752
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-13 03:27:53.500060
------------------------------------------------------
Started: 2024-12-13 06:11:32.035082
Existing_entries: 752
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 864
Summarized using gpt-4o-mini
Append: [phi-4语言模型：以数据质量为核心的创新](https://arxiv.org/abs/2412.08905)
Token length: 1831
Summarized using gpt-4o-mini
Append: [WaLLoC：高效的压缩领域学习神经编解码器](https://arxiv.org/abs/2412.09405)
Token length: 1697
Summarized using gpt-4o-mini
Append: [EasyRef: 一种用于扩散模型的多参考图像自适应方法](https://arxiv.org/abs/2412.09618)
Token length: 1489
Summarized using gpt-4o-mini
Append: [提升多模态大语言模型在几何感知中的表现](https://arxiv.org/abs/2412.08737)
Token length: 1156
Summarized using gpt-4o-mini
Append: [构建高质量多语种平行语料库以提升印地语言NMT模型性能](https://arxiv.org/abs/2412.09025)
Token length: 1037
Summarized using gpt-4o-mini
Append: [基于DINOv2的Gaze-LLE框架推广人眼注视目标估计](https://arxiv.org/abs/2412.09586)
Token length: 1408
Summarized using gpt-4o-mini
Append: [Latent语言建模：统一的多模态生成模型](https://arxiv.org/abs/2412.08635)
Token length: 1789
Summarized using gpt-4o-mini
Append: [基于流式感知和推理机制的多模态语言模型框架](https://arxiv.org/abs/2412.09596)
Token length: 1471
Summarized using gpt-4o-mini
Append: [OLA-VLM：优化多模态大语言模型的视觉理解能力](https://arxiv.org/abs/2412.09585)
Token length: 1269
Summarized using gpt-4o-mini
Append: [FreeSplatter：高效的稀疏视图重建框架](https://arxiv.org/abs/2412.09573)
Token length: 1079
Summarized using gpt-4o-mini
Append: [Neural LightRig：基于多重照明条件的物体几何与材料恢复](https://arxiv.org/abs/2412.09593)
Token length: 1141
Summarized using gpt-4o-mini
Append: [基于语言指导的视觉导航任务统一框架研究](https://arxiv.org/abs/2412.05552)
append_entries: 12
Finish: 2024-12-13 06:12:43.402963
------------------------------------------------------
Started: 2024-12-13 09:00:45.632020
Existing_entries: 764
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1042
Summarized using gpt-4o-mini
Append: [基于扩散逆向的新图像超分辨率技术](https://arxiv.org/abs/2412.09013)
Token length: 1061
Summarized using gpt-4o-mini
Append: [LoRACLR：一种高效的多概念图像生成方法](https://arxiv.org/abs/2412.09622)
Token length: 1351
Summarized using gpt-4o-mini
Append: [AgentTrek：基于网络教程的GUI代理高效数据合成方法](https://arxiv.org/abs/2412.09605)
Token length: 1323
Summarized using gpt-4o-mini
Append: [开发高效小型文本生成图像模型SnapGen](https://arxiv.org/abs/2412.09619)
Token length: 1330
Summarized using gpt-4o-mini
Append: [Lyra：提升多模态大语言模型的长语音理解能力](https://arxiv.org/abs/2412.09501)
Token length: 1776
Summarized using gpt-4o-mini
Append: [基于物理信息高斯函数的偏微分方程近似方法](https://arxiv.org/abs/2412.05994)
Token length: 1274
Summarized using gpt-4o-mini
Append: [RuleArena：评估大型语言模型规则推理能力的新基准](https://arxiv.org/abs/2412.08972)
Token length: 1272
Summarized using gpt-4o-mini
Append: [词义消歧的新任务：词义连接](https://arxiv.org/abs/2412.09370)
append_entries: 8
Finish: 2024-12-13 09:01:40.930970
------------------------------------------------------
Started: 2024-12-13 12:00:43.624907
Existing_entries: 772
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-13 12:00:43.878736
------------------------------------------------------
Started: 2024-12-13 15:00:56.758829
Existing_entries: 772
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 610
Summarized using gpt-4o-mini
Append: [评估版权材料对挪威语言模型性能的影响](https://arxiv.org/abs/2412.09460)
Token length: 1145
Summarized using gpt-4o-mini
Append: [系统评价中的LLM评估者：基于生成AI的新方法](https://arxiv.org/abs/2412.09569)
Token length: 1532
Summarized using gpt-4o-mini
Append: [DisPose: 基于稀疏信号的人物图像动画控制](https://arxiv.org/abs/2412.09349)
append_entries: 3
Finish: 2024-12-13 15:01:15.768214
------------------------------------------------------
Started: 2024-12-13 18:10:10.270872
Existing_entries: 775
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-13 18:10:10.520889
------------------------------------------------------
Started: 2024-12-13 21:00:54.221497
Existing_entries: 775
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1915
Summarized using gpt-4o-mini
Append: [ONEBench：开放式基准评估新范式](https://arxiv.org/abs/2412.06745)
append_entries: 1
Finish: 2024-12-13 21:00:59.425196
------------------------------------------------------
Started: 2024-12-14 00:36:15.965039
Existing_entries: 776
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1336
Summarized using gpt-4o-mini
Append: [TarFlow：一种新型的归一化流模型](https://arxiv.org/abs/2412.06329)
Token length: 1310
Summarized using gpt-4o-mini
Append: [VisionArena: 真实用户与视觉语言模型交互的数据集](https://arxiv.org/abs/2412.08687)
append_entries: 2
Finish: 2024-12-14 00:36:28.640332
------------------------------------------------------
Started: 2024-12-14 03:22:04.707442
Existing_entries: 778
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-14 03:22:04.935966
------------------------------------------------------
Started: 2024-12-14 06:00:56.744316
Existing_entries: 778
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-14 06:00:56.928528
------------------------------------------------------
Started: 2024-12-14 09:00:55.336098
Existing_entries: 778
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-14 09:00:55.506478
------------------------------------------------------
Started: 2024-12-14 12:11:49.420881
Existing_entries: 778
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-14 12:11:49.674187
------------------------------------------------------
Started: 2024-12-14 15:00:57.418810
Existing_entries: 778
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-14 15:00:57.626322
------------------------------------------------------
Started: 2024-12-14 18:01:07.306085
Existing_entries: 778
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-14 18:01:07.505154
------------------------------------------------------
Started: 2024-12-14 21:01:06.149331
Existing_entries: 778
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-14 21:01:06.403896
------------------------------------------------------
Started: 2024-12-15 00:41:10.231669
Existing_entries: 778
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-15 00:41:10.401848
------------------------------------------------------
Started: 2024-12-15 03:30:14.045969
Existing_entries: 778
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-15 03:30:14.227134
------------------------------------------------------
Started: 2024-12-15 06:00:44.199907
Existing_entries: 778
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-15 06:00:44.427813
------------------------------------------------------
Started: 2024-12-15 09:01:00.803565
Existing_entries: 778
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-15 09:01:00.976166
------------------------------------------------------
Started: 2024-12-15 12:00:52.090761
Existing_entries: 778
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-15 12:00:52.269728
------------------------------------------------------
Started: 2024-12-15 15:00:51.742928
Existing_entries: 778
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-15 15:00:51.987418
------------------------------------------------------
Started: 2024-12-15 18:00:47.653002
Existing_entries: 778
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-15 18:00:47.840350
------------------------------------------------------
Started: 2024-12-15 21:00:42.911041
Existing_entries: 778
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-15 21:00:43.163866
------------------------------------------------------
Started: 2024-12-16 00:39:32.992534
Existing_entries: 778
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-16 00:39:33.152658
------------------------------------------------------
Started: 2024-12-16 03:30:03.914854
Existing_entries: 778
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1909
Summarized using gpt-4o-mini
Append: [SCBench：针对长上下文的KV缓存优化基准评估](https://arxiv.org/abs/2412.10319)
Token length: 1004
Summarized using gpt-4o-mini
Append: [FireFlow：一种高效的图像反演与编辑方法](https://arxiv.org/abs/2412.07517)
append_entries: 2
Finish: 2024-12-16 03:30:15.004150
------------------------------------------------------
Started: 2024-12-16 06:11:56.946821
Existing_entries: 780
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-16 06:11:57.166836
------------------------------------------------------
Started: 2024-12-16 09:00:47.295536
Existing_entries: 780
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1594
Summarized using gpt-4o-mini
Append: [深入探究大规模多模态模型的视频理解机制](https://arxiv.org/abs/2412.10360)
Token length: 1168
Summarized using gpt-4o-mini
Append: [InstanceCap：基于实例的结构化视频字幕生成框架](https://arxiv.org/abs/2412.09283)
Token length: 1758
Summarized using gpt-4o-mini
Append: [从语言模型到行动模型：人工智能发展的新阶段](https://arxiv.org/abs/2412.10047)
Token length: 1570
Summarized using gpt-4o-mini
Append: [GenEx：基于生成想象的复杂三维世界探索系统](https://arxiv.org/abs/2412.09624)
Token length: 1347
Summarized using gpt-4o-mini
Append: [FreeScale：基于尺度融合的高分辨率视觉生成新范式](https://arxiv.org/abs/2412.09626)
append_entries: 5
Finish: 2024-12-16 09:01:15.077924
------------------------------------------------------
Started: 2024-12-16 12:14:41.189836
Existing_entries: 785
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1244
Summarized using gpt-4o-mini
Append: [SmolTulu-1.7b-Instruct模型的优化与性能分析](https://arxiv.org/abs/2412.08347)
Token length: 1857
Summarized using gpt-4o-mini
Append: [基于语言引导的对抗攻击方法Prompt2Perturb在乳腺癌影像中的应用](https://arxiv.org/abs/2412.09910)
Token length: 1440
Summarized using gpt-4o-mini
Append: [BiMediX2：先进的双语医学大模型](https://arxiv.org/abs/2412.07769)
Token length: 1430
Summarized using gpt-4o-mini
Append: [视觉音乐桥：一种新的多模态音乐生成方法](https://arxiv.org/abs/2412.09428)
append_entries: 4
Finish: 2024-12-16 12:15:04.465456
------------------------------------------------------
Started: 2024-12-16 15:00:45.802799
Existing_entries: 789
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1018
Summarized using gpt-4o-mini
Append: [FluxSpace：基于修正流模型的图像语义编辑方法](https://arxiv.org/abs/2412.09611)
Token length: 1280
Summarized using gpt-4o-mini
Append: [SynerGen-VL：一种简单高效的无编码多模态大型语言模型](https://arxiv.org/abs/2412.09604)
Token length: 1381
Summarized using gpt-4o-mini
Append: [无调优对象插入与主题驱动生成的新方法](https://arxiv.org/abs/2412.08645)
append_entries: 3
Finish: 2024-12-16 15:01:02.272308
------------------------------------------------------
Started: 2024-12-16 18:00:52.198717
Existing_entries: 792
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-16 18:00:52.391472
------------------------------------------------------
Started: 2024-12-16 21:05:37.539145
Existing_entries: 792
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-16 21:05:37.726045
------------------------------------------------------
Started: 2024-12-17 00:37:33.515342
Existing_entries: 792
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1770
Summarized using gpt-4o-mini
Append: [GReaTer：基于梯度的轻量级提示优化技术](https://arxiv.org/abs/2412.09722)
Token length: 1854
Summarized using gpt-4o-mini
Append: [LinGen框架：线性复杂度文本到视频生成的突破](https://arxiv.org/abs/2412.09856)
Token length: 1228
Summarized using gpt-4o-mini
Append: [视觉轨迹提示提升机器人操作的空间-时间意识](https://arxiv.org/abs/2412.10345)
append_entries: 3
Finish: 2024-12-17 00:37:47.672254
------------------------------------------------------
Started: 2024-12-17 03:25:41.773641
Existing_entries: 795
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-17 03:25:42.011845
------------------------------------------------------
Started: 2024-12-17 06:01:11.709900
Existing_entries: 795
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-17 06:01:11.873933
------------------------------------------------------
Started: 2024-12-17 09:00:34.540371
Existing_entries: 795
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1305
Summarized using gpt-4o-mini
Append: [RetroLLM：整合检索与生成的统一框架](https://arxiv.org/abs/2412.11919)
Token length: 1555
Summarized using gpt-4o-mini
Append: [GaussianProperty：无训练框架下的物理性质估计](https://arxiv.org/abs/2412.11258)
append_entries: 2
Finish: 2024-12-17 09:00:45.894296
------------------------------------------------------
Started: 2024-12-17 12:13:58.214136
Existing_entries: 797
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1052
Summarized using gpt-4o-mini
Append: [Byte Latent Transformer：新型字节级LLM架构提升推理效率](https://arxiv.org/abs/2412.09871)
Token length: 1281
Summarized using gpt-4o-mini
Append: [BrushEdit: 基于指令的自由形式图像编辑新方法](https://arxiv.org/abs/2412.10316)
Token length: 1302
Summarized using gpt-4o-mini
Append: [高效动态评估框架提升视觉生成模型评估效率](https://arxiv.org/abs/2412.09645)
Token length: 1374
Summarized using gpt-4o-mini
Append: [基于视频扩散模型的单幅图像高效3D场景重建方法](https://arxiv.org/abs/2412.12091)
Token length: 1493
Summarized using gpt-4o-mini
Append: [ColorFlow：基于扩散模型的图像序列自动上色框架](https://arxiv.org/abs/2412.11815)
Token length: 1182
Summarized using gpt-4o-mini
Append: [引入因果扩散模型：CausalFusion的创新方法](https://arxiv.org/abs/2412.12095)
Token length: 1182
Summarized using gpt-4o-mini
Append: [结合序列变换与状态变换提升基础模型效率](https://arxiv.org/abs/2412.11834)
Token length: 1497
Summarized using gpt-4o-mini
Append: [SPaR：提升语言模型指令遵循能力的新框架](https://arxiv.org/abs/2412.11605)
Token length: 983
Summarized using gpt-4o-mini
Append: [StrandHead：基于文本生成可拆卸3D头发模型的新方法](https://arxiv.org/abs/2412.11586)
Token length: 1421
Summarized using gpt-4o-mini
Append: [小型语言模型在指令演变中的潜力研究](https://arxiv.org/abs/2412.11231)
Token length: 1492
Summarized using gpt-4o-mini
Append: [基于扩散模型的多视角内在分解方法IDArb](https://arxiv.org/abs/2412.12083)
Token length: 1728
Summarized using gpt-4o-mini
Append: [MOVIS：增强多对象新视角合成的结构感知扩散模型](https://arxiv.org/abs/2412.11457)
append_entries: 12
Finish: 2024-12-17 12:15:05.310362
------------------------------------------------------
Started: 2024-12-17 15:00:58.991766
Existing_entries: 809
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-17 15:00:59.161792
------------------------------------------------------
Started: 2024-12-17 18:01:16.670848
Existing_entries: 809
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1369
Summarized using gpt-4o-mini
Append: [SepLLM：一种加速推理的大型语言模型框架](https://arxiv.org/abs/2412.12094)
Token length: 1126
Summarized using gpt-4o-mini
Append: [WHISPER-GPT：融合连续音频表示与离散音频令牌的生成大语言模型](https://arxiv.org/abs/2412.11449)
Token length: 1060
Summarized using gpt-4o-mini
Append: [基于模仿学习的灵活移动操控机器人设计](https://arxiv.org/abs/2412.10447)
Token length: 761
Summarized using gpt-4o-mini
Append: [提升垂直联邦学习中输入数据保护的模型架构转变研究](https://arxiv.org/abs/2412.11689)
append_entries: 4
Finish: 2024-12-17 18:01:31.839562
------------------------------------------------------
Started: 2024-12-17 21:00:58.719518
Existing_entries: 813
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1219
Summarized using gpt-4o-mini
Append: [Emma-X：基于视觉语言模型的机器人控制新方法](https://arxiv.org/abs/2412.11974)
Token length: 1416
Summarized using gpt-4o-mini
Append: [DynamicScaler：高质量全景动态场景视频生成](https://arxiv.org/abs/2412.11100)
Token length: 1862
Summarized using gpt-4o-mini
Append: [大语言模型的发展：开放源代码与闭源模型的较量](https://arxiv.org/abs/2412.12004)
Token length: 495
Summarized using gpt-4o-mini
Append: [Evalica：现代NLP模型评估工具包的介绍与应用](https://arxiv.org/abs/2412.11314)
append_entries: 4
Finish: 2024-12-17 21:01:25.626556
------------------------------------------------------
Started: 2024-12-18 00:36:07.373683
Existing_entries: 817
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1250
Summarized using gpt-4o-mini
Append: [MaxInfoRL：通过最大化信息增益平衡内在与外在探索](https://arxiv.org/abs/2412.12098)
Token length: 1623
Summarized using gpt-4o-mini
Append: [基于扩散模型的视频换脸新框架](https://arxiv.org/abs/2412.11279)
append_entries: 2
Finish: 2024-12-18 00:36:16.875748
------------------------------------------------------
Started: 2024-12-18 03:20:08.836276
Existing_entries: 819
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 844
Summarized using gpt-4o-mini
Append: [通过扰动预训练提高图像生成的保护效果](https://arxiv.org/abs/2412.11423)
Token length: 1316
Summarized using gpt-4o-mini
Append: [强化学习提炼通用策略：提升机器人精确操作能力](https://arxiv.org/abs/2412.09858)
append_entries: 2
Finish: 2024-12-18 03:20:16.300566
------------------------------------------------------
Started: 2024-12-18 06:00:53.833072
Existing_entries: 821
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-18 06:00:54.016706
------------------------------------------------------
Started: 2024-12-18 09:00:44.070292
Existing_entries: 821
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "多维洞察基准：评估大型多模态模型的现实人类需求",
  "keyword": ["大型多模态模型", "人类需求", "多维洞察基准"],
  "short_summary": "提出MDI基准，评估LMM在现实场景中的人类需求适应性。",
  "summary": "大型多模态模型（LMMs）迅速发展，但现有基准未能全面准确评估其在现实场景中满足人类多样需求的能力。为此，提出了多维洞察（MDI）基准，涵盖超过500张图像，涉及六种常见人类生活场景。MDI基准具有两大优势：首先，每张图像配有两类问题——简单问题评估模型对图像的理解，复杂问题考察其分析推理能力。其次，考虑到不同年龄群体在相同场景中的需求和视角差异，基准根据年轻人、中年人和老年人三类人群对问题进行分层设计。这一设计使得能够更细致地评估LMM在满足不同年龄群体偏好和需求方面的能力。MDI基准的数据和评估代码可在https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 277 (char 411). Line: 406.
Append: [Multi-Dimensional Insights: Benchmarking Real-World Personalization in Large Multimodal Models](https://arxiv.org/abs/2412.12606)
Token length: 1342
Summarized using gpt-4o-mini
Append: [新评估指标与动态基准提升大型语言模型推理能力](https://arxiv.org/abs/2412.13147)
append_entries: 2
Finish: 2024-12-18 09:00:54.507890
------------------------------------------------------
Started: 2024-12-18 12:13:31.174980
Existing_entries: 823
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1233
Summarized using gpt-4o-mini
Append: [基于概念编码解码机制的自回归变换器的学习能力研究](https://arxiv.org/abs/2412.12276)
Token length: 1593
Summarized using gpt-4o-mini
Append: [OmniEval：金融领域的自动化检索增强生成基准](https://arxiv.org/abs/2412.13018)
append_entries: 2
Finish: 2024-12-18 12:13:42.954501
------------------------------------------------------
Started: 2024-12-18 15:00:52.887101
Existing_entries: 825
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1459
Summarized using gpt-4o-mini
Append: [MIVE：新一代零-shot多实例视频编辑框架](https://arxiv.org/abs/2412.12877)
append_entries: 1
Finish: 2024-12-18 15:00:57.916341
------------------------------------------------------
Started: 2024-12-18 18:07:47.051264
Existing_entries: 826
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1040
Summarized using gpt-4o-mini
Append: [压缩链式思维框架（CCoT）提升语言模型推理性能](https://arxiv.org/abs/2412.13171)
Token length: 1356
Summarized using gpt-4o-mini
Append: [利用大型语言模型改善软件开发中的异常处理](https://arxiv.org/abs/2412.11713)
Token length: 1543
Summarized using gpt-4o-mini
Append: [提升视觉语言模型加速性能的新策略FEATHER](https://arxiv.org/abs/2412.13180)
Json decode failed:
{
  "title": "通过PAE系统实现自我学习的多能智能代理",
  "short_summary": "本文提出了一种自我发现技能的智能代理学习系统PAE。",
  "summary": "随着基础模型的广泛应用，智能代理的视觉和任务导向能力迅速提高。为了解决技能指定的局限性，本文提出了Proposer-Agent-Evaluator（PAE）系统，使得基础模型能够自主发现和实践技能。PAE依赖于一个上下文感知的任务提议者，利用环境信息（如用户演示或网站名称）提出任务，代理通过具体的操作尝试这些任务，真实世界的执行结果通过基于视觉语言模型的成功评估者进行评估，这一评估结果作为奖励信号，促进代理策略的优化。我们在视觉网页导航任务中验证了该系统的有效性，显示出在真实和自托管网站上的优越性能。此研究首次实现了自主任务提议与强化学习相结合的学习系统，达到最先进的表现，其开源代码可以在网址https:
  "keyword": ["智能代理", "自我学习", "技能发现"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 321 (char 406). Line: 406.
Append: [Proposer-Agent-Evaluator(PAE): Autonomous Skill Discovery For Foundation Model Internet Agents](https://arxiv.org/abs/2412.13194)
Token length: 1433
Summarized using gpt-4o-mini
Append: [VisDoMBench：多文档多模态问答系统的新基准与方法](https://arxiv.org/abs/2412.10704)
Token length: 1320
Summarized using gpt-4o-mini
Append: [对比解码与放弃法：提升大语言模型的可靠性与用户信任](https://arxiv.org/abs/2412.12527)
append_entries: 6
Finish: 2024-12-18 18:08:19.479669
------------------------------------------------------
Started: 2024-12-18 21:00:47.417375
Existing_entries: 832
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-18 21:00:47.599558
------------------------------------------------------
Started: 2024-12-19 00:38:12.674273
Existing_entries: 832
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-19 00:38:12.916546
------------------------------------------------------
Started: 2024-12-19 03:20:58.993482
Existing_entries: 832
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-19 03:20:59.220122
------------------------------------------------------
Started: 2024-12-19 06:00:54.489486
Existing_entries: 832
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-19 06:00:54.707493
------------------------------------------------------
Started: 2024-12-19 09:01:13.804379
Existing_entries: 832
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1000
Summarized using gpt-4o-mini
Append: [基于生成AI的2D动画制作流程优化](https://arxiv.org/abs/2412.14173)
Token length: 1252
Summarized using gpt-4o-mini
Append: [FashionComposer：灵活的服装图像生成框架](https://arxiv.org/abs/2412.14168)
Token length: 958
Summarized using gpt-4o-mini
Append: [基于提示的深度估计新范式：Prompt Depth Anything](https://arxiv.org/abs/2412.14015)
Token length: 1884
Summarized using gpt-4o-mini
Append: [ChatDiT：无调优的交互式视觉生成框架](https://arxiv.org/abs/2412.12571)
Token length: 1422
Summarized using gpt-4o-mini
Append: [RAG-RewardBench：评估检索增强语言模型奖励模型的新基准](https://arxiv.org/abs/2412.13746)
Token length: 962
Summarized using gpt-4o-mini
Append: [图形用户界面代理的综述与未来发展](https://arxiv.org/abs/2412.13501)
Token length: 1179
Summarized using gpt-4o-mini
Append: [VidTok：高性能视频Tokenizer的创新与应用](https://arxiv.org/abs/2412.13061)
Token length: 1706
Summarized using gpt-4o-mini
Append: [AI代理在职场任务自动化中的表现评估](https://arxiv.org/abs/2412.14161)
append_entries: 8
Finish: 2024-12-19 09:01:46.763149
------------------------------------------------------
Started: 2024-12-19 12:01:39.190601
Existing_entries: 840
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1360
Summarized using gpt-4o-mini
Append: [基于CAD-Recode的3D CAD逆向工程方法研究](https://arxiv.org/abs/2412.14042)
Token length: 1050
Summarized using gpt-4o-mini
Append: [AntiLeak-Bench：一种自动化的防泄漏基准框架](https://arxiv.org/abs/2412.13670)
Token length: 1822
Summarized using gpt-4o-mini
Append: [Mix-LN: 一种改进的层归一化技术提升大语言模型训练效果](https://arxiv.org/abs/2412.13795)
Token length: 1048
Summarized using gpt-4o-mini
Append: [AnySat：适应多样化地球观测数据的多模态模型](https://arxiv.org/abs/2412.14123)
Token length: 1319
Summarized using gpt-4o-mini
Append: [Humanoid-X: 大规模人形机器人数据集促进可扩展学习](https://arxiv.org/abs/2412.14172)
Token length: 1647
Summarized using gpt-4o-mini
Append: [Mixture-of-Denoising Experts: 提升模仿学习中的扩散策略](https://arxiv.org/abs/2412.12953)
append_entries: 6
Finish: 2024-12-19 12:02:34.465777
------------------------------------------------------
Started: 2024-12-19 15:00:55.254925
Existing_entries: 846
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-19 15:00:55.454345
------------------------------------------------------
Started: 2024-12-19 18:01:00.888000
Existing_entries: 846
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1319
Summarized using gpt-4o-mini
Append: [LLaVA-UHD v2: 一种提升多模态大语言模型视觉编码的新方法](https://arxiv.org/abs/2412.13871)
append_entries: 1
Finish: 2024-12-19 18:01:10.921420
------------------------------------------------------
Started: 2024-12-19 21:01:12.960701
Existing_entries: 847
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1629
Summarized using gpt-4o-mini
Append: [FastVLM: 高效视觉语言模型优化图像分辨率处理](https://arxiv.org/abs/2412.13303)
Token length: 981
Summarized using gpt-4o-mini
Append: [多模态大型语言模型的视觉空间智能研究](https://arxiv.org/abs/2412.14171)
Token length: 1918
Summarized using gpt-4o-mini
Append: [大型语言模型中的对齐伪装现象研究](https://arxiv.org/abs/2412.14093)
append_entries: 3
Finish: 2024-12-19 21:01:34.214630
------------------------------------------------------
Started: 2024-12-20 00:34:38.509257
Existing_entries: 850
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1466
Summarized using gpt-4o-mini
Append: [SGD-SaI: 一种有效的随机梯度下降方法提升深度学习训练效率](https://arxiv.org/abs/2412.11768)
Token length: 890
Summarized using gpt-4o-mini
Append: [ModernBERT: 优化后的高效编码器模型](https://arxiv.org/abs/2412.13663)
Token length: 1271
Summarized using gpt-4o-mini
Append: [高效自回归视频生成的新方法NOVA](https://arxiv.org/abs/2412.14169)
append_entries: 3
Finish: 2024-12-20 00:34:53.645898
------------------------------------------------------
Started: 2024-12-20 03:13:55.025663
Existing_entries: 853
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-20 03:13:55.261704
------------------------------------------------------
Started: 2024-12-20 06:10:24.987563
Existing_entries: 853
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-20 06:10:25.151681
------------------------------------------------------
Started: 2024-12-20 09:00:48.922363
Existing_entries: 853
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1162
Summarized using gpt-4o-mini
Append: [LeviTor：增强深度维度的图像到视频合成轨迹控制方法](https://arxiv.org/abs/2412.15214)
Token length: 1300
Summarized using gpt-4o-mini
Append: [AceMath：前沿数学模型与奖励模型的创新](https://arxiv.org/abs/2412.15084)
Token length: 1103
Summarized using gpt-4o-mini
Append: [基于视觉专家的图像描述增强方法DCE](https://arxiv.org/abs/2412.14233)
Token length: 1292
Summarized using gpt-4o-mini
Append: [DI-PCG：高效逆向程序内容生成的新方法](https://arxiv.org/abs/2412.15200)
Token length: 1326
Summarized using gpt-4o-mini
Append: [合成数据对语言模型训练的影响及解决方案](https://arxiv.org/abs/2412.14689)
Token length: 1267
Summarized using gpt-4o-mini
Append: [基于可供性概念的图像合成研究](https://arxiv.org/abs/2412.14462)
Token length: 1197
Summarized using gpt-4o-mini
Append: [无监督指令基础图像编辑模型的创新研究](https://arxiv.org/abs/2412.15216)
Token length: 1114
Summarized using gpt-4o-mini
Append: [文本驱动的开放分子生成基准（TOMG-Bench）研究](https://arxiv.org/abs/2412.14642)
Token length: 1797
Summarized using gpt-4o-mini
Append: [CrossFlow: 一种新型跨模态流匹配模型](https://arxiv.org/abs/2412.15213)
Token length: 1910
Summarized using gpt-4o-mini
Append: [Qwen2.5：全面升级的大型语言模型系列](https://arxiv.org/abs/2412.15115)
Token length: 1303
Summarized using gpt-4o-mini
Append: [MegaPairs: 一种新颖的数据合成方法提升多模态检索性能](https://arxiv.org/abs/2412.14475)
Token length: 1298
Summarized using gpt-4o-mini
Append: [LongBench v2：评估大语言模型处理长上下文问题的基准](https://arxiv.org/abs/2412.15204)
Token length: 1443
Summarized using gpt-4o-mini
Append: [AR-MCTS框架：提升多模态大语言模型的推理能力](https://arxiv.org/abs/2412.14835)
append_entries: 13
Finish: 2024-12-20 09:02:05.540692
------------------------------------------------------
Started: 2024-12-20 12:01:01.113344
Existing_entries: 866
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-20 12:01:01.343739
------------------------------------------------------
Started: 2024-12-20 15:01:09.277081
Existing_entries: 866
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "DateLogicQA: 时间推理的基准与评估",
  "short_summary": "本文介绍了DateLogicQA基准，评估大型语言模型在时间推理中的表现。",
  "summary": "本文介绍了DateLogicQA，这是一个包含190个问题的基准，涵盖多种日期格式、时间上下文和推理类型。我们提出了语义完整性指标，以评估词法分析的质量，并分析了两种偏差：影响嵌入的表示层偏差和影响推理输出的逻辑层偏差。研究结果对大型语言模型在时间推理中的能力和局限性进行了全面评估，并突出了准确处理时间数据中的关键挑战。此外，我们的工作相关的GitHub存储库可用，链接为 https:
  "keyword": [
    "时间推理",
    "基准",
    "大型语言模型"
  ]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 209 (char 308). Line: 406.
Append: [DateLogicQA: Benchmarking Temporal Biases in Large Language Models](https://arxiv.org/abs/2412.13377)
Token length: 1043
Summarized using gpt-4o-mini
Append: [Move-in-2D：基于场景图像生成多样化人类动作序列](https://arxiv.org/abs/2412.13185)
append_entries: 2
Finish: 2024-12-20 15:01:17.664291
------------------------------------------------------
Started: 2024-12-20 18:00:58.383215
Existing_entries: 868
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1512
Summarized using gpt-4o-mini
Append: [PixelMan：无反演、高效的一致性对象编辑方法](https://arxiv.org/abs/2412.14283)
append_entries: 1
Finish: 2024-12-20 18:01:02.958207
------------------------------------------------------
Started: 2024-12-20 21:00:46.300681
Existing_entries: 869
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-20 21:00:46.510642
------------------------------------------------------
Started: 2024-12-21 00:33:48.158115
Existing_entries: 869
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-21 00:33:48.322907
------------------------------------------------------
Started: 2024-12-21 03:10:21.994927
Existing_entries: 869
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 956
Summarized using gpt-4o-mini
Append: [AV-Link: 视频与音频生成的统一框架](https://arxiv.org/abs/2412.15191)
append_entries: 1
Finish: 2024-12-21 03:10:27.036106
------------------------------------------------------
Started: 2024-12-21 06:00:55.927144
Existing_entries: 870
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-21 06:00:56.090466
------------------------------------------------------
Started: 2024-12-21 09:00:42.282442
Existing_entries: 870
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-21 09:00:42.473674
------------------------------------------------------
Started: 2024-12-21 12:00:48.726467
Existing_entries: 870
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-21 12:00:48.915818
------------------------------------------------------
Started: 2024-12-21 15:00:49.706432
Existing_entries: 870
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-21 15:00:49.899990
------------------------------------------------------
Started: 2024-12-21 18:00:54.211386
Existing_entries: 870
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-21 18:00:54.402890
------------------------------------------------------
Started: 2024-12-21 21:00:58.825189
Existing_entries: 870
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-21 21:00:59.017181
------------------------------------------------------
Started: 2024-12-22 00:37:52.984522
Existing_entries: 870
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-22 00:37:53.226525
------------------------------------------------------
Started: 2024-12-22 03:16:20.988097
Existing_entries: 870
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-22 03:16:21.240245
------------------------------------------------------
Started: 2024-12-22 06:00:41.584147
Existing_entries: 870
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-22 06:00:41.765935
------------------------------------------------------
Started: 2024-12-22 09:00:50.552423
Existing_entries: 870
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-22 09:00:50.702470
------------------------------------------------------
Started: 2024-12-22 12:01:01.250272
Existing_entries: 870
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-22 12:01:01.470336
------------------------------------------------------
Started: 2024-12-22 15:00:43.386875
Existing_entries: 870
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-22 15:00:43.545662
------------------------------------------------------
Started: 2024-12-22 18:01:04.745554
Existing_entries: 870
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-22 18:01:05.133143
------------------------------------------------------
Started: 2024-12-22 21:00:52.680251
Existing_entries: 870
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-22 21:00:52.920293
------------------------------------------------------
Started: 2024-12-23 00:36:06.207801
Existing_entries: 870
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-23 00:36:06.413081
------------------------------------------------------
Started: 2024-12-23 03:14:28.025599
Existing_entries: 870
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-23 03:14:28.212528
------------------------------------------------------
Started: 2024-12-23 06:11:21.664996
Existing_entries: 870
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1067
Summarized using gpt-4o-mini
Append: [MMAudio：高质量音频合成的新方法](https://arxiv.org/abs/2412.15322)
Token length: 1177
Summarized using gpt-4o-mini
Append: [SCOPE框架：优化长输出生成中的KV缓存](https://arxiv.org/abs/2412.13649)
append_entries: 2
Finish: 2024-12-23 06:11:28.901407
------------------------------------------------------
Started: 2024-12-23 09:01:08.313033
Existing_entries: 872
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1438
Summarized using gpt-4o-mini
Append: [通过离线强化学习提升大型语言模型的多步推理能力](https://arxiv.org/abs/2412.16145)
Token length: 1615
Summarized using gpt-4o-mini
Append: [MixLLM：一种新型混合精度量化方法提升大语言模型性能](https://arxiv.org/abs/2412.14590)
Token length: 1580
Summarized using gpt-4o-mini
Append: [基于清晰局部注意力机制的高效图像生成模型](https://arxiv.org/abs/2412.16112)
Token length: 1377
Summarized using gpt-4o-mini
Append: [提高自回归视觉生成效率的并行化方法](https://arxiv.org/abs/2412.15119)
append_entries: 4
Finish: 2024-12-23 09:01:40.452497
------------------------------------------------------
Started: 2024-12-23 12:13:07.807092
Existing_entries: 876
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1267
Summarized using gpt-4o-mini
Append: [Fietje：面向荷兰语的小型语言模型家族](https://arxiv.org/abs/2412.15450)
append_entries: 1
Finish: 2024-12-23 12:13:13.838785
------------------------------------------------------
Started: 2024-12-23 15:00:57.685434
Existing_entries: 877
Fetching from https://rsshub.app/huggingface/daily-papers
Summarization failed, append the original article
error: 'NoneType' object has no attribute 'group'. Line: 406.
Append: [LLMs Lost in Translation: M-ALERT uncovers Cross-Linguistic Safety Gaps](https://arxiv.org/abs/2412.15035)
Summarization failed, append the original article
error: 'NoneType' object has no attribute 'group'. Line: 406.
Append: [Sequence Matters: Harnessing Video Models in 3D Super-Resolution](https://arxiv.org/abs/2412.11525)
append_entries: 2
Finish: 2024-12-23 15:01:14.169790
------------------------------------------------------
Started: 2024-12-23 18:01:03.273868
Existing_entries: 879
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1361
Summarized using gpt-4o-mini
Append: [基于单幅图像生成高保真3D全身头像的创新研究](https://arxiv.org/abs/2412.14963)
append_entries: 1
Finish: 2024-12-23 18:01:08.986192
------------------------------------------------------
Started: 2024-12-23 21:00:51.725861
Existing_entries: 880
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 980
Summarized using gpt-4o-mini
Append: [多LLM摘要框架的研究与应用](https://arxiv.org/abs/2412.15487)
append_entries: 1
Finish: 2024-12-23 21:00:55.285386
------------------------------------------------------
Started: 2024-12-24 00:34:22.052618
Existing_entries: 881
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 752
Summarized using gpt-4o-mini
Append: [TRecViT：一种新型视频建模架构](https://arxiv.org/abs/2412.14294)
append_entries: 1
Finish: 2024-12-24 00:34:28.599581
------------------------------------------------------
Started: 2024-12-24 03:13:10.864391
Existing_entries: 882
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-24 03:13:11.049792
------------------------------------------------------
Started: 2024-12-24 06:00:57.878882
Existing_entries: 882
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1805
Summarized using gpt-4o-mini
Append: [自我演化训练在多模态推理中的应用与优化](https://arxiv.org/abs/2412.17451)
Token length: 1643
Summarized using gpt-4o-mini
Append: [自我改善框架B-STaR在复杂推理任务中的应用](https://arxiv.org/abs/2412.17256)
Token length: 1218
Summarized using gpt-4o-mini
Append: [RobustFT：一种增强大规模语言模型鲁棒性的新型监督微调框架](https://arxiv.org/abs/2412.14922)
Token length: 1363
Summarized using gpt-4o-mini
Append: [长上下文语言模型中示例选择对ICL性能的影响](https://arxiv.org/abs/2412.16926)
append_entries: 4
Finish: 2024-12-24 06:01:16.190581
------------------------------------------------------
Started: 2024-12-24 09:00:47.969610
Existing_entries: 886
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1316
Summarized using gpt-4o-mini
Append: [基于结果精炼的过程监督：解决复杂编程任务的新方法](https://arxiv.org/abs/2412.15118)
Token length: 1479
Summarized using gpt-4o-mini
Append: [提升大型语言模型推理能力的缓存增强方法](https://arxiv.org/abs/2412.17747)
Token length: 1902
Summarized using gpt-4o-mini
Append: [基于蒸馏解码的自回归模型一键生成方法](https://arxiv.org/abs/2412.17153)
Token length: 1293
Summarized using gpt-4o-mini
Append: [NILE框架：提升LLMs与人类意图对齐的内部一致性优化](https://arxiv.org/abs/2412.16686)
append_entries: 4
Finish: 2024-12-24 09:01:08.135937
------------------------------------------------------
Started: 2024-12-24 12:00:55.779494
Existing_entries: 890
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "Agent-SafetyBench：评估大型语言模型代理安全性的新基准",
  "short_summary": "提出Agent-SafetyBench基准，评估大型语言模型代理的安全性。",
  "summary": "本文介绍了Agent-SafetyBench，这是一种旨在评估大型语言模型(LLM)代理安全性的综合基准。该基准包含349个交互环境和2000个测试案例，针对8类安全风险进行评估，并涵盖10种常见的失败模式。我们对16个流行的LLM代理进行了评估，结果显示没有一个代理的安全评分超过60%，凸显了LLM代理在安全性方面面临的重大挑战。通过量化分析，我们识别出关键失败模式，并总结出现有LLM代理中的两个基本安全缺陷：缺乏稳健性和风险意识。此外，研究发现单靠防御性提示不足以解决这些安全问题，强调了需要更先进、稳健的策略以提升安全性。我们将Agent-SafetyBench发布在https:
  "keyword": [
    "语言模型",
    "安全性评估",
    "代理"
  ]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 310 (char 421). Line: 406.
Append: [Agent-SafetyBench: Evaluating the Safety of LLM Agents](https://arxiv.org/abs/2412.14470)
Token length: 1599
Summarized using gpt-4o-mini
Append: [Friends-MMC：多模态多方会话数据集及关键任务研究](https://arxiv.org/abs/2412.17295)
Token length: 1260
Summarized using gpt-4o-mini
Append: [解析生成式AI在教育中的教学行为注入](https://arxiv.org/abs/2412.16429)
Token length: 1761
Summarized using gpt-4o-mini
Append: [引入DRT-o1：长链思维在神经机器翻译中的应用](https://arxiv.org/abs/2412.17498)
Token length: 1097
Summarized using gpt-4o-mini
Append: [OpenAI o1模型系列的安全性与健壮性研究](https://arxiv.org/abs/2412.16720)
Token length: 1623
Summarized using gpt-4o-mini
Append: [高保真视频变分自编码器的创新与应用](https://arxiv.org/abs/2412.17805)
append_entries: 6
Finish: 2024-12-24 12:01:35.287148
------------------------------------------------------
Started: 2024-12-24 15:00:35.858122
Existing_entries: 896
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 902
Summarized using gpt-4o-mini
Append: [OpenAI的强化微调技术报告：OpenRFT的应用与挑战](https://arxiv.org/abs/2412.16849)
Token length: 1856
Summarized using gpt-4o-mini
Append: [PC Agent：通过人类认知转移提升AI工作能力](https://arxiv.org/abs/2412.17589)
append_entries: 2
Finish: 2024-12-24 15:00:49.977474
------------------------------------------------------
Started: 2024-12-24 18:01:07.972396
Existing_entries: 898
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1518
Summarized using gpt-4o-mini
Append: [ResearchTown: 基于大语言模型的科研社区仿真框架](https://arxiv.org/abs/2412.17767)
append_entries: 1
Finish: 2024-12-24 18:01:14.879207
------------------------------------------------------
Started: 2024-12-24 21:00:47.699650
Existing_entries: 899
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-24 21:00:47.880364
------------------------------------------------------
Started: 2024-12-25 00:33:48.864330
Existing_entries: 899
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-25 00:33:49.122584
------------------------------------------------------
Started: 2024-12-25 03:11:18.960431
Existing_entries: 899
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-25 03:11:19.208556
------------------------------------------------------
Started: 2024-12-25 06:00:48.322790
Existing_entries: 899
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1365
Summarized using gpt-4o-mini
Append: [SKETCH：一种增强检索-生成系统的新方法](https://arxiv.org/abs/2412.15443)
append_entries: 1
Finish: 2024-12-25 06:00:53.188353
------------------------------------------------------
Started: 2024-12-25 09:01:04.115297
Existing_entries: 900
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1582
Summarized using gpt-4o-mini
Append: [DiTCtrl：基于MM-DiT架构的无训练多提示视频生成方法](https://arxiv.org/abs/2412.18597)
Token length: 1364
Summarized using gpt-4o-mini
Append: [基于傅里叶位置嵌入的语言模型上下文长度扩展方法](https://arxiv.org/abs/2412.17739)
Token length: 1113
Summarized using gpt-4o-mini
Append: [ReMoE：可微分的混合专家模型架构](https://arxiv.org/abs/2412.14711)
Token length: 978
Summarized using gpt-4o-mini
Append: [DepthLab：基于图像扩散的深度数据填补模型](https://arxiv.org/abs/2412.18153)
append_entries: 4
Finish: 2024-12-25 09:01:38.679236
------------------------------------------------------
Started: 2024-12-25 12:12:07.576407
Existing_entries: 904
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 790
Summarized using gpt-4o-mini
Append: [评估策略影响LLM挑战难度的研究](https://arxiv.org/abs/2412.17758)
Token length: 1368
Summarized using gpt-4o-mini
Append: [3DGraphLLM：基于3D场景图的语言模型增强方法](https://arxiv.org/abs/2412.18450)
Token length: 1488
Summarized using gpt-4o-mini
Append: [PartGen：基于多视图扩散模型的3D对象分部生成方法](https://arxiv.org/abs/2412.18608)
append_entries: 3
Finish: 2024-12-25 12:12:26.301472
------------------------------------------------------
Started: 2024-12-25 15:00:54.756842
Existing_entries: 907
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-25 15:00:54.985527
------------------------------------------------------
Started: 2024-12-25 18:01:03.864248
Existing_entries: 907
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1244
Summarized using gpt-4o-mini
Append: [LE-MCTS：一种基于蒙特卡洛树搜索的语言模型集成框架](https://arxiv.org/abs/2412.15797)
append_entries: 1
Finish: 2024-12-25 18:01:09.263414
------------------------------------------------------
Started: 2024-12-25 21:00:45.494234
Existing_entries: 908
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1268
Summarized using gpt-4o-mini
Append: [MotiF：提升文本引导图像动画的视频生成方法](https://arxiv.org/abs/2412.16153)
append_entries: 1
Finish: 2024-12-25 21:00:49.701263
------------------------------------------------------
Started: 2024-12-26 00:33:54.395077
Existing_entries: 909
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1762
Summarized using gpt-4o-mini
Append: [多模态数据集审计：训练数据的规模、来源与限制](https://arxiv.org/abs/2412.17847)
append_entries: 1
Finish: 2024-12-26 00:34:00.794089
------------------------------------------------------
Started: 2024-12-26 03:12:54.658896
Existing_entries: 910
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-26 03:12:54.866790
------------------------------------------------------
Started: 2024-12-26 06:10:24.204342
Existing_entries: 910
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1017
Summarized using gpt-4o-mini
Append: [基于令牌预算的语言模型推理框架](https://arxiv.org/abs/2412.18547)
append_entries: 1
Finish: 2024-12-26 06:10:27.579516
------------------------------------------------------
Started: 2024-12-26 09:00:34.829259
Existing_entries: 911
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-26 09:00:35.053692
------------------------------------------------------
Started: 2024-12-26 12:00:51.843262
Existing_entries: 911
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-26 12:00:55.502814
------------------------------------------------------
Started: 2024-12-26 15:00:37.604934
Existing_entries: 911
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-26 15:00:37.827191
------------------------------------------------------
Started: 2024-12-26 18:00:58.132306
Existing_entries: 911
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1919
Summarized using gpt-4o-mini
Append: [PepTune: 多目标离散扩散模型在治疗肽优化中的应用](https://arxiv.org/abs/2412.17780)
append_entries: 1
Finish: 2024-12-26 18:01:05.119260
------------------------------------------------------
Started: 2024-12-26 21:00:47.107117
Existing_entries: 912
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1175
Summarized using gpt-4o-mini
Append: [WavePulse：实时分析电台直播内容的框架](https://arxiv.org/abs/2412.17998)
Token length: 1531
Summarized using gpt-4o-mini
Append: [高效无编码器视频语言理解方法的提出](https://arxiv.org/abs/2412.18609)
Token length: 1184
Summarized using gpt-4o-mini
Append: [集体蒙特卡罗树搜索：一种多模态学习模型的推理与学习方法](https://arxiv.org/abs/2412.18319)
append_entries: 3
Finish: 2024-12-26 21:01:09.326479
------------------------------------------------------
Started: 2024-12-27 00:34:05.767028
Existing_entries: 915
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1139
Summarized using gpt-4o-mini
Append: [强化同步语音转文字翻译研究的必要性与未来方向](https://arxiv.org/abs/2412.18495)
append_entries: 1
Finish: 2024-12-27 00:34:12.232292
------------------------------------------------------
Started: 2024-12-27 03:12:27.918880
Existing_entries: 916
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-27 03:12:28.130945
------------------------------------------------------
Started: 2024-12-27 06:00:51.086544
Existing_entries: 916
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1267
Summarized using gpt-4o-mini
Append: [VidTwin：高效视频自动编码器的新方法](https://arxiv.org/abs/2412.17726)
append_entries: 1
Finish: 2024-12-27 06:00:56.214619
------------------------------------------------------
Started: 2024-12-27 09:00:56.580608
Existing_entries: 917
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1059
Summarized using gpt-4o-mini
Append: [YuLan-Mini：高效预训练的大型语言模型](https://arxiv.org/abs/2412.17743)
append_entries: 1
Finish: 2024-12-27 09:01:00.881753
------------------------------------------------------
Started: 2024-12-27 12:00:53.165466
Existing_entries: 918
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1086
Summarized using gpt-4o-mini
Append: [基于要旨的上下文压缩方法在长文本处理中的应用研究](https://arxiv.org/abs/2412.17483)
append_entries: 1
Finish: 2024-12-27 12:01:00.325040
------------------------------------------------------
Started: 2024-12-27 15:00:42.123425
Existing_entries: 919
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1607
Summarized using gpt-4o-mini
Append: [Molar: 多模态大语言模型在序列推荐中的应用](https://arxiv.org/abs/2412.18176)
Token length: 1895
Summarized using gpt-4o-mini
Append: [MMFactory：面向复杂视觉任务的通用解决方案框架](https://arxiv.org/abs/2412.18072)
append_entries: 2
Finish: 2024-12-27 15:00:52.606311
------------------------------------------------------
Started: 2024-12-27 18:01:13.644065
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-27 18:01:13.817051
------------------------------------------------------
Started: 2024-12-27 21:00:37.374899
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-27 21:00:37.533634
------------------------------------------------------
Started: 2024-12-28 00:33:23.279065
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-28 00:33:23.515976
------------------------------------------------------
Started: 2024-12-28 03:10:11.876451
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-28 03:10:12.060821
------------------------------------------------------
Started: 2024-12-28 06:00:45.296717
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-28 06:00:45.527706
------------------------------------------------------
Started: 2024-12-28 09:01:04.226325
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-28 09:01:04.392593
------------------------------------------------------
Started: 2024-12-28 12:01:01.820971
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-28 12:01:02.029603
------------------------------------------------------
Started: 2024-12-28 15:00:43.407123
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-28 15:00:43.554734
------------------------------------------------------
Started: 2024-12-28 18:00:38.361326
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-28 18:00:38.533347
------------------------------------------------------
Started: 2024-12-28 21:00:45.656835
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-28 21:00:45.837211
------------------------------------------------------
Started: 2024-12-29 00:38:04.995478
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-29 00:38:05.187360
------------------------------------------------------
Started: 2024-12-29 03:17:59.061021
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-29 03:17:59.250417
------------------------------------------------------
Started: 2024-12-29 06:01:01.050339
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-29 06:01:01.271852
------------------------------------------------------
Started: 2024-12-29 09:00:48.932807
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-29 09:00:49.094302
------------------------------------------------------
Started: 2024-12-29 12:10:54.229806
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-29 12:10:54.452985
------------------------------------------------------
Started: 2024-12-29 15:00:42.852055
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-29 15:00:43.015273
------------------------------------------------------
Started: 2024-12-29 18:01:11.787924
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-29 18:01:12.092299
------------------------------------------------------
Started: 2024-12-29 21:00:39.367014
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-29 21:00:39.577131
------------------------------------------------------
Started: 2024-12-30 00:36:06.281385
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-30 00:36:06.515705
------------------------------------------------------
Started: 2024-12-30 03:15:10.866525
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-30 03:15:11.075331
------------------------------------------------------
Started: 2024-12-30 06:00:44.805579
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-30 06:00:44.937402
------------------------------------------------------
Started: 2024-12-30 09:01:07.108654
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1587
Summarized using gpt-4o-mini
Append: [SuperDiff: 高效组合预训练扩散模型的新方法](https://arxiv.org/abs/2412.17762)
Token length: 1097
Summarized using gpt-4o-mini
Append: [SBSFigures：一种用于图形问答的逐步合成数据集](https://arxiv.org/abs/2412.17606)
Token length: 1359
Summarized using gpt-4o-mini
Append: [基于视频扩散模型的零-shot 定制视频生成框架](https://arxiv.org/abs/2412.19645)
Token length: 1417
Summarized using gpt-4o-mini
Append: [任务偏好优化：提升多模态大语言模型的视觉理解能力](https://arxiv.org/abs/2412.19326)
Token length: 1491
Summarized using gpt-4o-mini
Append: [基于层次设计原则的自动图形设计组合方法LaDeCo](https://arxiv.org/abs/2412.19712)
Token length: 1235
Summarized using gpt-4o-mini
Append: [HuatuoGPT-o1：用于复杂推理的医学大语言模型](https://arxiv.org/abs/2412.18925)
Token length: 1236
Summarized using gpt-4o-mini
Append: [Orient Anything：单图像物体方向估计的创新模型](https://arxiv.org/abs/2412.18605)
append_entries: 7
Finish: 2024-12-30 09:01:49.992582
------------------------------------------------------
Started: 2024-12-30 12:12:44.979612
Existing_entries: 928
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 913
Summarized using gpt-4o-mini
Append: [提升大型语言模型下游任务表现的安全方法](https://arxiv.org/abs/2412.19512)
append_entries: 1
Finish: 2024-12-30 12:12:49.535057
------------------------------------------------------
Started: 2024-12-30 15:00:55.349327
Existing_entries: 929
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1148
Summarized using gpt-4o-mini
Append: [多模态学习中的下一个令牌预测框架综述](https://arxiv.org/abs/2412.18619)
append_entries: 1
Finish: 2024-12-30 15:01:00.593695
------------------------------------------------------
Started: 2024-12-30 18:00:57.974743
Existing_entries: 930
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 791
Summarized using gpt-4o-mini
Append: [1.58-bit FLUX：高效的文本到图像生成模型量化方法](https://arxiv.org/abs/2412.18653)
append_entries: 1
Finish: 2024-12-30 18:01:04.147482
------------------------------------------------------
Started: 2024-12-30 21:01:03.343695
Existing_entries: 931
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1307
Summarized using gpt-4o-mini
Append: [提高大型语言模型检索效率的属性图视图研究](https://arxiv.org/abs/2412.18702)
append_entries: 1
Finish: 2024-12-30 21:01:09.787035
------------------------------------------------------
Started: 2024-12-31 00:34:05.488050
Existing_entries: 932
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-31 00:34:05.671017
------------------------------------------------------
Started: 2024-12-31 03:11:37.410525
Existing_entries: 932
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-31 03:11:37.569921
------------------------------------------------------
Started: 2024-12-31 06:00:46.049188
Existing_entries: 932
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-31 06:00:46.236989
------------------------------------------------------
Started: 2024-12-31 09:00:37.637147
Existing_entries: 932
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1409
Summarized using gpt-4o-mini
Append: [自调用代码生成评估新任务与基准的发展](https://arxiv.org/abs/2412.21199)
Token length: 1351
Summarized using gpt-4o-mini
Append: [基于文本提示的4D生成与3D对象动画方法](https://arxiv.org/abs/2412.20422)
Token length: 832
Summarized using gpt-4o-mini
Append: [SWE-Gym: 软件工程代理训练环境的首次发布](https://arxiv.org/abs/2412.21139)
Token length: 1359
Summarized using gpt-4o-mini
Append: [通过解释性指令促进计算机视觉中的零-shot任务泛化](https://arxiv.org/abs/2412.18525)
Token length: 1279
Summarized using gpt-4o-mini
Append: [Dynasor：优化大型语言模型推理查询的动态计算系统](https://arxiv.org/abs/2412.20993)
Token length: 890
Summarized using gpt-4o-mini
Append: [TangoFlux：高效的文本到音频生成模型](https://arxiv.org/abs/2412.21037)
Json decode failed:
{
  "title": "OneKE：基于架构的知识提取系统",
  "keyword": ["知识提取", "多领域", "架构设计"],
  "short_summary": "OneKE是一个能够从网络和PDF书籍提取知识的系统。",
  "summary": "OneKE是一种经过容器化的架构引导知识提取系统，能够从网络和原始PDF书籍中提取知识，支持多个领域（如科学、新闻等）。本系统设计了多个代理和可配置知识库，帮助优化不同的提取场景。代理各自承担不同角色，而可配置知识库则优化架构配置、错误案例调试与修正，显著提高系统性能。通过在基准数据集上的实证评估，OneKE展示了其有效性，并通过案例研究展示了其在多领域任务中的适应能力，显示其广泛应用的潜力。此外，相关代码已经开源，访问链接为：https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 237 (char 358). Line: 406.
Append: [OneKE: A Dockerized Schema-Guided LLM Agent-based Knowledge Extraction System](https://arxiv.org/abs/2412.20005)
Json decode failed:
{
  "title": "多模态大型语言模型在医疗图像理解中的应用研究",
  "keyword": ["多模态语言模型", "医疗图像", "组合泛化"],
  "short_summary": "探讨多模态大型语言模型在医疗领域的组合泛化能力及数据集选择。",
  "summary": "多模态大型语言模型（MLLMs）在医疗领域展现出巨大的潜力，但在某些医疗领域的数据不足限制了其能力。本文研究了MLLMs如何通过组合泛化（CG）来理解新颖的医学图像，以指导数据集选择和多任务训练的优化。通过组建106个医学数据集形成Med-MAT，实验结果表明MLLMs能够利用CG理解未见过的医学图像，并且CG是多任务训练中观察到的一项主要泛化驱动因素。此外，研究还表明CG可以有效支持数据有限的数据集，并在不同基础架构上提供一致的表现，展现了其灵活性和广泛适用性。Med-MAT已公开供研究使用，网址为 https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 275 (char 408). Line: 406.
Append: [On the Compositional Generalization of Multimodal LLMs for Medical Imaging](https://arxiv.org/abs/2412.20070)
Token length: 915
Summarized using gpt-4o-mini
Append: [Edicho：基于扩散模型的无训练一致性图片编辑](https://arxiv.org/abs/2412.21079)
append_entries: 9
Finish: 2024-12-31 09:01:22.518143
------------------------------------------------------
Started: 2024-12-31 12:12:29.598978
Existing_entries: 941
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1793
Summarized using gpt-4o-mini
Append: [高效的语言适应：学习嵌入传播（LEP）方法的提出](https://arxiv.org/abs/2412.21140)
append_entries: 1
Finish: 2024-12-31 12:12:34.662149
------------------------------------------------------
Started: 2024-12-31 15:00:54.600302
Existing_entries: 942
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1128
Summarized using gpt-4o-mini
Append: [提升模型效率：应对推理中的过度思考问题](https://arxiv.org/abs/2412.21187)
Token length: 1418
Summarized using gpt-4o-mini
Append: [慢感知：提升视觉推理能力的新方法](https://arxiv.org/abs/2412.20631)
Token length: 1198
Summarized using gpt-4o-mini
Append: [PERSE：个性化可动画生成头像的方法](https://arxiv.org/abs/2412.21206)
append_entries: 3
Finish: 2024-12-31 15:01:17.550967
------------------------------------------------------
Started: 2024-12-31 18:00:46.800232
Existing_entries: 945
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-31 18:00:47.022551
------------------------------------------------------
Started: 2024-12-31 21:00:59.394590
Existing_entries: 945
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-31 21:00:59.570153
------------------------------------------------------
Started: 2025-01-01 00:38:30.952403
Existing_entries: 945
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-01 00:38:31.129036
------------------------------------------------------
Started: 2025-01-01 03:19:56.622511
Existing_entries: 945
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-01 03:19:56.864011
------------------------------------------------------
Started: 2025-01-01 06:00:52.290615
Existing_entries: 945
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-01 06:00:52.452764
------------------------------------------------------
Started: 2025-01-01 09:01:00.840982
Existing_entries: 945
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-01 09:01:01.076576
------------------------------------------------------
Started: 2025-01-01 12:00:45.759860
Existing_entries: 945
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-01 12:00:45.956974
------------------------------------------------------
Started: 2025-01-01 15:00:47.810119
Existing_entries: 945
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-01 15:00:47.979995
------------------------------------------------------
Started: 2025-01-01 18:00:43.221133
Existing_entries: 945
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-01 18:00:43.465241
------------------------------------------------------
Started: 2025-01-01 21:00:43.241458
Existing_entries: 945
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-01 21:00:43.429824
------------------------------------------------------
Started: 2025-01-02 00:33:51.681362
Existing_entries: 945
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-02 00:33:51.898179
------------------------------------------------------
Started: 2025-01-02 03:11:33.844186
Existing_entries: 945
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-02 03:11:34.074443
------------------------------------------------------
Started: 2025-01-02 06:00:47.782217
Existing_entries: 945
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-02 06:00:48.055811
------------------------------------------------------
Started: 2025-01-02 09:00:37.336341
Existing_entries: 945
Fetching from https://rsshub.app/huggingface/daily-papers
Summarization failed, append the original article
error: 'NoneType' object has no attribute 'group'. Line: 406.
Append: [OS-Genesis: Automating GUI Agent Trajectory Construction via Reverse Task Synthesis](https://arxiv.org/abs/2412.19723)
Summarization failed, append the original article
error: 'NoneType' object has no attribute 'group'. Line: 406.
Append: [Xmodel-2 Technical Report](https://arxiv.org/abs/2412.19638)
append_entries: 2
Finish: 2025-01-02 09:00:47.031126
------------------------------------------------------
Started: 2025-01-02 12:00:42.383428
Existing_entries: 947
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-02 12:00:42.595072
------------------------------------------------------
Started: 2025-01-02 15:00:40.720333
Existing_entries: 947
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-02 15:00:40.877897
------------------------------------------------------
Started: 2025-01-02 18:01:04.684159
Existing_entries: 947
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 876
Summarized using gpt-4o-mini
Append: [HunyuanProver：基于Hunyuan 7B的交互式定理证明模型](https://arxiv.org/abs/2412.20735)
append_entries: 1
Finish: 2025-01-02 18:01:11.407019
------------------------------------------------------
Started: 2025-01-02 21:00:36.318929
Existing_entries: 948
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-02 21:00:36.461348
------------------------------------------------------
Started: 2025-01-03 00:34:37.810327
Existing_entries: 948
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-03 00:34:38.099809
------------------------------------------------------
Started: 2025-01-03 03:12:55.476422
Existing_entries: 948
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1165
Summarized using gpt-4o-mini
Append: [多视觉传感器感知与推理基准的创新研究](https://arxiv.org/abs/2412.20750)
Token length: 1467
Summarized using gpt-4o-mini
Append: [基于VMix适配器的扩散模型美学提升研究](https://arxiv.org/abs/2412.20800)
append_entries: 2
Finish: 2025-01-03 03:13:05.447857
------------------------------------------------------
Started: 2025-01-03 06:00:58.658716
Existing_entries: 950
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1704
Summarized using gpt-4o-mini
Append: [基于半监督学习的细粒度动作识别方法SeFAR](https://arxiv.org/abs/2501.01245)
Token length: 1569
Summarized using gpt-4o-mini
Append: [提升视觉语言模型预训练效果的多模态教材语料库](https://arxiv.org/abs/2501.00958)
Token length: 1793
Summarized using gpt-4o-mini
Append: [CodeElo：一种新颖的代码生成基准测试评估LLMs能力](https://arxiv.org/abs/2501.01257)
Summarization failed, append the original article
error: 'NoneType' object has no attribute 'group'. Line: 406.
Append: [VideoRefer Suite: Advancing Spatial-Temporal Object Understanding with Video LLM](https://arxiv.org/abs/2501.00599)
Token length: 1362
Summarized using gpt-4o-mini
Append: [通过增强单元测试提升语言模型在代码生成中的表现](https://arxiv.org/abs/2501.01054)
Token length: 1385
Summarized using gpt-4o-mini
Append: [VideoAnydoor：高保真视频对象插入框架](https://arxiv.org/abs/2501.01427)
Token length: 1288
Summarized using gpt-4o-mini
Append: [推出 Android Agent Arena：评估移动 GUI 代理的新平台](https://arxiv.org/abs/2501.01149)
Token length: 1835
Summarized using gpt-4o-mini
Append: [基于多模态大语言模型的零样本图像安全判断研究](https://arxiv.org/abs/2501.00192)
Token length: 1670
Summarized using gpt-4o-mini
Append: [利用VA-VAE提升潜在扩散模型的生成效率和图像质量](https://arxiv.org/abs/2501.01423)
Token length: 1016
Summarized using gpt-4o-mini
Append: [Program-driven Self-Correction for Large Language Models](https://arxiv.org/abs/2501.01264)
append_entries: 10
Finish: 2025-01-03 06:03:25.076176
------------------------------------------------------
Started: 2025-01-03 09:00:44.287998
Existing_entries: 960
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1110
Summarized using gpt-4o-mini
Append: [SeedVR：一种新型扩散变换器用于视频恢复](https://arxiv.org/abs/2501.01320)
Token length: 1910
Summarized using gpt-4o-mini
Append: [MapEval：评估基础模型在地图推理中的能力](https://arxiv.org/abs/2501.00316)
Token length: 1435
Summarized using gpt-4o-mini
Append: [MapQaTor：提升地图问答数据集创建的便捷性](https://arxiv.org/abs/2412.21015)
Json decode failed:
{
  "title": "结构状态空间模型的局限性与偏极化解决方案",
  "keyword": ["状态空间模型", "偏见", "记忆"],
  "short_summary": "本文探讨了状态空间模型的偏见及其解决方案。",
  "summary": "结构状态空间模型（SSMs）作为变换器的替代方案，尽管在捕捉长序列依赖性方面表现出色，但其固有的较强近期偏见限制了模型对远程信息的回忆能力并引发鲁棒性问题。通过实证研究发现，更深的SSMs结构能够促进对长上下文的学习，但理论分析表明，随着深度增加，模型表现出不可避免的过平滑趋势。为解决近期偏见与过平滑之间的基本困境，本文提出对状态转换矩阵的两个通道进行极化，分别设置为零和一。实验表明，该极化技术可有效提升长距离标记的回忆准确率，并使SSMs能够更好地利用深层架构。所有源代码已在https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 262 (char 379). Line: 406.
Append: [Understanding and Mitigating Bottlenecks of State Space Models through the Lens of Recency and Over-smoothing](https://arxiv.org/abs/2501.00658)
append_entries: 4
Finish: 2025-01-03 09:01:08.701990
------------------------------------------------------
Started: 2025-01-03 12:00:51.727184
Existing_entries: 964
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-03 12:00:51.973998
------------------------------------------------------
Started: 2025-01-03 15:01:08.898579
Existing_entries: 964
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1296
Summarized using gpt-4o-mini
Append: [TAPE：一种改进的动态位置编码框架](https://arxiv.org/abs/2501.00712)
Token length: 1683
Summarized using gpt-4o-mini
Append: [LTX-Video：高效的变压器基础视频生成模型](https://arxiv.org/abs/2501.00103)
append_entries: 2
Finish: 2025-01-03 15:01:16.194917
------------------------------------------------------
Started: 2025-01-03 18:00:42.671255
Existing_entries: 966
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1193
Summarized using gpt-4o-mini
Append: [Nested Attention机制在个性化文本到图像生成中的应用](https://arxiv.org/abs/2501.01407)
Token length: 1667
Summarized using gpt-4o-mini
Append: [基于人口特征的时间序列生成模型PaD-TS](https://arxiv.org/abs/2501.00910)
append_entries: 2
Finish: 2025-01-03 18:00:49.905324
------------------------------------------------------
Started: 2025-01-03 21:00:44.463372
Existing_entries: 968
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1423
Summarized using gpt-4o-mini
Append: [MERV：多编码器视频表示方法提升视频理解能力](https://arxiv.org/abs/2501.01426)
append_entries: 1
Finish: 2025-01-03 21:00:50.252341
------------------------------------------------------
Started: 2025-01-04 00:33:41.271432
Existing_entries: 969
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-04 00:33:41.537820
------------------------------------------------------
Started: 2025-01-04 03:10:34.875959
Existing_entries: 969
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-04 03:10:35.086338
------------------------------------------------------
Started: 2025-01-04 06:01:01.490747
Existing_entries: 969
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-04 06:01:01.699245
------------------------------------------------------
Started: 2025-01-04 09:00:31.484020
Existing_entries: 969
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-04 09:00:31.755006
------------------------------------------------------
Started: 2025-01-04 12:01:00.805660
Existing_entries: 969
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-04 12:01:00.967114
------------------------------------------------------
Started: 2025-01-04 15:00:50.051193
Existing_entries: 969
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-04 15:00:50.241720
------------------------------------------------------
Started: 2025-01-04 18:00:46.356332
Existing_entries: 969
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-04 18:00:46.581572
------------------------------------------------------
Started: 2025-01-04 21:01:02.031167
Existing_entries: 969
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-04 21:01:02.285620
------------------------------------------------------
Started: 2025-01-05 00:38:01.206930
Existing_entries: 969
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-05 00:38:01.410041
------------------------------------------------------
Started: 2025-01-05 03:16:38.148679
Existing_entries: 969
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-05 03:16:38.478480
------------------------------------------------------
Started: 2025-01-05 06:01:06.104953
Existing_entries: 969
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-05 06:01:06.302995
------------------------------------------------------
Started: 2025-01-05 09:00:38.883131
Existing_entries: 969
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-05 09:00:39.124160
------------------------------------------------------
Started: 2025-01-05 12:00:50.462123
Existing_entries: 969
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-05 12:00:50.706316
------------------------------------------------------
Started: 2025-01-05 15:00:57.108235
Existing_entries: 969
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-05 15:00:57.276454
------------------------------------------------------
Started: 2025-01-05 18:01:00.483308
Existing_entries: 969
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-05 18:01:00.732957
------------------------------------------------------
Started: 2025-01-05 21:00:45.524740
Existing_entries: 969
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-05 21:00:45.853785
------------------------------------------------------
Started: 2025-01-06 00:36:37.720604
Existing_entries: 969
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-06 00:36:37.939975
------------------------------------------------------
Started: 2025-01-06 03:16:49.413001
Existing_entries: 969
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-06 03:16:49.623096
------------------------------------------------------
Started: 2025-01-06 06:00:45.757944
Existing_entries: 969
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-06 06:00:45.954189
------------------------------------------------------
Started: 2025-01-06 09:00:36.578391
Existing_entries: 969
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1017
Summarized using gpt-4o-mini
Append: [基于人类偏好的视觉生成模型对齐策略](https://arxiv.org/abs/2412.21059)
Token length: 1920
Summarized using gpt-4o-mini
Append: [BoxingGym：评估LLM科学代理的实验设计与模型发现能力的基准](https://arxiv.org/abs/2501.01540)
Token length: 1157
Summarized using gpt-4o-mini
Append: [基于序列表示的图生成预训练变换器模型G2PT研究](https://arxiv.org/abs/2501.01073)
Token length: 1353
Summarized using gpt-4o-mini
Append: [LUSIFER：一种无监督的多语言嵌入模型](https://arxiv.org/abs/2501.00874)
Token length: 1591
Summarized using gpt-4o-mini
Append: [EnerVerse：未来空间生成的综合框架](https://arxiv.org/abs/2501.01895)
Token length: 1114
Summarized using gpt-4o-mini
Append: [提升多模态对话系统的视觉与语音交互能力](https://arxiv.org/abs/2501.01957)
Token length: 1332
Summarized using gpt-4o-mini
Append: [Virgo：多模态大语言模型的慢思维推理系统](https://arxiv.org/abs/2501.01904)
append_entries: 7
Finish: 2025-01-06 09:01:15.815864
------------------------------------------------------
Started: 2025-01-06 12:13:15.665464
Existing_entries: 976
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-06 12:13:15.897534
------------------------------------------------------
Started: 2025-01-06 15:00:59.105596
Existing_entries: 976
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1149
Summarized using gpt-4o-mini
Append: [基于段落级直接偏好优化的多轮社交智能提升](https://arxiv.org/abs/2501.01821)
append_entries: 1
Finish: 2025-01-06 15:01:05.186585
------------------------------------------------------
Started: 2025-01-06 18:09:46.340250
Existing_entries: 977
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-06 18:09:46.587991
------------------------------------------------------
Started: 2025-01-06 21:00:42.436395
Existing_entries: 977
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-06 21:00:42.589944
------------------------------------------------------
Started: 2025-01-07 00:34:56.344799
Existing_entries: 977
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-07 00:34:56.555358
------------------------------------------------------
Started: 2025-01-07 03:14:56.921091
Existing_entries: 977
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1118
Summarized using gpt-4o-mini
Append: [TransPixar：一种用于生成RGBA视频的新方法](https://arxiv.org/abs/2501.03006)
append_entries: 1
Finish: 2025-01-07 03:15:02.661638
------------------------------------------------------
Started: 2025-01-07 06:10:35.060139
Existing_entries: 978
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-07 06:10:35.279849
------------------------------------------------------
Started: 2025-01-07 09:00:52.102528
Existing_entries: 978
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1552
Summarized using gpt-4o-mini
Append: [BoostStep：提升大型语言模型数学推理质量的新方法](https://arxiv.org/abs/2501.03226)
Token length: 1799
Summarized using gpt-4o-mini
Append: [Dispider：实时视频LLM交互的新范式](https://arxiv.org/abs/2501.03218)
Token length: 1712
Summarized using gpt-4o-mini
Append: [基于文本描述的静态图像到视频生成新框架](https://arxiv.org/abs/2501.03059)
Token length: 1770
Summarized using gpt-4o-mini
Append: [GS-DiT：提升4D视频生成的新框架](https://arxiv.org/abs/2501.02690)
Token length: 1760
Summarized using gpt-4o-mini
Append: [Samba ASR：基于Mamba架构的先进自动语音识别模型](https://arxiv.org/abs/2501.02832)
Token length: 1211
Summarized using gpt-4o-mini
Append: [Auto-RT: 强化学习框架提升大型语言模型安全漏洞探测能力](https://arxiv.org/abs/2501.01830)
Token length: 1207
Summarized using gpt-4o-mini
Append: [ToolHop: 评估多跳工具使用的新数据集](https://arxiv.org/abs/2501.02506)
Token length: 986
Summarized using gpt-4o-mini
Append: [测试时计算扩展的潜力与系统思维转变](https://arxiv.org/abs/2501.02497)
Token length: 1167
Summarized using gpt-4o-mini
Append: [基于变换器的视频生成自定义框架研究](https://arxiv.org/abs/2501.01790)
Token length: 1558
Summarized using gpt-4o-mini
Append: [METAGENE-1：用于疾病监测的元基因组基础模型](https://arxiv.org/abs/2501.02045)
Token length: 1394
Summarized using gpt-4o-mini
Append: [基于文本到视频模型的真实世界视频超分辨率方法](https://arxiv.org/abs/2501.02976)
Token length: 1186
Summarized using gpt-4o-mini
Append: [PGraphRAG：基于用户知识图谱的个性化文本生成框架](https://arxiv.org/abs/2501.02157)
append_entries: 12
Finish: 2025-01-07 09:01:59.481421
------------------------------------------------------
Started: 2025-01-07 12:12:58.685642
Existing_entries: 990
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-07 12:12:58.940885
------------------------------------------------------
Started: 2025-01-07 15:54:25.820386
Existing_entries: 990
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1511
Summarized using gpt-4o-mini
Append: [浮点量化训练对大规模语言模型性能的影响研究](https://arxiv.org/abs/2501.02423)
Token length: 1554
Summarized using gpt-4o-mini
Append: [DepthMaster：基于扩散模型的单步深度估计](https://arxiv.org/abs/2501.02576)
append_entries: 2
Finish: 2025-01-07 15:54:37.106251
------------------------------------------------------
Started: 2025-01-07 18:01:04.398787
Existing_entries: 992
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1351
Summarized using gpt-4o-mini
Append: [自动化幻灯片生成的SlidesBench基准与AutoPresent模型](https://arxiv.org/abs/2501.00912)
append_entries: 1
Finish: 2025-01-07 18:01:09.591118
------------------------------------------------------
Started: 2025-01-07 21:01:00.419052
Existing_entries: 993
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1061
Summarized using gpt-4o-mini
Append: [AutoConverter：提升视觉语言模型评估的自动化框架](https://arxiv.org/abs/2501.03225)
append_entries: 1
Finish: 2025-01-07 21:01:06.394742
------------------------------------------------------
Started: 2025-01-08 00:34:45.888523
Existing_entries: 994
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-08 00:34:46.144572
------------------------------------------------------
Started: 2025-01-08 03:12:32.935352
Existing_entries: 994
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-08 03:12:33.179644
------------------------------------------------------
Started: 2025-01-08 06:10:19.206285
Existing_entries: 994
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1409
Summarized using gpt-4o-mini
Append: [Diffusion as Shader：多任务视频生成的新方法](https://arxiv.org/abs/2501.03847)
Token length: 833
Summarized using gpt-4o-mini
Append: [Cosmos世界基础模型平台：为物理AI定制世界模型](https://arxiv.org/abs/2501.03575)
Token length: 1360
Summarized using gpt-4o-mini
Append: [MotionBench: 评估视频理解模型的细粒度运动理解能力](https://arxiv.org/abs/2501.02955)
Token length: 1175
Summarized using gpt-4o-mini
Append: [基于自注意力机制的面部表情编辑模型MagicFace](https://arxiv.org/abs/2501.02260)
Token length: 1149
Summarized using gpt-4o-mini
Append: [Magic Mirror：高质量动态身份保留视频生成框架](https://arxiv.org/abs/2501.03931)
Token length: 1711
Summarized using gpt-4o-mini
Append: [LLaVA-Mini：高效的多模态模型通过极大压缩视觉令牌](https://arxiv.org/abs/2501.03895)
append_entries: 6
Finish: 2025-01-08 06:10:55.245803
------------------------------------------------------
Started: 2025-01-08 09:00:52.460916
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-08 09:00:52.716119
------------------------------------------------------
Started: 2025-01-08 12:12:53.598229
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1436
Summarized using gpt-4o-mini
Append: [Dolphin：首个闭环开放式自动科研框架的研究](https://arxiv.org/abs/2501.03916)
Token length: 1220
Summarized using gpt-4o-mini
Append: [Sa2VA：首个统一的图像与视频密集基础理解模型](https://arxiv.org/abs/2501.04001)
Json decode failed:
{
  "title": "REINFORCE++: 一种改进的强化学习算法从人类反馈中优化大语言模型",
  "short_summary": "本文介绍了REINFORCE++，一种新型的人类反馈强化学习算法。",
  "summary": "强化学习从人类反馈（RLHF）成为对齐大语言模型与人类偏好的关键方法。本文提出了一种改进版的REINFORCE算法，称为REINFORCE++，该算法结合了近端策略优化（PPO）的优化技术，且不再需要评论网络。REINFORCE++具有三个主要目标：简单性、增强的训练稳定性和降低的计算开销。通过广泛的实证评估，研究表明，REINFORCE++在稳定性上优于组相对策略优化（GRPO），同时在计算效率上超过PPO，且保持相当的性能。该算法的实现代码可在https:
  "keyword": [
    "强化学习",
    "人类反馈",
    "算法优化"
  ]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 247 (char 356). Line: 406.
Append: [REINFORCE++: A Simple and Efficient Approach for Aligning Large Language Models](https://arxiv.org/abs/2501.03262)
append_entries: 3
Finish: 2025-01-08 12:13:15.898192
------------------------------------------------------
Started: 2025-01-08 15:00:47.792190
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1159
Summarized using gpt-4o-mini
Append: [PPTAgent：提升自动生成演示文稿的质量与一致性](https://arxiv.org/abs/2501.03936)
Token length: 1619
Summarized using gpt-4o-mini
Append: [MoDecGS：高效动态场景重建的3D高斯分裂框架](https://arxiv.org/abs/2501.03714)
append_entries: 2
Finish: 2025-01-08 15:01:04.601756
------------------------------------------------------
Started: 2025-01-08 18:01:08.619767
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1919
Summarized using gpt-4o-mini
Append: [将图感知关系推理融入Transformer架构](https://arxiv.org/abs/2501.02393)
Token length: 1202
Summarized using gpt-4o-mini
Append: [基于段落奖励模型的强化学习优化语言模型评估](https://arxiv.org/abs/2501.02790)
append_entries: 2
Finish: 2025-01-08 18:01:21.965759
------------------------------------------------------
Started: 2025-01-08 21:00:48.214047
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-08 21:00:48.387461
------------------------------------------------------
Started: 2025-01-09 00:34:36.140075
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-09 00:34:36.334239
------------------------------------------------------
Started: 2025-01-09 03:29:47.628176
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-09 03:29:47.798727
------------------------------------------------------
Started: 2025-01-09 06:00:40.212888
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1070
Summarized using gpt-4o-mini
Append: [openomni: 开放式全模态学习与实时情感语音生成的新方法](https://arxiv.org/abs/2501.04561)
Token length: 1770
Summarized using gpt-4o-mini
Append: [文本引导图像生成模型的源头识别任务及其解决方案](https://arxiv.org/abs/2501.02376)
append_entries: 2
Finish: 2025-01-09 06:00:48.408906
------------------------------------------------------
Started: 2025-01-09 09:00:43.637221
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 928
Summarized using gpt-4o-mini
Append: [InfiGUIAgent：提升图形用户界面自动化的多模态语言模型代理](https://arxiv.org/abs/2501.04575)
Token length: 937
Summarized using gpt-4o-mini
Append: [Meta链式思维框架：提升人工智能推理能力](https://arxiv.org/abs/2501.04682)
Token length: 1553
Summarized using gpt-4o-mini
Append: [Agent Laboratory：加速科学发现的自主研究框架](https://arxiv.org/abs/2501.04227)
Token length: 1488
Summarized using gpt-4o-mini
Append: [rStar-Math：小型语言模型在数学推理能力上的突破](https://arxiv.org/abs/2501.04519)
Token length: 1445
Summarized using gpt-4o-mini
Append: [Generation Augmented Retrieval (GeAR)方法在文档检索中的应用](https://arxiv.org/abs/2501.02772)
append_entries: 5
Finish: 2025-01-09 09:01:10.806843
------------------------------------------------------
Started: 2025-01-09 12:12:47.624741
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1652
Summarized using gpt-4o-mini
Append: [基于特征树的代码生成框架提升LLM性能](https://arxiv.org/abs/2501.04694)
Token length: 833
Summarized using gpt-4o-mini
Append: [突破细粒度3D生成的创新系统](https://arxiv.org/abs/2501.04144)
Token length: 1241
Summarized using gpt-4o-mini
Append: [SPAR3D: 高效的单图像三维物体重建方法](https://arxiv.org/abs/2501.04689)
Token length: 961
Summarized using gpt-4o-mini
Append: [大型语言模型在科学研究中的变革性应用](https://arxiv.org/abs/2501.04306)
Token length: 1220
Summarized using gpt-4o-mini
Append: [DPO-Kernels：提升大语言模型对齐的创新方法](https://arxiv.org/abs/2501.03271)
Token length: 1568
Summarized using gpt-4o-mini
Append: [提升多模态数学推理的高质量CoT训练数据](https://arxiv.org/abs/2501.04686)
append_entries: 6
Finish: 2025-01-09 12:13:29.741591
------------------------------------------------------
Started: 2025-01-09 15:01:01.531350
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-09 15:01:01.713080
------------------------------------------------------
Started: 2025-01-09 18:01:13.478447
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1061
Summarized using gpt-4o-mini
Append: [提升检索增强生成应用的通用性与效率](https://arxiv.org/abs/2501.04652)
append_entries: 1
Finish: 2025-01-09 18:01:18.541020
------------------------------------------------------
Started: 2025-01-09 21:00:43.497015
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-09 21:00:43.640783
------------------------------------------------------
Started: 2025-01-10 00:35:28.171752
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-10 00:35:28.368855
------------------------------------------------------
Started: 2025-01-10 03:15:31.676994
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-10 03:15:31.874547
------------------------------------------------------
Started: 2025-01-10 06:10:27.480055
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1350
Summarized using gpt-4o-mini
Append: [Search-o1: 提升大型推理模型的知识检索与生成能力](https://arxiv.org/abs/2501.05366)
append_entries: 1
Finish: 2025-01-10 06:10:33.396129
------------------------------------------------------
Started: 2025-01-10 09:01:03.046820
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1269
Summarized using gpt-4o-mini
Append: [VAR模型的计算效率研究与低秩近似优化](https://arxiv.org/abs/2501.04377)
Token length: 1781
Summarized using gpt-4o-mini
Append: [优化私有推理的非线性解码器架构](https://arxiv.org/abs/2501.03489)
Token length: 956
Summarized using gpt-4o-mini
Append: [基于视频的自回归预训练研究：Toto模型的探索](https://arxiv.org/abs/2501.05453)
Token length: 1016
Summarized using gpt-4o-mini
Append: [简化现代GAN训练：R3GAN的提出与优势](https://arxiv.org/abs/2501.05441)
append_entries: 4
Finish: 2025-01-10 09:01:22.915382
------------------------------------------------------
Started: 2025-01-10 12:12:43.271845
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1618
Summarized using gpt-4o-mini
Append: [DriveBench：评估视觉语言模型在自动驾驶中的可靠性](https://arxiv.org/abs/2501.04003)
append_entries: 1
Finish: 2025-01-10 12:12:47.919317
------------------------------------------------------
Started: 2025-01-10 15:00:42.469614
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1594
Summarized using gpt-4o-mini
Append: [多语言视觉语言模型的训练策略研究](https://arxiv.org/abs/2501.05122)
Json decode failed:
{
  "title": "历史土耳其语自然语言处理基础资源与模型的介绍",
  "keyword": ["历史土耳其语", "命名实体识别", "数据集"],
  "short_summary": "本文介绍历史土耳其语的NLP基础资源和模型，包括数据集和实验结果。",
  "summary": "本文介绍了历史土耳其语自然语言处理（NLP）的基础资源和模型，填补了该领域在计算语言学中的空白。我们推出了首个命名实体识别（NER）数据集HisTR和第一个通用依赖树库OTA-BOUN，适用于历史土耳其语，并使用这些数据集训练了基于变换器的模型，以完成命名实体识别、依赖分析和词性标注任务。此外，我们还推出了奥斯曼文本语料库（OTC），这是一个涵盖多个历史时期的转写历史土耳其语文本的清晰语料库。实验结果表明，在历史土耳其语的计算分析中取得了显著的改进，在理解历史语言结构的任务中表现出良好的效果，同时也突显了诸如领域适应和语言时间变化等现存挑战。我们提供的所有资源和模型均可在 https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 311 (char 447). Line: 406.
Append: [Building Foundations for Natural Language Processing of Historical Turkish: Resources and Models](https://arxiv.org/abs/2501.04828)
append_entries: 2
Finish: 2025-01-10 15:00:50.342963
------------------------------------------------------
Started: 2025-01-10 18:01:09.390462
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-10 18:01:09.545808
------------------------------------------------------
Started: 2025-01-10 21:01:05.448606
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 694
Summarized using gpt-4o-mini
Append: [提升大型语言模型的人性化进展研究](https://arxiv.org/abs/2501.05032)
Token length: 1583
Summarized using gpt-4o-mini
Append: [SWE-Fixer: 开源大型语言模型解决GitHub软件工程问题](https://arxiv.org/abs/2501.05040)
append_entries: 2
Finish: 2025-01-10 21:01:13.802237
------------------------------------------------------
Started: 2025-01-11 00:34:33.305114
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-11 00:34:33.456961
------------------------------------------------------
Started: 2025-01-11 03:13:09.461064
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-11 03:13:09.699125
------------------------------------------------------
Started: 2025-01-11 06:00:56.311719
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-11 06:00:56.560930
------------------------------------------------------
Started: 2025-01-11 09:00:39.005390
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-11 09:00:39.197955
------------------------------------------------------
Started: 2025-01-11 12:11:06.279441
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-11 12:11:06.568559
------------------------------------------------------
Started: 2025-01-11 15:00:43.362386
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-11 15:00:43.497603
------------------------------------------------------
Started: 2025-01-11 18:00:45.917417
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-11 18:00:46.135465
------------------------------------------------------
Started: 2025-01-11 21:00:43.330741
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-11 21:00:43.615400
------------------------------------------------------
Started: 2025-01-12 00:38:28.500623
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-12 00:38:28.675058
------------------------------------------------------
Started: 2025-01-12 03:19:04.508058
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-12 03:19:04.751835
------------------------------------------------------
Started: 2025-01-12 06:00:50.296404
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-12 06:00:50.453462
------------------------------------------------------
Started: 2025-01-12 09:00:51.986255
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-12 09:00:52.224278
------------------------------------------------------
Started: 2025-01-12 12:11:03.816052
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-12 12:11:04.000575
------------------------------------------------------
Started: 2025-01-12 15:00:37.103823
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-12 15:00:37.256289
------------------------------------------------------
Started: 2025-01-12 18:00:42.428187
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-12 18:00:42.585269
------------------------------------------------------
Started: 2025-01-12 21:00:35.295842
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-12 21:00:35.533119
------------------------------------------------------
Started: 2025-01-13 00:37:29.962664
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-13 00:37:30.155305
------------------------------------------------------
Started: 2025-01-13 03:17:47.671293
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-13 03:17:47.923197
------------------------------------------------------
Started: 2025-01-13 06:11:16.269881
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-13 06:11:16.503642
------------------------------------------------------
Started: 2025-01-13 09:00:45.253607
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1089
Summarized using gpt-4o-mini
Append: [基于JPEG图像的视觉大型语言模型安全性测试新方法](https://arxiv.org/abs/2501.05542)
Token length: 1166
Summarized using gpt-4o-mini
Append: [多智能体语言模型的自我改进与专业化研究](https://arxiv.org/abs/2501.05707)
Token length: 1536
Summarized using gpt-4o-mini
Append: [面向机器人操控的新型对象中心表征方法](https://arxiv.org/abs/2501.03841)
Token length: 1916
Summarized using gpt-4o-mini
Append: [推动视觉推理：一个新的多步骤框架与基准](https://arxiv.org/abs/2501.06186)
Token length: 1473
Summarized using gpt-4o-mini
Append: [VideoRAG：动态视频检索与生成的创新框架](https://arxiv.org/abs/2501.05874)
Token length: 1202
Summarized using gpt-4o-mini
Append: [SCRIT：自我进化的语言模型批评框架](https://arxiv.org/abs/2501.05727)
append_entries: 6
Finish: 2025-01-13 09:01:24.952873
------------------------------------------------------
Started: 2025-01-13 12:13:53.713437
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1700
Summarized using gpt-4o-mini
Append: [ConceptMaster：多概念视频定制中的身份解耦框架](https://arxiv.org/abs/2501.04698)
Token length: 1544
Summarized using gpt-4o-mini
Append: [Video Alchemist：多主体开放集视频个性化合成的新方法](https://arxiv.org/abs/2501.06187)
Token length: 1893
Summarized using gpt-4o-mini
Append: [OVO-Bench: 进阶在线视频理解能力评估基准](https://arxiv.org/abs/2501.05510)
Token length: 1512
Summarized using gpt-4o-mini
Append: [ReFocus：提升多模态大语言模型的结构化图像理解能力](https://arxiv.org/abs/2501.05452)
append_entries: 4
Finish: 2025-01-13 12:14:16.969342
------------------------------------------------------
Started: 2025-01-13 15:00:48.479674
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-13 15:00:48.774410
------------------------------------------------------
Started: 2025-01-13 18:00:54.703473
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-13 18:00:54.905239
------------------------------------------------------
Started: 2025-01-13 21:00:41.223238
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-13 21:00:41.386532
------------------------------------------------------
Started: 2025-01-14 00:33:03.292109
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1338
Summarized using gpt-4o-mini
Append: [FINDAP：金融领域的大型语言模型领域适应后训练](https://arxiv.org/abs/2501.04961)
append_entries: 1
Finish: 2025-01-14 00:33:16.951600
------------------------------------------------------
Started: 2025-01-14 03:00:40.229037
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-14 03:00:40.463288
------------------------------------------------------
Started: 2025-01-14 06:00:52.086817
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1357
Summarized using gpt-4o-mini
Append: [Migician：首个多图像精准定位模型及评估基准](https://arxiv.org/abs/2501.05767)
Token length: 1363
Summarized using gpt-4o-mini
Append: [生成式人工智能在传统动画制作中的变革](https://arxiv.org/abs/2501.06250)
append_entries: 2
Finish: 2025-01-14 06:01:06.794737
------------------------------------------------------
Started: 2025-01-14 09:01:05.794157
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1113
Summarized using gpt-4o-mini
Append: [长时序叙事生成的烹饪视频数据集与改进方法](https://arxiv.org/abs/2501.06173)
Token length: 828
Summarized using gpt-4o-mini
Append: [WebWalkerQA: 一种评估LLM网络遍历能力的新基准](https://arxiv.org/abs/2501.07572)
Token length: 1433
Summarized using gpt-4o-mini
Append: [ChemAgent：提升大语言模型在化学推理中的表现](https://arxiv.org/abs/2501.06590)
Token length: 1891
Summarized using gpt-4o-mini
Append: [MinMo: 多模态大型语言模型实现无缝语音交互](https://arxiv.org/abs/2501.06282)
Json decode failed:
{
  "title": "自适应大型语言模型的新框架",
  "short_summary": "提出一种新框架，实现大型语言模型的实时自适应。",
  "summary": "本文介绍了一种新颖的自适应框架\implname，旨在解决传统微调方法的计算密集性和适应性不足的问题。该框架通过实时选择性调整权重矩阵的单一组件，能够高效适应未见任务。\implname在推理过程中使用双通机制：首先，调度系统识别任务属性，然后结合通过强化学习训练的任务特定“专家”向量，以实现针对性行为。实验证明，\implname在参数更少和效率更高的情况下，优于当前广泛使用的方法，如LoRA。该框架在不同的LLM架构和模态中展示了其多样性，特别是在视觉语言任务中。总体而言，\implname代表了一个重要的进步，为增强LLM的适应性和任务特定性能提供了可扩展、高效的解决方案，推动了真正动态的自组织AI系统的发展。",
  "keyword": ["自适应", "大型语言模型", "强化学习"]
}Summarization failed, append the original article
error: Invalid \escape: line 4 column 30 (char 105). Line: 406.
Append: [$\text{Transformer}^2$: Self-adaptive LLMs](https://arxiv.org/abs/2501.06252)
Token length: 1906
Summarized using gpt-4o-mini
Append: [提升大型语言模型推理流程监控的过程奖励模型研究](https://arxiv.org/abs/2501.07301)
Token length: 1284
Summarized using gpt-4o-mini
Append: [推理时间扩展对大型语言模型医学推理能力的影响](https://arxiv.org/abs/2501.06458)
Token length: 1241
Summarized using gpt-4o-mini
Append: [Tensor Product Attention：提高语言模型输入序列处理效率的新机制](https://arxiv.org/abs/2501.06425)
Token length: 857
Summarized using gpt-4o-mini
Append: [uCO3D：新型3D深度学习和生成AI对象数据集](https://arxiv.org/abs/2501.07574)
append_entries: 9
Finish: 2025-01-14 09:01:50.916172
------------------------------------------------------
Started: 2025-01-14 12:00:56.234618
Existing_entries: 1009
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-14 12:00:56.457197
------------------------------------------------------
Started: 2025-01-14 15:00:44.349033
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1807
Summarized using gpt-4o-mini
Append: [针对大语言模型训练的梯度尖峰问题及其优化策略](https://arxiv.org/abs/2501.06842)
Token length: 1553
Summarized using gpt-4o-mini
Append: [构建开放的生物医学视觉语言模型数据集BIOMEDICA](https://arxiv.org/abs/2501.07171)
append_entries: 2
Finish: 2025-01-14 15:00:56.610873
------------------------------------------------------
Started: 2025-01-14 18:00:51.145426
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1240
Summarized using gpt-4o-mini
Append: [基于Mimic Score的数据选择框架提升模型训练效果](https://arxiv.org/abs/2501.06708)
append_entries: 1
Finish: 2025-01-14 18:00:56.885364
------------------------------------------------------
Started: 2025-01-14 21:00:58.420170
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-14 21:00:58.620520
------------------------------------------------------
Started: 2025-01-15 00:34:01.494422
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-15 00:34:01.691146
------------------------------------------------------
Started: 2025-01-15 03:08:47.923217
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-15 03:08:48.167347
------------------------------------------------------
Started: 2025-01-15 06:00:56.634886
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1658
Summarized using gpt-4o-mini
Append: [FramePainter: 高效的图像到视频生成用于交互式图像编辑](https://arxiv.org/abs/2501.08225)
Token length: 751
Summarized using gpt-4o-mini
Append: [MangaNinjia：基于扩散模型的参考引导线艺术上色](https://arxiv.org/abs/2501.08332)
Token length: 955
Summarized using gpt-4o-mini
Append: [基于对抗后训练的实时视频生成模型Seaweed-APT](https://arxiv.org/abs/2501.08316)
Token length: 1509
Summarized using gpt-4o-mini
Append: [InstructCell：提高单细胞RNA测序分析的智能助手](https://arxiv.org/abs/2501.08187)
Json decode failed:
{
  "title": "推出MiniMax-01系列：超长上下文处理的前沿模型",
  "keyword": ["MiniMax-01", "长上下文", "模型性能"],
  "short_summary": "MiniMax-01系列模型在处理长上下文方面表现突出，并提供卓越的性能。",
  "summary": "MiniMax-01系列包括MiniMax-Text-01和MiniMax-VL-01，具有与顶尖模型相媲美乃至更强的长上下文处理能力。核心技术为闪电注意力和高效的扩展性，结合了混合专家(MoE)架构，形成一个拥有32个专家和4560亿总参数的模型，在每个token上激活459亿参数。我们开发了优化的并行策略及高效的计算-通信重叠技术，确保在训练和推理中的高效性，能够处理数亿token的上下文。MiniMax-Text-01的上下文窗口在训练时可达100万token，推理时可外推至400万token，且成本可控。MiniMax-VL-01则通过5120亿视觉-语言token的持续训练建立，实验结果表明我们的模型在标准和内部基准测试上，与最高性能的GPT-4o和Claude-3.5-Sonnet表现相当，同时能够支持20-32倍更长的上下文窗口。MiniMax-01系列现已公开发布，详情见https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 420 (char 568). Line: 406.
Append: [MiniMax-01: Scaling Foundation Models with Lightning Attention](https://arxiv.org/abs/2501.08313)
append_entries: 5
Finish: 2025-01-15 06:01:16.607957
------------------------------------------------------
Started: 2025-01-15 09:00:47.997691
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1275
Summarized using gpt-4o-mini
Append: [OpenCSG中文语料库：提升中文LLM性能的高质量数据集](https://arxiv.org/abs/2501.08197)
Json decode failed:
{
  "title": "评估大语言模型在文本总结中的有效性与可靠性",
  "short_summary": "研究探讨大语言模型在解读文本数据中的可靠性，强调人类评估的重要性。",
  "summary": "随着大语言模型（LLMs）技术的快速发展，它们在处理和总结非结构化文本数据方面展现出卓越的能力。本研究探讨了LLMs是否能够准确代表开放式数据集（如调查反馈）中的观点。尽管LLMs能生成类似人类的总结，但输出可能与原始内容存在偏差，从而影响决策的有效性。本研究利用Anthropic的Claude模型生成主题总结，并采用Amazon的Titan Express、Nova Pro和Meta的Llama作为评判模型，同时与人类评估进行比较。通过使用Cohen"s kappa、Spearman"s rho和Krippendorff"s alpha等方法验证了LLMs作为评估模型的有效性，发现其在可扩展性上与人类评估可比，然而人类在捕捉细微、特定背景的差异上仍具优势。本研究不仅丰富了AI辅助文本分析的知识体系，且讨论了限制和未来研究的建议，强调在不同背景和用例中推广LLM评判模型时需要谨慎考虑。",
  "keyword": ["大语言模型", "文本总结", "评估"]
}Summarization failed, append the original article
error: Expecting ',' delimiter: line 4 column 244 (char 337). Line: 406.
Append: [Potential and Perils of Large Language Models as Judges of Unstructured Textual Data](https://arxiv.org/abs/2501.08167)
Token length: 1261
Summarized using gpt-4o-mini
Append: [Tarsier2: 新一代视频语言模型的突破性进展](https://arxiv.org/abs/2501.07888)
Token length: 1675
Summarized using gpt-4o-mini
Append: [PokerBench：评估大型语言模型扑克能力的新基准](https://arxiv.org/abs/2501.08328)
Token length: 1278
Summarized using gpt-4o-mini
Append: [TA-TiTok：高效的文本感知一维图像标记器](https://arxiv.org/abs/2501.07730)
Token length: 1438
Summarized using gpt-4o-mini
Append: [HALoGEN：生成模型幻觉评估基准](https://arxiv.org/abs/2501.08292)
append_entries: 6
Finish: 2025-01-15 09:01:13.614474
------------------------------------------------------
Started: 2025-01-15 12:00:50.094121
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-15 12:00:50.325405
------------------------------------------------------
Started: 2025-01-15 15:00:52.399489
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1079
Summarized using gpt-4o-mini
Append: [Omni-RGPT: 跨区域理解的多模态大语言模型](https://arxiv.org/abs/2501.08326)
Token length: 1201
Summarized using gpt-4o-mini
Append: [分析填充标记在图像生成中的影响](https://arxiv.org/abs/2501.06751)
Token length: 1340
Summarized using gpt-4o-mini
Append: [优化大型语言模型特征描述的自动化方法](https://arxiv.org/abs/2501.08319)
Json decode failed:
{
  "title": "AfriHate：15种非洲语言的仇恨言论与滥用语言数据集",
  "keyword": ["仇恨言论", "数据集", "非洲语言"],
  "short_summary": "AfriHate项目提供15种非洲语言的仇恨言论数据集，旨在改善言论监控。",
  "summary": "AfriHate是一个包括15种非洲语言的多语言仇恨言论和滥用语言数据集的项目，旨在促进对仇恨言论的理解、识别和管理。该项目揭示了全球南方地区在言论监管中面临的挑战，特别是由于缺乏高质量的本地语言数据和当地社区参与的缺失而导致的监管不足与审查。数据集中每一实例均由熟悉当地文化的母语者注释，以提高注释质量。同时，文章展示了构建这些数据集所面临的挑战，并提供了不同分类基准结果，包括使用与不使用大型语言模型的比较。此数据集及其注释和相关词汇在 https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 242 (char 385). Line: 406.
Append: [AfriHate: A Multilingual Collection of Hate Speech and Abusive Language Datasets for African Languages](https://arxiv.org/abs/2501.08284)
append_entries: 4
Finish: 2025-01-15 15:01:15.898648
------------------------------------------------------
Started: 2025-01-15 18:01:20.875660
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1769
Summarized using gpt-4o-mini
Append: [基于FLUX的深度驱动解耦实例合成方法3DIS-FLUX](https://arxiv.org/abs/2501.05131)
Json decode failed:
{
  "title": "图基偏好递归语言模型的探索性优化及其在科学发现中的应用",
  "keyword": ["图推理", "符号抽象", "知识图谱"],
  "short_summary": "介绍了Graph-PReFLexOR框架，实现图推理与动态领域知识扩展。",
  "summary": "本文介绍了Graph-PReFLexOR（图基偏好递归语言模型）的框架，结合图推理和符号抽象，以动态扩展领域知识。该框架从强化学习中获得灵感，将推理定义为结构化映射，任务生成知识图谱和抽象模式，最终得出成果。核心思想借鉴范畴理论，通过节点编码概念，边描述关系，从而支持层次推理和自适应学习。此外，提出的"知识花园生长"策略促进跨领域的洞察整合，实现了学科间的联结。3亿参数的Graph-PReFLexOR模型展示了其在推理深度和适应性方面的优越表现，展现了透明且多学科的AI驱动发现的潜力，为普遍自主推理解决方案奠定了基础。"
}Summarization failed, append the original article
error: Expecting ',' delimiter: line 5 column 167 (char 307). Line: 406.
Append: [In-situ graph reasoning and knowledge expansion using Graph-PReFLexOR](https://arxiv.org/abs/2501.08120)
append_entries: 2
Finish: 2025-01-15 18:01:33.493795
------------------------------------------------------
Started: 2025-01-15 21:00:42.362135
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-15 21:00:42.586056
------------------------------------------------------
Started: 2025-01-16 00:33:48.430985
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1631
Summarized using gpt-4o-mini
Append: [基于合成训练信号的跨模态图像匹配框架](https://arxiv.org/abs/2501.07556)
append_entries: 1
Finish: 2025-01-16 00:34:12.996014
------------------------------------------------------
Started: 2025-01-16 03:08:51.712036
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-16 03:08:51.976717
------------------------------------------------------
Started: 2025-01-16 06:00:51.087864
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-16 06:00:51.329451
------------------------------------------------------
Started: 2025-01-16 09:00:52.461454
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 919
Summarized using gpt-4o-mini
Append: [多模态大语言模型在艺术美学评估中的推理能力研究](https://arxiv.org/abs/2501.09012)
Token length: 1830
Summarized using gpt-4o-mini
Append: [CityDreamer4D：生成真实感4D城市的创新模型](https://arxiv.org/abs/2501.08983)
Token length: 1505
Summarized using gpt-4o-mini
Append: [MMDocIR: 新多模态文档检索基准的建立与分析](https://arxiv.org/abs/2501.08828)
Token length: 1443
Summarized using gpt-4o-mini
Append: [RepVideo：增强文本到视频扩散模型的表示框架](https://arxiv.org/abs/2501.08994)
Token length: 1578
Summarized using gpt-4o-mini
Append: [Ouroboros-Diffusion：一种增强视频一致性的去噪框架](https://arxiv.org/abs/2501.09019)
Token length: 1696
Summarized using gpt-4o-mini
Append: [XMusic：一种通用的情感可控符号音乐生成框架](https://arxiv.org/abs/2501.08809)
append_entries: 6
Finish: 2025-01-16 09:01:37.008158
------------------------------------------------------
Started: 2025-01-16 12:12:18.916043
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1698
Summarized using gpt-4o-mini
Append: [AI大语言模型训练的版权争议及其影响](https://arxiv.org/abs/2501.08365)
Token length: 1479
Summarized using gpt-4o-mini
Append: [利用可信的机器学习模型实现安全计算](https://arxiv.org/abs/2501.08970)
Token length: 1609
Summarized using gpt-4o-mini
Append: [参数反转图像金字塔网络（PIIP）：高效多尺度视觉感知方法](https://arxiv.org/abs/2501.07783)
append_entries: 3
Finish: 2025-01-16 12:12:36.189944
------------------------------------------------------
Started: 2025-01-16 15:00:55.420672
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-16 15:00:55.801116
------------------------------------------------------
Started: 2025-01-16 18:00:50.560495
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-16 18:00:50.803503
------------------------------------------------------
Started: 2025-01-16 21:00:47.211084
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1525
Summarized using gpt-4o-mini
Append: [FuSe：多模态传感器的机器人操作新方法](https://arxiv.org/abs/2501.04693)
Token length: 1555
Summarized using gpt-4o-mini
Append: [MINIMA：多模态图像匹配统一框架](https://arxiv.org/abs/2412.19412)
append_entries: 2
Finish: 2025-01-16 21:01:02.212588
------------------------------------------------------
Started: 2025-01-17 00:33:21.597464
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-17 00:33:21.829291
------------------------------------------------------
Started: 2025-01-17 03:09:44.255920
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-17 03:09:44.520667
------------------------------------------------------
Started: 2025-01-17 06:00:52.825917
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-17 06:00:53.075916
------------------------------------------------------
Started: 2025-01-17 09:00:51.276653
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1072
Summarized using gpt-4o-mini
Append: [OmniThink：提高机器写作知识密度的框架](https://arxiv.org/abs/2501.09751)
Token length: 1905
Summarized using gpt-4o-mini
Append: [探索在线医疗咨询中询问与诊断的关系](https://arxiv.org/abs/2501.09484)
Token length: 1195
Summarized using gpt-4o-mini
Append: [SynthLight：基于扩散模型的人物肖像重照明](https://arxiv.org/abs/2501.09756)
Token length: 1401
Summarized using gpt-4o-mini
Append: [基于频率空间的机器人动作序列标记化方法](https://arxiv.org/abs/2501.09747)
Json decode failed:
{
  "title": "AnyStory：个性化多主体图像生成的统一方法",
  "short_summary": "AnyStory提出了一种高保真个性化多主体图像生成的新方法。",
  "summary": "近年来，大规模生成模型在文本到图像生成方面表现出色，但在生成高保真个性化图像，尤其是涉及多个主体时仍面临挑战。本文提出的AnyStory通过‘编码-路由’的方式统一解决个性化主体生成问题。具体而言，AnyStory在编码阶段利用强大的图像编码器ReferenceNet结合CLIP视觉编码器，实现高保真的主体特征编码。在路由阶段，AnyStory采用一种解耦的实例感知主体路由器，准确预测潜在主体在潜空间中的位置，引导主体条件的注入。实验结果表明，该方法在保留主体细节、对齐文本描述和实现多主体个性化生成方面表现优异。更多信息可见项目主页： https:
  "keyword": [
    "个性化生成",
    "图像编码",
    "多主体"
  ]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 292 (char 386). Line: 406.
Append: [AnyStory: Towards Unified Single and Multiple Subject Personalization in Text-to-Image Generation](https://arxiv.org/abs/2501.09503)
Token length: 1396
Summarized using gpt-4o-mini
Append: [高保真3D资产生成的CaPa框架研究](https://arxiv.org/abs/2501.09433)
Token length: 1888
Summarized using gpt-4o-mini
Append: [自编码器设计在图像与视频生成模型中的作用研究](https://arxiv.org/abs/2501.09755)
Token length: 1517
Summarized using gpt-4o-mini
Append: [扩展扩散模型的推理时间计算行为研究](https://arxiv.org/abs/2501.09732)
Token length: 1791
Summarized using gpt-4o-mini
Append: [大规模语言模型的推理能力研究进展](https://arxiv.org/abs/2501.09686)
Token length: 1892
Summarized using gpt-4o-mini
Append: [基于事后模拟的强化学习：提升生成型AI的对齐性](https://arxiv.org/abs/2501.08617)
append_entries: 10
Finish: 2025-01-17 09:01:45.048512
------------------------------------------------------
Started: 2025-01-17 12:12:01.333434
Existing_entries: 1010
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1258
Summarized using gpt-4o-mini
Append: [AI视频生成与物理理解的界限](https://arxiv.org/abs/2501.09038)
append_entries: 1
Finish: 2025-01-17 12:12:07.239299
------------------------------------------------------
Started: 2025-01-17 15:00:43.551851
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-17 15:00:43.744242
------------------------------------------------------
Started: 2025-01-17 18:01:11.034698
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 631
Summarized using gpt-4o-mini
Append: [推出全新多语言编程数据集The Heap](https://arxiv.org/abs/2501.09653)
append_entries: 1
Finish: 2025-01-17 18:01:15.389186
------------------------------------------------------
Started: 2025-01-17 21:00:47.801336
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-17 21:00:47.987472
------------------------------------------------------
Started: 2025-01-18 00:32:05.654248
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-18 00:32:05.897486
------------------------------------------------------
Started: 2025-01-18 03:00:45.995948
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-18 03:00:46.262946
------------------------------------------------------
Started: 2025-01-18 06:00:36.515329
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-18 06:00:36.759255
------------------------------------------------------
Started: 2025-01-18 09:00:50.016424
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-18 09:00:50.227706
------------------------------------------------------
Started: 2025-01-18 12:10:35.341613
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-18 12:10:35.555895
------------------------------------------------------
Started: 2025-01-18 15:00:39.634095
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-18 15:00:39.845844
------------------------------------------------------
Started: 2025-01-18 18:00:59.890604
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-18 18:01:18.868886
------------------------------------------------------
Started: 2025-01-18 21:00:49.267492
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-18 21:00:49.480948
------------------------------------------------------
Started: 2025-01-19 00:36:39.073099
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-19 00:36:39.385471
------------------------------------------------------
Started: 2025-01-19 03:11:57.291450
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-19 03:11:57.474378
------------------------------------------------------
Started: 2025-01-19 06:00:41.733122
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-19 06:00:42.028104
------------------------------------------------------
Started: 2025-01-19 09:00:35.887144
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-19 09:00:36.125540
------------------------------------------------------
Started: 2025-01-19 12:00:49.325110
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-19 12:00:49.495147
------------------------------------------------------
Started: 2025-01-19 15:00:52.714444
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-19 15:00:53.017251
------------------------------------------------------
Started: 2025-01-19 18:00:59.088728
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-19 18:00:59.250868
------------------------------------------------------
Started: 2025-01-19 21:00:54.956234
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-19 21:00:55.113955
------------------------------------------------------
Started: 2025-01-20 00:34:44.622930
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-20 00:34:44.904764
------------------------------------------------------
Started: 2025-01-20 03:10:30.073429
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-20 03:10:30.293010
------------------------------------------------------
Started: 2025-01-20 06:00:56.036101
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1281
Summarized using gpt-4o-mini
Append: [GaussianAvatar-Editor：文本驱动的可动画高斯头像编辑框架](https://arxiv.org/abs/2501.09978)
Token length: 706
Summarized using gpt-4o-mini
Append: [Mind Evolution：提升大型语言模型推理效率的进化搜索策略](https://arxiv.org/abs/2501.09891)
Token length: 1231
Summarized using gpt-4o-mini
Append: [PaSa：基于大语言模型的学术论文搜索代理](https://arxiv.org/abs/2501.10120)
Json decode failed:
{
  "title": "ComplexFuncBench: 复杂函数调用的基准与评估框架",
  "keyword": ["大型语言模型", "函数调用", "基准评估"],
  "short_summary": "文章介绍了ComplexFuncBench基准及其在复杂函数调用评估中的应用。",
  "summary": "本文提出了ComplexFuncBench，这是一个针对复杂函数调用的新基准，旨在评估大型语言模型（LLMs）在五个现实场景下的函数调用能力。与现有基准相比，ComplexFuncBench 涉及多步骤和受限的函数调用，要求长参数填充和参数值推理，使用了128k的长上下文。我们还提出了自动化框架ComplexEval，用于定量评估复杂的函数调用任务。通过全面的实验，我们揭示了当前最先进的 LLMs 在函数调用方面的缺陷，并建议未来优化这些能力的方向。数据和代码可在 https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 256 (char 407). Line: 406.
Append: [ComplexFuncBench: Exploring Multi-Step and Constrained Function Calling under Long-Context Scenario](https://arxiv.org/abs/2501.10132)
append_entries: 4
Finish: 2025-01-20 06:01:16.714102
------------------------------------------------------
Started: 2025-01-20 09:00:41.558533
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-20 09:00:41.732147
------------------------------------------------------
Started: 2025-01-20 12:12:44.675742
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1365
Summarized using gpt-4o-mini
Append: [X-Dyna：基于扩散的零-shot人类图像动画生成方法](https://arxiv.org/abs/2501.10021)
Token length: 1507
Summarized using gpt-4o-mini
Append: [HiFi-SR：基于GAN的高保真语音超分辨率方法](https://arxiv.org/abs/2501.10045)
Json decode failed:
{
  "title": "Textoon：基于文本描述生成多样化2D卡通角色的创新方法",
  "short_summary": "Textoon利用文本生成不同的Live2D 2D卡通角色。",
  "summary": "Textoon是一种基于文本描述生成多样化2D卡通角色的创新方法，采用Live2D格式，具有高效率和互动性。与资源密集的3D角色构建不同，Textoon能够通过现代语言与视觉模型快速解读文本意图，并在短时间内生成多种风格的2D角色。这一方法使用轻量级HTML5渲染，提高了可访问性和响应速度。该技术特别适合年轻受众，满足了对2D卡通风格角色的需求，同时展现出与3D角色动画相似的运动表现。项目主页为：https:
  "keyword": ["2D卡通", "Live2D", "字符生成"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 221 (char 320). Line: 406.
Append: [Textoon: Generating Vivid 2D Cartoon Characters from Text Descriptions](https://arxiv.org/abs/2501.10020)
append_entries: 3
Finish: 2025-01-20 12:13:07.829089
------------------------------------------------------
Started: 2025-01-20 15:00:43.594948
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1631
Summarized using gpt-4o-mini
Append: [语言模型自信度与推理顺序的关系研究](https://arxiv.org/abs/2501.09775)
append_entries: 1
Finish: 2025-01-20 15:00:51.090057
------------------------------------------------------
Started: 2025-01-20 18:00:41.207098
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 982
Summarized using gpt-4o-mini
Append: [多语言医疗知识大语言模型的挑战与发展](https://arxiv.org/abs/2501.09825)
append_entries: 1
Finish: 2025-01-20 18:00:46.579643
------------------------------------------------------
Started: 2025-01-20 21:00:47.772181
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-20 21:00:47.967488
------------------------------------------------------
Started: 2025-01-21 00:33:17.192173
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-21 00:33:17.374907
------------------------------------------------------
Started: 2025-01-21 03:08:49.315213
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-21 03:08:49.473899
------------------------------------------------------
Started: 2025-01-21 06:00:58.467387
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-21 06:00:58.654012
------------------------------------------------------
Started: 2025-01-21 09:00:56.491521
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1465
Summarized using gpt-4o-mini
Append: [GameFactory：游戏视频生成中的场景泛化框架](https://arxiv.org/abs/2501.08325)
append_entries: 1
Finish: 2025-01-21 09:01:05.018183
------------------------------------------------------
Started: 2025-01-21 12:12:32.581771
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-21 12:12:32.762734
------------------------------------------------------
Started: 2025-01-21 15:00:53.819737
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1313
Summarized using gpt-4o-mini
Append: [基于视觉输入的深度生成模型研究：VideoWorld的应用与发现](https://arxiv.org/abs/2501.09781)
append_entries: 1
Finish: 2025-01-21 15:01:02.314231
------------------------------------------------------
Started: 2025-01-21 18:00:49.073629
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1004
Summarized using gpt-4o-mini
Append: [SEAL：保护LoRA权重的安全水印技术](https://arxiv.org/abs/2501.09284)
append_entries: 1
Finish: 2025-01-21 18:01:03.363308
------------------------------------------------------
Started: 2025-01-21 21:00:46.519757
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-21 21:00:46.703675
------------------------------------------------------
Started: 2025-01-22 00:34:09.250479
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-22 00:34:09.420114
------------------------------------------------------
Started: 2025-01-22 03:10:57.593070
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-22 03:10:57.757189
------------------------------------------------------
Started: 2025-01-22 06:01:09.160192
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-22 06:01:09.439022
------------------------------------------------------
Started: 2025-01-22 09:00:38.882993
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1919
Summarized using gpt-4o-mini
Append: [Agent-R：迭代自我训练框架提升语言模型错误纠正能力](https://arxiv.org/abs/2501.11425)
Token length: 1914
Summarized using gpt-4o-mini
Append: [Mobile-Agent-E：新一代自我进化移动代理框架](https://arxiv.org/abs/2501.11733)
Token length: 1719
Summarized using gpt-4o-mini
Append: [Learn-by-interact: 提升大语言模型自主代理的数据合成方法](https://arxiv.org/abs/2501.10893)
Token length: 1849
Summarized using gpt-4o-mini
Append: [UI-TARS：一种全新的GUI代理模型](https://arxiv.org/abs/2501.12326)
Token length: 1818
Summarized using gpt-4o-mini
Append: [解构推理语言模型的模块化框架](https://arxiv.org/abs/2501.11223)
Token length: 822
Summarized using gpt-4o-mini
Append: [基于GPS标签的图像生成模型研究](https://arxiv.org/abs/2501.12390)
Token length: 1628
Summarized using gpt-4o-mini
Append: [改进Mixture-of-Experts模型训练中的负载均衡损失方法](https://arxiv.org/abs/2501.11873)
Token length: 1341
Summarized using gpt-4o-mini
Append: [MMVU：视频理解基础模型的专家级多学科基准评估](https://arxiv.org/abs/2501.12380)
Token length: 1077
Summarized using gpt-4o-mini
Append: [Condor：提高大模型会话能力的合成数据生成框架](https://arxiv.org/abs/2501.12273)
append_entries: 9
Finish: 2025-01-22 09:01:22.782931
------------------------------------------------------
Started: 2025-01-22 12:12:35.792377
Existing_entries: 1009
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1533
Summarized using gpt-4o-mini
Append: [基于结构化噪声采样的视频扩散模型运动控制](https://arxiv.org/abs/2501.08331)
Token length: 1554
Summarized using gpt-4o-mini
Append: [Video Depth Anything: 提高超长视频的深度估计一致性](https://arxiv.org/abs/2501.12375)
Token length: 1159
Summarized using gpt-4o-mini
Append: [音频驱动的自然对话生成方法研究](https://arxiv.org/abs/2501.10687)
Token length: 1402
Summarized using gpt-4o-mini
Append: [Hunyuan3D 2.0：先进的大规模3D合成系统](https://arxiv.org/abs/2501.12202)
append_entries: 4
Finish: 2025-01-22 12:13:28.676888
------------------------------------------------------
Started: 2025-01-22 15:00:49.189662
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1199
Summarized using gpt-4o-mini
Append: [引入多模态安全测试套件评估视觉语言模型的安全性](https://arxiv.org/abs/2501.10057)
append_entries: 1
Finish: 2025-01-22 15:00:57.083549
------------------------------------------------------
Started: 2025-01-22 18:00:59.099772
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 930
Summarized using gpt-4o-mini
Append: [剖析变换器模型中令牌嵌入几何与下一令牌预测的关系](https://arxiv.org/abs/2501.10573)
Token length: 981
Summarized using gpt-4o-mini
Append: [基于风格与内容的个性化新闻标题生成框架SCAPE](https://arxiv.org/abs/2501.11900)
Token length: 1712
Summarized using gpt-4o-mini
Append: [提升大视觉语言模型的生成质量：InternLM-XComposer2.5-Reward的应用](https://arxiv.org/abs/2501.12368)
Token length: 1293
Summarized using gpt-4o-mini
Append: [TokenVerse：多概念个性化生成的新方法](https://arxiv.org/abs/2501.12224)
append_entries: 4
Finish: 2025-01-22 18:01:18.951460
------------------------------------------------------
Started: 2025-01-22 21:00:45.433953
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-22 21:00:45.622405
------------------------------------------------------
Started: 2025-01-23 00:33:57.322848
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1532
Summarized using gpt-4o-mini
Append: [通过注意力机制优化减少大型视觉语言模型中的幻觉现象](https://arxiv.org/abs/2501.12206)
append_entries: 1
Finish: 2025-01-23 00:34:01.254802
------------------------------------------------------
Started: 2025-01-23 03:09:15.035814
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 899
Summarized using gpt-4o-mini
Append: [MAGI：创新的混合视频生成框架](https://arxiv.org/abs/2501.12389)
append_entries: 1
Finish: 2025-01-23 03:09:20.006047
------------------------------------------------------
Started: 2025-01-23 06:00:47.751230
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-23 06:00:47.937363
------------------------------------------------------
Started: 2025-01-23 09:00:59.659809
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1247
Summarized using gpt-4o-mini
Append: [测试时间偏好优化框架：实时调整大型语言模型输出](https://arxiv.org/abs/2501.12895)
Token length: 1705
Summarized using gpt-4o-mini
Append: [VideoLLaMA3：图像与视频理解的先进多模态基础模型](https://arxiv.org/abs/2501.13106)
Token length: 1911
Summarized using gpt-4o-mini
Append: [IntellAgent：评估对话式人工智能的新框架](https://arxiv.org/abs/2501.11067)
Token length: 1250
Summarized using gpt-4o-mini
Append: [自主专家选择的Mixture-of-Experts新范式](https://arxiv.org/abs/2501.13074)
Token length: 888
Summarized using gpt-4o-mini
Append: [发布首代推理模型DeepSeek-R1-Zero和DeepSeek-R1](https://arxiv.org/abs/2501.12948)
Token length: 1502
Summarized using gpt-4o-mini
Append: [FilmAgent：基于大型语言模型的虚拟电影制作自动化框架](https://arxiv.org/abs/2501.12909)
Token length: 1495
Summarized using gpt-4o-mini
Append: [Kimi k1.5：基于强化学习的多模态大语言模型训练](https://arxiv.org/abs/2501.12599)
Token length: 1403
Summarized using gpt-4o-mini
Append: [O1-Pruner：降低长思考推理模型推理时间的新方法](https://arxiv.org/abs/2501.12570)
append_entries: 8
Finish: 2025-01-23 09:01:53.889378
------------------------------------------------------
Started: 2025-01-23 12:12:55.236092
Existing_entries: 1008
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "基于对比奖励模型的Best-of-N采样优化",
  "keyword": ["对比奖励模型", "Best-of-N采样", "大语言模型"],
  "short_summary": "提出对比奖励模型，优化Large Language Models的Best-of-N采样策略。",
  "summary": "本文提出了Pairwise Reward Model（对比奖励模型，Pairwise RM），旨在优化Large Language Models（LLMs）在测试时采用的Best-of-N（BoN）采样策略。与传统的绝对分数评分方法不同，Pairwise RM通过同时评估两个候选解的正确性，从而消除了任意评分的需求。该模型通过迭代的淘汰赛方式，在多个候选解之间进行对比，从而逐步筛除不正确的解。为训练Pairwise RM，研究团队构建了一个名为\ourdataset的大规模数据集，其中包含443K对比实例，并通过监督微调技术进行训练。实验结果表明，Pairwise RM在MATH-500和奥林匹克基准测试中的表现显著优于传统的判别奖励模型，尤其在困难问题的前50%上实现了40%到60%的相对提升。"
}Summarization failed, append the original article
error: Invalid \escape: line 5 column 239 (char 396). Line: 406.
Append: [Pairwise RM: Perform Best-of-N Sampling with Knockout Tournament](https://arxiv.org/abs/2501.13007)
append_entries: 1
Finish: 2025-01-23 12:12:58.821600
------------------------------------------------------
Started: 2025-01-23 15:00:46.684136
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-23 15:00:46.870812
------------------------------------------------------
Started: 2025-01-23 18:00:38.938801
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-23 18:00:39.140948
------------------------------------------------------
Started: 2025-01-23 21:00:48.589095
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-23 21:00:48.780888
------------------------------------------------------
Started: 2025-01-24 00:33:49.107421
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-24 00:33:49.348681
------------------------------------------------------
Started: 2025-01-24 03:09:29.646337
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-24 03:09:29.852165
------------------------------------------------------
Started: 2025-01-24 06:01:07.869631
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1685
Summarized using gpt-4o-mini
Append: [增强人类监督提升强模型对齐能力的研究](https://arxiv.org/abs/2501.13124)
Token length: 1392
Summarized using gpt-4o-mini
Append: [提升长视频理解的时间定位能力：时间偏好优化框架](https://arxiv.org/abs/2501.13919)
Token length: 1745
Summarized using gpt-4o-mini
Append: [文本到图像模型的评估与未来展望](https://arxiv.org/abs/2501.13920)
Token length: 1557
Summarized using gpt-4o-mini
Append: [Sigma：高效的系统领域大语言模型及其DiffQKV关注机制](https://arxiv.org/abs/2501.13629)
Token length: 1173
Summarized using gpt-4o-mini
Append: [Step-KTO：提升大型语言模型的数学推理可信度](https://arxiv.org/abs/2501.10799)
Token length: 1601
Summarized using gpt-4o-mini
Append: [链式思维推理在自回归图像生成中的应用研究](https://arxiv.org/abs/2501.13926)
append_entries: 6
Finish: 2025-01-24 06:01:34.418349
------------------------------------------------------
Started: 2025-01-24 09:01:06.141489
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-24 09:01:06.397700
------------------------------------------------------
Started: 2025-01-24 12:12:32.423891
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1309
Summarized using gpt-4o-mini
Append: [GSTAR：动态场景中的高效3D跟踪与重建](https://arxiv.org/abs/2501.10283)
Token length: 1366
Summarized using gpt-4o-mini
Append: [基于扩散模型的高效视频修复方法DiffuEraser](https://arxiv.org/abs/2501.10018)
Token length: 1402
Summarized using gpt-4o-mini
Append: [EchoVideo：一种提升身份保护视频生成的有效方法](https://arxiv.org/abs/2501.13452)
Token length: 1396
Summarized using gpt-4o-mini
Append: [共享递归记忆变压器在多智能体强化学习中的应用](https://arxiv.org/abs/2501.13200)
Token length: 1869
Summarized using gpt-4o-mini
Append: [机器学习中的盲点：对未知未来的鲁棒性](https://arxiv.org/abs/2501.13075)
append_entries: 5
Finish: 2025-01-24 12:13:01.954771
------------------------------------------------------
Started: 2025-01-24 15:01:00.045184
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1510
Summarized using gpt-4o-mini
Append: [基于人类反馈的视频生成优化模型](https://arxiv.org/abs/2501.13918)
Json decode failed:
{
  "title": "Video-MMMU：评估多模态模型的视频知识获取能力的基准",
  "keyword": ["知识获取", "多模态模型", "视频学习"],
  "short_summary": "本文介绍了Video-MMMU基准，以评估多模态模型从视频中获取知识的能力。",
  "summary": "人类通过感知信息、理解知识以及将知识应用于解决新问题的三个认知阶段来获取知识。视频作为学习过程中有效的媒介，促进了这些认知阶段的进展。然而，现有的视频基准未能系统地评估大型多模态模型（LMMs）的知识获取能力。为此，本文提出了Video-MMMU，一个多模态、多学科的基准，旨在评估LMMs从视频中获取和利用知识的能力。Video-MMMU包括300个专业级视频和900个人工标注的问题，涵盖六个学科，通过阶段对齐的问题-答案对（感知、理解和适应）评估知识获取。我们提出的知识增益度量{\Delta}knowledge量化了观看视频后的性能提升。LMMs的评估显示，随着认知需求的增加，性能呈现显著下降，并突显了人类与模型知识获取之间的重要差距，强调了提升LMMs从视频中学习和适应能力的方法的必要性。"
}Summarization failed, append the original article
error: Invalid \escape: line 5 column 258 (char 405). Line: 406.
Append: [Video-MMMU: Evaluating Knowledge Acquisition from Multi-Discipline Professional Videos](https://arxiv.org/abs/2501.13826)
append_entries: 2
Finish: 2025-01-24 15:01:13.274397
------------------------------------------------------
Started: 2025-01-24 18:01:06.880728
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1173
Summarized using gpt-4o-mini
Append: [幻觉在药物发现中的应用潜力：大型语言模型的研究](https://arxiv.org/abs/2501.13824)
Token length: 1414
Summarized using gpt-4o-mini
Append: [一种无训练的文本到图像生成方法：One-Prompt-One-Story](https://arxiv.org/abs/2501.13554)
append_entries: 2
Finish: 2025-01-24 18:01:32.067502
------------------------------------------------------
Started: 2025-01-24 21:01:01.828009
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-24 21:01:01.992657
------------------------------------------------------
Started: 2025-01-25 00:32:48.811189
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1625
Summarized using gpt-4o-mini
Append: [Control LLM: 一种有效应对灾难性遗忘的方法](https://arxiv.org/abs/2501.10979)
append_entries: 1
Finish: 2025-01-25 00:32:54.932492
------------------------------------------------------
Started: 2025-01-25 03:00:44.469286
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-25 03:00:44.740398
------------------------------------------------------
Started: 2025-01-25 06:05:25.276332
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1430
Summarized using gpt-4o-mini
Append: [EmbodiedEval：多模态大语言模型的交互式评估基准](https://arxiv.org/abs/2501.11858)
append_entries: 1
Finish: 2025-01-25 06:05:31.365356
------------------------------------------------------
Started: 2025-01-25 09:01:00.820213
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-25 09:01:01.261498
------------------------------------------------------
Started: 2025-01-25 12:01:00.498445
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-25 12:01:00.644605
------------------------------------------------------
Started: 2025-01-25 15:00:39.734670
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-25 15:00:39.981978
------------------------------------------------------
Started: 2025-01-25 18:00:41.686130
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-25 18:00:41.892302
------------------------------------------------------
Started: 2025-01-25 21:00:37.419868
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-25 21:00:37.574330
------------------------------------------------------
Started: 2025-01-26 00:34:35.318645
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-26 00:34:35.516247
------------------------------------------------------
Started: 2025-01-26 03:09:42.442386
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-26 03:09:42.605992
------------------------------------------------------
Started: 2025-01-26 06:00:48.761904
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-26 06:00:53.177868
------------------------------------------------------
Started: 2025-01-26 09:00:40.221531
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-26 09:00:40.471485
------------------------------------------------------
Started: 2025-01-26 12:10:39.921914
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-26 12:10:40.082467
------------------------------------------------------
Started: 2025-01-26 15:00:58.120382
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-26 15:00:58.275186
------------------------------------------------------
Started: 2025-01-26 18:01:05.567967
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-26 18:01:05.776936
------------------------------------------------------
Started: 2025-01-26 21:00:51.242428
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-26 21:00:51.418548
------------------------------------------------------
Started: 2025-01-27 00:35:01.934080
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-27 00:35:02.194283
------------------------------------------------------
Started: 2025-01-27 03:10:16.340593
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-27 03:10:16.553450
------------------------------------------------------
Started: 2025-01-27 06:10:47.359244
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1452
Summarized using gpt-4o-mini
Append: [评估大型语言模型批评能力的新基准](https://arxiv.org/abs/2501.14492)
Token length: 1428
Summarized using gpt-4o-mini
Append: [CoRAG：链式检索增强生成模型的训练方法](https://arxiv.org/abs/2501.14342)
append_entries: 2
Finish: 2025-01-27 06:10:55.704855
------------------------------------------------------
Started: 2025-01-27 09:00:46.395668
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1656
Summarized using gpt-4o-mini
Append: [可重光照全身高斯编码虚拟形象建模方法](https://arxiv.org/abs/2501.14726)
Token length: 1246
Summarized using gpt-4o-mini
Append: [推出人类最后考试：评估大型语言模型的新基准工具](https://arxiv.org/abs/2501.14249)
append_entries: 2
Finish: 2025-01-27 09:00:55.413707
------------------------------------------------------
Started: 2025-01-27 12:01:04.660512
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1009
Summarized using gpt-4o-mini
Append: [评估多模态大语言模型基准的冗余性与优化策略](https://arxiv.org/abs/2501.13953)
append_entries: 1
Finish: 2025-01-27 12:01:08.119163
------------------------------------------------------
Started: 2025-01-27 15:01:15.943517
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-27 15:01:16.102978
------------------------------------------------------
Started: 2025-01-27 18:01:03.768525
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 973
Summarized using gpt-4o-mini
Append: [增强学习与元学习结合的变换器模型研究](https://arxiv.org/abs/2501.14176)
Token length: 1917
Summarized using gpt-4o-mini
Append: [基于频率挖掘的自适应全能图像恢复网络](https://arxiv.org/abs/2403.14614)
Token length: 1647
Summarized using gpt-4o-mini
Append: [基于扩散模型的图像恢复领域适应方法](https://arxiv.org/abs/2406.18516)
Token length: 1171
Summarized using gpt-4o-mini
Append: [提升视觉模型的3D意识：基于ViT的研究与优化](https://arxiv.org/abs/2411.19458)
Token length: 1560
Summarized using gpt-4o-mini
Append: [GeoPixel: 一种高分辨率遥感图像的像素级基础大模型](https://arxiv.org/abs/2501.13925)
append_entries: 5
Finish: 2025-01-27 18:01:35.163972
------------------------------------------------------
Started: 2025-01-27 21:01:06.406743
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1307
Summarized using gpt-4o-mini
Append: [CatV2TON：一种高效的图像与视频虚拟试穿方法](https://arxiv.org/abs/2501.11325)
Token length: 1399
Summarized using gpt-4o-mini
Append: [利用大型语言模型实现电子健康记录的语义问答](https://arxiv.org/abs/2501.13687)
append_entries: 2
Finish: 2025-01-27 21:01:15.753048
------------------------------------------------------
Started: 2025-01-28 00:34:04.630780
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-28 00:34:04.844688
------------------------------------------------------
Started: 2025-01-28 03:08:38.000238
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-28 03:08:38.187355
------------------------------------------------------
Started: 2025-01-28 06:02:56.662224
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-28 06:02:56.821880
------------------------------------------------------
Started: 2025-01-28 09:01:09.403396
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1233
Summarized using gpt-4o-mini
Append: [iFormer：一种优化移动应用延迟与准确性的混合视觉网络](https://arxiv.org/abs/2501.15369)
Token length: 1148
Summarized using gpt-4o-mini
Append: [可行学习：重塑机器学习的样本中心训练范式](https://arxiv.org/abs/2501.14912)
Token length: 1817
Summarized using gpt-4o-mini
Append: [Mixture-of-Mamba：一种新型的状态空间模型架构用于多模态预训练](https://arxiv.org/abs/2501.16295)
Token length: 1103
Summarized using gpt-4o-mini
Append: [统一的无模型深度强化学习算法MR.Q的探索及其性能评估](https://arxiv.org/abs/2501.16142)
Token length: 1915
Summarized using gpt-4o-mini
Append: [Qwen2.5-1M模型：实现百万级上下文处理](https://arxiv.org/abs/2501.15383)
Token length: 1135
Summarized using gpt-4o-mini
Append: [Baichuan-Omni-1.5：全新的多模态理解与音频生成模型](https://arxiv.org/abs/2501.15368)
append_entries: 6
Finish: 2025-01-28 09:01:41.988606
------------------------------------------------------
Started: 2025-01-28 12:00:48.277212
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1261
Summarized using gpt-4o-mini
Append: [基于RWKV的高效混合注意力模型研究](https://arxiv.org/abs/2501.15570)
append_entries: 1
Finish: 2025-01-28 12:00:52.839843
------------------------------------------------------
Started: 2025-01-28 15:00:58.071071
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1186
Summarized using gpt-4o-mini
Append: [稀疏专家混合模型中的参数稀疏性对性能的影响研究](https://arxiv.org/abs/2501.12370)
Token length: 1421
Summarized using gpt-4o-mini
Append: [Emilia-Pipe：构建多语言自发语音生成数据集的开源管道](https://arxiv.org/abs/2501.15907)
append_entries: 2
Finish: 2025-01-28 15:01:10.626427
------------------------------------------------------
Started: 2025-01-28 18:01:03.857496
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-28 18:01:04.052870
------------------------------------------------------
Started: 2025-01-28 21:00:47.118077
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 984
Summarized using gpt-4o-mini
Append: [大语言模型中的角色定制化与合成数据研究](https://arxiv.org/abs/2501.15427)
Token length: 1578
Summarized using gpt-4o-mini
Append: [小型语言模型中的编码器-解码器架构优势分析](https://arxiv.org/abs/2501.16273)
append_entries: 2
Finish: 2025-01-28 21:01:01.526275
------------------------------------------------------
Started: 2025-01-29 00:34:02.670663
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1603
Summarized using gpt-4o-mini
Append: [CodeMonkeys：基于多轮迭代编辑的代码问题解决系统](https://arxiv.org/abs/2501.14723)
Json decode failed:
{
  "title": "引导无关训练（GFT）：提升视觉生成模型的效率",
  "short_summary": "GFT算法实现视觉模型引导无关采样，降低计算成本，性能优于CFG。",
  "summary": "引导自由训练（GFT）是一种新型视觉生成模型训练方法，旨在消除现有技术中需要进行条件和无条件模型推理的复杂性。与经典的分类无关引导（CFG）方法相比，GFT能够在单一模型下进行采样，成本减半。GFT不依赖于预训练的CFG网络，而是允许从零开始的直接训练。该方法在最大似然目标上与CFG保持一致，仅在条件模型的参数化上有所不同，实现起来也非常简单，只需对现有代码库进行最小修改。通过对五种不同视觉模型的广泛实验，GFT表现出优越性与多样性，能够在扩散、自回归及遮挡预测建模领域中实现与CFG相当或更低的FID分数，表现出相似的多样性与保真度权衡，且完全不依赖于引导机制。代码将公开于https:
  "keyword": [
    "引导自由训练",
    "视觉生成模型",
    "计算效率"
  ]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 311 (char 406). Line: 406.
Append: [Visual Generation Without Guidance](https://arxiv.org/abs/2501.15420)
Token length: 1391
Summarized using gpt-4o-mini
Append: [视觉语言模型中的视觉偏差研究](https://arxiv.org/abs/2403.09193)
append_entries: 3
Finish: 2025-01-29 00:34:19.661539
------------------------------------------------------
Started: 2025-01-29 03:08:52.613867
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-29 03:08:52.776705
------------------------------------------------------
Started: 2025-01-29 06:00:50.844742
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "低秩适配器与神经架构搜索结合下的大语言模型优化",
  "short_summary": "文章探讨低秩适配器与神经架构搜索结合对大语言模型的优化方法。",
  "summary": "随着大语言模型（LLMs）的快速扩展，模型的微调和部署面临着显著的计算资源挑战。本文回顾了低秩适配器在参数高效微调（PEFT）中的有效性，并详细探讨了将低秩表示与神经架构搜索（NAS）技术相结合的创新方法，特别是权重共享超网络。通过整合这些方法，开发出了有效的解决方案以压缩和微调大型预训练模型。分析结果显示，这些组合策略有潜力使大语言模型的使用更加民主化，提高其在资源有限环境下的可接入性。所生成的模型在内存占用和推理速度上均有所改善，推动了大语言模型在实际应用中的可扩展性和实用性。相关模型和代码可在https:
  "keyword": ["大语言模型", "低秩适配器", "神经架构搜索"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 273 (char 365). Line: 406.
Append: [Low-Rank Adapters Meet Neural Architecture Search for LLM Compression](https://arxiv.org/abs/2501.16372)
Token length: 1246
Summarized using gpt-4o-mini
Append: [IndicMMLU-Pro：评估印地语言大型语言模型的新基准](https://arxiv.org/abs/2501.15747)
append_entries: 2
Finish: 2025-01-29 06:01:05.830486
------------------------------------------------------
Started: 2025-01-29 09:00:46.737857
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1171
Summarized using gpt-4o-mini
Append: [DiffSplat：基于文本和图像的3D生成功能框架](https://arxiv.org/abs/2501.16764)
Token length: 1308
Summarized using gpt-4o-mini
Append: [强化学习与有监督微调在模型泛化能力中的区别研究](https://arxiv.org/abs/2501.17161)
Token length: 1103
Summarized using gpt-4o-mini
Append: [FP4训练框架：应对大语言模型低比特算力挑战](https://arxiv.org/abs/2501.17116)
Token length: 915
Summarized using gpt-4o-mini
Append: [超标记化变换器：提升大型语言模型性能的新框架](https://arxiv.org/abs/2501.16975)
Token length: 960
Summarized using gpt-4o-mini
Append: [机械解释性领域的现状与挑战](https://arxiv.org/abs/2501.16496)
append_entries: 5
Finish: 2025-01-29 09:01:16.132672
------------------------------------------------------
Started: 2025-01-29 12:12:38.228379
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1388
Summarized using gpt-4o-mini
Append: [构建与人类价值观一致的法语数据集](https://arxiv.org/abs/2501.17117)
append_entries: 1
Finish: 2025-01-29 12:13:06.156666
------------------------------------------------------
Started: 2025-01-29 15:00:52.173253
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-29 15:00:52.366731
------------------------------------------------------
Started: 2025-01-29 18:00:54.687926
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-29 18:00:54.970072
------------------------------------------------------
Started: 2025-01-29 21:00:55.485575
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-29 21:00:55.691663
------------------------------------------------------
Started: 2025-01-30 00:33:11.405148
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-30 00:33:11.653974
------------------------------------------------------
Started: 2025-01-30 03:01:09.801796
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-30 03:01:10.042432
------------------------------------------------------
Started: 2025-01-30 06:00:40.813907
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1380
Summarized using gpt-4o-mini
Append: [批评微调：一种增强语言模型推理的新策略](https://arxiv.org/abs/2501.17703)
Token length: 1281
Summarized using gpt-4o-mini
Append: [Atla Selene Mini：新一代小型评估模型](https://arxiv.org/abs/2501.17195)
Token length: 1280
Summarized using gpt-4o-mini
Append: [大型语言模型安全性测试研究](https://arxiv.org/abs/2501.17749)
append_entries: 3
Finish: 2025-01-30 06:00:55.234822
------------------------------------------------------
Started: 2025-01-30 09:00:43.683743
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1061
Summarized using gpt-4o-mini
Append: [大型语言模型的安全性与有害微调攻击风险](https://arxiv.org/abs/2501.17433)
append_entries: 1
Finish: 2025-01-30 09:00:51.551842
------------------------------------------------------
Started: 2025-01-30 12:00:56.180109
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1592
Summarized using gpt-4o-mini
Append: [人工智能环境影响评估与净零目标的协调策略](https://arxiv.org/abs/2501.14334)
append_entries: 1
Finish: 2025-01-30 12:01:05.472942
------------------------------------------------------
Started: 2025-01-30 15:00:40.920846
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-30 15:00:41.073944
------------------------------------------------------
Started: 2025-01-30 18:01:05.456118
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1134
Summarized using gpt-4o-mini
Append: [人类对AI生成文本的检测能力研究](https://arxiv.org/abs/2501.15654)
append_entries: 1
Finish: 2025-01-30 18:01:20.970802
------------------------------------------------------
Started: 2025-01-30 21:00:35.867710
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-30 21:00:36.019143
------------------------------------------------------
Started: 2025-01-31 00:33:52.072172
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-31 00:33:52.248170
------------------------------------------------------
Started: 2025-01-31 03:08:40.044889
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-31 03:08:40.189691
------------------------------------------------------
Started: 2025-01-31 06:00:42.121203
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1700
Summarized using gpt-4o-mini
Append: [提升视觉语言模型在物理世界理解上的能力](https://arxiv.org/abs/2501.16411)
Token length: 985
Summarized using gpt-4o-mini
Append: [GuardReasoner：提升大语言模型安全性的新方法](https://arxiv.org/abs/2501.18492)
append_entries: 2
Finish: 2025-01-31 06:00:53.704023
------------------------------------------------------
Started: 2025-01-31 09:00:46.020338
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1348
Summarized using gpt-4o-mini
Append: [应对大语言模型中的思维不足现象](https://arxiv.org/abs/2501.18585)
Token length: 1224
Summarized using gpt-4o-mini
Append: [大型语言模型在开放任务中的探索能力研究](https://arxiv.org/abs/2501.18009)
append_entries: 2
Finish: 2025-01-31 09:01:09.685277
------------------------------------------------------
Started: 2025-01-31 12:01:01.779784
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1491
Summarized using gpt-4o-mini
Append: [改进的分布式训练算法DiLoCo：降低带宽需求的突破](https://arxiv.org/abs/2501.18512)
Token length: 1259
Summarized using gpt-4o-mini
Append: [MedXpertQA: 全面评价医学专家知识的基准测试](https://arxiv.org/abs/2501.18362)
Token length: 914
Summarized using gpt-4o-mini
Append: [WILDCHAT-50M：扩展的公共聊天数据集及其性能分析](https://arxiv.org/abs/2501.18511)
Token length: 1256
Summarized using gpt-4o-mini
Append: [DeepSeek-R1与OpenAI o3-mini安全性评估对比](https://arxiv.org/abs/2501.18438)
append_entries: 4
Finish: 2025-01-31 12:01:36.063101
------------------------------------------------------
Started: 2025-01-31 15:00:52.216844
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-31 15:00:52.400210
------------------------------------------------------
Started: 2025-01-31 18:00:48.808824
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-31 18:00:49.000713
------------------------------------------------------
Started: 2025-01-31 21:00:42.237908
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1379
Summarized using gpt-4o-mini
Append: [CowPilot：人机协作的网页导航框架](https://arxiv.org/abs/2501.16609)
append_entries: 1
Finish: 2025-01-31 21:00:46.591477
------------------------------------------------------
Started: 2025-02-01 00:36:40.766792
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-01 00:36:40.968877
------------------------------------------------------
Started: 2025-02-01 03:12:42.214891
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-01 03:12:42.384032
------------------------------------------------------
Started: 2025-02-01 06:00:41.260317
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-01 06:00:41.492480
------------------------------------------------------
Started: 2025-02-01 09:00:48.444131
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1066
Summarized using gpt-4o-mini
Append: [SANA-1.5：文本到图像生成中的高效线性扩展变换器](https://arxiv.org/abs/2501.18427)
append_entries: 1
Finish: 2025-02-01 09:00:54.242705
------------------------------------------------------
Started: 2025-02-01 12:00:40.587395
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-01 12:00:40.772194
------------------------------------------------------
Started: 2025-02-01 15:01:02.097475
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-01 15:01:02.329273
------------------------------------------------------
Started: 2025-02-01 18:00:53.010783
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-01 18:00:53.256040
------------------------------------------------------
Started: 2025-02-01 21:00:54.284231
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-01 21:00:54.515753
------------------------------------------------------
Started: 2025-02-02 00:36:23.975721
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-02 00:36:24.165636
------------------------------------------------------
Started: 2025-02-02 03:10:25.090090
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-02 03:10:25.324920
------------------------------------------------------
Started: 2025-02-03 05:01:33.134254
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We introduce Reward-Guided Speculative Decoding (RSD), a novel framework aimed at improving the efficiency of inference in large language models (LLMs). RSD synergistically combines a lightweight draft model with a more powerful target model, incorporating a controlled bias to prioritize high-reward outputs, in contrast to existing speculative decoding methods that enforce strict unbiasedness. RSD employs a process reward model to evaluate intermediate decoding steps and dynamically decide whether to invoke the target model, optimizing the trade-off between computational cost and output quality. We theoretically demonstrate that a threshold-based mixture strategy achieves an optimal balance between resource utilization and performance. Extensive evaluations on challenging reasoning benchmarks, including Olympiad-level tasks, show that RSD delivers significant efficiency gains against decoding with the target model only (up to 4.4x fewer FLOPs), while achieving significant better accuracy than parallel decoding method on average (up to +3.5). These results highlight RSD as a robust and cost-effective approach for deploying LLMs in resource-intensive scenarios.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Reward-Guided Speculative Decoding for Efficient LLM Reasoning](https://arxiv.org/abs/2501.19324)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Test-time scaling is a promising new approach to language modeling that uses extra test-time compute to improve performance. Recently, OpenAI\'s o1 model showed this capability but did not publicly share its methodology, leading to many replication efforts. We seek the simplest approach to achieve test-time scaling and strong reasoning performance. First, we curate a small dataset s1K of 1,000 questions paired with reasoning traces relying on three criteria we validate through ablations: difficulty, diversity, and quality. Second, we develop budget forcing to control test-time compute by forcefully terminating the model\'s thinking process or lengthening it by appending "Wait" multiple times to the model\'s generation when it tries to end. This can lead the model to double-check its answer, often fixing incorrect reasoning steps. After supervised finetuning the Qwen2.5-32B-Instruct language model on s1K and equipping it with budget forcing, our model s1 exceeds o1-preview on competition math questions by up to 27% (MATH and AIME24). Further, scaling s1 with budget forcing allows extrapolating beyond its performance without test-time intervention: from 50% to 57% on AIME24. Our model, data, and code are open-source at https://github.com/simplescaling/s1.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [s1: Simple test-time scaling](https://arxiv.org/abs/2501.19393)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We conduct experiments on the impact of increasing inference-time compute in reasoning models (specifically OpenAI o1-preview and o1-mini) on their robustness to adversarial attacks. We find that across a variety of attacks, increased inference-time compute leads to improved robustness. In many cases (with important exceptions), the fraction of model samples where the attack succeeds tends to zero as the amount of test-time compute grows. We perform no adversarial training for the tasks we study, and we increase inference-time compute by simply allowing the models to spend more compute on reasoning, independently of the form of attack. Our results suggest that inference-time compute has the potential to improve adversarial robustness for Large Language Models. We also explore new attacks directed at reasoning models, as well as settings where inference-time compute does not improve reliability, and speculate on the reasons for these as well as ways to address them.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Trading Inference-Time Compute for Adversarial Robustness](https://arxiv.org/abs/2501.18841)
append_entries: 3
Finish: 2025-02-03 05:01:35.097640
------------------------------------------------------
Started: 2025-02-03 06:00:37.378172
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-03 06:00:37.682922
------------------------------------------------------
Started: 2025-02-03 09:00:57.174278
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1135
Summarized using gpt-4o-mini
Append: [应对大语言模型的普遍越狱攻击：宪法分类器的应用与效果](https://arxiv.org/abs/2501.18837)
append_entries: 1
Finish: 2025-02-03 09:01:13.953024
------------------------------------------------------
Started: 2025-02-03 12:12:41.230062
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1560
Summarized using gpt-4o-mini
Append: [基于多语言模型的新闻摘要性能评估](https://arxiv.org/abs/2501.18128)
Token length: 1459
Summarized using gpt-4o-mini
Append: [TracksTo4D：从动态视频重建3D结构的新方法](https://arxiv.org/abs/2404.07097)
Token length: 1688
Summarized using gpt-4o-mini
Append: [DINO世界模型：无需重建视觉世界的视觉动态建模](https://arxiv.org/abs/2411.04983)
append_entries: 3
Finish: 2025-02-03 12:12:58.973533
------------------------------------------------------
Started: 2025-02-03 15:00:44.556969
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1124
Summarized using gpt-4o-mini
Append: [将知识图谱与大语言模型无缝集成的量化表示方法](https://arxiv.org/abs/2501.18119)
Token length: 1324
Summarized using gpt-4o-mini
Append: [针对任务通用提示的实例特定负样本挖掘方法](https://arxiv.org/abs/2501.18753)
append_entries: 2
Finish: 2025-02-03 15:01:01.093051
------------------------------------------------------
Started: 2025-02-03 18:01:09.061213
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 702
Summarized using gpt-4o-mini
Append: [学习率调度在大模型训练中的优化理论应用](https://arxiv.org/abs/2501.18965)
Token length: 1521
Summarized using gpt-4o-mini
Append: [统一视觉与文本输入的像素感知框架研究](https://arxiv.org/abs/2501.19339)
append_entries: 2
Finish: 2025-02-03 18:01:20.408966
------------------------------------------------------
Started: 2025-02-03 21:01:05.151565
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-03 21:01:05.422277
------------------------------------------------------
Started: 2025-02-04 00:34:00.422193
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1318
Summarized using gpt-4o-mini
Append: [SAeUron：通过稀疏自编码器优化扩散模型中的不当内容去除](https://arxiv.org/abs/2501.18052)
Token length: 1331
Summarized using gpt-4o-mini
Append: [基于扩散模型的多视点图像和深度图生成方法](https://arxiv.org/abs/2501.18804)
Token length: 967
Summarized using gpt-4o-mini
Append: [MatAnyone: 一种针对特定目标的视频抠图框架](https://arxiv.org/abs/2501.14677)
Token length: 1262
Summarized using gpt-4o-mini
Append: [SSMax：一种提升Transformer模型长文本处理能力的可扩展Softmax方法](https://arxiv.org/abs/2501.19399)
append_entries: 4
Finish: 2025-02-04 00:34:33.504199
------------------------------------------------------
Started: 2025-02-04 03:09:34.242814
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-04 03:09:34.509592
------------------------------------------------------
Started: 2025-02-04 06:10:56.646912
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1460
Summarized using gpt-4o-mini
Append: [提高潜在一致性模型质量的研究与方法](https://arxiv.org/abs/2502.01441)
Token length: 1387
Summarized using gpt-4o-mini
Append: [AIN：开创阿拉伯语多模态模型的新纪元](https://arxiv.org/abs/2502.00094)
append_entries: 2
Finish: 2025-02-04 06:11:08.227123
------------------------------------------------------
Started: 2025-02-04 09:00:52.097677
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1303
Summarized using gpt-4o-mini
Append: [偏好泄漏：LLM作为评判者的数据注释问题探讨](https://arxiv.org/abs/2502.01534)
Token length: 1307
Summarized using gpt-4o-mini
Append: [ENCORE：提升知识编辑的模型性能与速度](https://arxiv.org/abs/2502.01636)
Token length: 1347
Summarized using gpt-4o-mini
Append: [FastKV：提升长上下文序列的KV缓存压缩与延迟性能](https://arxiv.org/abs/2502.01068)
Token length: 1322
Summarized using gpt-4o-mini
Append: [OmniHuman：基于扩散转化器的高真实感人类视频生成框架](https://arxiv.org/abs/2502.01061)
Token length: 1324
Summarized using gpt-4o-mini
Append: [ZebraLogic：评估大型语言模型逻辑推理能力的框架](https://arxiv.org/abs/2502.01100)
Token length: 1452
Summarized using gpt-4o-mini
Append: [OpenAI o1与o3模型在多模态推理能力上的演变与挑战](https://arxiv.org/abs/2502.01081)
Token length: 902
Summarized using gpt-4o-mini
Append: [SCONE: 可扩展上下文化n-gram嵌入方法提升语言模型性能](https://arxiv.org/abs/2502.01637)
Token length: 1095
Summarized using gpt-4o-mini
Append: [基于模型的强化学习在Craftax经典基准上的突破性应用](https://arxiv.org/abs/2502.01591)
Token length: 1497
Summarized using gpt-4o-mini
Append: [PRIME：通过隐式过程奖励优化大语言模型的训练](https://arxiv.org/abs/2502.01456)
append_entries: 9
Finish: 2025-02-04 09:01:53.941335
------------------------------------------------------
Started: 2025-02-04 12:01:02.650519
Existing_entries: 1009
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1051
Summarized using gpt-4o-mini
Append: [基于马尔可夫决策过程的语言模型安全生成方法](https://arxiv.org/abs/2502.01208)
Token length: 1185
Summarized using gpt-4o-mini
Append: [基于普通知识的推理模型基准测试](https://arxiv.org/abs/2502.01584)
Token length: 1697
Summarized using gpt-4o-mini
Append: [病理基础模型的鲁棒性评估及临床应用前景](https://arxiv.org/abs/2501.18055)
Token length: 913
Summarized using gpt-4o-mini
Append: [DeepRAG：优化检索增强推理的新框架](https://arxiv.org/abs/2502.01142)
Token length: 1022
Summarized using gpt-4o-mini
Append: [利用ViLU-Net提高腹膜后肿瘤的自动分割效率](https://arxiv.org/abs/2502.00314)
Token length: 1153
Summarized using gpt-4o-mini
Append: [SafeRAG：评估检索增强生成模型的安全性](https://arxiv.org/abs/2501.18636)
Token length: 1193
Summarized using gpt-4o-mini
Append: [直接对齐算法在模型对齐中的应用与改进](https://arxiv.org/abs/2502.01237)
append_entries: 7
Finish: 2025-02-04 12:01:43.425580
------------------------------------------------------
Started: 2025-02-04 15:00:54.840016
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1097
Summarized using gpt-4o-mini
Append: [提出MM-IQ：多模态系统认知能力评估框架](https://arxiv.org/abs/2502.00698)
Token length: 1172
Summarized using gpt-4o-mini
Append: [SliderSpace: 一种可控的扩散模型视觉能力自动分解框架](https://arxiv.org/abs/2502.01639)
append_entries: 2
Finish: 2025-02-04 15:01:07.931795
------------------------------------------------------
Started: 2025-02-04 18:00:58.678034
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-04 18:00:58.919135
------------------------------------------------------
Started: 2025-02-04 21:01:19.362943
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1153
Summarized using gpt-4o-mini
Append: [AlignVLM: 视觉文本对齐的新方法](https://arxiv.org/abs/2502.01341)
append_entries: 1
Finish: 2025-02-04 21:01:26.066975
------------------------------------------------------
Started: 2025-02-05 00:34:22.899420
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-05 00:34:23.083590
------------------------------------------------------
Started: 2025-02-05 03:11:24.108910
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1114
Summarized using gpt-4o-mini
Append: [通过过程监督提升长文生成质量](https://arxiv.org/abs/2502.02095)
Token length: 1302
Summarized using gpt-4o-mini
Append: [MakeAnything：针对多域程序生成的创新框架](https://arxiv.org/abs/2502.01572)
Token length: 1540
Summarized using gpt-4o-mini
Append: [RandLoRA：克服低秩适应的局限性并提高模型性能](https://arxiv.org/abs/2502.00987)
Token length: 1414
Summarized using gpt-4o-mini
Append: [UTGen: 提高单位测试生成与调试的有效性](https://arxiv.org/abs/2502.01619)
Token length: 1695
Summarized using gpt-4o-mini
Append: [相对信心估计在语言模型中的应用研究](https://arxiv.org/abs/2502.01126)
append_entries: 5
Finish: 2025-02-05 03:11:49.646476
------------------------------------------------------
Started: 2025-02-05 06:01:06.323385
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-05 06:01:06.573316
------------------------------------------------------
Started: 2025-02-05 09:00:54.263039
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1097
Summarized using gpt-4o-mini
Append: [加速扩散桥接模型的推理效果](https://arxiv.org/abs/2502.01362)
Token length: 1108
Summarized using gpt-4o-mini
Append: [改进的文本到图像模型定制方法](https://arxiv.org/abs/2502.01720)
Token length: 1481
Summarized using gpt-4o-mini
Append: [VideoJAM：提升视频生成模型运动一致性的框架](https://arxiv.org/abs/2502.02492)
Token length: 1370
Summarized using gpt-4o-mini
Append: [KV缓存压缩方法对大型语言模型能力的影响研究](https://arxiv.org/abs/2502.01941)
Token length: 1330
Summarized using gpt-4o-mini
Append: [利用强化学习提升编程模型的训练效果](https://arxiv.org/abs/2502.01718)
Token length: 1363
Summarized using gpt-4o-mini
Append: [QLASS：增强语言代理的步进搜索策略](https://arxiv.org/abs/2502.02584)
Token length: 1407
Summarized using gpt-4o-mini
Append: [Satori：通过链式行动思维提升大语言模型的推理能力](https://arxiv.org/abs/2502.02508)
append_entries: 7
Finish: 2025-02-05 09:01:49.174633
------------------------------------------------------
Started: 2025-02-05 12:12:49.357607
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-05 12:12:49.516033
------------------------------------------------------
Started: 2025-02-05 15:00:59.349108
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-05 15:00:59.533333
------------------------------------------------------
Started: 2025-02-05 18:00:52.296113
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1341
Summarized using gpt-4o-mini
Append: [基于采样的搜索：规模化趋势及自我验证能力的提升](https://arxiv.org/abs/2502.01839)
Token length: 1534
Summarized using gpt-4o-mini
Append: [Self-MoA: 提升大型语言模型性能的新方法](https://arxiv.org/abs/2502.00674)
Token length: 1154
Summarized using gpt-4o-mini
Append: [基于k稀疏自编码器的文本到图像生成模型概念操控框架](https://arxiv.org/abs/2501.19066)
append_entries: 3
Finish: 2025-02-05 18:01:10.607968
------------------------------------------------------
Started: 2025-02-05 21:01:17.509069
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-05 21:01:17.696403
------------------------------------------------------
Started: 2025-02-06 00:34:38.893565
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1109
Summarized using gpt-4o-mini
Append: [COCONut-PanCap数据集：提升全景分割与图像描述的革新](https://arxiv.org/abs/2502.02589)
append_entries: 1
Finish: 2025-02-06 00:34:43.988434
------------------------------------------------------
Started: 2025-02-06 03:11:28.502092
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1211
Summarized using gpt-4o-mini
Append: [大型语言模型激活近似的安全性评估](https://arxiv.org/abs/2502.00840)
Token length: 1336
Summarized using gpt-4o-mini
Append: [FSLoRA: 针对设备异构性的联合微调方法](https://arxiv.org/abs/2501.19389)
append_entries: 2
Finish: 2025-02-06 03:11:41.645864
------------------------------------------------------
Started: 2025-02-06 06:00:51.045741
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1430
Summarized using gpt-4o-mini
Append: [CADFusion：基于大型语言模型的文本到CAD转换框架](https://arxiv.org/abs/2501.19054)
append_entries: 1
Finish: 2025-02-06 06:00:55.714248
------------------------------------------------------
Started: 2025-02-06 09:00:44.182336
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1162
Summarized using gpt-4o-mini
Append: [基于潜在离散令牌的混合推理表示方法](https://arxiv.org/abs/2502.03275)
Token length: 1851
Summarized using gpt-4o-mini
Append: [挑战传统认知：LIMO模型在复杂推理中的突破](https://arxiv.org/abs/2502.03387)
Token length: 1238
Summarized using gpt-4o-mini
Append: [SmolLM2：高效的小型语言模型开发](https://arxiv.org/abs/2502.02737)
Token length: 1542
Summarized using gpt-4o-mini
Append: [基于粒子蒙特卡洛方法的推理时间缩放新方法](https://arxiv.org/abs/2502.01618)
Token length: 1577
Summarized using gpt-4o-mini
Append: [增强大语言模型推理能力的长链思维研究](https://arxiv.org/abs/2502.03373)
Token length: 1345
Summarized using gpt-4o-mini
Append: [AStar：基于蒙特卡洛树搜索的多模态推理新范式](https://arxiv.org/abs/2502.02339)
Token length: 1262
Summarized using gpt-4o-mini
Append: [利用大型语言模型模拟社会经济系统的多智能体框架](https://arxiv.org/abs/2502.01506)
append_entries: 7
Finish: 2025-02-06 09:01:20.554692
------------------------------------------------------
Started: 2025-02-06 12:12:49.346248
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 880
Summarized using gpt-4o-mini
Append: [利用JUMP与DUMP技术对大型语言模型进行越狱与防御](https://arxiv.org/abs/2502.01154)
Token length: 1071
Summarized using gpt-4o-mini
Append: [LayerTracer：认知对齐分层SVG生成框架](https://arxiv.org/abs/2502.01105)
append_entries: 2
Finish: 2025-02-06 12:12:56.351644
------------------------------------------------------
Started: 2025-02-06 15:00:53.904115
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1523
Summarized using gpt-4o-mini
Append: [语言模型知识蒸馏中的教师黑客现象研究](https://arxiv.org/abs/2502.02671)
append_entries: 1
Finish: 2025-02-06 15:01:12.657555
------------------------------------------------------
Started: 2025-02-06 18:01:09.483926
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1049
Summarized using gpt-4o-mini
Append: [PyCapsule：高效的自动代码生成框架](https://arxiv.org/abs/2502.02928)
append_entries: 1
Finish: 2025-02-06 18:01:14.824851
------------------------------------------------------
Started: 2025-02-06 21:01:53.284251
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1206
Summarized using gpt-4o-mini
Append: [针对RAG系统的成员推断攻击：自然文本查询的隐蔽性与有效性](https://arxiv.org/abs/2502.00306)
append_entries: 1
Finish: 2025-02-06 21:02:13.272481
------------------------------------------------------
Started: 2025-02-07 00:34:30.787791
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1088
Summarized using gpt-4o-mini
Append: [大型语言模型在软件开发任务中的一致性评估](https://arxiv.org/abs/2502.00226)
Token length: 1103
Summarized using gpt-4o-mini
Append: [激活信息合并：提升大语言模型性能的创新方法](https://arxiv.org/abs/2502.02421)
append_entries: 2
Finish: 2025-02-07 00:34:40.708120
------------------------------------------------------
Started: 2025-02-07 03:12:18.847841
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-07 03:12:19.060150
------------------------------------------------------
Started: 2025-02-07 06:01:07.003517
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-07 06:01:07.204138
------------------------------------------------------
Started: 2025-02-07 09:00:44.925981
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1268
Summarized using gpt-4o-mini
Append: [MAGA框架：解决大型语言模型预训练数据稀缺问题](https://arxiv.org/abs/2502.04235)
Json decode failed:
{
  "title": "Ola: 开创全模态理解的语言模型",
  "keyword": ["全模态模型", "图像理解", "多模态学习"],
  "short_summary": "Ola是一种竞争力强的全模态语言模型，提升了多种模态的理解能力。",
  "summary": "本文介绍了Ola，一个新型的全模态语言模型，能够在图像、视频和音频理解方面与专门的单模态模型竞争。Ola采用渐进的模态对齐策略，先通过图像和文本的训练建立基础，再加入语音和视频数据以扩展模型技能。该训练管道可以保持跨模态对齐数据相对较小，从而简化现有视觉-语言模型向全模态模型的开发，并降低成本。同时，为了实现类似于GPT-4o的交互体验，Ola还设计了一种逐句解码方案以实现流式语音生成。实验证明，Ola在所有模态方面超越现有的开放全模态语言模型，并在类似规模的专门模型中也表现出高度竞争力。我们希望Ola能成为一个完全开放的全模态理解解决方案，推动这一新兴领域的未来研究。模型权重、代码和数据已在https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 321 (char 450). Line: 406.
Append: [Ola: Pushing the Frontiers of Omni-Modal Language Model with Progressive Modality Alignment](https://arxiv.org/abs/2502.04328)
Token length: 1301
Summarized using gpt-4o-mini
Append: [动态内容增强技术在实景视频中的应用](https://arxiv.org/abs/2502.03621)
Token length: 1125
Summarized using gpt-4o-mini
Append: [基于3D几何的动态视频生成框架](https://arxiv.org/abs/2502.03639)
Token length: 1563
Summarized using gpt-4o-mini
Append: [MotionCanvas: 用户驱动的图像到视频生成镜头设计方法](https://arxiv.org/abs/2502.04299)
Token length: 1685
Summarized using gpt-4o-mini
Append: [全新统一框架MotionLab在人体动作生成与编辑中的应用](https://arxiv.org/abs/2502.02358)
Token length: 1354
Summarized using gpt-4o-mini
Append: [AlphaGeometry2：超越金牌选手的自动几何问题求解系统](https://arxiv.org/abs/2502.03544)
Token length: 1453
Summarized using gpt-4o-mini
Append: [通过单层变换器架构优化语音合成的计算扩展](https://arxiv.org/abs/2502.04128)
Token length: 934
Summarized using gpt-4o-mini
Append: [基于人类反馈的政策插值学习方法](https://arxiv.org/abs/2502.04270)
Token length: 1713
Summarized using gpt-4o-mini
Append: [BOLT：无须知识蒸馏的长链思维能力提升方法](https://arxiv.org/abs/2502.03860)
Token length: 999
Summarized using gpt-4o-mini
Append: [ScoreFlow：基于梯度优化的多智能体系统自动化工作流优化框架](https://arxiv.org/abs/2502.04306)
Token length: 1324
Summarized using gpt-4o-mini
Append: [提升大语言模型指令跟随能力的UltraIF方法](https://arxiv.org/abs/2502.04153)
Json decode failed:
{
  "title": "内容-格式集成提示优化方法研究",
  "keyword": ["大型语言模型", "提示设计", "CFPO"],
  "short_summary": "提出了一种内容与格式联合优化的提示设计方法CFPO，以提升大型语言模型的性能。",
  "summary": "本文介绍了一种新的提示优化方法——内容-格式集成提示优化（CFPO），该方法通过迭代优化过程同时优化提示的内容和格式。尽管近年来研究主要集中在优化提示内容，提示格式这一重要维度却鲜有系统性探讨。CFPO利用自然语言变异探索内容变化，并采用动态格式探索策略系统性评估不同格式选择。我们在多个任务和开源大型语言模型上进行的广泛评估表明，CFPO相对于仅优化内容的方法显示出可测量的性能提升，强调了集成内容与格式优化的重要性，并提供了一种实用的模型不可知性的方法来增强大型语言模型的表现。相关代码将发布在 https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 271 (char 405). Line: 406.
Append: [Beyond Prompt Content: Enhancing LLM Performance via Content-Format Integrated Prompt Optimization](https://arxiv.org/abs/2502.04295)
Token length: 948
Summarized using gpt-4o-mini
Append: [异构masked自回归模型用于机器人学习中的视频动态建模](https://arxiv.org/abs/2502.04296)
append_entries: 14
Finish: 2025-02-07 09:01:58.572239
------------------------------------------------------
Started: 2025-02-07 12:00:48.994089
Existing_entries: 1014
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 985
Summarized using gpt-4o-mini
Append: [ChartCitor：增强大语言模型的图表问答能力](https://arxiv.org/abs/2502.00989)
Token length: 1129
Summarized using gpt-4o-mini
Append: [语言模型监督能力的进展与相似性影响](https://arxiv.org/abs/2502.04313)
Token length: 1271
Summarized using gpt-4o-mini
Append: [大型语言模型的安全脆弱性与恶意攻击研究](https://arxiv.org/abs/2502.04322)
Token length: 946
Summarized using gpt-4o-mini
Append: [基于稀疏自编码器的跨层特征映射与控制方法](https://arxiv.org/abs/2502.03032)
append_entries: 4
Finish: 2025-02-07 12:01:19.241139
------------------------------------------------------
Started: 2025-02-07 15:00:48.960396
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1648
Summarized using gpt-4o-mini
Append: [Weak-to-Strong Diffusion框架实现生成模型性能提升](https://arxiv.org/abs/2502.00473)
Token length: 1421
Summarized using gpt-4o-mini
Append: [PlotGen：自动化科学数据可视化的多智能体框架](https://arxiv.org/abs/2502.00988)
Token length: 1879
Summarized using gpt-4o-mini
Append: [提升大型语言模型在低资源编程语言中的代码生成性能研究](https://arxiv.org/abs/2501.19085)
append_entries: 3
Finish: 2025-02-07 15:01:09.458583
------------------------------------------------------
Started: 2025-02-07 18:00:58.244761
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-07 18:00:58.493534
------------------------------------------------------
Started: 2025-02-07 21:00:36.008527
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1176
Summarized using gpt-4o-mini
Append: [ConceptAttention：增强多模态扩散转换器的可解释性](https://arxiv.org/abs/2502.04320)
append_entries: 1
Finish: 2025-02-07 21:00:41.644283
------------------------------------------------------
Started: 2025-02-08 00:33:15.262506
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-08 00:33:15.484938
------------------------------------------------------
Started: 2025-02-08 03:09:21.209061
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-08 03:09:21.496714
------------------------------------------------------
Started: 2025-02-08 06:00:56.740572
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-08 06:00:57.035193
------------------------------------------------------
Started: 2025-02-08 09:00:43.819376
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-08 09:00:44.001692
------------------------------------------------------
Started: 2025-02-08 12:10:42.303344
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-08 12:10:42.473568
------------------------------------------------------
Started: 2025-02-08 15:00:40.184724
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-08 15:00:40.442052
------------------------------------------------------
Started: 2025-02-08 18:00:38.420332
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-08 18:00:38.606993
------------------------------------------------------
Started: 2025-02-08 21:01:01.109177
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-08 21:01:01.409790
------------------------------------------------------
Started: 2025-02-09 00:37:00.305394
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-09 00:37:00.520479
------------------------------------------------------
Started: 2025-02-09 03:12:30.515724
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-09 03:12:30.802876
------------------------------------------------------
Started: 2025-02-09 06:00:48.654226
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-09 06:00:49.012638
------------------------------------------------------
Started: 2025-02-09 09:01:00.110212
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-09 09:01:00.344273
------------------------------------------------------
Started: 2025-02-09 12:11:05.946135
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-09 12:11:06.233549
------------------------------------------------------
Started: 2025-02-09 15:00:44.283634
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-09 15:00:44.518588
------------------------------------------------------
Started: 2025-02-09 18:01:02.487882
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-09 18:01:02.864906
------------------------------------------------------
Started: 2025-02-09 21:00:56.066203
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-09 21:00:56.343904
------------------------------------------------------
Started: 2025-02-10 00:35:52.830696
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-10 00:35:53.112954
------------------------------------------------------
Started: 2025-02-10 03:13:18.978905
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-10 03:13:19.249563
------------------------------------------------------
Started: 2025-02-10 06:00:46.361293
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-10 06:00:46.559066
------------------------------------------------------
Started: 2025-02-10 09:00:46.787309
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1054
Summarized using gpt-4o-mini
Append: [量化语言-图像预训练方法QLIP的研究](https://arxiv.org/abs/2502.05178)
Token length: 1363
Summarized using gpt-4o-mini
Append: [大语言模型在会议代理中的应用与挑战](https://arxiv.org/abs/2502.04376)
Token length: 1505
Summarized using gpt-4o-mini
Append: [基于强化学习的多语言安全防护模型生成框架](https://arxiv.org/abs/2502.05163)
Token length: 1378
Summarized using gpt-4o-mini
Append: [FlashVideo：一种双阶段框架提升文本到视频生成的效率与质量](https://arxiv.org/abs/2502.05179)
Token length: 1277
Summarized using gpt-4o-mini
Append: [滑动块注意力：提升视频生成效率的新方法](https://arxiv.org/abs/2502.04507)
Token length: 1114
Summarized using gpt-4o-mini
Append: [AuraFusion360：高质量三维场景补全的新方法](https://arxiv.org/abs/2502.05176)
Token length: 857
Summarized using gpt-4o-mini
Append: [Goku模型：图像与视频生成的新标杆](https://arxiv.org/abs/2502.04896)
Token length: 1725
Summarized using gpt-4o-mini
Append: [On-device Sora：基于扩散模型的手机端文本转视频生成](https://arxiv.org/abs/2502.04363)
Token length: 1167
Summarized using gpt-4o-mini
Append: [语言模型中的知识构成线性相关性研究](https://arxiv.org/abs/2502.04520)
Token length: 812
Summarized using gpt-4o-mini
Append: [一种新型语言模型架构的研究](https://arxiv.org/abs/2502.05171)
Token length: 1556
Summarized using gpt-4o-mini
Append: [基于PDDL的高效规划领域生成方法](https://arxiv.org/abs/2502.04728)
Token length: 955
Summarized using gpt-4o-mini
Append: [探索代理性：框架依赖性与强化学习的关系](https://arxiv.org/abs/2502.04403)
Token length: 1253
Summarized using gpt-4o-mini
Append: [新型自回溯机制提升大语言模型推理能力](https://arxiv.org/abs/2502.04404)
Token length: 1334
Summarized using gpt-4o-mini
Append: [VideoRoPE: 高效视频旋转位置嵌入的新方法](https://arxiv.org/abs/2502.05173)
Token length: 1355
Summarized using gpt-4o-mini
Append: [CodeSteer: 提升大型语言模型代码生成与文本推理能力的方法](https://arxiv.org/abs/2502.04350)
append_entries: 15
Finish: 2025-02-10 09:02:19.380972
------------------------------------------------------
Started: 2025-02-10 12:12:59.344861
Existing_entries: 1015
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-10 12:12:59.512920
------------------------------------------------------
Started: 2025-02-10 15:00:55.681890
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1192
Summarized using gpt-4o-mini
Append: [有效的多任务模型合并框架](https://arxiv.org/abs/2502.04959)
Token length: 1186
Summarized using gpt-4o-mini
Append: [CMoE：从稠密模型高效切 carve Mixture-of-Experts](https://arxiv.org/abs/2502.04416)
Token length: 1055
Summarized using gpt-4o-mini
Append: [ARR：提升大语言模型问答能力的新型零-shot提示方法](https://arxiv.org/abs/2502.04689)
Token length: 1667
Summarized using gpt-4o-mini
Append: [QuEST：基于4位权重的量化感知训练方法](https://arxiv.org/abs/2502.05003)
Token length: 1498
Summarized using gpt-4o-mini
Append: [深入探讨视觉Transformer中的patchification信息损失及其影响](https://arxiv.org/abs/2502.03738)
Token length: 1251
Summarized using gpt-4o-mini
Append: [YinYangAlign：提升文本图像系统对齐精准度的基准框架](https://arxiv.org/abs/2502.03512)
append_entries: 6
Finish: 2025-02-10 15:01:51.154751
------------------------------------------------------
Started: 2025-02-10 18:00:47.548719
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1024
Summarized using gpt-4o-mini
Append: [视觉时间理解能力的挑战：对多模态大语言模型的研究](https://arxiv.org/abs/2502.05092)
append_entries: 1
Finish: 2025-02-10 18:00:51.459779
------------------------------------------------------
Started: 2025-02-10 21:00:44.082835
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1325
Summarized using gpt-4o-mini
Append: [机器学习中可预测的深度强化学习方法的规模扩展](https://arxiv.org/abs/2502.04327)
append_entries: 1
Finish: 2025-02-10 21:00:48.056683
------------------------------------------------------
Started: 2025-02-11 00:34:25.171727
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1153
Summarized using gpt-4o-mini
Append: [CUT3R: 持续更新的3D重建框架](https://arxiv.org/abs/2501.12387)
append_entries: 1
Finish: 2025-02-11 00:34:28.719098
------------------------------------------------------
Started: 2025-02-11 03:12:19.586010
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 919
Summarized using gpt-4o-mini
Append: [VectorQ：动态阈值框架提升语义缓存的效率](https://arxiv.org/abs/2502.03771)
Token length: 1327
Summarized using gpt-4o-mini
Append: [SPARC：轻量级持续学习框架用于大语言模型](https://arxiv.org/abs/2502.02909)
Token length: 1834
Summarized using gpt-4o-mini
Append: [自主边缘计算在机器人和智能城市中的应用](https://arxiv.org/abs/2502.02692)
append_entries: 3
Finish: 2025-02-11 03:12:39.732171
------------------------------------------------------
Started: 2025-02-11 06:02:30.333854
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1131
Summarized using gpt-4o-mini
Append: [层次化草拟方法加速大型语言模型推理](https://arxiv.org/abs/2502.05609)
Token length: 1328
Summarized using gpt-4o-mini
Append: [ReasonFlux-32B：通过层次化思维模板优化推理能力](https://arxiv.org/abs/2502.06772)
Token length: 1206
Summarized using gpt-4o-mini
Append: [EVEv2.0：高效的无编码视觉语言模型](https://arxiv.org/abs/2502.06788)
Token length: 1452
Summarized using gpt-4o-mini
Append: [双重标题偏好优化：提升文本到图像扩散模型的图像质量](https://arxiv.org/abs/2502.06023)
Token length: 1407
Summarized using gpt-4o-mini
Append: [自适应并行编码技术提升上下文增强生成的效率](https://arxiv.org/abs/2502.05431)
Json decode failed:
{
  "title": "Steel-LLM：面向中文的开源语言模型开发",
  "short_summary": "Steel-LLM项目致力于开发高质量的中文语言模型。",
  "summary": "Steel-LLM是一个以中文为中心的语言模型，旨在尽管计算资源有限仍能开发出高质量的开源模型。该项目于2024年3月启动，计划训练一个包含10亿参数的模型，使用大规模数据集，强调透明度和实践经验分享，以帮助社区中的其他开发者。训练过程中主要使用中文数据，并少量包含英语数据，旨在填补现有开源LMM的空白，提供更详细的模型构建过程。Steel-LLM在CEVAL和CMMLU等基准测试中表现出色，超越了来自更大机构的早期模型。本文全面总结了项目的关键贡献，包括数据收集、模型设计、训练方法和所遇挑战，成为希望开发自身LMM的研究者和实践者的重要资源。模型检查点和训练脚本可在https:
  "keyword": [
    "中文语言模型",
    "开源项目",
    "Steel-LLM"
  ]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 308 (char 397). Line: 406.
Append: [Steel-LLM:From Scratch to Open Source -- A Personal Journey in Building a Chinese-Centric LLM](https://arxiv.org/abs/2502.06635)
Token length: 1360
Summarized using gpt-4o-mini
Append: [LM2: 一种增强记忆模块的变压器架构](https://arxiv.org/abs/2502.06049)
Token length: 1444
Summarized using gpt-4o-mini
Append: [提升Diffusion Transformers视频生成效率的方法](https://arxiv.org/abs/2502.06155)
Token length: 1563
Summarized using gpt-4o-mini
Append: [VISTA：减轻大规模视觉语言模型的幻觉现象](https://arxiv.org/abs/2502.03628)
append_entries: 9
Finish: 2025-02-11 06:03:29.499332
------------------------------------------------------
Started: 2025-02-11 09:00:50.862125
Existing_entries: 1009
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1347
Summarized using gpt-4o-mini
Append: [Show-o Turbo：提升多模态生成模型的效率](https://arxiv.org/abs/2502.05415)
Token length: 1697
Summarized using gpt-4o-mini
Append: [MetaChain：通过自然语言构建 LLM 代理的全自动框架](https://arxiv.org/abs/2502.05957)
Token length: 1406
Summarized using gpt-4o-mini
Append: [Matryoshka量化：一种创新的多尺度量化技术](https://arxiv.org/abs/2502.06786)
Token length: 1332
Summarized using gpt-4o-mini
Append: [Lumina-Video: 基于Next-DiT的视频生成框架](https://arxiv.org/abs/2502.06782)
Token length: 1267
Summarized using gpt-4o-mini
Append: [基于DFoT的视频扩散生成与历史指导](https://arxiv.org/abs/2502.06764)
Token length: 1536
Summarized using gpt-4o-mini
Append: [CustomVideoX：基于视频扩散变换器的个性化视频生成框架](https://arxiv.org/abs/2502.06527)
Token length: 1524
Summarized using gpt-4o-mini
Append: [测试时间扩展对大型语言模型性能的影响分析](https://arxiv.org/abs/2502.06703)
Token length: 1771
Summarized using gpt-4o-mini
Append: [OREAL：基于结果奖励的数学推理强化学习框架](https://arxiv.org/abs/2502.06781)
append_entries: 8
Finish: 2025-02-11 09:01:35.316151
------------------------------------------------------
Started: 2025-02-11 12:00:46.525574
Existing_entries: 1008
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1506
Summarized using gpt-4o-mini
Append: [深度的诅咒：改善大语言模型训练效能的层归一化缩放](https://arxiv.org/abs/2502.05795)
Token length: 1545
Summarized using gpt-4o-mini
Append: [通过自然语言训练多智能体有效沟通](https://arxiv.org/abs/2502.06060)
Token length: 973
Summarized using gpt-4o-mini
Append: [生成多语种平行文本去毒化数据的新方法](https://arxiv.org/abs/2502.06394)
Token length: 1125
Summarized using gpt-4o-mini
Append: [DreamDPO：基于人类偏好的3D内容生成框架](https://arxiv.org/abs/2502.04370)
append_entries: 4
Finish: 2025-02-11 12:01:14.075525
------------------------------------------------------
Started: 2025-02-11 15:00:46.701935
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-11 15:00:46.873812
------------------------------------------------------
Started: 2025-02-11 18:00:57.908161
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Summarization failed, append the original article
error: 'NoneType' object has no attribute 'group'. Line: 406.
Append: [CODESIM: Multi-Agent Code Generation and Problem Solving through Simulation-Driven Planning and Debugging](https://arxiv.org/abs/2502.05664)
append_entries: 1
Finish: 2025-02-11 18:01:02.690119
------------------------------------------------------
Started: 2025-02-11 21:00:38.086387
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-11 21:00:38.387507
------------------------------------------------------
Started: 2025-02-12 00:34:09.952241
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1433
Summarized using gpt-4o-mini
Append: [无须人工标注的互联网规模导航代理训练方法](https://arxiv.org/abs/2502.06776)
Token length: 1147
Summarized using gpt-4o-mini
Append: [开发新评价方法以提升语言条件机器人模型的安全性与效能](https://arxiv.org/abs/2411.18676)
append_entries: 2
Finish: 2025-02-12 00:34:22.176836
------------------------------------------------------
Started: 2025-02-12 03:11:20.981885
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1266
Summarized using gpt-4o-mini
Append: [Jakiro：提升猜测解码效率与准确性的混合推理策略](https://arxiv.org/abs/2502.06282)
append_entries: 1
Finish: 2025-02-12 03:11:25.331539
------------------------------------------------------
Started: 2025-02-12 06:00:51.339018
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1516
Summarized using gpt-4o-mini
Append: [Magic 1-For-1：高效的视频生成模型](https://arxiv.org/abs/2502.07701)
Token length: 1431
Summarized using gpt-4o-mini
Append: [揭示大语言模型的过拟合：C-BOD基准检测器](https://arxiv.org/abs/2502.07445)
Token length: 1535
Summarized using gpt-4o-mini
Append: [VidCRAFT3: 多视觉元素控件的图像到视频生成框架](https://arxiv.org/abs/2502.07531)
Token length: 1335
Summarized using gpt-4o-mini
Append: [CAD-Editor: 基于文本的计算机辅助设计编辑框架](https://arxiv.org/abs/2502.03997)
Token length: 773
Summarized using gpt-4o-mini
Append: [Enhance-A-Video：一种无训练的视频生成增强方法](https://arxiv.org/abs/2502.07508)
Token length: 1015
Summarized using gpt-4o-mini
Append: [大语言模型中的提示缓存及其隐私泄露风险](https://arxiv.org/abs/2502.07776)
Token length: 1652
Summarized using gpt-4o-mini
Append: [NatureLM：针对科学发现的序列基础模型](https://arxiv.org/abs/2502.07527)
Token length: 1141
Summarized using gpt-4o-mini
Append: [Hephaestus-Forge：提升LLM代理能力的大规模预训练数据集](https://arxiv.org/abs/2502.06589)
Token length: 1016
Summarized using gpt-4o-mini
Append: [百亿规模预训练视觉语言模型的潜力研究](https://arxiv.org/abs/2502.07617)
Token length: 1395
Summarized using gpt-4o-mini
Append: [CodeI/O：提升大语言模型推理能力的新方法](https://arxiv.org/abs/2502.07316)
Token length: 1738
Summarized using gpt-4o-mini
Append: [大规模语言模型在复杂推理中的长链思维训练研究](https://arxiv.org/abs/2502.07374)
Token length: 1330
Summarized using gpt-4o-mini
Append: [强化学习在大型语言模型上的应用及其在编程竞赛中的表现](https://arxiv.org/abs/2502.06807)
append_entries: 12
Finish: 2025-02-12 06:02:14.870733
------------------------------------------------------
Started: 2025-02-12 09:00:59.182078
Existing_entries: 1012
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1227
Summarized using gpt-4o-mini
Append: [FocalCodec：高效低比特率语音编解码器](https://arxiv.org/abs/2502.04465)
Token length: 929
Summarized using gpt-4o-mini
Append: [利用CTRL框架提升大语言模型生成代码的自我评估能力](https://arxiv.org/abs/2502.03492)
append_entries: 2
Finish: 2025-02-12 09:01:06.866491
------------------------------------------------------
Started: 2025-02-12 12:12:54.166263
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1630
Summarized using gpt-4o-mini
Append: [参数化技能扩展与组合框架的研究](https://arxiv.org/abs/2502.05932)
Token length: 1437
Summarized using gpt-4o-mini
Append: [Eclair：一种新型文档层次OCR文本提取工具](https://arxiv.org/abs/2502.04223)
Token length: 1506
Summarized using gpt-4o-mini
Append: [FailSafeQA：评估金融问答系统中LLM的鲁棒性与上下文意识](https://arxiv.org/abs/2502.06329)
append_entries: 3
Finish: 2025-02-12 12:13:13.054070
------------------------------------------------------
Started: 2025-02-12 15:01:05.038718
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1286
Summarized using gpt-4o-mini
Append: [Chain-of-Shot提示框架提升长视频理解能力](https://arxiv.org/abs/2502.06428)
Token length: 1012
Summarized using gpt-4o-mini
Append: [宽范围超参数对比例法则的影响研究](https://arxiv.org/abs/2502.06857)
Token length: 1389
Summarized using gpt-4o-mini
Append: [用于金融时间序列预测的检索增强生成框架](https://arxiv.org/abs/2502.05878)
Token length: 1491
Summarized using gpt-4o-mini
Append: [增强自回归预测的训练范式：掩码增强自回归预测（MEAP）](https://arxiv.org/abs/2502.07490)
append_entries: 4
Finish: 2025-02-12 15:01:35.111028
------------------------------------------------------
Started: 2025-02-12 18:10:06.141864
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1417
Summarized using gpt-4o-mini
Append: [Hypencoder：一种新型学习相关性评分的检索模型](https://arxiv.org/abs/2502.05364)
Token length: 1310
Summarized using gpt-4o-mini
Append: [Goedel-Prover：开源数学自动证明生成的新标杆](https://arxiv.org/abs/2502.07640)
Token length: 1122
Summarized using gpt-4o-mini
Append: [利用稀疏自编码器理解与操控视觉模型](https://arxiv.org/abs/2502.06755)
append_entries: 3
Finish: 2025-02-12 18:10:24.285330
------------------------------------------------------
Started: 2025-02-12 21:00:36.892564
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1146
Summarized using gpt-4o-mini
Append: [Pippo：从单张照片生成高分辨率人类视频的生成模型](https://arxiv.org/abs/2502.07785)
append_entries: 1
Finish: 2025-02-12 21:00:42.663860
------------------------------------------------------
Started: 2025-02-13 00:34:30.546908
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-13 00:34:30.723174
------------------------------------------------------
Started: 2025-02-13 03:11:55.734863
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-13 03:11:55.981399
------------------------------------------------------
Started: 2025-02-13 05:01:27.323809
Existing_entries: 0
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1550
Summarized using gpt-4o-mini
Append: [可学习的合规性放弃：提高大规模语言模型的决策可靠性](https://arxiv.org/abs/2502.06884)
Token length: 1146
Summarized using gpt-4o-mini
Append: [Pippo: 从单张照片生成高分辨率密集视频的多视角扩散模型](https://arxiv.org/abs/2502.07785)
Token length: 1417
Summarized using gpt-4o-mini
Append: [Hypencoder：一种新型请求编码器提升文档检索性能](https://arxiv.org/abs/2502.05364)
Token length: 1310
Summarized using gpt-4o-mini
Append: [Goedel-Prover：开源自动化数学证明生成的最优语言模型](https://arxiv.org/abs/2502.07640)
Token length: 1122
Summarized using gpt-4o-mini
Append: [通过稀疏自编码器理解与控制视觉模型](https://arxiv.org/abs/2502.06755)
Token length: 1286
Summarized using gpt-4o-mini
Append: [基于链式选片的长视频理解优化](https://arxiv.org/abs/2502.06428)
Token length: 1012
Summarized using gpt-4o-mini
Append: [深入探讨模型架构与超参数对缩放法则的影响](https://arxiv.org/abs/2502.06857)
Token length: 1389
Summarized using gpt-4o-mini
Append: [基于检索增强生成的金融时间序列预测框架](https://arxiv.org/abs/2502.05878)
Token length: 1491
Summarized using gpt-4o-mini
Append: [Mask-Enhanced Autoregressive Prediction：提升大型语言模型信息检索能力](https://arxiv.org/abs/2502.07490)
Token length: 1630
Summarized using gpt-4o-mini
Append: [参数化技能扩展与组合框架PSEC的研究](https://arxiv.org/abs/2502.05932)
Token length: 1437
Summarized using gpt-4o-mini
Append: [Eclair: 一种高效的文档级光学字符识别工具](https://arxiv.org/abs/2502.04223)
Token length: 1506
Summarized using gpt-4o-mini
Append: [FailSafeQA：评估金融领域LLM的鲁棒性与上下文意识的新基准](https://arxiv.org/abs/2502.06329)
Token length: 1227
Summarized using gpt-4o-mini
Append: [FocalCodec：一种高效的低比特率语音编解码器](https://arxiv.org/abs/2502.04465)
Token length: 929
Summarized using gpt-4o-mini
Append: [通过强化学习提升大语言模型的代码生成能力](https://arxiv.org/abs/2502.03492)
Json decode failed:
{
  "title": "Magic 1-For-1：高效视频生成模型",
  "keyword": ["视频生成", "模型优化", "扩散步骤蒸馏"],
  "short_summary": "本文介绍了一种高效的视频生成模型Magic 1-For-1，优化了内存消耗和延迟。",
  "summary": "本技术报告介绍了Magic 1-For-1 (Magic141)，一个优化内存占用和推理延迟的视频生成模型。该模型的核心思想是将文本到视频的生成任务分解为两个更简单的任务进行扩散步骤蒸馏：文本到图像生成和图像到视频生成。研究表明，使用相同的优化算法，图像到视频任务的收敛速度确实优于文本到视频任务。报告中还探讨了一系列优化技巧，从模型收敛速度、推理延迟加速和内存成本优化三个方面降低了图像到视频模型的训练计算成本。通过这些技术，我们能够在3秒内生成5秒的视频片段，并在一分钟内生成1分钟的视频，显著提高了视觉质量和动态效果。代码和模型参数可在 https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 293 (char 436). Line: 406.
Append: [Magic 1-For-1: Generating One Minute Video Clips within One Minute](https://arxiv.org/abs/2502.07701)
Token length: 1431
Summarized using gpt-4o-mini
Append: [Chameleon Benchmark Overfit Detector：评估大型语言模型的真实理解能力](https://arxiv.org/abs/2502.07445)
Token length: 1535
Summarized using gpt-4o-mini
Append: [VidCRAFT3: 一种精准控制多视觉元素的图像到视频生成框架](https://arxiv.org/abs/2502.07531)
Token length: 1335
Summarized using gpt-4o-mini
Append: [CAD-Editor: 基于文本的计算机辅助设计编辑框架](https://arxiv.org/abs/2502.03997)
Token length: 773
Summarized using gpt-4o-mini
Append: [Enhance-A-Video: 一种提升DiT生成视频的一体化方法](https://arxiv.org/abs/2502.07508)
Token length: 1015
Summarized using gpt-4o-mini
Append: [大语言模型中的提示缓存引发的隐私泄露风险](https://arxiv.org/abs/2502.07776)
Token length: 1652
Summarized using gpt-4o-mini
Append: [Nature语言模型：跨领域科学发现的基础模型](https://arxiv.org/abs/2502.07527)
Token length: 1141
Summarized using gpt-4o-mini
Append: [Hephaestus-Forge：提升LLM代理的预训练数据集](https://arxiv.org/abs/2502.06589)
Token length: 1016
Summarized using gpt-4o-mini
Append: [超大规模预训练视觉语言模型的实证研究](https://arxiv.org/abs/2502.07617)
Token length: 1395
Summarized using gpt-4o-mini
Append: [CodeI/O：提升大语言模型的推理能力](https://arxiv.org/abs/2502.07316)
Token length: 1738
Summarized using gpt-4o-mini
Append: [大规模语言模型中长链推理的训练与结构探索](https://arxiv.org/abs/2502.07374)
Token length: 1330
Summarized using gpt-4o-mini
Append: [大语言模型强化学习在编码与推理任务中的应用](https://arxiv.org/abs/2502.06807)
append_entries: 26
Finish: 2025-02-13 05:03:42.719102
------------------------------------------------------
Started: 2025-02-13 06:00:33.854743
Existing_entries: 26
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1725
Summarized using gpt-4o-mini
Append: [LASP-2: 提升线性注意力变换器模型的序列并行ism方法](https://arxiv.org/abs/2502.07563)
Token length: 1125
Summarized using gpt-4o-mini
Append: [CoCoMix：结合离散的下一个标记预测与连续概念的预训练框架](https://arxiv.org/abs/2502.08524)
Token length: 905
Summarized using gpt-4o-mini
Append: [基于计算预算的模型蒸馏性能估计研究](https://arxiv.org/abs/2502.08606)
Json decode failed:
{
  "title": "SARChat-2M：首个大规模SAR图像的多模态对话数据集",
  "keyword": ["合成孔径雷达", "视觉语言模型", "多模态数据集"],
  "short_summary": "本文提出SARChat-2M数据集，推动SAR图像的多模态理解与应用。",
  "summary": "本文创新性地提出了首个大规模合成孔径雷达（SAR）图像的多模态对话数据集——SARChat-2M，包含约200万个高质量的图像-文本对，涵盖多种场景和详细的目标注释。此数据集支持视觉理解和目标检测等关键任务，同时为SAR领域的视觉语言模型（VLMs）提供了评估基础，验证了VLM在SAR图像解读中的能力。通过对16个主流VLM进行实验，充分验证了该数据集的有效性，并成功建立了SAR领域的首个多任务对话基准。本项目将发布在https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 232 (char 381). Line: 406.
Append: [SARChat-Bench-2M: A Multi-Task Vision-Language Benchmark for SAR Image Interpretation](https://arxiv.org/abs/2502.08168)
Token length: 1357
Summarized using gpt-4o-mini
Append: [CineMaster：3D感知可控文本到视频生成框架](https://arxiv.org/abs/2502.08639)
Token length: 1414
Summarized using gpt-4o-mini
Append: [基于下一块预测的半自回归视频生成框架](https://arxiv.org/abs/2502.07737)
Token length: 1547
Summarized using gpt-4o-mini
Append: [评估大型语言模型在金融推理中的能力与改进](https://arxiv.org/abs/2502.08127)
Json decode failed:
{
  "title": "解决DPO中选择概率位移的优化方法",
  "keyword": ["Direct Preference Optimization", "选择概率", "人类偏好"],
  "short_summary": "提出一种新方法控制选择概率，优化语言模型对人类偏好的调节。",
  "summary": "本研究针对Direct Preference Optimization (DPO)及其变种在训练过程中出现的选择概率下降现象（即似然位移）提出了一种新的方法\method，旨在可控地转移选择概率分布。我们展示了该方法在提高选择概率与牺牲奖励边际之间存在根本的权衡关系，这一结论通过理论分析和实验验证得到了支持。此外，我们在下游任务，如MT-Bench和设计的胜率实验中，展示了\method优于传统DPO的性能。研究结果表明，通过这一简单且有理论基础的解决方案，可以有效缓解DPO的似然位移问题。"
}Summarization failed, append the original article
error: Invalid \escape: line 5 column 93 (char 243). Line: 406.
Append: [DPO-Shift: Shifting the Distribution of Direct Preference Optimization](https://arxiv.org/abs/2502.07599)
Token length: 1423
Summarized using gpt-4o-mini
Append: [TransMLA：提升语言模型通信效率的新方法](https://arxiv.org/abs/2502.07864)
append_entries: 9
Finish: 2025-02-13 06:01:28.440569
------------------------------------------------------
Started: 2025-02-13 09:01:01.328372
Existing_entries: 35
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-13 09:01:01.460858
------------------------------------------------------
Started: 2025-02-13 12:12:49.218663
Existing_entries: 35
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 771
Summarized using gpt-4o-mini
Append: [通过增强交叉注意机制实现大型模型知识传输至小型模型](https://arxiv.org/abs/2502.08213)
Token length: 964
Summarized using gpt-4o-mini
Append: [改进长效目标优化的语言模型探索方法](https://arxiv.org/abs/2502.06533)
Token length: 1244
Summarized using gpt-4o-mini
Append: [Animate Anyone 2: 结合环境语义的角色动画生成](https://arxiv.org/abs/2502.06145)
Token length: 1172
Summarized using gpt-4o-mini
Append: [BenchMAX：一种多语言评估基准以测量语言模型的高级能力](https://arxiv.org/abs/2502.07346)
Token length: 1232
Summarized using gpt-4o-mini
Append: [优化模型合并提升大语言模型性能](https://arxiv.org/abs/2502.04411)
Token length: 867
Summarized using gpt-4o-mini
Append: [动态安全框架优化语言模型推理安全](https://arxiv.org/abs/2502.07985)
Token length: 1251
Summarized using gpt-4o-mini
Append: [WorldGUI：一种新颖的GUI基准用于真实用户交互评估](https://arxiv.org/abs/2502.08047)
Token length: 1488
Summarized using gpt-4o-mini
Append: [建立值得信赖的检索增强生成（RAG）系统的综合路线图](https://arxiv.org/abs/2502.06872)
Token length: 1379
Summarized using gpt-4o-mini
Append: [NoLiMa基准评估长文本环境下大语言模型的检索能力](https://arxiv.org/abs/2502.05167)
Token length: 1475
Summarized using gpt-4o-mini
Append: [TextAtlas5M：评估长文本条件下的图像生成的新数据集](https://arxiv.org/abs/2502.07870)
Token length: 1473
Summarized using gpt-4o-mini
Append: [Light-A-Video：无训练的视频重光照方法](https://arxiv.org/abs/2502.08590)
append_entries: 11
Finish: 2025-02-13 12:13:45.803273
------------------------------------------------------
Started: 2025-02-13 15:00:44.182122
Existing_entries: 46
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-13 15:00:44.372192
------------------------------------------------------
Started: 2025-02-13 18:00:42.341364
Existing_entries: 46
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1199
Summarized using gpt-4o-mini
Append: [PDE-Controller: 利用大型语言模型控制偏微分方程系统](https://arxiv.org/abs/2502.00963)
append_entries: 1
Finish: 2025-02-13 18:00:48.105916
------------------------------------------------------
Started: 2025-02-13 21:01:06.910239
Existing_entries: 47
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-13 21:01:07.121627
------------------------------------------------------
Started: 2025-02-14 00:34:22.782704
Existing_entries: 47
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1522
Summarized using gpt-4o-mini
Append: [基于GEMINI学习的医疗图像密集对比表示学习](https://arxiv.org/abs/2502.05282)
append_entries: 1
Finish: 2025-02-14 00:34:28.150875
------------------------------------------------------
Started: 2025-02-14 03:11:39.967560
Existing_entries: 48
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-14 03:11:40.191424
------------------------------------------------------
Started: 2025-02-14 06:00:43.199482
Existing_entries: 48
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1546
Summarized using gpt-4o-mini
Append: [高质量合成多模态数据及其在mmE5模型中的应用](https://arxiv.org/abs/2502.08468)
Token length: 1391
Summarized using gpt-4o-mini
Append: [构建评估框架以提升多模态大型语言模型在体感代理中的应用](https://arxiv.org/abs/2502.09560)
Token length: 1273
Summarized using gpt-4o-mini
Append: [Skrr: 提高文本编码器在T2I扩散模型中的内存效率](https://arxiv.org/abs/2502.08690)
Token length: 1276
Summarized using gpt-4o-mini
Append: [InfiniteHiP：高效的长序列推理框架](https://arxiv.org/abs/2502.08910)
Token length: 1896
Summarized using gpt-4o-mini
Append: [TripoSG：高保真3D形状生成的新流行扩散模型](https://arxiv.org/abs/2502.06608)
Token length: 1217
Summarized using gpt-4o-mini
Append: [提升泰语大语言模型推理能力的方法研究](https://arxiv.org/abs/2502.09056)
Token length: 1080
Summarized using gpt-4o-mini
Append: [对大型语言模型理解能力的系统评估](https://arxiv.org/abs/2502.08946)
Token length: 920
Summarized using gpt-4o-mini
Append: [大型语言模型中的逻辑推理能力研究](https://arxiv.org/abs/2502.09100)
Token length: 918
Summarized using gpt-4o-mini
Append: [SelfCite：一种自监督方法生成高质量句子级引用](https://arxiv.org/abs/2502.09604)
append_entries: 9
Finish: 2025-02-14 06:01:31.351791
------------------------------------------------------
Started: 2025-02-14 09:00:52.947726
Existing_entries: 57
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1165
Summarized using gpt-4o-mini
Append: [ProbeLog：提高分类模型检索效率的新方法](https://arxiv.org/abs/2502.09619)
Token length: 1338
Summarized using gpt-4o-mini
Append: [CoSER: 高质量角色扮演语言模型数据集及评估协议](https://arxiv.org/abs/2502.09082)
Json decode failed:
{
  "title": "SQuARE：提升自然语言处理中的推理能力",
  "short_summary": "本文提出SQuARE，一种新型提示方法以改进LLM的推理能力。",
  "summary": "在自然语言处理领域，大型语言模型（LLMs）面临越来越复杂的推理挑战。传统的如链式思维（CoT）提示方法虽然展现出良好效果，但往往无法充分发挥模型的推理能力。本文提出了一种名为SQuARE（顺序问题回答推理引擎）的新型提示技术，旨在通过自我质询范式来改善推理。SQuARE鼓励模型在解决主要问题之前，生成和解决多个辅助问题，以更全面地探讨主题的各个方面。通过对Llama 3和GPT-4o模型进行的多项评估，结果显示SQuARE显著超越了传统的CoT提示方法和现有的重述-回答方法。SQuARE通过系统地分解查询，推动了LLM在推理任务中的能力发展。代码已公开，可在https:
  "keyword": ["自然语言处理", "推理能力", "大型语言模型"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 304 (char 395). Line: 406.
Append: [SQuARE: Sequential Question Answering Reasoning Engine for Enhanced Chain-of-Thought in Large Language Models](https://arxiv.org/abs/2502.09390)
Token length: 1557
Summarized using gpt-4o-mini
Append: [无编码器架构在3D理解中的应用探索](https://arxiv.org/abs/2502.09620)
Token length: 1364
Summarized using gpt-4o-mini
Append: [MME-CoT：评估大型多模态模型的链式思维推理性能](https://arxiv.org/abs/2502.09621)
Token length: 1111
Summarized using gpt-4o-mini
Append: [Typhoon T1：开放的泰语推理模型开发](https://arxiv.org/abs/2502.09042)
Token length: 1487
Summarized using gpt-4o-mini
Append: [CoT-Valve: 动态控制推理链长度的方法](https://arxiv.org/abs/2502.09601)
append_entries: 7
Finish: 2025-02-14 09:01:44.588014
------------------------------------------------------
Started: 2025-02-14 12:00:47.960997
Existing_entries: 64
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1773
Summarized using gpt-4o-mini
Append: [通用神经追踪控制器的开发与应用](https://arxiv.org/abs/2502.09614)
Token length: 1815
Summarized using gpt-4o-mini
Append: [3CAD：用于工业缺陷检测的新型大规模数据集与检测框架](https://arxiv.org/abs/2502.05761)
append_entries: 2
Finish: 2025-02-14 12:00:58.034763
------------------------------------------------------
Started: 2025-02-14 15:00:44.465819
Existing_entries: 66
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1897
Summarized using gpt-4o-mini
Append: [VFX Creator: 基于AI的可控视觉效果生成新范式](https://arxiv.org/abs/2502.05979)
append_entries: 1
Finish: 2025-02-14 15:00:50.658285
------------------------------------------------------
Started: 2025-02-14 18:00:45.710920
Existing_entries: 67
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1358
Summarized using gpt-4o-mini
Append: [GSM-Ranges：评估大语言模型数学推理能力的新方法](https://arxiv.org/abs/2502.08680)
append_entries: 1
Finish: 2025-02-14 18:00:52.280324
------------------------------------------------------
Started: 2025-02-14 21:00:42.643197
Existing_entries: 68
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-14 21:00:42.829261
------------------------------------------------------
Started: 2025-02-15 00:33:43.668780
Existing_entries: 68
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-15 00:33:43.811823
------------------------------------------------------
Started: 2025-02-15 03:09:57.076670
Existing_entries: 68
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-15 03:09:57.252607
------------------------------------------------------
Started: 2025-02-15 06:00:53.212196
Existing_entries: 68
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1195
Summarized using gpt-4o-mini
Append: [新框架提升二维潜在空间的三维重建效果](https://arxiv.org/abs/2502.09613)
append_entries: 1
Finish: 2025-02-15 06:00:58.728035
------------------------------------------------------
Started: 2025-02-15 09:00:38.635508
Existing_entries: 69
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-15 09:00:38.852695
------------------------------------------------------
Started: 2025-02-15 12:10:58.850633
Existing_entries: 69
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-15 12:10:58.995437
------------------------------------------------------
Started: 2025-02-15 15:00:36.073702
Existing_entries: 69
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-15 15:00:36.246422
------------------------------------------------------
Started: 2025-02-15 18:00:37.926630
Existing_entries: 69
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-15 18:00:38.287223
------------------------------------------------------
Started: 2025-02-15 21:00:40.735015
Existing_entries: 69
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-15 21:00:40.906400
------------------------------------------------------
Started: 2025-02-16 00:37:47.736963
Existing_entries: 69
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-16 00:37:47.895472
------------------------------------------------------
Started: 2025-02-16 03:15:08.527039
Existing_entries: 69
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-16 03:15:08.767151
------------------------------------------------------
Started: 2025-02-16 06:00:35.947648
Existing_entries: 69
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-16 06:00:36.078887
------------------------------------------------------
Started: 2025-02-16 09:00:38.719136
Existing_entries: 69
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-16 09:00:38.889019
------------------------------------------------------
Started: 2025-02-16 12:00:41.929584
Existing_entries: 69
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-16 12:00:42.249105
------------------------------------------------------
Started: 2025-02-16 15:00:34.239231
Existing_entries: 69
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-16 15:00:34.423630
------------------------------------------------------
Started: 2025-02-16 18:00:53.149638
Existing_entries: 69
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-16 18:00:53.414377
------------------------------------------------------
Started: 2025-02-16 21:00:57.626840
Existing_entries: 69
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-16 21:00:57.776165
------------------------------------------------------
Started: 2025-02-17 00:36:44.630563
Existing_entries: 69
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-17 00:36:44.794506
------------------------------------------------------
Started: 2025-02-17 03:14:50.934691
Existing_entries: 69
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-17 03:14:51.167046
------------------------------------------------------
Started: 2025-02-17 06:00:55.216649
Existing_entries: 69
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1281
Summarized using gpt-4o-mini
Append: [利用LLM进行反监测的创新方法及其潜在风险](https://arxiv.org/abs/2502.09638)
Token length: 1121
Summarized using gpt-4o-mini
Append: [LLaDA：突破自回归模型的扩散模型探索](https://arxiv.org/abs/2502.09992)
Token length: 1262
Summarized using gpt-4o-mini
Append: [多模型推理方法提升LLM在高级数学和编码任务中的表现](https://arxiv.org/abs/2502.09955)
Token length: 1401
Summarized using gpt-4o-mini
Append: [傅里叶数字嵌入方法及其在大语言模型中的应用](https://arxiv.org/abs/2502.09741)
Token length: 1851
Summarized using gpt-4o-mini
Append: [MM-RLHF: 提升多模态大语言模型对人类偏好的对齐研究](https://arxiv.org/abs/2502.10391)
Token length: 1445
Summarized using gpt-4o-mini
Append: [Step-Video-T2V：先进的文本生成视频预训练模型](https://arxiv.org/abs/2502.10248)
Token length: 1638
Summarized using gpt-4o-mini
Append: [RAS：一种高效的动态采样策略以加速扩散模型](https://arxiv.org/abs/2502.10389)
Token length: 829
Summarized using gpt-4o-mini
Append: [ZeroBench：一项全新的视觉推理基准挑战大型多模态模型](https://arxiv.org/abs/2502.09696)
Token length: 1081
Summarized using gpt-4o-mini
Append: [基于时空记忆的智能代理框架STMA](https://arxiv.org/abs/2502.10177)
append_entries: 9
Finish: 2025-02-17 06:02:03.748844
------------------------------------------------------
Started: 2025-02-17 09:00:52.218288
Existing_entries: 78
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1427
Summarized using gpt-4o-mini
Append: [通过局部化关注层提升扩散模型文本生成能力](https://arxiv.org/abs/2502.09935)
Token length: 1501
Summarized using gpt-4o-mini
Append: [MR采样器：加速可控生成中的扩散模型采样过程](https://arxiv.org/abs/2502.07856)
Token length: 1478
Summarized using gpt-4o-mini
Append: [基于大语言模型的车辆间合作感知与规划研究](https://arxiv.org/abs/2502.09980)
append_entries: 3
Finish: 2025-02-17 09:01:15.523265
------------------------------------------------------
Started: 2025-02-17 12:00:44.269336
Existing_entries: 81
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "利用适配器优化预训练模型在多变量时间序列预测中的应用",
  "keyword": ["预训练模型", "时间序列预测", "适配器"],
  "short_summary": "本研究提出适配器以提升预训练模型在多变量时间序列预测中的表现。",
  "summary": "预训练基础模型在单变量时间序列预测中表现优异，但在处理特征间复杂依赖和预测不确定性方面仍面临挑战。本文通过引入适配器，解决这些限制，适配器通过将多变量输入投影到合适的潜在空间，使预训练的单变量时间序列模型能够独立地应用于每个维度。受表示学习和部分随机贝叶斯神经网络文献的启发，我们提出了一系列适配器及优化和推理策略。通过在合成和真实数据集上的实验，结果表明适配器能够显著提高预测准确性和不确定性量化能力。我们的框架AdaPTS将适配器视为一种模块化、可扩展且有效的解决方案，以提升时间序列模型在多变量中的应用，促进其在实际应用中的更广泛采用。代码已发布在 https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 299 (char 436). Line: 406.
Append: [AdaPTS: Adapting Univariate Foundation Models to Probabilistic Multivariate Time Series Forecasting](https://arxiv.org/abs/2502.10235)
Token length: 1685
Summarized using gpt-4o-mini
Append: [VibeGen：基于生成AI的蛋白质动态设计框架](https://arxiv.org/abs/2502.10173)
Token length: 1218
Summarized using gpt-4o-mini
Append: [通过新词开发理解人工智能的语言](https://arxiv.org/abs/2502.07586)
append_entries: 3
Finish: 2025-02-17 12:01:03.445755
------------------------------------------------------
Started: 2025-02-17 15:00:54.173241
Existing_entries: 84
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1609
Summarized using gpt-4o-mini
Append: [高效多级卷积架构在3D视觉定位中的应用](https://arxiv.org/abs/2502.10392)
Json decode failed:
{
  "title": "基于进化搜索的训练感知结构化剪枝方法",
  "short_summary": "提出一种提高大语言模型剪枝效率的新方法。",
  "summary": "本文提出了一种名为\sysname的训练感知结构化剪枝方法，旨在提高大语言模型的压缩效率，同时保持性能。研究表明，现有模型在剪枝时对不同组件的敏感度不同，因此非均匀模型压缩显得尤为重要。该方法基于进化搜索过程，通过生成多个后代模型并进行选择，进行剪枝，并结合轻量级的多步骤训练，逐步提升训练数据的使用效率。实验结果显示，\sysname在Llama-2-7B、Llama-3.1-8B和Qwen-2.5-14B-Instruct模型上取得了优秀性能，特别是在后期训练中，\sysname的表现优于ShearedLlama，但所需训练数据量减少了五倍。",
  "keyword": ["结构化剪枝", "训练感知", "进化搜索"]
}Summarization failed, append the original article
error: Invalid \escape: line 4 column 24 (char 101). Line: 406.
Append: [DarwinLM: Evolutionary Structured Pruning of Large Language Models](https://arxiv.org/abs/2502.07780)
Token length: 936
Summarized using gpt-4o-mini
Append: [ImageRAG：基于检索增强生成的图像合成方法](https://arxiv.org/abs/2502.09411)
Token length: 1489
Summarized using gpt-4o-mini
Append: [小型多语言模型在低资源语言处理中的适应性研究](https://arxiv.org/abs/2502.10140)
Token length: 755
Summarized using gpt-4o-mini
Append: [CAPI：一种基于聚类的纯MIM框架及其在图像识别中的应用](https://arxiv.org/abs/2502.08769)
append_entries: 5
Finish: 2025-02-17 15:01:21.256927
------------------------------------------------------
Started: 2025-02-17 18:00:45.859648
Existing_entries: 89
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1403
Summarized using gpt-4o-mini
Append: [选择性自我监督微调方法（S3FT）提升大语言模型的泛化能力](https://arxiv.org/abs/2502.08130)
Token length: 1133
Summarized using gpt-4o-mini
Append: [CLaMP 3: 一种跨模态与跨语言音乐信息检索统一框架](https://arxiv.org/abs/2502.10362)
append_entries: 2
Finish: 2025-02-17 18:00:56.803345
------------------------------------------------------
Started: 2025-02-17 21:00:40.920757
Existing_entries: 91
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-17 21:00:41.299330
------------------------------------------------------
Started: 2025-02-18 00:34:07.091199
Existing_entries: 91
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1431
Summarized using gpt-4o-mini
Append: [深度分析大型推理模型中的过度思考现象](https://arxiv.org/abs/2502.08235)
append_entries: 1
Finish: 2025-02-18 00:34:21.708070
------------------------------------------------------
Started: 2025-02-18 03:10:54.573150
Existing_entries: 92
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-18 03:10:54.723316
------------------------------------------------------
Started: 2025-02-18 06:00:43.253222
Existing_entries: 92
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-18 06:00:43.497170
------------------------------------------------------
Started: 2025-02-18 09:00:43.445115
Existing_entries: 92
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1304
Summarized using gpt-4o-mini
Append: [大型语言模型的数学推理能力研究](https://arxiv.org/abs/2502.11574)
Token length: 1266
Summarized using gpt-4o-mini
Append: [大型语言模型在语言复杂性测量任务中的表现研究](https://arxiv.org/abs/2502.11578)
Token length: 1243
Summarized using gpt-4o-mini
Append: [SysGen: 提升语言模型响应的系统消息生成管道](https://arxiv.org/abs/2502.11330)
Token length: 1115
Summarized using gpt-4o-mini
Append: [大型语言模型知识电路演化研究](https://arxiv.org/abs/2502.11196)
Token length: 1387
Summarized using gpt-4o-mini
Append: [探索大型语言模型作为代码执行替代者的能力](https://arxiv.org/abs/2502.11167)
Json decode failed:
{
  "title": "ReLearn：提升大型语言模型非学习效果的方法",
  "keyword": ["大型语言模型", "非学习", "数据增强"],
  "short_summary": "ReLearn提供了一种有效的非学习方法，提升生成质量并保留关键信息。",
  "summary": "当前大型语言模型的非学习方法主要依赖逆优化，虽能降低目标Token的概率，但却破坏了后续token的预测，从而影响了模型的整体性能和语言连贯性。针对这一问题，本文提出ReLearn，一个数据增强及微调的管道，并构建了综合评估框架，提出知识遗忘率（KFR）和知识保留率（KRR）来衡量知识层面的保存，以及语言评分（LS）来评估生成质量。实验结果表明，ReLearn能有效实现目标遗忘，同时保持高质量的输出。通过机制分析还表明，逆优化会干扰连贯文本的生成，而ReLearn则能够保护这一关键能力。代码可在 https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 272 (char 410). Line: 406.
Append: [ReLearn: Unlearning via Learning for Large Language Models](https://arxiv.org/abs/2502.11190)
Token length: 1511
Summarized using gpt-4o-mini
Append: [基于学习框架的人形机器人自动起立控制研究](https://arxiv.org/abs/2502.12152)
Json decode failed:
{
  "title": "SWE-Lancer：开源的自由软件工程任务基准",
  "keyword": ["自由职业", "软件工程", "AI经济影响"],
  "short_summary": "SWE-Lancer是一个包含1400多个自由软件工程任务的基准，旨在推动AI研究。",
  "summary": "SWE-Lancer是一个新的基准项目，涵盖来自Upwork的1400多个自由软件工程任务，真实的总价值达100万美元。该基准包括独立的工程任务，如50个缺陷修复和高达32,000美元的功能实现，以及需要选择技术实现提议的管理任务。独立任务通过由经验丰富的软件工程师三重验证的端到端测试进行评分，而管理决策则与原聘请的工程经理的选择进行比较。评价结果显示，现有的前沿模型仍无法有效解决大多数任务。为了促进未来的研究，项目团队开源了统一的Docker镜像和公共评估集SWE-Lancer Diamond，网址为https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 275 (char 421). Line: 406.
Append: [SWE-Lancer: Can Frontier LLMs Earn $1 Million from Real-World Freelance Software Engineering?](https://arxiv.org/abs/2502.12115)
Token length: 1397
Summarized using gpt-4o-mini
Append: [提升视频理解能力的开源多模态LLM video-SALMONN-o1](https://arxiv.org/abs/2502.11775)
Token length: 1084
Summarized using gpt-4o-mini
Append: [TalkHier：一种新型LLM-MA系统的结构化沟通框架](https://arxiv.org/abs/2502.11098)
Token length: 1424
Summarized using gpt-4o-mini
Append: [通过对例增强数学大语言模型的证明能力研究](https://arxiv.org/abs/2502.10454)
Token length: 1081
Summarized using gpt-4o-mini
Append: [Diffusion-Sharpening：一种优化采样轨迹的微调方法](https://arxiv.org/abs/2502.12146)
Token length: 1264
Summarized using gpt-4o-mini
Append: [HermesFlow：弥合多模态大语言模型理解与生成能力的差距](https://arxiv.org/abs/2502.12148)
Token length: 1091
Summarized using gpt-4o-mini
Append: [SAFE-SQL：自增强上下文学习提升Text-to-SQL性能](https://arxiv.org/abs/2502.11438)
Token length: 1385
Summarized using gpt-4o-mini
Append: [CRANE：一种增强推理能力的约束解码算法](https://arxiv.org/abs/2502.09061)
Token length: 983
Summarized using gpt-4o-mini
Append: [利用高质量LLM数据提升信息提取模型性能](https://arxiv.org/abs/2502.11275)
Token length: 1175
Summarized using gpt-4o-mini
Append: [合成数据增强在项目级证明导向编程中的应用](https://arxiv.org/abs/2502.11901)
append_entries: 17
Finish: 2025-02-18 09:02:04.930775
------------------------------------------------------
Started: 2025-02-18 12:12:53.281593
Existing_entries: 109
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 717
Summarized using gpt-4o-mini
Append: [Dyve：基于动态过程验证的语言模型错误检测增强工具](https://arxiv.org/abs/2502.11157)
Token length: 1392
Summarized using gpt-4o-mini
Append: [NSA：高效的长上下文稀疏注意力机制](https://arxiv.org/abs/2502.11089)
Token length: 502
Summarized using gpt-4o-mini
Append: [改进Adam优化器以缓解大语言模型中嵌入的各向异性问题](https://arxiv.org/abs/2502.08441)
Token length: 1159
Summarized using gpt-4o-mini
Append: [提升自动化事实核查工具的有效性](https://arxiv.org/abs/2502.09083)
Token length: 1459
Summarized using gpt-4o-mini
Append: [MagicArticulate：自动将静态3D模型转化为可动画资产的有效框架](https://arxiv.org/abs/2502.12135)
Token length: 1502
Summarized using gpt-4o-mini
Append: [ThinkDiff：增强图文扩散模型的多模态推理能力](https://arxiv.org/abs/2502.10458)
Token length: 1087
Summarized using gpt-4o-mini
Append: [深度神经网络模型中的直觉物理理解研究](https://arxiv.org/abs/2502.11831)
Token length: 1108
Summarized using gpt-4o-mini
Append: [量子属性预测中的预训练质量优于量](https://arxiv.org/abs/2502.11085)
Token length: 1345
Summarized using gpt-4o-mini
Append: [PhysReason：评估大语言模型物理推理能力的新基准](https://arxiv.org/abs/2502.12054)
append_entries: 9
Finish: 2025-02-18 12:13:37.021932
------------------------------------------------------
Started: 2025-02-18 15:00:56.779716
Existing_entries: 118
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-18 15:00:57.008528
------------------------------------------------------
Started: 2025-02-18 18:01:09.766308
Existing_entries: 118
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1254
Summarized using gpt-4o-mini
Append: [CALM：结合对话与智能能力的统一语言模型](https://arxiv.org/abs/2502.08820)
Token length: 1356
Summarized using gpt-4o-mini
Append: [模型编辑在问答系统中的评估与实践研究](https://arxiv.org/abs/2502.11177)
Token length: 1271
Summarized using gpt-4o-mini
Append: [MIKASA：增强记忆能力的强化学习基准](https://arxiv.org/abs/2502.10550)
append_entries: 3
Finish: 2025-02-18 18:01:38.245760
------------------------------------------------------
Started: 2025-02-18 21:00:41.780674
Existing_entries: 121
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1057
Summarized using gpt-4o-mini
Append: [EQ-VAE：提升潜在生成模型的等变性](https://arxiv.org/abs/2502.09509)
Token length: 1327
Summarized using gpt-4o-mini
Append: [多模态检索增强生成系统综述](https://arxiv.org/abs/2502.08826)
Token length: 1039
Summarized using gpt-4o-mini
Append: [IHEval：评估语言模型指令层级遵循能力的新基准](https://arxiv.org/abs/2502.08745)
Token length: 1401
Summarized using gpt-4o-mini
Append: [高效影响值估计的神经网络方法](https://arxiv.org/abs/2502.09969)
Token length: 1407
Summarized using gpt-4o-mini
Append: [合成多模态网络任务数据集和探索者代理的研究](https://arxiv.org/abs/2502.11357)
Token length: 1417
Summarized using gpt-4o-mini
Append: [ILIAS：用于实例级图像检索的新测试数据集](https://arxiv.org/abs/2502.11748)
append_entries: 6
Finish: 2025-02-18 21:01:17.869566
------------------------------------------------------
Started: 2025-02-19 00:34:36.979112
Existing_entries: 127
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-19 00:34:37.215241
------------------------------------------------------
Started: 2025-02-19 03:13:08.428103
Existing_entries: 127
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1255
Summarized using gpt-4o-mini
Append: [Decomposed Reward Models: 提取人类偏好的新方法](https://arxiv.org/abs/2502.13131)
Token length: 1161
Summarized using gpt-4o-mini
Append: [HEADINFER: 一种高效的长序列推理策略](https://arxiv.org/abs/2502.12574)
Json decode failed:
{
  "title": "Phantom: 一种统一的视频生成框架用于主题一致性",
  "keyword": [
    "视频生成",
    "主题一致性",
    "跨模态对齐"
  ],
  "short_summary": "Phantom框架实现主题一致性的视频生成，注重文本与图像的双模态平衡。",
  "summary": "随着基础模型在视频生成领域的持续发展，主题一致性的视频生成仍处于探索阶段。本文介绍了"主题到视频"的概念，通过提取参考图像中的主题元素，利用文本指令生成主题一致的视频。我们提出了Phantom，一个统一的视频生成框架，支持单一和多主题参考。Phantom重构了现有的文本到视频和图像到视频架构，重新设计了联合文本-图像注入模型，并通过文本-图像-视频三元组数据学习跨模态对齐。特别强调在人生成中的主题一致性，涵盖了现有的ID保持视频生成，同时提供了增强的优势。"
}Summarization failed, append the original article
error: Expecting ',' delimiter: line 9 column 58 (char 217). Line: 406.
Append: [Phantom: Subject-consistent video generation via cross-modal alignment](https://arxiv.org/abs/2502.11079)
Token length: 1261
Summarized using gpt-4o-mini
Append: [基于人群比较评估的LLM自动评价方法的改进](https://arxiv.org/abs/2502.12501)
Token length: 1405
Summarized using gpt-4o-mini
Append: [RealSyn：用于视觉-语言表示学习的真实与合成文本数据集](https://arxiv.org/abs/2502.12513)
Token length: 1483
Summarized using gpt-4o-mini
Append: [利用自然语言定义物体方向以增强机器人操作能力](https://arxiv.org/abs/2502.13143)
append_entries: 6
Finish: 2025-02-19 03:13:41.203954
------------------------------------------------------
Started: 2025-02-19 06:10:29.431538
Existing_entries: 133
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-19 06:10:29.640856
------------------------------------------------------
Started: 2025-02-19 09:00:49.171990
Existing_entries: 133
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 748
Summarized using gpt-4o-mini
Append: [Soundwave: 一种高效的语音到文本大语言模型训练方法](https://arxiv.org/abs/2502.12900)
Token length: 1527
Summarized using gpt-4o-mini
Append: [Magma：多模态AI代理任务的基础模型](https://arxiv.org/abs/2502.13130)
Token length: 1147
Summarized using gpt-4o-mini
Append: [测试时间缩放在大型语言模型中的应用与效果研究](https://arxiv.org/abs/2502.12215)
Token length: 1072
Summarized using gpt-4o-mini
Append: [SafeRoute：高效的安全守卫模型自适应路由方案](https://arxiv.org/abs/2502.12464)
Token length: 1098
Summarized using gpt-4o-mini
Append: [MUDD连接：提升Transformer跨层信息流动的有效方法](https://arxiv.org/abs/2502.12170)
Token length: 914
Summarized using gpt-4o-mini
Append: [XLM-SWCM：低资源语言文本生成的新框架](https://arxiv.org/abs/2502.10852)
Token length: 1365
Summarized using gpt-4o-mini
Append: [基于几何性质的连续扩散模型用于语言建模](https://arxiv.org/abs/2502.11564)
Token length: 876
Summarized using gpt-4o-mini
Append: [HealthGPT：融合医疗视觉的强大语言模型](https://arxiv.org/abs/2502.09838)
Token length: 1503
Summarized using gpt-4o-mini
Append: [mmMamba：一种线性复杂度的多模态状态空间模型框架](https://arxiv.org/abs/2502.13145)
Token length: 953
Summarized using gpt-4o-mini
Append: [FLAG-Trader：一种融合语言处理与强化学习的金融交易模型](https://arxiv.org/abs/2502.11433)
append_entries: 10
Finish: 2025-02-19 09:01:40.388861
------------------------------------------------------
Started: 2025-02-19 12:12:49.492954
Existing_entries: 143
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 980
Summarized using gpt-4o-mini
Append: [提升变换器性能的层集成记忆方法研究](https://arxiv.org/abs/2502.09245)
Token length: 1401
Summarized using gpt-4o-mini
Append: [增强大型语言模型的领域知识方法综述](https://arxiv.org/abs/2502.10708)
Token length: 1204
Summarized using gpt-4o-mini
Append: [增强的钙钛矿太阳能电池知识管理系统](https://arxiv.org/abs/2502.12669)
Token length: 1127
Summarized using gpt-4o-mini
Append: [OctoTools：一个面向多领域复杂推理任务的开放源框架](https://arxiv.org/abs/2502.11271)
Token length: 1209
Summarized using gpt-4o-mini
Append: [ARM4R：基于人类视频数据的自动回归机器人模型](https://arxiv.org/abs/2502.13142)
Token length: 1065
Summarized using gpt-4o-mini
Append: [基于动态提示的无提示微调方法研究](https://arxiv.org/abs/2502.12859)
append_entries: 6
Finish: 2025-02-19 12:13:20.758899
------------------------------------------------------
Started: 2025-02-19 15:00:48.235353
Existing_entries: 149
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1753
Summarized using gpt-4o-mini
Append: [Atom of Thoughts: 通过原子问题提升推理能力的框架](https://arxiv.org/abs/2502.12018)
Token length: 1100
Summarized using gpt-4o-mini
Append: [优化分布式训练的通信与计算重叠技术研究](https://arxiv.org/abs/2502.12996)
Token length: 1597
Summarized using gpt-4o-mini
Append: [金融领域文本嵌入基准测试与模型评估](https://arxiv.org/abs/2502.10990)
Token length: 1322
Summarized using gpt-4o-mini
Append: [序列令牌压缩的极限研究及优化潜力](https://arxiv.org/abs/2502.13063)
append_entries: 4
Finish: 2025-02-19 15:01:12.515856
------------------------------------------------------
Started: 2025-02-19 18:00:55.531712
Existing_entries: 153
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1102
Summarized using gpt-4o-mini
Append: [创新推理方法Flow-of-Options在AutoML中的应用](https://arxiv.org/abs/2502.12929)
Token length: 1229
Summarized using gpt-4o-mini
Append: [Text2World: 基于语言模型的符号世界模型生成新基准](https://arxiv.org/abs/2502.13092)
append_entries: 2
Finish: 2025-02-19 18:01:05.060632
------------------------------------------------------
Started: 2025-02-19 21:01:09.558705
Existing_entries: 155
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1286
Summarized using gpt-4o-mini
Append: [视觉模型在时间序列分析中的优势与未来研究方向](https://arxiv.org/abs/2502.08869)
append_entries: 1
Finish: 2025-02-19 21:01:14.586491
------------------------------------------------------
Started: 2025-02-20 00:34:50.061833
Existing_entries: 156
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1077
Summarized using gpt-4o-mini
Append: [基于注意力机制的YOLOv12框架提升目标检测性能](https://arxiv.org/abs/2502.12524)
append_entries: 1
Finish: 2025-02-20 00:35:01.064796
------------------------------------------------------
Started: 2025-02-20 03:12:53.046477
Existing_entries: 157
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1879
Summarized using gpt-4o-mini
Append: [提升大型语言模型决策能力的自动化奖励模型框架](https://arxiv.org/abs/2502.12130)
append_entries: 1
Finish: 2025-02-20 03:12:57.768387
------------------------------------------------------
Started: 2025-02-20 06:00:42.029363
Existing_entries: 158
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1127
Summarized using gpt-4o-mini
Append: [基于3DGS的闭环强化学习在自动驾驶中的应用](https://arxiv.org/abs/2502.13144)
Token length: 1058
Summarized using gpt-4o-mini
Append: [克服小模型学习差距的混合蒸馏策略](https://arxiv.org/abs/2502.12143)
Token length: 1578
Summarized using gpt-4o-mini
Append: [通过LongPO提升短文档LLM在长文档任务中的表现](https://arxiv.org/abs/2502.13922)
append_entries: 3
Finish: 2025-02-20 06:00:57.425928
------------------------------------------------------
Started: 2025-02-20 09:00:42.964917
Existing_entries: 161
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1062
Summarized using gpt-4o-mini
Append: [名字与身份：大型语言模型的偏见研究](https://arxiv.org/abs/2502.11995)
Token length: 1468
Summarized using gpt-4o-mini
Append: [SongGen：基于文本的可控歌曲生成模型](https://arxiv.org/abs/2502.13128)
Token length: 1130
Summarized using gpt-4o-mini
Append: [大型语言模型的安全对齐漏洞分析](https://arxiv.org/abs/2502.13946)
Token length: 1867
Summarized using gpt-4o-mini
Append: [Qwen2.5-VL：视觉语言系列最新旗舰模型](https://arxiv.org/abs/2502.13923)
Token length: 890
Summarized using gpt-4o-mini
Append: [提高大语言模型推理时效的信心评估](https://arxiv.org/abs/2502.13962)
Token length: 1401
Summarized using gpt-4o-mini
Append: [Thinking Preference Optimization：提升长链推理能力的有效方法](https://arxiv.org/abs/2502.13173)
Json decode failed:
{
  "title": "NExT-Mol：结合3D扩散与1D语言模型的分子生成新方法",
  "short_summary": "提出NExT-Mol，通过结合1D和3D模型，提升分子生成准确性。",
  "summary": "NExT-Mol是一种新型的基础模型，旨在结合1D SELFIES语言模型和3D扩散模型，以提高3D分子的生成性能。该模型首先利用经过广泛预训练的1D分子语言模型生成有效的1D分子，然后通过3D扩散模型预测生成分子的3D构象。通过扩大语言模型规模、改进扩散神经架构及应用1D到3D的迁移学习，NExT-Mol在分布相似度方面显著优于基线模型，同时保持分子的有效性。在GEOM-DRUGS数据集上，相较于以往模型，NExT-Mol在3D分子生成中实现了26%的相对提升，在QM9-2014数据集上则获得了13%的平均相对增益。我们的代码和预训练的检查点可在 https:
  "keyword": ["3D分子生成", "扩散模型", "语言模型"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 299 (char 401). Line: 406.
Append: [NExT-Mol: 3D Diffusion Meets 1D Language Modeling for 3D Molecule Generation](https://arxiv.org/abs/2502.12638)
Token length: 1238
Summarized using gpt-4o-mini
Append: [AdaptiveStep：基于自适应步长的过程奖励模型训练方法](https://arxiv.org/abs/2502.13943)
Token length: 953
Summarized using gpt-4o-mini
Append: [Crawl4LLM：基于优先评分的高效网页爬取方法](https://arxiv.org/abs/2502.13347)
Token length: 1179
Summarized using gpt-4o-mini
Append: [Autellix：优化LLM服务系统的高效调度方法](https://arxiv.org/abs/2502.13965)
Token length: 1005
Summarized using gpt-4o-mini
Append: [SearchRAG：提升医疗问答准确性的实时检索框架](https://arxiv.org/abs/2502.13233)
append_entries: 11
Finish: 2025-02-20 09:01:40.265438
------------------------------------------------------
Started: 2025-02-20 12:12:52.438888
Existing_entries: 172
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1264
Summarized using gpt-4o-mini
Append: [ActionPiece: 通过上下文增强的动作序列标记方法](https://arxiv.org/abs/2502.13581)
Token length: 1538
Summarized using gpt-4o-mini
Append: [Mixture-of-Memories: 提升线性序列建模的新架构](https://arxiv.org/abs/2502.13685)
append_entries: 2
Finish: 2025-02-20 12:13:04.201811
------------------------------------------------------
Started: 2025-02-20 15:00:41.423466
Existing_entries: 174
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-20 15:00:41.597643
------------------------------------------------------
Started: 2025-02-20 18:00:59.356838
Existing_entries: 174
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1071
Summarized using gpt-4o-mini
Append: [REFIND框架：改进大语言模型输出中的幻觉检测](https://arxiv.org/abs/2502.13622)
Token length: 1624
Summarized using gpt-4o-mini
Append: [LoRAM：高效的低秩适应训练方案](https://arxiv.org/abs/2502.13533)
Token length: 1609
Summarized using gpt-4o-mini
Append: [半监督异构领域适应中的可转移知识探讨](https://arxiv.org/abs/2502.13573)
Token length: 1467
Summarized using gpt-4o-mini
Append: [全球文化知识评估：GIMMICK多模态基准研究](https://arxiv.org/abs/2502.13766)
Json decode failed:
{
  "title": "高效小型语言模型的研发及其推理能力提升",
  "short_summary": "本文探讨了开发高效小型语言模型以提升推理能力的创新方法。",
  "summary": "随着大语言模型和多模态大语言模型在推理能力方面取得了显著进展，但仍面临高计算需求和隐私问题。本文专注于开发高效的小型语言模型（SLMs）和多模态小型语言模型（MSLMs），旨在保持竞争的推理能力。我们提出了一种创新的训练管道，以提升推理能力并便于在边缘设备上部署，同时实现了性能达到了最先进水平，并降低了开发成本。"InfR"旨在通过缩小模型规模来促进人工智能系统的进步，改善推理能力，降低采用门槛，并解决隐私问题。",
  "keyword": ["小型语言模型", "推理能力", "边缘设备"]
}Summarization failed, append the original article
error: Expecting ',' delimiter: line 4 column 173 (char 259). Line: 406.
Append: [InfiR : Crafting Effective Small Language Models and Multimodal Small Language Models in Reasoning](https://arxiv.org/abs/2502.11573)
append_entries: 5
Finish: 2025-02-20 18:01:32.109341
------------------------------------------------------
Started: 2025-02-20 21:00:57.175239
Existing_entries: 179
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1634
Summarized using gpt-4o-mini
Append: [推出大规模多语言文本嵌入基准（MMTEB）](https://arxiv.org/abs/2502.13595)
Token length: 1052
Summarized using gpt-4o-mini
Append: [AI驱动探索：优化机器学习工程的创新方法](https://arxiv.org/abs/2502.13138)
Json decode failed:
{
  "title": "MVL-SIB：针对低资源语言的多语言视觉-语言基准",
  "keyword": ["多语言基准", "视觉-语言模型", "低资源语言"],
  "short_summary": "MVL-SIB基准评估205种语言的视觉-语言模型表现，揭示低资源语言的表现不足。",
  "summary": "本文介绍了MVL-SIB，一个覆盖205种语言的多语言视觉-语言基准，解决了现有基准只能评估少数高资源语言的局限性。我们对多种开放权重的视觉-语言模型进行了评估，结果显示，在低资源语言的跨模态话题匹配中，这些模型的表现相较随机选择毫无改善，尤其是语言如N"Koo。此外，分析表明，相较于文本支持，视觉-语言模型在低资源语言的支持显著下降。观察还发现，开放权重的视觉-语言模型在处理多图像任务时，未能有效利用多个图像来表示话题。通过关联MVL-SIB与其他多语言视觉-语言基准的表现，我们强调MVL-SIB是检验视觉-语言模型多语言理解能力的重要工具。"
}Summarization failed, append the original article
error: Expecting ',' delimiter: line 5 column 143 (char 293). Line: 406.
Append: [MVL-SIB: A Massively Multilingual Vision-Language Benchmark for Cross-Modal Topical Matching](https://arxiv.org/abs/2502.12852)
Token length: 1169
Summarized using gpt-4o-mini
Append: [PGMR框架：提升自然语言生成SPARQL查询的准确性](https://arxiv.org/abs/2502.13369)
Token length: 1229
Summarized using gpt-4o-mini
Append: [SplatDiff：基于像素喷溅指导的视频扩散模型](https://arxiv.org/abs/2502.12752)
Token length: 982
Summarized using gpt-4o-mini
Append: [TESS 2：提升指令跟随能力的扩散语言模型](https://arxiv.org/abs/2502.13917)
append_entries: 6
Finish: 2025-02-20 21:01:29.255463
------------------------------------------------------
Started: 2025-02-21 00:35:01.424235
Existing_entries: 185
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1401
Summarized using gpt-4o-mini
Append: [基于真实对话的长效聊天机器人情感智能研究](https://arxiv.org/abs/2502.13270)
Token length: 903
Summarized using gpt-4o-mini
Append: [记忆代码：探索大型语言模型在长期互动中的局限性](https://arxiv.org/abs/2502.13791)
Token length: 1723
Summarized using gpt-4o-mini
Append: [大语言模型在相关性评估中的应用与挑战](https://arxiv.org/abs/2502.13908)
append_entries: 3
Finish: 2025-02-21 00:35:14.838524
------------------------------------------------------
Started: 2025-02-21 03:14:15.545186
Existing_entries: 188
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-21 03:14:15.785289
------------------------------------------------------
Started: 2025-02-21 06:00:39.880409
Existing_entries: 188
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-21 06:00:40.115197
------------------------------------------------------
Started: 2025-02-21 09:00:42.250706
Existing_entries: 188
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1627
Summarized using gpt-4o-mini
Append: [基于强化学习的量子码权重优化方法研究](https://arxiv.org/abs/2502.14372)
Token length: 1036
Summarized using gpt-4o-mini
Append: [语言模型的时间知识处理及其局部特征分析](https://arxiv.org/abs/2502.14258)
Token length: 1339
Summarized using gpt-4o-mini
Append: [Set-and-Sequence：动态概念个性化的视频生成框架](https://arxiv.org/abs/2502.14844)
Token length: 1287
Summarized using gpt-4o-mini
Append: [PC-Agent: 复杂交互环境下的分层代理框架](https://arxiv.org/abs/2502.14282)
Token length: 1238
Summarized using gpt-4o-mini
Append: [LongWriter-V-22k: 提升长文本生成能力的视觉语言模型](https://arxiv.org/abs/2502.14834)
Token length: 1379
Summarized using gpt-4o-mini
Append: [CoSyn框架：自动生成文本丰富的多模态数据](https://arxiv.org/abs/2502.14846)
Token length: 1222
Summarized using gpt-4o-mini
Append: [SigLIP 2：新一代多语言视觉-语言编码器](https://arxiv.org/abs/2502.14786)
Token length: 1640
Summarized using gpt-4o-mini
Append: [RelaCtrl：基于相关性指导的可控生成框架](https://arxiv.org/abs/2502.14377)
Token length: 881
Summarized using gpt-4o-mini
Append: [基于规则的强化学习在大型推理模型中的应用研究](https://arxiv.org/abs/2502.14768)
Token length: 1446
Summarized using gpt-4o-mini
Append: [评估大语言模型在多学科领域的知识和推理能力](https://arxiv.org/abs/2502.14739)
Token length: 1302
Summarized using gpt-4o-mini
Append: [增强语言模型的视觉空间推理能力的两阶段训练框架](https://arxiv.org/abs/2502.14669)
Token length: 1468
Summarized using gpt-4o-mini
Append: [Meta MLGym：评估与开发 LLM 代理的新框架与基准](https://arxiv.org/abs/2502.14499)
Json decode failed:
{
  "title": "S*: 一种新型混合测试时间扩展框架提升代码生成精度",
  "short_summary": "本文提出S*框架，提升代码生成模型的覆盖率与选择准确性。",
  "summary": "本文介绍了S*，一种新颖的混合测试时间扩展框架，旨在提升大型语言模型在代码生成领域的表现。S*结合了并行扩展和顺序扩展，显著提高了生成代码的覆盖率和选择准确性。它采用一种新颖的选择机制，能够适应性地生成对比输入，并结合执行基础的信息来准确识别正确解决方案。实验结果显示，S*在12种大型语言模型和推理模型中均表现出色，实现了：首先，3B模型在S*的辅助下超越GPT-4o-mini；其次，非推理模型在S*的支持下超越推理模型，S*处理的GPT-4o-mini在LiveCodeBench上超出o1-preview 3.7%；最后，S*还进一步提升了先进的推理模型的性能，例如，DeepSeek-R1-Distill-Qwen-32B在S*的支持下在LiveCodeBench上达到85.7%，接近88.5%的o1（高）。相关代码将在 https:
  "keyword": ["测试时间扩展", "代码生成", "大型语言模型"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 388 (char 481). Line: 406.
Append: [S*: Test Time Scaling for Code Generation](https://arxiv.org/abs/2502.14382)
append_entries: 13
Finish: 2025-02-21 09:02:00.808920
------------------------------------------------------
Started: 2025-02-21 12:12:45.608309
Existing_entries: 201
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1353
Summarized using gpt-4o-mini
Append: [改进长文本摘要的无结构证据引用方法](https://arxiv.org/abs/2502.14409)
Token length: 1853
Summarized using gpt-4o-mini
Append: [提升图像地理定位的综合框架与新方法](https://arxiv.org/abs/2502.13759)
append_entries: 2
Finish: 2025-02-21 12:12:53.922346
------------------------------------------------------
Started: 2025-02-21 15:00:39.819957
Existing_entries: 203
Fetching from https://rsshub.app/huggingface/daily-papers
Summarization failed, append the original article
error: 'NoneType' object has no attribute 'group'. Line: 406.
Append: [LLM-based User Profile Management for Recommender System](https://arxiv.org/abs/2502.14541)
Summarization failed, append the original article
error: 'NoneType' object has no attribute 'group'. Line: 406.
Append: [How Much Knowledge Can You Pack into a LoRA Adapter without Harming LLM?](https://arxiv.org/abs/2502.14502)
Summarization failed, append the original article
error: 'NoneType' object has no attribute 'group'. Line: 406.
Append: [How Much Do LLMs Hallucinate across Languages? On Multilingual Estimation of LLM Hallucination in the Wild](https://arxiv.org/abs/2502.12769)
Summarization failed, append the original article
error: 'NoneType' object has no attribute 'group'. Line: 406.
Append: [S$^2$R: Teaching LLMs to Self-verify and Self-correct via Reinforcement Learning](https://arxiv.org/abs/2502.12853)
append_entries: 4
Finish: 2025-02-21 15:01:23.494533
------------------------------------------------------
Started: 2025-02-21 18:00:53.882262
Existing_entries: 207
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-21 18:00:54.034350
------------------------------------------------------
Started: 2025-02-21 21:00:39.203515
Existing_entries: 207
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1432
Summarized using gpt-4o-mini
Append: [LServe：基于混合稀疏注意力的长序列大语言模型高效服务](https://arxiv.org/abs/2502.14866)
Token length: 1201
Summarized using gpt-4o-mini
Append: [提升大型多模态模型的视觉推理与可解释性的框架](https://arxiv.org/abs/2502.14044)
Token length: 873
Summarized using gpt-4o-mini
Append: [NaviClues数据集与Navig框架推动影像地理定位进步](https://arxiv.org/abs/2502.14638)
Token length: 1523
Summarized using gpt-4o-mini
Append: [HippoRAG 2: 近似人类长期记忆的高效检索增强生成框架](https://arxiv.org/abs/2502.14802)
Token length: 1314
Summarized using gpt-4o-mini
Append: [CLIPPER：用于叙述主张验证的合成数据生成方法](https://arxiv.org/abs/2502.14854)
append_entries: 5
Finish: 2025-02-21 21:00:59.723224
------------------------------------------------------
Started: 2025-02-22 00:33:20.879213
Existing_entries: 212
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1439
Summarized using gpt-4o-mini
Append: [S-VCO：提升大规模视觉语言模型对细粒度图像细节的敏感性](https://arxiv.org/abs/2502.13928)
Json decode failed:
{
  "title": "基于活跃学习的有机π功能材料分子设计",
  "keyword": ["分子发现", "增强学习", "活跃学习"],
  "short_summary": "提出了一种结合监督学习与活跃学习的分子设计新方法，生成新型吸收性分子。",
  "summary": "本研究解决了分子发现中生成具有离域特性的新型分子的挑战。虽然监督学习方法能够生成与已有数据集相似的高质量分子，但在推广至离域特性方面表现不足。强化学习虽然能探索新化学空间，但常常出现"奖励黑客"现象，生成不易合成的分子。为此，本研究整合了最先进的监督学习方法STGG+，构建了一个活跃学习循环，命名为STGG+AL。我们将STGG+AL应用于有机π功能材料的设计，特别是在两个挑战性任务上：1）生成具有高振荡强度的高吸收分子，2）设计在近红外（NIR）范围内具有合理振荡强度的吸收分子。通过时变密度泛函理论进行了分子验证与合理化，结果显示与现有的强化学习方法相比，本方法在生成高振荡强度的新分子方面效果显著。此外，我们开源了我们的活跃学习代码及包含290万种π共轭分子的Conjugated-xTB数据集，提供了近似振荡强度和吸收波长的函数（基于sTDA-xTB）。"
}Summarization failed, append the original article
error: Expecting ',' delimiter: line 5 column 107 (char 238). Line: 406.
Append: [Generating $π$-Functional Molecules Using STGG+ with Active Learning](https://arxiv.org/abs/2502.14842)
Token length: 1101
Summarized using gpt-4o-mini
Append: [CHASE框架：无人工参与的挑战性问题生成](https://arxiv.org/abs/2502.14678)
Json decode failed:
{
  "title": "Multimodal RewardBench: 新的多模态奖励模型评估基准",
  "short_summary": "推出Multimodal RewardBench以评估多模态奖励模型的表现。",
  "summary": "本文介绍了Multimodal RewardBench，一个涵盖六个领域的专家注释基准，以评估视觉语言模型（VLMs）中的多模态奖励模型。基准包括一般正确性、偏好、知识、推理、安全性和视觉问答等方面，共计5,211个注释的三元组（提示、选择的响应、拒绝的响应）。在对各种VLM评估器的测试中，甚至表现最好的模型如Gemini 1.5 Pro和Claude 3.5 Sonnet，整体准确率仅为72%。特别是在推理和安全性领域，大多数模型表现不佳。这些发现表明，Multimodal RewardBench为推动多领域奖励模型的发展提供了一个具有挑战性的测试平台，基准数据已发布于 https:
  "keyword": ["多模态", "奖励模型", "基准评估"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 311 (char 425). Line: 406.
Append: [Multimodal RewardBench: Holistic Evaluation of Reward Models for Vision Language Models](https://arxiv.org/abs/2502.14191)
append_entries: 4
Finish: 2025-02-22 00:33:38.140580
------------------------------------------------------
Started: 2025-02-22 03:09:46.562502
Existing_entries: 216
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-22 03:09:46.779509
------------------------------------------------------
Started: 2025-02-22 06:01:03.132360
Existing_entries: 216
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-22 06:01:03.272038
------------------------------------------------------
Started: 2025-02-22 09:00:48.973318
Existing_entries: 216
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1290
Summarized using gpt-4o-mini
Append: [MODis框架：基于多目标优化的数据集发现方法](https://arxiv.org/abs/2502.11262)
append_entries: 1
Finish: 2025-02-22 09:00:56.737014
------------------------------------------------------
Started: 2025-02-22 12:00:52.290972
Existing_entries: 217
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-22 12:00:52.477100
------------------------------------------------------
Started: 2025-02-22 15:00:38.022307
Existing_entries: 217
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-22 15:00:38.199379
------------------------------------------------------
Started: 2025-02-22 18:00:43.386749
Existing_entries: 217
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-22 18:00:43.530852
------------------------------------------------------
Started: 2025-02-22 21:00:54.652184
Existing_entries: 217
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-22 21:00:54.842410
------------------------------------------------------
Started: 2025-02-23 00:37:42.826061
Existing_entries: 217
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-23 00:37:43.118825
------------------------------------------------------
Started: 2025-02-23 03:15:22.753558
Existing_entries: 217
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-23 03:15:22.981921
------------------------------------------------------
Started: 2025-02-23 06:00:42.278556
Existing_entries: 217
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-23 06:00:42.484939
------------------------------------------------------
Started: 2025-02-23 09:00:56.337813
Existing_entries: 217
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-23 09:00:56.486566
------------------------------------------------------
Started: 2025-02-23 12:11:08.341738
Existing_entries: 217
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-23 12:11:08.494100
------------------------------------------------------
Started: 2025-02-23 15:00:36.409644
Existing_entries: 217
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-23 15:00:36.575018
------------------------------------------------------
Started: 2025-02-23 18:00:43.490300
Existing_entries: 217
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-23 18:00:43.720096
------------------------------------------------------
Started: 2025-02-23 21:00:39.199751
Existing_entries: 217
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-23 21:00:39.354177
------------------------------------------------------
Started: 2025-02-24 00:36:27.570921
Existing_entries: 217
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-24 00:36:27.790140
------------------------------------------------------
Started: 2025-02-24 03:16:40.783902
Existing_entries: 217
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-24 03:16:41.030129
------------------------------------------------------
Started: 2025-02-24 06:11:28.612694
Existing_entries: 217
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-24 06:11:28.773050
------------------------------------------------------
Started: 2025-02-24 09:00:52.096454
Existing_entries: 217
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1092
Summarized using gpt-4o-mini
Append: [大型语言模型中的上下文信息存储与量化](https://arxiv.org/abs/2502.15007)
Token length: 1677
Summarized using gpt-4o-mini
Append: [基于视频掩码重建的可泛化驾驶世界模型](https://arxiv.org/abs/2502.11663)
Token length: 1014
Summarized using gpt-4o-mini
Append: [CrossOver：灵活的跨模态三维场景理解框架](https://arxiv.org/abs/2502.15011)
Token length: 1293
Summarized using gpt-4o-mini
Append: [VLM^2-Bench：评估视觉语言模型的匹配线索能力](https://arxiv.org/abs/2502.12084)
Token length: 1306
Summarized using gpt-4o-mini
Append: [LightThinker：动态压缩增强大型语言模型推理效率](https://arxiv.org/abs/2502.15589)
Token length: 1915
Summarized using gpt-4o-mini
Append: [推动非代理性AI的发展以确保安全与创新](https://arxiv.org/abs/2502.15657)
Token length: 1337
Summarized using gpt-4o-mini
Append: [StructFlowBench：一项多轮指令跟随评估基准](https://arxiv.org/abs/2502.14494)
Token length: 1401
Summarized using gpt-4o-mini
Append: [UPCORE：平衡信息删除与模型保持的高效方法](https://arxiv.org/abs/2502.15082)
Token length: 1329
Summarized using gpt-4o-mini
Append: [PhotoDoodle：新型图像编辑框架促进艺术涂鸦](https://arxiv.org/abs/2502.14397)
Token length: 1755
Summarized using gpt-4o-mini
Append: [一种基于f散度最小化的扩散模型快速生成方法](https://arxiv.org/abs/2502.15681)
Token length: 1439
Summarized using gpt-4o-mini
Append: [使用SIFT技术提升大语言模型推理的准确性](https://arxiv.org/abs/2502.14922)
Token length: 1365
Summarized using gpt-4o-mini
Append: [利用深度强化学习提升大语言模型的模式遵循能力](https://arxiv.org/abs/2502.14905)
Token length: 1333
Summarized using gpt-4o-mini
Append: [Mol-LLaMA：跨学科的通用分子语言模型](https://arxiv.org/abs/2502.13449)
Token length: 953
Summarized using gpt-4o-mini
Append: [评估大型多模态模型的交互智能新工具与方法](https://arxiv.org/abs/2502.15027)
Token length: 1384
Summarized using gpt-4o-mini
Append: [大型语言模型在数学推理中的效率与准确性分析](https://arxiv.org/abs/2502.15631)
Token length: 1179
Summarized using gpt-4o-mini
Append: [SurveyX：高效自动化问卷生成系统](https://arxiv.org/abs/2502.14776)
append_entries: 16
Finish: 2025-02-24 09:02:25.979962
------------------------------------------------------
Started: 2025-02-24 12:13:26.234417
Existing_entries: 233
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-24 12:13:26.446329
------------------------------------------------------
Started: 2025-02-24 15:00:52.615343
Existing_entries: 233
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1187
Summarized using gpt-4o-mini
Append: [针对用户特定安全标准的LLM安全性评估新基准](https://arxiv.org/abs/2502.15086)
Token length: 1239
Summarized using gpt-4o-mini
Append: [WHAC框架：精确恢复人类模型与相机轨迹](https://arxiv.org/abs/2403.12959)
Json decode failed:
{
  "title": "韩国国家教育测试基准（KoNET）的设计与评估",
  "short_summary": "本文介绍了用于评估多模态生成AI系统的KoNET基准测试。",
  "summary": "本文提出了韩国国家教育测试基准（KoNET），旨在通过韩国国家教育测试评估多模态生成AI系统。KoNET包含四个考试：韩国小学通用教育发展测试（KoEGED）、中学考试（KoMGED）、高中考试（KoHGED）和大学入学能力测试（KoCSAT），这些考试以其严格的标准和多样化的问题著称，能够全面分析AI在不同教育水平的表现。KoNET专注于韩语，为较少探索的语言中的模型性能提供了深入见解。我们评估了一系列模型，包括开源模型、开放获取的API和封闭API，通过考查难度、学科多样性及人工错误率等方面进行分析。相关代码和数据集建构将完全开源，网址为 https:
  "keyword": [
    "KoNET",
    "多模态生成AI",
    "教育测试"
  ]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 296 (char 387). Line: 406.
Append: [Evaluating Multimodal Generative AI with Korean Educational Standards](https://arxiv.org/abs/2502.15422)
Token length: 1622
Summarized using gpt-4o-mini
Append: [大型语言模型情感边界处理评估框架的开放源代码基准](https://arxiv.org/abs/2502.14975)
Token length: 1560
Summarized using gpt-4o-mini
Append: [KITAB-Bench: 阿拉伯语OCR性能的新基准与挑战](https://arxiv.org/abs/2502.14949)
Token length: 1409
Summarized using gpt-4o-mini
Append: [快速高质量蛋白质骨架生成的ReQFlow方法](https://arxiv.org/abs/2502.14637)
Token length: 1362
Summarized using gpt-4o-mini
Append: [创新的混合块注意力机制提升长上下文任务效率](https://arxiv.org/abs/2502.13189)
Token length: 868
Summarized using gpt-4o-mini
Append: [JL1-CD数据集与多教师知识蒸馏框架在遥感影像变化检测中的应用](https://arxiv.org/abs/2502.13407)
append_entries: 8
Finish: 2025-02-24 15:01:38.707094
------------------------------------------------------
Started: 2025-02-24 18:00:43.106223
Existing_entries: 241
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-24 18:00:43.244496
------------------------------------------------------
Started: 2025-02-24 21:00:49.832365
Existing_entries: 241
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1351
Summarized using gpt-4o-mini
Append: [无调优身份保护文本到视频生成的新框架FantasyID](https://arxiv.org/abs/2502.13995)
Token length: 1270
Summarized using gpt-4o-mini
Append: [MedHallu：检测医疗领域大语言模型幻觉的新基准](https://arxiv.org/abs/2502.14302)
Token length: 812
Summarized using gpt-4o-mini
Append: [多语言风格嵌入模型mStyleDistance的介绍与应用](https://arxiv.org/abs/2502.15168)
Token length: 1104
Summarized using gpt-4o-mini
Append: [EgoSpeak：实时语音启动预测的创新框架](https://arxiv.org/abs/2502.14892)
append_entries: 4
Finish: 2025-02-24 21:01:08.073923
------------------------------------------------------
Started: 2025-02-25 00:35:40.858545
Existing_entries: 245
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1098
Summarized using gpt-4o-mini
Append: [Seq2Exp：精准预测基因表达的序列转表达网络](https://arxiv.org/abs/2502.13991)
Token length: 1479
Summarized using gpt-4o-mini
Append: [RareScale：结合语言模型与专家系统的罕见疾病诊断方法](https://arxiv.org/abs/2502.15069)
Token length: 1237
Summarized using gpt-4o-mini
Append: [利用Tree-of-Debate框架提升科学文献评估的创新性辩论](https://arxiv.org/abs/2502.14767)
Token length: 1501
Summarized using gpt-4o-mini
Append: [大语言模型在联合国决策中的应用研究](https://arxiv.org/abs/2502.14122)
append_entries: 4
Finish: 2025-02-25 00:35:55.270250
------------------------------------------------------
Started: 2025-02-25 03:16:13.964747
Existing_entries: 249
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-25 03:16:14.178845
------------------------------------------------------
Started: 2025-02-25 06:00:41.150834
Existing_entries: 249
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-25 06:00:41.366328
------------------------------------------------------
Started: 2025-02-25 09:00:50.109394
Existing_entries: 249
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1186
Summarized using gpt-4o-mini
Append: [多语种数学基准测试中的测试时间扩展方法研究](https://arxiv.org/abs/2502.17407)
Token length: 852
Summarized using gpt-4o-mini
Append: [开放权重模型影响力演变框架研究](https://arxiv.org/abs/2502.15987)
Token length: 1117
Summarized using gpt-4o-mini
Append: [Audio-FLAN: 统一音频理解与生成的指令调优数据集](https://arxiv.org/abs/2502.16584)
Token length: 779
Summarized using gpt-4o-mini
Append: [Slam：24小时内在单一GPU上训练高质量语言模型的Recipe](https://arxiv.org/abs/2502.15814)
Token length: 822
Summarized using gpt-4o-mini
Append: [CTM基准：评估语言模型的时间推理能力](https://arxiv.org/abs/2502.16922)
Token length: 1301
Summarized using gpt-4o-mini
Append: [DICEPTION：一种高效的通用视觉感知模型](https://arxiv.org/abs/2502.17157)
Token length: 1179
Summarized using gpt-4o-mini
Append: [GOAT：一种提升LoRA性能的新型专家模型框架](https://arxiv.org/abs/2502.16894)
Token length: 1014
Summarized using gpt-4o-mini
Append: [Mobile-Agent-V：基于视频指导的移动自动化框架](https://arxiv.org/abs/2502.17110)
Token length: 1475
Summarized using gpt-4o-mini
Append: [长上下文对大型语言模型的影响与挑战](https://arxiv.org/abs/2502.17129)
Token length: 1305
Summarized using gpt-4o-mini
Append: [CodeCriticBench：全面评估大型语言模型的代码批判能力](https://arxiv.org/abs/2502.16614)
Token length: 1475
Summarized using gpt-4o-mini
Append: [多模态不一致性推理基准的建立与评估](https://arxiv.org/abs/2502.16033)
Token length: 1207
Summarized using gpt-4o-mini
Append: [生成性人工智能系统发布及其接入性分析](https://arxiv.org/abs/2502.16701)
append_entries: 12
Finish: 2025-02-25 09:01:30.057618
------------------------------------------------------
Started: 2025-02-25 12:00:42.511855
Existing_entries: 261
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 999
Summarized using gpt-4o-mini
Append: [基于扩散模型的通用颜色一致性方法GCC](https://arxiv.org/abs/2502.17435)
Token length: 1241
Summarized using gpt-4o-mini
Append: [提升视觉语言模型在复杂机器人操作中的物理推理能力](https://arxiv.org/abs/2502.16707)
Token length: 918
Summarized using gpt-4o-mini
Append: [MONSTER：针对时间序列分类的大型数据集评估库](https://arxiv.org/abs/2502.15122)
Token length: 1666
Summarized using gpt-4o-mini
Append: [X-Dancer：基于音乐驱动的零样本人类舞蹈视频生成新方法](https://arxiv.org/abs/2502.17414)
Token length: 1145
Summarized using gpt-4o-mini
Append: [VideoGrain：实现细粒度视频编辑的零-shot方法](https://arxiv.org/abs/2502.17258)
Token length: 1053
Summarized using gpt-4o-mini
Append: [RIFLEx：高效视频生成的频率成分分析与应用](https://arxiv.org/abs/2502.15894)
append_entries: 6
Finish: 2025-02-25 12:01:10.423777
------------------------------------------------------
Started: 2025-02-25 15:01:02.032506
Existing_entries: 267
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1237
Summarized using gpt-4o-mini
Append: [TAME Agent Framework：构建去中心化层次多智能体系统](https://arxiv.org/abs/2502.15425)
Token length: 1504
Summarized using gpt-4o-mini
Append: [Stable-SPAM: 提高4位训练稳定性的优化器](https://arxiv.org/abs/2502.17055)
Token length: 1123
Summarized using gpt-4o-mini
Append: [社交媒体上信息获取与社区审核的互动研究](https://arxiv.org/abs/2502.14132)
Token length: 709
Summarized using gpt-4o-mini
Append: [布朗球面的连续CVS双射逆过程](https://arxiv.org/abs/2502.13074)
Json decode failed:
{
  "title": "M3-AGIQA：先进的AI生成图像质量评估框架",
  "keyword": ["AI生成图像", "质量评估", "多模态"],
  "short_summary": "提出M3-AGIQA框架，全面评估AI生成图像质量。",
  "summary": "随着AI生成图像模型的快速发展，评估其质量面临多维度的挑战，包括感知质量、提示对应性和真实性。为应对这些挑战，本文提出M3-AGIQA框架，该框架具有多模态、多轮次和多方面的特点，充分利用多模态大型语言模型的优势，对文本和图像进行联合编码。通过低秩适应（LoRA）微调，将先进的在线MLLM字幕能力提取到本地模型中。框架包括结构化的多轮评估机制，通过生成中间图像描述，深入洞察质量、对应性和真实性方面。为了使预测与人类感知判断对齐，框架结合了基于xLSTM的预测器和回归头，处理序列logits并预测平均意见分数（MOSs）。在多个基准数据集上进行的广泛实验表明，M3-AGIQA在捕捉AGI质量的细微差别方面表现出色，并且交叉数据集验证也确认了其强大的泛化能力。代码可在https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 357 (char 486). Line: 406.
Append: [M3-AGIQA: Multimodal, Multi-Round, Multi-Aspect AI-Generated Image Quality Assessment](https://arxiv.org/abs/2502.15167)
append_entries: 5
Finish: 2025-02-25 15:01:22.439884
------------------------------------------------------
Started: 2025-02-25 18:00:42.807889
Existing_entries: 272
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 985
Summarized using gpt-4o-mini
Append: [MegaLoc：多任务图像检索模型的研究](https://arxiv.org/abs/2502.17237)
append_entries: 1
Finish: 2025-02-25 18:00:46.003020
------------------------------------------------------
Started: 2025-02-25 21:00:45.327895
Existing_entries: 273
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1517
Summarized using gpt-4o-mini
Append: [Agentic Long-Context Understanding: 提升LLMs的复杂问题回答能力](https://arxiv.org/abs/2502.15920)
Token length: 1075
Summarized using gpt-4o-mini
Append: [基于大语言模型的房地产市场营销内容自动生成框架](https://arxiv.org/abs/2502.16810)
Token length: 1220
Summarized using gpt-4o-mini
Append: [评估大型语言模型的归纳推理能力：InductionBench基准介绍](https://arxiv.org/abs/2502.15823)
Token length: 1060
Summarized using gpt-4o-mini
Append: [量化技术在大语言模型安全性评估中的应用](https://arxiv.org/abs/2502.15799)
Token length: 933
Summarized using gpt-4o-mini
Append: [利用机器学习分析胸部X光片预测COVID-19病程严重性](https://arxiv.org/abs/2502.16622)
Token length: 1225
Summarized using gpt-4o-mini
Append: [提高机器翻译质量估计效率的模型](https://arxiv.org/abs/2502.14429)
append_entries: 6
Finish: 2025-02-25 21:01:08.584494
------------------------------------------------------
Started: 2025-02-26 00:35:04.473538
Existing_entries: 279
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1434
Summarized using gpt-4o-mini
Append: [多样化输入提示下的高质量3D形状和纹理生成框架](https://arxiv.org/abs/2502.14247)
Token length: 1285
Summarized using gpt-4o-mini
Append: [语音交互中的大音频模型(LAM)评估研究](https://arxiv.org/abs/2502.15919)
append_entries: 2
Finish: 2025-02-26 00:35:11.445981
------------------------------------------------------
Started: 2025-02-26 03:15:39.144691
Existing_entries: 281
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-26 03:15:39.304614
------------------------------------------------------
Started: 2025-02-26 06:10:50.047771
Existing_entries: 281
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1256
Summarized using gpt-4o-mini
Append: [MutaGReP: 基于变异的代码库计划搜索方法](https://arxiv.org/abs/2502.15872)
append_entries: 1
Finish: 2025-02-26 06:10:53.885132
------------------------------------------------------
Started: 2025-02-26 09:01:00.258373
Existing_entries: 282
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1118
Summarized using gpt-4o-mini
Append: [Scale-Distribution Decoupling: 稳定大规模语言模型训练的新方法](https://arxiv.org/abs/2502.15499)
Token length: 1370
Summarized using gpt-4o-mini
Append: [WebGames：评估通用网页浏览AI代理的新基准套件](https://arxiv.org/abs/2502.18356)
Token length: 1442
Summarized using gpt-4o-mini
Append: [兼顾人类听觉选择性的听觉注意驱动大型语言模型研究](https://arxiv.org/abs/2502.16794)
Token length: 1794
Summarized using gpt-4o-mini
Append: [基于难度聚类的下游性能预测框架在大语言模型中的应用](https://arxiv.org/abs/2502.17262)
Token length: 1247
Summarized using gpt-4o-mini
Append: [SpargeAttn：通用稀疏和量化注意力机制的实现](https://arxiv.org/abs/2502.18137)
Token length: 1722
Summarized using gpt-4o-mini
Append: [SWE-RL：通过强化学习提升软件工程领域的大语言模型推理能力](https://arxiv.org/abs/2502.18449)
Json decode failed:
{
  "title": "OmniAlign-V：提升多模态大型语言模型与人类偏好对齐的数据集",
  "keyword": ["多模态语言模型", "人类偏好对齐", "数据集"],
  "short_summary": "本文介绍了OmniAlign-V数据集，以增强多模态语言模型与人类偏好的对齐。", 
  "summary": "随着开源多模态大型语言模型（MLLMs）的最新进展，基础能力的增强仍然存在与人类偏好对齐的重要空白。本文提出了OmniAlign-V，一个包含20万高质量训练样本的数据集，涵盖多样化的图像、复杂问题和不同响应格式，旨在改善MLLMs与人类偏好的对齐情况。同时，我们还推出了MM-AlignBench，这是一项专门设计的人类标注基准，用于评估MLLMs在人类价值观方面的对齐情况。实验结果表明，使用Supervised Fine-Tuning（SFT）或Direct Preference Optimization（DPO）对MLLMs进行微调，结合OmniAlign-V能显著提升人类偏好对齐，同时在标准视觉问答基准上保持或增强其性能，保留其基本能力。我们的数据集、基准、代码和检查点已发布于 https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 368 (char 524). Line: 406.
Append: [OmniAlign-V: Towards Enhanced Alignment of MLLMs with Human Preference](https://arxiv.org/abs/2502.18411)
Token length: 1526
Summarized using gpt-4o-mini
Append: [匿名区域变换器（ART）：革命性的多层透明图像生成技术](https://arxiv.org/abs/2502.18364)
Token length: 1097
Summarized using gpt-4o-mini
Append: [KV-Edit：一种无训练的图像编辑背景一致性方法](https://arxiv.org/abs/2502.17363)
append_entries: 9
Finish: 2025-02-26 09:01:38.621200
------------------------------------------------------
Started: 2025-02-26 12:13:46.323830
Existing_entries: 291
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1585
Summarized using gpt-4o-mini
Append: [引入视觉感知标记提升多模态大语言模型性能](https://arxiv.org/abs/2502.17425)
Token length: 1063
Summarized using gpt-4o-mini
Append: [压缩LLM的最新进展与彩票模型假设](https://arxiv.org/abs/2502.17535)
Token length: 1057
Summarized using gpt-4o-mini
Append: [K-LoRA：一种无训练的内容与风格融合方法](https://arxiv.org/abs/2502.18461)
Token length: 922
Summarized using gpt-4o-mini
Append: [Shakti VLM：高效的视觉语言模型家族](https://arxiv.org/abs/2502.17092)
append_entries: 4
Finish: 2025-02-26 12:14:00.050665
------------------------------------------------------
Started: 2025-02-26 15:01:03.993860
Existing_entries: 295
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-26 15:01:04.205509
------------------------------------------------------
Started: 2025-02-26 18:01:11.250399
Existing_entries: 295
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 883
Summarized using gpt-4o-mini
Append: [LaTIM: 基于Mamba模型的细粒度令牌级可解释性方法](https://arxiv.org/abs/2502.15612)
append_entries: 1
Finish: 2025-02-26 18:01:15.096958
------------------------------------------------------
Started: 2025-02-26 21:00:43.528714
Existing_entries: 296
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1143
Summarized using gpt-4o-mini
Append: [统计学在大型语言模型中的作用与挑战](https://arxiv.org/abs/2502.17814)
Json decode failed:
{
  "title": "WiCkeD: 增强多项选择基准测试复杂性的方法",
  "keyword": ["多项选择", "WiCkeD", "基准测试"],
  "short_summary": "WiCkeD通过引入“无上述选项”来提升多项选择基准测试的难度。",
  "summary": "WiCkeD是一种简单的方法，通过随机将一个选项替换为“无上述选项”来提高现有多项选择基准的复杂性，这种方法通常用于教育测试。我们展示了WiCkeD可自动应用于任何现有基准，从而使其更具挑战性。我们将WiCkeD应用于六个流行的基准，并用其评估了18个开放权重的大型语言模型（LLMs）。相较于原始数据集模型的平均性能下降了12.1个百分点。在应用思维链法（chain-of-thought）于三个MMLU数据集时，WiCkeD变体的表现下降与直接使用LLMs时的观察结果相似，显示出WiCkeD同样对具有增强推理能力的模型具有挑战性。此外，WiCkeD还揭示出某些模型对额外推理的敏感性，提供了与原始基准测试相关的额外信息。我们的代码和数据已在https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 344 (char 480). Line: 406.
Append: [WiCkeD: A Simple Method to Make Multiple Choice Benchmarks More Challenging](https://arxiv.org/abs/2502.18316)
Token length: 1234
Summarized using gpt-4o-mini
Append: [基于提示的语言模型评估方法P2L的提案](https://arxiv.org/abs/2502.14855)
Token length: 1316
Summarized using gpt-4o-mini
Append: [提升大语言模型调优性能的可扩展偏好数据构建策略](https://arxiv.org/abs/2502.16825)
append_entries: 4
Finish: 2025-02-26 21:00:59.068338
------------------------------------------------------
Started: 2025-02-27 00:35:24.591963
Existing_entries: 300
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 976
Summarized using gpt-4o-mini
Append: [通过词汇课程学习提升语言模型的预训练效率](https://arxiv.org/abs/2502.17910)
Token length: 1052
Summarized using gpt-4o-mini
Append: [LDGen：高效的多语言文本到图像生成方法](https://arxiv.org/abs/2502.18302)
Token length: 1429
Summarized using gpt-4o-mini
Append: [多模态大语言模型在视觉识别中的效果与干预研究](https://arxiv.org/abs/2502.17422)
Json decode failed:
{
  "title": "Curie：提升科学实验可靠性的AI框架",
  "short_summary": "Curie框架通过三个模块提升科学实验的可靠性和可解释性。",
  "summary": "科学实验是人类进步的重要基石，但严格的实验自动化仍面临挑战。为此，本文提出Curie，一个AI代理框架，旨在通过三个关键组件提升实验的严谨性：内部严谨模块增强可靠性，外部严谨模块保持方法控制，以及实验知识模块增强可解释性。为评估Curie，设计了一个包含46个问题的新实验基准，覆盖四个计算机科学领域，所有问题均取自重要研究论文和广泛采用的开源项目。与测试的最强基线相比，Curie在正确回答实验问题上取得了3.4倍的提升。Curie的开源链接为：https:
  "keyword": ["AI框架", "科学实验", "自动化"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 245 (char 333). Line: 406.
Append: [Curie: Toward Rigorous and Automated Scientific Experimentation with AI Agents](https://arxiv.org/abs/2502.16069)
append_entries: 4
Finish: 2025-02-27 00:35:38.180751
------------------------------------------------------
Started: 2025-02-27 03:16:28.380092
Existing_entries: 304
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-27 03:16:28.591844
------------------------------------------------------
Started: 2025-02-27 06:00:47.273678
Existing_entries: 304
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-27 06:00:47.510977
------------------------------------------------------
Started: 2025-02-27 09:01:16.825232
Existing_entries: 304
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1514
Summarized using gpt-4o-mini
Append: [推出BIG-Bench Extra Hard：评估大型语言模型推理能力的新基准](https://arxiv.org/abs/2502.19187)
Token length: 1436
Summarized using gpt-4o-mini
Append: [提升语言模型反驳能力以加速科学发现](https://arxiv.org/abs/2502.19414)
Token length: 1455
Summarized using gpt-4o-mini
Append: [CritiQ：基于人类偏好的自动数据选择方法](https://arxiv.org/abs/2502.19279)
Token length: 1012
Summarized using gpt-4o-mini
Append: [PosterSum：科学海报总结的前沿基准](https://arxiv.org/abs/2502.17540)
Token length: 1322
Summarized using gpt-4o-mini
Append: [多语言模型的事实知识回忆与跨语言转移研究](https://arxiv.org/abs/2502.17955)
Token length: 1648
Summarized using gpt-4o-mini
Append: [首个希腊金融评估基准与语言模型的推出](https://arxiv.org/abs/2502.18772)
Token length: 1081
Summarized using gpt-4o-mini
Append: [Kanana系列双语语言模型的高效预训练与适应性方法](https://arxiv.org/abs/2502.18934)
Token length: 1121
Summarized using gpt-4o-mini
Append: [DeltaBench：评估o1-like模型在长推理链上的表现](https://arxiv.org/abs/2502.19361)
Token length: 1193
Summarized using gpt-4o-mini
Append: [利用量子力学知识提升3D分子表示的能谱预训练](https://arxiv.org/abs/2502.16284)
Token length: 1901
Summarized using gpt-4o-mini
Append: [AI助力科学发现：多智能体系统在生物医学领域的应用](https://arxiv.org/abs/2502.18864)
Token length: 1099
Summarized using gpt-4o-mini
Append: [AISafetyLab: 统一的AI安全框架与工具包](https://arxiv.org/abs/2502.16776)
Token length: 1087
Summarized using gpt-4o-mini
Append: [跨上下文蒸馏方法提升单目深度估计精度](https://arxiv.org/abs/2502.19204)
Token length: 1250
Summarized using gpt-4o-mini
Append: [基于Manim动画的定理解释视频生成与评估](https://arxiv.org/abs/2502.19400)
Token length: 1215
Summarized using gpt-4o-mini
Append: [一种结合可验证正确性信号的代理奖励建模方法](https://arxiv.org/abs/2502.19328)
Token length: 1360
Summarized using gpt-4o-mini
Append: [基于预训练值环境模型的无环境强化学习框架](https://arxiv.org/abs/2502.18906)
append_entries: 15
Finish: 2025-02-27 09:02:29.288020
------------------------------------------------------
Started: 2025-02-27 12:00:50.013857
Existing_entries: 319
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-27 12:00:50.168462
------------------------------------------------------
Started: 2025-02-27 15:00:41.996318
Existing_entries: 319
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1372
Summarized using gpt-4o-mini
Append: [知识单位：破解科学知识传播的版权壁垒](https://arxiv.org/abs/2502.19413)
Json decode failed:
{
  "title": "GHOST 2.0：一种用于头部交换的先进模型",
  "short_summary": "本文介绍了GHOST 2.0，一个用于高效头部交换的模型，克服了传统方法的局限。",
  "summary": "本文提出了GHOST 2.0，旨在解决人脸交换领域尚未深入研究的头部交换问题。头部交换在进行皮肤颜色转换的同时，还面临如何在合成过程中保持头部整体结构的信息以及如何填补交换头部与背景之间的空白等额外挑战。GHOST 2.0由两个特定模块组成：首先，增强的对齐模型用于头部重演，该模型在多个尺度上保留身份信息，对极端姿态变化具有良好的鲁棒性；其次，Blender模块将重演后的头部无缝融入目标背景，转移皮肤颜色并修补不匹配区域。实验结果表明，这两个模块在各自任务上都优于基线方法，实现了头部交换的最新技术水平。此外，本文还处理了源头与目标间发型差异较大的复杂情况。代码可在https:
  "keyword": ["头部交换", "模型", "计算机视觉"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 306 (char 408). Line: 406.
Append: [GHOST 2.0: generative high-fidelity one shot transfer of heads](https://arxiv.org/abs/2502.18417)
append_entries: 2
Finish: 2025-02-27 15:00:50.619416
------------------------------------------------------
Started: 2025-02-27 18:00:51.330735
Existing_entries: 321
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1009
Summarized using gpt-4o-mini
Append: [Rank1：基于测试时间计算的新型重排序模型](https://arxiv.org/abs/2502.18418)
Token length: 1589
Summarized using gpt-4o-mini
Append: [双重优化嵌入信息的方法提升弱监督语义分割性能](https://arxiv.org/abs/2502.15885)
append_entries: 2
Finish: 2025-02-27 18:01:01.365623
------------------------------------------------------
Started: 2025-02-27 21:00:47.361552
Existing_entries: 323
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1396
Summarized using gpt-4o-mini
Append: [基于少量偏好的个性化优化框架FSPO研究](https://arxiv.org/abs/2502.19312)
Token length: 1382
Summarized using gpt-4o-mini
Append: [Drop-Upcycling：提升混合专家模型训练效率的新方法](https://arxiv.org/abs/2502.19261)
append_entries: 2
Finish: 2025-02-27 21:01:00.092834
------------------------------------------------------
Started: 2025-02-28 00:35:24.339078
Existing_entries: 325
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1788
Summarized using gpt-4o-mini
Append: [多草稿推测解码的效率优化研究](https://arxiv.org/abs/2502.18779)
append_entries: 1
Finish: 2025-02-28 00:35:28.417349
------------------------------------------------------
Started: 2025-02-28 03:16:46.587594
Existing_entries: 326
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-28 03:16:46.859286
------------------------------------------------------
Started: 2025-02-28 06:10:38.689744
Existing_entries: 326
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1278
Summarized using gpt-4o-mini
Append: [提升大型多模态模型性能的新策略：测试时重路由](https://arxiv.org/abs/2502.20395)
Token length: 1239
Summarized using gpt-4o-mini
Append: [LongRoPE2：扩展大语言模型的上下文窗口](https://arxiv.org/abs/2502.20082)
Token length: 1369
Summarized using gpt-4o-mini
Append: [自我奖励推理大型语言模型的研究](https://arxiv.org/abs/2502.19613)
append_entries: 3
Finish: 2025-02-28 06:10:51.303159
------------------------------------------------------
Started: 2025-02-28 09:00:52.489857
Existing_entries: 329
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1239
Summarized using gpt-4o-mini
Append: [FINEREASON: 细粒度评估大语言模型推理能力的逻辑难题基准](https://arxiv.org/abs/2502.20238)
Token length: 1395
Summarized using gpt-4o-mini
Append: [Mobius：无注释文本生成无缝循环视频的新方法](https://arxiv.org/abs/2502.20307)
Token length: 1064
Summarized using gpt-4o-mini
Append: [FlexiDiT：一种动态计算预算的生成变换器](https://arxiv.org/abs/2502.20126)
Token length: 1510
Summarized using gpt-4o-mini
Append: [R1-Translator: 增强推理能力的通用机器翻译框架](https://arxiv.org/abs/2502.19735)
Token length: 1136
Summarized using gpt-4o-mini
Append: [UniTok：统一视觉生成与理解的新型离散标记器](https://arxiv.org/abs/2502.20321)
Token length: 1403
Summarized using gpt-4o-mini
Append: [CODESYNC：适应动态代码演变的语言模型评估基准](https://arxiv.org/abs/2502.16645)
Token length: 1230
Summarized using gpt-4o-mini
Append: [Subtask导向的强化微调（SoRFT）：提升大语言模型的issue解决能力](https://arxiv.org/abs/2502.20127)
append_entries: 7
Finish: 2025-02-28 09:01:31.787096
------------------------------------------------------
Started: 2025-02-28 12:00:47.110226
Existing_entries: 336
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1316
Summarized using gpt-4o-mini
Append: [MedVLM-R1：提升医疗图像分析的透明度与可信度](https://arxiv.org/abs/2502.19634)
Token length: 1469
Summarized using gpt-4o-mini
Append: [Dream Engine：一种高效的文本-图像交错控制生成框架](https://arxiv.org/abs/2502.20172)
Token length: 1281
Summarized using gpt-4o-mini
Append: [NeoBERT：下一代双向编码器的创新与突破](https://arxiv.org/abs/2502.19587)
Token length: 1277
Summarized using gpt-4o-mini
Append: [基于去耦价值策略优化的强化学习框架](https://arxiv.org/abs/2502.16944)
append_entries: 4
Finish: 2025-02-28 12:01:05.244462
------------------------------------------------------
Started: 2025-02-28 15:01:05.665215
Existing_entries: 340
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1342
Summarized using gpt-4o-mini
Append: [高效动态高斯点阵的渲染技术研究](https://arxiv.org/abs/2502.20378)
Token length: 1264
Summarized using gpt-4o-mini
Append: [ArtGS：一种用于多部件关节物体建模的新方法](https://arxiv.org/abs/2502.19459)
append_entries: 2
Finish: 2025-02-28 15:01:16.687267
------------------------------------------------------
Started: 2025-02-28 18:00:47.876595
Existing_entries: 342
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1513
Summarized using gpt-4o-mini
Append: [探讨大语言模型中的关系特定神经元](https://arxiv.org/abs/2502.17355)
Token length: 1828
Summarized using gpt-4o-mini
Append: [提升自主AI代理的安全性：应对攻击与脆弱性](https://arxiv.org/abs/2502.16750)
Json decode failed:
{
  "title": "基于流匹配框架的噪声耦合一致性训练方法",
  "short_summary": "提出了一种新颖的基于流匹配的噪声耦合一致性训练方法，提升图像生成效果。",
  "summary": "一致性训练（CT）作为图像生成任务中的一种新兴方法，尽管具有竞争力，但在非蒸馏一致性训练中常面临高方差和不稳定性的问题。本研究提出了一种基于流匹配框架的新型CT训练方法，主要贡献在于开发了一种受变分自编码器（VAE）架构启发的噪声耦合方案。通过训练一个数据依赖的噪声发射模型，我们的方法能够间接学习噪声到数据映射的几何特征，克服了经典CT中固定的正向过程选择带来的限制。实验证明，在多种图像数据集上，我们的模型显著改善了生成性能，超越了基准模型，并在CIFAR-10上达成了当前最先进的非蒸馏CT FID，在64x64分辨率的2步生成中，FID与ImageNet上的最先进水平相当。我们的代码已发布至https:
  "keyword": ["一致性训练", "噪声耦合", "图像生成"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 321 (char 414). Line: 406.
Append: [Training Consistency Models with Variational Noise Coupling](https://arxiv.org/abs/2502.18197)
append_entries: 3
Finish: 2025-02-28 18:01:01.610494
------------------------------------------------------
Started: 2025-02-28 21:00:50.724025
Existing_entries: 345
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1727
Summarized using gpt-4o-mini
Append: [xAR框架：一种扩展自回归模型的生成方法](https://arxiv.org/abs/2502.20388)
append_entries: 1
Finish: 2025-02-28 21:00:57.569242
------------------------------------------------------
Started: 2025-03-01 00:38:41.762942
Existing_entries: 346
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-01 00:38:42.078759
------------------------------------------------------
Started: 2025-03-01 03:21:56.175681
Existing_entries: 346
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1379
Summarized using gpt-4o-mini
Append: [PlanGEN框架：提升复杂规划问题推理能力的新方法](https://arxiv.org/abs/2502.16111)
append_entries: 1
Finish: 2025-03-01 03:21:59.688263
------------------------------------------------------
Started: 2025-03-01 06:09:34.650023
Existing_entries: 347
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-01 06:09:34.795420
------------------------------------------------------
Started: 2025-03-01 09:00:50.886084
Existing_entries: 347
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-01 09:00:51.051722
------------------------------------------------------
Started: 2025-03-01 12:11:29.965420
Existing_entries: 347
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-01 12:11:30.142426
------------------------------------------------------
Started: 2025-03-01 15:00:44.939306
Existing_entries: 347
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-01 15:00:45.177661
------------------------------------------------------
Started: 2025-03-01 18:01:09.224791
Existing_entries: 347
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-01 18:01:09.420290
------------------------------------------------------
Started: 2025-03-01 21:00:50.637154
Existing_entries: 347
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-01 21:00:50.808835
------------------------------------------------------
Started: 2025-03-02 00:38:18.193149
Existing_entries: 347
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-02 00:38:18.416621
------------------------------------------------------
Started: 2025-03-02 03:18:21.188428
Existing_entries: 347
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-02 03:18:21.364459
------------------------------------------------------
Started: 2025-03-02 06:01:03.702021
Existing_entries: 347
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-02 06:01:03.945753
------------------------------------------------------
Started: 2025-03-02 09:01:07.995570
Existing_entries: 347
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-02 09:01:08.146719
------------------------------------------------------
Started: 2025-03-02 12:11:12.199218
Existing_entries: 347
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-02 12:11:12.436418
------------------------------------------------------
Started: 2025-03-02 15:00:56.905320
Existing_entries: 347
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-02 15:00:57.138933
------------------------------------------------------
Started: 2025-03-02 18:00:59.264785
Existing_entries: 347
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-02 18:00:59.525426
------------------------------------------------------
Started: 2025-03-02 21:00:48.174007
Existing_entries: 347
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-02 21:00:48.354556
------------------------------------------------------
Started: 2025-03-03 00:37:28.123960
Existing_entries: 347
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-03 00:37:28.299938
------------------------------------------------------
Started: 2025-03-03 03:19:05.191647
Existing_entries: 347
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-03 03:19:05.387596
------------------------------------------------------
Started: 2025-03-03 06:11:38.856730
Existing_entries: 347
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1454
Summarized using gpt-4o-mini
Append: [ViDoSeek与ViDoRAG：解决视觉文档中的复杂推理挑战](https://arxiv.org/abs/2502.18017)
Token length: 1299
Summarized using gpt-4o-mini
Append: [应用强化学习提升人形机器人灵巧操作能力](https://arxiv.org/abs/2502.20396)
Token length: 1190
Summarized using gpt-4o-mini
Append: [双阶段数据注释管道在视频理解中的应用](https://arxiv.org/abs/2502.20811)
Token length: 1301
Summarized using gpt-4o-mini
Append: [大语言模型在多变量多项式非负性判断中的应用与研究](https://arxiv.org/abs/2502.20545)
Token length: 1029
Summarized using gpt-4o-mini
Append: [LiteASR：一种低秩压缩的自动语音识别编码器方案](https://arxiv.org/abs/2502.20583)
Token length: 938
Summarized using gpt-4o-mini
Append: [基于SolutionBench的复杂工程解决方案设计评估与SolutionRAG系统](https://arxiv.org/abs/2502.20730)
append_entries: 6
Finish: 2025-03-03 06:12:01.183849
------------------------------------------------------
Started: 2025-03-03 09:09:23.970842
Existing_entries: 353
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-03 09:09:24.133472
------------------------------------------------------
Started: 2025-03-03 12:13:43.780261
Existing_entries: 353
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 955
Summarized using gpt-4o-mini
Append: [ProtoFM：结合视觉基础模型的自解释分类器](https://arxiv.org/abs/2502.19577)
Token length: 776
Summarized using gpt-4o-mini
Append: [链式草稿模型：提升大语言模型推理效率的创新方法](https://arxiv.org/abs/2502.18600)
append_entries: 2
Finish: 2025-03-03 12:13:56.851863
------------------------------------------------------
Started: 2025-03-03 15:00:49.274845
Existing_entries: 355
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1174
Summarized using gpt-4o-mini
Append: [LettuceDetect：克服生成模型幻觉的高效检测框架](https://arxiv.org/abs/2502.17125)
Json decode failed:
{
  "title": "基于Hessian矩阵的Optimal Brain Apoptosis：一种高效的模型剪枝方法",
  "short_summary": "文章提出了一种新颖的剪枝方法，利用Hessian矩阵提高CNN和Transformer的计算效率。",
  "summary": "随着卷积神经网络（CNN）和变换器（Transformers）的复杂性和参数数量增加，计算效率和资源需求成为挑战。本文提出一种新颖的剪枝方法——Optimal Brain Apoptosis（OBA），在参数重要性评估上突破了传统方法，通过直接计算每个参数的Hessian-向量乘积值来提高剪枝效率。我们对Hessian矩阵进行层级分解，并识别层间Hessian子矩阵非零的条件，从而优化了参数的二阶Taylor展开计算。通过在CIFAR10、CIFAR100和Imagenet数据集上实验证实了该方法的有效性，验证了其在CNN和Transformers中的应用，我的代码可在此链接获取：https:
  "keyword": ["卷积神经网络", "变换器", "剪枝方法"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 315 (char 450). Line: 406.
Append: [Optimal Brain Apoptosis](https://arxiv.org/abs/2502.17941)
append_entries: 2
Finish: 2025-03-03 15:01:00.196908
------------------------------------------------------
Started: 2025-03-03 18:00:59.187451
Existing_entries: 357
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1674
Summarized using gpt-4o-mini
Append: [利用大型语言模型提升心理咨询服务的潜力](https://arxiv.org/abs/2502.19731)
Token length: 1460
Summarized using gpt-4o-mini
Append: [EgoNormia: 评估视觉语言模型的规范推理能力](https://arxiv.org/abs/2502.20490)
Token length: 767
Summarized using gpt-4o-mini
Append: [小数据集的战略增强在图像生成中的成功应用](https://arxiv.org/abs/2502.21318)
Token length: 1327
Summarized using gpt-4o-mini
Append: [DexGraspVLA：实现通用灵巧抓取的新框架](https://arxiv.org/abs/2502.20900)
Token length: 1040
Summarized using gpt-4o-mini
Append: [TeleRAG：提升RAG系统推理效率的创新方案](https://arxiv.org/abs/2502.20969)
Token length: 1666
Summarized using gpt-4o-mini
Append: [MIGE：统一的多模态框架促进主题驱动生成与指令编辑](https://arxiv.org/abs/2502.21291)
append_entries: 6
Finish: 2025-03-03 18:01:39.768452
------------------------------------------------------
Started: 2025-03-03 21:01:08.093768
Existing_entries: 363
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-03 21:01:08.357381
------------------------------------------------------
Started: 2025-03-04 00:36:12.468981
Existing_entries: 363
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 994
Summarized using gpt-4o-mini
Append: [基于单步反馈的多轮代码生成方法muCode](https://arxiv.org/abs/2502.20380)
append_entries: 1
Finish: 2025-03-04 00:36:16.046021
------------------------------------------------------
Started: 2025-03-04 03:18:42.368406
Existing_entries: 364
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-04 03:18:42.555409
------------------------------------------------------
Started: 2025-03-04 06:01:02.306063
Existing_entries: 364
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-04 06:01:02.618330
------------------------------------------------------
Started: 2025-03-04 09:00:45.604171
Existing_entries: 364
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1286
Summarized using gpt-4o-mini
Append: [DuoDecoding：提升大语言模型推理速度的新方法](https://arxiv.org/abs/2503.00784)
append_entries: 1
Finish: 2025-03-04 09:00:48.793774
------------------------------------------------------
Started: 2025-03-04 12:13:38.360538
Existing_entries: 365
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1128
Summarized using gpt-4o-mini
Append: [TOKENSWIFT框架：加速超长序列生成的解决方案](https://arxiv.org/abs/2502.18890)
Token length: 1436
Summarized using gpt-4o-mini
Append: [DiffRhythm：高效生成完整歌曲的潜在扩散模型](https://arxiv.org/abs/2503.01183)
Token length: 1484
Summarized using gpt-4o-mini
Append: [基于DUSt3R的多视角房间布局估计新方法](https://arxiv.org/abs/2502.16779)
Token length: 1917
Summarized using gpt-4o-mini
Append: [OneRec: 基于生成模型的推荐系统优化方案](https://arxiv.org/abs/2502.18965)
Token length: 1368
Summarized using gpt-4o-mini
Append: [大型语言模型在机间通信中开发私密声调语言的潜力研究](https://arxiv.org/abs/2503.01063)
Token length: 1634
Summarized using gpt-4o-mini
Append: [Liger：将预训练语言模型线性化为门控递归结构](https://arxiv.org/abs/2503.01496)
Token length: 1434
Summarized using gpt-4o-mini
Append: [封闭循环体态代理（CLEA）架构在动态环境中的任务管理](https://arxiv.org/abs/2503.00729)
Token length: 1242
Summarized using gpt-4o-mini
Append: [SpeQL: 利用大型语言模型加速大数据集查询执行](https://arxiv.org/abs/2503.00714)
Token length: 1194
Summarized using gpt-4o-mini
Append: [CodeArena：重塑大语言模型代码生成评估框架](https://arxiv.org/abs/2503.01295)
Token length: 1847
Summarized using gpt-4o-mini
Append: [Qilin数据集：推动多模态搜索与推荐服务的发展](https://arxiv.org/abs/2503.00501)
Token length: 1323
Summarized using gpt-4o-mini
Append: [Kiss3DGen: 高效的3D生成与编辑框架](https://arxiv.org/abs/2503.01370)
Token length: 1335
Summarized using gpt-4o-mini
Append: [基于单步扩散模型的3D重建与新视角合成增强方法](https://arxiv.org/abs/2503.01774)
Json decode failed:
{
  "title": "VideoUFO: 用户焦点视频数据集的构建与应用",
  "keyword": ["视频生成", "用户焦点", "数据集"],
  "short_summary": "本文提出了VideoUFO数据集，以满足用户的视频生成需求。",
  "summary": "本文介绍了VideoUFO，这是首个专门为满足用户兴趣而构建的视频数据集，应用于文本到视频生成模型。VideoUFO具有与现有数据集重叠度低（仅0.29%）和使用YouTube官方API搜索获得的Creative Commons授权视频等独特特点，能够为未来研究提供更加广泛的训练资源。该数据集包含逾109万段视频剪辑，并为每段剪辑生成简短及详细的描述。通过对大规模的文本到视频提示数据集VidProM进行主题聚类，我们识别出1,291个用户关注的话题并据此获取相关视频。实验结果显示，目前16种文本到视频模型在用户关注的主题上表现不一致，而使用VideoUFO训练的简单模型在表现最差的主题上超过了其他模型。该数据集已在https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 332 (char 464). Line: 406.
Append: [VideoUFO: A Million-Scale User-Focused Dataset for Text-to-Video Generation](https://arxiv.org/abs/2503.01739)
Token length: 1827
Summarized using gpt-4o-mini
Append: [语言模型自我改进的内在机制：推理行为的作用](https://arxiv.org/abs/2503.01307)
Json decode failed:
{
  "title": "数据选择方法在大规模训练中的有效性研究",
  "keyword": [
    "数据选择",
    "指令调整",
    "模型训练"
  ],
  "short_summary": "研究表明，数据选择在模型训练中的效果依赖于数据集规模，复杂方法往往表现不如随机选择。",
  "summary": "本研究系统性地探讨了数据选择方法在大规模指令调优中的效果，选择最多2.5M样本自5.8M样本池中进行评估，涵盖7个不同任务。结果显示，许多新提出的方法在这一环境下的表现不如随机选择，尽管它们使用了更多的计算资源。更令人关注的是，当面对更大数据池时，它们的性能反而下降。相较之下，一种基于表现的加权平均池化（RDS+）变体在所有测试环境中都 consistently 超过更复杂的方法，同时计算效率更高。我们的发现表明，自动选择方法的扩展性特征需要更深入的研究。相关代码、数据和模型已发布在 https:
}Summarization failed, append the original article
error: Invalid control character at: line 9 column 266 (char 421). Line: 406.
Append: [Large-Scale Data Selection for Instruction Tuning](https://arxiv.org/abs/2503.01807)
Token length: 1830
Summarized using gpt-4o-mini
Append: [视觉强化微调（Visual-RFT）：提升大型视觉语言模型的推理能力](https://arxiv.org/abs/2503.01785)
Token length: 1724
Summarized using gpt-4o-mini
Append: [Introducing Phi-4-Mini与Phi-4-Multimodal：紧凑且高效的语言和多模态模型](https://arxiv.org/abs/2503.01743)
append_entries: 17
Finish: 2025-03-04 12:15:25.171551
------------------------------------------------------
Started: 2025-03-04 21:00:48.295920
Existing_entries: 382
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1386
Summarized using gpt-4o-mini
Append: [基于模型置信度的测试时计算效率提升方法](https://arxiv.org/abs/2503.00031)
Token length: 1417
Summarized using gpt-4o-mini
Append: [Web AI代理的安全性与脆弱性分析](https://arxiv.org/abs/2502.20383)
Token length: 1463
Summarized using gpt-4o-mini
Append: [从人工有用智能到人工通用智能的过渡：分离知识与推理](https://arxiv.org/abs/2502.19402)
Token length: 1122
Summarized using gpt-4o-mini
Append: [PodAgent：一种全新的播客音频生成框架](https://arxiv.org/abs/2503.00455)
Token length: 1288
Summarized using gpt-4o-mini
Append: [评估大语言模型不确定性的方法研究](https://arxiv.org/abs/2503.01688)
Token length: 1174
Summarized using gpt-4o-mini
Append: [SampleMix: 一种基于样本特征的数据混合方法](https://arxiv.org/abs/2503.01506)
Token length: 1343
Summarized using gpt-4o-mini
Append: [探索语言模型语义重建中的词形与上下文信息的作用](https://arxiv.org/abs/2503.01714)
Token length: 1480
Summarized using gpt-4o-mini
Append: [Direct Discriminative Optimization：提升视觉生成模型的质量](https://arxiv.org/abs/2503.01103)
append_entries: 8
Finish: 2025-03-04 21:01:54.852133
------------------------------------------------------
Started: 2025-03-05 00:36:06.686739
Existing_entries: 390
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-05 00:36:07.033298
------------------------------------------------------
Started: 2025-03-05 03:17:31.268230
Existing_entries: 390
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-05 03:17:31.587505
------------------------------------------------------
Started: 2025-03-05 06:00:46.158119
Existing_entries: 390
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1068
Summarized using gpt-4o-mini
Append: [Meta Plan Optimization框架提升大型语言模型代理的规划能力](https://arxiv.org/abs/2503.02682)
Token length: 1171
Summarized using gpt-4o-mini
Append: [大语言模型对维基百科影响的深入分析](https://arxiv.org/abs/2503.02879)
Token length: 1789
Summarized using gpt-4o-mini
Append: [基于直接偏好优化的细粒度事实对齐方法Mask-DPO](https://arxiv.org/abs/2503.02846)
Token length: 1232
Summarized using gpt-4o-mini
Append: [ATLaS：提高大型语言模型代理在多任务中的泛化能力](https://arxiv.org/abs/2503.02197)
Token length: 1342
Summarized using gpt-4o-mini
Append: [SPIDER：多器官补丁级别的病理图像数据集及基准模型](https://arxiv.org/abs/2503.02876)
Token length: 799
Summarized using gpt-4o-mini
Append: [自我学习预见法：提高多步推理任务效率的自监督方法](https://arxiv.org/abs/2503.02878)
Json decode failed:
{
  "title": "MultiAgentBench：评估基于大型语言模型的多智能体系统的综合基准",
  "keyword": ["多智能体", "大型语言模型", "基准测试"],
  "short_summary": "本文提出了MultiAgentBench，用于评估多智能体系统的协作和竞争能力。",
  "summary": "本文介绍了MultiAgentBench，这是一个综合性的基准测试，用于评估基于大型语言模型（LLM）的多智能体系统在多样化互动场景中的表现。现有基准多集中于单个智能体任务或狭窄领域，无法反映多智能体协作与竞争的动态。MultiAgentBench不仅测量任务完成情况，还引入里程碑式关键绩效指标来评估协作和竞争质量。研究中评估了多种协调协议（包括星型、链式、树状和图状拓扑）以及组讨论和认知规划等创新策略。结果显示，gpt-4o-mini在任务评分上平均最高，图结构在协调协议中表现最佳，而认知规划使里程碑达成率提高了3%。相关代码和数据集已公开，地址为https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 299 (char 457). Line: 406.
Append: [MultiAgentBench: Evaluating the Collaboration and Competition of LLM agents](https://arxiv.org/abs/2503.01935)
Token length: 1158
Summarized using gpt-4o-mini
Append: [优化管道并行性中的激活内存消耗](https://arxiv.org/abs/2503.01328)
append_entries: 8
Finish: 2025-03-05 06:01:52.962836
------------------------------------------------------
Started: 2025-03-05 09:00:44.605926
Existing_entries: 398
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1363
Summarized using gpt-4o-mini
Append: [基于进化框架的智能GUI代理提升效率与灵活性](https://arxiv.org/abs/2503.02268)
Token length: 1037
Summarized using gpt-4o-mini
Append: [FR-Spec：一种优化的频率排名推测采样框架](https://arxiv.org/abs/2502.14856)
Token length: 963
Summarized using gpt-4o-mini
Append: [SemViQA：提升越南语事实检查的创新框架](https://arxiv.org/abs/2503.00955)
Json decode failed:
{
  "title": "通过开放语言接口统一细粒度视觉感知任务的框架",
  "keyword": ["视觉感知", "统一模型", "细粒度任务"],
  "short_summary": "提出了一种新框架，通过语言接口统一细粒度视觉感知任务。",
  "summary": "本文介绍了一种名为\ours的新框架，该框架旨在通过开放的语言接口统一细粒度视觉感知任务，包括对象检测、像素级分割和图像级视觉语言任务。该方法将所有感知目标转化为语言空间，从而简化了建筑设计和训练策略。同时，引入了一种新颖的嵌入检索方法，仅依赖语言接口来支持分割任务。经过对五个标准视觉感知数据集的多任务训练，\ours在COCO实例分割上超过了之前的通用模型12.3 mAP，在ADE20K语义分割上达到3.3 mIoU的提升。此外，该方法与现有的多模态语言模型（MLLMs）无缝集成，有效结合细粒度感知能力与先进的语言能力，从而支持更复杂的推理分割任务。相关代码和模型将公开可用。"
}Summarization failed, append the original article
error: Invalid \escape: line 5 column 24 (char 152). Line: 406.
Append: [UFO: A Unified Approach to Fine-grained Visual Perception via Open-ended Language Interface](https://arxiv.org/abs/2503.01342)
append_entries: 4
Finish: 2025-03-05 09:01:03.402659
------------------------------------------------------
Started: 2025-03-05 12:00:54.287275
Existing_entries: 402
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1232
Summarized using gpt-4o-mini
Append: [LADDER: 自主驱动的自我学习框架提升语言模型解决问题的能力](https://arxiv.org/abs/2503.00735)
Token length: 1355
Summarized using gpt-4o-mini
Append: [迭代价值函数优化：提升价值引导解码的有效性](https://arxiv.org/abs/2503.02368)
append_entries: 2
Finish: 2025-03-05 12:01:04.778376
------------------------------------------------------
Started: 2025-03-05 15:00:46.389105
Existing_entries: 404
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1271
Summarized using gpt-4o-mini
Append: [平衡回归中的均匀性学习方法](https://arxiv.org/abs/2503.00876)
Token length: 1457
Summarized using gpt-4o-mini
Append: [Q-EVAL-100K：评估文本与视觉内容的综合数据集](https://arxiv.org/abs/2503.02357)
Token length: 1281
Summarized using gpt-4o-mini
Append: [IterPref：提升代码大语言模型的偏好学习框架](https://arxiv.org/abs/2503.02783)
Token length: 1238
Summarized using gpt-4o-mini
Append: [RectifiedHR：一种高效的无训练高分辨率图像生成方法](https://arxiv.org/abs/2503.02537)
append_entries: 4
Finish: 2025-03-05 15:01:08.390251
------------------------------------------------------
Started: 2025-03-05 18:00:52.181667
Existing_entries: 408
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-05 18:00:52.349220
------------------------------------------------------
Started: 2025-03-05 21:00:52.841536
Existing_entries: 408
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1268
Summarized using gpt-4o-mini
Append: [高效的KV缓存压缩方法Q-Filters在自回归语言模型中的应用](https://arxiv.org/abs/2503.02812)
Token length: 1049
Summarized using gpt-4o-mini
Append: [味觉信息与音乐生成模型的关系研究](https://arxiv.org/abs/2503.02823)
Token length: 876
Summarized using gpt-4o-mini
Append: [Tabby: 一种用于合成表格数据的强大Transformer后训练方法](https://arxiv.org/abs/2503.02152)
Token length: 1283
Summarized using gpt-4o-mini
Append: [TokenOCR：一种针对文本图像任务的首个 token 级视觉基础模型](https://arxiv.org/abs/2503.02304)
Token length: 1014
Summarized using gpt-4o-mini
Append: [基于强化学习的离散时间混合自动机学习框架](https://arxiv.org/abs/2503.01842)
append_entries: 5
Finish: 2025-03-05 21:01:18.250390
------------------------------------------------------
Started: 2025-03-06 00:35:57.343912
Existing_entries: 413
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1690
Summarized using gpt-4o-mini
Append: [统一视频与动作模型：提升机器人任务性能的创新框架](https://arxiv.org/abs/2503.00200)
append_entries: 1
Finish: 2025-03-06 00:36:00.946881
------------------------------------------------------
Started: 2025-03-06 03:18:20.805525
Existing_entries: 414
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1273
Summarized using gpt-4o-mini
Append: [大型语言模型对齐的挑战与社会对齐框架的启示](https://arxiv.org/abs/2503.00069)
append_entries: 1
Finish: 2025-03-06 03:18:28.896242
------------------------------------------------------
Started: 2025-03-06 06:10:52.805304
Existing_entries: 415
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1378
Summarized using gpt-4o-mini
Append: [GEN3C：增强的视频生成模型与精确摄像机控制](https://arxiv.org/abs/2503.03751)
Token length: 1270
Summarized using gpt-4o-mini
Append: [Babel：开创多语言大模型的新标准](https://arxiv.org/abs/2503.00865)
Token length: 1473
Summarized using gpt-4o-mini
Append: [自主车辆与人驱动车辆的双向交互框架研究](https://arxiv.org/abs/2503.00502)
Token length: 1368
Summarized using gpt-4o-mini
Append: [ABC: 深度整合视觉与自然语言的多模态嵌入模型](https://arxiv.org/abs/2503.00329)
Token length: 1376
Summarized using gpt-4o-mini
Append: [KodCode：用于编码训练的高质量合成数据集](https://arxiv.org/abs/2503.02951)
append_entries: 5
Finish: 2025-03-06 06:11:17.685409
------------------------------------------------------
Started: 2025-03-06 09:01:11.197444
Existing_entries: 420
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1148
Summarized using gpt-4o-mini
Append: [机器翻译后编辑中单词级质量估计的影响研究](https://arxiv.org/abs/2503.03044)
Token length: 1395
Summarized using gpt-4o-mini
Append: [通过分解医学知识提升视觉语言模型在医学异常检测中的表现](https://arxiv.org/abs/2503.03278)
Token length: 1329
Summarized using gpt-4o-mini
Append: [利用多元信号提升小型模型的指令跟随能力](https://arxiv.org/abs/2503.01836)
Token length: 1142
Summarized using gpt-4o-mini
Append: [提升工具检索性能的ToolRet基准](https://arxiv.org/abs/2503.01763)
Token length: 1117
Summarized using gpt-4o-mini
Append: [FLAME基准：联邦学习在机器人操控中的应用](https://arxiv.org/abs/2503.01729)
Token length: 1820
Summarized using gpt-4o-mini
Append: [大语言模型在软件漏洞检测中的效能研究](https://arxiv.org/abs/2503.01449)
Token length: 1391
Summarized using gpt-4o-mini
Append: [CognitiveDrone：面向复杂无人机任务的视觉-语言-动作模型](https://arxiv.org/abs/2503.01378)
Token length: 1216
Summarized using gpt-4o-mini
Append: [瑞士法律翻译的挑战与SwiLTra-Bench创新解决方案](https://arxiv.org/abs/2503.01372)
append_entries: 8
Finish: 2025-03-06 09:02:05.703179
------------------------------------------------------
Started: 2025-03-06 12:13:44.882199
Existing_entries: 428
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 888
Summarized using gpt-4o-mini
Append: [小型语言模型Shakti在边缘设备上的应用研究](https://arxiv.org/abs/2503.01933)
Token length: 1227
Summarized using gpt-4o-mini
Append: [结构与文本检索的混合模型：MoR框架](https://arxiv.org/abs/2502.20317)
Token length: 1387
Summarized using gpt-4o-mini
Append: [对话助手中的问题重写与融合方法研究](https://arxiv.org/abs/2502.18860)
append_entries: 3
Finish: 2025-03-06 12:14:01.001410
------------------------------------------------------
Started: 2025-03-06 15:00:44.889194
Existing_entries: 431
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-06 15:00:45.118471
------------------------------------------------------
Started: 2025-03-06 18:10:17.868745
Existing_entries: 431
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1066
Summarized using gpt-4o-mini
Append: [基于过程的自奖励方法提升大语言模型数学推理能力](https://arxiv.org/abs/2503.03746)
append_entries: 1
Finish: 2025-03-06 18:10:21.131924
------------------------------------------------------
Started: 2025-03-06 21:00:42.725318
Existing_entries: 432
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1270
Summarized using gpt-4o-mini
Append: [重掩蔽扩散模型：提升离散扩散生成质量的新方法](https://arxiv.org/abs/2503.00307)
append_entries: 1
Finish: 2025-03-06 21:00:50.075301
------------------------------------------------------
Started: 2025-03-07 00:36:27.069621
Existing_entries: 433
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-07 00:36:27.311334
------------------------------------------------------
Started: 2025-03-07 03:19:13.694099
Existing_entries: 433
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1075
Summarized using gpt-4o-mini
Append: [Highlighted Chain-of-Thought Prompting提升大型语言模型的响应准确性](https://arxiv.org/abs/2503.02003)
Token length: 1531
Summarized using gpt-4o-mini
Append: [基于图神经网络变分自编码器的多智能体协调方法](https://arxiv.org/abs/2503.02954)
Token length: 1574
Summarized using gpt-4o-mini
Append: [基于信号时序逻辑的多样化自主决策方法研究](https://arxiv.org/abs/2503.02924)
append_entries: 3
Finish: 2025-03-07 03:19:27.390691
------------------------------------------------------
Started: 2025-03-07 06:00:42.524063
Existing_entries: 436
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1166
Summarized using gpt-4o-mini
Append: [音频理解与推理的先进模型：Audio Flamingo 2](https://arxiv.org/abs/2503.03983)
Token length: 1563
Summarized using gpt-4o-mini
Append: [预测GitHub对话中的毒性与偏离现象的主动调节策略](https://arxiv.org/abs/2503.02191)
Token length: 756
Summarized using gpt-4o-mini
Append: [大语言模型信息扭曲研究：迭代生成的传播影响](https://arxiv.org/abs/2502.20258)
Json decode failed:
{
  "title": "PokéChamp：基于大语言模型的Pokémon对战智能体",
  "keyword": ["Pokémon", "大语言模型", "强化学习"],
  "short_summary": "PokéChamp利用大语言模型优化Pokémon对战智能体，提升游戏表现。",
  "summary": "PokéChamp是一个基于大型语言模型（LLMs）的最小最大智能体，专为Pokémon对战而设计。该框架通过LLMs替代了三个关键模块：玩家动作采样、对手建模和价值函数估计，利用游戏历史和人类知识来降低搜索空间，解决部分可观察性的问题。经过评估，PokéChamp在流行的Gen 9 OU格式中表现优异，使用GPT-4o时对战胜率达到76%，对比现有最佳LLM基础机器人时，胜率为84%；即使是使用开源的8亿参数Llama 3.1模型，也能以64%的胜率超过之前的最佳LLM机器人Pok"éllmon。通过建立超过300万场游戏的真实玩家数据集，我们提出了一系列用于评估特定对战技能的基准和难题，期待此工作能促进Pokémon对战作为基准，将LLM技术与博弈论算法整合于多智能体问题的进一步研究。"
}Summarization failed, append the original article
error: Expecting ',' delimiter: line 5 column 260 (char 410). Line: 406.
Append: [PokéChamp: an Expert-level Minimax Language Agent](https://arxiv.org/abs/2503.04094)
Token length: 1707
Summarized using gpt-4o-mini
Append: [STORM：提升视频理解效率的时空编码新架构](https://arxiv.org/abs/2503.04130)
Token length: 1325
Summarized using gpt-4o-mini
Append: [LanDiff：融合自回归语言模型与扩散模型的文本生成视频新框架](https://arxiv.org/abs/2503.04606)
Token length: 1371
Summarized using gpt-4o-mini
Append: [HybridNorm: 一种新型混合归一化策略提高深度Transformer模型性能](https://arxiv.org/abs/2503.04598)
Token length: 1904
Summarized using gpt-4o-mini
Append: [START：一种集成工具的长链推理模型](https://arxiv.org/abs/2503.04625)
Token length: 1510
Summarized using gpt-4o-mini
Append: [FuseChat-3.0: 整合多种语言模型的高效新模型](https://arxiv.org/abs/2503.04222)
Token length: 1248
Summarized using gpt-4o-mini
Append: [基于反馈和编辑模型的推理时扩展方法](https://arxiv.org/abs/2503.04378)
append_entries: 10
Finish: 2025-03-07 06:01:34.576216
------------------------------------------------------
Started: 2025-03-07 09:00:57.099349
Existing_entries: 446
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 538
Summarized using gpt-4o-mini
Append: [高效采样贝叶斯逆问题的条件流匹配与变压器架构结合](https://arxiv.org/abs/2503.01375)
Token length: 766
Summarized using gpt-4o-mini
Append: [长范围依赖的双重互信息缩放法则及其在语言建模中的应用](https://arxiv.org/abs/2503.04725)
Token length: 1807
Summarized using gpt-4o-mini
Append: [EgoLife：基于AI的自我中心生活助理系统](https://arxiv.org/abs/2503.03803)
append_entries: 3
Finish: 2025-03-07 09:01:18.531409
------------------------------------------------------
Started: 2025-03-07 12:13:09.169605
Existing_entries: 449
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1431
Summarized using gpt-4o-mini
Append: [Union-of-Experts：提升MoE模型的动态路由与计算效率](https://arxiv.org/abs/2503.02495)
Token length: 1244
Summarized using gpt-4o-mini
Append: [优化大型语言模型翻译以克服翻译腔问题](https://arxiv.org/abs/2503.04369)
Token length: 1246
Summarized using gpt-4o-mini
Append: [评估大型语言模型推理能力的新框架：LINGOLY-TOO 的应用](https://arxiv.org/abs/2503.02972)
Token length: 1107
Summarized using gpt-4o-mini
Append: [IFIR：评估专家领域指令跟随信息检索的首个综合基准](https://arxiv.org/abs/2503.04644)
Token length: 1378
Summarized using gpt-4o-mini
Append: [提升LLM后训练量化性能的精确敏感性度量](https://arxiv.org/abs/2503.01901)
append_entries: 5
Finish: 2025-03-07 12:13:43.579403
------------------------------------------------------
Started: 2025-03-07 15:00:51.057303
Existing_entries: 454
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1375
Summarized using gpt-4o-mini
Append: [LLMVoX: 一种轻量级的自回归语音合成系统](https://arxiv.org/abs/2503.04724)
append_entries: 1
Finish: 2025-03-07 15:01:10.191042
------------------------------------------------------
Started: 2025-03-07 18:00:59.257180
Existing_entries: 455
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1080
Summarized using gpt-4o-mini
Append: [双语模型训练对跨语言结构启动的影响研究](https://arxiv.org/abs/2503.03962)
Token length: 1148
Summarized using gpt-4o-mini
Append: [提升大型语言模型可信度的Truthfulness Separator Vector](https://arxiv.org/abs/2503.01917)
append_entries: 2
Finish: 2025-03-07 18:01:10.029326
------------------------------------------------------
Started: 2025-03-07 21:00:40.566078
Existing_entries: 457
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-07 21:00:40.806620
------------------------------------------------------
Started: 2025-03-08 00:28:22.714958
Existing_entries: 457
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-08 00:28:22.949373
------------------------------------------------------
Started: 2025-03-08 03:00:51.873376
Existing_entries: 457
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-08 03:00:52.130201
------------------------------------------------------
Started: 2025-03-08 06:00:57.195373
Existing_entries: 457
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-08 06:00:57.442487
------------------------------------------------------
Started: 2025-03-08 09:00:38.305330
Existing_entries: 457
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-08 09:00:38.501220
------------------------------------------------------
Started: 2025-03-08 12:01:17.830598
Existing_entries: 457
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-08 12:01:17.995167
------------------------------------------------------
Started: 2025-03-08 15:00:45.147113
Existing_entries: 457
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-08 15:00:45.466694
------------------------------------------------------
Started: 2025-03-08 18:00:53.974043
Existing_entries: 457
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-08 18:00:54.336152
------------------------------------------------------
Started: 2025-03-08 21:00:45.062426
Existing_entries: 457
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-08 21:00:45.221210
------------------------------------------------------
Started: 2025-03-09 00:31:52.315848
Existing_entries: 457
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-09 00:31:52.621526
------------------------------------------------------
Started: 2025-03-09 03:01:08.783519
Existing_entries: 457
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-09 03:01:09.012756
------------------------------------------------------
Started: 2025-03-09 06:00:44.369674
Existing_entries: 457
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-09 06:00:44.665804
------------------------------------------------------
Started: 2025-03-09 09:00:57.321305
Existing_entries: 457
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-09 09:00:57.524409
------------------------------------------------------
Started: 2025-03-09 12:00:49.954478
Existing_entries: 457
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-09 12:00:50.123706
------------------------------------------------------
Started: 2025-03-09 15:00:41.953964
Existing_entries: 457
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-09 15:00:42.162480
------------------------------------------------------
Started: 2025-03-09 18:00:45.625419
Existing_entries: 457
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-09 18:00:45.896315
------------------------------------------------------
Started: 2025-03-09 21:01:02.875026
Existing_entries: 457
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-09 21:01:04.094022
------------------------------------------------------
Started: 2025-03-10 00:30:54.626618
Existing_entries: 457
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-10 00:30:54.780085
------------------------------------------------------
Started: 2025-03-10 03:01:06.980008
Existing_entries: 457
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-10 03:01:07.170136
------------------------------------------------------
Started: 2025-03-10 06:01:02.533349
Existing_entries: 457
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1374
Summarized using gpt-4o-mini
Append: [BEHAVIOR机器人套件：应对家庭任务的全面机器人控制框架](https://arxiv.org/abs/2503.05652)
Token length: 1192
Summarized using gpt-4o-mini
Append: [Sketch-of-Thought: 一种高效的语言模型推理框架](https://arxiv.org/abs/2503.05179)
Token length: 1540
Summarized using gpt-4o-mini
Append: [UnifiedReward：提升多模态生成与理解的统一奖励模型](https://arxiv.org/abs/2503.05236)
Token length: 1228
Summarized using gpt-4o-mini
Append: [引入遗忘门的变换器模型](https://arxiv.org/abs/2503.02130)
append_entries: 4
Finish: 2025-03-10 06:01:29.825038
------------------------------------------------------
Started: 2025-03-10 09:00:43.178429
Existing_entries: 461
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1036
Summarized using gpt-4o-mini
Append: [基于低秩适应的代码检索参数高效微调方法](https://arxiv.org/abs/2503.05315)
Token length: 1081
Summarized using gpt-4o-mini
Append: [R1-Searcher：提升大型语言模型推理能力的新方法](https://arxiv.org/abs/2503.05592)
Token length: 917
Summarized using gpt-4o-mini
Append: [基于可验证奖励的强化学习在多模态情感识别中的应用](https://arxiv.org/abs/2503.05379)
Token length: 1256
Summarized using gpt-4o-mini
Append: [DeepSeek R1在多模态推理中的成功应用与挑战](https://arxiv.org/abs/2503.05132)
Token length: 1248
Summarized using gpt-4o-mini
Append: [分支合并蒸馏法：提升大语言模型压缩与性能的创新策略](https://arxiv.org/abs/2503.04872)
Token length: 1299
Summarized using gpt-4o-mini
Append: [多尝试任务提升大型语言模型推理能力的研究](https://arxiv.org/abs/2503.04808)
append_entries: 6
Finish: 2025-03-10 09:01:16.262454
------------------------------------------------------
Started: 2025-03-10 12:00:59.805555
Existing_entries: 467
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1321
Summarized using gpt-4o-mini
Append: [Linear-MoE：集成线性序列建模与专家混合模型的高效系统](https://arxiv.org/abs/2503.05447)
Token length: 1850
Summarized using gpt-4o-mini
Append: [VideoPainter：一种高效的视频修复方法](https://arxiv.org/abs/2503.05639)
Token length: 1259
Summarized using gpt-4o-mini
Append: [可定制化视频异常检测技术及其应用](https://arxiv.org/abs/2503.04504)
Token length: 1029
Summarized using gpt-4o-mini
Append: [EuroBERT: 高性能多语言编码器的开发与应用](https://arxiv.org/abs/2503.05500)
Token length: 1832
Summarized using gpt-4o-mini
Append: [基于语义分割的检索增强生成框架SAGE的研究](https://arxiv.org/abs/2503.01713)
Token length: 879
Summarized using gpt-4o-mini
Append: [TrajectoryCrafter: 精确控制单目视频摄像机轨迹的新方法](https://arxiv.org/abs/2503.05638)
append_entries: 6
Finish: 2025-03-10 12:01:29.636187
------------------------------------------------------
Started: 2025-03-10 15:01:00.652416
Existing_entries: 473
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1034
Summarized using gpt-4o-mini
Append: [改进的流匹配技术在扩散模型中应用](https://arxiv.org/abs/2503.04824)
Token length: 1222
Summarized using gpt-4o-mini
Append: [STILL项目第三技术报告：强化学习模型的发展与工具操作的影响](https://arxiv.org/abs/2503.04548)
append_entries: 2
Finish: 2025-03-10 15:01:16.857896
------------------------------------------------------
Started: 2025-03-10 18:00:52.359594
Existing_entries: 475
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1426
Summarized using gpt-4o-mini
Append: [引入S2S-Arena：评估语音模型的指令跟随能力](https://arxiv.org/abs/2503.05085)
Token length: 1183
Summarized using gpt-4o-mini
Append: [LONGCODEU基准测试：评估长代码理解能力的研究](https://arxiv.org/abs/2503.04359)
Json decode failed:
{
  "title": "EAGLE-3: 一种新型高效的语言模型采样方法",
  "keyword": ["LLM", "EAGLE-3", "特征融合"],
  "short_summary": "EAGLE-3通过直接预测令牌显著提升模型性能和推理速度。",
  "summary": "本文介绍了EAGLE-3，这是一种新型的语言模型采样方法，旨在克服现有LLM在推理过程中的高成本和延迟问题。与EAGLE不同，EAGLE-3放弃了特征预测，转而采用直接令牌预测，并通过一种称为训练时测试的技术，实现多层特征融合。这种改进为模型性能提供了显著提升，使得提高训练数据规模的优势得到充分利用。实验表明，EAGLE-3在五个任务上相比于EAGLE-2实现了约6.5倍的速度提升及1.4倍的性能改善。本论文的代码可在https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 232 (char 365). Line: 406.
Append: [EAGLE-3: Scaling up Inference Acceleration of Large Language Models via Training-Time Test](https://arxiv.org/abs/2503.01840)
Token length: 1156
Summarized using gpt-4o-mini
Append: [俄语临床编码自动化的可行性研究](https://arxiv.org/abs/2502.21263)
Token length: 1396
Summarized using gpt-4o-mini
Append: [基于隐性用户画像的对话系统用户模拟器](https://arxiv.org/abs/2502.18968)
append_entries: 5
Finish: 2025-03-10 18:01:28.534564
------------------------------------------------------
Started: 2025-03-10 21:00:50.378362
Existing_entries: 480
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1227
Summarized using gpt-4o-mini
Append: [SafeArena：评估大型语言模型代理的网络滥用风险](https://arxiv.org/abs/2503.04957)
append_entries: 1
Finish: 2025-03-10 21:00:57.985434
------------------------------------------------------
Started: 2025-03-11 00:36:18.252251
Existing_entries: 481
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-11 00:36:18.421195
------------------------------------------------------
Started: 2025-03-11 03:19:24.608498
Existing_entries: 481
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1003
Summarized using gpt-4o-mini
Append: [稀疏专家激活剪枝：优化大型语言模型推理效率的新方法](https://arxiv.org/abs/2503.07605)
Token length: 885
Summarized using gpt-4o-mini
Append: [大型语言模型带来的假新闻风险与检测系统的挑战](https://arxiv.org/abs/2503.07595)
Token length: 1083
Summarized using gpt-4o-mini
Append: [PE3R：高效的3D重建框架](https://arxiv.org/abs/2503.07507)
Json decode failed:
{
  "title": "MM-Eureka：扩展大规模规则基础强化学习的多模态推理模型",
  "short_summary": "MM-Eureka通过规则基础强化学习提升多模态推理能力。",
  "summary": "MM-Eureka是一个多模态推理模型，它成功地将大规模规则基础强化学习（RL）扩展到多模态推理领域。尽管规则基础RL在文本领域显著提升了大型语言模型（LLMs）的推理能力，但在多模态环境中的应用仍然具有挑战性。我们的研究复现了文本基础RL系统（如DeepSeek-R1）在多模态空间中的关键特征，包括准确奖励和响应长度的稳步增加及反思行为的出现。我们证明，无论是指令调优还是预训练模型，通过规则基础RL都能在无需监督微调的情况下发展出强大的多模态推理能力，相较于其他方法显示出更优秀的数据效率。此外，我们还开源了完整的工作流程，以促进该领域的进一步研究，所有代码、模型和数据均可在https:
  "keyword": ["多模态推理", "规则基础强化学习", "开源研究"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 312 (char 411). Line: 406.
Append: [MM-Eureka: Exploring Visual Aha Moment with Rule-based Large-scale Reinforcement Learning](https://arxiv.org/abs/2503.07365)
Json decode failed:
{
  "title": "MovieAgent: 自动化电影生成框架",
  "keyword": ["自动化", "电影生成", "多智能体"],
  "short_summary": "MovieAgent通过自动化多智能体计划，实现高效的电影生成。",
  "summary": "本文介绍了MovieAgent，一个用于长视频生成的自动化电影生成框架。现有的长视频生成系统依赖手动输入剧本、场景和角色互动，导致成本高昂且效率低下。MovieAgent的主要优势在于首先探索和定义了自动化电影生成的范式，能够根据剧本和角色库生成多场景、多镜头的视频，确保叙事连贯性、角色一致性及字幕同步。其次，MovieAgent引入基于分层链式思维的推理过程，自动构建场景、镜头设置和摄影视觉，显著减少人力投入。实验结果显示，MovieAgent在剧本忠实度、角色一致性和叙事连贯性方面达到了新的最先进水平，为完全自动化电影生成提供了新的见解与方法。所有代码和项目网站可访问：https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 311 (char 441). Line: 406.
Append: [Automated Movie Generation via Multi-Agent CoT Planning](https://arxiv.org/abs/2503.07314)
Token length: 1340
Summarized using gpt-4o-mini
Append: [FedRand框架：提升联邦学习中的数据隐私](https://arxiv.org/abs/2503.07216)
Token length: 1043
Summarized using gpt-4o-mini
Append: [eMIGM：统一的图像生成与扩散模型](https://arxiv.org/abs/2503.07197)
Token length: 1756
Summarized using gpt-4o-mini
Append: [EasyControl: 高效灵活的条件引导扩散变换框架](https://arxiv.org/abs/2503.07027)
Token length: 1305
Summarized using gpt-4o-mini
Append: [MMDiag: 多轮多模态对话数据集及DiagNote模型](https://arxiv.org/abs/2503.07002)
Token length: 1131
Summarized using gpt-4o-mini
Append: [FEA-Bench: 评估大型语言模型在代码库增量开发中的能力](https://arxiv.org/abs/2503.06680)
Token length: 1014
Summarized using gpt-4o-mini
Append: [AutoCoA：提升自主性的大型代理模型框架](https://arxiv.org/abs/2503.06580)
Token length: 1401
Summarized using gpt-4o-mini
Append: [Seg-Zero: 用于分割推理的零-shot 学习框架](https://arxiv.org/abs/2503.06520)
Json decode failed:
{
  "title": "利用RWKV-7模型提升时间序列分析的性能",
  "short_summary": "提出RWKV-7模型，显著提高时间序列分析性能和训练效率。",
  "summary": "时间序列模型在处理大规模复杂数据集时面临显著挑战，尤其在实现与大型语言模型相似的扩展性方面。针对时间序列数据的独特特性和模型扩展的计算需求，研究人员探索了包括Transformers、LSTMs和GRUs等在内的多种架构。本文提出一种新颖的解决方案，使用RWKV-7模型，该模型在状态更新机制中融入了元学习。通过将RWKV-7的时间混合和通道混合组件整合到基于Transformer的时间序列模型Timer中，我们实现了性能显著提升，约为1.13至43.3倍，同时训练时间缩短了4.5倍，所需参数减少至原来的1/23。我们的代码和模型权重可在https:
  "keyword": ["时间序列模型", "RWKV-7", "性能提升"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 292 (char 381). Line: 406.
Append: [BlackGoose Rimer: Harnessing RWKV-7 as a Simple yet Superior Replacement for Transformers in Large-Scale Time Series Modeling](https://arxiv.org/abs/2503.06121)
Token length: 940
Summarized using gpt-4o-mini
Append: [NeuGrasp：应对透明和镜面物体抓取的神经表面重建方法](https://arxiv.org/abs/2503.03511)
Token length: 1040
Summarized using gpt-4o-mini
Append: [基于状态的参数高效微调方法在状态空间模型中的应用](https://arxiv.org/abs/2503.03499)
Token length: 1323
Summarized using gpt-4o-mini
Append: [LLaVE：增强多模态嵌入模型表现的动态框架](https://arxiv.org/abs/2503.04812)
Token length: 1545
Summarized using gpt-4o-mini
Append: [解析视觉语言模型中的文本偏见现象及其影响](https://arxiv.org/abs/2503.02199)
append_entries: 17
Finish: 2025-03-11 03:20:54.388351
------------------------------------------------------
Started: 2025-03-11 06:00:58.401334
Existing_entries: 498
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-11 06:00:58.583399
------------------------------------------------------
Started: 2025-03-11 09:00:55.636184
Existing_entries: 498
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1464
Summarized using gpt-4o-mini
Append: [AlphaDrive：基于强化学习和推理的自动驾驶视觉语言模型框架](https://arxiv.org/abs/2503.07608)
Token length: 1009
Summarized using gpt-4o-mini
Append: [图像与文本结合预训练模型在视语言任务中的表现](https://arxiv.org/abs/2503.07603)
Token length: 1799
Summarized using gpt-4o-mini
Append: [DreamRelation：一种基于示例视频的个性化关系视频定制方法](https://arxiv.org/abs/2503.07602)
Token length: 1514
Summarized using gpt-4o-mini
Append: [MedAgentsBench: 复杂医学问题的新评估基准](https://arxiv.org/abs/2503.07459)
Token length: 964
Summarized using gpt-4o-mini
Append: [DistiLLM-2：通过对比学习提升语言模型蒸馏效果](https://arxiv.org/abs/2503.07067)
Token length: 1025
Summarized using gpt-4o-mini
Append: [ProBench: 新型多模态智能评估基准的构建与实证分析](https://arxiv.org/abs/2503.06885)
Token length: 1615
Summarized using gpt-4o-mini
Append: [Vision-R1：增强多模态推理能力的深度学习模型](https://arxiv.org/abs/2503.06749)
Token length: 1110
Summarized using gpt-4o-mini
Append: [SurveyForge：提升文献综述生成质量的自动化工具](https://arxiv.org/abs/2503.04629)
Token length: 963
Summarized using gpt-4o-mini
Append: [提升人工文本检测的可解释性：稀疏自编码器的应用](https://arxiv.org/abs/2503.03601)
append_entries: 9
Finish: 2025-03-11 09:01:34.848673
------------------------------------------------------
Started: 2025-03-11 12:01:15.048198
Existing_entries: 507
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1822
Summarized using gpt-4o-mini
Append: [YOLOE：高效的开放式检测与分割模型](https://arxiv.org/abs/2503.07465)
Token length: 982
Summarized using gpt-4o-mini
Append: [基于ReLU的偏好优化算法RePO：简化语言模型对齐方法](https://arxiv.org/abs/2503.07426)
Token length: 1503
Summarized using gpt-4o-mini
Append: [Llama-MTSK：一种灵活的音视频识别多模态语言模型](https://arxiv.org/abs/2503.06362)
Token length: 1454
Summarized using gpt-4o-mini
Append: [探索三维编码器与文本特征空间的后期对齐](https://arxiv.org/abs/2503.05283)
Token length: 1178
Summarized using gpt-4o-mini
Append: [WritingBench：提升大语言模型写作能力的综合评估基准](https://arxiv.org/abs/2503.05244)
append_entries: 5
Finish: 2025-03-11 12:01:48.593876
------------------------------------------------------
Started: 2025-03-11 15:00:50.081634
Existing_entries: 512
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1207
Summarized using gpt-4o-mini
Append: [基于多镜头视频的人类动作重建框架](https://arxiv.org/abs/2503.07597)
Token length: 1466
Summarized using gpt-4o-mini
Append: [适配器引导蒸馏：提升条件扩散模型采样效率](https://arxiv.org/abs/2503.07274)
Token length: 1321
Summarized using gpt-4o-mini
Append: [WISE：基于世界知识的文本到图像生成语义评估基准](https://arxiv.org/abs/2503.07265)
Token length: 1356
Summarized using gpt-4o-mini
Append: [新型零样本音视频语音识别框架Zero-AVSR](https://arxiv.org/abs/2503.06273)
Json decode failed:
{
  "title": "一种单参考视角的新颖物体6D姿态估计方法",
  "short_summary": "提出了一种基于单参考视角的6D姿态估计方法SinRef-6D。",
  "summary": "本文提出了一种新颖的6D姿态估计方法SinRef-6D，旨在解决传统方法依赖CAD模型或密集参考视图所带来的困难。该方法通过迭代建立基于状态空间模型的点云对齐，能够有效处理较大的姿态偏差。此外，SinRef-6D引入的RGB和Points状态空间模型能够从单一视角捕获远程依赖关系和空间信息，具备线性复杂度和优越的空间建模能力。在通过合成数据预训练后，SinRef-6D无须重训练或CAD模型即可仅用单个参考视角估计新颖物体的6D姿态。通过在六个流行数据集和现实机器人场景进行广泛实验，我们的结果显示，尽管在更具挑战性的单参考设置下，SinRef-6D的表现与基于CAD和密集参考视图的方法相当。代码将发布于https:
  "keyword": [
    "6D姿态估计",
    "单参考视角",
    "状态空间模型"
  ]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 325 (char 415). Line: 406.
Append: [Novel Object 6D Pose Estimation with a Single Reference View](https://arxiv.org/abs/2503.05578)
Token length: 1248
Summarized using gpt-4o-mini
Append: [Mixture of Large Language Model Agents的安全性与防御机制研究](https://arxiv.org/abs/2503.05856)
Token length: 1102
Summarized using gpt-4o-mini
Append: [任务感知的键值缓存压缩：提升大型语言模型的信息处理效率](https://arxiv.org/abs/2503.04973)
append_entries: 7
Finish: 2025-03-11 15:01:38.440160
------------------------------------------------------
Started: 2025-03-11 18:00:59.771585
Existing_entries: 519
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1797
Summarized using gpt-4o-mini
Append: [REF-VLM：统一视觉解码任务的多模态大型语言模型框架](https://arxiv.org/abs/2503.07413)
Token length: 1760
Summarized using gpt-4o-mini
Append: [TRCE：提高文本生成模型中恶意内容的概念抹除能力](https://arxiv.org/abs/2503.07389)
Token length: 1429
Summarized using gpt-4o-mini
Append: [自回归表示对齐框架（ARRA）在文本到图像生成中的应用](https://arxiv.org/abs/2503.07334)
Token length: 1389
Summarized using gpt-4o-mini
Append: [基于SlotMIM的预训练视觉模型在机器人学习中的优化研究](https://arxiv.org/abs/2503.06960)
Token length: 853
Summarized using gpt-4o-mini
Append: [DiffCLIP：基于差分注意力机制的视觉-语言模型](https://arxiv.org/abs/2503.06626)
Token length: 1918
Summarized using gpt-4o-mini
Append: [Symbolic-MoE：基于技能的专家选择框架提升LLM性能](https://arxiv.org/abs/2503.05641)
append_entries: 6
Finish: 2025-03-11 18:01:38.956639
------------------------------------------------------
Started: 2025-03-11 21:00:53.296461
Existing_entries: 525
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1394
Summarized using gpt-4o-mini
Append: [VACE：全能视频生成与编辑框架](https://arxiv.org/abs/2503.07598)
Token length: 1220
Summarized using gpt-4o-mini
Append: [提升模型领域泛化能力的方法研究](https://arxiv.org/abs/2503.06698)
Json decode failed:
{
  "title": "语言模型在一对多事实查询中的知识回忆机制",
  "keyword": ["语言模型", "知识回忆", "答案抑制"],
  "short_summary": "语言模型通过促进与抑制机制实现一对多事实查询。",
  "summary": "本文探讨了语言模型（LM）在处理一对多事实查询时如何同时进行知识回忆与避免重复答案。我们提出了一种促进-抑制机制：模型首先回忆出所有可能的答案，然后抑制之前生成的答案。具体而言，LM通过主题和先前答案的标记执行知识回忆，注意力机制传播主题信息，而多层感知机（MLP）则促进答案生成。随后，注意力机制针对并抑制先前的答案标记，而MLP增强抑制信号。通过丰富的实验数据支持该机制的有效性，我们还引入了Token Lens方法，分析特定标记的注意力更新，以及击败方法，研究去除特定标记的注意力后MLP输出的变化。这项研究为了解语言模型内部组件如何与不同输入标记交互，从而支持复杂的事实回忆提供了新视角。代码可在 https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 324 (char 445). Line: 406.
Append: [Promote, Suppress, Iterate: How Language Models Answer One-to-Many Factual Queries](https://arxiv.org/abs/2502.20475)
append_entries: 3
Finish: 2025-03-11 21:01:11.642646
------------------------------------------------------
Started: 2025-03-12 00:36:03.594709
Existing_entries: 528
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-12 00:36:03.910660
------------------------------------------------------
Started: 2025-03-12 03:18:26.258108
Existing_entries: 528
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 896
Summarized using gpt-4o-mini
Append: [PhiloBERTA：跨语言的古希腊与拉丁语词汇语义关系测量](https://arxiv.org/abs/2503.05265)
Json decode failed:
{
  "title": "基于费曼-卡克修正的有效取样方法",
  "keyword": ["生成模型", "取样方法", "费曼-卡克"],
  "short_summary": "本文提出了一种基于费曼-卡克修正的有效取样方法。",
  "summary": "本文探讨了在基于评分的生成模型中控制推理行为的新方法。现有的无分类器指导方法依赖简单启发式，将条件和无条件得分混合，无法有效近似中间分布，导致额外的"修正"步骤。我们提出了一种高效且原则性的取样方法，利用来自预训练评分模型的退火、几何平均或乘积分布。通过导出基于费曼-卡克公式的加权仿真方案（Feynman-Kac Correctors, FKC），我们精确考虑适当偏微分方程（PDE）中的各项。为了模拟这些PDE，我们提出了利用推理时间缩放以提升取样质量的序列蒙特卡洛（SMC）重采样算法。通过推理时间温度退火、提升多目标分子生成的表现，以及改善文本到图像生成的无分类器指导，我们实证验证了我们方法的实用性。"
}Summarization failed, append the original article
error: Expecting ',' delimiter: line 5 column 90 (char 209). Line: 406.
Append: [Feynman-Kac Correctors in Diffusion: Annealing, Guidance, and Product of Experts](https://arxiv.org/abs/2503.02819)
append_entries: 2
Finish: 2025-03-12 03:18:37.501434
------------------------------------------------------
Started: 2025-03-12 06:00:53.669010
Existing_entries: 530
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1328
Summarized using gpt-4o-mini
Append: [新型视觉标记化框架的结构化实现](https://arxiv.org/abs/2503.08685)
Token length: 1653
Summarized using gpt-4o-mini
Append: [SynCoS：一种同步耦合采样框架用于长视频生成](https://arxiv.org/abs/2503.08605)
Token length: 1550
Summarized using gpt-4o-mini
Append: [UniF^2ace：用于细粒度面部理解与生成的统一多模态模型](https://arxiv.org/abs/2503.08120)
Token length: 1456
Summarized using gpt-4o-mini
Append: [促进东南亚文化多样性：SEA-VL开放源代码计划](https://arxiv.org/abs/2503.07920)
Token length: 1280
Summarized using gpt-4o-mini
Append: [VidDiff：识别视频中细微动作差异的新任务与基准](https://arxiv.org/abs/2503.07860)
Token length: 1910
Summarized using gpt-4o-mini
Append: [Seedream 2.0：双语图像生成模型的进步](https://arxiv.org/abs/2503.07703)
Token length: 1322
Summarized using gpt-4o-mini
Append: [语言模型的隐式推理能力与多步骤推理的研究](https://arxiv.org/abs/2503.07604)
Token length: 1618
Summarized using gpt-4o-mini
Append: [优化测试时间计算的元强化学习方法](https://arxiv.org/abs/2503.07572)
Json decode failed:
{
  "title": "提升大规模多模态模型中的推理能力",
  "keyword": [
    "多模态推理",
    "强化学习",
    "基础推理增强"
  ],
  "short_summary": "提出一种两阶段框架以增强多模态模型的推理能力。",
  "summary": "本文探讨了在大规模多模态模型中增强推理能力所面临的独特挑战，特别是在3B参数的紧凑架构中，视觉感知与逻辑推理之间的复杂相互作用限制了推理能力和模态对齐。针对基于规则的强化学习在文本领域的优越表现，提出了一种名为\method的两阶段框架，通过基础推理增强（FRE）和多模态泛化训练（MGT）来适应多模态推理需求。FRE阶段利用文本数据强化推理能力，而MGT阶段则将这些能力推广至多模态领域。在Qwen2.5-VL-Instruct-3B上的实验显示，\method在多模态和文本基准上分别比基线平均提高了4.83%和4.5%，在复杂的足球比赛任务中提高了3.63%。这些结果验证了基于文本的推理增强能够有效实现多模态泛化，提供了一种绕过高质量多模态训练数据的成本有效方案。"
}Summarization failed, append the original article
error: Invalid \escape: line 9 column 120 (char 256). Line: 406.
Append: [LMM-R1: Empowering 3B LMMs with Strong Reasoning Abilities Through Two-Stage Rule-Based RL](https://arxiv.org/abs/2503.07536)
Token length: 1460
Summarized using gpt-4o-mini
Append: [MoE-X：一种具备内在可解释性的混合专家语言模型](https://arxiv.org/abs/2503.07639)
append_entries: 10
Finish: 2025-03-12 06:01:55.587084
------------------------------------------------------
Started: 2025-03-12 09:01:07.885419
Existing_entries: 540
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1476
Summarized using gpt-4o-mini
Append: [QuoTA：基于查询重要性评估的视频标记分配模型](https://arxiv.org/abs/2503.08689)
Token length: 1380
Summarized using gpt-4o-mini
Append: [OmniMamba：首个线性架构的多模态生成模型](https://arxiv.org/abs/2503.08686)
Token length: 1452
Summarized using gpt-4o-mini
Append: [YuE：创新的长篇音乐生成模型](https://arxiv.org/abs/2503.08638)
Token length: 1774
Summarized using gpt-4o-mini
Append: [新的人类类掩膜标注任务：提升多模态大语言模型的像素理解能力](https://arxiv.org/abs/2503.08625)
Token length: 1567
Summarized using gpt-4o-mini
Append: [LightGen：一种高效的文本到图像生成方法](https://arxiv.org/abs/2503.08619)
Token length: 1139
Summarized using gpt-4o-mini
Append: [BiasEdit：一种去除语言模型刻板偏见的高效编辑方法](https://arxiv.org/abs/2503.08588)
Token length: 1050
Summarized using gpt-4o-mini
Append: [Gemini Embedding：多语言嵌入模型的突破](https://arxiv.org/abs/2503.07891)
Token length: 920
Summarized using gpt-4o-mini
Append: [RayFlow: 一种提升扩散模型生成效率的新框架](https://arxiv.org/abs/2503.07699)
Token length: 1908
Summarized using gpt-4o-mini
Append: [生存游戏：评估人工智能自主水平的框架](https://arxiv.org/abs/2502.18858)
append_entries: 9
Finish: 2025-03-12 09:02:02.526145
------------------------------------------------------
Started: 2025-03-12 12:13:40.001610
Existing_entries: 549
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1396
Summarized using gpt-4o-mini
Append: [提升计算机视觉中的个体识别能力：RexSeek模型与HumanRef数据集](https://arxiv.org/abs/2503.08507)
Token length: 1162
Summarized using gpt-4o-mini
Append: [一种无训练的人脸匿名化方法](https://arxiv.org/abs/2503.08478)
Token length: 860
Summarized using gpt-4o-mini
Append: [一种新型Transformer架构用于音视频生成的研究](https://arxiv.org/abs/2503.08307)
Token length: 1782
Summarized using gpt-4o-mini
Append: [智能记忆管理系统SECOND ME的创新应用](https://arxiv.org/abs/2503.08102)
Token length: 1201
Summarized using gpt-4o-mini
Append: [结合大语言模型与神经机器翻译的高效模型](https://arxiv.org/abs/2503.06594)
Token length: 1164
Summarized using gpt-4o-mini
Append: [VisualSimpleQA：一项针对大规模视觉语言模型的多模态基准评测](https://arxiv.org/abs/2503.06492)
Token length: 1601
Summarized using gpt-4o-mini
Append: [MagicInfinite：高保真多角色肖像动画的新方法](https://arxiv.org/abs/2503.05978)
Token length: 1585
Summarized using gpt-4o-mini
Append: [AI4SE基准的评估与优化：BenchScout和BenchFrame的应用](https://arxiv.org/abs/2503.05860)
append_entries: 8
Finish: 2025-03-12 12:14:29.406469
------------------------------------------------------
Started: 2025-03-12 15:01:02.049296
Existing_entries: 557
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1348
Summarized using gpt-4o-mini
Append: [源偏差与PLM基础检索模型的因果分析](https://arxiv.org/abs/2503.08684)
Token length: 977
Summarized using gpt-4o-mini
Append: [AnyMoLe：一种无数据集依赖的角色运动插值方法](https://arxiv.org/abs/2503.08417)
append_entries: 2
Finish: 2025-03-12 15:01:21.746205
------------------------------------------------------
Started: 2025-03-12 18:10:28.691344
Existing_entries: 559
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1102
Summarized using gpt-4o-mini
Append: [指令跟随检索器的安全风险研究](https://arxiv.org/abs/2503.08644)
Token length: 1251
Summarized using gpt-4o-mini
Append: [ObjectMover：应对复杂场景的物体移动生成模型](https://arxiv.org/abs/2503.08037)
Token length: 1315
Summarized using gpt-4o-mini
Append: [多模态基础模型在自驾车中人类与机器驾驶反应的比较研究](https://arxiv.org/abs/2503.07587)
Token length: 1187
Summarized using gpt-4o-mini
Append: [CineBrain：首个动态视听刺激下的EEG与fMRI同步记录数据集](https://arxiv.org/abs/2503.06940)
append_entries: 4
Finish: 2025-03-12 18:10:54.422211
------------------------------------------------------
Started: 2025-03-12 21:00:56.441148
Existing_entries: 563
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-12 21:00:56.730850
------------------------------------------------------
Started: 2025-03-13 00:36:50.507439
Existing_entries: 563
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 810
Summarized using gpt-4o-mini
Append: [引导矩匹配模型：快速稳定的生成模型](https://arxiv.org/abs/2503.07565)
Token length: 953
Summarized using gpt-4o-mini
Append: [多模态智能的推理优先视角及生成预训练算法的创新](https://arxiv.org/abs/2503.07154)
Token length: 1281
Summarized using gpt-4o-mini
Append: [通过容量感知推理优化混合专家模型的效率](https://arxiv.org/abs/2503.05066)
Token length: 1225
Summarized using gpt-4o-mini
Append: [深度检索模型中的偏见与鲁棒性研究](https://arxiv.org/abs/2503.05037)
Token length: 1155
Summarized using gpt-4o-mini
Append: [OTTER：一种新的视觉-语言-行动模型实现有效的机器人操作](https://arxiv.org/abs/2503.03734)
append_entries: 5
Finish: 2025-03-13 00:37:16.911314
------------------------------------------------------
Started: 2025-03-13 03:20:06.162343
Existing_entries: 568
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1259
Summarized using gpt-4o-mini
Append: [PlainQAFact框架在医疗领域中的事实性评估](https://arxiv.org/abs/2503.08890)
append_entries: 1
Finish: 2025-03-13 03:20:10.163092
------------------------------------------------------
Started: 2025-03-13 06:10:50.986485
Existing_entries: 569
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1043
Summarized using gpt-4o-mini
Append: [块扩散语言模型：突破生成限制的新方法](https://arxiv.org/abs/2503.09573)
Token length: 1288
Summarized using gpt-4o-mini
Append: [scMMGPT：结合细胞与文本建模的单细胞多模态生成预训练变换器](https://arxiv.org/abs/2503.09427)
append_entries: 2
Finish: 2025-03-13 06:11:03.139515
------------------------------------------------------
Started: 2025-03-13 09:00:52.457469
Existing_entries: 571
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1189
Summarized using gpt-4o-mini
Append: [TPDiff: 高效视频扩散模型的多阶段训练框架](https://arxiv.org/abs/2503.09566)
Token length: 1259
Summarized using gpt-4o-mini
Append: [增强一致性的潜在扩散模型（AF-LDM）](https://arxiv.org/abs/2503.09419)
Token length: 1473
Summarized using gpt-4o-mini
Append: [VLog: 一种基于语言模型的视频理解框架](https://arxiv.org/abs/2503.09402)
Token length: 1178
Summarized using gpt-4o-mini
Append: [Reangle-A-Video：新型同步多视角视频生成框架](https://arxiv.org/abs/2503.09151)
Token length: 1348
Summarized using gpt-4o-mini
Append: [Motion Anything：一种多模态运动生成框架](https://arxiv.org/abs/2503.06955)
append_entries: 5
Finish: 2025-03-13 09:01:31.764941
------------------------------------------------------
Started: 2025-03-13 12:14:03.571500
Existing_entries: 576
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1025
Summarized using gpt-4o-mini
Append: [RewardSDS: 基于对齐评分的采样优化方法](https://arxiv.org/abs/2503.09601)
Token length: 1231
Summarized using gpt-4o-mini
Append: [基于大语言模型的文本块处理优化研究](https://arxiv.org/abs/2503.09600)
Token length: 1348
Summarized using gpt-4o-mini
Append: [优化大语言模型的构建：上下文长度与注意力头的影响](https://arxiv.org/abs/2503.09579)
Token length: 1386
Summarized using gpt-4o-mini
Append: [通过可验证结果奖励强化学习提升视觉语言模型的推理能力](https://arxiv.org/abs/2503.08525)
Token length: 1424
Summarized using gpt-4o-mini
Append: [高效遥感图像的视觉语言理解方法](https://arxiv.org/abs/2503.07588)
Token length: 1830
Summarized using gpt-4o-mini
Append: [优化LLM的量化技术以提高代码生成效率](https://arxiv.org/abs/2503.07103)
Token length: 1087
Summarized using gpt-4o-mini
Append: [WildIFEval: 一个多约束用户指令评估数据集](https://arxiv.org/abs/2503.06573)
Token length: 790
Summarized using gpt-4o-mini
Append: [文档数量对检索增强生成性能的影响研究](https://arxiv.org/abs/2503.04388)
append_entries: 8
Finish: 2025-03-13 12:14:50.892657
------------------------------------------------------
Started: 2025-03-13 15:00:59.407126
Existing_entries: 584
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-13 15:00:59.642450
------------------------------------------------------
Started: 2025-03-13 18:00:43.601778
Existing_entries: 584
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1322
Summarized using gpt-4o-mini
Append: [BIMBA模型：应对长视频的高效视频问答](https://arxiv.org/abs/2503.09590)
Token length: 1201
Summarized using gpt-4o-mini
Append: [一种基于扩散的蒙特卡洛采样方法提升学习型RANSAC的泛化能力](https://arxiv.org/abs/2503.09410)
Token length: 920
Summarized using gpt-4o-mini
Append: [小型语言模型的自我纠错机制研究](https://arxiv.org/abs/2503.08681)
Token length: 957
Summarized using gpt-4o-mini
Append: [基于多代理的智能医疗助手：克服隐私与延迟挑战](https://arxiv.org/abs/2503.05397)
append_entries: 4
Finish: 2025-03-13 18:01:03.697579
------------------------------------------------------
Started: 2025-03-13 21:00:57.451865
Existing_entries: 588
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-13 21:00:57.701716
------------------------------------------------------
Started: 2025-03-14 00:35:49.160356
Existing_entries: 588
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1367
Summarized using gpt-4o-mini
Append: [Search-R1：通过强化学习优化的大型语言模型检索能力](https://arxiv.org/abs/2503.09516)
Token length: 1775
Summarized using gpt-4o-mini
Append: [改进机器学习力场在分布转移中的泛化能力](https://arxiv.org/abs/2503.08674)
Json decode failed:
{
  "title": "生成模型在物理模拟中的应用研究",
  "short_summary": "本文探讨生成模型在物理模拟中的性能与局限性。",
  "summary": "随着生成学习模型在复杂映射估计中的显著进展，本文建议研究其在物理模拟中的潜力。提供了一个包含30万个图像对的数据集及三个不同物理模拟任务的基线评估，旨在探讨两个问题：一是生成模型是否能够从输入输出图像对中学习复杂的物理关系；二是通过替代基于微分方程的模拟能实现多少加速。基线评估显示，尽管当前模型具有潜在的高加速能力，但在物理正确性方面也存在显著限制，这强调了迫切需要新的方法来加强物理正确性。数据、基线模型和评估代码可访问http:
  "keyword": ["生成模型", "物理模拟", "图像对"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 232 (char 308). Line: 406.
Append: [PhysicsGen: Can Generative Models Learn from Images to Predict Complex Physical Relations?](https://arxiv.org/abs/2503.05333)
append_entries: 3
Finish: 2025-03-14 00:36:03.332561
------------------------------------------------------
Started: 2025-03-14 03:19:24.134295
Existing_entries: 591
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-14 03:19:24.320271
------------------------------------------------------
Started: 2025-03-14 06:10:54.165399
Existing_entries: 591
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1469
Summarized using gpt-4o-mini
Append: [Generation Chain-of-Thought: 提升图像生成与编辑的推理驱动框架](https://arxiv.org/abs/2503.10639)
Token length: 1654
Summarized using gpt-4o-mini
Append: [提升蒸馏扩散模型多样性的研究](https://arxiv.org/abs/2503.10637)
Json decode failed:
{
  "title": "改进的条件最优传输方法提升无条件流匹配性能",
  "keyword": ["最优传输", "条件流匹配", "深度学习"],
  "short_summary": "提出条件最优传输C^2OT以改善流匹配中的训练和测试性能差异。",
  "summary": "本研究讨论了在无条件流匹配中使用的小批量最优传输方法，该方法通过简化计算减少了推理时的计算需求。然而，在条件流匹配中，该方法存在不足，因为默认的最优传输映射忽视了条件，导致训练过程中生成的先验分布存在偏斜。在测试时，我们无法使用偏斜的先验，而是从完整的无偏先验中进行采样。这种训练和测试之间的差距导致了性能下降。为了解决这一问题，我们提出了条件最优传输C^2OT，通过在计算最优传输分配时在成本矩阵中添加条件权重项来调整模型。实验表明，该简单修正方法在8gaussians-to-moons、CIFAR-10、ImageNet-32x32和ImageNet-256x256等数据集上均优于现有基线，展示了其在不同函数评估预算下的总体优势。代码可在 https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 345 (char 476). Line: 406.
Append: [The Curse of Conditions: Analyzing and Improving Optimal Transport for Conditional Flow-Based Generation](https://arxiv.org/abs/2503.10636)
Token length: 1571
Summarized using gpt-4o-mini
Append: [通用零样本目标导航的统一框架](https://arxiv.org/abs/2503.10630)
Token length: 1564
Summarized using gpt-4o-mini
Append: [R1-Onevision：跨模态推理模型的创新与评估](https://arxiv.org/abs/2503.10615)
Token length: 1540
Summarized using gpt-4o-mini
Append: [结合LLMs与图搜索的高效多回合图像编辑方法CoSTA*](https://arxiv.org/abs/2503.10613)
Token length: 1222
Summarized using gpt-4o-mini
Append: [GroundingSuite：推动视觉与语言交互的创新数据集](https://arxiv.org/abs/2503.10596)
Token length: 1223
Summarized using gpt-4o-mini
Append: [长上下文调优：提升视频生成一致性的训练方法](https://arxiv.org/abs/2503.10589)
Token length: 1421
Summarized using gpt-4o-mini
Append: [VisualWebInstruct：提升视觉语言模型推理能力的新数据集](https://arxiv.org/abs/2503.10582)
Token length: 1320
Summarized using gpt-4o-mini
Append: [ARPG：一种新型视觉自回归模型的提出](https://arxiv.org/abs/2503.10568)
Token length: 1079
Summarized using gpt-4o-mini
Append: [基于双偏好优化的新框架提升大型视觉语言模型的任务规划能力](https://arxiv.org/abs/2503.10480)
Token length: 1585
Summarized using gpt-4o-mini
Append: [Light-R1系列模型训练与性能提升研究](https://arxiv.org/abs/2503.10460)
Token length: 1877
Summarized using gpt-4o-mini
Append: [4D LangSplat：动态场景中的时间敏感语言查询](https://arxiv.org/abs/2503.10437)
Token length: 1517
Summarized using gpt-4o-mini
Append: [基于多模态大语言模型的多主体视频生成框架CINEMA](https://arxiv.org/abs/2503.10391)
Token length: 1804
Summarized using gpt-4o-mini
Append: [大型推理模型在机器翻译中的变革与挑战](https://arxiv.org/abs/2503.10351)
Token length: 899
Summarized using gpt-4o-mini
Append: [开源软件开发中错误报告讨论的毒性影响](https://arxiv.org/abs/2503.10072)
Token length: 1350
Summarized using gpt-4o-mini
Append: [Whisper模型的性能分析与量化方法研究](https://arxiv.org/abs/2503.09905)
Token length: 1328
Summarized using gpt-4o-mini
Append: [静默品牌攻击：数据中毒对文本生成图像模型的影响](https://arxiv.org/abs/2503.09669)
Token length: 1085
Summarized using gpt-4o-mini
Append: [Open-Sora 2.0：高效的商业级视频生成模型](https://arxiv.org/abs/2503.09642)
Token length: 925
Summarized using gpt-4o-mini
Append: [长输出生成的研究重要性与挑战](https://arxiv.org/abs/2503.04723)
append_entries: 20
Finish: 2025-03-14 06:12:25.197357
------------------------------------------------------
Started: 2025-03-14 09:00:41.330758
Existing_entries: 611
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1029
Summarized using gpt-4o-mini
Append: [探索Hugging Face模型的初步图谱及其潜力](https://arxiv.org/abs/2503.10633)
Token length: 1078
Summarized using gpt-4o-mini
Append: [动态Tanh：非标准化变压器的性能提升](https://arxiv.org/abs/2503.10622)
Token length: 1124
Summarized using gpt-4o-mini
Append: [Diffusion Transformers在文本到图像生成中的应用研究](https://arxiv.org/abs/2503.10618)
Token length: 1543
Summarized using gpt-4o-mini
Append: [SANA-Sprint：高效的文本到图像生成模型](https://arxiv.org/abs/2503.09641)
append_entries: 4
Finish: 2025-03-14 09:01:01.094616
------------------------------------------------------
Started: 2025-03-14 12:00:38.041598
Existing_entries: 615
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-14 12:00:38.297504
------------------------------------------------------
Started: 2025-03-14 15:00:39.898902
Existing_entries: 615
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1081
Summarized using gpt-4o-mini
Append: [文本到图像模型在分类概念生成中的应用研究](https://arxiv.org/abs/2503.10357)
Token length: 1249
Summarized using gpt-4o-mini
Append: [VisualPRM：增强多模态推理能力的过程奖励模型](https://arxiv.org/abs/2503.10291)
Token length: 837
Summarized using gpt-4o-mini
Append: [探究视觉语言模型在图像理解中的不足](https://arxiv.org/abs/2503.09837)
Token length: 1681
Summarized using gpt-4o-mini
Append: [CoRe²: 高效且有效的文本到图像生成模型推理框架](https://arxiv.org/abs/2503.09662)
Json decode failed:
{
  "title": "PerCoV2：一种新型的超低比特率感知图像压缩系统",
  "keyword": ["图像压缩", "感知质量", "低比特率"],
  "short_summary": "PerCoV2是一种新型的超低比特率图像压缩系统，旨在提升图像质量和压缩效率。",
  "summary": "PerCoV2是一种新开发的开源超低比特率感知图像压缩系统，专为带宽和存储受限的应用而设计。该系统在Careil等人之前工作的基础上进行了扩展，整合了Stable Diffusion 3生态系统，通过显式建模离散超潜图像分布，提高了熵编码效率。我们对最新的自回归方法（VAR和MaskGIT）进行了全面比较，并在大规模的MSCOCO-30k基准上评估了我们的方法。与以往的工作相比，PerCoV2在更低的比特率下实现了更高的图像保真度，同时保持了竞争力的感知质量，具有更省比特率的混合生成模式，并且完全基于公共组件构建。相关代码和训练模型将在https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 292 (char 435). Line: 406.
Append: [PerCoV2: Improved Ultra-Low Bit-Rate Perceptual Image Compression with Implicit Hierarchical Masked Image Modeling](https://arxiv.org/abs/2503.09368)
append_entries: 5
Finish: 2025-03-14 15:01:05.044930
------------------------------------------------------
Started: 2025-03-14 18:00:58.052788
Existing_entries: 620
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1315
Summarized using gpt-4o-mini
Append: [ConsisLoRA: 改进的样式转移方法与评估](https://arxiv.org/abs/2503.10614)
Token length: 1590
Summarized using gpt-4o-mini
Append: [应对大规模视觉语言模型中的物体幻觉挑战](https://arxiv.org/abs/2503.10602)
Token length: 1230
Summarized using gpt-4o-mini
Append: [融合视觉成分的生成框架：IP-Prior与基于LoRA的微调策略](https://arxiv.org/abs/2503.10365)
Token length: 965
Summarized using gpt-4o-mini
Append: [儿童与大型语言模型的安全性研究](https://arxiv.org/abs/2503.10242)
Token length: 1160
Summarized using gpt-4o-mini
Append: [DiLoCo在大模型训练中的扩展性研究](https://arxiv.org/abs/2503.09799)
Token length: 1684
Summarized using gpt-4o-mini
Append: [探索视觉Transformer模型中的关键神经元路径](https://arxiv.org/abs/2503.09046)
Token length: 1019
Summarized using gpt-4o-mini
Append: [OmniPaint：一种统一的图像对象去除与插入框架](https://arxiv.org/abs/2503.08677)
append_entries: 7
Finish: 2025-03-14 18:01:37.743478
------------------------------------------------------
Started: 2025-03-14 21:00:47.330299
Existing_entries: 627
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-14 21:00:47.681055
------------------------------------------------------
Started: 2025-03-15 00:35:45.038990
Existing_entries: 627
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1164
Summarized using gpt-4o-mini
Append: [无分类器引导在条件生成中的新视角](https://arxiv.org/abs/2503.10638)
Token length: 1901
Summarized using gpt-4o-mini
Append: [提高黑箱商业视觉语言模型的对抗攻击效果](https://arxiv.org/abs/2503.10635)
append_entries: 2
Finish: 2025-03-15 00:35:54.395312
------------------------------------------------------
Started: 2025-03-15 03:16:04.689202
Existing_entries: 629
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-15 03:16:04.863360
------------------------------------------------------
Started: 2025-03-15 06:09:34.632137
Existing_entries: 629
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 747
Summarized using gpt-4o-mini
Append: [PoseLess: 一种无姿态估计的机器人手控制框架](https://arxiv.org/abs/2503.07111)
append_entries: 1
Finish: 2025-03-15 06:09:38.629323
------------------------------------------------------
Started: 2025-03-15 09:00:57.082849
Existing_entries: 630
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-15 09:00:57.299565
------------------------------------------------------
Started: 2025-03-15 12:11:26.512590
Existing_entries: 630
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-15 12:11:26.717238
------------------------------------------------------
Started: 2025-03-15 15:00:32.792237
Existing_entries: 630
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-15 15:00:32.989741
------------------------------------------------------
Started: 2025-03-15 18:00:59.525518
Existing_entries: 630
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-15 18:00:59.767153
------------------------------------------------------
Started: 2025-03-15 21:00:40.600342
Existing_entries: 630
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-15 21:00:40.881444
------------------------------------------------------
Started: 2025-03-16 00:39:46.629217
Existing_entries: 630
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-16 00:39:46.899850
------------------------------------------------------
Started: 2025-03-16 03:23:06.808028
Existing_entries: 630
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-16 03:23:07.052956
------------------------------------------------------
Started: 2025-03-16 06:00:49.182711
Existing_entries: 630
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-16 06:00:49.353393
------------------------------------------------------
Started: 2025-03-16 09:00:33.015269
Existing_entries: 630
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-16 09:00:33.237482
------------------------------------------------------
Started: 2025-03-16 12:00:50.971612
Existing_entries: 630
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-16 12:00:51.344029
------------------------------------------------------
Started: 2025-03-16 15:00:40.513019
Existing_entries: 630
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-16 15:00:40.747204
------------------------------------------------------
Started: 2025-03-16 18:00:47.744940
Existing_entries: 630
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-16 18:00:47.940273
------------------------------------------------------
Started: 2025-03-16 21:00:38.309709
Existing_entries: 630
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-16 21:00:38.585867
------------------------------------------------------
Started: 2025-03-17 00:38:06.985044
Existing_entries: 630
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-17 00:38:07.229544
------------------------------------------------------
Started: 2025-03-17 03:22:25.646133
Existing_entries: 630
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-17 03:22:25.903122
------------------------------------------------------
Started: 2025-03-17 06:11:21.253047
Existing_entries: 630
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-17 06:11:21.462822
------------------------------------------------------
Started: 2025-03-17 09:00:28.781042
Existing_entries: 630
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1462
Summarized using gpt-4o-mini
Append: [ReCamMaster：一种新的视频重渲染框架实现动态镜头控制](https://arxiv.org/abs/2503.11647)
Token length: 1913
Summarized using gpt-4o-mini
Append: [利用对抗数据收集提高机器人操作的效率与性能](https://arxiv.org/abs/2503.11646)
Token length: 957
Summarized using gpt-4o-mini
Append: [状态空间模型的系统概述与应用](https://arxiv.org/abs/2503.11224)
Token length: 1375
Summarized using gpt-4o-mini
Append: [API与GUI基础大语言模型代理的比较研究](https://arxiv.org/abs/2503.11069)
Token length: 1878
Summarized using gpt-4o-mini
Append: [TxAgent：推动精准药物治疗的多模态自适应AI模型](https://arxiv.org/abs/2503.10970)
Token length: 1423
Summarized using gpt-4o-mini
Append: [FlowTok：高效的文本与图像跨模态生成框架](https://arxiv.org/abs/2503.10772)
Token length: 1613
Summarized using gpt-4o-mini
Append: [基于可学习Kolmogorov-Arnold网络的视觉Transformer架构研究](https://arxiv.org/abs/2503.10632)
Token length: 1619
Summarized using gpt-4o-mini
Append: [联邦学习中的梯度反演攻击分析与防御策略](https://arxiv.org/abs/2503.11514)
Token length: 1279
Summarized using gpt-4o-mini
Append: [提升视频详细描述的模型：Cockatiel](https://arxiv.org/abs/2503.09279)
Token length: 1189
Summarized using gpt-4o-mini
Append: [PLADIS：基于稀疏注意力的高效文本到图像扩散模型优化方法](https://arxiv.org/abs/2503.07677)
Token length: 1897
Summarized using gpt-4o-mini
Append: [基于轨迹分布匹配的少步扩散模型学习](https://arxiv.org/abs/2503.06674)
Token length: 1615
Summarized using gpt-4o-mini
Append: [GoalFlow：高质量多模态轨迹生成的端到端自主驾驶方法](https://arxiv.org/abs/2503.05689)
append_entries: 12
Finish: 2025-03-17 09:01:41.966461
------------------------------------------------------
Started: 2025-03-17 12:13:44.636824
Existing_entries: 642
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1403
Summarized using gpt-4o-mini
Append: [基于密集边界框的视频字幕生成与物体定位新方法](https://arxiv.org/abs/2503.10781)
Token length: 1370
Summarized using gpt-4o-mini
Append: [新型ETC身体拟合方法提升衣着人类的拟合准确性](https://arxiv.org/abs/2503.10624)
Token length: 1627
Summarized using gpt-4o-mini
Append: [邻接自回归建模：一种新的视觉生成框架](https://arxiv.org/abs/2503.10696)
Token length: 1376
Summarized using gpt-4o-mini
Append: [MaRI框架：提升3D资产真实感的材料检索](https://arxiv.org/abs/2503.08111)
Token length: 1522
Summarized using gpt-4o-mini
Append: [ProJudgeBench：多模态大语言模型的过程评估基准](https://arxiv.org/abs/2503.06553)
Token length: 1503
Summarized using gpt-4o-mini
Append: [ARMOR：高效的多模态理解与生成框架](https://arxiv.org/abs/2503.06542)
append_entries: 6
Finish: 2025-03-17 12:14:11.762025
------------------------------------------------------
Started: 2025-03-17 15:00:54.087861
Existing_entries: 648
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 995
Summarized using gpt-4o-mini
Append: [VGGT：高效的3D场景属性推断网络](https://arxiv.org/abs/2503.11651)
Token length: 1216
Summarized using gpt-4o-mini
Append: [TreeMeshGPT：高质量艺术网格生成的新方法](https://arxiv.org/abs/2503.11629)
Token length: 1206
Summarized using gpt-4o-mini
Append: [VAMBA：高效处理长视频的混合变换器模型](https://arxiv.org/abs/2503.11579)
Token length: 1345
Summarized using gpt-4o-mini
Append: [SmolDocling：超紧凑的文档转换视觉语言模型](https://arxiv.org/abs/2503.11576)
Token length: 868
Summarized using gpt-4o-mini
Append: [将多语言大型语言模型扩展至语音模态的研究](https://arxiv.org/abs/2503.10620)
Token length: 1435
Summarized using gpt-4o-mini
Append: [群体鲁棒的机器遗忘：解决非均匀分布遗忘集的问题](https://arxiv.org/abs/2503.09330)
Token length: 1443
Summarized using gpt-4o-mini
Append: [基于自监督学习的视频技能边界检测](https://arxiv.org/abs/2503.10684)
append_entries: 7
Finish: 2025-03-17 15:01:27.920318
------------------------------------------------------
Started: 2025-03-17 18:10:16.765759
Existing_entries: 655
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-17 18:10:16.923095
------------------------------------------------------
Started: 2025-03-17 21:00:47.903413
Existing_entries: 655
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1632
Summarized using gpt-4o-mini
Append: [大规模推理模型在类比推理中的性能评估](https://arxiv.org/abs/2503.11207)
append_entries: 1
Finish: 2025-03-17 21:00:52.388294
------------------------------------------------------
Started: 2025-03-18 00:36:22.088674
Existing_entries: 656
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-18 00:36:22.251125
------------------------------------------------------
Started: 2025-03-18 03:21:45.411777
Existing_entries: 656
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1137
Summarized using gpt-4o-mini
Append: [CHOrD框架：高效生成3D室内场景的创新方法](https://arxiv.org/abs/2503.11958)
append_entries: 1
Finish: 2025-03-18 03:21:49.368334
------------------------------------------------------
Started: 2025-03-18 06:00:47.891377
Existing_entries: 657
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1377
Summarized using gpt-4o-mini
Append: [VideoMind：一个新的视频语言代理用于时间基础的视频理解](https://arxiv.org/abs/2503.13444)
Token length: 1541
Summarized using gpt-4o-mini
Append: [WideRange4D: 一种针对大范围空间运动的4D重建基准与方法](https://arxiv.org/abs/2503.13435)
Token length: 1873
Summarized using gpt-4o-mini
Append: [MicroVQA：生物医学研究中的多模态视觉问答基准](https://arxiv.org/abs/2503.13399)
Token length: 1212
Summarized using gpt-4o-mini
Append: [Edit Transfer: 基于少量示例的非刚性图像编辑技术](https://arxiv.org/abs/2503.13327)
Token length: 1494
Summarized using gpt-4o-mini
Append: [通过奖励增强的生成方法提升文本到图像生成控制能力](https://arxiv.org/abs/2503.13070)
Token length: 1293
Summarized using gpt-4o-mini
Append: [Step-wise Group Relative Policy Optimization提升多语言大型模型的推理能力](https://arxiv.org/abs/2503.12937)
Token length: 1544
Summarized using gpt-4o-mini
Append: [DreamRenderer：增强图像生成的实例控制](https://arxiv.org/abs/2503.12885)
Token length: 1323
Summarized using gpt-4o-mini
Append: [基于扩散变换器的个性化图像生成新方法](https://arxiv.org/abs/2503.12590)
Token length: 1626
Summarized using gpt-4o-mini
Append: [Being-0: 一种高效的人形机器人自主代理框架](https://arxiv.org/abs/2503.12533)
Token length: 895
Summarized using gpt-4o-mini
Append: [视觉语言模型中的基本水平分类研究](https://arxiv.org/abs/2503.12530)
Token length: 777
Summarized using gpt-4o-mini
Append: [量化大语言模型不确定性以增强用户信任](https://arxiv.org/abs/2503.12528)
Token length: 1330
Summarized using gpt-4o-mini
Append: [强化奖励模型的鲁棒性研究](https://arxiv.org/abs/2503.11751)
Token length: 1527
Summarized using gpt-4o-mini
Append: [视频时空推理基准V-STaR的提出及视频大语言模型评估](https://arxiv.org/abs/2503.11495)
Token length: 1775
Summarized using gpt-4o-mini
Append: [MTV-Inpaint：统一多任务视频修复框架](https://arxiv.org/abs/2503.11412)
Token length: 1247
Summarized using gpt-4o-mini
Append: [理论分析与改进：自回归视频扩散模型的统一框架](https://arxiv.org/abs/2503.10704)
append_entries: 15
Finish: 2025-03-18 06:02:09.945038
------------------------------------------------------
Started: 2025-03-18 09:00:45.126613
Existing_entries: 672
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1218
Summarized using gpt-4o-mini
Append: [BlobCtrl：精确灵活的元素级视觉内容生成与编辑框架](https://arxiv.org/abs/2503.13434)
Token length: 1558
Summarized using gpt-4o-mini
Append: [提升视频生成的时空一致性研究](https://arxiv.org/abs/2503.06053)
append_entries: 2
Finish: 2025-03-18 09:00:54.258603
------------------------------------------------------
Started: 2025-03-18 12:00:58.596425
Existing_entries: 674
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1009
Summarized using gpt-4o-mini
Append: [Sightation：提升视觉障碍者图表描述的模型评估与数据集](https://arxiv.org/abs/2503.13369)
Token length: 1498
Summarized using gpt-4o-mini
Append: [基于人类指令的混杂物品抓取任务研究](https://arxiv.org/abs/2503.13082)
Token length: 1251
Summarized using gpt-4o-mini
Append: [多模态链条思维推理的系统性综述](https://arxiv.org/abs/2503.12605)
Token length: 1221
Summarized using gpt-4o-mini
Append: [LVAS-Agent: 长视频音频合成的新框架](https://arxiv.org/abs/2503.10719)
append_entries: 4
Finish: 2025-03-18 12:01:23.051761
------------------------------------------------------
Started: 2025-03-18 15:00:45.199332
Existing_entries: 678
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1600
Summarized using gpt-4o-mini
Append: [SPIN-Bench: 评估战略规划与社会推理的新基准](https://arxiv.org/abs/2503.12349)
append_entries: 1
Finish: 2025-03-18 15:00:51.542455
------------------------------------------------------
Started: 2025-03-18 18:00:44.837111
Existing_entries: 679
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1431
Summarized using gpt-4o-mini
Append: [GenStereo：高质量立体图像生成的新方法](https://arxiv.org/abs/2503.12720)
Token length: 1763
Summarized using gpt-4o-mini
Append: [WISA: 提升文本生成视频模型物理理解的新框架](https://arxiv.org/abs/2503.08153)
append_entries: 2
Finish: 2025-03-18 18:00:55.283478
------------------------------------------------------
Started: 2025-03-18 21:00:54.425873
Existing_entries: 681
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 607
Summarized using gpt-4o-mini
Append: [可扩展的开源视频基础模型训练管道](https://arxiv.org/abs/2503.12964)
append_entries: 1
Finish: 2025-03-18 21:00:58.354225
------------------------------------------------------
Started: 2025-03-19 00:36:48.815960
Existing_entries: 682
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "利用机械解释性技术的白盒对抗攻击新方法",
  "short_summary": "提出一种新方法，通过机械解释性技术提高对抗攻击成功率。",
  "summary": "本文介绍了一种新颖的白盒对抗攻击方法，结合了机械解释性技术以生成实用的对抗输入。该方法通过识别接受子空间，即不会触发模型拒绝机制的特征向量集合，采用基于梯度的优化技术将嵌入从拒绝子空间重新引导到接受子空间，以实现快速的‘越狱’效果。这种针对性的策略显著降低了计算成本，相较于现有技术，该方法在包括Gemma2、Llama3.2和Qwen2.5的先进模型上取得了80-95%的攻击成功率，仅需数分钟或甚至几秒钟。此外，该方法为攻击研究和防御开发开辟了新的方向，并展示了机械解释性的实际应用价值。相关代码和生成的数据集可在 https:
  "keyword": ["对抗攻击", "机械解释性", "接受子空间"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 281 (char 366). Line: 406.
Append: [Using Mechanistic Interpretability to Craft Adversarial Attacks against Large Language Models](https://arxiv.org/abs/2503.06269)
append_entries: 1
Finish: 2025-03-19 00:36:53.026687
------------------------------------------------------
Started: 2025-03-19 03:21:36.817233
Existing_entries: 683
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "RWKV-7 "Goose": 一种新的序列建模架构与多语言任务的最佳性能表现",
  "keyword": ["RWKV-7", "序列建模", "语言模型"],
  "short_summary": "RWKV-7在多语言任务上创造了新的最佳性能记录。",
  "summary": "RWKV-7 "Goose"是一种新型序列建模架构，提供了三十亿参数规模下的预训练语言模型，在多语言任务上创造了新的最佳性能，尽管其训练所用的语料远少于其他顶级模型。该模型在每个token的推理时间和内存使用上均保持恒定，展现出其新的广义delta规则与向量值门控及上下文学习率的结合。RWKV-7不仅能够进行状态跟踪和识别所有正规语言，还保留了训练的并行性，超越了标准复杂性猜想下的Transformer能力。同时，我们还推出了一个扩展的开源多语言语料库，包含3.1万亿个token，并基于此数据集训练了四个不同参数规模的RWKV-7模型。为促进开放性和复现性，我们发布了模型及数据集组件，代码托管在公有GitHub上，以Apache 2.0 License开放。"
}Summarization failed, append the original article
error: Expecting ',' delimiter: line 2 column 21 (char 22). Line: 406.
Append: [RWKV-7 "Goose" with Expressive Dynamic State Evolution](https://arxiv.org/abs/2503.14456)
Token length: 1301
Summarized using gpt-4o-mini
Append: [IPV-Bench：评估生成与理解不可能视频的新基准](https://arxiv.org/abs/2503.14378)
Token length: 941
Summarized using gpt-4o-mini
Append: [Frac-Connections：一种新型的深度学习连接方法](https://arxiv.org/abs/2503.14125)
Token length: 892
Summarized using gpt-4o-mini
Append: [Infinite Mobility：一种生成高保真关节物体的新方法](https://arxiv.org/abs/2503.13424)
Token length: 1280
Summarized using gpt-4o-mini
Append: [提升多模态大语言模型安全性的机器去学习基准研究](https://arxiv.org/abs/2503.12545)
Token length: 1252
Summarized using gpt-4o-mini
Append: [MPBench：评估过程级奖励模型的多任务基准](https://arxiv.org/abs/2503.12505)
Token length: 1348
Summarized using gpt-4o-mini
Append: [KUDA：集成动态学习与视觉提示的开放词汇操控系统](https://arxiv.org/abs/2503.10546)
Token length: 1619
Summarized using gpt-4o-mini
Append: [RoCo-Sim：提升路边协同感知的新模拟框架](https://arxiv.org/abs/2503.10410)
append_entries: 8
Finish: 2025-03-19 03:22:18.476850
------------------------------------------------------
Started: 2025-03-19 06:11:35.474812
Existing_entries: 691
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1561
Summarized using gpt-4o-mini
Append: [多模态大语言模型的对齐算法综述](https://arxiv.org/abs/2503.14504)
Token length: 1297
Summarized using gpt-4o-mini
Append: [AI系统任务完成时间的新度量与未来展望](https://arxiv.org/abs/2503.14499)
Json decode failed:
{
  "title": "基于时间一致性的数学验证方法",
  "keyword": ["时间一致性", "数学验证", "深度学习"],
  "short_summary": "提出一种新型时间一致性方法以提升数学验证的准确性。",
  "summary": "本文介绍了一种新颖的时间一致性方法旨在提升数学验证的效果。与传统的一轮验证或多模型辩论方法不同，我们的方法通过迭代反思的方式，基于先前的评估来逐步精炼判断，从而提高验证准确性。通过在多种数学过程错误识别基准（Mathcheck、ProcessBench和PRM800K）上的实证评估，证明了该方法在性能上一致性地优于基准方法。特别是在近期的DeepSeek R1蒸馏模型应用中，我们的方法使得7B/8B蒸馏模型的表现超越所有70B/72B模型及GPT-4o。同时，蒸馏的14B模型在应用该方法后表现可与Deepseek-R1相媲美。相关代码已发布在https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 295 (char 413). Line: 406.
Append: [Temporal Consistency for LLM Reasoning Process Error Identification](https://arxiv.org/abs/2503.14495)
Token length: 951
Summarized using gpt-4o-mini
Append: [Cosmos-Transfer: 基于多模态输入的条件世界生成模型](https://arxiv.org/abs/2503.14492)
Token length: 1309
Summarized using gpt-4o-mini
Append: [Creation-MMBench: 评估多模态大语言模型创意能力的新基准](https://arxiv.org/abs/2503.14478)
Token length: 985
Summarized using gpt-4o-mini
Append: [开放源码的大规模强化学习系统提升LLM推理能力](https://arxiv.org/abs/2503.14476)
Token length: 1640
Summarized using gpt-4o-mini
Append: [DeepPerception: 融合认知视觉感知的多模态大型语言模型](https://arxiv.org/abs/2503.12797)
Token length: 1415
Summarized using gpt-4o-mini
Append: [CapArena：评估视觉语言模型在图像描述中的表现](https://arxiv.org/abs/2503.12329)
Token length: 1600
Summarized using gpt-4o-mini
Append: [Reflect-DiT：用于文本到图像生成的推理时间扩展](https://arxiv.org/abs/2503.12271)
append_entries: 9
Finish: 2025-03-19 06:12:28.307277
------------------------------------------------------
Started: 2025-03-19 09:01:00.163050
Existing_entries: 700
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 902
Summarized using gpt-4o-mini
Append: [Concat-ID：统一的身份保持视频生成框架](https://arxiv.org/abs/2503.14151)
append_entries: 1
Finish: 2025-03-19 09:01:06.583142
------------------------------------------------------
Started: 2025-03-19 12:13:47.378051
Existing_entries: 701
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1419
Summarized using gpt-4o-mini
Append: [小规模高质量数据集提升大型语言模型推理能力的研究](https://arxiv.org/abs/2503.13661)
Token length: 1240
Summarized using gpt-4o-mini
Append: [FlexWorld: 从单幅图像生成灵活视角3D场景](https://arxiv.org/abs/2503.13265)
Token length: 1007
Summarized using gpt-4o-mini
Append: [提升3D空间理解能力的多模态大型语言模型研究](https://arxiv.org/abs/2503.13111)
Token length: 1491
Summarized using gpt-4o-mini
Append: [基于超曲率空间的安全意识视觉-语言模型HySAC的提出](https://arxiv.org/abs/2503.12127)
Token length: 1544
Summarized using gpt-4o-mini
Append: [Florenz: 单语视觉语言模型在多语种任务中的系统性泛化研究](https://arxiv.org/abs/2503.09443)
append_entries: 5
Finish: 2025-03-19 12:14:18.742300
------------------------------------------------------
Started: 2025-03-19 15:01:10.265220
Existing_entries: 706
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1843
Summarized using gpt-4o-mini
Append: [自我提升认知框架：构建下一代多模态大型语言模型](https://arxiv.org/abs/2503.12303)
append_entries: 1
Finish: 2025-03-19 15:01:21.558913
------------------------------------------------------
Started: 2025-03-19 18:01:12.947140
Existing_entries: 707
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1278
Summarized using gpt-4o-mini
Append: [MeshFleet：高质量三维车辆数据集的自动过滤与注释](https://arxiv.org/abs/2503.14002)
Token length: 1136
Summarized using gpt-4o-mini
Append: [Multi-Scale Attention模型与Atlas架构在大规模图像建模中的应用](https://arxiv.org/abs/2503.12355)
Token length: 1159
Summarized using gpt-4o-mini
Append: [AdaLLaVA：一种自适应的多模态大型语言模型推断框架](https://arxiv.org/abs/2503.10905)
Token length: 1416
Summarized using gpt-4o-mini
Append: [AudioX：统一的音频与音乐生成模型](https://arxiv.org/abs/2503.10522)
Token length: 1428
Summarized using gpt-4o-mini
Append: [EvalTree: 生成语言模型弱点档案的创新方法](https://arxiv.org/abs/2503.08893)
Token length: 1502
Summarized using gpt-4o-mini
Append: [CoLMDriver: 基于大语言模型的协作驾驶系统](https://arxiv.org/abs/2503.08683)
append_entries: 6
Finish: 2025-03-19 18:01:48.265665
------------------------------------------------------
Started: 2025-03-19 21:00:52.365228
Existing_entries: 713
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-19 21:00:52.780095
------------------------------------------------------
Started: 2025-03-20 00:35:57.844266
Existing_entries: 713
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-20 00:35:58.061026
------------------------------------------------------
Started: 2025-03-20 03:20:03.099189
Existing_entries: 713
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1241
Summarized using gpt-4o-mini
Append: [PyGDA：开源图域适配库的发布](https://arxiv.org/abs/2503.10284)
append_entries: 1
Finish: 2025-03-20 03:20:07.143458
------------------------------------------------------
Started: 2025-03-20 06:11:07.971825
Existing_entries: 714
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-20 06:11:08.228982
------------------------------------------------------
Started: 2025-03-20 09:00:48.241911
Existing_entries: 714
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1377
Summarized using gpt-4o-mini
Append: [TULIP：提升图像理解的开源CLIP替代模型](https://arxiv.org/abs/2503.15485)
Token length: 1110
Summarized using gpt-4o-mini
Append: [构建3D智能的基础模型：Roblox的探索与设计](https://arxiv.org/abs/2503.15475)
Token length: 919
Summarized using gpt-4o-mini
Append: [FluxFlow: 提升视频生成的时间质量](https://arxiv.org/abs/2503.15417)
Token length: 1087
Summarized using gpt-4o-mini
Append: [DeepMesh：优化三维网格生成的框架](https://arxiv.org/abs/2503.15265)
Token length: 1257
Summarized using gpt-4o-mini
Append: [ELTEX框架：专用领域合成训练数据生成的有效解决方案](https://arxiv.org/abs/2503.15055)
Token length: 1686
Summarized using gpt-4o-mini
Append: [基于文本反演的扩散模型个性化量化方法](https://arxiv.org/abs/2503.14868)
Json decode failed:
{
  "title": "MusicInfuser：基于音乐生成高质量舞蹈视频的方法",
  "keyword": ["音频视频模型", "舞蹈视频生成", "音乐同步"],
  "short_summary": "MusicInfuser利用现有模型实现与音乐同步的舞蹈视频生成。",
  "summary": "MusicInfuser是一种生成高质量舞蹈视频的创新方法，能够与指定的音乐曲目同步。该方法通过引入轻量级的音乐-视频交叉注意机制和低秩适配器，改进了现有的视频扩散模型，而不需设计新的多模态音视频模型。与以往需要运动捕捉数据的研究不同，MusicInfuser只针对舞蹈视频进行微调，从而实现高质量的音乐驱动视频生成，并保持基础模型的灵活性和生成能力。此外，项目还引入了一种评估框架，利用视频大语言模型（Video-LLMs）来评估舞蹈生成质量的多个维度。项目页面和代码可以访问https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 260 (char 404). Line: 406.
Append: [MusicInfuser: Making Video Diffusion Listen and Dance](https://arxiv.org/abs/2503.14505)
Token length: 1244
Summarized using gpt-4o-mini
Append: [扩展流媒体视频理解的新任务与ViSpeak模型](https://arxiv.org/abs/2503.12769)
Token length: 1233
Summarized using gpt-4o-mini
Append: [STEVE：高效训练计算机使用代理的步骤验证管道](https://arxiv.org/abs/2503.12532)
append_entries: 9
Finish: 2025-03-20 09:01:22.798884
------------------------------------------------------
Started: 2025-03-20 12:13:54.029026
Existing_entries: 723
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1592
Summarized using gpt-4o-mini
Append: [SynthScars: 高质量合成图像数据集与LEGION图像伪造分析框架](https://arxiv.org/abs/2503.15264)
Token length: 1413
Summarized using gpt-4o-mini
Append: [提升多模态推理：取向视觉条件化的新方法](https://arxiv.org/abs/2503.13360)
Json decode failed:
{
  "title": "基于前瞻采样的phi-Decoding解码策略",
  "short_summary": "phi-Decoding通过前瞻采样优化推理过程，提升性能与效率。",
  "summary": "本文提出了一种新的解码策略phi-Decoding，以前瞻采样为基础，旨在高效地平衡推理过程中的探索与利用。尽管以往的基于搜索的方法解决了自回归生成中的短视问题，但广泛的搜索空间往往导致过度探索和不足的利用。而phi-Decoding通过模拟未来步骤来获得全局最优步骤估计，提高了步骤价值的精确性与表现力。该策略还支持适应性计算分配，利用宽度和深度剪枝策略实现了推理效率的轻量化。通过在七个基准测试上进行的广泛实验，phi-Decoding在性能与效率上超越了多个强基线。此外，分析表明其在多种大语言模型中可泛化，并能够在不同的计算预算下扩展。代码将发布于https:
  "keyword": ["推理优化", "phi-Decoding", "前瞻采样"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 299 (char 394). Line: 406.
Append: [φ-Decoding: Adaptive Foresight Sampling for Balanced Inference-Time Exploration and Exploitation](https://arxiv.org/abs/2503.13288)
Token length: 1127
Summarized using gpt-4o-mini
Append: [统一构建广义知识图谱的框架研究](https://arxiv.org/abs/2503.11227)
append_entries: 4
Finish: 2025-03-20 12:14:17.183712
------------------------------------------------------
Started: 2025-03-20 15:00:47.183131
Existing_entries: 727
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1503
Summarized using gpt-4o-mini
Append: [KDTalker：结合无监督3D关键点与时空扩散模型的音频驱动人像生成框架](https://arxiv.org/abs/2503.12963)
append_entries: 1
Finish: 2025-03-20 15:02:32.682724
------------------------------------------------------
Started: 2025-03-20 18:10:22.618249
Existing_entries: 728
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1091
Summarized using gpt-4o-mini
Append: [动态解构框架提升长文本验证的准确性](https://arxiv.org/abs/2503.15354)
Token length: 1393
Summarized using gpt-4o-mini
Append: [MetaLadder：基于类比问题的数学推理框架](https://arxiv.org/abs/2503.14891)
Token length: 1228
Summarized using gpt-4o-mini
Append: [CURIE基准：评估大语言模型在科学问题解决中的能力](https://arxiv.org/abs/2503.13517)
append_entries: 3
Finish: 2025-03-20 18:10:33.519015
------------------------------------------------------
Started: 2025-03-20 21:00:57.081599
Existing_entries: 731
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1166
Summarized using gpt-4o-mini
Append: [基于多轮交互的新一代强化学习算法SWEET-RL](https://arxiv.org/abs/2503.15478)
Token length: 1039
Summarized using gpt-4o-mini
Append: [SkyLadder：一种优化的上下文窗口调度策略提升大规模语言模型预训练效率](https://arxiv.org/abs/2503.15450)
Token length: 1633
Summarized using gpt-4o-mini
Append: [DP-Recon: 使用扩散先验优化3D场景重建](https://arxiv.org/abs/2503.14830)
Token length: 1367
Summarized using gpt-4o-mini
Append: [LLM-FE: 基于大语言模型的自动化特征工程框架](https://arxiv.org/abs/2503.14434)
Json decode failed:
{
  "title": "VERIFY: A Benchmark for Visual Reasoning in Multimodal Large Language Models",
  "short_summary": "VERIFY introduces a new benchmark to rigorously evaluate the visual reasoning capabilities of MLLMs.",
  "summary": "VERIFY is a new benchmark designed to evaluate the visual reasoning abilities of Multimodal Large Language Models (MLLMs). Unlike existing benchmarks that mainly test recognition skills, VERIFY focuses on the models" ability to reason from visual data with minimal textual context. Each task is accompanied by a human-annotated reasoning path, making it unique in evaluating the model"s decision-making process. The benchmark also introduces novel metrics that assess visual reasoning fidelity, revealing critical shortcomings in current MLLMs" reasoning patterns. The findings emphasize the need for a more balanced approach to model development, integrating both perception and reasoning capabilities.",
  "keyword": ["visual reasoning", "MLLMs", "benchmark"]
}Summarization failed, append the original article
error: Expecting ',' delimiter: line 4 column 232 (char 447). Line: 406.
Append: [VERIFY: A Benchmark of Visual Explanation and Reasoning for Investigating Multimodal Reasoning Fidelity](https://arxiv.org/abs/2503.11557)
append_entries: 5
Finish: 2025-03-20 21:02:19.515954
------------------------------------------------------
Started: 2025-03-21 00:37:17.431333
Existing_entries: 736
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-21 00:37:17.632661
------------------------------------------------------
Started: 2025-03-21 03:22:08.242865
Existing_entries: 736
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1464
Summarized using gpt-4o-mini
Append: [三维空间多模态记忆系统M3的设计与应用](https://arxiv.org/abs/2503.16413)
Token length: 1316
Summarized using gpt-4o-mini
Append: [CaKE：一种有效的知识编辑方法提升LLM的多跳推理能力](https://arxiv.org/abs/2503.16356)
Json decode failed:
{
  "title": "Uni-3DAR：无缝集成3D结构生成与理解的统一框架",
  "keyword": ["3D结构生成", "自回归预测", "深度学习"],
  "short_summary": "Uni-3DAR通过自回归预测无缝整合3D结构生成与理解任务。",
  "summary": "Uni-3DAR是一个统一框架，旨在通过自回归预测集成3D结构生成与理解任务。该框架采用新颖的分层标记技术，通过八叉树压缩3D空间，充分利用3D结构的稀疏性，并细化了结构的关键属性如原子类型和精确的空间坐标。此外，Uni-3DAR提出了两项优化策略：一是双层子树压缩，能够将八叉树标记序列缩减至最多8倍；二是针对动态变化标记位置的掩码下一个标记预测机制，显著提高模型性能。通过这些策略，Uni-3DAR在多个微观3D生成与理解任务中展现出优异的效果和多样性，超越了最先进的扩散模型，取得了高达256\%的相对提升，并且推理速度提高了21.8倍。"
}Summarization failed, append the original article
error: Invalid \escape: line 5 column 264 (char 403). Line: 406.
Append: [Uni-3DAR: Unified 3D Generation and Understanding via Autoregression on Compressed Spatial Tokens](https://arxiv.org/abs/2503.16278)
Token length: 1008
Summarized using gpt-4o-mini
Append: [Fin-R1：专为金融领域设计的推理大型语言模型](https://arxiv.org/abs/2503.16252)
Token length: 1228
Summarized using gpt-4o-mini
Append: [欺骗幽默数据集（DHD）的构建与分析](https://arxiv.org/abs/2503.16031)
Token length: 1258
Summarized using gpt-4o-mini
Append: [Unified Variational Auto-Encoder在3D分子生成中的应用](https://arxiv.org/abs/2503.15567)
Token length: 1457
Summarized using gpt-4o-mini
Append: [Cosmos-Reason1模型：启用物理AI的链式推理与决策](https://arxiv.org/abs/2503.15558)
append_entries: 7
Finish: 2025-03-21 03:22:40.371971
------------------------------------------------------
Started: 2025-03-21 06:01:51.660038
Existing_entries: 743
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-21 06:01:51.873173
------------------------------------------------------
Started: 2025-03-21 09:00:47.358455
Existing_entries: 743
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1471
Summarized using gpt-4o-mini
Append: [XAttention: 高效的长上下文Transformer模型稀疏注意力框架](https://arxiv.org/abs/2503.16428)
Token length: 1408
Summarized using gpt-4o-mini
Append: [4D Gaussian Splatting的优化与提升](https://arxiv.org/abs/2503.16422)
Token length: 1667
Summarized using gpt-4o-mini
Append: [MagicMotion：精确轨迹控制的视频生成框架](https://arxiv.org/abs/2503.16421)
Token length: 1539
Summarized using gpt-4o-mini
Append: [优化大语言模型的高效推理方法综述](https://arxiv.org/abs/2503.16419)
Token length: 1143
Summarized using gpt-4o-mini
Append: [InfiniteYou：基于扩散变换器的高保真身份保留图像生成框架](https://arxiv.org/abs/2503.16418)
Token length: 1394
Summarized using gpt-4o-mini
Append: [基于视觉语言的后训练行动决策模型提升](https://arxiv.org/abs/2503.16365)
Token length: 1358
Summarized using gpt-4o-mini
Append: [超分辨率适应的关键指南URAE](https://arxiv.org/abs/2503.16322)
Token length: 1509
Summarized using gpt-4o-mini
Append: [FlashVDM：加速3D形状生成的新框架](https://arxiv.org/abs/2503.16302)
Token length: 1634
Summarized using gpt-4o-mini
Append: [MathFusion: 跨问题指令合成增强数学推理能力的框架](https://arxiv.org/abs/2503.16212)
Token length: 1469
Summarized using gpt-4o-mini
Append: [基于粗细预测的自回归图像生成模型](https://arxiv.org/abs/2503.16194)
Token length: 1919
Summarized using gpt-4o-mini
Append: [基于强化学习的少样本分类策略研究](https://arxiv.org/abs/2503.16188)
Token length: 978
Summarized using gpt-4o-mini
Append: [缓解视觉语言模型中的主导模态偏见的BalGrad框架](https://arxiv.org/abs/2503.13834)
Token length: 1403
Summarized using gpt-4o-mini
Append: [MagicID: 实现动态丰富且一致身份的视频生成](https://arxiv.org/abs/2503.12689)
append_entries: 13
Finish: 2025-03-21 09:01:44.921739
------------------------------------------------------
Started: 2025-03-21 12:13:22.975342
Existing_entries: 756
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1210
Summarized using gpt-4o-mini
Append: [LLM驱动代理的评估方法综述](https://arxiv.org/abs/2503.16416)
Token length: 1176
Summarized using gpt-4o-mini
Append: [高效生成多样化户外场景的方法研究](https://arxiv.org/abs/2503.16375)
Token length: 1426
Summarized using gpt-4o-mini
Append: [小型语言模型的强化学习推理能力提升研究](https://arxiv.org/abs/2503.16219)
Token length: 843
Summarized using gpt-4o-mini
Append: [Race-DiT: 一种新型混合专家模型在扩散变换器中的应用](https://arxiv.org/abs/2503.16057)
Token length: 1483
Summarized using gpt-4o-mini
Append: [SALT: 结合低秩变换的奇异值适应医学图像分割方法](https://arxiv.org/abs/2503.16055)
Token length: 1498
Summarized using gpt-4o-mini
Append: [Zero-1-to-A：提高4D可动画化头像生成质量的方法](https://arxiv.org/abs/2503.15851)
Token length: 1231
Summarized using gpt-4o-mini
Append: [MotionStreamer: 基于文本的流式动作生成新框架](https://arxiv.org/abs/2503.15451)
Token length: 1254
Summarized using gpt-4o-mini
Append: [DiffMoE：提升扩散模型图像生成能力的新方法](https://arxiv.org/abs/2503.14487)
Token length: 1330
Summarized using gpt-4o-mini
Append: [多智能体系统中的挑战与解决方案：综合研究与探索](https://arxiv.org/abs/2503.13657)
Token length: 1374
Summarized using gpt-4o-mini
Append: [基于单幅图像的高保真可动画人类重建模型LHM](https://arxiv.org/abs/2503.10625)
append_entries: 10
Finish: 2025-03-21 12:14:22.476848
------------------------------------------------------
Started: 2025-03-21 15:00:37.924568
Existing_entries: 766
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1219
Summarized using gpt-4o-mini
Append: [基于集合代币化的图像生成新范式](https://arxiv.org/abs/2503.16425)
Token length: 1051
Summarized using gpt-4o-mini
Append: [SwD：扩展的扩散模型蒸馏框架](https://arxiv.org/abs/2503.16397)
Token length: 1607
Summarized using gpt-4o-mini
Append: [VidKV：一种新型的低位数KV缓存量化方法用于视频大语言模型](https://arxiv.org/abs/2503.16257)
Token length: 1601
Summarized using gpt-4o-mini
Append: [机器智能驱动的药物依从性预测与干预系统](https://arxiv.org/abs/2503.16091)
Token length: 1626
Summarized using gpt-4o-mini
Append: [VideoRFSplat：一种直接的文本到3D模型生成方法](https://arxiv.org/abs/2503.15855)
Token length: 1215
Summarized using gpt-4o-mini
Append: [BigO(Bench)：评估生成模型理解和生成代码复杂性的基准](https://arxiv.org/abs/2503.15242)
Token length: 1236
Summarized using gpt-4o-mini
Append: [优化视频训练方法的令牌选择与增强工具Flux](https://arxiv.org/abs/2503.14237)
Token length: 1254
Summarized using gpt-4o-mini
Append: [RSD: 一种加速超分辨率扩散模型的新型蒸馏方法](https://arxiv.org/abs/2503.13358)
append_entries: 8
Finish: 2025-03-21 15:01:23.316043
------------------------------------------------------
Started: 2025-03-21 18:09:57.088917
Existing_entries: 774
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1295
Summarized using gpt-4o-mini
Append: [Sonata：高效自监督点云学习模型的创新与应用](https://arxiv.org/abs/2503.16429)
Token length: 803
Summarized using gpt-4o-mini
Append: [基于文本描述的3D世界生成方法SynCity](https://arxiv.org/abs/2503.16420)
Token length: 1573
Summarized using gpt-4o-mini
Append: [评估大型语言模型的事实知识编码能力](https://arxiv.org/abs/2503.15299)
Token length: 1628
Summarized using gpt-4o-mini
Append: [PORTAL：一种新型AI框架实现多3D游戏智能代理](https://arxiv.org/abs/2503.13356)
Token length: 1172
Summarized using gpt-4o-mini
Append: [TikZero：从图像到图形程序的文本驱动生成](https://arxiv.org/abs/2503.11509)
Token length: 1526
Summarized using gpt-4o-mini
Append: [利用多模态大语言模型评估AI生成视频的有效性](https://arxiv.org/abs/2503.09949)
append_entries: 6
Finish: 2025-03-21 18:10:31.141015
------------------------------------------------------
Started: 2025-03-21 21:00:35.738089
Existing_entries: 780
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-21 21:00:36.019804
------------------------------------------------------
Started: 2025-03-22 00:35:40.350777
Existing_entries: 780
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1517
Summarized using gpt-4o-mini
Append: [GASP：自主驾驶中的几何与语义自监督预训练方法](https://arxiv.org/abs/2503.15672)
Token length: 1828
Summarized using gpt-4o-mini
Append: [基于深度学习的代码补全工具的组织和开发者特定微调研究](https://arxiv.org/abs/2503.14201)
Json decode failed:
{
  "title": "分析大型视觉语言模型的视觉理解行为",
  "keyword": ["视觉语言模型", "视觉理解", "热图可视化"],
  "short_summary": "本文探讨了大型视觉语言模型在视觉理解中的依赖程度及其行为特征。",
  "summary": "本文旨在探讨大型视觉语言模型（LVLMs）在视觉理解和推理任务中的表现，尤其是它们对视觉输入的依赖程度及不同图像区域对响应的贡献。我们扩展了现有的热图可视化方法，以支持LVLM在开放式视觉问答中的应用。通过选择与生成答案相关的视觉标记，我们分析了LVLMs在需要视觉信息以作答的基准测试中的表现。研究发现了LVLM行为的多个重要见解，包括聚焦区域与答案正确性之间的关系、不同架构之间的视觉注意力差异以及大语言模型规模对视觉理解的影响。本文的代码和数据可在https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 248 (char 377). Line: 406.
Append: [Where do Large Vision-Language Models Look at when Answering Questions?](https://arxiv.org/abs/2503.13891)
Token length: 1420
Summarized using gpt-4o-mini
Append: [DeCapBench与DCScore：细节图像标注的新标准](https://arxiv.org/abs/2503.07906)
append_entries: 4
Finish: 2025-03-22 00:35:59.737910
------------------------------------------------------
Started: 2025-03-22 03:20:56.267744
Existing_entries: 784
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-22 03:20:56.476407
------------------------------------------------------
Started: 2025-03-22 06:00:41.001471
Existing_entries: 784
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-22 06:00:41.174974
------------------------------------------------------
Started: 2025-03-22 09:01:01.099162
Existing_entries: 784
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-22 09:01:01.313280
------------------------------------------------------
Started: 2025-03-22 12:00:41.781205
Existing_entries: 784
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-22 12:00:42.039994
------------------------------------------------------
Started: 2025-03-22 15:00:35.860586
Existing_entries: 784
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-22 15:00:36.103059
------------------------------------------------------
Started: 2025-03-22 18:00:35.367749
Existing_entries: 784
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-22 18:00:35.716844
------------------------------------------------------
Started: 2025-03-22 21:00:55.427536
Existing_entries: 784
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-22 21:00:55.589182
------------------------------------------------------
Started: 2025-03-23 00:40:03.004860
Existing_entries: 784
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-23 00:40:03.176627
------------------------------------------------------
Started: 2025-03-23 03:25:21.218669
Existing_entries: 784
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-23 03:25:21.392124
------------------------------------------------------
Started: 2025-03-23 06:00:44.871777
Existing_entries: 784
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-23 06:00:45.109608
------------------------------------------------------
Started: 2025-03-23 09:00:32.763465
Existing_entries: 784
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-23 09:00:33.008254
------------------------------------------------------
Started: 2025-03-23 12:12:07.787324
Existing_entries: 784
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-23 12:12:07.970750
------------------------------------------------------
Started: 2025-03-23 15:00:30.844179
Existing_entries: 784
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-23 15:00:31.085023
------------------------------------------------------
Started: 2025-03-23 18:00:57.054803
Existing_entries: 784
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-23 18:00:57.227434
------------------------------------------------------
Started: 2025-03-23 21:00:32.867473
Existing_entries: 784
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-23 21:00:33.079261
------------------------------------------------------
Started: 2025-03-24 00:38:34.315211
Existing_entries: 784
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-24 00:38:34.544106
------------------------------------------------------
Started: 2025-03-24 03:26:53.479476
Existing_entries: 784
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-24 03:26:53.742427
------------------------------------------------------
Started: 2025-03-24 06:11:29.587031
Existing_entries: 784
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1435
Summarized using gpt-4o-mini
Append: [深度视觉语言模型OpenVLThinker的推理能力提升研究](https://arxiv.org/abs/2503.17352)
Token length: 1151
Summarized using gpt-4o-mini
Append: [FastCuRL：高效的课程强化学习方法提升推理模型性能](https://arxiv.org/abs/2503.17287)
Token length: 1199
Summarized using gpt-4o-mini
Append: [提升创意写作生成的多样性与质量](https://arxiv.org/abs/2503.17126)
Token length: 1202
Summarized using gpt-4o-mini
Append: [VCtrl：提升视频生成中的细粒度控制能力](https://arxiv.org/abs/2503.16983)
Token length: 1359
Summarized using gpt-4o-mini
Append: [基于适应性DPO的图像生成模型偏好数据研究](https://arxiv.org/abs/2503.16921)
Token length: 1320
Summarized using gpt-4o-mini
Append: [基于多智能体框架的多模态科学问题解决策略](https://arxiv.org/abs/2503.16905)
Token length: 1230
Summarized using gpt-4o-mini
Append: [基于多智能体框架的自动化提示优化方法](https://arxiv.org/abs/2503.16874)
Token length: 1551
Summarized using gpt-4o-mini
Append: [TokenBridge：结合离散与连续Token的视觉生成模型](https://arxiv.org/abs/2503.16430)
Token length: 1134
Summarized using gpt-4o-mini
Append: [多智能体系统的组合约束与自动数据收集框架设计](https://arxiv.org/abs/2503.16408)
append_entries: 9
Finish: 2025-03-24 06:12:37.780198
------------------------------------------------------
Started: 2025-03-24 09:00:55.560196
Existing_entries: 793
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1570
Summarized using gpt-4o-mini
Append: [MathFlow：提升多模态大语言模型视觉数学问题解决能力的框架](https://arxiv.org/abs/2503.16549)
Token length: 1423
Summarized using gpt-4o-mini
Append: [针对长尾问题的自适应数据精炼框架在大视觉语言模型中的应用](https://arxiv.org/abs/2503.12821)
Token length: 985
Summarized using gpt-4o-mini
Append: [人工智能中的隐性偏见：通过推理模型隐性联想测试的研究](https://arxiv.org/abs/2503.11572)
append_entries: 3
Finish: 2025-03-24 09:01:20.104104
------------------------------------------------------
Started: 2025-03-24 12:14:31.765675
Existing_entries: 796
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1716
Summarized using gpt-4o-mini
Append: [PVChat：个性化视频大语言模型的单次学习框架](https://arxiv.org/abs/2503.17069)
Token length: 1395
Summarized using gpt-4o-mini
Append: [ETVA：一种新的文本到视频对齐评估方法](https://arxiv.org/abs/2503.16867)
Token length: 1385
Summarized using gpt-4o-mini
Append: [基于特征效用评估的视觉编码器优化方法](https://arxiv.org/abs/2503.16660)
append_entries: 3
Finish: 2025-03-24 12:14:48.311521
------------------------------------------------------
Started: 2025-03-24 15:00:43.804824
Existing_entries: 799
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1270
Summarized using gpt-4o-mini
Append: [FFaceNeRF：一种灵活的3D人脸编辑技术](https://arxiv.org/abs/2503.17095)
Token length: 1289
Summarized using gpt-4o-mini
Append: [TaoAvatar：高保真轻量级全身虚拟头像的实时渲染](https://arxiv.org/abs/2503.17032)
Token length: 1488
Summarized using gpt-4o-mini
Append: [融合3D视觉语言模型的通用少样本点云分割框架](https://arxiv.org/abs/2503.16282)
Token length: 1249
Summarized using gpt-4o-mini
Append: [SISO：基于单图像的个性化图像生成与编辑方法](https://arxiv.org/abs/2503.16025)
append_entries: 4
Finish: 2025-03-24 15:01:06.751301
------------------------------------------------------
Started: 2025-03-24 18:00:34.073742
Existing_entries: 803
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1555
Summarized using gpt-4o-mini
Append: [GAEA：图像地理定位中的对话模型创新](https://arxiv.org/abs/2503.16423)
append_entries: 1
Finish: 2025-03-24 18:00:39.598884
------------------------------------------------------
Started: 2025-03-24 21:00:28.411825
Existing_entries: 804
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "MapBench：针对人类可读的像素地图导航的首个数据集",
  "keyword": ["地图导航", "数据集", "空间推理"],
  "short_summary": "MapBench是首个为像素地图导航设计的数据集，挑战现有语言模型的推理能力。",
  "summary": "本文介绍了MapBench，这是首个专门为人类可读的像素地图导航设计的数据集，涵盖了复杂路径寻找场景。MapBench包含来自100个多样化地图的1600多个像素空间地图路径问题。通过提供Map Space Scene Graph（MSSG）作为索引数据结构，该数据集支持将自然语言转换并评估大型视觉语言模型（LVLM）生成的导航指令。我们的研究表明，MapBench显著提高了对先进LVLM的挑战，特别是在零-shot提示及基于思维链推理框架下，展示了地图导航过程的分解和认知过程的序列化。对开源和闭源LVLM的评估凸显了MapBench所带来的重大挑战，揭示这些模型在空间推理和结构化决策能力上的关键局限性。所有代码和数据集已在https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 337 (char 481). Line: 406.
Append: [Can Large Vision Language Models Read Maps Like a Human?](https://arxiv.org/abs/2503.14607)
append_entries: 1
Finish: 2025-03-24 21:00:32.693092
------------------------------------------------------
Started: 2025-03-25 00:37:29.529171
Existing_entries: 805
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-25 00:37:29.729463
------------------------------------------------------
Started: 2025-03-25 03:23:38.194872
Existing_entries: 805
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-25 03:23:38.420832
------------------------------------------------------
Started: 2025-03-25 06:00:42.269971
Existing_entries: 805
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1557
Summarized using gpt-4o-mini
Append: [Bottleneck Sampling：一种高效的扩散模型推理框架](https://arxiv.org/abs/2503.18940)
Token length: 691
Summarized using gpt-4o-mini
Append: [AlphaSpace：提升大型语言模型在3D空间导航中的空间推理能力](https://arxiv.org/abs/2503.18769)
Token length: 1848
Summarized using gpt-4o-mini
Append: [利用多模态LLM评估跨模态理解与生成任务](https://arxiv.org/abs/2503.17489)
Token length: 1016
Summarized using gpt-4o-mini
Append: [推动游戏开发革新的生成游戏引擎](https://arxiv.org/abs/2503.17359)
Token length: 1467
Summarized using gpt-4o-mini
Append: [通过错误学习提升大型语言模型的数学推理能力](https://arxiv.org/abs/2503.17439)
Token length: 1362
Summarized using gpt-4o-mini
Append: [MagicComp: 通过双阶段精炼提升文本生成视频的组合能力](https://arxiv.org/abs/2503.14428)
append_entries: 6
Finish: 2025-03-25 06:01:10.736318
------------------------------------------------------
Started: 2025-03-25 09:00:47.215375
Existing_entries: 811
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1308
Summarized using gpt-4o-mini
Append: [Aether框架：结合几何重建与生成建模的智能空间推理系统](https://arxiv.org/abs/2503.18945)
Token length: 1704
Summarized using gpt-4o-mini
Append: [探索测试时间扩展对视频生成质量的影响](https://arxiv.org/abs/2503.18942)
Token length: 1831
Summarized using gpt-4o-mini
Append: [Video SimpleQA：评估大型视频语言模型的事实性基准](https://arxiv.org/abs/2503.18923)
Token length: 1327
Summarized using gpt-4o-mini
Append: [FFN Fusion: 提升大规模语言模型推理效率的新技术](https://arxiv.org/abs/2503.18908)
Token length: 1536
Summarized using gpt-4o-mini
Append: [基于零强化学习的多模型链式推理训练研究](https://arxiv.org/abs/2503.18892)
Token length: 1570
Summarized using gpt-4o-mini
Append: [利用潜在思维推断提升语言模型预训练数据效率](https://arxiv.org/abs/2503.18866)
Token length: 857
Summarized using gpt-4o-mini
Append: [CaMeL：增强大语言模型安全性的防御措施](https://arxiv.org/abs/2503.18813)
Token length: 1787
Summarized using gpt-4o-mini
Append: [Hummingbird: 高效的文本到视频生成框架](https://arxiv.org/abs/2503.18559)
Token length: 1486
Summarized using gpt-4o-mini
Append: [AgentRxiv：促进科学研究的协作框架](https://arxiv.org/abs/2503.18102)
Token length: 1401
Summarized using gpt-4o-mini
Append: [Vision-R1: 一种新型的视觉引导强化学习算法](https://arxiv.org/abs/2503.18013)
Token length: 1902
Summarized using gpt-4o-mini
Append: [资源受限条件下视频生成模型的训练策略研究](https://arxiv.org/abs/2503.17735)
Token length: 933
Summarized using gpt-4o-mini
Append: [优化大语言模型预训练的权重初始化与方差控制策略](https://arxiv.org/abs/2503.17500)
Token length: 953
Summarized using gpt-4o-mini
Append: [优化RISC-V CPU上的大型语言模型推理](https://arxiv.org/abs/2503.17422)
Token length: 1746
Summarized using gpt-4o-mini
Append: [优化最小高斯表示法（OMG）在3D场景渲染中的应用](https://arxiv.org/abs/2503.16924)
Token length: 1318
Summarized using gpt-4o-mini
Append: [Typed-RAG: 面向非事实问答的多维度框架](https://arxiv.org/abs/2503.15879)
append_entries: 15
Finish: 2025-03-25 09:01:51.859378
------------------------------------------------------
Started: 2025-03-25 12:13:54.518544
Existing_entries: 826
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1398
Summarized using gpt-4o-mini
Append: [新型平衡图像建模框架的提出](https://arxiv.org/abs/2503.18948)
Token length: 1036
Summarized using gpt-4o-mini
Append: [CFG-Zero*: 改进的分类器自由引导技术](https://arxiv.org/abs/2503.18886)
Token length: 1145
Summarized using gpt-4o-mini
Append: [探究大型语言模型的推理机制：基于稀疏自编码器的分析](https://arxiv.org/abs/2503.18878)
Token length: 864
Summarized using gpt-4o-mini
Append: [CURA: 提升软件工程任务的代码理解与推理代理系统](https://arxiv.org/abs/2503.18494)
Token length: 1478
Summarized using gpt-4o-mini
Append: [MetaSpatial：基于强化学习的3D空间推理框架](https://arxiv.org/abs/2503.18470)
Token length: 1303
Summarized using gpt-4o-mini
Append: [Diffusion-4K：基于文本生成的超高分辨率图像合成框架](https://arxiv.org/abs/2503.18352)
Token length: 1273
Summarized using gpt-4o-mini
Append: [OmnimatteZero：一种无训练视频分层提取的新方法](https://arxiv.org/abs/2503.18033)
append_entries: 7
Finish: 2025-03-25 12:14:26.486228
------------------------------------------------------
Started: 2025-03-25 15:00:39.861052
Existing_entries: 833
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1839
Summarized using gpt-4o-mini
Append: [文化适应性对大型语言模型数学推理能力的影响研究](https://arxiv.org/abs/2503.18018)
append_entries: 1
Finish: 2025-03-25 15:00:46.062400
------------------------------------------------------
Started: 2025-03-25 18:00:42.076489
Existing_entries: 834
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1006
Summarized using gpt-4o-mini
Append: [人类运动去学习：防止合成有害动画的新方法](https://arxiv.org/abs/2503.18674)
Token length: 1244
Summarized using gpt-4o-mini
Append: [多模态推理的发展与挑战综述](https://arxiv.org/abs/2503.18071)
Token length: 1095
Summarized using gpt-4o-mini
Append: [Feather-SQL: 一种针对小型语言模型的轻量级NL2SQL框架](https://arxiv.org/abs/2503.17811)
Token length: 1234
Summarized using gpt-4o-mini
Append: [CODA：一种有效的视觉离散化框架](https://arxiv.org/abs/2503.17760)
Token length: 1916
Summarized using gpt-4o-mini
Append: [DynamicVis：面向遥感图像的动态视觉感知基础模型](https://arxiv.org/abs/2503.16426)
Token length: 1071
Summarized using gpt-4o-mini
Append: [基于变换器的多光源白平衡修正方法](https://arxiv.org/abs/2503.14774)
Token length: 1739
Summarized using gpt-4o-mini
Append: [揭示图像超分辨率评估中的地面真实图像质量影响](https://arxiv.org/abs/2503.13074)
append_entries: 7
Finish: 2025-03-25 18:01:06.688882
------------------------------------------------------
Started: 2025-03-25 21:00:35.997771
Existing_entries: 841
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-25 21:00:36.156533
------------------------------------------------------
Started: 2025-03-26 00:36:42.663719
Existing_entries: 841
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-26 00:36:42.857083
------------------------------------------------------
Started: 2025-03-26 03:22:17.708726
Existing_entries: 841
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1530
Summarized using gpt-4o-mini
Append: [基于视觉语言模型的3D室内场景生成算法研究](https://arxiv.org/abs/2503.18476)
Token length: 1485
Summarized using gpt-4o-mini
Append: [Instruct-CLIP：改进图像编辑指令对齐的自监督方法](https://arxiv.org/abs/2503.18406)
Token length: 1470
Summarized using gpt-4o-mini
Append: [QuartDepth：优化单目深度估计在ASIC上的应用](https://arxiv.org/abs/2503.16709)
append_entries: 3
Finish: 2025-03-26 03:22:35.459932
------------------------------------------------------
Started: 2025-03-26 06:00:39.224228
Existing_entries: 844
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1812
Summarized using gpt-4o-mini
Append: [CoLLM：增强复杂图像检索的综合框架](https://arxiv.org/abs/2503.19910)
Token length: 1702
Summarized using gpt-4o-mini
Append: [PS3：革命性的高分辨率视觉预训练方法](https://arxiv.org/abs/2503.19903)
Token length: 1321
Summarized using gpt-4o-mini
Append: [Multi-round Thinking：一种提升大语言模型推理性能的新方法](https://arxiv.org/abs/2503.19855)
Token length: 1391
Summarized using gpt-4o-mini
Append: [研究视频模态大规模多模态模型的幻觉问题](https://arxiv.org/abs/2503.19622)
Token length: 1066
Summarized using gpt-4o-mini
Append: [ReSearch：通过强化学习整合推理与搜索的框架](https://arxiv.org/abs/2503.19470)
Token length: 1495
Summarized using gpt-4o-mini
Append: [流模型的推理时刻扩展方法研究](https://arxiv.org/abs/2503.19385)
Token length: 1627
Summarized using gpt-4o-mini
Append: [长时间上下文视频生成的进展与Frame AutoRegressive模型](https://arxiv.org/abs/2503.19325)
Json decode failed:
{
  "title": "LookAhead Tuning：提升大语言模型安全性的有效方法",
  "short_summary": "LookAhead Tuning通过数据调整保持大语言模型的安全性。",
  "summary": "Fine-tuning尽管能让大型语言模型（LLMs）适应特定领域，却常常削弱其已建立的安全性。为了解决这个问题，本文提出了一种名为LookAhead Tuning的方法，包含两种简单、低资源、有效的数据驱动方法，通过预览部分答案前缀来修改训练数据。这两种方法旨在通过最小化初始令牌分布的扰动，保护模型固有的安全机制。综合实验表明，LookAhead Tuning在不牺牲下游任务强大性能的情况下，有效保持了模型的安全性。我们的研究定位LookAhead Tuning为安全、有效地调整LLMs的可靠解决方案，并将在https:
  "keyword": [
    "大型语言模型",
    "安全性",
    "LookAhead Tuning"
  ]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 279 (char 384). Line: 406.
Append: [LookAhead Tuning: Safer Language Models via Partial Answer Previews](https://arxiv.org/abs/2503.19041)
Token length: 1097
Summarized using gpt-4o-mini
Append: [通过CoMP实现的视觉基础模型的多模态预训练](https://arxiv.org/abs/2503.18931)
Token length: 1622
Summarized using gpt-4o-mini
Append: [Frequency Dynamic Convolution: 一种高效的自适应卷积方法](https://arxiv.org/abs/2503.18783)
Token length: 1161
Summarized using gpt-4o-mini
Append: [LSRNA：基于潜在空间的图像超分辨率生成框架](https://arxiv.org/abs/2503.18446)
Token length: 1492
Summarized using gpt-4o-mini
Append: [基于Gumbel-Softmax的流匹配框架用于高维简约体的序列生成](https://arxiv.org/abs/2503.17361)
Token length: 1309
Summarized using gpt-4o-mini
Append: [提升视觉语言模型的人本决策能力](https://arxiv.org/abs/2503.16965)
append_entries: 13
Finish: 2025-03-26 06:01:45.197464
------------------------------------------------------
Started: 2025-03-26 09:00:57.790328
Existing_entries: 857
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1037
Summarized using gpt-4o-mini
Append: [基于YOLOv12与BoT-SORT的多无人机跟踪方法](https://arxiv.org/abs/2503.17237)
Json decode failed:
{
  "title": "FakeVLM: 一种新型多模态模型用于合成图像及深伪检测",
  "short_summary": "FakeVLM模型提升了合成图像的真实性评估与解析能力。",
  "summary": "随着人工智能生成内容技术的快速发展，合成图像在日常生活中日益普遍，这也对真实性评估和检测提出了新挑战。为了解决这些问题，本文介绍了FakeVLM，这是一种专门为合成图像和深伪检测任务设计的大型多模态模型。FakeVLM在区分真实与虚假图像方面表现出色，并提供自然语言的解释，以增强可解释性。此外，我们提出了FakeClue，一个包含超过10万张图像的综合数据集，涵盖七个类别，并附有细致的自然语言伪造线索注释。FakeVLM的性能与专家模型相媲美，且无需额外的分类器，为合成数据检测提供了一个强大的解决方案。通过在多个数据集上的广泛评估，FakeVLM在真实性分类和伪造解析任务中展现优越性，为合成图像检测设定了新基准。相关数据集和代码将发布在：https:
  "keyword": [
    "合成图像",
    "深伪检测",
    "人工智能"
  ]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 344 (char 440). Line: 406.
Append: [Spot the Fake: Large Multimodal Model-Based Synthetic Image Detection with Artifact Explanation](https://arxiv.org/abs/2503.14905)
Token length: 1514
Summarized using gpt-4o-mini
Append: [MDocAgent：一种多模态多智能体文档理解框架](https://arxiv.org/abs/2503.13964)
append_entries: 3
Finish: 2025-03-26 09:01:08.193135
------------------------------------------------------
Started: 2025-03-26 12:13:46.418801
Existing_entries: 860
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-26 12:13:46.667234
------------------------------------------------------
Started: 2025-03-26 15:01:03.558330
Existing_entries: 860
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-26 15:01:03.758188
------------------------------------------------------
Started: 2025-03-26 18:01:00.145264
Existing_entries: 860
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1204
Summarized using gpt-4o-mini
Append: [FullDiT：统一的视频生成基础模型](https://arxiv.org/abs/2503.19907)
Token length: 1002
Summarized using gpt-4o-mini
Append: [无训练开放词汇语义分割的方法LPOSS+](https://arxiv.org/abs/2503.19777)
Token length: 1315
Summarized using gpt-4o-mini
Append: [实时交互视频数据集：评估AI模型的对话能力](https://arxiv.org/abs/2503.19356)
Token length: 1596
Summarized using gpt-4o-mini
Append: [基于少量图像的个性化3D人类头像重建与动画技术](https://arxiv.org/abs/2503.19207)
Token length: 1248
Summarized using gpt-4o-mini
Append: [VocAgnoLM：解决教师与学生模型词汇不匹配的问题](https://arxiv.org/abs/2503.19123)
Token length: 1483
Summarized using gpt-4o-mini
Append: [WikiAutoGen：一款自动化多模态维基百科式文章生成系统](https://arxiv.org/abs/2503.19065)
Token length: 1476
Summarized using gpt-4o-mini
Append: [xKV：提升长上下文语言模型内存效率的新方法](https://arxiv.org/abs/2503.18893)
Json decode failed:
{
  "title": "下一代地球观测基础模型的进展",
  "keyword": ["地球观测", "Copernicus", "基础模型"],
  "short_summary": "本研究提出了下一代地球观测基础模型的三个关键组成部分。",
  "summary": "本文介绍了在地球观测（EO）基础模型领域的最新进展，重点关注如何利用大规模卫星数据进行更通用的空间表示学习。研究提出了三个关键组件：首先是Copernicus-Pretrain，这是一个包含来自主要Copernicus Sentinel任务的1870万幅对齐图像的大规模预训练数据集，涵盖了地球表面到大气层的多个层面；其次是Copernicus-FM，一个统一的基础模型，能够处理任何光谱或非光谱传感器模态，利用扩展动态超网络和灵活的元数据编码；最后是Copernicus-Bench，一个系统化评估基准，涵盖15个分层下游任务，横跨从预处理到特殊应用的各个方面。这些组件显著提高了EO基础模型的可扩展性、灵活性和多模态适应能力，同时为连接EO、天气与气候研究创造了新的机会。相关代码、数据集和模型可以在 https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 374 (char 499). Line: 406.
Append: [Towards a Unified Copernicus Foundation Model for Earth Vision](https://arxiv.org/abs/2503.11849)
append_entries: 8
Finish: 2025-03-26 18:01:38.561911
------------------------------------------------------
Started: 2025-03-26 21:00:32.644637
Existing_entries: 868
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1084
Summarized using gpt-4o-mini
Append: [基于单目相机的无人机深度和语义地图预测](https://arxiv.org/abs/2503.17982)
Token length: 1292
Summarized using gpt-4o-mini
Append: [PhysTwin: 基于稀疏视频的动态物体物理数字双胞胎框架](https://arxiv.org/abs/2503.17973)
append_entries: 2
Finish: 2025-03-26 21:00:41.094539
------------------------------------------------------
Started: 2025-03-27 00:36:52.581006
Existing_entries: 870
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1463
Summarized using gpt-4o-mini
Append: [提升时空推理能力的视觉语言模型ST-VLM及其基准评测](https://arxiv.org/abs/2503.19355)
Token length: 843
Summarized using gpt-4o-mini
Append: [OpenCity3D：城市规模环境的语言驱动分析新范式](https://arxiv.org/abs/2503.16776)
append_entries: 2
Finish: 2025-03-27 00:37:00.623893
------------------------------------------------------
Started: 2025-03-27 03:23:09.455003
Existing_entries: 872
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1885
Summarized using gpt-4o-mini
Append: [高效的微调转移策略：提升预训练模型的性能](https://arxiv.org/abs/2503.20110)
Token length: 1270
Summarized using gpt-4o-mini
Append: [多模态大语言模型在复杂行为识别中的应用与提升](https://arxiv.org/abs/2503.18712)
Token length: 914
Summarized using gpt-4o-mini
Append: [Any6D：无模型框架实现6D物体姿态估计](https://arxiv.org/abs/2503.18673)
Token length: 1291
Summarized using gpt-4o-mini
Append: [高质量360度人头视图生成的新方法](https://arxiv.org/abs/2503.15667)
Token length: 1134
Summarized using gpt-4o-mini
Append: [基于多模态大语言模型的3D场景生成研究](https://arxiv.org/abs/2503.04919)
append_entries: 5
Finish: 2025-03-27 03:23:39.501069
------------------------------------------------------
Started: 2025-03-27 06:11:10.339046
Existing_entries: 877
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1171
Summarized using gpt-4o-mini
Append: [MCTS-RAG：提升小型语言模型推理能力的新方法](https://arxiv.org/abs/2503.20757)
Json decode failed:
{
  "title": "利用知识编辑改善自动驾驶系统中的大规模多模态模型应用",
  "short_summary": "提出知识编辑方法以解决自动驾驶系统中的多模态模型应用挑战。",
  "summary": "本文探讨了大型多模态模型（LMMs）在自动驾驶系统（ADS）中的应用前景，但面临交通知识理解、复杂路况和车辆状态多样性等挑战。为了解决这些问题，提出了一种知识编辑的方法，可以针对性地修改模型行为，无需完整的重训练。同时，创建了ADS-Edit，这是一个专门为ADS设计的多模态知识编辑数据集，包含了各种真实场景和多种数据类型及全面的评估指标。通过综合实验，我们得出了一些有趣的结论，期望本研究能够推动知识编辑在自动驾驶领域的进一步应用。代码和数据可在 https:
  "keyword": [
    "自动驾驶",
    "多模态模型",
    "知识编辑"
  ]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 247 (char 341). Line: 406.
Append: [ADS-Edit: A Multimodal Knowledge Editing Dataset for Autonomous Driving Systems](https://arxiv.org/abs/2503.20756)
Token length: 1729
Summarized using gpt-4o-mini
Append: [突破性商业内容生成：以超密布局为基础的文本到图像生成模型](https://arxiv.org/abs/2503.20672)
Token length: 1867
Summarized using gpt-4o-mini
Append: [Wan：一套开源视频基础模型的创新与应用](https://arxiv.org/abs/2503.20314)
Token length: 1209
Summarized using gpt-4o-mini
Append: [优化条件扩散模型的无条件噪声预测](https://arxiv.org/abs/2503.20240)
Token length: 1383
Summarized using gpt-4o-mini
Append: [DINeMo：无3D注释的神经网格模型与伪对应生成](https://arxiv.org/abs/2503.20220)
Token length: 1419
Summarized using gpt-4o-mini
Append: [开放深度搜索（ODS）：提升开源搜索AI性能的新框架](https://arxiv.org/abs/2503.20201)
Json decode failed:
{
  "title": "长文本图像生成的新突破：\ModelName的创新与应用",
  "keyword": ["长文本生成", "图像生成", "模型优化"],
  "short_summary": "本文介绍了一种新模型\ModelName，用于生成高质量长文本图像。", 
  "summary": "虽然自回归和扩散模型在短文本图像生成上取得了显著进展，但生成连贯的长文本图像仍是一个主要挑战。本文首次专注于长文本图像生成，填补现有文本到图像系统的空白。通过对最新自回归生成模型的深入分析，识别出图像分词器作为文本生成质量的关键瓶颈。为此，我们提出了一种新的文本聚焦二进制分词器，旨在捕捉详细的场景文本特征。利用该分词器，我们开发了\ModelName，一个多模态自回归模型，能够以空前的精准度生成高质量的长文本图像。我们的模型具有强大的可控性，允许用户自定义文本属性如字体样式、大小、颜色和对齐方式。实验表明，\ModelName在长文本生成的准确性、一致性和灵活性上显著优于其他模型，如SD3.5 Large和GPT4o与DALL-E 3。除了其技术成就外，\ModelName还为创新应用如交错文档和PowerPoint生成开辟了新的前沿。"
}Summarization failed, append the original article
error: Invalid \escape: line 2 column 25 (char 26). Line: 406.
Append: [Beyond Words: Advancing Long-Text Image Generation via Multimodal Autoregressive Models](https://arxiv.org/abs/2503.20198)
Token length: 1849
Summarized using gpt-4o-mini
Append: [Gemini Robotics：革命性的机器人视觉-语言-动作模型](https://arxiv.org/abs/2503.20020)
Token length: 974
Summarized using gpt-4o-mini
Append: [无监督视频中运动估计的新方法](https://arxiv.org/abs/2503.19953)
Token length: 1107
Summarized using gpt-4o-mini
Append: [利用Attention-IoU度量揭示计算机视觉模型中的偏见](https://arxiv.org/abs/2503.19846)
Token length: 1154
Summarized using gpt-4o-mini
Append: [LogQuant：高效的2位量化技术提升大语言模型推理性能](https://arxiv.org/abs/2503.19950)
Token length: 1570
Summarized using gpt-4o-mini
Append: [Dita：一种可扩展的多模态扩散框架用于机器人行动决策](https://arxiv.org/abs/2503.19757)
Token length: 1811
Summarized using gpt-4o-mini
Append: [GenHancer：提升CLIP表征能力的生成模型探索](https://arxiv.org/abs/2503.19480)
Token length: 1515
Summarized using gpt-4o-mini
Append: [AccVideo: 高效视频扩散模型加速方法](https://arxiv.org/abs/2503.19462)
Json decode failed:
{
  "title": "基于随机抽样的知识蒸馏方法提升稀疏知识蒸馏性能",
  "keyword": ["知识蒸馏", "大语言模型", "随机抽样"],
  "short_summary": "提出一种随机抽样知识蒸馏方法，提升稀疏知识蒸馏的性能与效率。",
  "summary": "知识蒸馏是一种在大语言模型中有效提取知识的成本效益技术，但其在预训练中的应用仍然探索不足。本研究表明，简单的稀疏知识蒸馏方法如缓存Top-K概率，虽然直观，但会导致教师概率分布对学生的偏差估计，进而降低模型性能和校准效果。为了克服这个问题，我们提出了一种基于重要性抽样的"随机抽样知识蒸馏"方法，该方法提供无偏估计，保持梯度的期望值，并需求存储更稀疏的logits。我们的实验表明，相比于交叉熵训练，采用该方法进行学生模型的训练不仅可以加速训练过程，且附加开销低于10%，同时在300M到3B范围的模型上保持了竞争力的性能。"
}Summarization failed, append the original article
error: Expecting ',' delimiter: line 5 column 151 (char 283). Line: 406.
Append: [Sparse Logit Sampling: Accelerating Knowledge Distillation in LLMs](https://arxiv.org/abs/2503.16870)
append_entries: 16
Finish: 2025-03-27 06:12:40.295241
------------------------------------------------------
Started: 2025-03-27 09:00:54.256257
Existing_entries: 893
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1775
Summarized using gpt-4o-mini
Append: [Qwen2.5-Omni：多模态流处理模型的创新与应用](https://arxiv.org/abs/2503.20215)
Token length: 1555
Summarized using gpt-4o-mini
Append: [评估多模态大语言模型的空间推理能力：LEGO-Puzzles基准测试](https://arxiv.org/abs/2503.19990)
append_entries: 2
Finish: 2025-03-27 09:01:08.699800
------------------------------------------------------
Started: 2025-03-27 12:18:55.232831
Existing_entries: 895
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1470
Summarized using gpt-4o-mini
Append: [Vision-Language奖励模型的评估与进展](https://arxiv.org/abs/2503.20271)
Token length: 1105
Summarized using gpt-4o-mini
Append: [利用运动模糊进行稳健的相机运动估计](https://arxiv.org/abs/2503.17358)
append_entries: 2
Finish: 2025-03-27 12:19:07.777418
------------------------------------------------------
Started: 2025-03-27 15:00:48.815512
Existing_entries: 897
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1587
Summarized using gpt-4o-mini
Append: [PathoHR：提高乳腺癌生存预测的计算病理新方法](https://arxiv.org/abs/2503.17970)
append_entries: 1
Finish: 2025-03-27 15:00:54.646519
------------------------------------------------------
Started: 2025-03-27 18:01:11.496145
Existing_entries: 898
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1847
Summarized using gpt-4o-mini
Append: [模型合并在长期到短期推理中的应用研究](https://arxiv.org/abs/2503.20641)
Token length: 1265
Summarized using gpt-4o-mini
Append: [基于轨迹平衡与异步的强化学习系统TBA](https://arxiv.org/abs/2503.18929)
Token length: 1658
Summarized using gpt-4o-mini
Append: [UniHDSA: 一种统一的文档层次结构分析方法](https://arxiv.org/abs/2503.15893)
Token length: 838
Summarized using gpt-4o-mini
Append: [RONA：增强多模态大语言模型图像标注多样性的策略](https://arxiv.org/abs/2503.10997)
append_entries: 4
Finish: 2025-03-27 18:01:32.285161
------------------------------------------------------
Started: 2025-03-27 21:00:50.481420
Existing_entries: 902
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 810
Summarized using gpt-4o-mini
Append: [RecTable: 高效生成高质量表格数据的新模型](https://arxiv.org/abs/2503.20731)
Token length: 957
Summarized using gpt-4o-mini
Append: [Gemma 3：多模态轻量级模型的升级版](https://arxiv.org/abs/2503.19786)
append_entries: 2
Finish: 2025-03-27 21:01:00.142902
------------------------------------------------------
Started: 2025-03-28 00:36:57.495033
Existing_entries: 904
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-28 00:36:57.815091
------------------------------------------------------
Started: 2025-03-28 03:24:20.926145
Existing_entries: 904
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-28 03:24:21.181249
------------------------------------------------------
Started: 2025-03-28 06:11:40.743539
Existing_entries: 904
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-28 06:11:40.990204
------------------------------------------------------
Started: 2025-03-28 09:00:42.420555
Existing_entries: 904
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1333
Summarized using gpt-4o-mini
Append: [Video-R1: 基于多模态大语言模型的视频推理探索](https://arxiv.org/abs/2503.21776)
Token length: 903
Summarized using gpt-4o-mini
Append: [优化步长调度的扩散模型提高生成效率](https://arxiv.org/abs/2503.21774)
Token length: 1783
Summarized using gpt-4o-mini
Append: [视频生成中的物理认知进展及其挑战](https://arxiv.org/abs/2503.21765)
Token length: 1281
Summarized using gpt-4o-mini
Append: [Lumina-Image 2.0：先进的文本生成图像框架](https://arxiv.org/abs/2503.21758)
Token length: 1913
Summarized using gpt-4o-mini
Append: [推进视频生成模型的内在真实性评估](https://arxiv.org/abs/2503.21755)
Token length: 1122
Summarized using gpt-4o-mini
Append: [LeX-Art: 高质量文本-图像合成的完整解决方案](https://arxiv.org/abs/2503.21749)
Token length: 1299
Summarized using gpt-4o-mini
Append: [ReaRAG：增强准确性的推理模型](https://arxiv.org/abs/2503.21729)
Token length: 1418
Summarized using gpt-4o-mini
Append: [基于规则的强化学习提升多模态大语言模型的GUI动作预测能力](https://arxiv.org/abs/2503.21620)
Token length: 1177
Summarized using gpt-4o-mini
Append: [智能代理时代的到来：大语言模型驱动下的研究综述](https://arxiv.org/abs/2503.21460)
Token length: 1526
Summarized using gpt-4o-mini
Append: [OlymMATH: 新的奥林匹克数学基准测试大规模推理模型](https://arxiv.org/abs/2503.21380)
Token length: 1713
Summarized using gpt-4o-mini
Append: [基于音频输入的实时互动视频生成框架](https://arxiv.org/abs/2503.21144)
Token length: 1281
Summarized using gpt-4o-mini
Append: [ZJUKLAB团队在SemEval-2025任务中的敏感内容去除研究](https://arxiv.org/abs/2503.21088)
Token length: 1416
Summarized using gpt-4o-mini
Append: [统一多模态离散扩散模型UniDisc的探索与应用](https://arxiv.org/abs/2503.20853)
Token length: 1681
Summarized using gpt-4o-mini
Append: [Feature4X：扩展2D视觉模型至4D领域的通用框架](https://arxiv.org/abs/2503.20776)
Token length: 966
Summarized using gpt-4o-mini
Append: [基于大型语言模型的故障诱发输入提取研究](https://arxiv.org/abs/2503.20578)
Token length: 914
Summarized using gpt-4o-mini
Append: [利用合成视频提升视频生成模型的物理真实性](https://arxiv.org/abs/2503.20822)
append_entries: 16
Finish: 2025-03-28 09:02:16.501297
------------------------------------------------------
Started: 2025-03-28 12:00:58.871206
Existing_entries: 920
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1513
Summarized using gpt-4o-mini
Append: [Embodied Reasoner：提升交互式体态搜索任务的推理能力](https://arxiv.org/abs/2503.21696)
Token length: 1158
Summarized using gpt-4o-mini
Append: [大语言模型在科学发现中的潜力与新基准](https://arxiv.org/abs/2503.21248)
Token length: 1195
Summarized using gpt-4o-mini
Append: [FinAudio: 金融领域音频语言模型评估基准](https://arxiv.org/abs/2503.20990)
append_entries: 3
Finish: 2025-03-28 12:01:18.204313
------------------------------------------------------
Started: 2025-03-28 15:01:03.011478
Existing_entries: 923
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1140
Summarized using gpt-4o-mini
Append: [LOCATEdit：基于图的文本引导图像编辑方法](https://arxiv.org/abs/2503.21541)
append_entries: 1
Finish: 2025-03-28 15:01:08.390842
------------------------------------------------------
Started: 2025-03-28 18:00:52.069980
Existing_entries: 924
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1175
Summarized using gpt-4o-mini
Append: [无训练的测试时领域适应框架SemLA在开放词汇语义分割中的应用](https://arxiv.org/abs/2503.21780)
append_entries: 1
Finish: 2025-03-28 18:01:04.432348
------------------------------------------------------
Started: 2025-03-28 21:00:40.502594
Existing_entries: 925
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1193
Summarized using gpt-4o-mini
Append: [Tracktention Layer：提升视频预测中的时间一致性](https://arxiv.org/abs/2503.19904)
append_entries: 1
Finish: 2025-03-28 21:00:45.642617
------------------------------------------------------
Started: 2025-03-29 00:36:38.343419
Existing_entries: 926
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-29 00:36:38.536546
------------------------------------------------------
Started: 2025-03-29 03:20:45.131082
Existing_entries: 926
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-29 03:20:45.314703
------------------------------------------------------
Started: 2025-03-29 06:09:43.686411
Existing_entries: 926
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-29 06:09:43.910853
------------------------------------------------------
Started: 2025-03-29 09:00:45.580370
Existing_entries: 926
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-29 09:00:45.834637
------------------------------------------------------
Started: 2025-03-29 12:00:45.893587
Existing_entries: 926
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-29 12:00:46.075395
------------------------------------------------------
Started: 2025-03-29 15:00:45.028991
Existing_entries: 926
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-29 15:00:45.209687
------------------------------------------------------
Started: 2025-03-29 18:00:31.394722
Existing_entries: 926
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-29 18:00:31.729272
------------------------------------------------------
Started: 2025-03-29 21:00:42.014229
Existing_entries: 926
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-29 21:00:42.200272
------------------------------------------------------
Started: 2025-03-30 00:40:32.810804
Existing_entries: 926
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-30 00:40:32.977083
------------------------------------------------------
Started: 2025-03-30 03:28:59.511314
Existing_entries: 926
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-30 03:28:59.742888
------------------------------------------------------
Started: 2025-03-30 06:00:52.850901
Existing_entries: 926
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-30 06:00:53.006318
------------------------------------------------------
Started: 2025-03-30 09:00:50.900841
Existing_entries: 926
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-30 09:00:51.091699
------------------------------------------------------
Started: 2025-03-30 12:12:04.569544
Existing_entries: 926
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-30 12:12:04.790443
------------------------------------------------------
Started: 2025-03-30 15:00:35.712302
Existing_entries: 926
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-30 15:00:35.894642
------------------------------------------------------
Started: 2025-03-30 18:00:34.882817
Existing_entries: 926
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-30 18:00:35.056433
------------------------------------------------------
Started: 2025-03-30 21:00:45.781865
Existing_entries: 926
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-30 21:00:45.975453
------------------------------------------------------
Started: 2025-03-31 00:40:08.291180
Existing_entries: 926
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-31 00:40:08.740995
------------------------------------------------------
Started: 2025-03-31 03:29:27.829720
Existing_entries: 926
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-31 03:29:28.031684
------------------------------------------------------
Started: 2025-03-31 06:11:58.420826
Existing_entries: 926
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Sequential Recommendation (SeqRec) aims to predict the next item by capturing sequential patterns from users' historical interactions, playing a crucial role in many real-world recommender systems. However, existing approaches predominantly adopt a direct forward computation paradigm, where the final hidden state of the sequence encoder serves as the user representation. We argue that this inference paradigm, due to its limited computational depth, struggles to model the complex evolving nature of user preferences and lacks a nuanced understanding of long-tail items, leading to suboptimal performance. To address this issue, we propose ReaRec, the first inference-time computing framework for recommender systems, which enhances user representations through implicit multi-step reasoning. Specifically, ReaRec autoregressively feeds the sequence's last hidden state into the sequential recommender while incorporating special reasoning position embeddings to decouple the original item encoding space from the multi-step reasoning space. Moreover, we introduce two lightweight reasoning-based learning methods, Ensemble Reasoning Learning (ERL) and Progressive Reasoning Learning (PRL), to further effectively exploit ReaRec's reasoning potential. Extensive experiments on five public real-world datasets and different SeqRec architectures demonstrate the generality and effectiveness of our proposed ReaRec. Remarkably, post-hoc analyses reveal that ReaRec significantly elevates the performance ceiling of multiple sequential recommendation backbones by approximately 30\\%-50\\%. Thus, we believe this work can open a new and promising avenue for future research in inference-time computing for sequential recommendation."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Think Before Recommend: Unleashing the Latent Reasoning Power for Sequential Recommendation](https://arxiv.org/abs/2503.22675)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We introduce ORIGEN, the first zero-shot method for 3D orientation grounding in text-to-image generation across multiple objects and diverse categories. While previous work on spatial grounding in image generation has mainly focused on 2D positioning, it lacks control over 3D orientation. To address this, we propose a reward-guided sampling approach using a pretrained discriminative model for 3D orientation estimation and a one-step text-to-image generative flow model. While gradient-ascent-based optimization is a natural choice for reward-based guidance, it struggles to maintain image realism. Instead, we adopt a sampling-based approach using Langevin dynamics, which extends gradient ascent by simply injecting random noise--requiring just a single additional line of code. Additionally, we introduce adaptive time rescaling based on the reward function to accelerate convergence. Our experiments show that ORIGEN outperforms both training-based and test-time guidance methods across quantitative metrics and user studies.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [ORIGEN: Zero-Shot 3D Orientation Grounding in Text-to-Image Generation](https://arxiv.org/abs/2503.22194)
append_entries: 2
Finish: 2025-03-31 06:11:59.681915
------------------------------------------------------
Started: 2025-03-31 09:00:36.706444
Existing_entries: 928
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Motivated in part by their relevance for low-precision training and quantization, massive activations in large language models (LLMs) have recently emerged as a topic of interest. However, existing analyses are limited in scope, and generalizability across architectures is unclear. This paper helps address some of these gaps by conducting an analysis of massive activations across a broad range of LLMs, including both GLU-based and non-GLU-based architectures. Our findings challenge several prior assumptions, most importantly: (1) not all massive activations are detrimental, i.e. suppressing them does not lead to an explosion of perplexity or a collapse in downstream task performance; (2) proposed mitigation strategies such as Attention KV bias are model-specific and ineffective in certain cases. We consequently investigate novel hybrid mitigation strategies; in particular pairing Target Variance Rescaling (TVR) with Attention KV bias or Dynamic Tanh (DyT) successfully balances the mitigation of massive activations with preserved downstream model performance in the scenarios we investigated. Our code is available at: https://github.com/bluorion-com/refine_massive_activations.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [A Refined Analysis of Massive Activations in LLMs](https://arxiv.org/abs/2503.22329)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Moving object segmentation is a crucial task for achieving a high-level understanding of visual scenes and has numerous downstream applications. Humans can effortlessly segment moving objects in videos. Previous work has largely relied on optical flow to provide motion cues; however, this approach often results in imperfect predictions due to challenges such as partial motion, complex deformations, motion blur and background distractions. We propose a novel approach for moving object segmentation that combines long-range trajectory motion cues with DINO-based semantic features and leverages SAM2 for pixel-level mask densification through an iterative prompting strategy. Our model employs Spatio-Temporal Trajectory Attention and Motion-Semantic Decoupled Embedding to prioritize motion while integrating semantic support. Extensive testing on diverse datasets demonstrates state-of-the-art performance, excelling in challenging scenarios and fine-grained segmentation of multiple objects. Our code is available at https://motion-seg.github.io/.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Segment Any Motion in Videos](https://arxiv.org/abs/2503.22268)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'With the growing demand for high-fidelity 3D models from 2D images, existing methods still face significant challenges in accurately reproducing fine-grained geometric details due to limitations in domain gaps and inherent ambiguities in RGB images. To address these issues, we propose Hi3DGen, a novel framework for generating high-fidelity 3D geometry from images via normal bridging. Hi3DGen consists of three key components: (1) an image-to-normal estimator that decouples the low-high frequency image pattern with noise injection and dual-stream training to achieve generalizable, stable, and sharp estimation; (2) a normal-to-geometry learning approach that uses normal-regularized latent diffusion learning to enhance 3D geometry generation fidelity; and (3) a 3D data synthesis pipeline that constructs a high-quality dataset to support training. Extensive experiments demonstrate the effectiveness and superiority of our framework in generating rich geometric details, outperforming state-of-the-art methods in terms of fidelity. Our work provides a new direction for high-fidelity 3D geometry generation from images by leveraging normal maps as an intermediate representation.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Hi3DGen: High-fidelity 3D Geometry Generation from Images via Normal Bridging](https://arxiv.org/abs/2503.22236)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Reinforcement Learning from Human Feedback (RLHF) is crucial for aligning large language models with human preferences. While recent research has focused on algorithmic improvements, the importance of prompt-data construction has been overlooked. This paper addresses this gap by exploring data-driven bottlenecks in RLHF performance scaling, particularly reward hacking and decreasing response diversity. We introduce a hybrid reward system combining reasoning task verifiers (RTV) and a generative reward model (GenRM) to mitigate reward hacking. We also propose a novel prompt-selection method, Pre-PPO, to maintain response diversity and enhance learning effectiveness. Additionally, we find that prioritizing mathematical and coding tasks early in RLHF training significantly improves performance. Experiments across two model sizes validate our methods' effectiveness and scalability. Results show that RTV is most resistant to reward hacking, followed by GenRM with ground truth, and then GenRM with SFT Best-of-N responses. Our strategies enable rapid capture of subtle task-specific distinctions, leading to substantial improvements in overall RLHF performance. This work highlights the importance of careful data construction and provides practical methods to overcome performance barriers in RLHF."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Exploring Data Scaling Trends and Effects in Reinforcement Learning from Human Feedback](https://arxiv.org/abs/2503.22230)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Four-dimensional computed tomography (4D CT) reconstruction is crucial for capturing dynamic anatomical changes but faces inherent limitations from conventional phase-binning workflows. Current methods discretize temporal resolution into fixed phases with respiratory gating devices, introducing motion misalignment and restricting clinical practicality. In this paper, We propose X^2-Gaussian, a novel framework that enables continuous-time 4D-CT reconstruction by integrating dynamic radiative Gaussian splatting with self-supervised respiratory motion learning. Our approach models anatomical dynamics through a spatiotemporal encoder-decoder architecture that predicts time-varying Gaussian deformations, eliminating phase discretization. To remove dependency on external gating devices, we introduce a physiology-driven periodic consistency loss that learns patient-specific breathing cycles directly from projections via differentiable optimization. Extensive experiments demonstrate state-of-the-art performance, achieving a 9.93 dB PSNR gain over traditional methods and 2.25 dB improvement against prior Gaussian splatting techniques. By unifying continuous motion modeling with hardware-free period learning, X^2-Gaussian advances high-fidelity 4D CT reconstruction for dynamic clinical imaging. Project website at: https://x2-gaussian.github.io/.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [X^{2}-Gaussian: 4D Radiative Gaussian Splatting for Continuous-time Tomographic Reconstruction](https://arxiv.org/abs/2503.21779)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Creating high-fidelity 3D meshes with arbitrary topology, including open surfaces and complex interiors, remains a significant challenge. Existing implicit field methods often require costly and detail-degrading watertight conversion, while other approaches struggle with high resolutions. This paper introduces SparseFlex, a novel sparse-structured isosurface representation that enables differentiable mesh reconstruction at resolutions up to 1024^3 directly from rendering losses. SparseFlex combines the accuracy of Flexicubes with a sparse voxel structure, focusing computation on surface-adjacent regions and efficiently handling open surfaces. Crucially, we introduce a frustum-aware sectional voxel training strategy that activates only relevant voxels during rendering, dramatically reducing memory consumption and enabling high-resolution training. This also allows, for the first time, the reconstruction of mesh interiors using only rendering supervision. Building upon this, we demonstrate a complete shape modeling pipeline by training a variational autoencoder (VAE) and a rectified flow transformer for high-quality 3D shape generation. Our experiments show state-of-the-art reconstruction accuracy, with a ~82% reduction in Chamfer Distance and a ~88% increase in F-score compared to previous methods, and demonstrate the generation of high-resolution, detailed 3D shapes with arbitrary topology. By enabling high-resolution, differentiable mesh reconstruction and generation with rendering losses, SparseFlex significantly advances the state-of-the-art in 3D shape representation and modeling.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [SparseFlex: High-Resolution and Arbitrary-Topology 3D Shape Modeling](https://arxiv.org/abs/2503.21732)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Traditional image classification requires a predefined list of semantic categories. In contrast, Large Multimodal Models (LMMs) can sidestep this requirement by classifying images directly using natural language (e.g., answering the prompt "What is the main object in the image?"). Despite this remarkable capability, most existing studies on LMM classification performance are surprisingly limited in scope, often assuming a closed-world setting with a predefined set of categories. In this work, we address this gap by thoroughly evaluating LMM classification performance in a truly open-world setting. We first formalize the task and introduce an evaluation protocol, defining various metrics to assess the alignment between predicted and ground truth classes. We then evaluate 13 models across 10 benchmarks, encompassing prototypical, non-prototypical, fine-grained, and very fine-grained classes, demonstrating the challenges LMMs face in this task. Further analyses based on the proposed metrics reveal the types of errors LMMs make, highlighting challenges related to granularity and fine-grained capabilities, showing how tailored prompting and reasoning can alleviate them.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [On Large Multimodal Models as Open-World Image Classifiers](https://arxiv.org/abs/2503.21851)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Recent Large Reasoning Models (LRMs), such as DeepSeek-R1 and OpenAI o1, have demonstrated strong performance gains by scaling up the length of Chain-of-Thought (CoT) reasoning during inference. However, a growing concern lies in their tendency to produce excessively long reasoning traces, which are often filled with redundant content (e.g., repeated definitions), over-analysis of simple problems, and superficial exploration of multiple reasoning paths for harder tasks. This inefficiency introduces significant challenges for training, inference, and real-world deployment (e.g., in agent-based systems), where token economy is critical. In this survey, we provide a comprehensive overview of recent efforts aimed at improving reasoning efficiency in LRMs, with a particular focus on the unique challenges that arise in this new paradigm. We identify common patterns of inefficiency, examine methods proposed across the LRM lifecycle, i.e., from pretraining to inference, and discuss promising future directions for research. To support ongoing development, we also maintain a real-time GitHub repository tracking recent progress in the field. We hope this survey serves as a foundation for further exploration and inspires innovation in this rapidly evolving area.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [A Survey of Efficient Reasoning for Large Reasoning Models: Language, Multimodality, and Beyond](https://arxiv.org/abs/2503.21614)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Summarization refinement faces challenges when extending to multi-dimension. In this paper, we introduce ReFeed, a powerful summarization refinement pipeline that enhances multiple dimensions through reflective reasoning on feedback. To achieve this, we release SumFeed-CoT, a large-scale Long-CoT-based dataset optimized for training a lightweight model with reflective reasoning. Our experiments reveal how the number of dimensions, feedback exposure, and reasoning policy influence refinement performance, highlighting reflective reasoning and simultaneously addressing multiple feedback is crucial to mitigate trade-off between dimensions. Furthermore, ReFeed is robust to noisy feedback and feedback order. Lastly, our finding emphasizes that creating data with a proper goal and guideline constitutes a fundamental pillar of effective reasoning. The dataset and model will be released.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [ReFeed: Multi-dimensional Summarization Refinement with Reflective Reasoning on Feedback](https://arxiv.org/abs/2503.21332)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We present Free4D, a novel tuning-free framework for 4D scene generation from a single image. Existing methods either focus on object-level generation, making scene-level generation infeasible, or rely on large-scale multi-view video datasets for expensive training, with limited generalization ability due to the scarcity of 4D scene data. In contrast, our key insight is to distill pre-trained foundation models for consistent 4D scene representation, which offers promising advantages such as efficiency and generalizability. 1) To achieve this, we first animate the input image using image-to-video diffusion models followed by 4D geometric structure initialization. 2) To turn this coarse structure into spatial-temporal consistent multiview videos, we design an adaptive guidance mechanism with a point-guided denoising strategy for spatial consistency and a novel latent replacement strategy for temporal coherence. 3) To lift these generated observations into consistent 4D representation, we propose a modulation-based refinement to mitigate inconsistencies while fully leveraging the generated information. The resulting 4D representation enables real-time, controllable rendering, marking a significant advancement in single-image-based 4D scene generation.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Free4D: Tuning-free 4D Scene Generation with Spatial-Temporal Consistency](https://arxiv.org/abs/2503.20785)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Recent advancements in speech-driven 3D talking head generation have made significant progress in lip synchronization. However, existing models still struggle to capture the perceptual alignment between varying speech characteristics and corresponding lip movements. In this work, we claim that three criteria -- Temporal Synchronization, Lip Readability, and Expressiveness -- are crucial for achieving perceptually accurate lip movements. Motivated by our hypothesis that a desirable representation space exists to meet these three criteria, we introduce a speech-mesh synchronized representation that captures intricate correspondences between speech signals and 3D face meshes. We found that our learned representation exhibits desirable characteristics, and we plug it into existing models as a perceptual loss to better align lip movements to the given speech. In addition, we utilize this representation as a perceptual metric and introduce two other physically grounded lip synchronization metrics to assess how well the generated 3D talking heads align with these three criteria. Experiments show that training 3D talking head generation models with our perceptual loss significantly improve all three aspects of perceptually accurate lip synchronization. Codes and datasets are available at https://perceptual-3d-talking-head.github.io/.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Perceptually Accurate 3D Talking Head Generation: New Definitions, Speech-Mesh Representation, and Evaluation Metrics](https://arxiv.org/abs/2503.20308)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We introduce PHYSICS, a comprehensive benchmark for university-level physics problem solving. It contains 1297 expert-annotated problems covering six core areas: classical mechanics, quantum mechanics, thermodynamics and statistical mechanics, electromagnetism, atomic physics, and optics. Each problem requires advanced physics knowledge and mathematical reasoning. We develop a robust automated evaluation system for precise and reliable validation. Our evaluation of leading foundation models reveals substantial limitations. Even the most advanced model, o3-mini, achieves only 59.9% accuracy, highlighting significant challenges in solving high-level scientific problems. Through comprehensive error analysis, exploration of diverse prompting strategies, and Retrieval-Augmented Generation (RAG)-based knowledge augmentation, we identify key areas for improvement, laying the foundation for future advancements.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [PHYSICS: Benchmarking Foundation Models on University-Level Physics Problem Solving](https://arxiv.org/abs/2503.21821)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Large Language Models (LLMs) have shown impressive versatility as general purpose models. However, their broad applicability comes at a high-cost computational overhead, particularly in auto-regressive decoding where each step requires a forward pass. In domain-specific settings, general-purpose capabilities are unnecessary and can be exchanged for efficiency. In this work, we take a novel perspective on domain adaptation, reducing latency and computational costs by adapting the vocabulary to focused domains of interest. We introduce AdaptiVocab, an end-to-end approach for vocabulary adaptation, designed to enhance LLM efficiency in low-resource domains. AdaptiVocab can be applied to any tokenizer and architecture, modifying the vocabulary by replacing tokens with domain-specific n-gram-based tokens, thereby reducing the number of tokens required for both input processing and output generation. AdaptiVocab initializes new n-token embeddings using an exponentially weighted combination of existing embeddings and employs a lightweight fine-tuning phase that can be efficiently performed on a single GPU. We evaluate two 7B LLMs across three niche domains, assessing efficiency, generation quality, and end-task performance. Our results show that AdaptiVocab reduces token usage by over 25% without compromising performance'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [AdaptiVocab: Enhancing LLM Efficiency in Focused Domains through Lightweight Vocabulary Adaptation](https://arxiv.org/abs/2503.19693)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Developing reliable AI systems to assist human clinicians in multi-modal medical diagnosis has long been a key objective for researchers. Recently, Multi-modal Large Language Models (MLLMs) have gained significant attention and achieved success across various domains. With strong reasoning capabilities and the ability to perform diverse tasks based on user instructions, they hold great potential for enhancing medical diagnosis. However, directly applying MLLMs to the medical domain still presents challenges. They lack detailed perception of visual inputs, limiting their ability to perform quantitative image analysis, which is crucial for medical diagnostics. Additionally, MLLMs often exhibit hallucinations and inconsistencies in reasoning, whereas clinical diagnoses must adhere strictly to established criteria. To address these challenges, we propose MedAgent-Pro, an evidence-based reasoning agentic system designed to achieve reliable, explainable, and precise medical diagnoses. This is accomplished through a hierarchical workflow: at the task level, knowledge-based reasoning generate reliable diagnostic plans for specific diseases following retrieved clinical criteria. While at the case level, multiple tool agents process multi-modal inputs, analyze different indicators according to the plan, and provide a final diagnosis based on both quantitative and qualitative evidence. Comprehensive experiments on both 2D and 3D medical diagnosis tasks demonstrate the superiority and effectiveness of MedAgent-Pro, while case studies further highlight its reliability and interpretability. The code is available at https://github.com/jinlab-imvr/MedAgent-Pro.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [MedAgent-Pro: Towards Multi-modal Evidence-based Medical Diagnosis via Reasoning Agentic Workflow](https://arxiv.org/abs/2503.18968)
append_entries: 14
Finish: 2025-03-31 09:00:42.139602
------------------------------------------------------
Started: 2025-03-31 12:00:59.587969
Existing_entries: 942
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-31 12:00:59.800642
------------------------------------------------------
Started: 2025-03-31 15:00:40.015548
Existing_entries: 942
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'In this paper, we introduce a method for reconstructing 3D humans from a single image using a biomechanically accurate skeleton model. To achieve this, we train a transformer that takes an image as input and estimates the parameters of the model. Due to the lack of training data for this task, we build a pipeline to produce pseudo ground truth model parameters for single images and implement a training procedure that iteratively refines these pseudo labels. Compared to state-of-the-art methods for 3D human mesh recovery, our model achieves competitive performance on standard benchmarks, while it significantly outperforms them in settings with extreme 3D poses and viewpoints. Additionally, we show that previous reconstruction methods frequently violate joint angle limits, leading to unnatural rotations. In contrast, our approach leverages the biomechanically plausible degrees of freedom making more realistic joint rotation estimates. We validate our approach across multiple human pose estimation benchmarks. We make the code, models and data available at: https://isshikihugh.github.io/HSMR/'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Reconstructing Humans with a Biomechanically Accurate Skeleton](https://arxiv.org/abs/2503.21751)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Vision Transformers (ViTs) have shown remarkable performance and scalability across various computer vision tasks. To apply single-scale ViTs to image segmentation, existing methods adopt a convolutional adapter to generate multi-scale features, a pixel decoder to fuse these features, and a Transformer decoder that uses the fused features to make predictions. In this paper, we show that the inductive biases introduced by these task-specific components can instead be learned by the ViT itself, given sufficiently large models and extensive pre-training. Based on these findings, we introduce the Encoder-only Mask Transformer (EoMT), which repurposes the plain ViT architecture to conduct image segmentation. With large-scale models and pre-training, EoMT obtains a segmentation accuracy similar to state-of-the-art models that use task-specific components. At the same time, EoMT is significantly faster than these methods due to its architectural simplicity, e.g., up to 4x faster with ViT-L. Across a range of model sizes, EoMT demonstrates an optimal balance between segmentation accuracy and prediction speed, suggesting that compute resources are better spent on scaling the ViT itself rather than adding architectural complexity. Code: https://www.tue-mps.org/eomt/.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Your ViT is Secretly an Image Segmentation Model](https://arxiv.org/abs/2503.19108)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Multimodal Large Language Models (MLLMs) have demonstrated impressive 2D image/video understanding capabilities. However, there are no publicly standardized benchmarks to assess the abilities of MLLMs in understanding the 4D objects (3D objects with temporal evolution over time). In this paper, we introduce 4D-Bench, the first benchmark to evaluate the capabilities of MLLMs in 4D object understanding, featuring tasks in 4D object Question Answering (4D object QA) and 4D object captioning. 4D-Bench provides 4D objects with diverse categories, high-quality annotations, and tasks necessitating multi-view spatial-temporal understanding, different from existing 2D image/video-based benchmarks. With 4D-Bench, we evaluate a wide range of open-source and closed-source MLLMs. The results from the 4D object captioning experiment indicate that MLLMs generally exhibit weaker temporal understanding compared to their appearance understanding, notably, while open-source models approach closed-source performance in appearance understanding, they show larger performance gaps in temporal understanding. 4D object QA yields surprising findings: even with simple single-object videos, MLLMs perform poorly, with state-of-the-art GPT-4o achieving only 63\\% accuracy compared to the human baseline of 91\\%. These findings highlight a substantial gap in 4D object understanding and the need for further advancements in MLLMs.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [4D-Bench: Benchmarking Multi-modal Large Language Models for 4D Object Understanding](https://arxiv.org/abs/2503.17827)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Multimodal Large Language Models (MLLMs) have gained significant traction for their ability to process diverse input data types and generate coherent, contextually relevant outputs across various applications. While supervised fine-tuning (SFT) has been the predominant approach to enhance MLLM capabilities in task-specific optimization, it often falls short in fostering crucial generalized reasoning abilities. Although reinforcement learning (RL) holds great promise in overcoming these limitations, it encounters two significant challenges: (1) its generalized capacities in multimodal tasks remain largely unexplored, and (2) its training constraints, including the constant Kullback-Leibler divergence or the clamp strategy, often result in suboptimal bottlenecks. To address these challenges, we propose OThink-MR1, an advanced MLLM equipped with profound comprehension and reasoning capabilities across multimodal tasks. Specifically, we introduce Group Relative Policy Optimization with a dynamic Kullback-Leibler strategy (GRPO-D), which markedly enhances reinforcement learning (RL) performance. For Qwen2-VL-2B-Instruct, GRPO-D achieves a relative improvement of more than 5.72% over SFT and more than 13.59% over GRPO in same-task evaluation on two adapted datasets. Furthermore, GRPO-D demonstrates remarkable cross-task generalization capabilities, with an average relative improvement of more than 61.63% over SFT in cross-task evaluation. These results highlight that the MLLM trained with GRPO-D on one multimodal task can be effectively transferred to another task, underscoring the superior generalized reasoning capabilities of our proposed OThink-MR1 model.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [OThink-MR1: Stimulating multimodal generalized reasoning capabilities via dynamic reinforcement learning](https://arxiv.org/abs/2503.16081)
append_entries: 4
Finish: 2025-03-31 15:00:41.912631
------------------------------------------------------
Started: 2025-03-31 18:00:48.971080
Existing_entries: 946
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-31 18:00:49.252402
------------------------------------------------------
Started: 2025-03-31 21:00:58.730923
Existing_entries: 946
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Intent, typically clearly formulated and planned, functions as a cognitive framework for reasoning and problem-solving. This paper introduces the concept of Speaking with Intent (SWI) in large language models (LLMs), where the explicitly generated intent encapsulates the model's underlying intention and provides high-level planning to guide subsequent analysis and communication. By emulating deliberate and purposeful thoughts in the human mind, SWI is hypothesized to enhance the reasoning capabilities and generation quality of LLMs. Extensive experiments on mathematical reasoning benchmarks consistently demonstrate the superiority of Speaking with Intent over Baseline (i.e., generation without explicit intent). Moreover, SWI outperforms answer-trigger prompting methods Chain-of-Thought and Plan-and-Solve and maintains competitive performance with the strong method ARR (Analyzing, Retrieving, and Reasoning). Additionally, the effectiveness and generalizability of SWI are solidified on reasoning-intensive question answering (QA) and text summarization benchmarks, where SWI brings consistent improvement to the Baseline generation. In text summarization, SWI-generated summaries exhibit greater accuracy, conciseness, and factual correctness, with fewer hallucinations. Furthermore, human evaluations verify the coherence, effectiveness, and interpretability of the intent produced by SWI. This proof-of-concept study creates a novel avenue for enhancing LLMs' reasoning abilities with cognitive notions."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [SWI: Speaking with Intent in Large Language Models](https://arxiv.org/abs/2503.21544)
append_entries: 1
Finish: 2025-03-31 21:00:59.638190
------------------------------------------------------
Started: 2025-04-01 00:42:53.296303
Existing_entries: 947
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-01 00:42:53.469403
------------------------------------------------------
Started: 2025-04-01 03:35:19.720672
Existing_entries: 947
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-01 03:35:19.887942
------------------------------------------------------
Started: 2025-04-01 06:00:49.490880
Existing_entries: 947
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Reasoning-enhanced large language models (LLMs) explicitly generate intermediate reasoning steps prior to generating final answers, helping the model excel in complex problem-solving. In this paper, we demonstrate that this emerging generation framework offers a unique opportunity for more fine-grained control over model behavior. We propose Thinking Intervention, a novel paradigm designed to explicitly guide the internal reasoning processes of LLMs by strategically inserting or revising specific thinking tokens. We conduct comprehensive evaluations across multiple tasks, including instruction following on IFEval, instruction hierarchy on SEP, and safety alignment on XSTest and SORRY-Bench. Our results demonstrate that Thinking Intervention significantly outperforms baseline prompting approaches, achieving up to 6.7% accuracy gains in instruction-following scenarios, 15.4% improvements in reasoning about instruction hierarchies, and a 40.0% increase in refusal rates for unsafe prompts using open-source DeepSeek R1 models. Overall, our work opens a promising new research avenue for controlling reasoning LLMs.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Effectively Controlling Reasoning Models through Thinking Intervention](https://arxiv.org/abs/2503.24370)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'The detection of telecom fraud faces significant challenges due to the lack of high-quality multimodal training data that integrates audio signals with reasoning-oriented textual analysis. To address this gap, we present TeleAntiFraud-28k, the first open-source audio-text slow-thinking dataset specifically designed for automated telecom fraud analysis. Our dataset is constructed through three strategies: (1) Privacy-preserved text-truth sample generation using automatically speech recognition (ASR)-transcribed call recordings (with anonymized original audio), ensuring real-world consistency through text-to-speech (TTS) model regeneration; (2) Semantic enhancement via large language model (LLM)-based self-instruction sampling on authentic ASR outputs to expand scenario coverage; (3) Multi-agent adversarial synthesis that simulates emerging fraud tactics through predefined communication scenarios and fraud typologies. The generated dataset contains 28,511 rigorously processed speech-text pairs, complete with detailed annotations for fraud reasoning. The dataset is divided into three tasks: scenario classification, fraud detection, fraud type classification. Furthermore, we construct TeleAntiFraud-Bench, a standardized evaluation benchmark comprising proportionally sampled instances from the dataset, to facilitate systematic testing of model performance on telecom fraud detection tasks. We also contribute a production-optimized supervised fine-tuning (SFT) model trained on hybrid real/synthetic data, while open-sourcing the data processing framework to enable community-driven dataset expansion. This work establishes a foundational framework for multimodal anti-fraud research while addressing critical challenges in data privacy and scenario diversity. The project will be released at https://github.com/JimmyMa99/TeleAntiFraud.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [TeleAntiFraud-28k: A Audio-Text Slow-Thinking Dataset for Telecom Fraud Detection](https://arxiv.org/abs/2503.24115)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Recent advancements in video generation have achieved impressive motion realism, yet they often overlook character-driven storytelling, a crucial task for automated film, animation generation. We introduce Talking Characters, a more realistic task to generate talking character animations directly from speech and text. Unlike talking head, Talking Characters aims at generating the full portrait of one or more characters beyond the facial region. In this paper, we propose MoCha, the first of its kind to generate talking characters. To ensure precise synchronization between video and speech, we propose a speech-video window attention mechanism that effectively aligns speech and video tokens. To address the scarcity of large-scale speech-labeled video datasets, we introduce a joint training strategy that leverages both speech-labeled and text-labeled video data, significantly improving generalization across diverse character actions. We also design structured prompt templates with character tags, enabling, for the first time, multi-character conversation with turn-based dialogue-allowing AI-generated characters to engage in context-aware conversations with cinematic coherence. Extensive qualitative and quantitative evaluations, including human preference studies and benchmark comparisons, demonstrate that MoCha sets a new standard for AI-generated cinematic storytelling, achieving superior realism, expressiveness, controllability and generalization.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [MoCha: Towards Movie-Grade Talking Character Synthesis](https://arxiv.org/abs/2503.23307)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Evolutionary multiobjective optimization (EMO) has made significant strides over the past two decades. However, as problem scales and complexities increase, traditional EMO algorithms face substantial performance limitations due to insufficient parallelism and scalability. While most work has focused on algorithm design to address these challenges, little attention has been given to hardware acceleration, thereby leaving a clear gap between EMO algorithms and advanced computing devices, such as GPUs. To bridge the gap, we propose to parallelize EMO algorithms on GPUs via the tensorization methodology. By employing tensorization, the data structures and operations of EMO algorithms are transformed into concise tensor representations, which seamlessly enables automatic utilization of GPU computing. We demonstrate the effectiveness of our approach by applying it to three representative EMO algorithms: NSGA-III, MOEA/D, and HypE. To comprehensively assess our methodology, we introduce a multiobjective robot control benchmark using a GPU-accelerated physics engine. Our experiments show that the tensorized EMO algorithms achieve speedups of up to 1113x compared to their CPU-based counterparts, while maintaining solution quality and effectively scaling population sizes to hundreds of thousands. Furthermore, the tensorized EMO algorithms efficiently tackle complex multiobjective robot control tasks, producing high-quality solutions with diverse behaviors. Source codes are available at https://github.com/EMI-Group/evomo.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Bridging Evolutionary Multiobjective Optimization and GPU Acceleration via Tensorization](https://arxiv.org/abs/2503.20286)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'In recent years, large language models (LLMs) have shown remarkable capabilities in various artificial intelligence problems. However, they fail to plan reliably, even when prompted with a detailed definition of the planning task. Attempts to improve their planning capabilities, such as chain-of-thought prompting, fine-tuning, and explicit "reasoning" still yield incorrect plans and usually fail to generalize to larger tasks. In this paper, we show how to use LLMs to generate correct plans, even for out-of-distribution tasks of increasing size. For a given planning domain, we ask an LLM to generate several domain-dependent heuristic functions in the form of Python code, evaluate them on a set of training tasks within a greedy best-first search, and choose the strongest one. The resulting LLM-generated heuristics solve many more unseen test tasks than state-of-the-art domain-independent heuristics for classical planning. They are even competitive with the strongest learning algorithm for domain-dependent planning. These findings are especially remarkable given that our proof-of-concept implementation is based on an unoptimized Python planner and the baselines all build upon highly optimized C++ code. In some domains, the LLM-generated heuristics expand fewer states than the baselines, revealing that they are not only efficiently computable, but sometimes even more informative than the state-of-the-art heuristics. Overall, our results show that sampling a set of planning heuristic function programs can significantly improve the planning capabilities of LLMs.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Classical Planning with LLM-Generated Heuristics: Challenging the State of the Art with Python Code](https://arxiv.org/abs/2503.18809)
append_entries: 5
Finish: 2025-04-01 06:00:52.449090
------------------------------------------------------
Started: 2025-04-01 09:00:44.873222
Existing_entries: 952
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Reasoning before action and imagining potential outcomes (i.e., world models) are essential for embodied agents operating in complex open-world environments. Yet, prior work either incorporates only one of these abilities in an end-to-end agent or integrates multiple specialized models into an agent system, limiting the learning efficiency and generalization of the policy. Thus, this paper makes the first attempt to synergize Reasoning and Imagination in an end-to-end Generalist policy, termed RIG. To train RIG in an end-to-end manner, we construct a data pipeline that progressively integrates and enriches the content of imagination and reasoning in the trajectories collected from existing agents. The joint learning of reasoning and next image generation explicitly models the inherent correlation between reasoning, action, and dynamics of environments, and thus exhibits more than 17times sample efficiency improvements and generalization in comparison with previous works. During inference, RIG first reasons about the next action, produces potential action, and then predicts the action outcomes, which offers the agent a chance to review and self-correct based on the imagination before taking real actions. Experimental results show that the synergy of reasoning and imagination not only improves the robustness, generalization, and interoperability of generalist policy but also enables test-time scaling to enhance overall performance.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [RIG: Synergizing Reasoning and Imagination in End-to-End Generalist Policy](https://arxiv.org/abs/2503.24388)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We propose a novel approach for generating complex outputs that significantly improves accuracy in text-to-SQL tasks. Our method leverages execution results to select the most semantically consistent query from multiple candidates, enabling smaller, cost-effective models to surpass computationally intensive reasoning methods such as o1, o3-mini, and DeepSeek R1 while reducing inference cost by as much as 30 times. It integrates effortlessly with existing models, offering a practical and scalable pathway to state-of-the-art SQL generation.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Query and Conquer: Execution-Guided SQL Generation](https://arxiv.org/abs/2503.24364)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We introduce Open-Reasoner-Zero, the first open source implementation of large-scale reasoning-oriented RL training focusing on scalability, simplicity and accessibility. Through extensive experiments, we demonstrate that a minimalist approach, vanilla PPO with GAE (lambda=1, gamma=1) and straightforward rule-based rewards, without any KL regularization, is sufficient to scale up both response length and benchmark performance, similar to the phenomenon observed in DeepSeek-R1-Zero. Using the same base model as DeepSeek-R1-Zero-Qwen-32B, our implementation achieves superior performance on AIME2024, MATH500, and the GPQA Diamond benchmark while demonstrating remarkable efficiency -- requiring only a tenth of the training steps, compared to DeepSeek-R1-Zero pipeline. In the spirit of open source, we release our source code, parameter settings, training data, and model weights across various sizes.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Open-Reasoner-Zero: An Open Source Approach to Scaling Up Reinforcement Learning on the Base Model](https://arxiv.org/abs/2503.24290)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "As enthusiasm for scaling computation (data and parameters) in the pretraining era gradually diminished, test-time scaling (TTS), also referred to as ``test-time computing'' has emerged as a prominent research focus. Recent studies demonstrate that TTS can further elicit the problem-solving capabilities of large language models (LLMs), enabling significant breakthroughs not only in specialized reasoning tasks, such as mathematics and coding, but also in general tasks like open-ended Q&A. However, despite the explosion of recent efforts in this area, there remains an urgent need for a comprehensive survey offering a systemic understanding. To fill this gap, we propose a unified, multidimensional framework structured along four core dimensions of TTS research: what to scale, how to scale, where to scale, and how well to scale. Building upon this taxonomy, we conduct an extensive review of methods, application scenarios, and assessment aspects, and present an organized decomposition that highlights the unique functional roles of individual techniques within the broader TTS landscape. From this analysis, we distill the major developmental trajectories of TTS to date and offer hands-on guidelines for practical deployment. Furthermore, we identify several open challenges and offer insights into promising future directions, including further scaling, clarifying the functional essence of techniques, generalizing to more tasks, and more attributions."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [What, How, Where, and How Well? A Survey on Test-Time Scaling in Large Language Models](https://arxiv.org/abs/2503.24235)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Reinforcement learning (RL) with verifiable rewards (RLVR) has shown promising results in mathematical reasoning and coding tasks where well-structured reference answers are available. However, its applicability to broader domains remains underexplored. In this work, we study the extension of RLVR to more diverse domains such as medicine, chemistry, psychology, and economics. We observe high agreement in binary judgments across different large language models (LLMs) when objective reference answers exist, which challenges the necessity of large-scale annotation for training domain-specific reward models. To address the limitations of binary rewards when handling unstructured reference answers, we further incorporate model-based soft scoring into RLVR to improve its flexibility. Our experiments show that a distilled generative reward model can serve as an effective cross-domain verifier, providing reliable reward signals for RL without requiring domain-specific annotations. By fine-tuning a base 7B model using various RL algorithms against our reward model, we obtain policies that outperform state-of-the-art open-source aligned LLMs such as Qwen2.5-72B-Instruct and DeepSeek-R1-Distill-Qwen-32B by a large margin, across domains in free-form answer settings. This also strengthens RLVR's robustness and scalability, highlighting its potential for real-world applications with noisy or weak labels."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Expanding RL with Verifiable Rewards Across Diverse Domains](https://arxiv.org/abs/2503.23829)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'The recent emergence of Large Vision-Language Models(VLMs) has resulted in a variety of different benchmarks for evaluating such models. Despite this, we observe that most existing evaluation methods suffer from the fact that they either require the model to choose from pre-determined responses, sacrificing open-endedness, or evaluate responses using a judge model, resulting in subjective and unreliable evaluation. In addition, we observe a lack of benchmarks for VLMs in the Korean language, which are necessary as a separate metric from more common English language benchmarks, as the performance of generative language models can differ significantly based on the language being used. Therefore, we present KOFFVQA, a general-purpose free-form visual question answering benchmark in the Korean language for the evaluation of VLMs. Our benchmark consists of 275 carefully crafted questions each paired with an image and grading criteria covering 10 different aspects of VLM performance. The grading criteria eliminate the problem of unreliability by allowing the judge model to grade each response based on a pre-determined set of rules. By defining the evaluation criteria in an objective manner, even a small open-source model can be used to evaluate models on our benchmark reliably. In addition to evaluating a large number of existing VLMs on our benchmark, we also experimentally verify that our method of using pre-existing grading criteria for evaluation is much more reliable than existing methods. Our evaluation code is available at https://github.com/maum-ai/KOFFVQA'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [KOFFVQA: An Objectively Evaluated Free-form VQA Benchmark for Large Vision-Language Models in the Korean Language](https://arxiv.org/abs/2503.23730)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'This paper explores the task of Complex Visual Text Generation (CVTG), which centers on generating intricate textual content distributed across diverse regions within visual images. In CVTG, image generation models often rendering distorted and blurred visual text or missing some visual text. To tackle these challenges, we propose TextCrafter, a novel multi-visual text rendering method. TextCrafter employs a progressive strategy to decompose complex visual text into distinct components while ensuring robust alignment between textual content and its visual carrier. Additionally, it incorporates a token focus enhancement mechanism to amplify the prominence of visual text during the generation process. TextCrafter effectively addresses key challenges in CVTG tasks, such as text confusion, omissions, and blurriness. Moreover, we present a new benchmark dataset, CVTG-2K, tailored to rigorously evaluate the performance of generative models on CVTG tasks. Extensive experiments demonstrate that our method surpasses state-of-the-art approaches.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [TextCrafter: Accurately Rendering Multiple Texts in Complex Visual Scenes](https://arxiv.org/abs/2503.23461)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Video generation and editing conditioned on text prompts or images have undergone significant advancements. However, challenges remain in accurately controlling global layout and geometry details solely by texts, and supporting motion control and local modification through images. In this paper, we aim to achieve sketch-based spatial and motion control for video generation and support fine-grained editing of real or synthetic videos. Based on the DiT video generation model, we propose a memory-efficient control structure with sketch control blocks that predict residual features of skipped DiT blocks. Sketches are drawn on one or two keyframes (at arbitrary time points) for easy interaction. To propagate such temporally sparse sketch conditions across all frames, we propose an inter-frame attention mechanism to analyze the relationship between the keyframes and each video frame. For sketch-based video editing, we design an additional video insertion module that maintains consistency between the newly edited content and the original video's spatial feature and dynamic motion. During inference, we use latent fusion for the accurate preservation of unedited regions. Extensive experiments demonstrate that our SketchVideo achieves superior performance in controllable video generation and editing."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [SketchVideo: Sketch-based Video Generation and Editing](https://arxiv.org/abs/2503.23284)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Large Reasoning Models (LRMs) significantly improve the reasoning ability of Large Language Models (LLMs) by learning to reason, exhibiting promising performance in complex task-solving. However, their deliberative reasoning process leads to inefficiencies in token usage, memory consumption, and inference time. Thus, this survey provides a review of efficient inference methods designed specifically for LRMs, focusing on mitigating token inefficiency while preserving the reasoning quality. First, we introduce a taxonomy to group the recent methods into two main categories: (a) explicit compact Chain-of-Thought (CoT), which reduces tokens while keeping the explicit reasoning structure, and (b) implicit latent CoT, which encodes reasoning steps within hidden representations instead of explicit tokens. Meanwhile, we discuss their strengths and weaknesses. Then, we conduct empirical analyses on existing methods from performance and efficiency aspects. Besides, we present open challenges in this field, including human-centric controllable reasoning, trade-off between interpretability and efficiency of reasoning, ensuring safety of efficient reasoning, and broader applications of efficient reasoning. In addition, we highlight key insights for enhancing LRMs' inference efficiency via techniques such as model merging, new architectures, and agent routers. We hope this work serves as a valuable guide, helping researchers overcome challenges in this vibrant fieldhttps://github.com/yueliu1999/Awesome-Efficient-Inference-for-LRMs."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Efficient Inference for Large Reasoning Models: A Survey](https://arxiv.org/abs/2503.23077)
append_entries: 9
Finish: 2025-04-01 09:00:48.638030
------------------------------------------------------
Started: 2025-04-01 12:14:29.579380
Existing_entries: 961
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Recent advances in DUSt3R have enabled robust estimation of dense point clouds and camera parameters of static scenes, leveraging Transformer network architectures and direct supervision on large-scale 3D datasets. In contrast, the limited scale and diversity of available 4D datasets present a major bottleneck for training a highly generalizable 4D model. This constraint has driven conventional 4D methods to fine-tune 3D models on scalable dynamic video data with additional geometric priors such as optical flow and depths. In this work, we take an opposite path and introduce Easi3R, a simple yet efficient training-free method for 4D reconstruction. Our approach applies attention adaptation during inference, eliminating the need for from-scratch pre-training or network fine-tuning. We find that the attention layers in DUSt3R inherently encode rich information about camera and object motion. By carefully disentangling these attention maps, we achieve accurate dynamic region segmentation, camera pose estimation, and 4D dense point map reconstruction. Extensive experiments on real-world dynamic videos demonstrate that our lightweight attention adaptation significantly outperforms previous state-of-the-art methods that are trained or finetuned on extensive dynamic datasets. Our code is publicly available for research purpose at https://easi3r.github.io/'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Easi3R: Estimating Disentangled Motion from DUSt3R Without Training](https://arxiv.org/abs/2503.24391)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'It is highly desirable to obtain a model that can generate high-quality 3D meshes from text prompts in just seconds. While recent attempts have adapted pre-trained text-to-image diffusion models, such as Stable Diffusion (SD), into generators of 3D representations (e.g., Triplane), they often suffer from poor quality due to the lack of sufficient high-quality 3D training data. Aiming at overcoming the data shortage, we propose a novel training scheme, termed as Progressive Rendering Distillation (PRD), eliminating the need for 3D ground-truths by distilling multi-view diffusion models and adapting SD into a native 3D generator. In each iteration of training, PRD uses the U-Net to progressively denoise the latent from random noise for a few steps, and in each step it decodes the denoised latent into 3D output. Multi-view diffusion models, including MVDream and RichDreamer, are used in joint with SD to distill text-consistent textures and geometries into the 3D outputs through score distillation. Since PRD supports training without 3D ground-truths, we can easily scale up the training data and improve generation quality for challenging text prompts with creative concepts. Meanwhile, PRD can accelerate the inference speed of the generation model in just a few steps. With PRD, we train a Triplane generator, namely TriplaneTurbo, which adds only 2.5% trainable parameters to adapt SD for Triplane generation. TriplaneTurbo outperforms previous text-to-3D generators in both efficiency and quality. Specifically, it can produce high-quality 3D meshes in 1.2 seconds and generalize well for challenging text input. The code is available at https://github.com/theEricMa/TriplaneTurbo.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Progressive Rendering Distillation: Adapting Stable Diffusion for Instant Text-to-Mesh Generation without 3D Data](https://arxiv.org/abs/2503.21694)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Synthesizing diverse and physically plausible Human-Scene Interactions (HSI) is pivotal for both computer animation and embodied AI. Despite encouraging progress, current methods mainly focus on developing separate controllers, each specialized for a specific interaction task. This significantly hinders the ability to tackle a wide variety of challenging HSI tasks that require the integration of multiple skills, e.g., sitting down while carrying an object. To address this issue, we present TokenHSI, a single, unified transformer-based policy capable of multi-skill unification and flexible adaptation. The key insight is to model the humanoid proprioception as a separate shared token and combine it with distinct task tokens via a masking mechanism. Such a unified policy enables effective knowledge sharing across skills, thereby facilitating the multi-task training. Moreover, our policy architecture supports variable length inputs, enabling flexible adaptation of learned skills to new scenarios. By training additional task tokenizers, we can not only modify the geometries of interaction targets but also coordinate multiple skills to address complex tasks. The experiments demonstrate that our approach can significantly improve versatility, adaptability, and extensibility in various HSI tasks. Website: https://liangpan99.github.io/TokenHSI/'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [TokenHSI: Unified Synthesis of Physical Human-Scene Interactions through Task Tokenization](https://arxiv.org/abs/2503.19901)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Multimodal Large Language Models (MLLMs) have emerged to tackle the challenges of Visual Question Answering (VQA), sparking a new research focus on conducting objective evaluations of these models. Existing evaluation methods face limitations due to the significant human workload required to design Q&A pairs for visual images, which inherently restricts the scale and scope of evaluations. Although automated MLLM-as-judge approaches attempt to reduce the human workload through automatic evaluations, they often introduce biases. To address these problems, we propose an Unsupervised Peer review MLLM Evaluation framework. It utilizes only image data, allowing models to automatically generate questions and conduct peer review assessments of answers from other models, effectively alleviating the reliance on human workload. Additionally, we introduce the vision-language scoring system to mitigate the bias issues, which focuses on three aspects: (i) response correctness; (ii) visual understanding and reasoning; and (iii) image-text correlation. Experimental results demonstrate that UPME achieves a Pearson correlation of 0.944 with human evaluations on the MMstar dataset and 0.814 on the ScienceQA dataset, indicating that our framework closely aligns with human-designed benchmarks and inherent human preferences.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [UPME: An Unsupervised Peer Review Framework for Multimodal Large Language Model Evaluation](https://arxiv.org/abs/2503.14941)
append_entries: 4
Finish: 2025-04-01 12:14:31.391025
------------------------------------------------------
Started: 2025-04-01 15:00:34.515406
Existing_entries: 965
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'The mathematical problem-solving capabilities of large language models have become a focal point of research, with growing interests in leveraging self-generated reasoning paths as a promising way to refine and enhance these models. These paths capture step-by-step logical processes while requiring only the correct answer for supervision. The self-training method has been shown to be effective in reasoning tasks while eliminating the need for external models and manual annotations. However, optimizing the use of self-generated data for model training remains an open challenge. In this work, we propose Entropy-Based Adaptive Weighting for Self-Training (EAST), an adaptive weighting strategy designed to prioritize uncertain data during self-training. Specifically, EAST employs a mapping function with a tunable parameter that controls the sharpness of the weighting, assigning higher weights to data where the model exhibits greater uncertainty. This approach guides the model to focus on more informative and challenging examples, thereby enhancing its reasoning ability. We evaluate our approach on GSM8K and MATH benchmarks. Empirical results show that, while the vanilla method yields virtually no improvement (0%) on MATH, EAST achieves around a 1% gain over backbone model. On GSM8K, EAST attains a further 1-2% performance boost compared to the vanilla method.'}]}]Summarization failed, append the original article
error: Request timed out.. Line: 406.
Append: [Entropy-Based Adaptive Weighting for Self-Training](https://arxiv.org/abs/2503.23913)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'In the domain of 3D content creation, achieving optimal mesh topology through AI models has long been a pursuit for 3D artists. Previous methods, such as MeshGPT, have explored the generation of ready-to-use 3D objects via mesh auto-regressive techniques. While these methods produce visually impressive results, their reliance on token-by-token predictions in the auto-regressive process leads to several significant limitations. These include extremely slow generation speeds and an uncontrollable number of mesh faces. In this paper, we introduce MeshCraft, a novel framework for efficient and controllable mesh generation, which leverages continuous spatial diffusion to generate discrete triangle faces. Specifically, MeshCraft consists of two core components: 1) a transformer-based VAE that encodes raw meshes into continuous face-level tokens and decodes them back to the original meshes, and 2) a flow-based diffusion transformer conditioned on the number of faces, enabling the generation of high-quality 3D meshes with a predefined number of faces. By utilizing the diffusion model for the simultaneous generation of the entire mesh topology, MeshCraft achieves high-fidelity mesh generation at significantly faster speeds compared to auto-regressive methods. Specifically, MeshCraft can generate an 800-face mesh in just 3.2 seconds (35times faster than existing baselines). Extensive experiments demonstrate that MeshCraft outperforms state-of-the-art techniques in both qualitative and quantitative evaluations on ShapeNet dataset and demonstrates superior performance on Objaverse dataset. Moreover, it integrates seamlessly with existing conditional guidance strategies, showcasing its potential to relieve artists from the time-consuming manual work involved in mesh creation.'}]}]Summarization failed, append the original article
error: Request timed out.. Line: 406.
Append: [MeshCraft: Exploring Efficient and Controllable Mesh Generation with Flow-based DiTs](https://arxiv.org/abs/2503.23022)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Parameter-Efficient FineTuning (PEFT) methods have recently gained significant popularity thanks to the widespread availability of large-scale pretrained models. These methods allow for quick adaptation to downstream tasks with minimal computational cost. However, popular finetuning methods such as LoRA exhibit limited robustness when it comes to hyperparameter choices or extended training regimes, preventing optimal out-of-the-box performance. In contrast, bounded approaches, such as ETHER, provide greater robustness but are limited to extremely low-rank adaptations and fixed-strength transformations, reducing their adaptation expressive power. In this work, we propose Decoupled Low-rank Adaptation (DeLoRA), a novel finetuning method that normalizes and scales learnable low-rank matrices. By bounding the distance of the transformation, DeLoRA effectively decouples the angular learning from the adaptation strength, enhancing robustness without compromising performance. Through evaluations on subject-driven image generation, natural language understanding, and instruction tuning, we show that DeLoRA matches or surpasses performance of competing PEFT methods, while exhibiting stronger robustness. Code is available at https://github.com/ExplainableML/DeLoRA.'}]}]Summarization failed, append the original article
error: Request timed out.. Line: 406.
Append: [Decoupling Angles and Strength in Low-rank Adaptation](https://arxiv.org/abs/2503.18225)
append_entries: 3
Finish: 2025-04-01 15:01:24.072257
------------------------------------------------------
Started: 2025-04-01 18:00:38.063888
Existing_entries: 968
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Co-speech gestures play a vital role in non-verbal communication. In this paper, we introduce a new framework for co-speech gesture understanding in the wild. Specifically, we propose three new tasks and benchmarks to evaluate a model's capability to comprehend gesture-text-speech associations: (i) gesture-based retrieval, (ii) gestured word spotting, and (iii) active speaker detection using gestures. We present a new approach that learns a tri-modal speech-text-video-gesture representation to solve these tasks. By leveraging a combination of global phrase contrastive loss and local gesture-word coupling loss, we demonstrate that a strong gesture representation can be learned in a weakly supervised manner from videos in the wild. Our learned representations outperform previous methods, including large vision-language models (VLMs), across all three tasks. Further analysis reveals that speech and text modalities capture distinct gesture-related signals, underscoring the advantages of learning a shared tri-modal embedding space. The dataset, model, and code are available at: https://www.robots.ox.ac.uk/~vgg/research/jegal"}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Understanding Co-speech Gestures in-the-wild](https://arxiv.org/abs/2503.22668)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Training vision-language models (VLMs) typically requires large-scale, high-quality image-text pairs, but collecting or synthesizing such data is costly. In contrast, text data is abundant and inexpensive, prompting the question: can high-quality multimodal training data be synthesized purely from text? To tackle this, we propose a cross-integrated three-stage multimodal data synthesis framework, which generates two datasets: Unicorn-1.2M and Unicorn-471K-Instruction. In Stage 1: Diverse Caption Data Synthesis, we construct 1.2M semantically diverse high-quality captions by expanding sparse caption seeds using large language models (LLMs). In Stage 2: Instruction-Tuning Data Generation, we further process 471K captions into multi-turn instruction-tuning tasks to support complex reasoning. Finally, in Stage 3: Modality Representation Transfer, these textual captions representations are transformed into visual representations, resulting in diverse synthetic image representations. This three-stage process enables us to construct Unicorn-1.2M for pretraining and Unicorn-471K-Instruction for instruction-tuning, without relying on real images. By eliminating the dependency on real images while maintaining data quality and diversity, our framework offers a cost-effective and scalable solution for VLMs training. Code is available at https://github.com/Yu-xm/Unicorn.git.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Unicorn: Text-Only Data Synthesis for Vision Language Model Training](https://arxiv.org/abs/2503.22655)
append_entries: 2
Finish: 2025-04-01 18:00:39.107647
------------------------------------------------------
Started: 2025-04-01 21:00:38.429985
Existing_entries: 970
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Pre-trained video large language models (Video LLMs) exhibit remarkable reasoning capabilities, yet adapting these models to new tasks involving additional modalities or data types (e.g., audio or 3D information) remains challenging. In this paper, we present PAVE, a flexible framework for adapting pre-trained Video LLMs to downstream tasks with side-channel signals, such as audio, 3D cues, or multi-view videos. PAVE introduces lightweight adapters, referred to as "patches," which add a small number of parameters and operations to a base model without modifying its architecture or pre-trained weights. In doing so, PAVE can effectively adapt the pre-trained base model to support diverse downstream tasks, including audio-visual question answering, 3D reasoning, multi-view video recognition, and high frame rate video understanding. Across these tasks, PAVE significantly enhances the performance of the base model, surpassing state-of-the-art task-specific models while incurring a minor cost of ~0.1% additional FLOPs and parameters. Further, PAVE supports multi-task learning and generalizes well across different Video LLMs. Our code is available at https://github.com/dragonlzm/PAVE.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [PAVE: Patching and Adapting Video Large Language Models](https://arxiv.org/abs/2503.19794)
append_entries: 1
Finish: 2025-04-01 21:00:39.217485
------------------------------------------------------
Started: 2025-04-02 00:37:45.135559
Existing_entries: 971
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Action models are essential for enabling autonomous agents to perform complex tasks. However, training large action models remains challenging due to the diversity of agent environments and the complexity of agentic data. Despite growing interest, existing infrastructure provides limited support for scalable, agent-specific fine-tuning. We present ActionStudio, a lightweight and extensible data and training framework designed for large action models. ActionStudio unifies heterogeneous agent trajectories through a standardized format, supports diverse training paradigms including LoRA, full fine-tuning, and distributed setups, and integrates robust preprocessing and verification tools. We validate its effectiveness across both public and realistic industry benchmarks, demonstrating strong performance and practical scalability. We open-sourced code and data at https://github.com/SalesforceAIResearch/xLAM to facilitate research in the community.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [ActionStudio: A Lightweight Framework for Data and Training of Large Action Models](https://arxiv.org/abs/2503.22673)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'This work focuses on open-domain 4D avatarization, with the purpose of creating a 4D avatar from a portrait image in an arbitrary style. We select parametric triplanes as the intermediate 4D representation and propose a practical training paradigm that takes advantage of both generative adversarial networks (GANs) and diffusion models. Our design stems from the observation that 4D GANs excel at bridging images and triplanes without supervision yet usually face challenges in handling diverse data distributions. A robust 2D diffusion prior emerges as the solution, assisting the GAN in transferring its expertise across various domains. The synergy between these experts permits the construction of a multi-domain image-triplane dataset, which drives the development of a general 4D avatar creator. Extensive experiments suggest that our model, AvatarArtist, is capable of producing high-quality 4D avatars with strong robustness to various source image domains. The code, the data, and the models will be made publicly available to facilitate future studies..'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [AvatarArtist: Open-Domain 4D Avatarization](https://arxiv.org/abs/2503.19906)
append_entries: 2
Finish: 2025-04-02 00:37:46.321605
------------------------------------------------------
Started: 2025-04-02 03:24:52.275308
Existing_entries: 973
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Most 3D object generators focus on aesthetic quality, often neglecting physical constraints necessary in applications. One such constraint is that the 3D object should be self-supporting, i.e., remains balanced under gravity. Prior approaches to generating stable 3D objects used differentiable physics simulators to optimize geometry at test-time, which is slow, unstable, and prone to local optima. Inspired by the literature on aligning generative models to external feedback, we propose Direct Simulation Optimization (DSO), a framework to use the feedback from a (non-differentiable) simulator to increase the likelihood that the 3D generator outputs stable 3D objects directly. We construct a dataset of 3D objects labeled with a stability score obtained from the physics simulator. We can then fine-tune the 3D generator using the stability score as the alignment metric, via direct preference optimization (DPO) or direct reward optimization (DRO), a novel objective, which we introduce, to align diffusion models without requiring pairwise preferences. Our experiments show that the fine-tuned feed-forward generator, using either DPO or DRO objective, is much faster and more likely to produce stable objects than test-time optimization. Notably, the DSO framework works even without any ground-truth 3D objects for training, allowing the 3D generator to self-improve by automatically collecting simulation feedback on its own outputs.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [DSO: Aligning 3D Generators with Simulation Feedback for Physical Soundness](https://arxiv.org/abs/2503.22677)
append_entries: 1
Finish: 2025-04-02 03:24:53.044151
------------------------------------------------------
Started: 2025-04-02 06:00:42.826672
Existing_entries: 974
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Despite remarkable advancements in video depth estimation, existing methods exhibit inherent limitations in achieving geometric fidelity through the affine-invariant predictions, limiting their applicability in reconstruction and other metrically grounded downstream tasks. We propose GeometryCrafter, a novel framework that recovers high-fidelity point map sequences with temporal coherence from open-world videos, enabling accurate 3D/4D reconstruction, camera parameter estimation, and other depth-based applications. At the core of our approach lies a point map Variational Autoencoder (VAE) that learns a latent space agnostic to video latent distributions for effective point map encoding and decoding. Leveraging the VAE, we train a video diffusion model to model the distribution of point map sequences conditioned on the input videos. Extensive evaluations on diverse datasets demonstrate that GeometryCrafter achieves state-of-the-art 3D accuracy, temporal consistency, and generalization capability.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [GeometryCrafter: Consistent Geometry Estimation for Open-world Videos with Diffusion Priors](https://arxiv.org/abs/2504.01016)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Scaling test-time compute has emerged as a key strategy for enhancing the reasoning capabilities of large language models (LLMs), particularly in tasks like mathematical problem-solving. A traditional approach, Self-Consistency (SC), generates multiple solutions to a problem and selects the most common answer via majority voting. Another common method involves scoring each solution with a reward model (verifier) and choosing the best one. Recent advancements in Generative Reward Models (GenRM) reframe verification as a next-token prediction task, enabling inference-time scaling along a new axis. Specifically, GenRM generates multiple verification chains-of-thought to score each solution. Under a limited inference budget, this introduces a fundamental trade-off: should you spend the budget on scaling solutions via SC or generate fewer solutions and allocate compute to verification via GenRM? To address this, we evaluate GenRM against SC under a fixed inference budget. Interestingly, we find that SC is more compute-efficient than GenRM for most practical inference budgets across diverse models and datasets. For instance, GenRM first matches SC after consuming up to 8x the inference compute and requires significantly more compute to outperform it. Furthermore, we derive inference scaling laws for the GenRM paradigm, revealing that compute-optimal inference favors scaling solution generation more aggressively than scaling the number of verifications. Our work provides practical guidance on optimizing test-time scaling by balancing solution generation and verification. The code is available at https://github.com/nishadsinghi/sc-genrm-scaling.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [When To Solve, When To Verify: Compute-Optimal Problem Solving and Generative Verification for LLM Reasoning](https://arxiv.org/abs/2504.01005)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Computer use agents automate digital tasks by directly interacting with graphical user interfaces (GUIs) on computers and mobile devices, offering significant potential to enhance human productivity by completing an open-ended space of user queries. However, current agents face significant challenges: imprecise grounding of GUI elements, difficulties with long-horizon task planning, and performance bottlenecks from relying on single generalist models for diverse cognitive tasks. To this end, we introduce Agent S2, a novel compositional framework that delegates cognitive responsibilities across various generalist and specialist models. We propose a novel Mixture-of-Grounding technique to achieve precise GUI localization and introduce Proactive Hierarchical Planning, dynamically refining action plans at multiple temporal scales in response to evolving observations. Evaluations demonstrate that Agent S2 establishes new state-of-the-art (SOTA) performance on three prominent computer use benchmarks. Specifically, Agent S2 achieves 18.9% and 32.7% relative improvements over leading baseline agents such as Claude Computer Use and UI-TARS on the OSWorld 15-step and 50-step evaluation. Moreover, Agent S2 generalizes effectively to other operating systems and applications, surpassing previous best methods by 52.8% on WindowsAgentArena and by 16.52% on AndroidWorld relatively. Code available at https://github.com/simular-ai/Agent-S.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Agent S2: A Compositional Generalist-Specialist Framework for Computer Use Agents](https://arxiv.org/abs/2504.00906)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'To address the bottleneck of accurate user intent interpretation within the current video generation community, we present Any2Caption, a novel framework for controllable video generation under any condition. The key idea is to decouple various condition interpretation steps from the video synthesis step. By leveraging modern multimodal large language models (MLLMs), Any2Caption interprets diverse inputs--text, images, videos, and specialized cues such as region, motion, and camera poses--into dense, structured captions that offer backbone video generators with better guidance. We also introduce Any2CapIns, a large-scale dataset with 337K instances and 407K conditions for any-condition-to-caption instruction tuning. Comprehensive evaluations demonstrate significant improvements of our system in controllability and video quality across various aspects of existing video generation models. Project Page: https://sqwu.top/Any2Cap/'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Any2Caption:Interpreting Any Condition to Caption for Controllable Video Generation](https://arxiv.org/abs/2503.24379)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Recent advancements in Large Language Models (LLMs) have significantly enhanced their ability to perform complex reasoning tasks, transitioning from fast and intuitive thinking (System 1) to slow and deep reasoning (System 2). While System 2 reasoning improves task accuracy, it often incurs substantial computational costs due to its slow thinking nature and inefficient or unnecessary reasoning behaviors. In contrast, System 1 reasoning is computationally efficient but leads to suboptimal performance. Consequently, it is critical to balance the trade-off between performance (benefits) and computational costs (budgets), giving rise to the concept of reasoning economy. In this survey, we provide a comprehensive analysis of reasoning economy in both the post-training and test-time inference stages of LLMs, encompassing i) the cause of reasoning inefficiency, ii) behavior analysis of different reasoning patterns, and iii) potential solutions to achieve reasoning economy. By offering actionable insights and highlighting open challenges, we aim to shed light on strategies for improving the reasoning economy of LLMs, thereby serving as a valuable resource for advancing research in this evolving area. We also provide a public repository to continually track developments in this fast-evolving field.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Harnessing the Reasoning Economy: A Survey of Efficient Reasoning for Large Language Models](https://arxiv.org/abs/2503.24377)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Recent advancements in Chain of Thought (COT) generation have significantly improved the reasoning capabilities of Large Language Models (LLMs), with reinforcement learning (RL) emerging as an effective post-training approach. Multimodal Large Language Models (MLLMs) inherit this reasoning potential but remain underexplored in tasks requiring both perception and logical reasoning. To address this, we introduce SEED-Bench-R1, a benchmark designed to systematically evaluate post-training methods for MLLMs in video understanding. It includes intricate real-world videos and complex everyday planning tasks in the format of multiple-choice questions, requiring sophisticated perception and reasoning. SEED-Bench-R1 assesses generalization through a three-level hierarchy: in-distribution, cross-environment, and cross-environment-task scenarios, equipped with a large-scale training dataset with easily verifiable ground-truth answers. Using Qwen2-VL-Instruct-7B as a base model, we compare RL with supervised fine-tuning (SFT), demonstrating RL's data efficiency and superior performance on both in-distribution and out-of-distribution tasks, even outperforming SFT on general video understanding benchmarks like LongVideoBench. Our detailed analysis reveals that RL enhances visual perception but often produces less logically coherent reasoning chains. We identify key limitations such as inconsistent reasoning and overlooked visual cues, and suggest future improvements in base model reasoning, reward modeling, and RL robustness against noisy signals."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Exploring the Effect of Reinforcement Learning on Video Understanding: Insights from SEED-Bench-R1](https://arxiv.org/abs/2503.24376)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Recently, model merging methods have demonstrated powerful strengths in combining abilities on various tasks from multiple Large Language Models (LLMs). While previous model merging methods mainly focus on merging homogeneous models with identical architecture, they meet challenges when dealing with Multimodal Large Language Models (MLLMs) with inherent heterogeneous property, including differences in model architecture and the asymmetry in the parameter space. In this work, we propose AdaMMS, a novel model merging method tailored for heterogeneous MLLMs. Our method tackles the challenges in three steps: mapping, merging and searching. Specifically, we first design mapping function between models to apply model merging on MLLMs with different architecture. Then we apply linear interpolation on model weights to actively adapt the asymmetry in the heterogeneous MLLMs. Finally in the hyper-parameter searching step, we propose an unsupervised hyper-parameter selection method for model merging. As the first model merging method capable of merging heterogeneous MLLMs without labeled data, extensive experiments on various model combinations demonstrated that AdaMMS outperforms previous model merging methods on various vision-language benchmarks.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [AdaMMS: Model Merging for Heterogeneous Multimodal Large Language Models with Unsupervised Coefficient Optimization](https://arxiv.org/abs/2503.23733)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Large language models (LLMs) possess impressive linguistic capabilities but often fail to faithfully retain factual knowledge, leading to hallucinations and unreliable outputs. Understanding LLMs' knowledge deficiencies by exhaustively evaluating against full-scale knowledge bases is computationally prohibitive, especially for closed-weight models. We propose stochastic error ascent (SEA), a scalable and efficient framework for discovering knowledge deficiencies (errors) in closed-weight LLMs under a strict query budget. Rather than naively probing all knowledge candidates, SEA formulates error discovery as a stochastic optimization process: it iteratively retrieves new high-error candidates by leveraging the semantic similarity to previously observed failures. To further enhance search efficiency and coverage, SEA employs hierarchical retrieval across document and paragraph levels, and constructs a relation directed acyclic graph to model error propagation and identify systematic failure modes. Empirically, SEA uncovers 40.7x more knowledge errors than Automated Capability Discovery and 26.7% more than AutoBencher, while reducing the cost-per-error by 599x and 9x, respectively. Human evaluation confirms the high quality of generated questions, while ablation and convergence analyses validate the contribution of each component in SEA. Further analysis on the discovered errors reveals correlated failure patterns across LLM families and recurring deficits, highlighting the need for better data coverage and targeted fine-tuning in future LLM development."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Discovering Knowledge Deficiencies of Language Models on Massive Knowledge Base](https://arxiv.org/abs/2503.23361)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Human hands play a central role in interacting, motivating increasing research in dexterous robotic manipulation. Data-driven embodied AI algorithms demand precise, large-scale, human-like manipulation sequences, which are challenging to obtain with conventional reinforcement learning or real-world teleoperation. To address this, we introduce ManipTrans, a novel two-stage method for efficiently transferring human bimanual skills to dexterous robotic hands in simulation. ManipTrans first pre-trains a generalist trajectory imitator to mimic hand motion, then fine-tunes a specific residual module under interaction constraints, enabling efficient learning and accurate execution of complex bimanual tasks. Experiments show that ManipTrans surpasses state-of-the-art methods in success rate, fidelity, and efficiency. Leveraging ManipTrans, we transfer multiple hand-object datasets to robotic hands, creating DexManipNet, a large-scale dataset featuring previously unexplored tasks like pen capping and bottle unscrewing. DexManipNet comprises 3.3K episodes of robotic manipulation and is easily extensible, facilitating further policy training for dexterous hands and enabling real-world deployments.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [ManipTrans: Efficient Dexterous Bimanual Manipulation Transfer via Residual Learning](https://arxiv.org/abs/2503.21860)
append_entries: 9
Finish: 2025-04-02 06:00:47.380561
------------------------------------------------------
Started: 2025-04-02 09:00:53.789392
Existing_entries: 983
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Soft attention is a critical mechanism powering LLMs to locate relevant parts within a given context. However, individual attention weights are determined by the similarity of only a single query and key token vector. This "single token attention" bottlenecks the amount of information used in distinguishing a relevant part from the rest of the context. To address this issue, we propose a new attention method, Multi-Token Attention (MTA), which allows LLMs to condition their attention weights on multiple query and key vectors simultaneously. This is achieved by applying convolution operations over queries, keys and heads, allowing nearby queries and keys to affect each other\'s attention weights for more precise attention. As a result, our method can locate relevant context using richer, more nuanced information that can exceed a single vector\'s capacity. Through extensive evaluations, we demonstrate that MTA achieves enhanced performance on a range of popular benchmarks. Notably, it outperforms Transformer baseline models on standard language modeling tasks, and on tasks that require searching for information within long contexts, where our method\'s ability to leverage richer information proves particularly beneficial.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Multi-Token Attention](https://arxiv.org/abs/2504.00927)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Test-time scaling has emerged as a powerful technique for enhancing the reasoning capabilities of large language models. However, its effectiveness in medical reasoning remains uncertain, as the medical domain fundamentally differs from mathematical tasks in terms of knowledge representation and decision-making processes. In this paper, we provide the first comprehensive investigation of test-time scaling for medical reasoning and present m1, a simple yet effective approach that increases a model's medical reasoning capability at inference. Our evaluation across diverse medical tasks demonstrates that test-time scaling consistently enhances medical reasoning, enabling lightweight fine-tuned models under 10B parameters to establish new state-of-the-art performance, while our 32B model rivals previous 70B-scale medical LLMs. However, we identify an optimal reasoning token budget of approximately 4K, beyond which performance may degrade due to overthinking. Budget forcing, which extends test-time computation through iterative prompts, helps models double-check answers but does not necessarily improve the overall medical QA performance and, in some cases, even introduces errors into previously correct responses. Our case-by-case analysis identifies insufficient medical knowledge as a key bottleneck that prevents further performance gains through test-time scaling. We find that increasing data scale, improving data quality, and expanding model capacity consistently enhance medical knowledge grounding, enabling continued performance improvements, particularly on challenging medical benchmarks where smaller models reach saturation. These findings underscore fundamental differences between medical and mathematical reasoning in LLMs, highlighting that enriched medical knowledge, other than increased reasoning depth alone, is essential for realizing the benefits of test-time scaling."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [m1: Unleash the Potential of Test-Time Scaling for Medical Reasoning with Large Language Models](https://arxiv.org/abs/2504.00869)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Large Language Models (LLMs) can achieve enhanced complex problem-solving through test-time computing scaling, yet this often entails longer contexts and numerous reasoning token costs. In this paper, we propose an efficient test-time scaling method that trains LLMs on code-related reasoning trajectories, facilitating their reduction of excess thinking tokens while maintaining performance. First, we create Z1-Code-Reasoning-107K, a curated dataset of simple and complex coding problems paired with their short and long solution trajectories. Second, we present a novel Shifted Thinking Window to mitigate overthinking overhead by removing context-delimiting tags (e.g., . . . ) and capping reasoning tokens. Trained with long and short trajectory data and equipped with Shifted Thinking Window, our model, Z1-7B, demonstrates the ability to adjust its reasoning level as the complexity of problems and exhibits efficient test-time scaling across different reasoning tasks that matches R1-Distill-Qwen-7B performance with about 30% of its average thinking tokens. Notably, fine-tuned with only code trajectories, Z1-7B demonstrates generalization to broader reasoning tasks (47.5% on GPQA Diamond). Our analysis of efficient reasoning elicitation also provides valuable insights for future research.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Z1: Efficient Test-time Scaling with Code](https://arxiv.org/abs/2504.00810)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'In this report we describe the development of Command A, a powerful large language model purpose-built to excel at real-world enterprise use cases. Command A is an agent-optimised and multilingual-capable model, with support for 23 languages of global business, and a novel hybrid architecture balancing efficiency with top of the range performance. It offers best-in-class Retrieval Augmented Generation (RAG) capabilities with grounding and tool use to automate sophisticated business processes. These abilities are achieved through a decentralised training approach, including self-refinement algorithms and model merging techniques. We also include results for Command R7B which shares capability and architectural similarities to Command A. Weights for both models have been released for research purposes. This technical report details our original training pipeline and presents an extensive evaluation of our models across a suite of enterprise-relevant tasks and public benchmarks, demonstrating excellent performance and efficiency.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Command A: An Enterprise-Ready Large Language Model](https://arxiv.org/abs/2504.00698)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'The reproduction of state-of-the-art multimodal LLM pre-training faces barriers at every stage of the pipeline, including high-quality data filtering, multimodal data mixture strategies, sequence packing techniques, and training frameworks. We introduce Open-Qwen2VL, a fully open-source 2B-parameter Multimodal Large Language Model pre-trained efficiently on 29M image-text pairs using only 442 A100-40G GPU hours. Our approach employs low-to-high dynamic image resolution and multimodal sequence packing to significantly enhance pre-training efficiency. The training dataset was carefully curated using both MLLM-based filtering techniques (e.g., MLM-Filter) and conventional CLIP-based filtering methods, substantially improving data quality and training efficiency. The Open-Qwen2VL pre-training is conducted on academic level 8xA100-40G GPUs at UCSB on 5B packed multimodal tokens, which is 0.36\\% of 1.4T multimodal pre-training tokens of Qwen2-VL. The final instruction-tuned Open-Qwen2VL outperforms partially-open state-of-the-art MLLM Qwen2-VL-2B on various multimodal benchmarks of MMBench, SEEDBench, MMstar, and MathVista, indicating the remarkable training efficiency of Open-Qwen2VL. We open-source all aspects of our work, including compute-efficient and data-efficient training details, data filtering methods, sequence packing scripts, pre-training data in WebDataset format, FSDP-based training codebase, and both base and instruction-tuned model checkpoints. We redefine "fully open" for multimodal LLMs as the complete release of: 1) the training codebase, 2) detailed data filtering techniques, and 3) all pre-training and supervised fine-tuning data used to develop the model.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Open-Qwen2VL: Compute-Efficient Pre-Training of Fully-Open Multimodal LLMs on Academic Resources](https://arxiv.org/abs/2504.00595)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Visual token reduction lowers inference costs caused by extensive image features in large vision-language models (LVLMs). Unlike relevant studies that prune tokens in self-attention-only LVLMs, our work uniquely addresses cross-attention-based models, which achieve superior performance. We identify that the key-value (KV) cache size for image tokens in cross-attention layers significantly exceeds that of text tokens in self-attention layers, posing a major compute bottleneck. To mitigate this issue, we exploit the sparse nature in cross-attention maps to selectively prune redundant visual features. Our Trimmed Llama effectively reduces KV cache demands without requiring additional training. By benefiting from 50%-reduced visual features, our model can reduce inference latency and memory usage while achieving benchmark parity.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Efficient LLaMA-3.2-Vision by Trimming Cross-attended Visual Features](https://arxiv.org/abs/2504.00557)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "The rapid escalation from elementary school-level to frontier problems of the difficulty for LLM benchmarks in recent years have weaved a miracle for researchers that we are only inches away from surpassing human intelligence. However, is the LLMs' remarkable reasoning ability indeed comes from true intelligence by human standards, or are they simply reciting solutions witnessed during training at an Internet level? To study this problem, we propose RoR-Bench, a novel, multi-modal benchmark for detecting LLM's recitation behavior when asked simple reasoning problems but with conditions subtly shifted, and conduct empirical analysis on our benchmark. Surprisingly, we found existing cutting-edge LLMs unanimously exhibits extremely severe recitation behavior; by changing one phrase in the condition, top models such as OpenAI-o1 and DeepSeek-R1 can suffer 60% performance loss on elementary school-level arithmetic and reasoning problems. Such findings are a wake-up call to the LLM community that compels us to re-evaluate the true intelligence level of cutting-edge LLMs."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Recitation over Reasoning: How Cutting-Edge Language Models Can Fail on Elementary School-Level Reasoning Problems?](https://arxiv.org/abs/2504.00509)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Inference-time scaling can enhance the reasoning capabilities of large language models (LLMs) on complex problems that benefit from step-by-step problem solving. Although lengthening generated scratchpads has proven effective for mathematical tasks, the broader impact of this approach on other tasks remains less clear. In this work, we investigate the benefits and limitations of scaling methods across nine state-of-the-art models and eight challenging tasks, including math and STEM reasoning, calendar planning, NP-hard problems, navigation, and spatial reasoning. We compare conventional models (e.g., GPT-4o) with models fine-tuned for inference-time scaling (e.g., o1) through evaluation protocols that involve repeated model calls, either independently or sequentially with feedback. These evaluations approximate lower and upper performance bounds and potential for future performance improvements for each model, whether through enhanced training or multi-model inference systems. Our extensive empirical analysis reveals that the advantages of inference-time scaling vary across tasks and diminish as problem complexity increases. In addition, simply using more tokens does not necessarily translate to higher accuracy in these challenging regimes. Results from multiple independent runs with conventional models using perfect verifiers show that, for some tasks, these models can achieve performance close to the average performance of today's most advanced reasoning models. However, for other tasks, a significant performance gap remains, even in very high scaling regimes. Encouragingly, all models demonstrate significant gains when inference is further scaled with perfect verifiers or strong feedback, suggesting ample potential for future improvements."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Inference-Time Scaling for Complex Tasks: Where We Stand and What Lies Ahead](https://arxiv.org/abs/2504.00294)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "We address the task of video chaptering, i.e., partitioning a long video timeline into semantic units and generating corresponding chapter titles. While relatively underexplored, automatic chaptering has the potential to enable efficient navigation and content retrieval in long-form videos. In this paper, we achieve strong chaptering performance on hour-long videos by efficiently addressing the problem in the text domain with our 'Chapter-Llama' framework. Specifically, we leverage a pretrained large language model (LLM) with large context window, and feed as input (i) speech transcripts and (ii) captions describing video frames, along with their respective timestamps. Given the inefficiency of exhaustively captioning all frames, we propose a lightweight speech-guided frame selection strategy based on speech transcript content, and experimentally demonstrate remarkable advantages. We train the LLM to output timestamps for the chapter boundaries, as well as free-form chapter titles. This simple yet powerful approach scales to processing one-hour long videos in a single forward pass. Our results demonstrate substantial improvements (e.g., 45.3 vs 26.7 F1 score) over the state of the art on the recent VidChapters-7M benchmark. To promote further research, we release our code and models at our project page."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Chapter-Llama: Efficient Chaptering in Hour-Long Videos with LLMs](https://arxiv.org/abs/2504.00072)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Inductive program synthesis, or programming by example, requires synthesizing functions from input-output examples that generalize to unseen inputs. While large language model agents have shown promise in programming tasks guided by natural language, their ability to perform inductive program synthesis is underexplored. Existing evaluation protocols rely on static sets of examples and held-out tests, offering no feedback when synthesized functions are incorrect and failing to reflect real-world scenarios such as reverse engineering. We propose CodeARC, the Code Abstraction and Reasoning Challenge, a new evaluation framework where agents interact with a hidden target function by querying it with new inputs, synthesizing candidate functions, and iteratively refining their solutions using a differential testing oracle. This interactive setting encourages agents to perform function calls and self-correction based on feedback. We construct the first large-scale benchmark for general-purpose inductive program synthesis, featuring 1114 functions. Among 18 models evaluated, o3-mini performs best with a success rate of 52.7%, highlighting the difficulty of this task. Fine-tuning LLaMA-3.1-8B-Instruct on curated synthesis traces yields up to a 31% relative performance gain. CodeARC provides a more realistic and challenging testbed for evaluating LLM-based program synthesis and inductive reasoning.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [CodeARC: Benchmarking Reasoning Capabilities of LLM Agents for Inductive Program Synthesis](https://arxiv.org/abs/2503.23145)
append_entries: 10
Finish: 2025-04-02 09:00:58.701826
------------------------------------------------------
Started: 2025-04-02 12:13:54.447888
Existing_entries: 993
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Generating human motion guided by conditions such as textual descriptions is challenging due to the need for datasets with pairs of high-quality motion and their corresponding conditions. The difficulty increases when aiming for finer control in the generation. To that end, prior works have proposed to combine several motion diffusion models pre-trained on datasets with different types of conditions, thus allowing control with multiple conditions. However, the proposed merging strategies overlook that the optimal way to combine the generation processes might depend on the particularities of each pre-trained generative model and also the specific textual descriptions. In this context, we introduce MixerMDM, the first learnable model composition technique for combining pre-trained text-conditioned human motion diffusion models. Unlike previous approaches, MixerMDM provides a dynamic mixing strategy that is trained in an adversarial fashion to learn to combine the denoising process of each model depending on the set of conditions driving the generation. By using MixerMDM to combine single- and multi-person motion diffusion models, we achieve fine-grained control on the dynamics of every person individually, and also on the overall interaction. Furthermore, we propose a new evaluation technique that, for the first time in this task, measures the interaction and individual quality by computing the alignment between the mixed generated motions and their conditions as well as the capabilities of MixerMDM to adapt the mixing throughout the denoising process depending on the motions to mix.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [MixerMDM: Learnable Composition of Human Motion Diffusion Models](https://arxiv.org/abs/2504.01019)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Visual Self-Supervised Learning (SSL) currently underperforms Contrastive Language-Image Pretraining (CLIP) in multimodal settings such as Visual Question Answering (VQA). This multimodal gap is often attributed to the semantics introduced by language supervision, even though visual SSL and CLIP models are often trained on different data. In this work, we ask the question: "Do visual self-supervised approaches lag behind CLIP due to the lack of language supervision, or differences in the training data?" We study this question by training both visual SSL and CLIP models on the same MetaCLIP data, and leveraging VQA as a diverse testbed for vision encoders. In this controlled setup, visual SSL models scale better than CLIP models in terms of data and model capacity, and visual SSL performance does not saturate even after scaling up to 7B parameters. Consequently, we observe visual SSL methods achieve CLIP-level performance on a wide range of VQA and classic vision benchmarks. These findings demonstrate that pure visual SSL can match language-supervised visual pretraining at scale, opening new opportunities for vision-centric representation learning.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Scaling Language-Free Visual Representation Learning](https://arxiv.org/abs/2504.01017)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Reconstructing sharp 3D representations from blurry multi-view images are long-standing problem in computer vision. Recent works attempt to enhance high-quality novel view synthesis from the motion blur by leveraging event-based cameras, benefiting from high dynamic range and microsecond temporal resolution. However, they often reach sub-optimal visual quality in either restoring inaccurate color or losing fine-grained details. In this paper, we present DiET-GS, a diffusion prior and event stream-assisted motion deblurring 3DGS. Our framework effectively leverages both blur-free event streams and diffusion prior in a two-stage training strategy. Specifically, we introduce the novel framework to constraint 3DGS with event double integral, achieving both accurate color and well-defined details. Additionally, we propose a simple technique to leverage diffusion prior to further enhance the edge details. Qualitative and quantitative results on both synthetic and real-world data demonstrate that our DiET-GS is capable of producing significantly better quality of novel views compared to the existing baselines. Our project page is https://diet-gs.github.io'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [DiET-GS: Diffusion Prior and Event Stream-Assisted Motion Deblurring 3D Gaussian Splatting](https://arxiv.org/abs/2503.24210)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'The rise of Large Language Models (LLMs) as evaluators offers a scalable alternative to human annotation, yet existing Supervised Fine-Tuning (SFT) for judges approaches often fall short in domains requiring complex reasoning. In this work, we investigate whether LLM judges truly benefit from enhanced reasoning capabilities. Through a detailed analysis of reasoning requirements across evaluation tasks, we reveal a negative correlation between SFT performance gains and the proportion of reasoning-demanding samples - highlighting the limitations of SFT in such scenarios. To address this, we introduce JudgeLRM, a family of judgment-oriented LLMs trained using reinforcement learning (RL) with judge-wise, outcome-driven rewards. JudgeLRM models consistently outperform both SFT-tuned and state-of-the-art reasoning models. Notably, JudgeLRM-3B surpasses GPT-4, and JudgeLRM-7B outperforms DeepSeek-R1 by 2.79% in F1 score, particularly excelling in judge tasks requiring deep reasoning.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [JudgeLRM: Large Reasoning Models as a Judge](https://arxiv.org/abs/2504.00050)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'GUI agents, powered by large foundation models, can interact with digital interfaces, enabling various applications in web automation, mobile navigation, and software testing. However, their increasing autonomy has raised critical concerns about their security, privacy, and safety. This survey examines the trustworthiness of GUI agents in five critical dimensions: security vulnerabilities, reliability in dynamic environments, transparency and explainability, ethical considerations, and evaluation methodologies. We also identify major challenges such as vulnerability to adversarial attacks, cascading failure modes in sequential decision-making, and a lack of realistic evaluation benchmarks. These issues not only hinder real-world deployment but also call for comprehensive mitigation strategies beyond task success. As GUI agents become more widespread, establishing robust safety standards and responsible development practices is essential. This survey provides a foundation for advancing trustworthy GUI agents through systematic understanding and future research.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Towards Trustworthy GUI Agents: A Survey](https://arxiv.org/abs/2503.23434)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'The rapid advancement of multi-modal language models (MLLMs) like GPT-4o has propelled the development of Omni language models, designed to process and proactively respond to continuous streams of multi-modal data. Despite their potential, evaluating their real-world interactive capabilities in streaming video contexts remains a formidable challenge. In this work, we introduce OmniMMI, a comprehensive multi-modal interaction benchmark tailored for OmniLLMs in streaming video contexts. OmniMMI encompasses over 1,121 videos and 2,290 questions, addressing two critical yet underexplored challenges in existing video benchmarks: streaming video understanding and proactive reasoning, across six distinct subtasks. Moreover, we propose a novel framework, Multi-modal Multiplexing Modeling (M4), designed to enable an inference-efficient streaming model that can see, listen while generating.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [OmniMMI: A Comprehensive Multi-modal Interaction Benchmark in Streaming Video Contexts](https://arxiv.org/abs/2503.22952)
append_entries: 6
Finish: 2025-04-02 12:13:56.826388
------------------------------------------------------
Started: 2025-04-02 15:00:53.393556
Existing_entries: 999
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We propose a unified framework that integrates object detection (OD) and visual grounding (VG) for remote sensing (RS) imagery. To support conventional OD and establish an intuitive prior for VG task, we fine-tune an open-set object detector using referring expression data, framing it as a partially supervised OD task. In the first stage, we construct a graph representation of each image, comprising object queries, class embeddings, and proposal locations. Then, our task-aware architecture processes this graph to perform the VG task. The model consists of: (i) a multi-branch network that integrates spatial, visual, and categorical features to generate task-aware proposals, and (ii) an object reasoning network that assigns probabilities across proposals, followed by a soft selection mechanism for final referring object localization. Our model demonstrates superior performance on the OPT-RSVG and DIOR-RSVG datasets, achieving significant improvements over state-of-the-art methods while retaining classical OD capabilities. The code will be available in our repository: https://github.com/rd20karim/MB-ORES.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [MB-ORES: A Multi-Branch Object Reasoner for Visual Grounding in Remote Sensing](https://arxiv.org/abs/2503.24219)
append_entries: 1
Finish: 2025-04-02 15:00:54.235507
------------------------------------------------------
Started: 2025-04-02 18:10:54.723701
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Text-to-SQL is a challenging task involving multiple reasoning-intensive subtasks, including natural language understanding, database schema comprehension, and precise SQL query formulation. Existing approaches often rely on handcrafted reasoning paths with inductive biases that can limit their overall effectiveness. Motivated by the recent success of reasoning-enhanced models such as DeepSeek R1 and OpenAI o1, which effectively leverage reward-driven self-exploration to enhance reasoning capabilities and generalization, we propose a novel set of partial rewards tailored specifically for the Text-to-SQL task. Our reward set includes schema-linking, AI feedback, n-gram similarity, and syntax check, explicitly designed to address the reward sparsity issue prevalent in reinforcement learning (RL). Leveraging group relative policy optimization (GRPO), our approach explicitly encourages large language models (LLMs) to develop intrinsic reasoning skills necessary for accurate SQL query generation. With models of different sizes, we demonstrate that RL-only training with our proposed rewards consistently achieves higher accuracy and superior generalization compared to supervised fine-tuning (SFT). Remarkably, our RL-trained 14B-parameter model significantly outperforms larger proprietary models, e.g. o3-mini by 4% and Gemini-1.5-Pro-002 by 3% on the BIRD benchmark. These highlight the efficacy of our proposed RL-training framework with partial rewards for enhancing both accuracy and reasoning capabilities in Text-to-SQL tasks.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Reasoning-SQL: Reinforcement Learning with SQL Tailored Partial Rewards for Reasoning-Enhanced Text-to-SQL](https://arxiv.org/abs/2503.23157)
append_entries: 1
Finish: 2025-04-02 18:10:55.741298
------------------------------------------------------
Started: 2025-04-02 21:00:35.976505
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-02 21:00:36.205619
------------------------------------------------------
Started: 2025-04-03 00:36:58.969750
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Numerous applications of large language models (LLMs) rely on their ability to perform step-by-step reasoning. However, the reasoning behavior of LLMs remains poorly understood, posing challenges to research, development, and safety. To address this gap, we introduce landscape of thoughts-the first visualization tool for users to inspect the reasoning paths of chain-of-thought and its derivatives on any multi-choice dataset. Specifically, we represent the states in a reasoning path as feature vectors that quantify their distances to all answer choices. These features are then visualized in two-dimensional plots using t-SNE. Qualitative and quantitative analysis with the landscape of thoughts effectively distinguishes between strong and weak models, correct and incorrect answers, as well as different reasoning tasks. It also uncovers undesirable reasoning patterns, such as low consistency and high uncertainty. Additionally, users can adapt our tool to a model that predicts the property they observe. We showcase this advantage by adapting our tool to a lightweight verifier that evaluates the correctness of reasoning paths. The code is publicly available at: https://github.com/tmlr-group/landscape-of-thoughts.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Landscape of Thoughts: Visualizing the Reasoning Process of Large Language Models](https://arxiv.org/abs/2503.22165)
append_entries: 1
Finish: 2025-04-03 00:36:59.764438
------------------------------------------------------
Started: 2025-04-03 03:24:23.591891
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-03 03:24:23.860590
------------------------------------------------------
Started: 2025-04-03 06:11:21.345685
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "We introduce PaperBench, a benchmark evaluating the ability of AI agents to replicate state-of-the-art AI research. Agents must replicate 20 ICML 2024 Spotlight and Oral papers from scratch, including understanding paper contributions, developing a codebase, and successfully executing experiments. For objective evaluation, we develop rubrics that hierarchically decompose each replication task into smaller sub-tasks with clear grading criteria. In total, PaperBench contains 8,316 individually gradable tasks. Rubrics are co-developed with the author(s) of each ICML paper for accuracy and realism. To enable scalable evaluation, we also develop an LLM-based judge to automatically grade replication attempts against rubrics, and assess our judge's performance by creating a separate benchmark for judges. We evaluate several frontier models on PaperBench, finding that the best-performing tested agent, Claude 3.5 Sonnet (New) with open-source scaffolding, achieves an average replication score of 21.0\\%. Finally, we recruit top ML PhDs to attempt a subset of PaperBench, finding that models do not yet outperform the human baseline. We https://github.com/openai/preparedness{open-source our code} to facilitate future research in understanding the AI engineering capabilities of AI agents."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [PaperBench: Evaluating AI's Ability to Replicate AI Research](https://arxiv.org/abs/2504.01848)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'While recent image-based human animation methods achieve realistic body and facial motion synthesis, critical gaps remain in fine-grained holistic controllability, multi-scale adaptability, and long-term temporal coherence, which leads to their lower expressiveness and robustness. We propose a diffusion transformer (DiT) based framework, DreamActor-M1, with hybrid guidance to overcome these limitations. For motion guidance, our hybrid control signals that integrate implicit facial representations, 3D head spheres, and 3D body skeletons achieve robust control of facial expressions and body movements, while producing expressive and identity-preserving animations. For scale adaptation, to handle various body poses and image scales ranging from portraits to full-body views, we employ a progressive training strategy using data with varying resolutions and scales. For appearance guidance, we integrate motion patterns from sequential frames with complementary visual references, ensuring long-term temporal coherence for unseen regions during complex movements. Experiments demonstrate that our method outperforms the state-of-the-art works, delivering expressive results for portraits, upper-body, and full-body generation with robust long-term consistency. Project Page: https://grisoon.github.io/DreamActor-M1/.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [DreamActor-M1: Holistic, Expressive and Robust Human Image Animation with Hybrid Guidance](https://arxiv.org/abs/2504.01724)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Vision-Language Models (VLMs) extend the capabilities of Large Language Models (LLMs) by incorporating visual information, yet they remain vulnerable to jailbreak attacks, especially when processing noisy or corrupted images. Although existing VLMs adopt security measures during training to mitigate such attacks, vulnerabilities associated with noise-augmented visual inputs are overlooked. In this work, we identify that missing noise-augmented training causes critical security gaps: many VLMs are susceptible to even simple perturbations such as Gaussian noise. To address this challenge, we propose Robust-VLGuard, a multimodal safety dataset with aligned / misaligned image-text pairs, combined with noise-augmented fine-tuning that reduces attack success rates while preserving functionality of VLM. For stronger optimization-based visual perturbation attacks, we propose DiffPure-VLM, leveraging diffusion models to convert adversarial perturbations into Gaussian-like noise, which can be defended by VLMs with noise-augmented safety fine-tuning. Experimental results demonstrate that the distribution-shifting property of diffusion model aligns well with our fine-tuned VLMs, significantly mitigating adversarial perturbations across varying intensities. The dataset and code are available at https://github.com/JarvisUSTC/DiffPure-RobustVLM.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Safeguarding Vision-Language Models: Mitigating Vulnerabilities to Gaussian Noise in Perturbation-based Attacks](https://arxiv.org/abs/2504.01308)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We present Articulated Kinematics Distillation (AKD), a framework for generating high-fidelity character animations by merging the strengths of skeleton-based animation and modern generative models. AKD uses a skeleton-based representation for rigged 3D assets, drastically reducing the Degrees of Freedom (DoFs) by focusing on joint-level control, which allows for efficient, consistent motion synthesis. Through Score Distillation Sampling (SDS) with pre-trained video diffusion models, AKD distills complex, articulated motions while maintaining structural integrity, overcoming challenges faced by 4D neural deformation fields in preserving shape consistency. This approach is naturally compatible with physics-based simulation, ensuring physically plausible interactions. Experiments show that AKD achieves superior 3D consistency and motion quality compared with existing works on text-to-4D generation. Project page: https://research.nvidia.com/labs/dir/akd/'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Articulated Kinematics Distillation from Video Diffusion Models](https://arxiv.org/abs/2504.01204)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Recent advancements in image and video synthesis have opened up new promise in generative games. One particularly intriguing application is transforming characters from anime films into interactive, playable entities. This allows players to immerse themselves in the dynamic anime world as their favorite characters for life simulation through language instructions. Such games are defined as infinite game since they eliminate predetermined boundaries and fixed gameplay rules, where players can interact with the game world through open-ended language and experience ever-evolving storylines and environments. Recently, a pioneering approach for infinite anime life simulation employs large language models (LLMs) to translate multi-turn text dialogues into language instructions for image generation. However, it neglects historical visual context, leading to inconsistent gameplay. Furthermore, it only generates static images, failing to incorporate the dynamics necessary for an engaging gaming experience. In this work, we propose AnimeGamer, which is built upon Multimodal Large Language Models (MLLMs) to generate each game state, including dynamic animation shots that depict character movements and updates to character states, as illustrated in Figure 1. We introduce novel action-aware multimodal representations to represent animation shots, which can be decoded into high-quality video clips using a video diffusion model. By taking historical animation shot representations as context and predicting subsequent representations, AnimeGamer can generate games with contextual consistency and satisfactory dynamics. Extensive evaluations using both automated metrics and human evaluations demonstrate that AnimeGamer outperforms existing methods in various aspects of the gaming experience. Codes and checkpoints are available at https://github.com/TencentARC/AnimeGamer.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [AnimeGamer: Infinite Anime Life Simulation with Next Game State Prediction](https://arxiv.org/abs/2504.01014)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Masked Image Modeling (MIM) with Vector Quantization (VQ) has achieved great success in both self-supervised pre-training and image generation. However, most existing methods struggle to address the trade-off in shared latent space for generation quality vs. representation learning and efficiency. To push the limits of this paradigm, we propose MergeVQ, which incorporates token merging techniques into VQ-based generative models to bridge the gap between image generation and visual representation learning in a unified architecture. During pre-training, MergeVQ decouples top-k semantics from latent space with the token merge module after self-attention blocks in the encoder for subsequent Look-up Free Quantization (LFQ) and global alignment and recovers their fine-grained details through cross-attention in the decoder for reconstruction. As for the second-stage generation, we introduce MergeAR, which performs KV Cache compression for efficient raster-order prediction. Extensive experiments on ImageNet verify that MergeVQ as an AR generative model achieves competitive performance in both visual representation learning and image generation tasks while maintaining favorable token efficiency and inference speed. The code and model will be available at https://apexgen-x.github.io/MergeVQ.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [MergeVQ: A Unified Framework for Visual Generation and Representation with Disentangled Token Merging and Quantization](https://arxiv.org/abs/2504.00999)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Increasing attention has been placed on improving the reasoning capacities of multi-modal large language models (MLLMs). As the cornerstone for AI agents that function in the physical realm, video-based visual-spatial intelligence (VSI) emerges as one of the most pivotal reasoning capabilities of MLLMs. This work conducts a first, in-depth study on improving the visual-spatial reasoning of MLLMs via R1-Zero-like training. Technically, we first identify that the visual-spatial reasoning capacities of small- to medium-sized Qwen2-VL models cannot be activated via Chain of Thought (CoT) prompts. We then incorporate GRPO training for improved visual-spatial reasoning, using the carefully curated VSI-100k dataset, following DeepSeek-R1-Zero. During the investigation, we identify the necessity to keep the KL penalty (even with a small value) in GRPO. With just 120 GPU hours, our vsGRPO-2B model, fine-tuned from Qwen2-VL-2B, can outperform the base model by 12.1% and surpass GPT-4o. Moreover, our vsGRPO-7B model, fine-tuned from Qwen2-VL-7B, achieves performance comparable to that of the best open-source model LLaVA-NeXT-Video-72B. Additionally, we compare vsGRPO to supervised fine-tuning and direct preference optimization baselines and observe strong performance superiority. The code and dataset will be available soon.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Improved Visual-Spatial Reasoning via R1-Zero-Like Training](https://arxiv.org/abs/2504.00883)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Academic writing requires both coherent text generation and precise citation of relevant literature. Although recent Retrieval-Augmented Generation (RAG) systems have significantly improved factual accuracy in general-purpose text generation, their capacity to adequately support professional academic writing remains limited. In this work, we introduce ScholarCopilot, a unified framework designed to enhance existing large language models for generating professional academic articles with accurate and contextually relevant citations. ScholarCopilot dynamically determines when to retrieve scholarly references by generating a retrieval token [RET], and then utilizes its representation to look up relevant citations from a database. The retrieved references are fed into the model to augment the generation process. We jointly optimize both the generation and citation tasks within a single framework to increase efficiency. Trained on 500K papers from arXiv, our model achieves a top-1 retrieval accuracy of 40.1% on our evaluation dataset, outperforming baselines such as E5-Mistral-7B-Instruct (15.0%) and BM25 (9.8%). On a dataset of 1,000 academic writing samples, ScholarCopilot scores 16.2/25 in generation quality (measured across relevance, coherence, academic rigor, completeness, and innovation), surpassing models with 10x more parameters such as Qwen-2.5-72B-Instruct (15.8/25). Human studies also confirm ScholarCopilot's superior performance in citation recall, writing efficiency, and overall user experience, confirming the effectiveness of our approach."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [ScholarCopilot: Training Large Language Models for Academic Writing with Accurate Citations](https://arxiv.org/abs/2504.00824)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Vision network designs, including Convolutional Neural Networks and Vision Transformers, have significantly advanced the field of computer vision. Yet, their complex computations pose challenges for practical deployments, particularly in real-time applications. To tackle this issue, researchers have explored various lightweight and efficient network designs. However, existing lightweight models predominantly leverage self-attention mechanisms and convolutions for token mixing. This dependence brings limitations in effectiveness and efficiency in the perception and aggregation processes of lightweight networks, hindering the balance between performance and efficiency under limited computational budgets. In this paper, we draw inspiration from the dynamic heteroscale vision ability inherent in the efficient human vision system and propose a ``See Large, Focus Small'' strategy for lightweight vision network design. We introduce LS (Large-Small) convolution, which combines large-kernel perception and small-kernel aggregation. It can efficiently capture a wide range of perceptual information and achieve precise feature aggregation for dynamic and complex visual representations, thus enabling proficient processing of visual information. Based on LS convolution, we present LSNet, a new family of lightweight models. Extensive experiments demonstrate that LSNet achieves superior performance and efficiency over existing lightweight networks in various vision tasks. Codes and models are available at https://github.com/jameslahm/lsnet."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [LSNet: See Large, Focus Small](https://arxiv.org/abs/2503.23135)
append_entries: 9
Finish: 2025-04-03 06:11:25.743524
------------------------------------------------------
Started: 2025-04-03 09:00:49.032919
Existing_entries: 1009
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Recovering 3D scenes from sparse views is a challenging task due to its inherent ill-posed problem. Conventional methods have developed specialized solutions (e.g., geometry regularization or feed-forward deterministic model) to mitigate the issue. However, they still suffer from performance degradation by minimal overlap across input views with insufficient visual information. Fortunately, recent video generative models show promise in addressing this challenge as they are capable of generating video clips with plausible 3D structures. Powered by large pretrained video diffusion models, some pioneering research start to explore the potential of video generative prior and create 3D scenes from sparse views. Despite impressive improvements, they are limited by slow inference time and the lack of 3D constraint, leading to inefficiencies and reconstruction artifacts that do not align with real-world geometry structure. In this paper, we propose VideoScene to distill the video diffusion model to generate 3D scenes in one step, aiming to build an efficient and effective tool to bridge the gap from video to 3D. Specifically, we design a 3D-aware leap flow distillation strategy to leap over time-consuming redundant information and train a dynamic denoising policy network to adaptively determine the optimal leap timestep during inference. Extensive experiments demonstrate that our VideoScene achieves faster and superior 3D scene generation results than previous video diffusion models, highlighting its potential as an efficient tool for future video to 3D applications. Project Page: https://hanyang-21.github.io/VideoScene'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [VideoScene: Distilling Video Diffusion Model to Generate 3D Scenes in One Step](https://arxiv.org/abs/2504.01956)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We present ILLUME+ that leverages dual visual tokenization and a diffusion decoder to improve both deep semantic understanding and high-fidelity image generation. Existing unified models have struggled to simultaneously handle the three fundamental capabilities in a unified model: understanding, generation, and editing. Models like Chameleon and EMU3 utilize VQGAN for image discretization, due to the lack of deep semantic interaction, they lag behind specialist models like LLaVA in visual understanding tasks. To mitigate this, LaViT and ILLUME employ semantic encoders for tokenization, but they struggle with image editing due to poor texture preservation. Meanwhile, Janus series decouples the input and output image representation, limiting their abilities to seamlessly handle interleaved image-text understanding and generation. In contrast, ILLUME+ introduces a unified dual visual tokenizer, DualViTok, which preserves both fine-grained textures and text-aligned semantics while enabling a coarse-to-fine image representation strategy for multimodal understanding and generation. Additionally, we employ a diffusion model as the image detokenizer for enhanced generation quality and efficient super-resolution. ILLUME+ follows a continuous-input, discrete-output scheme within the unified MLLM and adopts a progressive training procedure that supports dynamic resolution across the vision tokenizer, MLLM, and diffusion decoder. This design allows for flexible and efficient context-aware image editing and generation across diverse tasks. ILLUME+ (3B) exhibits competitive performance against existing unified MLLMs and specialized models across multimodal understanding, generation, and editing benchmarks. With its strong performance, ILLUME+ provides a scalable and versatile foundation for future multimodal applications. Project Page: https://illume-unified-mllm.github.io/.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [ILLUME+: Illuminating Unified MLLM with Dual Visual Tokenization and Diffusion Refinement](https://arxiv.org/abs/2504.01934)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "DeepSeek-R1-Zero has shown that reinforcement learning (RL) at scale can directly enhance the reasoning capabilities of LLMs without supervised fine-tuning. In this work, we critically examine R1-Zero-like training by analyzing its two core components: base models and RL. We investigate a wide range of base models, including DeepSeek-V3-Base, to understand how pretraining characteristics influence RL performance. Our analysis reveals that DeepSeek-V3-Base already exhibit ''Aha moment'', while Qwen2.5 base models demonstrate strong reasoning capabilities even without prompt templates, suggesting potential pretraining biases. Additionally, we identify an optimization bias in Group Relative Policy Optimization (GRPO), which artificially increases response length (especially for incorrect outputs) during training. To address this, we introduce Dr. GRPO, an unbiased optimization method that improves token efficiency while maintaining reasoning performance. Leveraging these insights, we present a minimalist R1-Zero recipe that achieves 43.3% accuracy on AIME 2024 with a 7B base model, establishing a new state-of-the-art. Our code is available at https://github.com/sail-sg/understand-r1-zero."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Understanding R1-Zero-Like Training: A Critical Perspective](https://arxiv.org/abs/2503.20783)
append_entries: 3
Finish: 2025-04-03 09:00:50.823972
------------------------------------------------------
Started: 2025-04-03 12:13:53.426444
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Large language models demonstrate remarkable reasoning capabilities but often produce unreliable or incorrect responses. Existing verification methods are typically model-specific or domain-restricted, requiring significant computational resources and lacking scalability across diverse reasoning tasks. To address these limitations, we propose VerifiAgent, a unified verification agent that integrates two levels of verification: meta-verification, which assesses completeness and consistency in model responses, and tool-based adaptive verification, where VerifiAgent autonomously selects appropriate verification tools based on the reasoning type, including mathematical, logical, or commonsense reasoning. This adaptive approach ensures both efficiency and robustness across different verification scenarios. Experimental results show that VerifiAgent outperforms baseline verification methods (e.g., deductive verifier, backward verifier) among all reasoning tasks. Additionally, it can further enhance reasoning accuracy by leveraging feedback from verification results. VerifiAgent can also be effectively applied to inference scaling, achieving better results with fewer generated samples and costs compared to existing process reward models in the mathematical reasoning domain. Code is available at https://github.com/Jiuzhouh/VerifiAgent'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [VerifiAgent: a Unified Verification Agent in Language Model Reasoning](https://arxiv.org/abs/2504.00406)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Prior research on out-of-distribution detection (OoDD) has primarily focused on single-modality models. Recently, with the advent of large-scale pretrained vision-language models such as CLIP, OoDD methods utilizing such multi-modal representations through zero-shot and prompt learning strategies have emerged. However, these methods typically involve either freezing the pretrained weights or only partially tuning them, which can be suboptimal for downstream datasets. In this paper, we highlight that multi-modal fine-tuning (MMFT) can achieve notable OoDD performance. Despite some recent works demonstrating the impact of fine-tuning methods for OoDD, there remains significant potential for performance improvement. We investigate the limitation of na\\"ive fine-tuning methods, examining why they fail to fully leverage the pretrained knowledge. Our empirical analysis suggests that this issue could stem from the modality gap within in-distribution (ID) embeddings. To address this, we propose a training objective that enhances cross-modal alignment by regularizing the distances between image and text embeddings of ID data. This adjustment helps in better utilizing pretrained textual information by aligning similar semantics from different modalities (i.e., text and image) more closely in the hyperspherical representation space. We theoretically demonstrate that the proposed regularization corresponds to the maximum likelihood estimation of an energy-based model on a hypersphere. Utilizing ImageNet-1k OoD benchmark datasets, we show that our method, combined with post-hoc OoDD approaches leveraging pretrained knowledge (e.g., NegLabel), significantly outperforms existing methods, achieving state-of-the-art OoDD performance and leading ID accuracy.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Enhanced OoD Detection through Cross-Modal Alignment of Multi-Modal Representations](https://arxiv.org/abs/2503.18817)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'The generation of high-quality human images through text-to-image (T2I) methods is a significant yet challenging task. Distinct from general image generation, human image synthesis must satisfy stringent criteria related to human pose, anatomy, and alignment with textual prompts, making it particularly difficult to achieve realistic results. Recent advancements in T2I generation based on diffusion models have shown promise, yet challenges remain in meeting human-specific preferences. In this paper, we introduce a novel approach tailored specifically for human image generation utilizing Direct Preference Optimization (DPO). Specifically, we introduce an efficient method for constructing a specialized DPO dataset for training human image generation models without the need for costly human feedback. We also propose a modified loss function that enhances the DPO training process by minimizing artifacts and improving image fidelity. Our method demonstrates its versatility and effectiveness in generating human images, including personalized text-to-image generation. Through comprehensive evaluations, we show that our approach significantly advances the state of human image generation, achieving superior results in terms of natural anatomies, poses, and text-image alignment.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Boost Your Own Human Image Generation Model via Direct Preference Optimization with AI Feedback](https://arxiv.org/abs/2405.20216)
append_entries: 3
Finish: 2025-04-03 12:13:54.941772
------------------------------------------------------
Started: 2025-04-03 15:00:42.813619
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Vision-language models (VLMs) are prone to object hallucinations, where they erroneously indicate the presenceof certain objects in an image. Existing benchmarks quantify hallucinations using relatively small, labeled datasets. However, this approach is i) insufficient to assess hallucinations that arise in open-world settings, where VLMs are widely used, and ii) inadequate for detecting systematic errors in VLMs. We propose DASH (Detection and Assessment of Systematic Hallucinations), an automatic, large-scale pipeline designed to identify systematic hallucinations of VLMs on real-world images in an open-world setting. A key component is DASH-OPT for image-based retrieval, where we optimize over the ''natural image manifold'' to generate images that mislead the VLM. The output of DASH consists of clusters of real and semantically similar images for which the VLM hallucinates an object. We apply DASH to PaliGemma and two LLaVA-NeXT models across 380 object classes and, in total, find more than 19k clusters with 950k images. We study the transfer of the identified systematic hallucinations to other VLMs and show that fine-tuning PaliGemma with the model-specific images obtained with DASH mitigates object hallucinations. Code and data are available at https://YanNeu.github.io/DASH."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [DASH: Detection and Assessment of Systematic Hallucinations of VLMs](https://arxiv.org/abs/2503.23573)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Video diffusion models (VDMs) have advanced significantly in recent years, enabling the generation of highly realistic videos and drawing the attention of the community in their potential as world simulators. However, despite their capabilities, VDMs often fail to produce physically plausible videos due to an inherent lack of understanding of physics, resulting in incorrect dynamics and event sequences. To address this limitation, we propose a novel two-stage image-to-video generation framework that explicitly incorporates physics. In the first stage, we employ a Vision Language Model (VLM) as a coarse-grained motion planner, integrating chain-of-thought and physics-aware reasoning to predict a rough motion trajectories/changes that approximate real-world physical dynamics while ensuring the inter-frame consistency. In the second stage, we use the predicted motion trajectories/changes to guide the video generation of a VDM. As the predicted motion trajectories/changes are rough, noise is added during inference to provide freedom to the VDM in generating motion with more fine details. Extensive experimental results demonstrate that our framework can produce physically plausible motion, and comparative evaluations highlight the notable superiority of our approach over existing methods. More video results are available on our Project Page: https://madaoer.github.io/projects/physically_plausible_video_generation.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Towards Physically Plausible Video Generation via VLM Planning](https://arxiv.org/abs/2503.23368)
append_entries: 2
Finish: 2025-04-03 15:00:44.226454
------------------------------------------------------
Started: 2025-04-03 18:00:54.456640
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Large language models (LLMs) have the potential to transform medicine, but real-world clinical scenarios contain extraneous information that can hinder performance. The rise of assistive technologies like ambient dictation, which automatically generates draft notes from live patient encounters, has the potential to introduce additional noise making it crucial to assess the ability of LLM's to filter relevant data. To investigate this, we developed MedDistractQA, a benchmark using USMLE-style questions embedded with simulated real-world distractions. Our findings show that distracting statements (polysemous words with clinical meanings used in a non-clinical context or references to unrelated health conditions) can reduce LLM accuracy by up to 17.9%. Commonly proposed solutions to improve model performance such as retrieval-augmented generation (RAG) and medical fine-tuning did not change this effect and in some cases introduced their own confounders and further degraded performance. Our findings suggest that LLMs natively lack the logical mechanisms necessary to distinguish relevant from irrelevant clinical information, posing challenges for real-world applications. MedDistractQA and our results highlights the need for robust mitigation strategies to enhance LLM resilience to extraneous information."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Medical large language models are easily distracted](https://arxiv.org/abs/2504.01201)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'While recent zero-shot text-to-speech (TTS) models have significantly improved speech quality and expressiveness, mainstream systems still suffer from issues related to speech-text alignment modeling: 1) models without explicit speech-text alignment modeling exhibit less robustness, especially for hard sentences in practical applications; 2) predefined alignment-based models suffer from naturalness constraints of forced alignments. This paper introduces MegaTTS 3, a TTS system featuring an innovative sparse alignment algorithm that guides the latent diffusion transformer (DiT). Specifically, we provide sparse alignment boundaries to MegaTTS 3 to reduce the difficulty of alignment without limiting the search space, thereby achieving high naturalness. Moreover, we employ a multi-condition classifier-free guidance strategy for accent intensity adjustment and adopt the piecewise rectified flow technique to accelerate the generation process. Experiments demonstrate that MegaTTS 3 achieves state-of-the-art zero-shot TTS speech quality and supports highly flexible control over accent intensity. Notably, our system can generate high-quality one-minute speech with only 8 sampling steps. Audio samples are available at https://sditdemo.github.io/sditdemo/.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [MegaTTS 3: Sparse Alignment Enhanced Latent Diffusion Transformer for Zero-Shot Speech Synthesis](https://arxiv.org/abs/2502.18924)
append_entries: 2
Finish: 2025-04-03 18:00:55.782784
------------------------------------------------------
Started: 2025-04-03 21:00:55.818798
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "We present a target-aware video diffusion model that generates videos from an input image in which an actor interacts with a specified target while performing a desired action. The target is defined by a segmentation mask and the desired action is described via a text prompt. Unlike existing controllable image-to-video diffusion models that often rely on dense structural or motion cues to guide the actor's movements toward the target, our target-aware model requires only a simple mask to indicate the target, leveraging the generalization capabilities of pretrained models to produce plausible actions. This makes our method particularly effective for human-object interaction (HOI) scenarios, where providing precise action guidance is challenging, and further enables the use of video diffusion models for high-level action planning in applications such as robotics. We build our target-aware model by extending a baseline model to incorporate the target mask as an additional input. To enforce target awareness, we introduce a special token that encodes the target's spatial information within the text prompt. We then fine-tune the model with our curated dataset using a novel cross-attention loss that aligns the cross-attention maps associated with this token with the input target mask. To further improve performance, we selectively apply this loss to the most semantically relevant transformer blocks and attention regions. Experimental results show that our target-aware model outperforms existing solutions in generating videos where actors interact accurately with the specified targets. We further demonstrate its efficacy in two downstream applications: video content creation and zero-shot 3D HOI motion synthesis."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Target-Aware Video Diffusion Models](https://arxiv.org/abs/2503.18950)
append_entries: 1
Finish: 2025-04-03 21:00:56.576683
------------------------------------------------------
Started: 2025-04-04 00:37:03.309058
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'State Space Models (SSMs) are emerging as a compelling alternative to Transformers because of their consistent memory usage and high performance. Despite this, scaling up SSMs on cloud services or limited-resource devices is challenging due to their storage requirements and computational power. To overcome this, quantizing SSMs with low bit-width data formats can reduce model size and benefit from hardware acceleration. As SSMs are prone to quantization-induced errors, recent efforts have focused on optimizing a particular model or bit-width for efficiency without sacrificing performance. However, distinct bit-width configurations are essential for different scenarios, like W4A8 for boosting large-batch decoding speed, and W4A16 for enhancing generation speed in short prompt applications for a single user. To this end, we present Quamba2, compatible with W8A8, W4A8, and W4A16 for both Mamba1 and Mamba2 backbones, addressing the growing demand for SSM deployment on various platforms. Based on the channel order preserving and activation persistence of SSMs, we propose an offline approach to quantize inputs of a linear recurrence in 8-bit by sorting and clustering for input x, combined with a per-state-group quantization for input-dependent parameters B and C. To ensure compute-invariance in the SSM output, we rearrange weights offline according to the clustering sequence. The experiments show that Quamba2-8B outperforms several state-of-the-art SSM quantization methods and delivers 1.3times and 3times speed-ups in the pre-filling and generation stages, respectively, while offering 4times memory reduction with only a 1.6% average accuracy drop. The evaluation on MMLU shows the generalizability and robustness of our framework. The code and quantized models will be released at: https://github.com/enyac-group/Quamba.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Quamba2: A Robust and Scalable Post-training Quantization Framework for Selective State Space Models](https://arxiv.org/abs/2503.22879)
append_entries: 1
Finish: 2025-04-04 00:37:03.974087
------------------------------------------------------
Started: 2025-04-04 03:23:44.328153
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Various layer-skipping methods have been proposed to accelerate token generation in large language models (LLMs). However, they have overlooked a fundamental question: How do computational demands vary across the generation of different tokens? In this work, we introduce FlexiDepth, a method that dynamically adjusts the number of Transformer layers used in text generation. By incorporating a plug-in router and adapter, FlexiDepth enables adaptive layer-skipping in LLMs without modifying their original parameters. Introducing FlexiDepth to Llama-3-8B model achieves layer skipping of 8 layers out of 32, and meanwhile maintains the full 100\\% benchmark performance. Experimental results with FlexiDepth demonstrate that computational demands in LLMs significantly vary based on token type. Specifically, generating repetitive tokens or fixed phrases requires fewer layers, whereas producing tokens involving computation or high uncertainty requires more layers. Interestingly, this adaptive allocation pattern aligns with human intuition. To advance research in this area, we open sourced FlexiDepth and a dataset documenting FlexiDepth's layer allocation patterns for future exploration."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Adaptive Layer-skipping in Pre-trained LLMs](https://arxiv.org/abs/2503.23798)
append_entries: 1
Finish: 2025-04-04 03:23:45.015570
------------------------------------------------------
Started: 2025-04-04 06:11:15.446038
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Large Multi-modality Models (LMMs) have made significant progress in visual understanding and generation, but they still face challenges in General Visual Editing, particularly in following complex instructions, preserving appearance consistency, and supporting flexible input formats. To address this gap, we introduce RISEBench, the first benchmark for evaluating Reasoning-Informed viSual Editing (RISE). RISEBench focuses on four key reasoning types: Temporal, Causal, Spatial, and Logical Reasoning. We curate high-quality test cases for each category and propose an evaluation framework that assesses Instruction Reasoning, Appearance Consistency, and Visual Plausibility with both human judges and an LMM-as-a-judge approach. Our experiments reveal that while GPT-4o-Native significantly outperforms other open-source and proprietary models, even this state-of-the-art system struggles with logical reasoning tasks, highlighting an area that remains underexplored. As an initial effort, RISEBench aims to provide foundational insights into reasoning-aware visual editing and to catalyze future research. Though still in its early stages, we are committed to continuously expanding and refining the benchmark to support more comprehensive, reliable, and scalable evaluations of next-generation multimodal systems. Our code and data will be released at https://github.com/PhoenixZ810/RISEBench.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Envisioning Beyond the Pixels: Benchmarking Reasoning-Informed Visual Editing](https://arxiv.org/abs/2504.02826)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "The recent breakthroughs in OpenAI's GPT4o model have demonstrated surprisingly good capabilities in image generation and editing, resulting in significant excitement in the community. This technical report presents the first-look evaluation benchmark (named GPT-ImgEval), quantitatively and qualitatively diagnosing GPT-4o's performance across three critical dimensions: (1) generation quality, (2) editing proficiency, and (3) world knowledge-informed semantic synthesis. Across all three tasks, GPT-4o demonstrates strong performance, significantly surpassing existing methods in both image generation control and output quality, while also showcasing exceptional knowledge reasoning capabilities. Furthermore, based on the GPT-4o's generated data, we propose a classification-model-based approach to investigate the underlying architecture of GPT-4o, where our empirical results suggest the model consists of an auto-regressive (AR) combined with a diffusion-based head for image decoding, rather than the VAR-like architectures. We also provide a complete speculation on GPT-4o's overall architecture. In addition, we conduct a series of analyses to identify and visualize GPT-4o's specific limitations and the synthetic artifacts commonly observed in its image generation. We also present a comparative study of multi-round image editing between GPT-4o and Gemini 2.0 Flash, and discuss the safety implications of GPT-4o's outputs, particularly their detectability by existing image forensic models. We hope that our work can offer valuable insight and provide a reliable benchmark to guide future research, foster reproducibility, and accelerate innovation in the field of image generation and beyond. The codes and datasets used for evaluating GPT-4o can be found at https://github.com/PicoTrex/GPT-ImgEval."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [GPT-ImgEval: A Comprehensive Benchmark for Diagnosing GPT4o in Image Generation](https://arxiv.org/abs/2504.02782)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Reinforcement learning (RL) has recently shown strong potential in improving the reasoning capabilities of large language models and is now being actively extended to vision-language models (VLMs). However, existing RL applications in VLMs often rely on heavily engineered frameworks that hinder reproducibility and accessibility, while lacking standardized evaluation protocols, making it difficult to compare results or interpret training dynamics. This work introduces a transparent, from-scratch framework for RL in VLMs, offering a minimal yet functional four-step pipeline validated across multiple models and datasets. In addition, a standardized evaluation scheme is proposed to assess training dynamics and reflective behaviors. Extensive experiments on visual reasoning tasks uncover key empirical findings: response length is sensitive to random seeds, reflection correlates with output length, and RL consistently outperforms supervised fine-tuning (SFT) in generalization, even with high-quality data. These findings, together with the proposed framework, aim to establish a reproducible baseline and support broader engagement in RL-based VLM research.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Rethinking RL Scaling for Vision Language Models: A Transparent, From-Scratch Framework and Comprehensive Evaluation Scheme](https://arxiv.org/abs/2504.02587)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Talking head synthesis is vital for virtual avatars and human-computer interaction. However, most existing methods are typically limited to accepting control from a single primary modality, restricting their practical utility. To this end, we introduce ACTalker, an end-to-end video diffusion framework that supports both multi-signals control and single-signal control for talking head video generation. For multiple control, we design a parallel mamba structure with multiple branches, each utilizing a separate driving signal to control specific facial regions. A gate mechanism is applied across all branches, providing flexible control over video generation. To ensure natural coordination of the controlled video both temporally and spatially, we employ the mamba structure, which enables driving signals to manipulate feature tokens across both dimensions in each branch. Additionally, we introduce a mask-drop strategy that allows each driving signal to independently control its corresponding facial region within the mamba structure, preventing control conflicts. Experimental results demonstrate that our method produces natural-looking facial videos driven by diverse signals and that the mamba layer seamlessly integrates multiple driving modalities without conflict.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Audio-visual Controlled Video Diffusion with Masked Selective State Spaces Modeling for Natural Talking Head Generation](https://arxiv.org/abs/2504.02542)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'This paper presents SkyReels-A2, a controllable video generation framework capable of assembling arbitrary visual elements (e.g., characters, objects, backgrounds) into synthesized videos based on textual prompts while maintaining strict consistency with reference images for each element. We term this task elements-to-video (E2V), whose primary challenges lie in preserving the fidelity of each reference element, ensuring coherent composition of the scene, and achieving natural outputs. To address these, we first design a comprehensive data pipeline to construct prompt-reference-video triplets for model training. Next, we propose a novel image-text joint embedding model to inject multi-element representations into the generative process, balancing element-specific consistency with global coherence and text alignment. We also optimize the inference pipeline for both speed and output stability. Moreover, we introduce a carefully curated benchmark for systematic evaluation, i.e, A2 Bench. Experiments demonstrate that our framework can generate diverse, high-quality videos with precise element control. SkyReels-A2 is the first open-source commercial grade model for the generation of E2V, performing favorably against advanced closed-source commercial models. We anticipate SkyReels-A2 will advance creative applications such as drama and virtual e-commerce, pushing the boundaries of controllable video generation.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [SkyReels-A2: Compose Anything in Video Diffusion Transformers](https://arxiv.org/abs/2504.02436)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Model selection is a critical step in time series forecasting, traditionally requiring extensive performance evaluations across various datasets. Meta-learning approaches aim to automate this process, but they typically depend on pre-constructed performance matrices, which are costly to build. In this work, we propose to leverage Large Language Models (LLMs) as a lightweight alternative for model selection. Our method eliminates the need for explicit performance matrices by utilizing the inherent knowledge and reasoning capabilities of LLMs. Through extensive experiments with LLaMA, GPT and Gemini, we demonstrate that our approach outperforms traditional meta-learning techniques and heuristic baselines, while significantly reducing computational overhead. These findings underscore the potential of LLMs in efficient model selection for time series forecasting.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Efficient Model Selection for Time Series Forecasting via LLMs](https://arxiv.org/abs/2504.02119)
append_entries: 6
Finish: 2025-04-04 06:11:18.943614
------------------------------------------------------
Started: 2025-04-04 09:00:48.643065
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Training large language models (LLMs) presents numerous challenges, including gradient instability and loss spikes. These phenomena can lead to catastrophic divergence, requiring costly checkpoint restoration and data batch skipping. Traditional gradient clipping techniques, such as constant or norm-based methods, fail to address these issues effectively due to their reliance on fixed thresholds or heuristics, leading to inefficient learning and requiring frequent manual intervention. In this work, we propose ZClip, an adaptive gradient clipping algorithm that dynamically adjusts the clipping threshold based on statistical properties of gradient norms over time. Unlike prior reactive strategies, ZClip proactively adapts to training dynamics without making any prior assumptions on the scale and the temporal evolution of gradient norms. At its core, it leverages z-score-based anomaly detection to identify and mitigate large gradient spikes, preventing malignant loss spikes while not interfering with convergence otherwise. Our code is available at: https://github.com/bluorion-com/ZClip.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [ZClip: Adaptive Spike Mitigation for LLM Pre-Training](https://arxiv.org/abs/2504.02507)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Existing Speech Language Model (SLM) scaling analysis paints a bleak picture. They predict that SLMs require much more compute and data compared to text, leading some to question the feasibility of training high-quality SLMs. However, modern SLMs are often initialised from pre-trained TextLMs using speech-text interleaving to allow knowledge transfer. This raises the question - Do interleaved SLMs scale more efficiently than textless-SLMs? In this paper we answer a resounding, yes! We conduct scaling analysis of interleaved SLMs by training several dozen and analysing the scaling trends. We see that under this setup SLMs scale more efficiently with compute. Additionally, our results indicate that the scaling-dynamics are significantly different than textless-SLMs, suggesting one should allocate notably more of the compute budget for increasing model size over training tokens. We also study the role of synthetic data and TextLM model families in unlocking this potential. Results suggest, that our scaled up model achieves comparable performance with leading models on speech semantic metrics while using less compute and data than other approaches. We open source models, samples, and data - https://pages.cs.huji.ac.il/adiyoss-lab/sims.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Scaling Analysis of Interleaved Speech-Text Language Models](https://arxiv.org/abs/2504.02398)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Learning to generate neural network parameters conditioned on task descriptions and architecture specifications is pivotal for advancing model adaptability and transfer learning. Existing methods especially those based on diffusion models suffer from limited scalability to large architectures, rigidity in handling varying network depths, and disjointed parameter generation that undermines inter-layer coherence. In this work, we propose IGPG (Instruction Guided Parameter Generation), an autoregressive framework that unifies parameter synthesis across diverse tasks and architectures. IGPG leverages a VQ-VAE and an autoregressive model to generate neural network parameters, conditioned on task instructions, dataset, and architecture details. By autoregressively generating neural network weights' tokens, IGPG ensures inter-layer coherence and enables efficient adaptation across models and datasets. Operating at the token level, IGPG effectively captures complex parameter distributions aggregated from a broad spectrum of pretrained models. Extensive experiments on multiple vision datasets demonstrate that IGPG consolidates diverse pretrained models into a single, flexible generative framework. The synthesized parameters achieve competitive or superior performance relative to state-of-the-art methods, especially in terms of scalability and efficiency when applied to large architectures. These results underscore ICPG potential as a powerful tool for pretrained weight retrieval, model selection, and rapid task-specific fine-tuning."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Instruction-Guided Autoregressive Neural Network Parameter Generation](https://arxiv.org/abs/2504.02012)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Recent advancements in Large Language Models (LLMs) have shown that it is promising to utilize Process Reward Models (PRMs) as verifiers to enhance the performance of LLMs. However, current PRMs face three key challenges: (1) limited process supervision and generalization capabilities, (2) dependence on scalar value prediction without leveraging the generative abilities of LLMs, and (3) inability to scale the test-time compute of PRMs. In this work, we introduce GenPRM, a generative process reward model that performs explicit Chain-of-Thought (CoT) reasoning with code verification before providing judgment for each reasoning step. To obtain high-quality process supervision labels and rationale data, we propose Relative Progress Estimation (RPE) and a rationale synthesis framework that incorporates code verification. Experimental results on ProcessBench and several mathematical reasoning tasks show that GenPRM significantly outperforms prior PRMs with only 23K training data from MATH dataset. Through test-time scaling, a 1.5B GenPRM outperforms GPT-4o, and a 7B GenPRM surpasses Qwen2.5-Math-PRM-72B on ProcessBench. Additionally, GenPRM demonstrates strong abilities to serve as a critic model for policy model refinement. This work establishes a new paradigm for process supervision that bridges the gap between PRMs and critic models in LLMs. Our code, model, and data will be available in https://ryanliu112.github.io/GenPRM.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [GenPRM: Scaling Test-Time Compute of Process Reward Models via Generative Reasoning](https://arxiv.org/abs/2504.00891)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Multimodal Large Language Models (MLLMs) suffer from high computational costs due to their massive size and the large number of visual tokens. In this paper, we investigate layer-wise redundancy in MLLMs by introducing a novel metric, Layer Contribution (LC), which quantifies the impact of a layer's transformations on visual and text tokens, respectively. The calculation of LC involves measuring the divergence in model output that results from removing the layer's transformations on the specified tokens. Our pilot experiment reveals that many layers of MLLMs exhibit minimal contribution during the processing of visual tokens. Motivated by this observation, we propose ShortV, a training-free method that leverages LC to identify ineffective layers, and freezes visual token updates in these layers. Experiments show that ShortV can freeze visual token in approximately 60\\% of the MLLM layers, thereby dramatically reducing computational costs related to updating visual tokens. For example, it achieves a 50\\% reduction in FLOPs on LLaVA-NeXT-13B while maintaining superior performance. The code will be publicly available at https://github.com/icip-cas/ShortV"}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [ShortV: Efficient Multimodal Large Language Models by Freezing Visual Tokens in Ineffective Layers](https://arxiv.org/abs/2504.00502)
append_entries: 5
Finish: 2025-04-04 09:00:50.801963
------------------------------------------------------
Started: 2025-04-04 12:13:38.827335
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Sparse Autoencoders (SAEs) have recently been shown to enhance interpretability and steerability in Large Language Models (LLMs). In this work, we extend the application of SAEs to Vision-Language Models (VLMs), such as CLIP, and introduce a comprehensive framework for evaluating monosemanticity in vision representations. Our experimental results reveal that SAEs trained on VLMs significantly enhance the monosemanticity of individual neurons while also exhibiting hierarchical representations that align well with expert-defined structures (e.g., iNaturalist taxonomy). Most notably, we demonstrate that applying SAEs to intervene on a CLIP vision encoder, directly steer output from multimodal LLMs (e.g., LLaVA) without any modifications to the underlying model. These findings emphasize the practicality and efficacy of SAEs as an unsupervised approach for enhancing both the interpretability and control of VLMs.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Sparse Autoencoders Learn Monosemantic Features in Vision-Language Models](https://arxiv.org/abs/2504.02821)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "We present the first mechanistic evidence that model-free reinforcement learning agents can learn to plan. This is achieved by applying a methodology based on concept-based interpretability to a model-free agent in Sokoban -- a commonly used benchmark for studying planning. Specifically, we demonstrate that DRC, a generic model-free agent introduced by Guez et al. (2019), uses learned concept representations to internally formulate plans that both predict the long-term effects of actions on the environment and influence action selection. Our methodology involves: (1) probing for planning-relevant concepts, (2) investigating plan formation within the agent's representations, and (3) verifying that discovered plans (in the agent's representations) have a causal effect on the agent's behavior through interventions. We also show that the emergence of these plans coincides with the emergence of a planning-like property: the ability to benefit from additional test-time compute. Finally, we perform a qualitative analysis of the planning algorithm learned by the agent and discover a strong resemblance to parallelized bidirectional search. Our findings advance understanding of the internal mechanisms underlying planning behavior in agents, which is important given the recent trend of emergent planning and reasoning capabilities in LLMs through RL"}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Interpreting Emergent Planning in Model-Free Reinforcement Learning](https://arxiv.org/abs/2504.01871)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'The advent of large language models (LLMs) has catalyzed a transformative shift in artificial intelligence, paving the way for advanced intelligent agents capable of sophisticated reasoning, robust perception, and versatile action across diverse domains. As these agents increasingly drive AI research and practical applications, their design, evaluation, and continuous improvement present intricate, multifaceted challenges. This survey provides a comprehensive overview, framing intelligent agents within a modular, brain-inspired architecture that integrates principles from cognitive science, neuroscience, and computational research. We structure our exploration into four interconnected parts. First, we delve into the modular foundation of intelligent agents, systematically mapping their cognitive, perceptual, and operational modules onto analogous human brain functionalities, and elucidating core components such as memory, world modeling, reward processing, and emotion-like systems. Second, we discuss self-enhancement and adaptive evolution mechanisms, exploring how agents autonomously refine their capabilities, adapt to dynamic environments, and achieve continual learning through automated optimization paradigms, including emerging AutoML and LLM-driven optimization strategies. Third, we examine collaborative and evolutionary multi-agent systems, investigating the collective intelligence emerging from agent interactions, cooperation, and societal structures, highlighting parallels to human social dynamics. Finally, we address the critical imperative of building safe, secure, and beneficial AI systems, emphasizing intrinsic and extrinsic security threats, ethical alignment, robustness, and practical mitigation strategies necessary for trustworthy real-world deployment.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Advances and Challenges in Foundation Agents: From Brain-Inspired Intelligence to Evolutionary, Collaborative, and Safe Systems](https://arxiv.org/abs/2504.01990)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Scientific discovery is poised for rapid advancement through advanced robotics and artificial intelligence. Current scientific practices face substantial limitations as manual experimentation remains time-consuming and resource-intensive, while multidisciplinary research demands knowledge integration beyond individual researchers' expertise boundaries. Here, we envision an autonomous generalist scientist (AGS) concept combines agentic AI and embodied robotics to automate the entire research lifecycle. This system could dynamically interact with both physical and virtual environments while facilitating the integration of knowledge across diverse scientific disciplines. By deploying these technologies throughout every research stage -- spanning literature review, hypothesis generation, experimentation, and manuscript writing -- and incorporating internal reflection alongside external feedback, this system aims to significantly reduce the time and resources needed for scientific discovery. Building on the evolution from virtual AI scientists to versatile generalist AI-based robot scientists, AGS promises groundbreaking potential. As these autonomous systems become increasingly integrated into the research process, we hypothesize that scientific discovery might adhere to new scaling laws, potentially shaped by the number and capabilities of these autonomous systems, offering novel perspectives on how knowledge is generated and evolves. The adaptability of embodied robots to extreme environments, paired with the flywheel effect of accumulating scientific knowledge, holds the promise of continually pushing beyond both physical and intellectual frontiers."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Scaling Laws in Scientific Discovery with AI and Robot Scientists](https://arxiv.org/abs/2503.22444)
append_entries: 4
Finish: 2025-04-04 12:13:40.625560
------------------------------------------------------
Started: 2025-04-04 15:00:39.049265
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Reinforcement learning (RL) has been widely adopted in post-training for large language models (LLMs) at scale. Recently, the incentivization of reasoning capabilities in LLMs from RL indicates that proper learning methods could enable effective inference-time scalability. A key challenge of RL is to obtain accurate reward signals for LLMs in various domains beyond verifiable questions or artificial rules. In this work, we investigate how to improve reward modeling (RM) with more inference compute for general queries, i.e. the inference-time scalability of generalist RM, and further, how to improve the effectiveness of performance-compute scaling with proper learning methods. For the RM approach, we adopt pointwise generative reward modeling (GRM) to enable flexibility for different input types and potential for inference-time scaling. For the learning method, we propose Self-Principled Critique Tuning (SPCT) to foster scalable reward generation behaviors in GRMs through online RL, to generate principles adaptively and critiques accurately, resulting in DeepSeek-GRM models. Furthermore, for effective inference-time scaling, we use parallel sampling to expand compute usage, and introduce a meta RM to guide voting process for better scaling performance. Empirically, we show that SPCT significantly improves the quality and scalability of GRMs, outperforming existing methods and models in various RM benchmarks without severe biases, and could achieve better performance compared to training-time scaling. DeepSeek-GRM still meets challenges in some tasks, which we believe can be addressed by future efforts in generalist reward systems. The models will be released and open-sourced.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Inference-Time Scaling for Generalist Reward Modeling](https://arxiv.org/abs/2504.02495)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Automatic speech recognition systems have undoubtedly advanced with the integration of multilingual and multitask models such as Whisper, which have shown a promising ability to understand and process speech across a wide range of languages. Despite their robustness, these models often fall short in handling the linguistic distinctions of minority languages. This study addresses this gap by integrating traditional and novel language models with fine-tuned Whisper models to raise their performance in less commonly studied languages. Through rigorous fine-tuning and evaluation across multiple datasets, we demonstrate substantial improvements in word error rate, particularly in low-resource scenarios. Our approach not only does take advantage of the extensive data Whisper was pre-trained on, but also complements its linguistic adaptability by incorporating language models. We obtained improvements up to 51\\% for in-distribution datasets and up to 34\\% for out-of-distribution sentences using statistical language models, while large language models provided moderate but consistently robust improvement across diverse linguistic contexts. The findings reveal that, while the integration reliably benefits all model sizes, the extent of improvement varies, highlighting the importance of optimized language model parameters. Finally, we emphasize the importance of selecting appropriate evaluation parameters when reporting the results using transformer-based ASR models. In summary, this research clears the way for more inclusive ASR technologies that perform better across languages by enriching their linguistic knowledge. For further implementation details of this study, the technical documentation and source code are available at http://www.github.com/hitz-zentroa/whisper-lm.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Whisper-LM: Improving ASR Models with Language Models for Low-Resource Languages](https://arxiv.org/abs/2503.23542)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': '3D Gaussian Splatting (3DGS) demonstrates superior quality and rendering speed, but with millions of 3D Gaussians and significant storage and transmission costs. Recent 3DGS compression methods mainly concentrate on compressing Scaffold-GS, achieving impressive performance but with an additional voxel structure and a complex encoding and quantization strategy. In this paper, we aim to develop a simple yet effective method called NeuralGS that explores in another way to compress the original 3DGS into a compact representation without the voxel structure and complex quantization strategies. Our observation is that neural fields like NeRF can represent complex 3D scenes with Multi-Layer Perceptron (MLP) neural networks using only a few megabytes. Thus, NeuralGS effectively adopts the neural field representation to encode the attributes of 3D Gaussians with MLPs, only requiring a small storage size even for a large-scale scene. To achieve this, we adopt a clustering strategy and fit the Gaussians with different tiny MLPs for each cluster, based on importance scores of Gaussians as fitting weights. We experiment on multiple datasets, achieving a 45-times average model size reduction without harming the visual quality. The compression performance of our method on original 3DGS is comparable to the dedicated Scaffold-GS-based compression methods, which demonstrate the huge potential of directly compressing original 3DGS with neural fields.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [NeuralGS: Bridging Neural Fields and 3D Gaussian Splatting for Compact 3D Representations](https://arxiv.org/abs/2503.23162)
append_entries: 3
Finish: 2025-04-04 15:00:40.492653
------------------------------------------------------
Started: 2025-04-04 18:10:13.853128
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Diffusion models offer impressive controllability for image tasks, primarily through noise predictions that encode task-specific information and classifier-free guidance enabling adjustable scaling. This scaling mechanism implicitly defines a ``scaling space'' whose potential for fine-grained semantic manipulation remains underexplored. We investigate this space, starting with inversion-based editing where the difference between conditional/unconditional noise predictions carries key semantic information. Our core contribution stems from a Fourier analysis of noise predictions, revealing that its low- and high-frequency components evolve differently throughout diffusion. Based on this insight, we introduce FreSca, a straightforward method that applies guidance scaling independently to different frequency bands in the Fourier domain. FreSca demonstrably enhances existing image editing methods without retraining. Excitingly, its effectiveness extends to image understanding tasks such as depth estimation, yielding quantitative gains across multiple datasets."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [FreSca: Unveiling the Scaling Space in Diffusion Models](https://arxiv.org/abs/2504.02154)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "We present the challenging task of automatically creating a high-level Wikipedia-style article that aggregates information from multiple diverse videos about real-world events, such as natural disasters or political elections. Videos are intuitive sources for retrieval-augmented generation (RAG), but most contemporary RAG workflows focus heavily on text and existing methods for video-based summarization focus on low-level scene understanding rather than high-level event semantics. To close this gap, we introduce WikiVideo, a benchmark consisting of expert-written articles and densely annotated videos that provide evidence for articles' claims, facilitating the integration of video into RAG pipelines and enabling the creation of in-depth content that is grounded in multimodal sources. We further propose Collaborative Article Generation (CAG), a novel interactive method for article creation from multiple videos. CAG leverages an iterative interaction between an r1-style reasoning model and a VideoLLM to draw higher level inferences about the target event than is possible with VideoLLMs alone, which fixate on low-level visual features. We benchmark state-of-the-art VideoLLMs and CAG in both oracle retrieval and RAG settings and find that CAG consistently outperforms alternative methods, while suggesting intriguing avenues for future work."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [WikiVideo: Article Generation from Multiple Videos](https://arxiv.org/abs/2504.00939)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'This paper introduces JavisDiT, a novel Joint Audio-Video Diffusion Transformer designed for synchronized audio-video generation (JAVG). Built upon the powerful Diffusion Transformer (DiT) architecture, JavisDiT is able to generate high-quality audio and video content simultaneously from open-ended user prompts. To ensure optimal synchronization, we introduce a fine-grained spatio-temporal alignment mechanism through a Hierarchical Spatial-Temporal Synchronized Prior (HiST-Sypo) Estimator. This module extracts both global and fine-grained spatio-temporal priors, guiding the synchronization between the visual and auditory components. Furthermore, we propose a new benchmark, JavisBench, consisting of 10,140 high-quality text-captioned sounding videos spanning diverse scenes and complex real-world scenarios. Further, we specifically devise a robust metric for evaluating the synchronization between generated audio-video pairs in real-world complex content. Experimental results demonstrate that JavisDiT significantly outperforms existing methods by ensuring both high-quality generation and precise synchronization, setting a new standard for JAVG tasks. Our code, model, and dataset will be made publicly available at https://javisdit.github.io/.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [JavisDiT: Joint Audio-Video Diffusion Transformer with Hierarchical Spatio-Temporal Prior Synchronization](https://arxiv.org/abs/2503.23377)
append_entries: 3
Finish: 2025-04-04 18:10:15.707417
------------------------------------------------------
Started: 2025-04-04 21:00:38.953652
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Unsupervised panoptic segmentation aims to partition an image into semantically meaningful regions and distinct object instances without training on manually annotated data. In contrast to prior work on unsupervised panoptic scene understanding, we eliminate the need for object-centric training data, enabling the unsupervised understanding of complex scenes. To that end, we present the first unsupervised panoptic method that directly trains on scene-centric imagery. In particular, we propose an approach to obtain high-resolution panoptic pseudo labels on complex scene-centric data, combining visual representations, depth, and motion cues. Utilizing both pseudo-label training and a panoptic self-training strategy yields a novel approach that accurately predicts panoptic segmentation of complex scenes without requiring any human annotations. Our approach significantly improves panoptic quality, e.g., surpassing the recent state of the art in unsupervised panoptic segmentation on Cityscapes by 9.4% points in PQ.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Scene-Centric Unsupervised Panoptic Segmentation](https://arxiv.org/abs/2504.01955)
append_entries: 1
Finish: 2025-04-04 21:00:39.706989
------------------------------------------------------
Started: 2025-04-05 00:36:25.697177
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-05 00:36:25.876910
------------------------------------------------------
Started: 2025-04-05 03:21:54.990439
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Since the advent of reasoning-based large language models, many have found great success from distilling reasoning capabilities into student models. Such techniques have significantly bridged the gap between reasoning and standard LLMs on coding tasks. Despite this, much of the progress on distilling reasoning models remains locked behind proprietary datasets or lacks details on data curation, filtering and subsequent training. To address this, we construct a superior supervised fine-tuning (SFT) dataset that we use to achieve state-of-the-art coding capability results in models of various sizes. Our distilled models use only SFT to achieve 61.8% on LiveCodeBench and 24.6% on CodeContests, surpassing alternatives trained with reinforcement learning. We then perform analysis on the data sources used to construct our dataset, the impact of code execution filtering, and the importance of instruction/solution diversity. We observe that execution filtering negatively affected benchmark accuracy, leading us to prioritize instruction diversity over solution correctness. Finally, we also analyze the token efficiency and reasoning patterns utilized by these models. We will open-source these datasets and distilled models to the community.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [OpenCodeReasoning: Advancing Data Distillation for Competitive Coding](https://arxiv.org/abs/2504.01943)
append_entries: 1
Finish: 2025-04-05 03:21:55.666316
------------------------------------------------------
Started: 2025-04-05 06:00:46.014530
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-05 06:00:46.236807
------------------------------------------------------
Started: 2025-04-05 09:00:32.644717
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-05 09:00:32.868462
------------------------------------------------------
Started: 2025-04-05 12:11:57.065145
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-05 12:11:57.441927
------------------------------------------------------
Started: 2025-04-05 15:00:35.479127
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-05 15:00:35.686013
------------------------------------------------------
Started: 2025-04-05 18:00:54.444595
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-05 18:00:54.679027
------------------------------------------------------
Started: 2025-04-05 21:00:50.351559
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-05 21:00:50.641358
------------------------------------------------------
Started: 2025-04-06 00:40:18.999937
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-06 00:40:19.186234
------------------------------------------------------
Started: 2025-04-06 03:26:37.546821
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-06 03:26:37.826662
------------------------------------------------------
Started: 2025-04-06 06:00:52.259424
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-06 06:00:52.454535
------------------------------------------------------
Started: 2025-04-06 09:00:49.133618
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-06 09:00:49.348230
------------------------------------------------------
Started: 2025-04-06 12:00:39.030697
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-06 12:00:39.382470
------------------------------------------------------
Started: 2025-04-06 15:00:30.338736
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-06 15:00:30.506516
------------------------------------------------------
Started: 2025-04-06 18:08:51.776843
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-06 18:08:51.983035
------------------------------------------------------
Started: 2025-04-06 21:00:46.863827
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-06 21:00:47.094376
------------------------------------------------------
Started: 2025-04-07 00:38:50.060512
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-07 00:38:50.290330
------------------------------------------------------
Started: 2025-04-07 03:27:59.597115
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-07 03:27:59.761357
------------------------------------------------------
Started: 2025-04-07 06:00:40.512337
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Existing MLLM benchmarks face significant challenges in evaluating Unified MLLMs (U-MLLMs) due to: 1) lack of standardized benchmarks for traditional tasks, leading to inconsistent comparisons; 2) absence of benchmarks for mixed-modality generation, which fails to assess multimodal reasoning capabilities. We present a comprehensive evaluation framework designed to systematically assess U-MLLMs. Our benchmark includes: Standardized Traditional Task Evaluation. We sample from 12 datasets, covering 10 tasks with 30 subtasks, ensuring consistent and fair comparisons across studies." 2. Unified Task Assessment. We introduce five novel tasks testing multimodal reasoning, including image editing, commonsense QA with image generation, and geometric reasoning. 3. Comprehensive Model Benchmarking. We evaluate 12 leading U-MLLMs, such as Janus-Pro, EMU3, VILA-U, and Gemini2-flash, alongside specialized understanding (e.g., Claude-3.5-Sonnet) and generation models (e.g., DALL-E-3). Our findings reveal substantial performance gaps in existing U-MLLMs, highlighting the need for more robust models capable of handling mixed-modality tasks effectively. The code and evaluation data can be found in https://mme-unify.github.io/.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [MME-Unify: A Comprehensive Benchmark for Unified Multimodal Understanding and Generation Models](https://arxiv.org/abs/2504.03641)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'In the interaction between agents and their environments, agents expand their capabilities by planning and executing actions. However, LLM-based agents face substantial challenges when deployed in novel environments or required to navigate unconventional action spaces. To empower agents to autonomously explore environments, optimize workflows, and enhance their understanding of actions, we propose SynWorld, a framework that allows agents to synthesize possible scenarios with multi-step action invocation within the action space and perform Monte Carlo Tree Search (MCTS) exploration to effectively refine their action knowledge in the current environment. Our experiments demonstrate that SynWorld is an effective and general approach to learning action knowledge in new environments. Code is available at https://github.com/zjunlp/SynWorld.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [SynWorld: Virtual Scenario Synthesis for Agentic Action Knowledge Refinement](https://arxiv.org/abs/2504.03561)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Large Language Models (LLMs) have achieved considerable performance across various agentic planning tasks. However, traditional agent planning approaches adopt a "flood irrigation" methodology that indiscriminately injects gold trajectories, external feedback, and domain knowledge into agent models. This practice overlooks the fundamental human cognitive principle of situational self-awareness during decision-making-the ability to dynamically assess situational demands and strategically employ resources during decision-making. We propose agentic knowledgeable self-awareness to address this gap, a novel paradigm enabling LLM-based agents to autonomously regulate knowledge utilization. Specifically, we propose KnowSelf, a data-centric approach that applies agents with knowledgeable self-awareness like humans. Concretely, we devise a heuristic situation judgement criterion to mark special tokens on the agent\'s self-explored trajectories for collecting training data. Through a two-stage training process, the agent model can switch between different situations by generating specific special tokens, achieving optimal planning effects with minimal costs. Our experiments demonstrate that KnowSelf can outperform various strong baselines on different tasks and models with minimal use of external knowledge. Code is available at https://github.com/zjunlp/KnowSelf.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Agentic Knowledgeable Self-awareness](https://arxiv.org/abs/2504.03553)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'In this work, we present VARGPT-v1.1, an advanced unified visual autoregressive model that builds upon our previous framework VARGPT. The model preserves the dual paradigm of next-token prediction for visual understanding and next-scale generation for image synthesis. Specifically, VARGPT-v1.1 integrates: (1) a novel training strategy combining iterative visual instruction tuning with reinforcement learning through Direct Preference Optimization (DPO), (2) an expanded training corpus containing 8.3M visual-generative instruction pairs, (3) an upgraded language model backbone using Qwen2, (4) enhanced image generation resolution, and (5) emergent image editing capabilities without architectural modifications. These advancements enable VARGPT-v1.1 to achieve state-of-the-art performance in multimodal understanding and text-to-image instruction-following tasks, demonstrating significant improvements in both comprehension and generation metrics. Notably, through visual instruction tuning, the model acquires image editing functionality while maintaining architectural consistency with its predecessor, revealing the potential for unified visual understanding, generation, and editing. Our findings suggest that well-designed unified visual autoregressive models can effectively adopt flexible training strategies from large language models (LLMs), exhibiting promising scalability. The codebase and model weights are publicly available at https://github.com/VARGPT-family/VARGPT-v1.1.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [VARGPT-v1.1: Improve Visual Autoregressive Large Unified Model via Iterative Instruction Tuning and Reinforcement Learning](https://arxiv.org/abs/2504.02949)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'The task of issue resolving is to modify a codebase to generate a patch that addresses a given issue. However, existing benchmarks, such as SWE-bench, focus almost exclusively on Python, making them insufficient for evaluating Large Language Models (LLMs) across diverse software ecosystems. To address this, we introduce a multilingual issue-resolving benchmark, called Multi-SWE-bench, covering Java, TypeScript, JavaScript, Go, Rust, C, and C++. It includes a total of 1,632 high-quality instances, which were carefully annotated from 2,456 candidates by 68 expert annotators, ensuring that the benchmark can provide an accurate and reliable evaluation. Based on Multi-SWE-bench, we evaluate a series of state-of-the-art models using three representative methods (Agentless, SWE-agent, and OpenHands) and present a comprehensive analysis with key empirical insights. In addition, we launch a Multi-SWE-RL open-source community, aimed at building large-scale reinforcement learning (RL) training datasets for issue-resolving tasks. As an initial contribution, we release a set of 4,723 well-structured instances spanning seven programming languages, laying a solid foundation for RL research in this domain. More importantly, we open-source our entire data production pipeline, along with detailed tutorials, encouraging the open-source community to continuously contribute and expand the dataset. We envision our Multi-SWE-bench and the ever-growing Multi-SWE-RL community as catalysts for advancing RL toward its full potential, bringing us one step closer to the dawn of AGI.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Multi-SWE-bench: A Multilingual Benchmark for Issue Resolving](https://arxiv.org/abs/2504.02605)
append_entries: 5
Finish: 2025-04-07 06:00:43.164623
------------------------------------------------------
Started: 2025-04-07 09:00:35.328018
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Training effective AI agents for multi-turn interactions requires high-quality data that captures realistic human-agent dynamics, yet such data is scarce and expensive to collect manually. We introduce APIGen-MT, a two-phase framework that generates verifiable and diverse multi-turn agent data. In the first phase, our agentic pipeline produces detailed task blueprints with ground-truth actions, leveraging a committee of LLM reviewers and iterative feedback loops. These blueprints are then transformed into complete interaction trajectories through simulated human-agent interplay. We train a family of models -- the xLAM-2-fc-r series with sizes ranging from 1B to 70B parameters. Our models outperform frontier models such as GPT-4o and Claude 3.5 on tau-bench and BFCL benchmarks, with the smaller models surpassing their larger counterparts, particularly in multi-turn settings, while maintaining superior consistency across multiple trials. Comprehensive experiments demonstrate that our verified blueprint-to-details approach yields high-quality training data, enabling the development of more reliable, efficient, and capable agents. We open-source both the synthetic data collected and the trained xLAM-2-fc-r models to advance research in AI agents. Models are available on HuggingFace at https://huggingface.co/collections/Salesforce/xlam-2-67ef5be12949d8dcdae354c4 and project website is https://apigen-mt.github.io'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [APIGen-MT: Agentic Pipeline for Multi-Turn Data Generation via Simulated Agent-Human Interplay](https://arxiv.org/abs/2504.03601)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Single-image human reconstruction is vital for digital human modeling applications but remains an extremely challenging task. Current approaches rely on generative models to synthesize multi-view images for subsequent 3D reconstruction and animation. However, directly generating multiple views from a single human image suffers from geometric inconsistencies, resulting in issues like fragmented or blurred limbs in the reconstructed models. To tackle these limitations, we introduce HumanDreamer-X, a novel framework that integrates multi-view human generation and reconstruction into a unified pipeline, which significantly enhances the geometric consistency and visual fidelity of the reconstructed 3D models. In this framework, 3D Gaussian Splatting serves as an explicit 3D representation to provide initial geometry and appearance priority. Building upon this foundation, HumanFixer is trained to restore 3DGS renderings, which guarantee photorealistic results. Furthermore, we delve into the inherent challenges associated with attention mechanisms in multi-view human generation, and propose an attention modulation strategy that effectively enhances geometric details identity consistency across multi-view. Experimental results demonstrate that our approach markedly improves generation and reconstruction PSNR quality metrics by 16.45% and 12.65%, respectively, achieving a PSNR of up to 25.62 dB, while also showing generalization capabilities on in-the-wild data and applicability to various human reconstruction backbone models.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [HumanDreamer-X: Photorealistic Single-image Human Avatars Reconstruction via Gaussian Restoration](https://arxiv.org/abs/2504.03536)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'This paper introduces Comprehensive Relighting, the first all-in-one approach that can both control and harmonize the lighting from an image or video of humans with arbitrary body parts from any scene. Building such a generalizable model is extremely challenging due to the lack of dataset, restricting existing image-based relighting models to a specific scenario (e.g., face or static human). To address this challenge, we repurpose a pre-trained diffusion model as a general image prior and jointly model the human relighting and background harmonization in the coarse-to-fine framework. To further enhance the temporal coherence of the relighting, we introduce an unsupervised temporal lighting model that learns the lighting cycle consistency from many real-world videos without any ground truth. In inference time, our temporal lighting module is combined with the diffusion models through the spatio-temporal feature blending algorithms without extra training; and we apply a new guided refinement as a post-processing to preserve the high-frequency details from the input image. In the experiments, Comprehensive Relighting shows a strong generalizability and lighting temporal coherence, outperforming existing image-based human relighting and harmonization methods.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Comprehensive Relighting: Generalizable and Consistent Monocular Human Relighting and Harmonization](https://arxiv.org/abs/2504.03011)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'When sound waves hit an object, they induce vibrations that produce high-frequency and subtle visual changes, which can be used for recovering the sound. Early studies always encounter trade-offs related to sampling rate, bandwidth, field of view, and the simplicity of the optical path. Recent advances in event camera hardware show good potential for its application in visual sound recovery, because of its superior ability in capturing high-frequency signals. However, existing event-based vibration recovery methods are still sub-optimal for sound recovery. In this work, we propose a novel pipeline for non-contact sound recovery, fully utilizing spatial-temporal information from the event stream. We first generate a large training set using a novel simulation pipeline. Then we designed a network that leverages the sparsity of events to capture spatial information and uses Mamba to model long-term temporal information. Lastly, we train a spatial aggregation block to aggregate information from different locations to further improve signal quality. To capture event signals caused by sound waves, we also designed an imaging system using a laser matrix to enhance the gradient and collected multiple data sequences for testing. Experimental results on synthetic and real-world data demonstrate the effectiveness of our method.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [EvMic: Event-based Non-contact sound recovery from effective spatial-temporal modeling](https://arxiv.org/abs/2504.02402)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'In this research, we introduce BEATS, a novel framework for evaluating Bias, Ethics, Fairness, and Factuality in Large Language Models (LLMs). Building upon the BEATS framework, we present a bias benchmark for LLMs that measure performance across 29 distinct metrics. These metrics span a broad range of characteristics, including demographic, cognitive, and social biases, as well as measures of ethical reasoning, group fairness, and factuality related misinformation risk. These metrics enable a quantitative assessment of the extent to which LLM generated responses may perpetuate societal prejudices that reinforce or expand systemic inequities. To achieve a high score on this benchmark a LLM must show very equitable behavior in their responses, making it a rigorous standard for responsible AI evaluation. Empirical results based on data from our experiment show that, 37.65\\% of outputs generated by industry leading models contained some form of bias, highlighting a substantial risk of using these models in critical decision making systems. BEATS framework and benchmark offer a scalable and statistically rigorous methodology to benchmark LLMs, diagnose factors driving biases, and develop mitigation strategies. With the BEATS framework, our goal is to help the development of more socially responsible and ethically aligned AI models.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [BEATS: Bias Evaluation and Assessment Test Suite for Large Language Models](https://arxiv.org/abs/2503.24310)
append_entries: 5
Finish: 2025-04-07 09:00:38.027016
------------------------------------------------------
Started: 2025-04-07 12:14:29.913562
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Transformers are the cornerstone of modern large language models, but their quadratic computational complexity limits efficiency in long-sequence processing. Recent advancements in Mamba, a state space model (SSM) with linear complexity, offer promising efficiency gains but suffer from unstable contextual learning and multitask generalization. This paper proposes TransMamba, a novel framework that unifies Transformer and Mamba through shared parameter matrices (e.g., QKV and CBx), and thus could dynamically switch between attention and SSM mechanisms at different token lengths and layers. We design the Memory converter to bridge Transformer and Mamba by converting attention outputs into SSM-compatible states, ensuring seamless information flow at TransPoints where the transformation happens. The TransPoint scheduling is also thoroughly explored for further improvements. We conducted extensive experiments demonstrating that TransMamba achieves superior training efficiency and performance compared to baselines, and validated the deeper consistency between Transformer and Mamba paradigms, offering a scalable solution for next-generation sequence modeling.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [TransMamba: Flexibly Switching between Transformer and Mamba](https://arxiv.org/abs/2503.24067)
append_entries: 1
Finish: 2025-04-07 12:14:30.676679
------------------------------------------------------
Started: 2025-04-07 15:00:37.520485
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Medical image and video segmentation is a critical task for precision medicine, which has witnessed considerable progress in developing task or modality-specific and generalist models for 2D images. However, there have been limited studies on building general-purpose models for 3D images and videos with comprehensive user studies. Here, we present MedSAM2, a promptable segmentation foundation model for 3D image and video segmentation. The model is developed by fine-tuning the Segment Anything Model 2 on a large medical dataset with over 455,000 3D image-mask pairs and 76,000 frames, outperforming previous models across a wide range of organs, lesions, and imaging modalities. Furthermore, we implement a human-in-the-loop pipeline to facilitate the creation of large-scale datasets resulting in, to the best of our knowledge, the most extensive user study to date, involving the annotation of 5,000 CT lesions, 3,984 liver MRI lesions, and 251,550 echocardiogram video frames, demonstrating that MedSAM2 can reduce manual costs by more than 85%. MedSAM2 is also integrated into widely used platforms with user-friendly interfaces for local and cloud deployment, making it a practical tool for supporting efficient, scalable, and high-quality segmentation in both research and healthcare environments.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [MedSAM2: Segment Anything in 3D Medical Images and Videos](https://arxiv.org/abs/2504.03600)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Mathematical reasoning is a cornerstone of human intelligence and a key benchmark for advanced capabilities in large language models (LLMs). However, the research community still lacks an open, large-scale, high-quality corpus tailored to the demands of math-centric LLM pre-training. We present MegaMath, an open dataset curated from diverse, math-focused sources through following practices: (1) Revisiting web data: We re-extracted mathematical documents from Common Crawl with math-oriented HTML optimizations, fasttext-based filtering and deduplication, all for acquiring higher-quality data on the Internet. (2) Recalling Math-related code data: We identified high quality math-related code from large code training corpus, Stack-V2, further enhancing data diversity. (3) Exploring Synthetic data: We synthesized QA-style text, math-related code, and interleaved text-code blocks from web data or code data. By integrating these strategies and validating their effectiveness through extensive ablations, MegaMath delivers 371B tokens with the largest quantity and top quality among existing open math pre-training datasets.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [MegaMath: Pushing the Limits of Open Math Corpora](https://arxiv.org/abs/2504.02807)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Balancing temporal resolution and spatial detail under limited compute budget remains a key challenge for video-based multi-modal large language models (MLLMs). Existing methods typically compress video representations using predefined rules before feeding them into the LLM, resulting in irreversible information loss and often ignoring input instructions. To address this, we propose a novel slow-fast architecture that naturally circumvents this trade-off, enabling the use of more input frames while preserving spatial details. Inspired by how humans first skim a video before focusing on relevant parts, our slow-fast design employs a dual-token strategy: 1) "fast" visual tokens -- a compact set of compressed video features -- are fed into the LLM alongside text embeddings to provide a quick overview; 2) "slow" visual tokens -- uncompressed video features -- are cross-attended by text embeddings through specially designed hybrid decoder layers, enabling instruction-aware extraction of relevant visual details with linear complexity. We conduct systematic exploration to optimize both the overall architecture and key components. Experiments show that our model significantly outperforms self-attention-only baselines, extending the input capacity from 16 to 128 frames with just a 3% increase in computation, and achieving a 16% average performance improvement across five video understanding benchmarks. Our 7B model achieves state-of-the-art performance among models of similar size. Furthermore, our slow-fast architecture is a plug-and-play design that can be integrated into other video MLLMs to improve efficiency and scalability.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Slow-Fast Architecture for Video Multi-Modal Large Language Models](https://arxiv.org/abs/2504.01328)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Fine-tuning a pre-trained Text-to-Image (T2I) model on a tailored portrait dataset is the mainstream method for text-driven customization of portrait attributes. Due to Semantic Pollution during fine-tuning, existing methods struggle to maintain the original model's behavior and achieve incremental learning while customizing target attributes. To address this issue, we propose SPF-Portrait, a pioneering work to purely understand customized semantics while eliminating semantic pollution in text-driven portrait customization. In our SPF-Portrait, we propose a dual-path pipeline that introduces the original model as a reference for the conventional fine-tuning path. Through contrastive learning, we ensure adaptation to target attributes and purposefully align other unrelated attributes with the original portrait. We introduce a novel Semantic-Aware Fine Control Map, which represents the precise response regions of the target semantics, to spatially guide the alignment process between the contrastive paths. This alignment process not only effectively preserves the performance of the original model but also avoids over-alignment. Furthermore, we propose a novel response enhancement mechanism to reinforce the performance of target attributes, while mitigating representation discrepancy inherent in direct cross-modal supervision. Extensive experiments demonstrate that SPF-Portrait achieves state-of-the-art performance. Project webpage: https://spf-portrait.github.io/SPF-Portrait/"}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [SPF-Portrait: Towards Pure Portrait Customization with Semantic Pollution-Free Fine-tuning](https://arxiv.org/abs/2504.00396)
append_entries: 4
Finish: 2025-04-07 15:00:39.673364
------------------------------------------------------
Started: 2025-04-07 18:10:40.166084
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Recent advancements in behavior cloning have enabled robots to perform complex manipulation tasks. However, accurately assessing training performance remains challenging, particularly for real-world applications, as behavior cloning losses often correlate poorly with actual task success. Consequently, researchers resort to success rate metrics derived from costly and time-consuming real-world evaluations, making the identification of optimal policies and detection of overfitting or underfitting impractical. To address these issues, we propose real-is-sim, a novel behavior cloning framework that incorporates a dynamic digital twin (based on Embodied Gaussians) throughout the entire policy development pipeline: data collection, training, and deployment. By continuously aligning the simulated world with the physical world, demonstrations can be collected in the real world with states extracted from the simulator. The simulator enables flexible state representations by rendering image inputs from any viewpoint or extracting low-level state information from objects embodied within the scene. During training, policies can be directly evaluated within the simulator in an offline and highly parallelizable manner. Finally, during deployment, policies are run within the simulator where the real robot directly tracks the simulated robot's joints, effectively decoupling policy execution from real hardware and mitigating traditional domain-transfer challenges. We validate real-is-sim on the PushT manipulation task, demonstrating strong correlation between success rates obtained in the simulator and real-world evaluations. Videos of our system can be found at https://realissim.rai-inst.com."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Real-is-Sim: Bridging the Sim-to-Real Gap with a Dynamic Digital Twin for Real-World Robot Policy Evaluation](https://arxiv.org/abs/2504.03597)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'The accurate delineation of agricultural field boundaries from satellite imagery is vital for land management and crop monitoring. However, current methods face challenges due to limited dataset sizes, resolution discrepancies, and diverse environmental conditions. We address this by reformulating the task as instance segmentation and introducing the Field Boundary Instance Segmentation - 22M dataset (FBIS-22M), a large-scale, multi-resolution dataset comprising 672,909 high-resolution satellite image patches (ranging from 0.25 m to 10 m) and 22,926,427 instance masks of individual fields, significantly narrowing the gap between agricultural datasets and those in other computer vision domains. We further propose Delineate Anything, an instance segmentation model trained on our new FBIS-22M dataset. Our proposed model sets a new state-of-the-art, achieving a substantial improvement of 88.5% in mAP@0.5 and 103% in mAP@0.5:0.95 over existing methods, while also demonstrating significantly faster inference and strong zero-shot generalization across diverse image resolutions and unseen geographic regions. Code, pre-trained models, and the FBIS-22M dataset are available at https://lavreniuk.github.io/Delineate-Anything.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Delineate Anything: Resolution-Agnostic Field Boundary Delineation on Satellite Imagery](https://arxiv.org/abs/2504.02534)
append_entries: 2
Finish: 2025-04-07 18:10:41.476688
------------------------------------------------------
Started: 2025-04-07 21:00:43.487411
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-07 21:00:43.697464
------------------------------------------------------
Started: 2025-04-08 00:37:08.580459
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Autonomous agents powered by foundation models have seen widespread adoption across various real-world applications. However, they remain highly vulnerable to malicious instructions and attacks, which can result in severe consequences such as privacy breaches and financial losses. More critically, existing guardrails for LLMs are not applicable due to the complex and dynamic nature of agents. To tackle these challenges, we propose ShieldAgent, the first guardrail agent designed to enforce explicit safety policy compliance for the action trajectory of other protected agents through logical reasoning. Specifically, ShieldAgent first constructs a safety policy model by extracting verifiable rules from policy documents and structuring them into a set of action-based probabilistic rule circuits. Given the action trajectory of the protected agent, ShieldAgent retrieves relevant rule circuits and generates a shielding plan, leveraging its comprehensive tool library and executable code for formal verification. In addition, given the lack of guardrail benchmarks for agents, we introduce ShieldAgent-Bench, a dataset with 3K safety-related pairs of agent instructions and action trajectories, collected via SOTA attacks across 6 web environments and 7 risk categories. Experiments show that ShieldAgent achieves SOTA on ShieldAgent-Bench and three existing benchmarks, outperforming prior methods by 11.3% on average with a high recall of 90.1%. Additionally, ShieldAgent reduces API queries by 64.7% and inference time by 58.2%, demonstrating its high precision and efficiency in safeguarding agents.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [ShieldAgent: Shielding Agents via Verifiable Safety Policy Reasoning](https://arxiv.org/abs/2503.22738)
append_entries: 1
Finish: 2025-04-08 00:37:09.385719
------------------------------------------------------
Started: 2025-04-08 03:24:40.095456
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-08 03:24:40.362981
------------------------------------------------------
Started: 2025-04-08 06:00:53.915760
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Region-level captioning aims to generate natural language descriptions for specific image regions while highlighting their distinguishing features. However, existing methods struggle to produce unique captions across multi-granularity, limiting their real-world applicability. To address the need for detailed region-level understanding, we introduce URECA dataset, a large-scale dataset tailored for multi-granularity region captioning. Unlike prior datasets that focus primarily on salient objects, URECA dataset ensures a unique and consistent mapping between regions and captions by incorporating a diverse set of objects, parts, and background elements. Central to this is a stage-wise data curation pipeline, where each stage incrementally refines region selection and caption generation. By leveraging Multimodal Large Language Models (MLLMs) at each stage, our pipeline produces distinctive and contextually grounded captions with improved accuracy and semantic diversity. Building upon this dataset, we present URECA, a novel captioning model designed to effectively encode multi-granularity regions. URECA maintains essential spatial properties such as position and shape through simple yet impactful modifications to existing MLLMs, enabling fine-grained and semantically rich region descriptions. Our approach introduces dynamic mask modeling and a high-resolution mask encoder to enhance caption uniqueness. Experiments show that URECA achieves state-of-the-art performance on URECA dataset and generalizes well to existing region-level captioning benchmarks.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [URECA: Unique Region Caption Anything](https://arxiv.org/abs/2504.05305)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Diffusion models approximate the denoising distribution as a Gaussian and predict its mean, whereas flow matching models reparameterize the Gaussian mean as flow velocity. However, they underperform in few-step sampling due to discretization error and tend to produce over-saturated colors under classifier-free guidance (CFG). To address these limitations, we propose a novel Gaussian mixture flow matching (GMFlow) model: instead of predicting the mean, GMFlow predicts dynamic Gaussian mixture (GM) parameters to capture a multi-modal flow velocity distribution, which can be learned with a KL divergence loss. We demonstrate that GMFlow generalizes previous diffusion and flow matching models where a single Gaussian is learned with an L_2 denoising loss. For inference, we derive GM-SDE/ODE solvers that leverage analytic denoising distributions and velocity fields for precise few-step sampling. Furthermore, we introduce a novel probabilistic guidance scheme that mitigates the over-saturation issues of CFG and improves image generation quality. Extensive experiments demonstrate that GMFlow consistently outperforms flow matching baselines in generation quality, achieving a Precision of 0.942 with only 6 sampling steps on ImageNet 256times256.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Gaussian Mixture Flow Matching Models](https://arxiv.org/abs/2504.05304)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Transformers today still struggle to generate one-minute videos because self-attention layers are inefficient for long context. Alternatives such as Mamba layers struggle with complex multi-scene stories because their hidden states are less expressive. We experiment with Test-Time Training (TTT) layers, whose hidden states themselves can be neural networks, therefore more expressive. Adding TTT layers into a pre-trained Transformer enables it to generate one-minute videos from text storyboards. For proof of concept, we curate a dataset based on Tom and Jerry cartoons. Compared to baselines such as Mamba~2, Gated DeltaNet, and sliding-window attention layers, TTT layers generate much more coherent videos that tell complex stories, leading by 34 Elo points in a human evaluation of 100 videos per method. Although promising, results still contain artifacts, likely due to the limited capability of the pre-trained 5B model. The efficiency of our implementation can also be improved. We have only experimented with one-minute videos due to resource constraints, but the approach can be extended to longer videos and more complex stories. Sample videos, code and annotations are available at: https://test-time-training.github.io/video-dit'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [One-Minute Video Generation with Test-Time Training](https://arxiv.org/abs/2504.05298)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Recent advancements in reasoning language models have demonstrated remarkable performance in complex tasks, but their extended chain-of-thought reasoning process increases inference overhead. While quantization has been widely adopted to reduce the inference cost of large language models, its impact on reasoning models remains understudied. In this study, we conduct the first systematic study on quantized reasoning models, evaluating the open-sourced DeepSeek-R1-Distilled Qwen and LLaMA families ranging from 1.5B to 70B parameters, and QwQ-32B. Our investigation covers weight, KV cache, and activation quantization using state-of-the-art algorithms at varying bit-widths, with extensive evaluation across mathematical (AIME, MATH-500), scientific (GPQA), and programming (LiveCodeBench) reasoning benchmarks. Our findings reveal that while lossless quantization can be achieved with W8A8 or W4A16 quantization, lower bit-widths introduce significant accuracy risks. We further identify model size, model origin, and task difficulty as critical determinants of performance. Contrary to expectations, quantized models do not exhibit increased output lengths. In addition, strategically scaling the model sizes or reasoning steps can effectively enhance the performance. All quantized models and codes will be open-sourced in https://github.com/ruikangliu/Quantized-Reasoning-Models.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Quantization Hurts Reasoning? An Empirical Study on Quantized Reasoning Models](https://arxiv.org/abs/2504.04823)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'The proliferation of Large Language Models (LLMs) accessed via black-box APIs introduces a significant trust challenge: users pay for services based on advertised model capabilities (e.g., size, performance), but providers may covertly substitute the specified model with a cheaper, lower-quality alternative to reduce operational costs. This lack of transparency undermines fairness, erodes trust, and complicates reliable benchmarking. Detecting such substitutions is difficult due to the black-box nature, typically limiting interaction to input-output queries. This paper formalizes the problem of model substitution detection in LLM APIs. We systematically evaluate existing verification techniques, including output-based statistical tests, benchmark evaluations, and log probability analysis, under various realistic attack scenarios like model quantization, randomized substitution, and benchmark evasion. Our findings reveal the limitations of methods relying solely on text outputs, especially against subtle or adaptive attacks. While log probability analysis offers stronger guarantees when available, its accessibility is often limited. We conclude by discussing the potential of hardware-based solutions like Trusted Execution Environments (TEEs) as a pathway towards provable model integrity, highlighting the trade-offs between security, performance, and provider adoption. Code is available at https://github.com/sunblaze-ucb/llm-api-audit'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Are You Getting What You Pay For? Auditing Model Substitution in LLM APIs](https://arxiv.org/abs/2504.04715)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Diffusion models are widely used for image editing tasks. Existing editing methods often design a representation manipulation procedure by curating an edit direction in the text embedding or score space. However, such a procedure faces a key challenge: overestimating the edit strength harms visual consistency while underestimating it fails the editing task. Notably, each source image may require a different editing strength, and it is costly to search for an appropriate strength via trial-and-error. To address this challenge, we propose Concept Lancet (CoLan), a zero-shot plug-and-play framework for principled representation manipulation in diffusion-based image editing. At inference time, we decompose the source input in the latent (text embedding or diffusion score) space as a sparse linear combination of the representations of the collected visual concepts. This allows us to accurately estimate the presence of concepts in each image, which informs the edit. Based on the editing task (replace/add/remove), we perform a customized concept transplant process to impose the corresponding editing direction. To sufficiently model the concept space, we curate a conceptual representation dataset, CoLan-150K, which contains diverse descriptions and scenarios of visual terms and phrases for the latent dictionary. Experiments on multiple diffusion-based image editing baselines show that methods equipped with CoLan achieve state-of-the-art performance in editing effectiveness and consistency preservation.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Concept Lancet: Image Editing with Compositional Representation Transplant](https://arxiv.org/abs/2504.02828)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Multimodal large language models (MLLMs) excel in vision-language tasks but also pose significant risks of generating harmful content, particularly through jailbreak attacks. Jailbreak attacks refer to intentional manipulations that bypass safety mechanisms in models, leading to the generation of inappropriate or unsafe content. Detecting such attacks is critical to ensuring the responsible deployment of MLLMs. Existing jailbreak detection methods face three primary challenges: (1) Many rely on model hidden states or gradients, limiting their applicability to white-box models, where the internal workings of the model are accessible; (2) They involve high computational overhead from uncertainty-based analysis, which limits real-time detection, and (3) They require fully labeled harmful datasets, which are often scarce in real-world settings. To address these issues, we introduce a test-time adaptive framework called JAILDAM. Our method leverages a memory-based approach guided by policy-driven unsafe knowledge representations, eliminating the need for explicit exposure to harmful data. By dynamically updating unsafe knowledge during test-time, our framework improves generalization to unseen jailbreak strategies while maintaining efficiency. Experiments on multiple VLM jailbreak benchmarks demonstrate that JAILDAM delivers state-of-the-art performance in harmful content detection, improving both accuracy and speed.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [JailDAM: Jailbreak Detection with Adaptive Memory for Vision-Language Model](https://arxiv.org/abs/2504.03770)
append_entries: 7
Finish: 2025-04-08 06:00:57.380831
------------------------------------------------------
Started: 2025-04-08 09:00:58.390017
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-08 09:00:58.607802
------------------------------------------------------
Started: 2025-04-08 12:00:38.535200
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Large Vision-Language Models (VLMs) deliver exceptional performance but require significant computational resources, limiting their deployment on mobile and edge devices. Smaller VLMs typically mirror design choices of larger models, such as extensive image tokenization, leading to inefficient GPU memory usage and constrained practicality for on-device applications.   We introduce SmolVLM, a series of compact multimodal models specifically engineered for resource-efficient inference. We systematically explore architectural configurations, tokenization strategies, and data curation optimized for low computational overhead. Through this, we identify key design choices that yield substantial performance gains on image and video tasks with minimal memory footprints.   Our smallest model, SmolVLM-256M, uses less than 1GB GPU memory during inference and outperforms the 300-times larger Idefics-80B model, despite an 18-month development gap. Our largest model, at 2.2B parameters, rivals state-of-the-art VLMs consuming twice the GPU memory. SmolVLM models extend beyond static images, demonstrating robust video comprehension capabilities.   Our results emphasize that strategic architectural optimizations, aggressive yet efficient tokenization, and carefully curated training data significantly enhance multimodal performance, facilitating practical, energy-efficient deployments at significantly smaller scales.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [SmolVLM: Redefining small and efficient multimodal models](https://arxiv.org/abs/2504.05299)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We introduce LiveVQA, an automatically collected dataset of latest visual knowledge from the Internet with synthesized VQA problems. LiveVQA consists of 3,602 single- and multi-hop visual questions from 6 news websites across 14 news categories, featuring high-quality image-text coherence and authentic information. Our evaluation across 15 MLLMs (e.g., GPT-4o, Gemma-3, and Qwen-2.5-VL family) demonstrates that stronger models perform better overall, with advanced visual reasoning capabilities proving crucial for complex multi-hop questions. Despite excellent performance on textual problems, models with tools like search engines still show significant gaps when addressing visual questions requiring latest visual knowledge, highlighting important areas for future research.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [LiveVQA: Live Visual Knowledge Seeking](https://arxiv.org/abs/2504.05288)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Recent studies have demonstrated that test-time compute scaling effectively improves the performance of small language models (sLMs). However, prior research has mainly examined test-time compute scaling with an additional larger model as a verifier, leaving self-verification by sLMs underexplored. In this work, we investigate whether sLMs can reliably self-verify their outputs under test-time scaling. We find that even with knowledge distillation from larger verifiers, sLMs struggle with verification tasks requiring memorization, such as numerical calculations and fact-checking. To address this limitation, we propose Tool-integrated self-verification (T1), which delegates memorization-heavy verification steps to external tools, such as a code interpreter. Our theoretical analysis shows that tool integration reduces memorization demands and improves test-time scaling performance. Experiments on the MATH benchmark demonstrate that, with T1, a Llama-3.2 1B model under test-time scaling outperforms the significantly larger Llama-3.1 8B model. Moreover, T1 generalizes effectively to both mathematical (MATH500) and multi-domain knowledge-intensive tasks (MMLU-Pro). Our findings highlight the potential of tool integration to substantially improve the self-verification abilities of sLMs.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [T1: Tool-integrated Self-verification for Test-time Compute Scaling in Small Language Models](https://arxiv.org/abs/2504.04718)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We introduce Clinical ModernBERT, a transformer based encoder pretrained on large scale biomedical literature, clinical notes, and medical ontologies, incorporating PubMed abstracts, MIMIC IV clinical data, and medical codes with their textual descriptions. Building on ModernBERT the current state of the art natural language text encoder featuring architectural upgrades such as rotary positional embeddings (RoPE), Flash Attention, and extended context length up to 8,192 tokens our model adapts these innovations specifically for biomedical and clinical domains. Clinical ModernBERT excels at producing semantically rich representations tailored for long context tasks. We validate this both by analyzing its pretrained weights and through empirical evaluation on a comprehensive suite of clinical NLP benchmarks.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Clinical ModernBERT: An efficient and long context encoder for biomedical text](https://arxiv.org/abs/2504.03964)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Vision Foundation Models (VFMs) and Vision-Language Models (VLMs) have gained traction in Domain Generalized Semantic Segmentation (DGSS) due to their strong generalization capabilities. However, existing DGSS methods often rely exclusively on either VFMs or VLMs, overlooking their complementary strengths. VFMs (e.g., DINOv2) excel at capturing fine-grained features, while VLMs (e.g., CLIP) provide robust text alignment but struggle with coarse granularity. Despite their complementary strengths, effectively integrating VFMs and VLMs with attention mechanisms is challenging, as the increased patch tokens complicate long-sequence modeling. To address this, we propose MFuser, a novel Mamba-based fusion framework that efficiently combines the strengths of VFMs and VLMs while maintaining linear scalability in sequence length. MFuser consists of two key components: MVFuser, which acts as a co-adapter to jointly fine-tune the two models by capturing both sequential and spatial dynamics; and MTEnhancer, a hybrid attention-Mamba module that refines text embeddings by incorporating image priors. Our approach achieves precise feature locality and strong text alignment without incurring significant computational overhead. Extensive experiments demonstrate that MFuser significantly outperforms state-of-the-art DGSS methods, achieving 68.20 mIoU on synthetic-to-real and 71.87 mIoU on real-to-real benchmarks. The code is available at https://github.com/devinxzhang/MFuser.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Mamba as a Bridge: Where Vision Foundation Models Meet Vision Language Models for Domain-Generalized Semantic Segmentation](https://arxiv.org/abs/2504.03193)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We present the evaluation methodology, datasets and results of the BOP Challenge 2024, the sixth in a series of public competitions organized to capture the state of the art in 6D object pose estimation and related tasks. In 2024, our goal was to transition BOP from lab-like setups to real-world scenarios. First, we introduced new model-free tasks, where no 3D object models are available and methods need to onboard objects just from provided reference videos. Second, we defined a new, more practical 6D object detection task where identities of objects visible in a test image are not provided as input. Third, we introduced new BOP-H3 datasets recorded with high-resolution sensors and AR/VR headsets, closely resembling real-world scenarios. BOP-H3 include 3D models and onboarding videos to support both model-based and model-free tasks. Participants competed on seven challenge tracks, each defined by a task, object onboarding setup, and dataset group. Notably, the best 2024 method for model-based 6D localization of unseen objects (FreeZeV2.1) achieves 22% higher accuracy on BOP-Classic-Core than the best 2023 method (GenFlow), and is only 4% behind the best 2023 method for seen objects (GPose2023) although being significantly slower (24.9 vs 2.7s per image). A more practical 2024 method for this task is Co-op which takes only 0.8s per image and is 25X faster and 13% more accurate than GenFlow. Methods have a similar ranking on 6D detection as on 6D localization but higher run time. On model-based 2D detection of unseen objects, the best 2024 method (MUSE) achieves 21% relative improvement compared to the best 2023 method (CNOS). However, the 2D detection accuracy for unseen objects is still noticealy (-53%) behind the accuracy for seen objects (GDet2023). The online evaluation system stays open and is available at http://bop.felk.cvut.cz/'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [BOP Challenge 2024 on Model-Based and Model-Free 6D Object Pose Estimation](https://arxiv.org/abs/2504.02812)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Tool-Augmented Larage Language Models (TA-LLMs) have shown promise in real-world applications, but face challenges in handling incomplete queries and out-of-scope requests. While existing approaches rely mainly on Supervised Fine-Tuning with expert trajectories, we propose DiaTool-DPO, a novel method that enhances TA-LLM's dialogue capabilities through Direct Preference Optimization. We model TA-LLM interactions as a Markov Decision Process with 5 distinct dialogue states and categorize user queries into 3 types based on their state transition trajectories. We automatically construct paired trajectory datasets of correct and incorrect dialogue flows and introduce a specialized objective loss for dialogue control. Our comprehensive evaluation demonstrates that DiaTool-DPO approaches GPT-4o's performance (94.8% in information gathering, 91% in tool call rejection) with substantial improvements over baseline (44% and 9.6% respectively) while maintaining core functionality. Our approach opens new possibilities for developing TA-LLMs that can handle diverse real-world scenarios without requiring additional expert demonstrations or human labeling."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [DiaTool-DPO: Multi-Turn Direct Preference Optimization for Tool-Augmented Large Language Models](https://arxiv.org/abs/2504.02882)
append_entries: 7
Finish: 2025-04-08 12:00:42.098417
------------------------------------------------------
Started: 2025-04-08 21:00:35.220321
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We present VAPO, Value-based Augmented Proximal Policy Optimization framework for reasoning models., a novel framework tailored for reasoning models within the value-based paradigm. Benchmarked the AIME 2024 dataset, VAPO, built on the Qwen 32B pre-trained model, attains a state-of-the-art score of 60.4. In direct comparison under identical experimental settings, VAPO outperforms the previously reported results of DeepSeek-R1-Zero-Qwen-32B and DAPO by more than 10 points. The training process of VAPO stands out for its stability and efficiency. It reaches state-of-the-art performance within a mere 5,000 steps. Moreover, across multiple independent runs, no training crashes occur, underscoring its reliability. This research delves into long chain-of-thought (long-CoT) reasoning using a value-based reinforcement learning framework. We pinpoint three key challenges that plague value-based methods: value model bias, the presence of heterogeneous sequence lengths, and the sparsity of reward signals. Through systematic design, VAPO offers an integrated solution that effectively alleviates these challenges, enabling enhanced performance in long-CoT reasoning tasks.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [VAPO: Efficient and Reliable Reinforcement Learning for Advanced Reasoning Tasks](https://arxiv.org/abs/2504.05118)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Large language models (LLMs) are advancing at an unprecedented pace globally, with regions increasingly adopting these models for applications in their primary language. Evaluation of these models in diverse linguistic environments, especially in low-resource languages, has become a major challenge for academia and industry. Existing evaluation frameworks are disproportionately focused on English and a handful of high-resource languages, thereby overlooking the realistic performance of LLMs in multilingual and lower-resource scenarios. To address this gap, we introduce GlotEval, a lightweight framework designed for massively multilingual evaluation. Supporting seven key tasks (machine translation, text classification, summarization, open-ended generation, reading comprehension, sequence labeling, and intrinsic evaluation), spanning over dozens to hundreds of languages, GlotEval highlights consistent multilingual benchmarking, language-specific prompt templates, and non-English-centric machine translation. This enables a precise diagnosis of model strengths and weaknesses in diverse linguistic contexts. A multilingual translation case study demonstrates GlotEval's applicability for multilingual and language-specific evaluations."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [GlotEval: A Test Suite for Massively Multilingual Evaluation of Large Language Models](https://arxiv.org/abs/2504.04155)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Large Language Models (LLMs) exhibit significant disparities in performance across languages, primarily benefiting high-resource languages while marginalizing underrepresented ones. Continual Pretraining (CPT) has emerged as a promising approach to address this imbalance, although the relative effectiveness of monolingual, bilingual, and code-augmented data strategies remains unclear. This study systematically evaluates 36 CPT configurations involving three multilingual base models, across 30+ languages categorized as altruistic, selfish, and stagnant, spanning various resource levels. Our findings reveal three major insights: (1) Bilingual CPT improves multilingual classification but often causes language mixing issues during generation. (2) Including programming code data during CPT consistently enhances multilingual classification accuracy, particularly benefiting low-resource languages, but introduces a trade-off by slightly degrading generation quality. (3) Contrary to prior work, we observe substantial deviations from language classifications according to their impact on cross-lingual transfer: Languages classified as altruistic often negatively affect related languages, selfish languages show conditional and configuration-dependent behavior, and stagnant languages demonstrate surprising adaptability under certain CPT conditions. These nuanced interactions emphasize the complexity of multilingual representation learning, underscoring the importance of systematic studies on generalizable language classification to inform future multilingual CPT strategies.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Rethinking Multilingual Continual Pretraining: Data Mixing for Adapting LLMs Across Languages and Resources](https://arxiv.org/abs/2504.04152)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "A language model's ability to reflect on its own reasoning provides a key advantage for solving complex problems. While most recent research has focused on how this ability develops during reinforcement learning, we show that it actually begins to emerge much earlier - during the model's pre-training. To study this, we introduce deliberate errors into chains-of-thought and test whether the model can still arrive at the correct answer by recognizing and correcting these mistakes. By tracking performance across different stages of pre-training, we observe that this self-correcting ability appears early and improves steadily over time. For instance, an OLMo2-7B model pre-trained on 4 trillion tokens displays self-correction on our six self-reflection tasks."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Rethinking Reflection in Pre-Training](https://arxiv.org/abs/2504.04022)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Reasoning is central to human intelligence, enabling structured problem-solving across diverse tasks. Recent advances in large language models (LLMs) have greatly enhanced their reasoning abilities in arithmetic, commonsense, and symbolic domains. However, effectively extending these capabilities into multimodal contexts-where models must integrate both visual and textual inputs-continues to be a significant challenge. Multimodal reasoning introduces complexities, such as handling conflicting information across modalities, which require models to adopt advanced interpretative strategies. Addressing these challenges involves not only sophisticated algorithms but also robust methodologies for evaluating reasoning accuracy and coherence. This paper offers a concise yet insightful overview of reasoning techniques in both textual and multimodal LLMs. Through a thorough and up-to-date comparison, we clearly formulate core reasoning challenges and opportunities, highlighting practical methods for post-training optimization and test-time inference. Our work provides valuable insights and guidance, bridging theoretical frameworks and practical implementations, and sets clear directions for future research.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Why Reasoning Matters? A Survey of Advancements in Multimodal Reasoning (v1)](https://arxiv.org/abs/2504.03151)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Increasing test-time computation has emerged as a promising direction for improving language model performance, particularly in scenarios where model finetuning is impractical or impossible due to computational constraints or private model weights. However, existing test-time search methods using a reward model (RM) often degrade in quality as compute scales, due to the over-optimization of what are inherently imperfect reward proxies. We introduce QAlign, a new test-time alignment approach. As we scale test-time compute, QAlign converges to sampling from the optimal aligned distribution for each individual prompt. By adopting recent advances in Markov chain Monte Carlo for text generation, our method enables better-aligned outputs without modifying the underlying model or even requiring logit access. We demonstrate the effectiveness of QAlign on mathematical reasoning benchmarks (GSM8K and GSM-Symbolic) using a task-specific RM, showing consistent improvements over existing test-time compute methods like best-of-n and majority voting. Furthermore, when applied with more realistic RMs trained on the Tulu 3 preference dataset, QAlign outperforms direct preference optimization (DPO), best-of-n, majority voting, and weighted majority voting on a diverse range of datasets (GSM8K, MATH500, IFEval, MMLU-Redux, and TruthfulQA). A practical solution to aligning language models at test time using additional computation without degradation, our approach expands the limits of the capability that can be obtained from off-the-shelf language models without further training.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Sample, Don't Search: Rethinking Test-Time Alignment for Language Models](https://arxiv.org/abs/2504.03790)
append_entries: 6
Finish: 2025-04-08 21:00:37.761212
------------------------------------------------------
Started: 2025-04-09 00:37:28.274262
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We present a novel approach for training small language models for reasoning-intensive document ranking that combines knowledge distillation with reinforcement learning optimization. While existing methods often rely on expensive human annotations or large black-box language models, our methodology leverages web data and a teacher LLM to automatically generate high-quality training examples with relevance explanations. By framing document ranking as a reinforcement learning problem and incentivizing explicit reasoning capabilities, we train a compact 3B parameter language model that achieves state-of-the-art performance on the BRIGHT benchmark. Our model ranks third on the leaderboard while using substantially fewer parameters than other approaches, outperforming models that are over 20 times larger. Through extensive experiments, we demonstrate that generating explanations during inference, rather than directly predicting relevance scores, enables more effective reasoning with smaller language models. The self-supervised nature of our method offers a scalable and interpretable solution for modern information retrieval systems.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Distillation and Refinement of Reasoning in Small Language Models for Document Re-ranking](https://arxiv.org/abs/2504.03947)
append_entries: 1
Finish: 2025-04-09 00:37:28.955994
------------------------------------------------------
Started: 2025-04-09 03:25:19.465915
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': '3D scene understanding from single images is a pivotal problem in computer vision with numerous downstream applications in graphics, augmented reality, and robotics. While diffusion-based modeling approaches have shown promise, they often struggle to maintain object and scene consistency, especially in complex real-world scenarios. To address these limitations, we propose an autoregressive generative approach called Local Random Access Sequence (LRAS) modeling, which uses local patch quantization and randomly ordered sequence generation. By utilizing optical flow as an intermediate representation for 3D scene editing, our experiments demonstrate that LRAS achieves state-of-the-art novel view synthesis and 3D object manipulation capabilities. Furthermore, we show that our framework naturally extends to self-supervised depth estimation through a simple modification of the sequence design. By achieving strong performance on multiple 3D scene understanding tasks, LRAS provides a unified and effective framework for building the next generation of 3D vision models.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [3D Scene Understanding Through Local Random Access Sequence Modeling](https://arxiv.org/abs/2504.03875)
append_entries: 1
Finish: 2025-04-09 03:25:20.019638
------------------------------------------------------
Started: 2025-04-09 06:11:36.424732
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-09 06:11:36.610027
------------------------------------------------------
Started: 2025-04-09 09:00:50.963965
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Scalable Vector Graphics (SVG) is an important image format widely adopted in graphic design because of their resolution independence and editability. The study of generating high-quality SVG has continuously drawn attention from both designers and researchers in the AIGC community. However, existing methods either produces unstructured outputs with huge computational cost or is limited to generating monochrome icons of over-simplified structures. To produce high-quality and complex SVG, we propose OmniSVG, a unified framework that leverages pre-trained Vision-Language Models (VLMs) for end-to-end multimodal SVG generation. By parameterizing SVG commands and coordinates into discrete tokens, OmniSVG decouples structural logic from low-level geometry for efficient training while maintaining the expressiveness of complex SVG structure. To further advance the development of SVG synthesis, we introduce MMSVG-2M, a multimodal dataset with two million richly annotated SVG assets, along with a standardized evaluation protocol for conditional SVG generation tasks. Extensive experiments show that OmniSVG outperforms existing methods and demonstrates its potential for integration into professional SVG design workflows.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [OmniSVG: A Unified Scalable Vector Graphics Generation Model](https://arxiv.org/abs/2504.06263)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Large Language Models (LLMs) have demonstrated the ability to tackle increasingly complex tasks through advanced reasoning, long-form content generation, and tool use. Solving these tasks often involves long inference-time computations. In human problem solving, a common strategy to expedite work is collaboration: by dividing the problem into sub-tasks, exploring different strategies concurrently, etc. Recent research has shown that LLMs can also operate in parallel by implementing explicit cooperation frameworks, such as voting mechanisms or the explicit creation of independent sub-tasks that can be executed in parallel. However, each of these frameworks may not be suitable for all types of tasks, which can hinder their applicability. In this work, we propose a different design approach: we run LLM "workers" in parallel , allowing them to synchronize via a concurrently-updated attention cache and prompt these workers to decide how best to collaborate. Our approach allows the instances to come up with their own collaboration strategy for the problem at hand, all the while "seeing" each other\'s partial progress in the concurrent cache. We implement this approach via Hogwild! Inference: a parallel LLM inference engine where multiple instances of the same LLM run in parallel with the same attention cache, with "instant" access to each other\'s generated tokens. Hogwild! inference takes advantage of Rotary Position Embeddings (RoPE) to avoid recomputation while improving parallel hardware utilization. We find that modern reasoning-capable LLMs can perform inference with shared Key-Value cache out of the box, without additional fine-tuning.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Hogwild! Inference: Parallel LLM Generation via Concurrent Attention](https://arxiv.org/abs/2504.06261)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "The landscape of image generation has rapidly evolved, from early GAN-based approaches to diffusion models and, most recently, to unified generative architectures that seek to bridge understanding and generation tasks. Recent advances, especially the GPT-4o, have demonstrated the feasibility of high-fidelity multimodal generation, their architectural design remains mysterious and unpublished. This prompts the question of whether image and text generation have already been successfully integrated into a unified framework for those methods. In this work, we conduct an empirical study of GPT-4o's image generation capabilities, benchmarking it against leading open-source and commercial models. Our evaluation covers four main categories, including text-to-image, image-to-image, image-to-3D, and image-to-X generation, with more than 20 tasks. Our analysis highlights the strengths and limitations of GPT-4o under various settings, and situates it within the broader evolution of generative modeling. Through this investigation, we identify promising directions for future unified generative models, emphasizing the role of architectural design and data scaling."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [An Empirical Study of GPT-4o Image Generation Capabilities](https://arxiv.org/abs/2504.05979)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We introduce Skywork R1V, a multimodal reasoning model extending the an R1-series Large language models (LLM) to visual modalities via an efficient multimodal transfer method. Leveraging a lightweight visual projector, Skywork R1V facilitates seamless multimodal adaptation without necessitating retraining of either the foundational language model or the vision encoder. To strengthen visual-text alignment, we propose a hybrid optimization strategy that combines Iterative Supervised Fine-Tuning (SFT) with Group Relative Policy Optimization (GRPO), significantly enhancing cross-modal integration efficiency. Additionally, we introduce an adaptive-length Chain-of-Thought distillation approach for reasoning data generation. This approach dynamically optimizes reasoning chain lengths, thereby enhancing inference efficiency and preventing excessive reasoning overthinking. Empirical evaluations demonstrate that Skywork R1V, with only 38B parameters, delivers competitive performance, achieving a score of 69.0 on the MMMU benchmark and 67.5 on MathVista. Meanwhile, it maintains robust textual reasoning performance, evidenced by impressive scores of 72.0 on AIME and 94.0 on MATH500. The Skywork R1V model weights have been publicly released to promote openness and reproducibility.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Skywork R1V: Pioneering Multimodal Reasoning with Chain-of-Thought](https://arxiv.org/abs/2504.05599)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Balancing fidelity and editability is essential in text-based image editing (TIE), where failures commonly lead to over- or under-editing issues. Existing methods typically rely on attention injections for structure preservation and leverage the inherent text alignment capabilities of pre-trained text-to-image (T2I) models for editability, but they lack explicit and unified mechanisms to properly balance these two objectives. In this work, we introduce UnifyEdit, a tuning-free method that performs diffusion latent optimization to enable a balanced integration of fidelity and editability within a unified framework. Unlike direct attention injections, we develop two attention-based constraints: a self-attention (SA) preservation constraint for structural fidelity, and a cross-attention (CA) alignment constraint to enhance text alignment for improved editability. However, simultaneously applying both constraints can lead to gradient conflicts, where the dominance of one constraint results in over- or under-editing. To address this challenge, we introduce an adaptive time-step scheduler that dynamically adjusts the influence of these constraints, guiding the diffusion latent toward an optimal balance. Extensive quantitative and qualitative experiments validate the effectiveness of our approach, demonstrating its superiority in achieving a robust balance between structure preservation and text alignment across various editing tasks, outperforming other state-of-the-art methods. The source code will be available at https://github.com/CUC-MIPG/UnifyEdit.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Tuning-Free Image Editing with Fidelity and Editability via Unified Latent Diffusion Model](https://arxiv.org/abs/2504.05594)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "With powerful large language models (LLMs) demonstrating superhuman reasoning capabilities, a critical question arises: Do LLMs genuinely reason, or do they merely recall answers from their extensive, web-scraped training datasets? Publicly released benchmarks inevitably become contaminated once incorporated into subsequent LLM training sets, undermining their reliability as faithful assessments. To address this, we introduce KUMO, a generative evaluation framework designed specifically for assessing reasoning in LLMs. KUMO synergistically combines LLMs with symbolic engines to dynamically produce diverse, multi-turn reasoning tasks that are partially observable and adjustable in difficulty. Through an automated pipeline, KUMO continuously generates novel tasks across open-ended domains, compelling models to demonstrate genuine generalization rather than memorization. We evaluated 23 state-of-the-art LLMs on 5,000 tasks across 100 domains created by KUMO, benchmarking their reasoning abilities against university students. Our findings reveal that many LLMs have outperformed university-level performance on easy reasoning tasks, and reasoning-scaled LLMs reach university-level performance on complex reasoning challenges. Moreover, LLM performance on KUMO tasks correlates strongly with results on newly released real-world reasoning benchmarks, underscoring KUMO's value as a robust, enduring assessment tool for genuine LLM reasoning capabilities."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Generative Evaluation of Complex Reasoning in Large Language Models](https://arxiv.org/abs/2504.02810)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Although subject-driven generation has been extensively explored in image generation due to its wide applications, it still has challenges in data scalability and subject expansibility. For the first challenge, moving from curating single-subject datasets to multiple-subject ones and scaling them is particularly difficult. For the second, most recent methods center on single-subject generation, making it hard to apply when dealing with multi-subject scenarios. In this study, we propose a highly-consistent data synthesis pipeline to tackle this challenge. This pipeline harnesses the intrinsic in-context generation capabilities of diffusion transformers and generates high-consistency multi-subject paired data. Additionally, we introduce UNO, which consists of progressive cross-modal alignment and universal rotary position embedding. It is a multi-image conditioned subject-to-image model iteratively trained from a text-to-image model. Extensive experiments show that our method can achieve high consistency while ensuring controllability in both single-subject and multi-subject driven generation.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Less-to-More Generalization: Unlocking More Controllability by In-Context Generation](https://arxiv.org/abs/2504.02160)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Existing reasoning evaluation frameworks for Large Language Models (LLMs) and Large Vision-Language Models (LVLMs) predominantly either assess text-based reasoning or vision-language understanding capabilities, with limited dynamic interplay between textual and visual constraints. To address this limitation, we introduce CrossWordBench, a benchmark designed to evaluate the reasoning capabilities of both LLMs and LVLMs through the medium of crossword puzzles-a task requiring multimodal adherence to semantic constraints from text-based clues and intersectional constraints from visual grid structures. CrossWordBench leverages a controllable puzzle generation framework that produces puzzles in multiple formats (text and image) and offers different evaluation strategies ranging from direct puzzle solving to interactive modes. Our extensive evaluation of over 20 models reveals that reasoning LLMs outperform non-reasoning models substantially by effectively leveraging crossing-letter constraints. We further demonstrate that LVLMs struggle with the task, showing a strong correlation between their puzzle-solving performance and grid-parsing accuracy. Our findings offer insights into the limitations of the reasoning capabilities of current LLMs and LVLMs, and provide an effective approach for creating multimodal constrained tasks for future evaluations.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [CrossWordBench: Evaluating the Reasoning Capabilities of LLMs and LVLMs with Controllable Puzzle Generation](https://arxiv.org/abs/2504.00043)
append_entries: 8
Finish: 2025-04-09 09:00:54.220862
------------------------------------------------------
Started: 2025-04-09 12:13:48.099561
Existing_entries: 1008
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Text-to-image (T2I) diffusion/flow models have drawn considerable attention recently due to their remarkable ability to deliver flexible visual creations. Still, high-resolution image synthesis presents formidable challenges due to the scarcity and complexity of high-resolution content. To this end, we present HiFlow, a training-free and model-agnostic framework to unlock the resolution potential of pre-trained flow models. Specifically, HiFlow establishes a virtual reference flow within the high-resolution space that effectively captures the characteristics of low-resolution flow information, offering guidance for high-resolution generation through three key aspects: initialization alignment for low-frequency consistency, direction alignment for structure preservation, and acceleration alignment for detail fidelity. By leveraging this flow-aligned guidance, HiFlow substantially elevates the quality of high-resolution image synthesis of T2I models and demonstrates versatility across their personalized variants. Extensive experiments validate HiFlow's superiority in achieving superior high-resolution image quality over current state-of-the-art methods."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [HiFlow: Training-free High-Resolution Image Generation with Flow-Aligned Guidance](https://arxiv.org/abs/2504.06232)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Recent advancements in Multimodal Large Language Models (MLLMs) have led to significant improvements across various multimodal benchmarks. However, as evaluations shift from static datasets to open-world, dynamic environments, current game-based benchmarks remain inadequate because they lack visual-centric tasks and fail to assess the diverse reasoning skills required for real-world decision-making. To address this, we introduce Visual-centric Multiple Abilities Game Evaluation (V-MAGE), a game-based evaluation framework designed to assess visual reasoning capabilities of MLLMs. V-MAGE features five diverse games with 30+ handcrafted levels, testing models on core visual skills such as positioning, trajectory tracking, timing, and visual memory, alongside higher-level reasoning like long-term planning and deliberation. We use V-MAGE to evaluate leading MLLMs, revealing significant challenges in their visual perception and reasoning. In all game environments, the top-performing MLLMs, as determined by Elo rating comparisons, exhibit a substantial performance gap compared to humans. Our findings highlight critical limitations, including various types of perceptual errors made by the models, and suggest potential avenues for improvement from an agent-centric perspective, such as refining agent strategies and addressing perceptual inaccuracies. Code is available at https://github.com/CSU-JPG/V-MAGE.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [V-MAGE: A Game Evaluation Framework for Assessing Visual-Centric Capabilities in Multimodal Large Language Models](https://arxiv.org/abs/2504.06148)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Aligning large language models (LLMs) with human preferences has achieved remarkable success. However, existing Chinese preference datasets are limited by small scale, narrow domain coverage, and lack of rigorous data validation. Additionally, the reliance on human annotators for instruction and response labeling significantly constrains the scalability of human preference datasets. To address these challenges, we design an LLM-based Chinese preference dataset annotation pipeline with no human intervention. Specifically, we crawled and carefully filtered 92k high-quality Chinese queries and employed 15 mainstream LLMs to generate and score chosen-rejected response pairs. Based on it, we introduce COIG-P (Chinese Open Instruction Generalist - Preference), a high-quality, large-scale Chinese preference dataset, comprises 1,009k Chinese preference pairs spanning 6 diverse domains: Chat, Code, Math, Logic, Novel, and Role. Building upon COIG-P, to reduce the overhead of using LLMs for scoring, we trained a 8B-sized Chinese Reward Model (CRM) and meticulously constructed a Chinese Reward Benchmark (CRBench). Evaluation results based on AlignBench liu2024alignbenchbenchmarkingchinesealignment show that that COIG-P significantly outperforms other Chinese preference datasets, and it brings significant performance improvements ranging from 2% to 12% for the Qwen2/2.5 and Infinity-Instruct-3M-0625 model series, respectively. The results on CRBench demonstrate that our CRM has a strong and robust scoring ability. We apply it to filter chosen-rejected response pairs in a test split of COIG-P, and our experiments show that it is comparable to GPT-4o in identifying low-quality samples while maintaining efficiency and cost-effectiveness. Our codes and data are released in https://github.com/multimodal-art-projection/COIG-P.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [COIG-P: A High-Quality and Large-Scale Chinese Preference Dataset for Alignment with Human Values](https://arxiv.org/abs/2504.05535)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Recent advances in reasoning models have demonstrated significant improvements in accuracy, particularly for complex tasks such as mathematical reasoning, by employing detailed and comprehensive reasoning processes. However, generating these lengthy reasoning sequences is computationally expensive and time-consuming. To address this inefficiency, we leverage the inherent parallelizability of certain tasks to accelerate the reasoning process. Specifically, when multiple parallel reasoning branches exist, we decode multiple tokens per step using a specialized attention mask, processing them within a single sequence, avoiding additional memory usage. Experimental results show that our method achieves over 100% speedup in decoding time while maintaining the answer quality.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Accelerate Parallelizable Reasoning via Parallel Decoding within One Sequence](https://arxiv.org/abs/2503.20533)
append_entries: 4
Finish: 2025-04-09 12:13:50.618174
------------------------------------------------------
Started: 2025-04-09 15:01:16.919240
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-09 15:01:17.128291
------------------------------------------------------
Started: 2025-04-09 18:11:01.716518
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Recent advances in automated theorem proving (ATP) through LLMs have highlighted the potential of formal reasoning with Lean 4 codes. However, ATP has not yet be revolutionized by the recent posttraining scaling as demonstrated by Open AI O1/O3 and Deepseek R1. In this work, we investigate the entire posttraining of ATP, aiming to align it with breakthroughs in reasoning models in natural languages.To begin, we continual train current ATP models with a hybrid dataset, which consists of numerous statement-proof pairs, and additional data aimed at incorporating cognitive behaviors that emulate human reasoning and hypothesis refinement. Next, we explore reinforcement learning with the use of outcome reward returned by Lean 4 compiler. Through our designed continual training and reinforcement learning processes, we have successfully improved existing formal provers, including both DeepSeek-Prover-v1.5 and Goedel-Prover, achieving state-of-the-art performance in the field of whole-proof generation. For example, we achieve a 59.8% pass rate (pass@32) on MiniF2F. This is an on-going project and we will progressively update our findings, release our data and training details.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Leanabell-Prover: Posttraining Scaling in Formal Reasoning](https://arxiv.org/abs/2504.06122)
append_entries: 1
Finish: 2025-04-09 18:11:02.436421
------------------------------------------------------
Started: 2025-04-09 21:00:34.527164
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'The Mixture of Experts (MoE) architecture has demonstrated significant advantages as it enables to increase the model capacity without a proportional increase in computation. However, the large MoE model size still introduces substantial memory demands, which usually requires expert offloading on resource-constrained platforms and incurs significant overhead. Hybrid CPU-GPU inference has been proposed to leverage CPU computation to reduce expert loading overhead but faces major challenges: on one hand, the expert activation patterns of MoE models are highly unstable, rendering the fixed mapping strategies in existing works inefficient; on the other hand, the hybrid CPU-GPU schedule for MoE is inherently complex due to the diverse expert sizes, structures, uneven workload distribution, etc. To address these challenges, in this paper, we propose HybriMoE, a hybrid CPU-GPU inference framework that improves resource utilization through a novel CPU-GPU scheduling and cache management system. HybriMoE introduces (i) a dynamic intra-layer scheduling strategy to balance workloads across CPU and GPU, (ii) an impact-driven inter-layer prefetching algorithm, and (iii) a score-based caching algorithm to mitigate expert activation instability. We implement HybriMoE on top of the kTransformers framework and evaluate it on three widely used MoE-based LLMs. Experimental results demonstrate that HybriMoE achieves an average speedup of 1.33times in the prefill stage and 1.70times in the decode stage compared to state-of-the-art hybrid MoE inference framework. Our code is available at: https://github.com/PKU-SEC-Lab/HybriMoE.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [HybriMoE: Hybrid CPU-GPU Scheduling and Cache Management for Efficient MoE Inference](https://arxiv.org/abs/2504.05897)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Reinforcement finetuning (RFT) has shown great potential for enhancing the mathematical reasoning capabilities of large language models (LLMs), but it is often sample- and compute-inefficient, requiring extensive training. In this work, we introduce AdaRFT (Adaptive Curriculum Reinforcement Finetuning), a method that significantly improves both the efficiency and final accuracy of RFT through adaptive curriculum learning. AdaRFT dynamically adjusts the difficulty of training problems based on the model's recent reward signals, ensuring that the model consistently trains on tasks that are challenging but solvable. This adaptive sampling strategy accelerates learning by maintaining an optimal difficulty range, avoiding wasted computation on problems that are too easy or too hard. AdaRFT requires only a lightweight extension to standard RFT algorithms like Proximal Policy Optimization (PPO), without modifying the reward function or model architecture. Experiments on competition-level math datasets-including AMC, AIME, and IMO-style problems-demonstrate that AdaRFT significantly improves both training efficiency and reasoning performance. We evaluate AdaRFT across multiple data distributions and model sizes, showing that it reduces the number of training steps by up to 2x and improves accuracy by a considerable margin, offering a more scalable and effective RFT framework."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Efficient Reinforcement Finetuning via Adaptive Curriculum Learning](https://arxiv.org/abs/2504.05520)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Generalized category discovery (GCD) is a pragmatic but underexplored problem, which requires models to automatically cluster and discover novel categories by leveraging the labeled samples from old classes. The challenge is that unlabeled data contain both old and new classes. Early works leveraging pseudo-labeling with parametric classifiers handle old and new classes separately, which brings about imbalanced accuracy between them. Recent methods employing contrastive learning neglect potential positives and are decoupled from the clustering objective, leading to biased representations and sub-optimal results. To address these issues, we introduce a unified and unbiased prototype learning framework, namely ProtoGCD, wherein old and new classes are modeled with joint prototypes and unified learning objectives, {enabling unified modeling between old and new classes}. Specifically, we propose a dual-level adaptive pseudo-labeling mechanism to mitigate confirmation bias, together with two regularization terms to collectively help learn more suitable representations for GCD. Moreover, for practical considerations, we devise a criterion to estimate the number of new classes. Furthermore, we extend ProtoGCD to detect unseen outliers, achieving task-level unification. Comprehensive experiments show that ProtoGCD achieves state-of-the-art performance on both generic and fine-grained datasets. The code is available at https://github.com/mashijie1028/ProtoGCD.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [ProtoGCD: Unified and Unbiased Prototype Learning for Generalized Category Discovery](https://arxiv.org/abs/2504.03755)
append_entries: 3
Finish: 2025-04-09 21:00:36.090386
------------------------------------------------------
Started: 2025-04-10 00:37:15.122967
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-10 00:37:15.403780
------------------------------------------------------
Started: 2025-04-10 03:25:44.698861
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-10 03:26:04.666102
------------------------------------------------------
Started: 2025-04-10 06:11:27.003331
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Diffusion transformers have demonstrated remarkable generation quality, albeit requiring longer training iterations and numerous inference steps. In each denoising step, diffusion transformers encode the noisy inputs to extract the lower-frequency semantic component and then decode the higher frequency with identical modules. This scheme creates an inherent optimization dilemma: encoding low-frequency semantics necessitates reducing high-frequency components, creating tension between semantic encoding and high-frequency decoding. To resolve this challenge, we propose a new \\color{ddtD}ecoupled \\color{ddtD}iffusion \\color{ddtT}ransformer~(\\color{ddtDDT}), with a decoupled design of a dedicated condition encoder for semantic extraction alongside a specialized velocity decoder. Our experiments reveal that a more substantial encoder yields performance improvements as model size increases. For ImageNet 256times256, Our DDT-XL/2 achieves a new state-of-the-art performance of {1.31 FID}~(nearly 4times faster training convergence compared to previous diffusion transformers). For ImageNet 512times512, Our DDT-XL/2 achieves a new state-of-the-art FID of 1.28. Additionally, as a beneficial by-product, our decoupled architecture enhances inference speed by enabling the sharing self-condition between adjacent denoising steps. To minimize performance degradation, we propose a novel statistical dynamic programming approach to identify optimal sharing strategies.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [DDT: Decoupled Diffusion Transformer](https://arxiv.org/abs/2504.05741)
append_entries: 1
Finish: 2025-04-10 06:11:27.801978
------------------------------------------------------
Started: 2025-04-10 09:00:35.370528
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We present OLMoTrace, the first system that traces the outputs of language models back to their full, multi-trillion-token training data in real time. OLMoTrace finds and shows verbatim matches between segments of language model output and documents in the training text corpora. Powered by an extended version of infini-gram (Liu et al., 2024), our system returns tracing results within a few seconds. OLMoTrace can help users understand the behavior of language models through the lens of their training data. We showcase how it can be used to explore fact checking, hallucination, and the creativity of language models. OLMoTrace is publicly available and fully open-source.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [OLMoTrace: Tracing Language Model Outputs Back to Trillions of Training Tokens](https://arxiv.org/abs/2504.07096)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Camera trajectory design plays a crucial role in video production, serving as a fundamental tool for conveying directorial intent and enhancing visual storytelling. In cinematography, Directors of Photography meticulously craft camera movements to achieve expressive and intentional framing. However, existing methods for camera trajectory generation remain limited: Traditional approaches rely on geometric optimization or handcrafted procedural systems, while recent learning-based methods often inherit structural biases or lack textual alignment, constraining creative synthesis. In this work, we introduce an auto-regressive model inspired by the expertise of Directors of Photography to generate artistic and expressive camera trajectories. We first introduce DataDoP, a large-scale multi-modal dataset containing 29K real-world shots with free-moving camera trajectories, depth maps, and detailed captions in specific movements, interaction with the scene, and directorial intent. Thanks to the comprehensive and diverse database, we further train an auto-regressive, decoder-only Transformer for high-quality, context-aware camera movement generation based on text guidance and RGBD inputs, named GenDoP. Extensive experiments demonstrate that compared to existing methods, GenDoP offers better controllability, finer-grained trajectory adjustments, and higher motion stability. We believe our approach establishes a new standard for learning-based cinematography, paving the way for future advancements in camera control and filmmaking. Our project website: https://kszpxxzmc.github.io/GenDoP/.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [GenDoP: Auto-regressive Camera Trajectory Generation as a Director of Photography](https://arxiv.org/abs/2504.07083)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "We find that the response length of reasoning LLMs, whether trained by reinforcement learning or supervised learning, drastically increases for ill-posed questions with missing premises (MiP), ending up with redundant and ineffective thinking. This newly introduced scenario exacerbates the general overthinking issue to a large extent, which we name as the MiP-Overthinking. Such failures are against the ``test-time scaling law'' but have been widely observed on multiple datasets we curated with MiP, indicating the harm of cheap overthinking and a lack of critical thinking. Surprisingly, LLMs not specifically trained for reasoning exhibit much better performance on the MiP scenario, producing much shorter responses that quickly identify ill-posed queries. This implies a critical flaw of the current training recipe for reasoning LLMs, which does not encourage efficient thinking adequately, leading to the abuse of thinking patterns. To further investigate the reasons behind such failures, we conduct fine-grained analyses of the reasoning length, overthinking patterns, and location of critical thinking on different types of LLMs. Moreover, our extended ablation study reveals that the overthinking is contagious through the distillation of reasoning models' responses. These results improve the understanding of overthinking and shed novel insights into mitigating the problem."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Missing Premise exacerbates Overthinking: Are Reasoning Models losing Critical Thinking Skill?](https://arxiv.org/abs/2504.06514)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Creating a realistic animatable avatar from a single static portrait remains challenging. Existing approaches often struggle to capture subtle facial expressions, the associated global body movements, and the dynamic background. To address these limitations, we propose a novel framework that leverages a pretrained video diffusion transformer model to generate high-fidelity, coherent talking portraits with controllable motion dynamics. At the core of our work is a dual-stage audio-visual alignment strategy. In the first stage, we employ a clip-level training scheme to establish coherent global motion by aligning audio-driven dynamics across the entire scene, including the reference portrait, contextual objects, and background. In the second stage, we refine lip movements at the frame level using a lip-tracing mask, ensuring precise synchronization with audio signals. To preserve identity without compromising motion flexibility, we replace the commonly used reference network with a facial-focused cross-attention module that effectively maintains facial consistency throughout the video. Furthermore, we integrate a motion intensity modulation module that explicitly controls expression and body motion intensity, enabling controllable manipulation of portrait movements beyond mere lip motion. Extensive experimental results show that our proposed approach achieves higher quality with better realism, coherence, motion intensity, and identity preservation. Ours project page: https://fantasy-amap.github.io/fantasy-talking/.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [FantasyTalking: Realistic Talking Portrait Generation via Coherent Motion Synthesis](https://arxiv.org/abs/2504.04842)
append_entries: 4
Finish: 2025-04-10 09:00:37.158957
------------------------------------------------------
Started: 2025-04-10 12:00:42.980906
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We propose OmniCaptioner, a versatile visual captioning framework for generating fine-grained textual descriptions across a wide variety of visual domains. Unlike prior methods limited to specific image types (e.g., natural images or geometric visuals), our framework provides a unified solution for captioning natural images, visual text (e.g., posters, UIs, textbooks), and structured visuals (e.g., documents, tables, charts). By converting low-level pixel information into semantically rich textual representations, our framework bridges the gap between visual and textual modalities. Our results highlight three key advantages: (i) Enhanced Visual Reasoning with LLMs, where long-context captions of visual modalities empower LLMs, particularly the DeepSeek-R1 series, to reason effectively in multimodal scenarios; (ii) Improved Image Generation, where detailed captions improve tasks like text-to-image generation and image transformation; and (iii) Efficient Supervised Fine-Tuning (SFT), which enables faster convergence with less data. We believe the versatility and adaptability of OmniCaptioner can offer a new perspective for bridging the gap between language and visual modalities.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [OmniCaptioner: One Captioner to Rule Them All](https://arxiv.org/abs/2504.07089)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Reasoning has emerged as the next major frontier for language models (LMs), with rapid advances from both academic and industrial labs. However, this progress often outpaces methodological rigor, with many evaluations relying on benchmarking practices that lack transparency, robustness, or statistical grounding. In this work, we conduct a comprehensive empirical study and find that current mathematical reasoning benchmarks are highly sensitive to subtle implementation choices - including decoding parameters, random seeds, prompt formatting, and even hardware and software-framework configurations. Performance gains reported in recent studies frequently hinge on unclear comparisons or unreported sources of variance. To address these issues, we propose a standardized evaluation framework with clearly defined best practices and reporting standards. Using this framework, we reassess recent methods and find that reinforcement learning (RL) approaches yield only modest improvements - far below prior claims - and are prone to overfitting, especially on small-scale benchmarks like AIME24. In contrast, supervised finetuning (SFT) methods show consistently stronger generalization. To foster reproducibility, we release all code, prompts, and model outputs, for reasoning benchmarks, establishing more rigorous foundations for future work.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [A Sober Look at Progress in Language Model Reasoning: Pitfalls and Paths to Reproducibility](https://arxiv.org/abs/2504.07086)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Robust grasping of various objects from single-view perception is fundamental for dexterous robots. Previous works often rely on fully observable objects, expert demonstrations, or static grasping poses, which restrict their generalization ability and adaptability to external disturbances. In this paper, we present a reinforcement-learning-based framework that enables zero-shot dynamic dexterous grasping of a wide range of unseen objects from single-view perception, while performing adaptive motions to external disturbances. We utilize a hand-centric object representation for shape feature extraction that emphasizes interaction-relevant local shapes, enhancing robustness to shape variance and uncertainty. To enable effective hand adaptation to disturbances with limited observations, we propose a mixed curriculum learning strategy, which first utilizes imitation learning to distill a policy trained with privileged real-time visual-tactile feedback, and gradually transfers to reinforcement learning to learn adaptive motions under disturbances caused by observation noises and dynamic randomization. Our experiments demonstrate strong generalization in grasping unseen objects with random poses, achieving success rates of 97.0% across 247,786 simulated objects and 94.6% across 512 real objects. We also demonstrate the robustness of our method to various disturbances, including unobserved object movement and external forces, through both quantitative and qualitative evaluations. Project Page: https://zdchan.github.io/Robust_DexGrasp/'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [RobustDexGrasp: Robust Dexterous Grasping of General Objects from Single-view Perception](https://arxiv.org/abs/2504.05287)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Generating naturalistic and nuanced listener motions for extended interactions remains an open problem. Existing methods often rely on low-dimensional motion codes for facial behavior generation followed by photorealistic rendering, limiting both visual fidelity and expressive richness. To address these challenges, we introduce DiTaiListener, powered by a video diffusion model with multimodal conditions. Our approach first generates short segments of listener responses conditioned on the speaker's speech and facial motions with DiTaiListener-Gen. It then refines the transitional frames via DiTaiListener-Edit for a seamless transition. Specifically, DiTaiListener-Gen adapts a Diffusion Transformer (DiT) for the task of listener head portrait generation by introducing a Causal Temporal Multimodal Adapter (CTM-Adapter) to process speakers' auditory and visual cues. CTM-Adapter integrates speakers' input in a causal manner into the video generation process to ensure temporally coherent listener responses. For long-form video generation, we introduce DiTaiListener-Edit, a transition refinement video-to-video diffusion model. The model fuses video segments into smooth and continuous videos, ensuring temporal consistency in facial expressions and image quality when merging short video segments produced by DiTaiListener-Gen. Quantitatively, DiTaiListener achieves the state-of-the-art performance on benchmark datasets in both photorealism (+73.8% in FID on RealTalk) and motion representation (+6.1% in FD metric on VICO) spaces. User studies confirm the superior performance of DiTaiListener, with the model being the clear preference in terms of feedback, diversity, and smoothness, outperforming competitors by a significant margin."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [DiTaiListener: Controllable High Fidelity Listener Video Generation with Diffusion](https://arxiv.org/abs/2504.04010)
append_entries: 4
Finish: 2025-04-10 12:00:44.673149
------------------------------------------------------
Started: 2025-04-10 15:00:47.410532
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Object-centric learning (OCL) seeks to learn representations that only encode an object, isolated from other objects or background cues in a scene. This approach underpins various aims, including out-of-distribution (OOD) generalization, sample-efficient composition, and modeling of structured environments. Most research has focused on developing unsupervised mechanisms that separate objects into discrete slots in the representation space, evaluated using unsupervised object discovery. However, with recent sample-efficient segmentation models, we can separate objects in the pixel space and encode them independently. This achieves remarkable zero-shot performance on OOD object discovery benchmarks, is scalable to foundation models, and can handle a variable number of slots out-of-the-box. Hence, the goal of OCL methods to obtain object-centric representations has been largely achieved. Despite this progress, a key question remains: How does the ability to separate objects within a scene contribute to broader OCL objectives, such as OOD generalization? We address this by investigating the OOD generalization challenge caused by spurious background cues through the lens of OCL. We propose a novel, training-free probe called Object-Centric Classification with Applied Masks (OCCAM), demonstrating that segmentation-based encoding of individual objects significantly outperforms slot-based OCL methods. However, challenges in real-world applications remain. We provide the toolbox for the OCL community to use scalable object-centric representations, and focus on practical applications and fundamental questions, such as understanding object perception in human cognition. Our code is available https://github.com/AlexanderRubinstein/OCCAM{here}.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Are We Done with Object-Centric Learning?](https://arxiv.org/abs/2504.07092)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'While test-time reasoning enables language models to tackle complex tasks, searching or planning in natural language can be slow, costly, and error-prone. But even when LMs struggle to emulate the precise reasoning steps needed to solve a problem, they often excel at describing its abstract structure--both how to verify solutions and how to search for them. This paper introduces DisCIPL, a method for "self-steering" LMs where a Planner model generates a task-specific inference program that is executed by a population of Follower models. Our approach equips LMs with the ability to write recursive search procedures that guide LM inference, enabling new forms of verifiable and efficient reasoning. When instantiated with a small Follower (e.g., Llama-3.2-1B), DisCIPL matches (and sometimes outperforms) much larger models, including GPT-4o and o1, on challenging constrained generation tasks. In decoupling planning from execution, our work opens up a design space of highly-parallelized Monte Carlo inference strategies that outperform standard best-of-N sampling, require no finetuning, and can be implemented automatically by existing LMs.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Self-Steering Language Models](https://arxiv.org/abs/2504.07081)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Conditional image generation has gained significant attention for its ability to personalize content. However, the field faces challenges in developing task-agnostic, reliable, and explainable evaluation metrics. This paper introduces CIGEval, a unified agentic framework for comprehensive evaluation of conditional image generation tasks. CIGEval utilizes large multimodal models (LMMs) as its core, integrating a multi-functional toolbox and establishing a fine-grained evaluation framework. Additionally, we synthesize evaluation trajectories for fine-tuning, empowering smaller LMMs to autonomously select appropriate tools and conduct nuanced analyses based on tool outputs. Experiments across seven prominent conditional image generation tasks demonstrate that CIGEval (GPT-4o version) achieves a high correlation of 0.4625 with human assessments, closely matching the inter-annotator correlation of 0.47. Moreover, when implemented with 7B open-source LMMs using only 2.3K training trajectories, CIGEval surpasses the previous GPT-4o-based state-of-the-art method. Case studies on GPT-4o image generation highlight CIGEval's capability in identifying subtle issues related to subject consistency and adherence to control guidance, indicating its great potential for automating evaluation of image generation tasks with human-level reliability."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [A Unified Agentic Framework for Evaluating Conditional Image Generation](https://arxiv.org/abs/2504.07046)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Recent advancements in reinforcement learning have significantly advanced the reasoning capabilities of multimodal large language models (MLLMs). While approaches such as Group Relative Policy Optimization (GRPO) and rule-based reward mechanisms demonstrate promise in text and image domains, their application to video understanding remains limited. This paper presents a systematic exploration of Reinforcement Fine-Tuning (RFT) with GRPO for video MLLMs, aiming to enhance spatio-temporal perception while maintaining general capabilities. Our experiments reveal that RFT is highly data-efficient for task-specific improvements. Through multi-task RFT on spatio-temporal perception objectives with limited samples, we develop VideoChat-R1, a powerful video MLLM that achieves state-of-the-art performance on spatio-temporal perception tasks without sacrificing chat ability, while exhibiting emerging spatio-temporal reasoning abilities. Compared to Qwen2.5-VL-7B, VideoChat-R1 boosts performance several-fold in tasks like temporal grounding (+31.8) and object tracking (+31.2). Additionally, it significantly improves on general QA benchmarks such as VideoMME (+0.9), MVBench (+1.0), and Perception Test (+0.9). Our findings underscore the potential of RFT for specialized task enhancement of Video MLLMs. We hope our work offers valuable insights for future RL research in video MLLMs.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [VideoChat-R1: Enhancing Spatio-Temporal Perception via Reinforcement Fine-Tuning](https://arxiv.org/abs/2504.06958)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'In this paper, we introduce the Dialogue Evaluation shared task on extraction of structured opinions from Russian news texts. The task of the contest is to extract opinion tuples for a given sentence; the tuples are composed of a sentiment holder, its target, an expression and sentiment from the holder to the target. In total, the task received more than 100 submissions. The participants experimented mainly with large language models in zero-shot, few-shot and fine-tuning formats. The best result on the test set was obtained with fine-tuning of a large language model. We also compared 30 prompts and 11 open source language models with 3-32 billion parameters in the 1-shot and 10-shot settings and found the best models and prompts.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [RuOpinionNE-2024: Extraction of Opinion Tuples from Russian News Texts](https://arxiv.org/abs/2504.06947)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Self-supervised learning has transformed 2D computer vision by enabling models trained on large, unannotated datasets to provide versatile off-the-shelf features that perform similarly to models trained with labels. However, in 3D scene understanding, self-supervised methods are typically only used as a weight initialization step for task-specific fine-tuning, limiting their utility for general-purpose feature extraction. This paper addresses this shortcoming by proposing a robust evaluation protocol specifically designed to assess the quality of self-supervised features for 3D scene understanding. Our protocol uses multi-resolution feature sampling of hierarchical models to create rich point-level representations that capture the semantic capabilities of the model and, hence, are suitable for evaluation with linear probing and nearest-neighbor methods. Furthermore, we introduce the first self-supervised model that performs similarly to supervised models when only off-the-shelf features are used in a linear probing setup. In particular, our model is trained natively in 3D with a novel self-supervised approach based on a Masked Scene Modeling objective, which reconstructs deep features of masked patches in a bottom-up manner and is specifically tailored to hierarchical 3D models. Our experiments not only demonstrate that our method achieves competitive performance to supervised models, but also surpasses existing self-supervised approaches by a large margin. The model and training code can be found at our Github repository (https://github.com/phermosilla/msm).'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Masked Scene Modeling: Narrowing the Gap Between Supervised and Self-Supervised Learning in 3D Scene Understanding](https://arxiv.org/abs/2504.06719)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "We present WildGS-SLAM, a robust and efficient monocular RGB SLAM system designed to handle dynamic environments by leveraging uncertainty-aware geometric mapping. Unlike traditional SLAM systems, which assume static scenes, our approach integrates depth and uncertainty information to enhance tracking, mapping, and rendering performance in the presence of moving objects. We introduce an uncertainty map, predicted by a shallow multi-layer perceptron and DINOv2 features, to guide dynamic object removal during both tracking and mapping. This uncertainty map enhances dense bundle adjustment and Gaussian map optimization, improving reconstruction accuracy. Our system is evaluated on multiple datasets and demonstrates artifact-free view synthesis. Results showcase WildGS-SLAM's superior performance in dynamic environments compared to state-of-the-art methods."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [WildGS-SLAM: Monocular Gaussian Splatting SLAM in Dynamic Environments](https://arxiv.org/abs/2504.03886)
append_entries: 7
Finish: 2025-04-10 15:00:51.513628
------------------------------------------------------
Started: 2025-04-10 18:10:54.185505
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "We present CAT-V (Caption AnyThing in Video), a training-free framework for fine-grained object-centric video captioning that enables detailed descriptions of user-selected objects through time. CAT-V integrates three key components: a Segmenter based on SAMURAI for precise object segmentation across frames, a Temporal Analyzer powered by TRACE-Uni for accurate event boundary detection and temporal analysis, and a Captioner using InternVL-2.5 for generating detailed object-centric descriptions. Through spatiotemporal visual prompts and chain-of-thought reasoning, our framework generates detailed, temporally-aware descriptions of objects' attributes, actions, statuses, interactions, and environmental contexts without requiring additional training data. CAT-V supports flexible user interactions through various visual prompts (points, bounding boxes, and irregular regions) and maintains temporal sensitivity by tracking object states and interactions across different time segments. Our approach addresses limitations of existing video captioning methods, which either produce overly abstract descriptions or lack object-level precision, enabling fine-grained, object-specific descriptions while maintaining temporal coherence and spatial accuracy. The GitHub repository for this project is available at https://github.com/yunlong10/CAT-V"}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Caption Anything in Video: Fine-grained Object-centric Captioning via Spatiotemporal Multimodal Prompting](https://arxiv.org/abs/2504.05541)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Large language models (LLMs) have shown potential as tools for scientific discovery. This has engendered growing interest in their use in humanistic disciplines, such as historical linguistics and literary studies. These fields often construct arguments on the basis of delineations like genre, or more inflexibly, time period. Although efforts have been made to restrict inference to specific domains via fine-tuning or model editing, we posit that the only true guarantee is domain-restricted pretraining -- typically, a data- and compute-expensive proposition.   We show that efficient pretraining techniques can produce useful models over corpora too large for easy manual inspection but too small for "typical" LLM approaches. We employ a novel date-attribution pipeline in order to obtain a temporally-segmented dataset of five 10-million-word slices. We train two corresponding five-model batteries over these corpus segments, efficient pretraining and Llama3-8B parameter efficiently finetuned.   We find that the pretrained models are faster to train than the finetuned baselines and that they better respect the historical divisions of our corpus. Emphasizing speed and precision over a-historical comprehensiveness enables a number of novel approaches to hypothesis discovery and testing in our target fields. Taking up diachronic linguistics as a testbed, we show that our method enables the detection of a diverse set of phenomena, including en masse lexical change, non-lexical (grammatical and morphological) change, and word sense introduction/obsolescence. We provide a ready-to-use pipeline that allows extension of our approach to other target fields with only minimal adaptation.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Pretraining Language Models for Diachronic Linguistic Change Discovery](https://arxiv.org/abs/2504.05523)
append_entries: 2
Finish: 2025-04-10 18:10:55.298961
------------------------------------------------------
Started: 2025-04-10 21:00:43.456062
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-10 21:00:43.696041
------------------------------------------------------
Started: 2025-04-11 00:37:49.049368
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "The dominant approach to generating from language models subject to some constraint is locally constrained decoding (LCD), incrementally sampling tokens at each time step such that the constraint is never violated. Typically, this is achieved through token masking: looping over the vocabulary and excluding non-conforming tokens. There are two important problems with this approach. (i) Evaluating the constraint on every token can be prohibitively expensive -- LM vocabularies often exceed 100,000 tokens. (ii) LCD can distort the global distribution over strings, sampling tokens based only on local information, even if they lead down dead-end paths. This work introduces a new algorithm that addresses both these problems. First, to avoid evaluating a constraint on the full vocabulary at each step of generation, we propose an adaptive rejection sampling algorithm that typically requires orders of magnitude fewer constraint evaluations. Second, we show how this algorithm can be extended to produce low-variance, unbiased estimates of importance weights at a very small additional cost -- estimates that can be soundly used within previously proposed sequential Monte Carlo algorithms to correct for the myopic behavior of local constraint enforcement. Through extensive empirical evaluation in text-to-SQL, molecular synthesis, goal inference, pattern matching, and JSON domains, we show that our approach is superior to state-of-the-art baselines, supporting a broader class of constraints and improving both runtime and performance. Additional theoretical and empirical analyses show that our method's runtime efficiency is driven by its dynamic use of computation, scaling with the divergence between the unconstrained and constrained LM, and as a consequence, runtime improvements are greater for better models."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Fast Controlled Generation from Language Models with Adaptive Weighted Rejection Sampling](https://arxiv.org/abs/2504.05410)
append_entries: 1
Finish: 2025-04-11 00:38:05.905068
------------------------------------------------------
Started: 2025-04-11 03:25:34.875008
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-11 03:25:35.112601
------------------------------------------------------
Started: 2025-04-11 06:00:37.699038
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-11 06:00:37.900842
------------------------------------------------------
Started: 2025-04-11 09:00:56.203643
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Mixture-of-Experts (MoE) Large Language Models (LLMs) suffer from severely sub-optimal expert pathways-our study reveals that naive expert selection learned from pretraining leaves a surprising 10-20% accuracy gap for improvement. Motivated by this observation, we develop a novel class of test-time optimization methods to re-weight or "re-mixing" the experts in different layers jointly for each test sample. Since the test sample\'s ground truth is unknown, we propose to optimize a surrogate objective defined by the sample\'s "successful neighbors" from a reference set of samples. We introduce three surrogates and algorithms based on mode-finding, kernel regression, and the average loss of similar reference samples/tasks. To reduce the cost of optimizing whole pathways, we apply our algorithms merely to the core experts\' mixing weights in critical layers, which enjoy similar performance but save significant computation. This leads to "Critical-Layer, Core-Expert, Collaborative Pathway Optimization (C3PO)". We apply C3PO to two recent MoE LLMs and examine it on six widely-used benchmarks. It consistently improves the base model by 7-15% in accuracy and outperforms widely used test-time learning baselines, e.g., in-context learning and prompt/prefix tuning, by a large margin. Moreover, C3PO enables MoE LLMs with 1-3B active parameters to outperform LLMs of 7-9B parameters, hence improving MoE\'s advantages on efficiency. Our thorough ablation study further sheds novel insights on achieving test-time improvement on MoE.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [C3PO: Critical-Layer, Core-Expert, Collaborative Pathway Optimization for Test-Time Expert Re-Mixing](https://arxiv.org/abs/2504.07964)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Recent progress in diffusion models significantly advances various image generation tasks. However, the current mainstream approach remains focused on building task-specific models, which have limited efficiency when supporting a wide range of different needs. While universal models attempt to address this limitation, they face critical challenges, including generalizable task instruction, appropriate task distributions, and unified architectural design. To tackle these challenges, we propose VisualCloze, a universal image generation framework, which supports a wide range of in-domain tasks, generalization to unseen ones, unseen unification of multiple tasks, and reverse generation. Unlike existing methods that rely on language-based task instruction, leading to task ambiguity and weak generalization, we integrate visual in-context learning, allowing models to identify tasks from visual demonstrations. Meanwhile, the inherent sparsity of visual task distributions hampers the learning of transferable knowledge across tasks. To this end, we introduce Graph200K, a graph-structured dataset that establishes various interrelated tasks, enhancing task density and transferable knowledge. Furthermore, we uncover that our unified image generation formulation shared a consistent objective with image infilling, enabling us to leverage the strong generative priors of pre-trained infilling models without modifying the architectures.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [VisualCloze: A Universal Image Generation Framework via Visual In-Context Learning](https://arxiv.org/abs/2504.07960)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'The Instruction Following (IF) ability measures how well Multi-modal Large Language Models (MLLMs) understand exactly what users are telling them and whether they are doing it right. Existing multimodal instruction following training data is scarce, the benchmarks are simple with atomic instructions, and the evaluation strategies are imprecise for tasks demanding exact output constraints. To address this, we present MM-IFEngine, an effective pipeline to generate high-quality image-instruction pairs. Our MM-IFEngine pipeline yields large-scale, diverse, and high-quality training data MM-IFInstruct-23k, which is suitable for Supervised Fine-Tuning (SFT) and extended as MM-IFDPO-23k for Direct Preference Optimization (DPO). We further introduce MM-IFEval, a challenging and diverse multi-modal instruction-following benchmark that includes (1) both compose-level constraints for output responses and perception-level constraints tied to the input images, and (2) a comprehensive evaluation pipeline incorporating both rule-based assessment and judge model. We conduct SFT and DPO experiments and demonstrate that fine-tuning MLLMs on MM-IFInstruct-23k and MM-IFDPO-23k achieves notable gains on various IF benchmarks, such as MM-IFEval (+10.2%), MIA (+7.6%), and IFEval (+12.3%). The full data and evaluation code will be released on https://github.com/SYuan03/MM-IFEngine.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [MM-IFEngine: Towards Multimodal Instruction Following](https://arxiv.org/abs/2504.07957)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "The advancement of Chain-of-Thought (CoT) reasoning has significantly enhanced the capabilities of large language models (LLMs) and large vision-language models (LVLMs). However, a rigorous evaluation framework for video CoT reasoning remains absent. Current video benchmarks fail to adequately assess the reasoning process and expose whether failures stem from deficiencies in perception or reasoning capabilities. Therefore, we introduce VCR-Bench, a novel benchmark designed to comprehensively evaluate LVLMs' Video Chain-of-Thought Reasoning capabilities. VCR-Bench comprises 859 videos spanning a variety of video content and durations, along with 1,034 high-quality question-answer pairs. Each pair is manually annotated with a stepwise CoT rationale, where every step is tagged to indicate its association with the perception or reasoning capabilities. Furthermore, we design seven distinct task dimensions and propose the CoT score to assess the entire CoT process based on the stepwise tagged CoT rationals. Extensive experiments on VCR-Bench highlight substantial limitations in current LVLMs. Even the top-performing model, o1, only achieves a 62.8% CoT score and an 56.7% accuracy, while most models score below 40%. Experiments show most models score lower on perception than reasoning steps, revealing LVLMs' key bottleneck in temporal-spatial information processing for complex video reasoning. A robust positive correlation between the CoT score and accuracy confirms the validity of our evaluation framework and underscores the critical role of CoT reasoning in solving complex video reasoning tasks. We hope VCR-Bench to serve as a standardized evaluation framework and expose the actual drawbacks in complex video reasoning task."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [VCR-Bench: A Comprehensive Evaluation Framework for Video Chain-of-Thought Reasoning](https://arxiv.org/abs/2504.07956)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': '3D part amodal segmentation--decomposing a 3D shape into complete, semantically meaningful parts, even when occluded--is a challenging but crucial task for 3D content creation and understanding. Existing 3D part segmentation methods only identify visible surface patches, limiting their utility. Inspired by 2D amodal segmentation, we introduce this novel task to the 3D domain and propose a practical, two-stage approach, addressing the key challenges of inferring occluded 3D geometry, maintaining global shape consistency, and handling diverse shapes with limited training data. First, we leverage existing 3D part segmentation to obtain initial, incomplete part segments. Second, we introduce HoloPart, a novel diffusion-based model, to complete these segments into full 3D parts. HoloPart utilizes a specialized architecture with local attention to capture fine-grained part geometry and global shape context attention to ensure overall shape consistency. We introduce new benchmarks based on the ABO and PartObjaverse-Tiny datasets and demonstrate that HoloPart significantly outperforms state-of-the-art shape completion methods. By incorporating HoloPart with existing segmentation techniques, we achieve promising results on 3D part amodal segmentation, opening new avenues for applications in geometry editing, animation, and material assignment.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [HoloPart: Generative 3D Part Amodal Segmentation](https://arxiv.org/abs/2504.07943)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'In this paper, we present an effective method to enhance visual reasoning with significantly fewer training samples, relying purely on self-improvement with no knowledge distillation. Our key insight is that the difficulty of training data during reinforcement fine-tuning (RFT) is critical. Appropriately challenging samples can substantially boost reasoning capabilities even when the dataset is small. Despite being intuitive, the main challenge remains in accurately quantifying sample difficulty to enable effective data filtering. To this end, we propose a novel way of repurposing Monte Carlo Tree Search (MCTS) to achieve that. Starting from our curated 70k open-source training samples, we introduce an MCTS-based selection method that quantifies sample difficulty based on the number of iterations required by the VLMs to solve each problem. This explicit step-by-step reasoning in MCTS enforces the model to think longer and better identifies samples that are genuinely challenging. We filter and retain 11k samples to perform RFT on Qwen2.5-VL-7B-Instruct, resulting in our final model, ThinkLite-VL. Evaluation results on eight benchmarks show that ThinkLite-VL improves the average performance of Qwen2.5-VL-7B-Instruct by 7%, using only 11k training samples with no knowledge distillation. This significantly outperforms all existing 7B-level reasoning VLMs, and our fairly comparable baselines that use classic selection methods such as accuracy-based filtering. Notably, on MathVista, ThinkLite-VL-7B achieves the SoTA accuracy of 75.1, surpassing Qwen2.5-VL-72B, GPT-4o, and O1. Our code, data, and model are available at https://github.com/si0wang/ThinkLite-VL.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [SoTA with Less: MCTS-Guided Sample Selection for Data-Efficient Visual Reasoning Self-Improvement](https://arxiv.org/abs/2504.07934)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "We present a novel, open-source social network simulation framework, MOSAIC, where generative language agents predict user behaviors such as liking, sharing, and flagging content. This simulation combines LLM agents with a directed social graph to analyze emergent deception behaviors and gain a better understanding of how users determine the veracity of online social content. By constructing user representations from diverse fine-grained personas, our system enables multi-agent simulations that model content dissemination and engagement dynamics at scale. Within this framework, we evaluate three different content moderation strategies with simulated misinformation dissemination, and we find that they not only mitigate the spread of non-factual content but also increase user engagement. In addition, we analyze the trajectories of popular content in our simulations, and explore whether simulation agents' articulated reasoning for their social interactions truly aligns with their collective engagement patterns. We open-source our simulation software to encourage further research within AI and social sciences."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [MOSAIC: Modeling Social AI for Content Dissemination and Regulation in Multi-Agent Simulations](https://arxiv.org/abs/2504.07830)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We present Kimi-VL, an efficient open-source Mixture-of-Experts (MoE) vision-language model (VLM) that offers advanced multimodal reasoning, long-context understanding, and strong agent capabilities - all while activating only 2.8B parameters in its language decoder (Kimi-VL-A3B). Kimi-VL demonstrates strong performance across challenging domains: as a general-purpose VLM, Kimi-VL excels in multi-turn agent tasks (e.g., OSWorld), matching flagship models. Furthermore, it exhibits remarkable capabilities across diverse challenging vision language tasks, including college-level image and video comprehension, OCR, mathematical reasoning, and multi-image understanding. In comparative evaluations, it effectively competes with cutting-edge efficient VLMs such as GPT-4o-mini, Qwen2.5-VL-7B, and Gemma-3-12B-IT, while surpassing GPT-4o in several key domains. Kimi-VL also advances in processing long contexts and perceiving clearly. With a 128K extended context window, Kimi-VL can process diverse long inputs, achieving impressive scores of 64.5 on LongVideoBench and 35.1 on MMLongBench-Doc. Its native-resolution vision encoder, MoonViT, further allows it to see and understand ultra-high-resolution visual inputs, achieving 83.2 on InfoVQA and 34.5 on ScreenSpot-Pro, while maintaining lower computational cost for common tasks. Building upon Kimi-VL, we introduce an advanced long-thinking variant: Kimi-VL-Thinking. Developed through long chain-of-thought (CoT) supervised fine-tuning (SFT) and reinforcement learning (RL), this model exhibits strong long-horizon reasoning capabilities. It achieves scores of 61.7 on MMMU, 36.8 on MathVision, and 71.3 on MathVista while maintaining the compact 2.8B activated LLM parameters, setting a new standard for efficient multimodal thinking models. Code and models are publicly accessible at https://github.com/MoonshotAI/Kimi-VL.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Kimi-VL Technical Report](https://arxiv.org/abs/2504.07491)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Despite the existing evolution of Multimodal Large Language Models (MLLMs), a non-neglectable limitation remains in their struggle with visual text grounding, especially in text-rich images of documents. Document images, such as scanned forms and infographics, highlight critical challenges due to their complex layouts and textual content. However, current benchmarks do not fully address these challenges, as they mostly focus on visual grounding on natural images, rather than text-rich document images. Thus, to bridge this gap, we introduce TRIG, a novel task with a newly designed instruction dataset for benchmarking and improving the Text-Rich Image Grounding capabilities of MLLMs in document question-answering. Specifically, we propose an OCR-LLM-human interaction pipeline to create 800 manually annotated question-answer pairs as a benchmark and a large-scale training set of 90$ synthetic data based on four diverse datasets. A comprehensive evaluation of various MLLMs on our proposed benchmark exposes substantial limitations in their grounding capability on text-rich images. In addition, we propose two simple and effective TRIG methods based on general instruction tuning and plug-and-play efficient embedding, respectively. By finetuning MLLMs on our synthetic dataset, they promisingly improve spatial reasoning and grounding capabilities.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Towards Visual Text Grounding of Multimodal Large Language Model](https://arxiv.org/abs/2504.04974)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Large Reasoning Models like DeepSeek-R1 mark a fundamental shift in how LLMs approach complex problems. Instead of directly producing an answer for a given input, DeepSeek-R1 creates detailed multi-step reasoning chains, seemingly "thinking" about a problem before providing an answer. This reasoning process is publicly available to the user, creating endless opportunities for studying the reasoning behaviour of the model and opening up the field of Thoughtology. Starting from a taxonomy of DeepSeek-R1\'s basic building blocks of reasoning, our analyses on DeepSeek-R1 investigate the impact and controllability of thought length, management of long or confusing contexts, cultural and safety concerns, and the status of DeepSeek-R1 vis-\\`a-vis cognitive phenomena, such as human-like language processing and world modelling. Our findings paint a nuanced picture. Notably, we show DeepSeek-R1 has a \'sweet spot\' of reasoning, where extra inference time can impair model performance. Furthermore, we find a tendency for DeepSeek-R1 to persistently ruminate on previously explored problem formulations, obstructing further exploration. We also note strong safety vulnerabilities of DeepSeek-R1 compared to its non-reasoning counterpart, which can also compromise safety-aligned LLMs.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [DeepSeek-R1 Thoughtology: Let's <think> about LLM Reasoning](https://arxiv.org/abs/2504.07128)
append_entries: 10
Finish: 2025-04-11 09:01:00.786607
------------------------------------------------------
Started: 2025-04-11 12:14:07.656003
Existing_entries: 1010
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Current monocular 3D detectors are held back by the limited diversity and scale of real-world datasets. While data augmentation certainly helps, it's particularly difficult to generate realistic scene-aware augmented data for outdoor settings. Most current approaches to synthetic data generation focus on realistic object appearance through improved rendering techniques. However, we show that where and how objects are positioned is just as crucial for training effective 3D monocular detectors. The key obstacle lies in automatically determining realistic object placement parameters - including position, dimensions, and directional alignment when introducing synthetic objects into actual scenes. To address this, we introduce MonoPlace3D, a novel system that considers the 3D scene content to create realistic augmentations. Specifically, given a background scene, MonoPlace3D learns a distribution over plausible 3D bounding boxes. Subsequently, we render realistic objects and place them according to the locations sampled from the learned distribution. Our comprehensive evaluation on two standard datasets KITTI and NuScenes, demonstrates that MonoPlace3D significantly improves the accuracy of multiple existing monocular 3D detectors while being highly data efficient."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [MonoPlace3D: Learning 3D-Aware Object Placement for 3D Monocular Detection](https://arxiv.org/abs/2504.06801)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Existing approaches for controlling text-to-image diffusion models, while powerful, do not allow for explicit 3D object-centric control, such as precise control of object orientation. In this work, we address the problem of multi-object orientation control in text-to-image diffusion models. This enables the generation of diverse multi-object scenes with precise orientation control for each object. The key idea is to condition the diffusion model with a set of orientation-aware compass tokens, one for each object, along with text tokens. A light-weight encoder network predicts these compass tokens taking object orientation as the input. The model is trained on a synthetic dataset of procedurally generated scenes, each containing one or two 3D assets on a plain background. However, direct training this framework results in poor orientation control as well as leads to entanglement among objects. To mitigate this, we intervene in the generation process and constrain the cross-attention maps of each compass token to its corresponding object regions. The trained model is able to achieve precise orientation control for a) complex objects not seen during training and b) multi-object scenes with more than two objects, indicating strong generalization capabilities. Further, when combined with personalization methods, our method precisely controls the orientation of the new object in diverse contexts. Our method achieves state-of-the-art orientation control and text alignment, quantified with extensive evaluations and a user study.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Compass Control: Multi Object Orientation Control for Text-to-Image Generation](https://arxiv.org/abs/2504.06752)
append_entries: 2
Finish: 2025-04-11 12:14:09.061851
------------------------------------------------------
Started: 2025-04-11 15:01:00.779975
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Building general-purpose models that can effectively perceive the world through multimodal signals has been a long-standing goal. Current approaches involve integrating separately pre-trained components, such as connecting vision encoders to LLMs and continuing multimodal training. While such approaches exhibit remarkable sample efficiency, it remains an open question whether such late-fusion architectures are inherently superior. In this work, we revisit the architectural design of native multimodal models (NMMs)--those trained from the ground up on all modalities--and conduct an extensive scaling laws study, spanning 457 trained models with different architectures and training mixtures. Our investigation reveals no inherent advantage to late-fusion architectures over early-fusion ones, which do not rely on image encoders. On the contrary, early-fusion exhibits stronger performance at lower parameter counts, is more efficient to train, and is easier to deploy. Motivated by the strong performance of the early-fusion architectures, we show that incorporating Mixture of Experts (MoEs) allows for models that learn modality-specific weights, significantly enhancing performance.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Scaling Laws for Native Multimodal Models Scaling Laws for Native Multimodal Models](https://arxiv.org/abs/2504.07951)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Tracking Any Point (TAP) in a video is a challenging computer vision problem with many demonstrated applications in robotics, video editing, and 3D reconstruction. Existing methods for TAP rely heavily on complex tracking-specific inductive biases and heuristics, limiting their generality and potential for scaling. To address these challenges, we present TAPNext, a new approach that casts TAP as sequential masked token decoding. Our model is causal, tracks in a purely online fashion, and removes tracking-specific inductive biases. This enables TAPNext to run with minimal latency, and removes the temporal windowing required by many existing state of art trackers. Despite its simplicity, TAPNext achieves a new state-of-the-art tracking performance among both online and offline trackers. Finally, we present evidence that many widely used tracking heuristics emerge naturally in TAPNext through end-to-end training.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [TAPNext: Tracking Any Point (TAP) as Next Token Prediction](https://arxiv.org/abs/2504.05579)
append_entries: 2
Finish: 2025-04-11 15:01:01.879507
------------------------------------------------------
Started: 2025-04-11 18:00:54.838031
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We introduce Geo4D, a method to repurpose video diffusion models for monocular 3D reconstruction of dynamic scenes. By leveraging the strong dynamic prior captured by such video models, Geo4D can be trained using only synthetic data while generalizing well to real data in a zero-shot manner. Geo4D predicts several complementary geometric modalities, namely point, depth, and ray maps. It uses a new multi-modal alignment algorithm to align and fuse these modalities, as well as multiple sliding windows, at inference time, thus obtaining robust and accurate 4D reconstruction of long videos. Extensive experiments across multiple benchmarks show that Geo4D significantly surpasses state-of-the-art video depth estimation methods, including recent methods such as MonST3R, which are also designed to handle dynamic scenes.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Geo4D: Leveraging Video Generators for Geometric 4D Scene Reconstruction](https://arxiv.org/abs/2504.07961)
append_entries: 1
Finish: 2025-04-11 18:00:55.542211
------------------------------------------------------
Started: 2025-04-11 21:00:39.849486
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-11 21:00:40.054261
------------------------------------------------------
Started: 2025-04-12 00:36:44.654814
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-12 00:36:44.841990
------------------------------------------------------
Started: 2025-04-12 03:22:34.308908
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-12 03:22:34.530623
------------------------------------------------------
Started: 2025-04-12 06:00:48.899814
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-12 06:00:49.090028
------------------------------------------------------
Started: 2025-04-12 09:00:46.969479
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-12 09:00:47.191813
------------------------------------------------------
Started: 2025-04-12 12:00:43.038639
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-12 12:00:43.202503
------------------------------------------------------
Started: 2025-04-12 15:00:35.710567
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-12 15:00:35.919482
------------------------------------------------------
Started: 2025-04-12 18:00:35.331329
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-12 18:00:35.698250
------------------------------------------------------
Started: 2025-04-12 21:00:43.952862
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-12 21:00:44.203121
------------------------------------------------------
Started: 2025-04-13 02:04:38.926662
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-13 02:04:39.122053
------------------------------------------------------
Started: 2025-04-13 04:18:47.187517
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-13 04:18:47.407417
------------------------------------------------------
Started: 2025-04-13 06:00:32.888576
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-13 06:00:33.015111
------------------------------------------------------
Started: 2025-04-13 09:00:43.962342
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-13 09:00:44.179057
------------------------------------------------------
Started: 2025-04-13 12:12:18.038844
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-13 12:12:18.205502
------------------------------------------------------
Started: 2025-04-13 15:00:40.173384
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-13 15:00:40.378137
------------------------------------------------------
Started: 2025-04-13 18:00:29.850298
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-13 18:00:30.007531
------------------------------------------------------
Started: 2025-04-13 21:00:38.393024
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-13 21:00:38.733925
------------------------------------------------------
Started: 2025-04-14 00:40:41.299047
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-14 00:40:41.496536
------------------------------------------------------
Started: 2025-04-14 03:30:23.209057
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-14 03:30:23.457957
------------------------------------------------------
Started: 2025-04-14 06:12:21.262745
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'This technical report presents a cost-efficient strategy for training a video generation foundation model. We present a mid-sized research model with approximately 7 billion parameters (7B) called Seaweed-7B trained from scratch using 665,000 H100 GPU hours. Despite being trained with moderate computational resources, Seaweed-7B demonstrates highly competitive performance compared to contemporary video generation models of much larger size. Design choices are especially crucial in a resource-constrained setting. This technical report highlights the key design decisions that enhance the performance of the medium-sized diffusion model. Empirically, we make two observations: (1) Seaweed-7B achieves performance comparable to, or even surpasses, larger models trained on substantially greater GPU resources, and (2) our model, which exhibits strong generalization ability, can be effectively adapted across a wide range of downstream applications either by lightweight fine-tuning or continue training. See the project page at https://seaweed.video/'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Seaweed-7B: Cost-Effective Training of Video Generation Foundation Model](https://arxiv.org/abs/2504.08685)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'World modeling is a crucial task for enabling intelligent agents to effectively interact with humans and operate in dynamic environments. In this work, we propose MineWorld, a real-time interactive world model on Minecraft, an open-ended sandbox game which has been utilized as a common testbed for world modeling. MineWorld is driven by a visual-action autoregressive Transformer, which takes paired game scenes and corresponding actions as input, and generates consequent new scenes following the actions. Specifically, by transforming visual game scenes and actions into discrete token ids with an image tokenizer and an action tokenizer correspondingly, we consist the model input with the concatenation of the two kinds of ids interleaved. The model is then trained with next token prediction to learn rich representations of game states as well as the conditions between states and actions simultaneously. In inference, we develop a novel parallel decoding algorithm that predicts the spatial redundant tokens in each frame at the same time, letting models in different scales generate 4 to 7 frames per second and enabling real-time interactions with game players. In evaluation, we propose new metrics to assess not only visual quality but also the action following capacity when generating new scenes, which is crucial for a world model. Our comprehensive evaluation shows the efficacy of MineWorld, outperforming SoTA open-sourced diffusion based world models significantly. The code and model have been released.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [MineWorld: a Real-Time and Open-Source Interactive World Model on Minecraft](https://arxiv.org/abs/2504.08388)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We propose a new problem, In-2-4D, for generative 4D (i.e., 3D + motion) inbetweening from a minimalistic input setting: two single-view images capturing an object in two distinct motion states. Given two images representing the start and end states of an object in motion, our goal is to generate and reconstruct the motion in 4D. We utilize a video interpolation model to predict the motion, but large frame-to-frame motions can lead to ambiguous interpretations. To overcome this, we employ a hierarchical approach to identify keyframes that are visually close to the input states and show significant motion, then generate smooth fragments between them. For each fragment, we construct the 3D representation of the keyframe using Gaussian Splatting. The temporal frames within the fragment guide the motion, enabling their transformation into dynamic Gaussians through a deformation field. To improve temporal consistency and refine 3D motion, we expand the self-attention of multi-view diffusion across timesteps and apply rigid transformation regularization. Finally, we merge the independently generated 3D motion segments by interpolating boundary deformation fields and optimizing them to align with the guiding video, ensuring smooth and flicker-free transitions. Through extensive qualitative and quantitiave experiments as well as a user study, we show the effectiveness of our method and its components. The project page is available at https://in-2-4d.github.io/'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [In-2-4D: Inbetweening from Two Single-View Images to 4D Generation](https://arxiv.org/abs/2504.08366)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'With the rapid advancement of 2D generative models, preserving subject identity while enabling diverse editing has emerged as a critical research focus. Existing methods typically face inherent trade-offs between identity preservation and personalized manipulation. We introduce FlexIP, a novel framework that decouples these objectives through two dedicated components: a Personalization Adapter for stylistic manipulation and a Preservation Adapter for identity maintenance. By explicitly injecting both control mechanisms into the generative model, our framework enables flexible parameterized control during inference through dynamic tuning of the weight adapter. Experimental results demonstrate that our approach breaks through the performance limitations of conventional methods, achieving superior identity preservation while supporting more diverse personalized generation capabilities (Project Page: https://flexip-tech.github.io/flexip/).'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [FlexIP: Dynamic Control of Preservation and Personality for Customized Image Generation](https://arxiv.org/abs/2504.07405)
append_entries: 4
Finish: 2025-04-14 06:12:23.620696
------------------------------------------------------
Started: 2025-04-14 09:00:37.546448
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'In autoregressive (AR) image generation, visual tokenizers compress images into compact discrete latent tokens, enabling efficient training of downstream autoregressive models for visual generation via next-token prediction. While scaling visual tokenizers improves image reconstruction quality, it often degrades downstream generation quality -- a challenge not adequately addressed in existing literature. To address this, we introduce GigaTok, the first approach to simultaneously improve image reconstruction, generation, and representation learning when scaling visual tokenizers. We identify the growing complexity of latent space as the key factor behind the reconstruction vs. generation dilemma. To mitigate this, we propose semantic regularization, which aligns tokenizer features with semantically consistent features from a pre-trained visual encoder. This constraint prevents excessive latent space complexity during scaling, yielding consistent improvements in both reconstruction and downstream autoregressive generation. Building on semantic regularization, we explore three key practices for scaling tokenizers:(1) using 1D tokenizers for better scalability, (2) prioritizing decoder scaling when expanding both encoder and decoder, and (3) employing entropy loss to stabilize training for billion-scale tokenizers. By scaling to 3 space billion parameters, GigaTok achieves state-of-the-art performance in reconstruction, downstream AR generation, and downstream AR representation quality.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [GigaTok: Scaling Visual Tokenizers to 3 Billion Parameters for Autoregressive Image Generation](https://arxiv.org/abs/2504.08736)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Pretrained transformer-encoder models like DeBERTaV3 and ModernBERT introduce architectural advancements aimed at improving efficiency and performance. Although the authors of ModernBERT report improved performance over DeBERTaV3 on several benchmarks, the lack of disclosed training data and the absence of comparisons using a shared dataset make it difficult to determine whether these gains are due to architectural improvements or differences in training data. In this work, we conduct a controlled study by pretraining ModernBERT on the same dataset as CamemBERTaV2, a DeBERTaV3 French model, isolating the effect of model design. Our results show that the previous model generation remains superior in sample efficiency and overall benchmark performance, with ModernBERT's primary advantage being faster training and inference speed. However, the new proposed model still provides meaningful architectural improvements compared to earlier models such as BERT and RoBERTa. Additionally, we observe that high-quality pre-training data accelerates convergence but does not significantly improve final performance, suggesting potential benchmark saturation. These findings show the importance of disentangling pretraining data from architectural innovations when evaluating transformer models."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [ModernBERT or DeBERTaV3? Examining Architecture and Data Influence on Transformer Encoder Models Performance](https://arxiv.org/abs/2504.08716)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Natural Language to SQL (NL2SQL) enables intuitive interactions with databases by transforming natural language queries into structured SQL statements. Despite recent advancements in enhancing human-computer interaction within database applications, significant challenges persist, particularly regarding the inference performance in complex scenarios involving multi-table joins and nested queries. Current methodologies primarily utilize supervised fine-tuning (SFT) to train the NL2SQL model, which may limit adaptability and interpretability in new environments (e.g., finance and healthcare). In order to enhance the reasoning performance of the NL2SQL model in the above complex situations, we introduce SQL-R1, a novel NL2SQL reasoning model trained by the reinforcement learning (RL) algorithms. We design a specialized RL-based reward function tailored for NL2SQL tasks and discussed the impact of cold start on the effectiveness of intensive training. In addition, we achieve competitive accuracy using only a tiny amount of synthetic NL2SQL data for augmented training and further explore data engineering for RL. In existing experiments, SQL-R1 achieves execution accuracy of 88.6% and 66.6% on the benchmark Spider and BIRD, respectively, only using the 7B base model.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [SQL-R1: Training Natural Language to SQL Reasoning Model By Reinforcement Learning](https://arxiv.org/abs/2504.08600)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We present PixelFlow, a family of image generation models that operate directly in the raw pixel space, in contrast to the predominant latent-space models. This approach simplifies the image generation process by eliminating the need for a pre-trained Variational Autoencoder (VAE) and enabling the whole model end-to-end trainable. Through efficient cascade flow modeling, PixelFlow achieves affordable computation cost in pixel space. It achieves an FID of 1.98 on 256times256 ImageNet class-conditional image generation benchmark. The qualitative text-to-image results demonstrate that PixelFlow excels in image quality, artistry, and semantic control. We hope this new paradigm will inspire and open up new opportunities for next-generation visual generation models. Code and models are available at https://github.com/ShoufaChen/PixelFlow.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [PixelFlow: Pixel-Space Generative Models with Flow](https://arxiv.org/abs/2504.07963)
append_entries: 4
Finish: 2025-04-14 09:00:40.001827
------------------------------------------------------
Started: 2025-04-14 12:14:03.245277
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Machine unlearning is a promising approach to improve LLM safety by removing unwanted knowledge from the model. However, prevailing gradient-based unlearning methods suffer from issues such as high computational costs, hyperparameter instability, poor sequential unlearning capability, vulnerability to relearning attacks, low data efficiency, and lack of interpretability. While Sparse Autoencoders are well-suited to improve these aspects by enabling targeted activation-based unlearning, prior approaches underperform gradient-based methods. This work demonstrates that, contrary to these earlier findings, SAEs can significantly improve unlearning when employed dynamically. We introduce Dynamic DAE Guardrails (DSG), a novel method for precision unlearning that leverages principled feature selection and a dynamic classifier. Our experiments show DSG substantially outperforms leading unlearning methods, achieving superior forget-utility trade-offs. DSG addresses key drawbacks of gradient-based approaches for unlearning -- offering enhanced computational efficiency and stability, robust performance in sequential unlearning, stronger resistance to relearning attacks, better data efficiency including zero-shot settings, and more interpretable unlearning.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [SAEs Can Improve Unlearning: Dynamic Sparse Autoencoder Guardrails for Precision Unlearning in LLMs](https://arxiv.org/abs/2504.08192)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We introduce InteractVLM, a novel method to estimate 3D contact points on human bodies and objects from single in-the-wild images, enabling accurate human-object joint reconstruction in 3D. This is challenging due to occlusions, depth ambiguities, and widely varying object shapes. Existing methods rely on 3D contact annotations collected via expensive motion-capture systems or tedious manual labeling, limiting scalability and generalization. To overcome this, InteractVLM harnesses the broad visual knowledge of large Vision-Language Models (VLMs), fine-tuned with limited 3D contact data. However, directly applying these models is non-trivial, as they reason only in 2D, while human-object contact is inherently 3D. Thus we introduce a novel Render-Localize-Lift module that: (1) embeds 3D body and object surfaces in 2D space via multi-view rendering, (2) trains a novel multi-view localization model (MV-Loc) to infer contacts in 2D, and (3) lifts these to 3D. Additionally, we propose a new task called Semantic Human Contact estimation, where human contact predictions are conditioned explicitly on object semantics, enabling richer interaction modeling. InteractVLM outperforms existing work on contact estimation and also facilitates 3D reconstruction from an in-the wild image. Code and models are available at https://interactvlm.is.tue.mpg.de.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [InteractVLM: 3D Interaction Reasoning from 2D Foundational Models](https://arxiv.org/abs/2504.05303)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Despite high benchmark scores, Large Language Models (LLMs) often fail simple problem, raising a critical question: Do LLMs learn mathematical principles or merely memorize patterns? Rather than designing increasingly complex benchmarks like recent works, we investigate this using elementary two-integer addition (0 to 2^{64}), probing two core properties: commutativity (A+B=B+A) and compositional generalization (via isomorphic symbolic mappings, e.g., 7 rightarrow y). While state-of-the-art LLMs achieve 73.8-99.8\\% accuracy on numerical addition, performance collapses to leq7.5\\% under symbolic mapping, indicating failure to generalize learned rules. Non-monotonic performance scaling with digit count and frequent commutativity violations (over 1,700 cases of A+B neq B+A) further support this. Explicitly providing addition rules degrades performance by 81.2\\% on average, while self-explanation maintains baseline accuracy, suggesting LLM arithmetic processing is misaligned with human-defined principles. Our findings indicate current LLMs rely on memory pattern over genuine rule learning, highlighting architectural limitations and the need for new approaches to achieve true mathematical reasoning.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Do PhD-level LLMs Truly Grasp Elementary Addition? Probing Rule Learning vs. Memorization in Large Language Models](https://arxiv.org/abs/2504.05262)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Retrieval-Augmented Generation (RAG) models excel in knowledge-intensive tasks, especially under few-shot learning constraints. We introduce CoRAG, a framework extending RAG to collaborative settings, where clients jointly train a shared model using a collaborative passage store. To evaluate CoRAG, we introduce CRAB, a benchmark for collaborative homogeneous open-domain question answering. Our experiments demonstrate that CoRAG consistently outperforms both parametric collaborative learning methods and locally trained RAG models in low-resource scenarios. Further analysis reveals the critical importance of relevant passages within the shared store, the surprising benefits of incorporating irrelevant passages, and the potential for hard negatives to negatively impact performance. This introduces a novel consideration in collaborative RAG: the trade-off between leveraging a collectively enriched knowledge base and the potential risk of incorporating detrimental passages from other clients. Our findings underscore the viability of CoRAG, while also highlighting key design challenges and promising avenues for future research.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [CoRAG: Collaborative Retrieval-Augmented Generation](https://arxiv.org/abs/2504.01883)
append_entries: 4
Finish: 2025-04-14 12:14:05.595900
------------------------------------------------------
Started: 2025-04-14 15:00:31.663373
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'This study presents Latent Diffusion Autoencoder (LDAE), a novel encoder-decoder diffusion-based framework for efficient and meaningful unsupervised learning in medical imaging, focusing on Alzheimer disease (AD) using brain MR from the ADNI database as a case study. Unlike conventional diffusion autoencoders operating in image space, LDAE applies the diffusion process in a compressed latent representation, improving computational efficiency and making 3D medical imaging representation learning tractable. To validate the proposed approach, we explore two key hypotheses: (i) LDAE effectively captures meaningful semantic representations on 3D brain MR associated with AD and ageing, and (ii) LDAE achieves high-quality image generation and reconstruction while being computationally efficient. Experimental results support both hypotheses: (i) linear-probe evaluations demonstrate promising diagnostic performance for AD (ROC-AUC: 90%, ACC: 84%) and age prediction (MAE: 4.1 years, RMSE: 5.2 years); (ii) the learned semantic representations enable attribute manipulation, yielding anatomically plausible modifications; (iii) semantic interpolation experiments show strong reconstruction of missing scans, with SSIM of 0.969 (MSE: 0.0019) for a 6-month gap. Even for longer gaps (24 months), the model maintains robust performance (SSIM > 0.93, MSE < 0.004), indicating an ability to capture temporal progression trends; (iv) compared to conventional diffusion autoencoders, LDAE significantly increases inference throughput (20x faster) while also enhancing reconstruction quality. These findings position LDAE as a promising framework for scalable medical imaging applications, with the potential to serve as a foundation model for medical image analysis. Code available at https://github.com/GabrieleLozupone/LDAE'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Latent Diffusion Autoencoders: Toward Efficient and Meaningful Unsupervised Representation Learning in Medical Imaging](https://arxiv.org/abs/2504.08635)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We present Pangu Ultra, a Large Language Model (LLM) with 135 billion parameters and dense Transformer modules trained on Ascend Neural Processing Units (NPUs). Although the field of LLM has been witnessing unprecedented advances in pushing the scale and capability of LLM in recent years, training such a large-scale model still involves significant optimization and system challenges. To stabilize the training process, we propose depth-scaled sandwich normalization, which effectively eliminates loss spikes during the training process of deep models. We pre-train our model on 13.2 trillion diverse and high-quality tokens and further enhance its reasoning capabilities during post-training. To perform such large-scale training efficiently, we utilize 8,192 Ascend NPUs with a series of system optimizations. Evaluations on multiple diverse benchmarks indicate that Pangu Ultra significantly advances the state-of-the-art capabilities of dense LLMs such as Llama 405B and Mistral Large 2, and even achieves competitive results with DeepSeek-R1, whose sparse model structure contains much more parameters. Our exploration demonstrates that Ascend NPUs are capable of efficiently and effectively training dense models with more than 100 billion parameters. Our model and system will be available for our commercial customers.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Pangu Ultra: Pushing the Limits of Dense Large Language Models on Ascend NPUs](https://arxiv.org/abs/2504.07866)
append_entries: 2
Finish: 2025-04-14 15:00:32.982278
------------------------------------------------------
Started: 2025-04-14 18:00:31.824262
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We present a system using Multimodal LLMs (MLLMs) to analyze a large database with tens of millions of images captured at different times, with the aim of discovering patterns in temporal changes. Specifically, we aim to capture frequent co-occurring changes ("trends") across a city over a certain period. Unlike previous visual analyses, our analysis answers open-ended queries (e.g., "what are the frequent types of changes in the city?") without any predetermined target subjects or training labels. These properties cast prior learning-based or unsupervised visual analysis tools unsuitable. We identify MLLMs as a novel tool for their open-ended semantic understanding capabilities. Yet, our datasets are four orders of magnitude too large for an MLLM to ingest as context. So we introduce a bottom-up procedure that decomposes the massive visual analysis problem into more tractable sub-problems. We carefully design MLLM-based solutions to each sub-problem. During experiments and ablation studies with our system, we find it significantly outperforms baselines and is able to discover interesting trends from images captured in large cities (e.g., "addition of outdoor dining,", "overpass was painted blue," etc.). See more results and interactive demos at https://boyangdeng.com/visual-chronicles.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Visual Chronicles: Using Multimodal LLMs to Analyze Massive Collections of Images](https://arxiv.org/abs/2504.08727)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Recent advancements in text-to-video (T2V) diffusion models have significantly enhanced the visual quality of the generated videos. However, even recent T2V models find it challenging to follow text descriptions accurately, especially when the prompt requires accurate control of spatial layouts or object trajectories. A recent line of research uses layout guidance for T2V models that require fine-tuning or iterative manipulation of the attention map during inference time. This significantly increases the memory requirement, making it difficult to adopt a large T2V model as a backbone. To address this, we introduce Video-MSG, a training-free Guidance method for T2V generation based on Multimodal planning and Structured noise initialization. Video-MSG consists of three steps, where in the first two steps, Video-MSG creates Video Sketch, a fine-grained spatio-temporal plan for the final video, specifying background, foreground, and object trajectories, in the form of draft video frames. In the last step, Video-MSG guides a downstream T2V diffusion model with Video Sketch through noise inversion and denoising. Notably, Video-MSG does not need fine-tuning or attention manipulation with additional memory during inference time, making it easier to adopt large T2V models. Video-MSG demonstrates its effectiveness in enhancing text alignment with multiple T2V backbones (VideoCrafter2 and CogVideoX-5B) on popular T2V generation benchmarks (T2VCompBench and VBench). We provide comprehensive ablation studies about noise inversion ratio, different background generators, background object detection, and foreground object segmentation.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Training-free Guidance in Text-to-Video Generation via Multimodal Planning and Structured Noise Initialization](https://arxiv.org/abs/2504.08641)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Recent progress in generative models has significantly improved image restoration capabilities, particularly through powerful diffusion models that offer remarkable recovery of semantic details and local fidelity. However, deploying these models at ultra-high resolutions faces a critical trade-off between quality and efficiency due to the computational demands of long-range attention mechanisms. To address this, we introduce ZipIR, a novel framework that enhances efficiency, scalability, and long-range modeling for high-res image restoration. ZipIR employs a highly compressed latent representation that compresses image 32x, effectively reducing the number of spatial tokens, and enabling the use of high-capacity models like the Diffusion Transformer (DiT). Toward this goal, we propose a Latent Pyramid VAE (LP-VAE) design that structures the latent space into sub-bands to ease diffusion training. Trained on full images up to 2K resolution, ZipIR surpasses existing diffusion-based methods, offering unmatched speed and quality in restoring high-resolution images from severely degraded inputs.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [ZipIR: Latent Pyramid Diffusion Transformer for High-Resolution Image Restoration](https://arxiv.org/abs/2504.08591)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Recently DeepSeek R1 has shown that reinforcement learning (RL) can substantially improve the reasoning capabilities of Large Language Models (LLMs) through a simple yet effective design. The core of R1 lies in its rule-based reward formulation, which leverages tasks with deterministic ground-truth answers to enable precise and stable reward computation. In the visual domain, we similarly observe that a wide range of visual understanding tasks are inherently equipped with well-defined ground-truth annotations. This property makes them naturally compatible with rule-based reward mechanisms. Motivated by this observation, we investigate the extension of R1-style reinforcement learning to Vision-Language Models (VLMs), aiming to enhance their visual reasoning capabilities. To this end, we develop VLM-R1, a dedicated framework designed to harness RL for improving VLMs\' performance on general vision-language tasks. Using this framework, we further explore the feasibility of applying RL to visual domain. Experimental results indicate that the RL-based model not only delivers competitive performance on visual understanding tasks but also surpasses Supervised Fine-Tuning (SFT) in generalization ability. Furthermore, we conduct comprehensive ablation studies that uncover a series of noteworthy insights, including the presence of reward hacking in object detection, the emergence of the "OD aha moment", the impact of training data quality, and the scaling behavior of RL across different model sizes. Through these analyses, we aim to deepen the understanding of how reinforcement learning enhances the capabilities of vision-language models, and we hope our findings and open-source contributions will support continued progress in the vision-language RL community. Our code and model are available at https://github.com/om-ai-lab/VLM-R1'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [VLM-R1: A Stable and Generalizable R1-style Large Vision-Language Model](https://arxiv.org/abs/2504.07615)
append_entries: 4
Finish: 2025-04-14 18:00:34.031443
------------------------------------------------------
Started: 2025-04-14 21:00:43.840260
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'In medical imaging, the primary challenge is collecting large-scale labeled data due to privacy concerns, logistics, and high labeling costs. In this work, we present the UK Biobank Organs and Bones (UKBOB), the largest labeled dataset of body organs, comprising 51,761 MRI 3D samples (equivalent to 17.9 million 2D images) and more than 1.37 billion 2D segmentation masks of 72 organs, all based on the UK Biobank MRI dataset. We utilize automatic labeling, introduce an automated label cleaning pipeline with organ-specific filters, and manually annotate a subset of 300 MRIs with 11 abdominal classes to validate the quality (referred to as UKBOB-manual). This approach allows for scaling up the dataset collection while maintaining confidence in the labels. We further confirm the validity of the labels by demonstrating zero-shot generalization of trained models on the filtered UKBOB to other small labeled datasets from similar domains (e.g., abdominal MRI). To further mitigate the effect of noisy labels, we propose a novel method called Entropy Test-time Adaptation (ETTA) to refine the segmentation output. We use UKBOB to train a foundation model, Swin-BOB, for 3D medical image segmentation based on the Swin-UNetr architecture, achieving state-of-the-art results in several benchmarks in 3D medical imaging, including the BRATS brain MRI tumor challenge (with a 0.4% improvement) and the BTCV abdominal CT scan benchmark (with a 1.3% improvement). The pre-trained models and the code are available at https://emmanuelleb985.github.io/ukbob , and the filtered labels will be made available with the UK Biobank.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [UKBOB: One Billion MRI Labeled Masks for Generalizable 3D Medical Image Segmentation](https://arxiv.org/abs/2504.06908)
append_entries: 1
Finish: 2025-04-14 21:00:44.557731
------------------------------------------------------
Started: 2025-04-15 00:38:51.060122
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "3D graphics editing is crucial in applications like movie production and game design, yet it remains a time-consuming process that demands highly specialized domain expertise. Automating this process is challenging because graphical editing requires performing a variety of tasks, each requiring distinct skill sets. Recently, vision-language models (VLMs) have emerged as a powerful framework for automating the editing process, but their development and evaluation are bottlenecked by the lack of a comprehensive benchmark that requires human-level perception and presents real-world editing complexity. In this work, we present BlenderGym, the first comprehensive VLM system benchmark for 3D graphics editing. BlenderGym evaluates VLM systems through code-based 3D reconstruction tasks. We evaluate closed- and open-source VLM systems and observe that even the state-of-the-art VLM system struggles with tasks relatively easy for human Blender users. Enabled by BlenderGym, we study how inference scaling techniques impact VLM's performance on graphics editing tasks. Notably, our findings reveal that the verifier used to guide the scaling of generation can itself be improved through inference scaling, complementing recent insights on inference scaling of LLM generation in coding and math tasks. We further show that inference compute is not uniformly effective and can be optimized by strategically distributing it between generation and verification."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [BlenderGym: Benchmarking Foundational Model Systems for Graphics Editing](https://arxiv.org/abs/2504.01786)
append_entries: 1
Finish: 2025-04-15 00:38:51.856074
------------------------------------------------------
Started: 2025-04-15 03:30:06.332628
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Recent advances in reinforcement learning (RL)-based post-training have led to notable improvements in large language models (LLMs), particularly in enhancing their reasoning capabilities to handle complex tasks. However, most existing methods treat the training data as a unified whole, overlooking the fact that modern LLM training often involves a mixture of data from diverse distributions-varying in both source and difficulty. This heterogeneity introduces a key challenge: how to adaptively schedule training across distributions to optimize learning efficiency. In this paper, we present a principled curriculum learning framework grounded in the notion of distribution-level learnability. Our core insight is that the magnitude of policy advantages reflects how much a model can still benefit from further training on a given distribution. Based on this, we propose a distribution-level curriculum learning framework for RL-based LLM post-training, which leverages the Upper Confidence Bound (UCB) principle to dynamically adjust sampling probabilities for different distrubutions. This approach prioritizes distributions with either high average advantage (exploitation) or low sample count (exploration), yielding an adaptive and theoretically grounded training schedule. We instantiate our curriculum learning framework with GRPO as the underlying RL algorithm and demonstrate its effectiveness on logic reasoning datasets with multiple difficulties and sources. Our experiments show that our framework significantly improves convergence speed and final performance, highlighting the value of distribution-aware curriculum strategies in LLM post-training. Code: https://github.com/ZhentingWang/DUMP.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [DUMP: Automated Distribution-Level Curriculum Learning for RL-based LLM Post-training](https://arxiv.org/abs/2504.09710)
append_entries: 1
Finish: 2025-04-15 03:30:07.046826
------------------------------------------------------
Started: 2025-04-15 06:11:31.532468
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We introduce InternVL3, a significant advancement in the InternVL series featuring a native multimodal pre-training paradigm. Rather than adapting a text-only large language model (LLM) into a multimodal large language model (MLLM) that supports visual inputs, InternVL3 jointly acquires multimodal and linguistic capabilities from both diverse multimodal data and pure-text corpora during a single pre-training stage. This unified training paradigm effectively addresses the complexities and alignment challenges commonly encountered in conventional post-hoc training pipelines for MLLMs. To further improve performance and scalability, InternVL3 incorporates variable visual position encoding (V2PE) to support extended multimodal contexts, employs advanced post-training techniques such as supervised fine-tuning (SFT) and mixed preference optimization (MPO), and adopts test-time scaling strategies alongside an optimized training infrastructure. Extensive empirical evaluations demonstrate that InternVL3 delivers superior performance across a wide range of multi-modal tasks. In particular, InternVL3-78B achieves a score of 72.2 on the MMMU benchmark, setting a new state-of-the-art among open-source MLLMs. Its capabilities remain highly competitive with leading proprietary models, including ChatGPT-4o, Claude 3.5 Sonnet, and Gemini 2.5 Pro, while also maintaining strong pure-language proficiency. In pursuit of open-science principles, we will publicly release both the training data and model weights to foster further research and development in next-generation MLLMs.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models](https://arxiv.org/abs/2504.10479)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Scientific equation discovery is a fundamental task in the history of scientific progress, enabling the derivation of laws governing natural phenomena. Recently, Large Language Models (LLMs) have gained interest for this task due to their potential to leverage embedded scientific knowledge for hypothesis generation. However, evaluating the true discovery capabilities of these methods remains challenging, as existing benchmarks often rely on common equations that are susceptible to memorization by LLMs, leading to inflated performance metrics that do not reflect discovery. In this paper, we introduce LLM-SRBench, a comprehensive benchmark with 239 challenging problems across four scientific domains specifically designed to evaluate LLM-based scientific equation discovery methods while preventing trivial memorization. Our benchmark comprises two main categories: LSR-Transform, which transforms common physical models into less common mathematical representations to test reasoning beyond memorized forms, and LSR-Synth, which introduces synthetic, discovery-driven problems requiring data-driven reasoning. Through extensive evaluation of several state-of-the-art methods, using both open and closed LLMs, we find that the best-performing system so far achieves only 31.5% symbolic accuracy. These findings highlight the challenges of scientific equation discovery, positioning LLM-SRBench as a valuable resource for future research.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [LLM-SRBench: A New Benchmark for Scientific Equation Discovery with Large Language Models](https://arxiv.org/abs/2504.10415)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "We introduce S1-Bench, a novel benchmark designed to evaluate Large Reasoning Models' (LRMs) performance on simple tasks that favor intuitive system 1 thinking rather than deliberative system 2 reasoning. While LRMs have achieved significant breakthroughs in complex reasoning tasks through explicit chains of thought, their reliance on deep analytical thinking may limit their system 1 thinking capabilities. Moreover, a lack of benchmark currently exists to evaluate LRMs' performance in tasks that require such capabilities. To fill this gap, S1-Bench presents a set of simple, diverse, and naturally clear questions across multiple domains and languages, specifically designed to assess LRMs' performance in such tasks. Our comprehensive evaluation of 22 LRMs reveals significant lower efficiency tendencies, with outputs averaging 15.5 times longer than those of traditional small LLMs. Additionally, LRMs often identify correct answers early but continue unnecessary deliberation, with some models even producing numerous errors. These findings highlight the rigid reasoning patterns of current LRMs and underscore the substantial development needed to achieve balanced dual-system thinking capabilities that can adapt appropriately to task complexity."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [S1-Bench: A Simple Benchmark for Evaluating System 1 Thinking Capability of Large Reasoning Models](https://arxiv.org/abs/2504.10368)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Social simulation is transforming traditional social science research by modeling human behavior through interactions between virtual individuals and their environments. With recent advances in large language models (LLMs), this approach has shown growing potential in capturing individual differences and predicting group behaviors. However, existing methods face alignment challenges related to the environment, target users, interaction mechanisms, and behavioral patterns. To this end, we introduce SocioVerse, an LLM-agent-driven world model for social simulation. Our framework features four powerful alignment components and a user pool of 10 million real individuals. To validate its effectiveness, we conducted large-scale simulation experiments across three distinct domains: politics, news, and economics. Results demonstrate that SocioVerse can reflect large-scale population dynamics while ensuring diversity, credibility, and representativeness through standardized procedures and minimal manual adjustments.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [SocioVerse: A World Model for Social Simulation Powered by LLM Agents and A Pool of 10 Million Real-World Users](https://arxiv.org/abs/2504.10157)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Long-context video understanding in multimodal large language models (MLLMs) faces a critical challenge: balancing computational efficiency with the retention of fine-grained spatio-temporal patterns. Existing approaches (e.g., sparse sampling, dense sampling with low resolution, and token compression) suffer from significant information loss in temporal dynamics, spatial details, or subtle interactions, particularly in videos with complex motion or varying resolutions. To address this, we propose Mavors, a novel framework that introduces Multi-granularity video representation for holistic long-video modeling. Specifically, Mavors directly encodes raw video content into latent representations through two core components: 1) an Intra-chunk Vision Encoder (IVE) that preserves high-resolution spatial features via 3D convolutions and Vision Transformers, and 2) an Inter-chunk Feature Aggregator (IFA) that establishes temporal coherence across chunks using transformer-based dependency modeling with chunk-level rotary position encodings. Moreover, the framework unifies image and video understanding by treating images as single-frame videos via sub-image decomposition. Experiments across diverse benchmarks demonstrate Mavors' superiority in maintaining both spatial fidelity and temporal continuity, significantly outperforming existing methods in tasks requiring fine-grained spatio-temporal reasoning."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Mavors: Multi-granularity Video Representation for Multimodal Large Language Model](https://arxiv.org/abs/2504.10068)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We introduce FUSION, a family of multimodal large language models (MLLMs) with a fully vision-language alignment and integration paradigm. Unlike existing methods that primarily rely on late-stage modality interaction during LLM decoding, our approach achieves deep, dynamic integration throughout the entire processing pipeline. To this end, we propose Text-Guided Unified Vision Encoding, incorporating textual information in vision encoding to achieve pixel-level integration. We further design Context-Aware Recursive Alignment Decoding that recursively aggregates visual features conditioned on textual context during decoding, enabling fine-grained, question-level semantic integration. To guide feature mapping and mitigate modality discrepancies, we develop Dual-Supervised Semantic Mapping Loss. Additionally, we construct a Synthesized Language-Driven Question-Answer (QA) dataset through a new data synthesis method, prioritizing high-quality QA pairs to optimize text-guided feature integration. Building on these foundations, we train FUSION at two scales-3B, 8B-and demonstrate that our full-modality integration approach significantly outperforms existing methods with only 630 vision tokens. Notably, FUSION 3B surpasses Cambrian-1 8B and Florence-VL 8B on most benchmarks. FUSION 3B continues to outperform Cambrian-1 8B even when limited to 300 vision tokens. Our ablation studies show that FUSION outperforms LLaVA-NeXT on over half of the benchmarks under same configuration without dynamic resolution, highlighting the effectiveness of our approach. We release our code, model weights, and dataset. https://github.com/starriver030515/FUSION'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [FUSION: Fully Integration of Vision-Language Representations for Deep Cross-Modal Understanding](https://arxiv.org/abs/2504.09925)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "The rise of LLM-driven AI characters raises safety concerns, particularly for vulnerable human users with psychological disorders. To address these risks, we propose EmoAgent, a multi-agent AI framework designed to evaluate and mitigate mental health hazards in human-AI interactions. EmoAgent comprises two components: EmoEval simulates virtual users, including those portraying mentally vulnerable individuals, to assess mental health changes before and after interactions with AI characters. It uses clinically proven psychological and psychiatric assessment tools (PHQ-9, PDI, PANSS) to evaluate mental risks induced by LLM. EmoGuard serves as an intermediary, monitoring users' mental status, predicting potential harm, and providing corrective feedback to mitigate risks. Experiments conducted in popular character-based chatbots show that emotionally engaging dialogues can lead to psychological deterioration in vulnerable users, with mental state deterioration in more than 34.4% of the simulations. EmoGuard significantly reduces these deterioration rates, underscoring its role in ensuring safer AI-human interactions. Our code is available at: https://github.com/1akaman/EmoAgent"}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [EmoAgent: Assessing and Safeguarding Human-AI Interaction for Mental Health Safety](https://arxiv.org/abs/2504.09689)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Recently, improving the reasoning ability of large multimodal models (LMMs) through reinforcement learning has made great progress. However, most existing works are based on highly reasoning-intensive datasets such as mathematics and code, and researchers generally choose large-scale models as the foundation. We argue that exploring small-scale models\' reasoning capabilities remains valuable for researchers with limited computational resources. Moreover, enabling models to explain their reasoning processes on general question-answering datasets is equally meaningful. Therefore, we present the small-scale video reasoning model TinyLLaVA-Video-R1. Based on TinyLLaVA-Video, a traceably trained video understanding model with no more than 4B parameters, it not only demonstrates significantly improved reasoning and thinking capabilities after using reinforcement learning on general Video-QA datasets, but also exhibits the emergent characteristic of "aha moments". Furthermore, we share a series of experimental findings, aiming to provide practical insights for future exploration of video reasoning (thinking) abilities in small-scale models. It is available at https://github.com/ZhangXJ199/TinyLLaVA-Video-R1.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [TinyLLaVA-Video-R1: Towards Smaller LMMs for Video Reasoning](https://arxiv.org/abs/2504.09641)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Web agents enable users to perform tasks on web browsers through natural language interaction. Evaluating web agents trajectories is an important problem, since it helps us determine whether the agent successfully completed the tasks. Rule-based methods are widely used for this purpose, but they are challenging to extend to new tasks and may not always recognize successful trajectories. We may achieve higher accuracy through human evaluation, but the process would be substantially slower and more expensive. Automatic evaluations with LLMs may avoid the challenges of designing new rules and manually annotating trajectories, enabling faster and cost-effective evaluation. However, it is unclear how effective they are at evaluating web agents. To this end, we propose AgentRewardBench, the first benchmark to assess the effectiveness of LLM judges for evaluating web agents. AgentRewardBench contains 1302 trajectories across 5 benchmarks and 4 LLMs. Each trajectory in AgentRewardBench is reviewed by an expert, who answers questions pertaining to the success, side effects, and repetitiveness of the agent. Using our benchmark, we evaluate 12 LLM judges and find that no single LLM excels across all benchmarks. We also find that the rule-based evaluation used by common benchmarks tends to underreport the success rate of web agents, highlighting a key weakness of rule-based evaluation and the need to develop more flexible automatic evaluations. We release the benchmark at: https://agent-reward-bench.github.io'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [AgentRewardBench: Evaluating Automatic Evaluations of Web Agent Trajectories](https://arxiv.org/abs/2504.08942)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Recently, slow-thinking systems like GPT-o1 and DeepSeek-R1 have demonstrated great potential in solving challenging problems through explicit reflection. They significantly outperform the best fast-thinking models, such as GPT-4o, on various math and science benchmarks. However, their multimodal reasoning capabilities remain on par with fast-thinking models. For instance, GPT-o1's performance on benchmarks like MathVista, MathVerse, and MathVision is similar to fast-thinking models. In this paper, we aim to enhance the slow-thinking capabilities of vision-language models using reinforcement learning (without relying on distillation) to advance the state of the art. First, we adapt the GRPO algorithm with a novel technique called Selective Sample Replay (SSR) to address the vanishing advantages problem. While this approach yields strong performance, the resulting RL-trained models exhibit limited self-reflection or self-verification. To further encourage slow-thinking, we introduce Forced Rethinking, which appends a textual rethinking trigger to the end of initial rollouts in RL training, explicitly enforcing a self-reflection reasoning step. By combining these two techniques, our model, VL-Rethinker, advances state-of-the-art scores on MathVista, MathVerse, and MathVision to achieve 80.3%, 61.8%, and 43.9% respectively. VL-Rethinker also achieves open-source SoTA on multi-disciplinary benchmarks such as MMMU-Pro, EMMA, and MEGA-Bench, narrowing the gap with GPT-o1."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [VL-Rethinker: Incentivizing Self-Reflection of Vision-Language Models with Reinforcement Learning](https://arxiv.org/abs/2504.08837)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "OpenAI's multimodal GPT-4o has demonstrated remarkable capabilities in image generation and editing, yet its ability to achieve world knowledge-informed semantic synthesis--seamlessly integrating domain knowledge, contextual reasoning, and instruction adherence--remains unproven. In this study, we systematically evaluate these capabilities across three critical dimensions: (1) Global Instruction Adherence, (2) Fine-Grained Editing Precision, and (3) Post-Generation Reasoning. While existing benchmarks highlight GPT-4o's strong capabilities in image generation and editing, our evaluation reveals GPT-4o's persistent limitations: the model frequently defaults to literal interpretations of instructions, inconsistently applies knowledge constraints, and struggles with conditional reasoning tasks. These findings challenge prevailing assumptions about GPT-4o's unified understanding and generation capabilities, exposing significant gaps in its dynamic knowledge integration. Our study calls for the development of more robust benchmarks and training strategies that go beyond surface-level alignment, emphasizing context-aware and reasoning-grounded multimodal generation."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Have we unified image generation and understanding yet? An empirical study of GPT-4o's image generation ability](https://arxiv.org/abs/2504.08003)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Emergency of DeepSeek R1 and QwQ 32B have broken through performance barriers for running frontier large language models (LLMs) on home devices. While consumer hardware is getting stronger and model quantization is improving, existing end-side solutions still demand GPU clusters, large RAM/VRAM, and high bandwidth, far beyond what a common home cluster can handle. This paper introduces prima.cpp, a distributed inference system that runs 70B-scale models on everyday home devices using a mix of CPU/GPU, low RAM/VRAM, Wi-Fi, and cross-platform support. It uses mmap to manage model weights and introduces piped-ring parallelism with prefetching to hide disk loading. By modeling heterogeneity in computation, communication, disk, memory (and its management behavior), and OS, it optimally assigns model layers to each device's CPU and GPU, further reducing token latency. An elegant algorithm named Halda is proposed to solve this NP-hard assignment problem. We evaluate prima.cpp on a common four-node home cluster. It outperforms llama.cpp, exo, and dllama on 30B+ models while keeping memory pressure below 6%. This brings frontier 30B-70B models, such as Llama 3, DeepSeek R1, Qwen 2.5, and QwQ to home assistants, making advanced AI truly accessible to individuals. The code is open source and available at https://github.com/Lizonghang/prima.cpp."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [PRIMA.CPP: Speeding Up 70B-Scale LLM Inference on Low-Resource Everyday Home Clusters](https://arxiv.org/abs/2504.08791)
append_entries: 12
Finish: 2025-04-15 06:11:36.006055
------------------------------------------------------
Started: 2025-04-15 09:00:46.880670
Existing_entries: 1012
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-15 09:00:47.082501
------------------------------------------------------
Started: 2025-04-15 12:00:48.081931
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Effective reasoning is crucial to solving complex mathematical problems. Recent large language models (LLMs) have boosted performance by scaling test-time computation through long chain-of-thought reasoning. However, transformer-based models are inherently limited in extending context length due to their quadratic computational complexity and linear memory requirements. In this paper, we introduce a novel hybrid linear RNN reasoning model, M1, built on the Mamba architecture, which allows memory-efficient inference. Our approach leverages a distillation process from existing reasoning models and is further enhanced through RL training. Experimental results on the AIME and MATH benchmarks show that M1 not only outperforms previous linear RNN models but also matches the performance of state-of-the-art Deepseek R1 distilled reasoning models at a similar scale. We also compare our generation speed with a highly performant general purpose inference engine, vLLM, and observe more than a 3x speedup compared to a same size transformer. With throughput speedup, we are able to achieve higher accuracy compared to DeepSeek R1 distilled transformer reasoning models under a fixed generation time budget using self-consistency voting. Overall, we introduce a hybrid Mamba reasoning model and provide a more effective approach to scaling test-time generation using self-consistency or long chain of thought reasoning.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [M1: Towards Scalable Test-Time Compute with Mamba Reasoning Models](https://arxiv.org/abs/2504.10449)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Recent advancements in Large Language Models (LLMs) have enabled them to approach human-level persuasion capabilities. However, such potential also raises concerns about the safety risks of LLM-driven persuasion, particularly their potential for unethical influence through manipulation, deception, exploitation of vulnerabilities, and many other harmful tactics. In this work, we present a systematic investigation of LLM persuasion safety through two critical aspects: (1) whether LLMs appropriately reject unethical persuasion tasks and avoid unethical strategies during execution, including cases where the initial persuasion goal appears ethically neutral, and (2) how influencing factors like personality traits and external pressures affect their behavior. To this end, we introduce PersuSafety, the first comprehensive framework for the assessment of persuasion safety which consists of three stages, i.e., persuasion scene creation, persuasive conversation simulation, and persuasion safety assessment. PersuSafety covers 6 diverse unethical persuasion topics and 15 common unethical strategies. Through extensive experiments across 8 widely used LLMs, we observe significant safety concerns in most LLMs, including failing to identify harmful persuasion tasks and leveraging various unethical persuasion strategies. Our study calls for more attention to improve safety alignment in progressive and goal-driven conversations such as persuasion.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [LLM Can be a Dangerous Persuader: Empirical Study of Persuasion Safety in Large Language Models](https://arxiv.org/abs/2504.10430)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Graphical User Interface (GUI) agents offer cross-platform solutions for automating complex digital tasks, with significant potential to transform productivity workflows. However, their performance is often constrained by the scarcity of high-quality trajectory data. To address this limitation, we propose training Vision Language Models (VLMs) on data-rich, reasoning-intensive tasks during a dedicated mid-training stage, and then examine how incorporating these tasks facilitates generalization to GUI planning scenarios. Specifically, we explore a range of tasks with readily available instruction-tuning data, including GUI perception, multimodal reasoning, and textual reasoning. Through extensive experiments across 11 mid-training tasks, we demonstrate that: (1) Task generalization proves highly effective, yielding substantial improvements across most settings. For instance, multimodal mathematical reasoning enhances performance on AndroidWorld by an absolute 6.3%. Remarkably, text-only mathematical data significantly boosts GUI web agent performance, achieving a 5.6% improvement on WebArena and 5.4% improvement on AndroidWorld, underscoring notable cross-modal generalization from text-based to visual domains; (2) Contrary to prior assumptions, GUI perception data - previously considered closely aligned with GUI agent tasks and widely utilized for training - has a comparatively limited impact on final performance; (3) Building on these insights, we identify the most effective mid-training tasks and curate optimized mixture datasets, resulting in absolute performance gains of 8.0% on WebArena and 12.2% on AndroidWorld. Our work provides valuable insights into cross-domain knowledge transfer for GUI agents and offers a practical approach to addressing data scarcity challenges in this emerging field. The code, data and models will be available at https://github.com/hkust-nlp/GUIMid.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Breaking the Data Barrier -- Building GUI Agents Through Task Generalization](https://arxiv.org/abs/2504.10127)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Scientists often infer abstract procedures from specific instances of problems and use the abstractions to generate new, related instances. For example, programs encoding the formal rules and properties of a system have been useful in fields ranging from RL (procedural environments) to physics (simulation engines). These programs can be seen as functions which execute to different outputs based on their parameterizations (e.g., gridworld configuration or initial physical conditions). We introduce the term EFA (Executable Functional Abstraction) to denote such programs for math problems. EFA-like constructs have been shown to be useful for math reasoning as problem generators for stress-testing models. However, prior work has been limited to abstractions for grade-school math (whose simple rules are easy to encode in programs), while generating EFAs for advanced math has thus far required human engineering. We explore the automatic construction of EFAs for advanced math problems. We operationalize the task of automatically constructing EFAs as a program synthesis task, and develop EFAGen, which conditions an LLM on a seed math problem and its step-by-step solution to generate candidate EFA programs that are faithful to the generalized problem and solution class underlying the seed problem. Furthermore, we formalize properties any valid EFA must possess in terms of executable unit tests, and show how the tests can be used as verifiable rewards to train LLMs to become better writers of EFAs. We demonstrate that EFAs constructed by EFAGen behave rationally by remaining faithful to seed problems, produce learnable problem variations, and that EFAGen can infer EFAs across multiple diverse sources of competition-level math problems. Finally, we show downstream uses of model-written EFAs e.g. finding problem variations that are harder or easier for a learner to solve, as well as data generation.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Executable Functional Abstractions: Inferring Generative Programs for Advanced Math Problems](https://arxiv.org/abs/2504.09763)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Generating high-quality code that solves complex programming tasks is challenging, especially with current decoder-based models that produce highly stochastic outputs. In code generation, even minor errors can easily break the entire solution. Leveraging multiple sampled solutions can significantly improve the overall output quality.   One effective way to enhance code generation is by pairing a code generation model with a reranker model, which selects the best solution from the generated samples. We propose a novel iterative self-training approach for self-training reranker models using Proximal Policy Optimization (PPO), aimed at improving both reranking accuracy and the overall code generation process. Unlike traditional PPO approaches, where the focus is on optimizing a generative model with a reward model, our approach emphasizes the development of a robust reward/reranking model. This model improves the quality of generated code through reranking and addresses problems and errors that the reward model might overlook during PPO alignment with the reranker. Our method iteratively refines the training dataset by re-evaluating outputs, identifying high-scoring negative examples, and incorporating them into the training loop, that boosting model performance.   Our evaluation on the MultiPL-E dataset demonstrates that our 13.4B parameter model outperforms a 33B model in code generation quality while being three times faster. Moreover, it achieves performance comparable to GPT-4 and surpasses it in one programming language.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Iterative Self-Training for Code Generation via Reinforced Re-Ranking](https://arxiv.org/abs/2504.09643)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Large language models learn and continually learn through the accumulation of gradient-based updates, but how individual pieces of new information affect existing knowledge, leading to both beneficial generalization and problematic hallucination, remains poorly understood. We demonstrate that when learning new information, LLMs exhibit a "priming" effect: learning a new fact can cause the model to inappropriately apply that knowledge in unrelated contexts. To systematically study this phenomenon, we introduce "Outlandish," a carefully curated dataset of 1320 diverse text samples designed to probe how new knowledge permeates through an LLM\'s existing knowledge base. Using this dataset, we show that the degree of priming after learning new information can be predicted by measuring the token probability of key words before learning. This relationship holds robustly across different model architectures (PALM-2, Gemma, Llama), sizes, and training stages. Finally, we develop two novel techniques to modulate how new knowledge affects existing model behavior: (1) a ``stepping-stone\'\' text augmentation strategy and (2) an ``ignore-k\'\' update pruning method. These approaches reduce undesirable priming effects by 50-95\\% while preserving the model\'s ability to learn new information. Our findings provide both empirical insights into how LLMs learn and practical tools for improving the specificity of knowledge insertion in language models. Further materials: https://sunchipsster1.github.io/projects/outlandish/'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [How new data permeates LLM knowledge and how to dilute it](https://arxiv.org/abs/2504.09522)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Recent advancements in Large Vision-Language Models have showcased remarkable capabilities. However, they often falter when confronted with complex reasoning tasks that humans typically address through visual aids and deliberate, step-by-step thinking. While existing methods have explored text-based slow thinking or rudimentary visual assistance, they fall short of capturing the intricate, interleaved nature of human visual-verbal reasoning processes. To overcome these limitations and inspired by the mechanisms of slow thinking in human cognition, we introduce VisuoThink, a novel framework that seamlessly integrates visuospatial and linguistic domains. VisuoThink facilitates multimodal slow thinking by enabling progressive visual-textual reasoning and incorporates test-time scaling through look-ahead tree search. Extensive experiments demonstrate that VisuoThink significantly enhances reasoning capabilities via inference-time scaling, even without fine-tuning, achieving state-of-the-art performance in tasks involving geometry and spatial reasoning.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search](https://arxiv.org/abs/2504.09130)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'AI is increasingly playing a pivotal role in transforming how scientific discoveries are made. We introduce The AI Scientist-v2, an end-to-end agentic system capable of producing the first entirely AI generated peer-review-accepted workshop paper. This system iteratively formulates scientific hypotheses, designs and executes experiments, analyzes and visualizes data, and autonomously authors scientific manuscripts. Compared to its predecessor (v1, Lu et al., 2024 arXiv:2408.06292), The AI Scientist-v2 eliminates the reliance on human-authored code templates, generalizes effectively across diverse machine learning domains, and leverages a novel progressive agentic tree-search methodology managed by a dedicated experiment manager agent. Additionally, we enhance the AI reviewer component by integrating a Vision-Language Model (VLM) feedback loop for iterative refinement of content and aesthetics of the figures. We evaluated The AI Scientist-v2 by submitting three fully autonomous manuscripts to a peer-reviewed ICLR workshop. Notably, one manuscript achieved high enough scores to exceed the average human acceptance threshold, marking the first instance of a fully AI-generated paper successfully navigating a peer review. This accomplishment highlights the growing capability of AI in conducting all aspects of scientific research. We anticipate that further advancements in autonomous scientific discovery technologies will profoundly impact human knowledge generation, enabling unprecedented scalability in research productivity and significantly accelerating scientific breakthroughs, greatly benefiting society at large. We have open-sourced the code at https://github.com/SakanaAI/AI-Scientist-v2 to foster the future development of this transformative technology. We also discuss the role of AI in science, including AI safety.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [The AI Scientist-v2: Workshop-Level Automated Scientific Discovery via Agentic Tree Search](https://arxiv.org/abs/2504.08066)
append_entries: 8
Finish: 2025-04-15 12:00:52.474425
------------------------------------------------------
Started: 2025-04-18 05:13:48.870304
Existing_entries: 1008
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 808
Summarized using qwen-turbo
Append: [BitNet b1.58 2B4T：首个开源1比特20亿参数大型语言模型](https://arxiv.org/abs/2504.12285)
Token length: 1035
Summarized using qwen-turbo
Append: [基于激光雷达的零样本形状补全方法CAL](https://arxiv.org/abs/2504.12264)
Token length: 1339
Summarized using qwen-turbo
Append: [Cobra：高效灵活的漫画线条艺术着色方法](https://arxiv.org/abs/2504.12240)
Token length: 1118
Summarized using qwen-turbo
Append: [多语言混合作者文本中AI生成内容检测模型的研究](https://arxiv.org/abs/2504.11952)
Token length: 1848
Summarized using qwen-turbo
Append: [ReTool：通过工具集成学习提升复杂数学推理能力](https://arxiv.org/abs/2504.11536)
Token length: 1113
Summarized using qwen-turbo
Append: [Vivid4D：基于单目视频的4D动态场景重建方法](https://arxiv.org/abs/2504.11092)
Token length: 1308
Summarized using qwen-turbo
Append: [基于表示对齐的端到端扩散模型训练方法](https://arxiv.org/abs/2504.10483)
Token length: 1030
Summarized using qwen-turbo
Append: [AlayaDB：面向大规模语言模型的高效向量数据库系统](https://arxiv.org/abs/2504.10326)
Token length: 1545
Summarized using qwen-turbo
Append: [MLRC-Bench：评估大语言模型在机器学习研究竞赛中的表现](https://arxiv.org/abs/2504.09702)
Json decode failed:
{
  "title": "Syzygy of Thoughts：通过代数方法增强语言模型的推理能力",
  "short_summary": "提出一种基于代数原理的新框架Syzygy of Thoughts，显著提升复杂问题解决能力。",
  "summary": "本文介绍了一种名为Syzygy of Thoughts（SoT）的新框架，该框架通过引入辅助且相互关联的推理路径，扩展了传统的Chain-of-Thought（CoT）提示方法。受交换代数和代数几何中的Minimal Free Resolution（MFR）启发，SoT能够捕捉更深的逻辑依赖关系，从而实现更加稳健和结构化的推理过程。SoT将原问题分解成一系列具有最小自由度的子问题，同时保持关键特征并缩短推理长度。实验表明，SoT在多种数据集和模型上达到了与主流CoT相当甚至更高的推理准确性，并通过优化采样过程提高了大规模语言模型的推理效率。未来，我们的代码将在https:
  "keyword": ["推理增强", "Syzygy of Thoughts", "Minimal Free Resolution"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 304 (char 425). Line: 406.
Append: [Syzygy of Thoughts: Improving LLM CoT with the Minimal Free Resolution](https://arxiv.org/abs/2504.09566)
Token length: 1092
Summarized using qwen-turbo
Append: [AI语音生成技术对多语言口音影响的社会技术分析](https://arxiv.org/abs/2504.09346)
Token length: 836
Summarized using qwen-turbo
Append: [基于SIFT的大规模语音指令微调数据集与语言模型](https://arxiv.org/abs/2504.09081)
Token length: 1593
Summarized using qwen-turbo
Append: [BlockGaussian：高效高质量的大规模场景重建框架](https://arxiv.org/abs/2504.09048)
Token length: 1725
Summarized using qwen-turbo
Append: [大型视觉语言模型训练中的伪推理路径问题及改进方法](https://arxiv.org/abs/2504.11468)
Token length: 1585
Summarized using qwen-turbo
Append: [ColorBench：评估视觉语言模型颜色理解能力的基准](https://arxiv.org/abs/2504.10514)
append_entries: 15
Finish: 2025-04-18 05:14:47.948826
------------------------------------------------------
Started: 2025-04-18 06:19:55.461122
Existing_entries: 1015
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1407
Summarized using qwen-turbo
Append: [REVERSE：一种统一的视觉-语言模型幻觉缓解框架](https://arxiv.org/abs/2504.13169)
Json decode failed:
{
  "title": "对抗蒸馏采样：保护大模型实用性的新策略",
  "short_summary": "对抗蒸馏采样通过修改概率分布削弱模型蒸馏效果。",
  "summary": "前沿的大规模语言模型在生成扩展推理追踪时会无意间产生丰富的标记序列，这些序列可促进模型蒸馏。意识到这一潜在漏洞后，模型所有者可能寻求限制蒸馏效果但不影响模型性能的采样策略。对抗蒸馏采样正是为此提供了解决方案。它通过战略性地调整模型的下一标记概率分布，毒化推理追踪，从而显著降低其对蒸馏的有效性，同时保持模型的实际效用。对抗蒸馏采样的具体实现细节和技术机制，可以在https:
  "keyword": ["对抗蒸馏", "模型蒸馏", "采样策略"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 202 (char 283). Line: 406.
Append: [Antidistillation Sampling](https://arxiv.org/abs/2504.13146)
Token length: 1259
Summarized using qwen-turbo
Append: [VistaDPO：基于层次化空间-时间直接偏好优化的大规模视频模型对齐框架](https://arxiv.org/abs/2504.13122)
Token length: 963
Summarized using qwen-turbo
Append: [FramePack：用于视频生成的高效帧预测神经网络结构](https://arxiv.org/abs/2504.12626)
Token length: 1078
Summarized using qwen-turbo
Append: [WorldMem：基于记忆模块提升世界模拟中的时空一致性](https://arxiv.org/abs/2504.12369)
Json decode failed:
{
  "title": "ChartQAPro：面向复杂图表推理的新基准测试",
  "short_summary": "新基准ChartQAPro引入多样化图表及问题类型，揭示现代模型性能瓶颈。",
  "summary": "图表广泛应用于数据分析，但进行复杂分析需要大量认知努力。现有的图表问答(CQA)系统通过自动化处理数据可视化推理任务提高了效率，然而现有数据集如ChartQA缺乏多样性且面临性能饱和问题。为解决这一局限性，我们开发了ChartQAPro，该数据集包含来自157个来源的1,341张图表，涵盖多种图表类型及1,948个多样化问题，如多选、对话、假设及无法回答的问题，以更好地模拟现实世界挑战。对21个模型的评估显示，视觉语言模型(VLVM)在ChartQAPro上的表现显著下降，例如Claude Sonnet 3.5在ChartQA上得分为90.5%，而在ChartQAPro上仅为55.81%。我们的研究还通过详细错误分析和消融实验确定了提升VLVM在图表理解和推理方面能力的关键挑战与机遇。ChartQAPro现已开源，可访问https:
  "keyword": ["图表问答", "视觉语言模型", "基准测试"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 386 (char 487). Line: 406.
Append: [ChartQAPro: A More Diverse and Challenging Benchmark for Chart Question Answering](https://arxiv.org/abs/2504.05506)
append_entries: 6
Finish: 2025-04-18 06:20:17.698488
------------------------------------------------------
Started: 2025-04-18 12:26:38.729174
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1468
Summarized using qwen-turbo
Append: [通过睡眠计算提升大语言模型推理效率](https://arxiv.org/abs/2504.13171)
Token length: 1501
Summarized using qwen-turbo
Append: [CLIMB框架实现高效预训练数据混合优化](https://arxiv.org/abs/2504.13161)
Token length: 1613
Summarized using qwen-turbo
Append: [利用专家失败探索提升大型语言模型代理性能](https://arxiv.org/abs/2504.13145)
Token length: 1853
Summarized using qwen-turbo
Append: [多因素挑战下的RAG系统改进：RAMDocs与MADAM-RAG](https://arxiv.org/abs/2504.13079)
Token length: 1238
Summarized using qwen-turbo
Append: [NoisyRollout：通过视觉导向策略增强视觉语言模型的推理能力](https://arxiv.org/abs/2504.13055)
Token length: 1673
Summarized using qwen-turbo
Append: [ANT：通过自动引导去噪轨迹实现文本转图像模型的概念擦除](https://arxiv.org/abs/2504.12782)
Token length: 1582
Summarized using qwen-turbo
Append: [InstantCharacter：基于扩散Transformer的可扩展角色定制框架](https://arxiv.org/abs/2504.12395)
Token length: 1393
Summarized using qwen-turbo
Append: [基于分数蒸馏的文本到图像模型合并方法](https://arxiv.org/abs/2504.12364)
Json decode failed:
{
  "title": "FocusedAD：以角色为中心的电影音频描述框架",
  "short_summary": "提出一种新框架FocusedAD，生成以角色为中心的电影音频描述。",
  "summary": "Movie Audio Description (AD) 是为了在无对话片段中叙述视觉内容，尤其有助于盲人和视力障碍者。与普通视频字幕不同，AD需要情节相关的叙述并明确引用角色名称，因此面临独特挑战。我们提出了FocusedAD框架，包括角色感知模块（CPM）、动态先验模块（DPM）和聚焦字幕模块（FCM），旨在识别活跃主角并关注与剧情相关区域。此外，还引入自动化管道构建角色查询库以解决角色识别限制。FocusedAD在多个基准测试中表现优异，包括MAD-eval-Named和新提出的Cinepile-AD数据集的零样本结果。代码和数据将在https:
  "keyword": ["Movie Audio Description", "FocusedAD", "Character-Centric"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 294 (char 391). Line: 406.
Append: [FocusedAD: Character-centric Movie Audio Description](https://arxiv.org/abs/2504.12157)
Token length: 1638
Summarized using qwen-turbo
Append: [GRA框架：多小模型协作生成高质量数据](https://arxiv.org/abs/2504.12322)
append_entries: 10
Finish: 2025-04-18 12:27:33.890380
------------------------------------------------------
Started: 2025-04-18 18:18:13.500841
Existing_entries: 1010
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1257
Summarized using qwen-turbo
Append: [Perception Encoder：通过视觉-语言对比学习实现多任务通用编码器](https://arxiv.org/abs/2504.13181)
Token length: 1546
Summarized using qwen-turbo
Append: [MetaSynth：通过元提示增强合成数据多样性以实现领域自适应](https://arxiv.org/abs/2504.12563)
Token length: 1242
Summarized using qwen-turbo
Append: [基于学习的跨相机色彩恒常性方法](https://arxiv.org/abs/2504.07959)
append_entries: 3
Finish: 2025-04-18 18:18:31.329952
------------------------------------------------------
Started: 2025-04-19 01:03:57.865563
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "动态长度浮点压缩框架DFloat11实现大语言模型高效部署",
  "short_summary": "提出一种新框架DFloat11，可将大语言模型大小减少30%，同时保持输出精度。",
  "summary": "本文介绍了一种名为DFloat11的新框架，这是一种无损压缩方法，可以将大型语言模型（LLMs）的大小减少约30%，同时确保输出与原始模型完全相同（比特位完全一致）。DFloat11的设计灵感来源于LLMs中BFloat16权重表示的低熵特性，揭示了现有存储格式的效率低下。通过应用熵编码技术，该框架根据权重出现频率分配动态长度编码，实现了接近信息最优的压缩效果且不丢失任何精度。为了支持高效推理，我们开发了一个定制化的GPU内核以实现在线解压缩。此外，我们的设计还包括分解内存密集型查找表为适合GPU SRAM的紧凑型查找表、采用两阶段内核协调线程读写位置以及按Transformer块级别进行解压缩等优化措施，从而最小化延迟。实验表明，在最近发布的模型如Llama-3.1、Qwen-2.5和Gemma-3上，DFloat11不仅达到了预期的压缩率，还显著提高了推理吞吐量并延长了上下文长度。特别值得一提的是，我们的方法能够在配备8块80GB显存GPU的单节点上实现对Llama-3.1-405B（810GB模型）的无损推理。我们的代码和模型已公开发布在https:
  "keyword": ["大语言模型", "无损压缩", "动态长度浮点"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 500 (char 608). Line: 406.
Append: [70% Size, 100% Accuracy: Lossless LLM Compression for Efficient GPU Inference via Dynamic-Length Float](https://arxiv.org/abs/2504.11651)
append_entries: 1
Finish: 2025-04-19 01:04:03.885954
------------------------------------------------------
Started: 2025-04-19 06:18:36.573220
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1288
Summarized using qwen-turbo
Append: [构建透明图像与视频理解研究的开放性感知语言模型](https://arxiv.org/abs/2504.13180)
Token length: 1650
Summarized using qwen-turbo
Append: [Complex-Edit：基于指令的图像编辑模型综合评估基准](https://arxiv.org/abs/2504.13143)
Token length: 1408
Summarized using qwen-turbo
Append: [基于Vision Transformer的无人机跟踪中抗遮挡表示学习](https://arxiv.org/abs/2504.09228)
append_entries: 3
Finish: 2025-04-19 06:18:51.465511
------------------------------------------------------
Started: 2025-04-19 12:23:42.214375
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-19 12:23:42.501151
------------------------------------------------------
Started: 2025-04-19 18:17:09.961691
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-19 18:17:10.215312
------------------------------------------------------
Started: 2025-04-20 01:11:44.571502
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-20 01:11:44.841727
------------------------------------------------------
Started: 2025-04-20 06:18:31.714982
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-20 06:18:31.886896
------------------------------------------------------
Started: 2025-04-20 12:24:24.722548
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-20 12:24:24.981612
------------------------------------------------------
Started: 2025-04-20 18:17:21.104849
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-20 18:17:21.306442
------------------------------------------------------
Started: 2025-04-21 01:10:41.606453
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-21 01:10:41.932058
------------------------------------------------------
Started: 2025-04-21 06:20:18.625396
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-21 06:20:18.795292
------------------------------------------------------
Started: 2025-04-21 12:27:08.830749
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1859
Summarized using qwen-turbo
Append: [强化学习与可验证奖励对大语言模型推理能力的影响](https://arxiv.org/abs/2504.13837)
Token length: 1458
Summarized using qwen-turbo
Append: [基于最大信息增益的指令微调数据高效采样方法](https://arxiv.org/abs/2504.13835)
Token length: 1801
Summarized using qwen-turbo
Append: [基于注意力偏差的深度学习架构设计框架Miras](https://arxiv.org/abs/2504.13173)
Token length: 1668
Summarized using qwen-turbo
Append: [结合伪合成与真实图像的空中地面视角几何重建](https://arxiv.org/abs/2504.13157)
Token length: 1293
Summarized using qwen-turbo
Append: [HiScene：基于层次结构的场景级3D生成框架](https://arxiv.org/abs/2504.13072)
Token length: 980
Summarized using qwen-turbo
Append: [多语言推理在大型语言模型中的上限潜力研究](https://arxiv.org/abs/2504.11833)
Token length: 1430
Summarized using qwen-turbo
Append: [NodeRAG：基于异构图结构的大规模语言模型增强型检索生成框架](https://arxiv.org/abs/2504.11544)
append_entries: 7
Finish: 2025-04-21 12:27:50.965596
------------------------------------------------------
Started: 2025-04-21 18:19:10.685303
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1522
Summarized using qwen-turbo
Append: [ThoughtMani：通过外部CoTs减少大型推理模型的冗余推理步骤](https://arxiv.org/abs/2504.13626)
Token length: 1699
Summarized using qwen-turbo
Append: [CLASH数据集评估大型语言模型在高风险情境下的价值决策能力](https://arxiv.org/abs/2504.10823)
Token length: 1417
Summarized using qwen-turbo
Append: [DehazeXL：一种高效处理大分辨率图像雾霾去除的方法](https://arxiv.org/abs/2504.09621)
append_entries: 3
Finish: 2025-04-21 18:19:28.886745
------------------------------------------------------
Started: 2025-04-22 01:07:22.594558
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1260
Summarized using qwen-turbo
Append: [从知识检索到思维构建：生成式AI的第二幕](https://arxiv.org/abs/2504.13828)
Token length: 1314
Summarized using qwen-turbo
Append: [多语言大型语言模型的知识边界感知研究](https://arxiv.org/abs/2504.13816)
Token length: 885
Summarized using qwen-turbo
Append: [语言模型中不确定性量化评估的偏差问题及其解决方案](https://arxiv.org/abs/2504.13677)
Json decode failed:
{
  "title": "基于注意力引导双边滤波的低剂量CT单图像去噪框架",
  "short_summary": "提出一种可解释的自监督单图像去噪框架Filter2Noise(F2N)，显著提升低剂量CT图像质量。",
  "summary": "低剂量计算机断层扫描(CT)中的有效降噪对于增强细微结构和低对比度病灶至关重要，但监督方法受限于有限配对数据集，而自监督方法通常需要多张噪声图像并依赖深度网络如U-Net，难以提供去噪机制的直观理解。为解决这些挑战，我们提出了一个可解释的自监督单图像去噪框架——Filter2Noise(F2N)。该框架引入了一个注意力引导双边滤波器，通过轻量级模块预测空间变化的滤波参数，这些参数在训练后可以可视化并调整，从而实现用户对感兴趣区域的可控去噪。为了实现单图像训练，我们引入了一种新颖的下采样洗牌策略和新的自监督损失函数，将Noise2Noise的概念扩展到单图像，并解决了空间相关噪声问题。在Mayo Clinic 2016低剂量CT数据集上的实验表明，F2N在峰值信噪比(PSNR)上比领先的自监督单图像方法(ZS-N2N)高出4.59 dB，同时提高了透明性、用户控制能力和参数效率。这些特性为需要精确且可解释噪声减少的医学应用提供了关键优势。我们的代码可在https:
  "keyword": ["低剂量CT", "单图像去噪", "自监督学习"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 452 (char 565). Line: 406.
Append: [Filter2Noise: Interpretable Self-Supervised Single-Image Denoising for Low-Dose CT with Attention-Guided Bilateral Filtering](https://arxiv.org/abs/2504.13519)
Token length: 1840
Summarized using qwen-turbo
Append: [基于生产理论的语言模型经济价值评估框架](https://arxiv.org/abs/2504.13359)
Token length: 1493
Summarized using qwen-turbo
Append: [基于自我校准框架的大型视频语言模型改进研究](https://arxiv.org/abs/2504.12083)
append_entries: 6
Finish: 2025-04-22 01:07:46.078924
------------------------------------------------------
Started: 2025-04-22 06:20:17.962579
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-22 06:20:18.175735
------------------------------------------------------
Started: 2025-04-22 12:27:52.652850
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1656
Summarized using qwen-turbo
Append: [StyleMe3D：实现3D高斯点云风格迁移的综合性框架](https://arxiv.org/abs/2504.15281)
Json decode failed:
{
  "title": "多模态大语言模型在多视角场景理解中的挑战与评估",
  "short_summary": "研究提出All-Angles Bench基准测试多视角场景理解能力。",
  "summary": "多视角理解（Multi-view understanding），即整合来自不同视角的视觉信息以支持导航、操作及三维场景理解，是多模态大型语言模型（MLLMs）作为具身代理时面临的一项基础性挑战。尽管近期的MLLMs在高级推理和规划方面取得了显著进展，但它们在处理多视角几何一致性与跨视角对应关系时往往表现欠佳。为全面评估MLLMs在多视角场景推理方面的挑战，我们设计并发布了All-Angles Bench，这是一个包含超过2100个人工标注的多视角问答对的基准，涵盖90个多样化的真实世界场景。该基准包含六个具体任务：计数、属性识别、相对距离、相对方向、物体操作及相机姿态估计，旨在测试模型的几何对应能力和跨视角信息对齐能力。通过广泛的实验，我们发现当前主流的27个MLLMs（如Gemini-2.0-Flash、Claude-3.7-Sonnet和GPT-4o）与人类评估者相比存在显著性能差距。深入分析显示，MLLMs在部分遮挡视角下的跨视角对应关系以及粗略相机姿态估计方面表现尤为不足。这些发现强调了开发特定领域改进模块以增强多视角感知能力的重要性。我们认为，All-Angles Bench提供了有价值的见解，有助于缩小MLLMs与人类水平多视角理解之间的差距。该项目及其基准现已公开访问：https:
  "keyword": ["多模态大型语言模型", "多视角理解", "All-Angles Bench"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 571 (char 667). Line: 406.
Append: [Seeing from Another Perspective: Evaluating Multi-View Understanding in MLLMs](https://arxiv.org/abs/2504.15280)
Token length: 1082
Summarized using qwen-turbo
Append: [Eagle 2.5：面向长上下文多模态学习的前沿视觉语言模型](https://arxiv.org/abs/2504.15271)
Token length: 1427
Summarized using qwen-turbo
Append: [Quicksviewer：基于动态时间密度划分的高效多模态模型](https://arxiv.org/abs/2504.15270)
Token length: 993
Summarized using qwen-turbo
Append: [基于推理的查询级元代理FlowReasoner自动化设计](https://arxiv.org/abs/2504.15257)
Token length: 1920
Summarized using qwen-turbo
Append: [DRAGON框架：一种灵活的生成模型微调方法](https://arxiv.org/abs/2504.15217)
Token length: 1265
Summarized using qwen-turbo
Append: [EasyEdit2：支持大语言模型实时行为调控的新框架](https://arxiv.org/abs/2504.15133)
Token length: 1709
Summarized using qwen-turbo
Append: [RainbowPlus：基于进化计算的大语言模型红队框架](https://arxiv.org/abs/2504.15047)
Token length: 1249
Summarized using qwen-turbo
Append: [LUFFY框架：通过离线策略指导提升大规模推理模型的泛化能力](https://arxiv.org/abs/2504.14945)
Token length: 1664
Summarized using qwen-turbo
Append: [Uni3C：统一3D增强框架实现视频生成中摄像机与人体运动的精确控制](https://arxiv.org/abs/2504.14899)
Token length: 1373
Summarized using qwen-turbo
Append: [TAPIP3D：一种新颖的单目RGB和RGB-D视频中的长期3D点跟踪方法](https://arxiv.org/abs/2504.14717)
Token length: 755
Summarized using qwen-turbo
Append: [LeetCodeDataset：面向代码生成模型的高质量基准数据集](https://arxiv.org/abs/2504.14655)
Token length: 1482
Summarized using qwen-turbo
Append: [UFO2：面向Windows桌面的多智能体操作系统实现可靠自动化](https://arxiv.org/abs/2504.14603)
Token length: 1361
Summarized using qwen-turbo
Append: [SphereDiff：一种无缝全景图像与视频生成方法](https://arxiv.org/abs/2504.14396)
Json decode failed:
{
  "title": "基于MLLM的GUI代理InfiGUI-R1：从反应式行为到深思熟虑推理的转变",
  "short_summary": "提出一种通过两阶段训练将GUI代理从反应式行为转变为深思熟虑推理的方法。",
  "summary": "本文探讨了多模态大型语言模型（MLLMs）在图形用户界面（GUI）任务中的应用，特别是在自动化计算设备上的任务。尽管已有工作展示了令人鼓舞的结果，但许多现有方法依赖于手工设计的推理模板，这可能导致推理不够稳健和适应复杂GUI环境。此外，一些现有代理仍作为反应式演员运作，缺乏足够的深度进行需要规划和错误恢复的任务。为了解决这些问题，我们提出了InfiGUI-R1，这是一个通过Actor2Reasoner框架开发的MLLM基GUI代理。该框架采用推理为中心的两阶段训练方法，逐步将代理从反应式行为转变为深思熟虑推理。第一阶段称为推理注入，专注于构建基本推理器，通过显式推理步骤的轨迹将跨模态空间推理能力从教师模型转移到MLLMs，使模型能够在动作生成之前整合GUI视觉空间信息和逻辑推理。第二阶段为深思熟虑增强，使用强化学习细化基本推理器为深思熟虑推理器。此阶段引入了两种方法：子目标指导和错误恢复场景构建。实验结果显示，InfiGUI-R1在GUI定位和轨迹任务中表现出色。更多资源可访问https:
  "keyword": ["GUI代理", "MLLM", "推理"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 466 (char 580). Line: 406.
Append: [InfiGUI-R1: Advancing Multimodal GUI Agents from Reactive Actors to Deliberative Reasoners](https://arxiv.org/abs/2504.14239)
Token length: 1593
Summarized using qwen-turbo
Append: [通过人机演示提升移动GUI代理性能](https://arxiv.org/abs/2504.13805)
Token length: 1439
Summarized using qwen-turbo
Append: [强化学习中工具使用奖励设计的研究与实践](https://arxiv.org/abs/2504.13958)
Token length: 819
Summarized using qwen-turbo
Append: [基于单目摄像机的多人3D姿态检测与跟踪方法](https://arxiv.org/abs/2504.12186)
Token length: 1677
Summarized using qwen-turbo
Append: [NEMOTRON-CROSSTHINK：强化学习框架提升大语言模型跨领域推理能力](https://arxiv.org/abs/2504.13941)
Token length: 1349
Summarized using qwen-turbo
Append: [X-Teaming：一种高效的多轮对话语言模型攻击框架](https://arxiv.org/abs/2504.13203)
Token length: 1048
Summarized using qwen-turbo
Append: [基于生成模型的新型透视变形图像创作](https://arxiv.org/abs/2504.08902)
append_entries: 21
Finish: 2025-04-22 12:29:36.228943
------------------------------------------------------
Started: 2025-04-22 18:19:37.548476
Existing_entries: 1021
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-22 18:19:38.012664
------------------------------------------------------
Started: 2025-04-23 01:07:43.244525
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1446
Summarized using qwen-turbo
Append: [通过强化学习优化工具集成推理中的工具使用效率](https://arxiv.org/abs/2504.14870)
Token length: 1090
Summarized using qwen-turbo
Append: [推理模型过思考问题的研究与优化](https://arxiv.org/abs/2504.13367)
Token length: 1908
Summarized using qwen-turbo
Append: [RF-DETR与YOLOv12在复杂果园环境中的绿果检测对比研究](https://arxiv.org/abs/2504.13099)
Token length: 1473
Summarized using qwen-turbo
Append: [基于语音交互的医学视觉语言模型SilVar-Med及其可解释性研究](https://arxiv.org/abs/2504.10642)
append_entries: 4
Finish: 2025-04-23 01:07:59.787842
------------------------------------------------------
Started: 2025-04-23 06:20:20.075704
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "基于测试时强化学习的无标签数据大语言模型训练方法",
  "short_summary": "提出一种利用无标签数据通过强化学习提升大语言模型性能的新方法。",
  "summary": "本文研究了在大型语言模型（LLMs）的推理任务中，针对无显式标签数据的强化学习（RL）。主要挑战是在推断过程中缺乏真实奖励信息的情况下进行奖励估计。我们发现测试时缩放（TTS）中的常见实践（如多数投票）能有效产生适合驱动强化学习训练的奖励。为此，我们引入了测试时强化学习（TTRL），这是一种利用预训练模型先验知识的新型方法。实验表明，TTRL在多种任务和模型上均能稳定提升性能，例如在AIME 2024比赛中，Qwen-2.5-Math-7B的pass@1性能提升了约159%。尽管TTRL仅由Maj@N指标监督，但其表现已超越初始模型上限并接近直接使用真实标签训练的模型性能。我们的研究验证了TTRL在各种任务上的有效性，并展示了其在更广泛领域中的潜力。GitHub链接：https:
  "keyword": ["强化学习", "大语言模型", "无标签数据"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 359 (char 453). Line: 406.
Append: [TTRL: Test-Time Reinforcement Learning](https://arxiv.org/abs/2504.16084)
Token length: 1435
Summarized using qwen-turbo
Append: [MR. Video：基于MapReduce原理的长视频理解框架](https://arxiv.org/abs/2504.16082)
Token length: 1352
Summarized using qwen-turbo
Append: [ReflectionFlow：基于推理时自省的文本到图像扩散模型优化框架](https://arxiv.org/abs/2504.16080)
Token length: 979
Summarized using qwen-turbo
Append: [Describe Anything Model：实现图像和视频的精细化局部描述](https://arxiv.org/abs/2504.16072)
Json decode failed:
{
  "title": "基于自动语音识别的低成本大规模视频语言模型训练方法",
  "short_summary": "提出一种基于ASR自动转录的大规模视频语言模型训练新方法。",
  "summary": "本文探讨了一种利用廉价自动语音识别(ASR)转录进行大规模视频语言模型训练的新方法。该方法通过时间戳密集交错ASR单词和视频帧，使模型能够学习到时间对齐且细粒度的视觉-语言建模。为了支持这一算法，我们构建了一个数据生产管道处理YouTube视频及其字幕，生成了Live-CC-5M预训练数据集和Live-WhisperX-526K高质量监督微调(SFT)数据集。实验表明，即使不经过SFT，仅使用ASR转录预训练的LiveCC-7B-Base模型也能在通用视频问答(QA)任务上表现出色，并具备实时视频评论能力。进一步优化后，LiveCC-7B-Instruct模型在实时模式下甚至超越了更大规模的72B参数模型，在多个流行视频QA基准测试中达到了最先进的性能，展示了该方法的广泛适用性。所有资源已公开发布于https:
  "keyword": ["Video LLM", "ASR", "实时视频评论"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 375 (char 468). Line: 406.
Append: [LiveCC: Learning Video LLM with Streaming Speech Transcription at Scale](https://arxiv.org/abs/2504.16030)
Token length: 1496
Summarized using qwen-turbo
Append: [通过神经符号世界模型提升大型语言模型代理性能](https://arxiv.org/abs/2504.15785)
Token length: 1818
Summarized using qwen-turbo
Append: [Vidi：面向视频编辑的大规模多模态模型](https://arxiv.org/abs/2504.15681)
Token length: 1825
Summarized using qwen-turbo
Append: [多语言基准评估的现状与未来：挑战与改进建议](https://arxiv.org/abs/2504.15521)
Token length: 1476
Summarized using qwen-turbo
Append: [自适应并行推理框架提升语言模型推理能力](https://arxiv.org/abs/2504.15466)
Json decode failed:
{
    "title": "IV-Bench：首个评估图像引导视频感知与推理能力的综合基准",
    "short_summary": "研究提出IV-Bench，评估现有多模态大语言模型在图像引导视频理解中的不足。",
    "summary": "当前对多模态大型语言模型的评估框架主要集中在图像推理或一般视频理解上，忽视了图像上下文在视频理解中的重要作用。为此，我们提出了IV-Bench，这是第一个全面评估图像引导视频感知与推理能力的基准。IV-Bench包含967个视频及其2585个精心标注的图像-文本查询，涵盖13项任务（7项感知任务和6项推理任务）及5个代表性类别。对最新开源和闭源多模态大型语言模型的广泛评估显示，现有模型在这方面的表现显著不足，最高准确率仅为28.9%。进一步分析表明，推理模式、帧数和分辨率等因素影响模型性能。此外，通过简单的数据合成方法，我们发现IV-Bench的挑战不仅限于训练过程中的数据格式对齐问题。这些发现为未来研究提供了宝贵见解。相关代码和数据已发布在https:
    "keyword": ["多模态大型语言模型", "图像引导视频理解", "IV-Bench"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 348 (char 461). Line: 406.
Append: [IV-Bench: A Benchmark for Image-Grounded Video Perception and Reasoning in Multimodal LLMs](https://arxiv.org/abs/2504.15415)
Token length: 1105
Summarized using qwen-turbo
Append: [基于平行隐藏解码的高效长度缩放预训练框架](https://arxiv.org/abs/2504.14992)
Token length: 1531
Summarized using qwen-turbo
Append: [基于DiT模型的可控角色动画生成方法](https://arxiv.org/abs/2504.14977)
Token length: 1121
Summarized using qwen-turbo
Append: [BookWorld：基于书籍的多智能体社会构建与模拟系统](https://arxiv.org/abs/2504.14538)
Token length: 1605
Summarized using qwen-turbo
Append: [CheXWorld：基于自监督学习的胸部X光影像世界模型](https://arxiv.org/abs/2504.13820)
Token length: 1916
Summarized using qwen-turbo
Append: [Progent：一种用于大型语言模型代理的权限控制机制](https://arxiv.org/abs/2504.11703)
append_entries: 15
Finish: 2025-04-23 06:21:17.452770
------------------------------------------------------
Started: 2025-04-23 12:28:15.872991
Existing_entries: 1015
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1210
Summarized using qwen-turbo
Append: [通过强化学习优化大型语言模型的决策能力](https://arxiv.org/abs/2504.16078)
Token length: 1289
Summarized using qwen-turbo
Append: [IPBench：推动大语言模型在知识产权领域的应用评估](https://arxiv.org/abs/2504.15524)
Token length: 968
Summarized using qwen-turbo
Append: [高效整合新语言到大型语言模型的方法研究](https://arxiv.org/abs/2504.15120)
Token length: 1313
Summarized using qwen-turbo
Append: [DiffVox：一种可微分的音乐人声效果匹配模型](https://arxiv.org/abs/2504.14735)
append_entries: 4
Finish: 2025-04-23 12:28:29.161965
------------------------------------------------------
Started: 2025-04-23 18:20:24.652871
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1795
Summarized using qwen-turbo
Append: [视觉语言模型在处理遮挡模式计数中的挑战与局限性](https://arxiv.org/abs/2504.15485)
Token length: 1021
Summarized using qwen-turbo
Append: [基于自回归模型的个性化图像合成研究](https://arxiv.org/abs/2504.13162)
append_entries: 2
Finish: 2025-04-23 18:20:31.870820
------------------------------------------------------
Started: 2025-04-24 01:07:48.052505
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-24 01:07:48.282800
------------------------------------------------------
Started: 2025-04-24 06:20:52.364083
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1247
Summarized using qwen-turbo
Append: [统一信息论框架下的现代机器学习损失函数](https://arxiv.org/abs/2504.16929)
Token length: 1675
Summarized using qwen-turbo
Append: [DreamO：一种支持多类型条件集成的图像定制框架](https://arxiv.org/abs/2504.16915)
Token length: 1910
Summarized using qwen-turbo
Append: [Decoupled Global-Local Alignment框架提升视觉语言对齐模型的复合概念理解](https://arxiv.org/abs/2504.16801)
Token length: 1314
Summarized using qwen-turbo
Append: [Pre-DPO：通过引导参考模型优化偏好强化学习](https://arxiv.org/abs/2504.15843)
Token length: 728
Summarized using qwen-turbo
Append: [Trillion-7B：高效韩文多语言大模型](https://arxiv.org/abs/2504.15431)
Token length: 1035
Summarized using qwen-turbo
Append: [VisuLogic：评估多模态大型语言模型视觉推理能力的新基准](https://arxiv.org/abs/2504.15279)
append_entries: 6
Finish: 2025-04-24 06:21:15.460347
------------------------------------------------------
Started: 2025-04-24 12:28:53.191352
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1574
Summarized using qwen-turbo
Append: [Tina：基于LoRA高效实现语言模型强推理能力的研究](https://arxiv.org/abs/2504.15777)
Json decode failed:
{
    "title": "评估MSCOCO标注误差对POPE基准的影响",
    "short_summary": "研究发现MSCOCO标签错误显著影响POPE基准模型排名。",
    "summary": "随着数据标注成本增加，基准数据集常借用已建立图像数据集的标签。本研究评估了MSCOCO标签错误对常用目标检测基准POPE的影响，重新标注基准图像后发现不同子集间存在标注误差不平衡现象。通过在修订后的标签（命名为RePOPE）上评估多个模型，我们观察到模型排名出现显著变化，凸显了标签质量的重要性。相关代码和数据可在https:
    "keyword": ["数据标注", "标签误差", "基准评估"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 180 (char 274). Line: 406.
Append: [RePOPE: Impact of Annotation Errors on the POPE Benchmark](https://arxiv.org/abs/2504.15707)
Token length: 1898
Summarized using qwen-turbo
Append: [大型语言模型全栈安全综述](https://arxiv.org/abs/2504.15585)
Token length: 1533
Summarized using qwen-turbo
Append: [CRUST-Bench：评估C转Rust编译的基准数据集](https://arxiv.org/abs/2504.15254)
Token length: 1720
Summarized using qwen-turbo
Append: [DreamID：基于扩散模型的高效高保真人脸交换技术](https://arxiv.org/abs/2504.14509)
Token length: 1481
Summarized using qwen-turbo
Append: [基于LLM自适应难度的高质量链式思维数据生成方法](https://arxiv.org/abs/2504.11919)
Token length: 916
Summarized using qwen-turbo
Append: [CheckboxQA：评估视觉语言模型处理复选框能力的新基准](https://arxiv.org/abs/2504.10419)
append_entries: 7
Finish: 2025-04-24 12:29:19.685895
------------------------------------------------------
Started: 2025-04-24 18:19:16.334323
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1094
Summarized using qwen-turbo
Append: [构建顶级数学推理模型的方法与实践](https://arxiv.org/abs/2504.16891)
Json decode failed:
{
  "title": "PHYBench：评估大语言模型物理推理能力的新基准",
  "short_summary": "PHYBench是一个评估大语言模型物理推理能力的新基准，涵盖多个物理领域。",
  "summary": "本文介绍了一个名为PHYBench的新基准，它由500个精心策划的物理问题组成，旨在评估大型语言模型（LLMs）在理解与推理现实物理过程中的能力。PHYBench覆盖了从高中到大学水平及物理奥林匹克竞赛难度的问题，涉及力学、电磁学、热力学、光学、现代物理和高级物理等领域。此外，我们还提出了表达编辑距离（EED）评分，这是一种基于数学表达式编辑距离的新型评估指标，可以更有效地捕捉模型推理过程和结果之间的差异。通过对多个LLMs进行评估并与人类专家比较，结果表明即使最先进的推理模型也显著落后于人类专家，强调了在复杂物理推理场景中改进的需求。PHYBench的结果和数据集可在https:
  "keyword": ["大语言模型", "物理推理", "PHYBench"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 309 (char 412). Line: 406.
Append: [PHYBench: Holistic Evaluation of Physical Perception and Reasoning in Large Language Models](https://arxiv.org/abs/2504.16074)
Token length: 1826
Summarized using qwen-turbo
Append: [基于渐进语言引导视觉学习的多任务视觉定位框架](https://arxiv.org/abs/2504.16145)
append_entries: 3
Finish: 2025-04-24 18:19:29.124371
------------------------------------------------------
Started: 2025-04-25 01:08:13.825568
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "Causal-Copilot：将高级因果分析带入专家级应用",
  "short_summary": "Causal-Copilot是一款结合因果发现和推理的自动化工具，降低非专业人士门槛。",
  "summary": "因果分析对科学研究和决策制定至关重要，但因复杂性常被领域专家忽视。为解决这一问题，我们开发了Causal-Copilot，这是一种基于大型语言模型的自主代理，能够实现从表数据到时间序列数据的完整因果分析流程，包括因果发现、推断、算法选择、超参数优化、结果解释及生成可操作见解。通过自然语言交互，它降低了非专业人士的使用门槛，同时保持方法学严谨性。集成超过20种最先进的因果分析技术，该系统促进了因果方法在实际中的广泛应用，推动了因果理论的发展。实验表明，Causal-Copilot在性能上优于现有基线，提供了一种可靠、可扩展且可扩展的解决方案，弥合了理论复杂性和实际应用之间的差距。Causal-Copilot的在线互动演示可在https:
  "keyword": ["因果分析", "自动化工具", "领域专家"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 336 (char 447). Line: 406.
Append: [Causal-Copilot: An Autonomous Causal Analysis Agent](https://arxiv.org/abs/2504.13263)
append_entries: 1
Finish: 2025-04-25 01:08:17.738938
------------------------------------------------------
Started: 2025-04-25 06:20:28.630877
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1412
Summarized using qwen-turbo
Append: [Step1X-Edit：开源图像编辑模型的突破性进展](https://arxiv.org/abs/2504.17761)
Token length: 1740
Summarized using qwen-turbo
Append: [UniME：基于多模态大语言模型的表征学习框架](https://arxiv.org/abs/2504.17432)
Token length: 1361
Summarized using qwen-turbo
Append: [基于抽象视角变化的视觉语言模型视角感知推理框架](https://arxiv.org/abs/2504.17207)
append_entries: 3
Finish: 2025-04-25 06:20:41.470668
------------------------------------------------------
Started: 2025-04-25 12:28:17.087348
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1840
Summarized using qwen-turbo
Append: [Token-Shuffle：通过维度重排提升基于Transformer的文本到高分辨率图像生成](https://arxiv.org/abs/2504.17789)
Token length: 1374
Summarized using qwen-turbo
Append: [结合线性和非线性方法的新一代降维算法](https://arxiv.org/abs/2504.17601)
Token length: 1176
Summarized using qwen-turbo
Append: [RefVNLI：一种高效可靠的文本到图像生成评估方法](https://arxiv.org/abs/2504.17502)
Token length: 1410
Summarized using qwen-turbo
Append: [基于扩散模型的高质量视频试穿框架3DV-TON](https://arxiv.org/abs/2504.17414)
Token length: 1868
Summarized using qwen-turbo
Append: [TimeChat-Online：革新实时视频交互的在线VideoLLM](https://arxiv.org/abs/2504.17343)
Token length: 1461
Summarized using qwen-turbo
Append: [PaperCoder：基于多智能体大语言模型的论文代码自动生成框架](https://arxiv.org/abs/2504.17192)
Token length: 1386
Summarized using qwen-turbo
Append: [基于任意顺序补丁生成的自回归图像生成方法](https://arxiv.org/abs/2504.17069)
Token length: 1477
Summarized using qwen-turbo
Append: [DyMU：一种高效且无需训练的视觉-语言模型动态计算降低框架](https://arxiv.org/abs/2504.17040)
Token length: 1829
Summarized using qwen-turbo
Append: [IberBench：评估伊比利亚半岛及伊比罗-美洲语言的大语言模型基准](https://arxiv.org/abs/2504.16921)
Token length: 1625
Summarized using qwen-turbo
Append: [QuaDMix：统一框架优化大语言模型训练数据的质量与多样性](https://arxiv.org/abs/2504.16511)
Token length: 1184
Summarized using qwen-turbo
Append: [一种结合表征学习与扩散模型的图像生成新框架](https://arxiv.org/abs/2504.16064)
Token length: 1756
Summarized using qwen-turbo
Append: [ViSMap：基于元提示的无监督视频摘要技术](https://arxiv.org/abs/2504.15921)
append_entries: 12
Finish: 2025-04-25 12:29:20.303334
------------------------------------------------------
Started: 2025-04-25 18:19:43.296446
Existing_entries: 1012
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1439
Summarized using qwen-turbo
Append: [DiMeR：一种用于稀疏视图网格重建的解耦双流前馈模型](https://arxiv.org/abs/2504.17670)
Json decode failed:
{
  "title": "ThinkPRM：基于长链推理的高效过程奖励模型",
  "short_summary": "ThinkPRM通过生成验证链推理显著减少标签需求，提升测试时间计算效率。",
  "summary": "过程奖励模型（PRMs）是测试时间扩展的关键组件，但需要逐步骤监督，训练成本高昂。本文提出ThinkPRM，一种通过生成验证链推理（CoT）实现高效训练的长链推理模型。相比判别式PRMs，ThinkPRM仅需1%的过程标签即可在多个基准测试中表现更优，包括ProcessBench、MATH-500和AIME "24。此外，在GPQA-Diamond和LiveCodeBench的域外评估中，ThinkPRM分别超越传统判别式模型8%和4.5%。同时，ThinkPRM在相同计算预算下，比LLM-as-a-Judge更有效地扩展了验证计算能力，提升了7.2%性能。研究强调了生成式长链推理PRMs在低监督条件下提升测试时间计算扩展性的价值。相关代码、数据和模型将在https:
  "keyword": ["过程奖励模型", "长链推理", "测试时间扩展"]
}Summarization failed, append the original article
error: Expecting ',' delimiter: line 4 column 171 (char 271). Line: 406.
Append: [Process Reward Models That Think](https://arxiv.org/abs/2504.16828)
append_entries: 2
Finish: 2025-04-25 18:19:52.601509
------------------------------------------------------
Started: 2025-04-26 01:05:49.676425
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 969
Summarized using qwen-turbo
Append: [DynPose-100K：大规模动态互联网视频的相机姿态标注数据集](https://arxiv.org/abs/2504.17788)
append_entries: 1
Finish: 2025-04-26 01:05:53.971888
------------------------------------------------------
Started: 2025-04-26 06:18:24.344556
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-26 06:18:24.562922
------------------------------------------------------
Started: 2025-04-26 12:24:49.039850
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-26 12:24:49.270935
------------------------------------------------------
Started: 2025-04-26 18:17:23.963075
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-26 18:17:24.170743
------------------------------------------------------
Started: 2025-04-27 01:12:17.010272
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-27 01:12:17.206027
------------------------------------------------------
Started: 2025-04-27 06:19:00.982355
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-27 06:19:01.196030
------------------------------------------------------
Started: 2025-04-27 12:25:02.385407
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-27 12:25:02.556631
------------------------------------------------------
Started: 2025-04-27 18:17:28.175486
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-27 18:17:28.482427
------------------------------------------------------
Started: 2025-04-28 01:10:19.883498
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-28 01:10:20.092011
------------------------------------------------------
Started: 2025-04-28 06:27:55.727252
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 851
Summarized using qwen-turbo
Append: [BitNet v2：高效部署1比特大语言模型的新框架](https://arxiv.org/abs/2504.18415)
Token length: 1279
Summarized using qwen-turbo
Append: [MMLA基准：多模态语言理解能力的全面评估](https://arxiv.org/abs/2504.16427)
Token length: 1475
Summarized using qwen-turbo
Append: [CameraBench：评估与提升摄像机运动理解的数据集与基准](https://arxiv.org/abs/2504.15376)
Token length: 1898
Summarized using qwen-turbo
Append: [基于Dual Consistency SAM方法的上下文分割研究](https://arxiv.org/abs/2504.12080)
append_entries: 4
Finish: 2025-04-28 06:28:17.329678
------------------------------------------------------
Started: 2025-04-28 12:28:20.688787
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1653
Summarized using qwen-turbo
Append: [Transformer LLMs中稀疏注意力的研究：效率、准确性及扩展性分析](https://arxiv.org/abs/2504.17768)
Token length: 1465
Summarized using qwen-turbo
Append: [VideoVista-CulturalLingo：首个跨文化视频评估基准](https://arxiv.org/abs/2504.17821)
Token length: 1443
Summarized using qwen-turbo
Append: [Skywork R1V2：下一代多模态推理模型的突破性进展](https://arxiv.org/abs/2504.16656)
Token length: 1257
Summarized using qwen-turbo
Append: [零样本条件下的个性化视频生成模型](https://arxiv.org/abs/2504.17816)
Token length: 1774
Summarized using qwen-turbo
Append: [DianJin-R1：面向金融领域的推理增强框架](https://arxiv.org/abs/2504.15716)
append_entries: 4
Finish: 2025-04-28 12:28:43.015522
------------------------------------------------------
Started: 2025-04-28 18:20:33.162485
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "Kimi-Audio：开源音频基础模型实现跨模态卓越性能",
  "short_summary": "介绍Kimi-Audio，一种优秀的开源音频理解与生成模型。",
  "summary": "本文介绍了Kimi-Audio，这是一种专注于音频理解、生成及对话的开源基础模型。在构建过程中，我们采用了12.5Hz的音频分词器，设计了一种基于连续特征输入和离散标记输出的新架构，并开发了一种基于流匹配的块级流解码器。预训练数据集包含超过1300万小时涵盖多种模态的音频数据，如语音、声音和音乐，并通过精心设计的任务对模型进行持续预训练和微调，使其支持多样化的音频相关任务。评估结果显示，Kimi-Audio在语音识别、音频理解、音频问答和语音对话等多个基准测试中达到领先水平。项目代码、模型权重及评估工具包已公开发布于https:
  "keyword": ["音频模型", "开源", "跨模态"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 282 (char 379). Line: 406.
Append: [Kimi-Audio Technical Report](https://arxiv.org/abs/2504.18425)
Token length: 1035
Summarized using qwen-turbo
Append: [新一代小型推理模型Pleias-RAG在RAG和搜索领域的突破性进展](https://arxiv.org/abs/2504.18225)
Token length: 1653
Summarized using qwen-turbo
Append: [Transformer LLMs中稀疏注意力的研究：效率-准确性权衡与扩展性分析](https://arxiv.org/abs/2504.17768)
Token length: 1255
Summarized using qwen-turbo
Append: [针对意大利语优化的英语大型语言模型词汇适应技术](https://arxiv.org/abs/2504.17025)
append_entries: 4
Finish: 2025-04-28 18:20:52.161662
------------------------------------------------------
Started: 2025-04-29 01:08:09.993852
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-29 01:08:10.168834
------------------------------------------------------
Started: 2025-04-29 06:21:19.269103
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1333
Summarized using qwen-turbo
Append: [基于大型语言模型的手机图形用户界面智能代理综述](https://arxiv.org/abs/2504.19838)
Token length: 1304
Summarized using qwen-turbo
Append: [大型语言模型在医疗建议中的表现与用户交互挑战](https://arxiv.org/abs/2504.18919)
append_entries: 2
Finish: 2025-04-29 06:21:29.457601
------------------------------------------------------
Started: 2025-04-29 12:29:53.881620
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1624
Summarized using qwen-turbo
Append: [RepText：一种无需理解文本的多语言视觉文本生成方法](https://arxiv.org/abs/2504.19724)
Token length: 1342
Summarized using qwen-turbo
Append: [利用替代密码研究In-Context Learning中的双模态操作](https://arxiv.org/abs/2504.19395)
Token length: 1571
Summarized using qwen-turbo
Append: [基于自博弈批评者的大型语言模型推理可靠性评估方法](https://arxiv.org/abs/2504.19162)
Token length: 1681
Summarized using qwen-turbo
Append: [CipherBank：评估大型语言模型在密码学推理中的能力](https://arxiv.org/abs/2504.19093)
Token length: 1349
Summarized using qwen-turbo
Append: [VCBENCH：大型视觉语言模型在多模态数学推理中的挑战与评估](https://arxiv.org/abs/2504.18589)
Token length: 1184
Summarized using qwen-turbo
Append: [基于均匀下采样的群等变架构广义化研究](https://arxiv.org/abs/2504.17258)
Token length: 1511
Summarized using qwen-turbo
Append: [MMInference：一种加速多模态长上下文推理的动态稀疏注意力方法](https://arxiv.org/abs/2504.16083)
Token length: 1678
Summarized using qwen-turbo
Append: [基于可信赖生成的数据引擎TrustGeoGen用于几何问题求解](https://arxiv.org/abs/2504.15780)
append_entries: 8
Finish: 2025-04-29 12:30:30.072538
------------------------------------------------------
Started: 2025-04-29 18:20:03.624716
Existing_entries: 1008
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1507
Summarized using qwen-turbo
Append: [基于领域适应的Chisel代码生成模型ChiseLLM](https://arxiv.org/abs/2504.19144)
Json decode failed:
{
  "title": "VersBand：基于提示的多任务歌曲生成框架",
  "short_summary": "提出VersBand框架，解决基于提示的高质量对齐歌曲生成问题。",
  "summary": "本文介绍了一种名为VersBand的多任务歌曲生成框架，旨在通过基于提示的方式生成高质量且对齐良好的歌曲。VersBand由三个主要模型组成：VocalBand，一种解耦模型，采用流匹配方法生成歌声风格、音高和梅尔频谱图，支持快速高质量的歌声生成；AccompBand，一种基于流的变压器模型，结合Band-MOE机制，选择合适的专家以提升质量、对齐度和可控性，实现与人声对齐的可控高质量伴奏生成；LyricBand和MelodyBand两个生成模型分别负责歌词和旋律的生成，共同构建全面的多任务歌曲生成系统。实验结果显示，VersBand在多个歌曲生成任务中，无论是客观指标还是主观评价上均优于基线模型。相关音频样本可在https:
  "keyword": ["歌曲生成", "多任务学习", "基于提示控制"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 332 (char 426). Line: 406.
Append: [Versatile Framework for Song Generation with Prompt-based Control](https://arxiv.org/abs/2504.19062)
append_entries: 2
Finish: 2025-04-29 18:20:12.365952
------------------------------------------------------
Started: 2025-04-30 01:08:39.777743
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1389
Summarized using qwen-turbo
Append: [NORA：高效视觉-语言-动作模型实现机器人实时自主性](https://arxiv.org/abs/2504.19854)
Token length: 1920
Summarized using qwen-turbo
Append: [Mem0：基于记忆增强的大语言模型对话一致性优化](https://arxiv.org/abs/2504.19413)
append_entries: 2
Finish: 2025-04-30 01:08:47.687337
------------------------------------------------------
Started: 2025-04-30 06:20:37.913078
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "Yo"Chameleon：大型多模态模型个性化研究的首次尝试",
  "short_summary": "提出首个针对大型多模态模型个性化研究的方法Yo"Chameleon。",
  "summary": "本文介绍了Yo"Chameleon，这是首个专注于大型多模态模型（如GPT-4、Gemini、Chameleon）个性化研究的系统性方法。尽管这些模型功能强大且用户众多，但它们缺乏特定用户的个性化知识。此前的研究主要集中在文本生成的个性化，而如何将这些方法扩展到新领域，例如图像生成，仍是一个挑战。Yo"Chameleon通过软提示微调技术，利用3至5张特定概念的图片，嵌入主体相关的信息，从而实现对主体的问答以及在新情境下生成主体像素级细节的图像。该方法通过自提示优化机制平衡多模态性能，并采用“软正样本”图像生成方法提升少量样本设置下的图像质量。",
  "keyword": ["多模态模型", "个性化", "图像生成"]
}Summarization failed, append the original article
error: Expecting ',' delimiter: line 2 column 16 (char 17). Line: 406.
Append: [YoChameleon: Personalized Vision and Language Generation](https://arxiv.org/abs/2504.20998)
Token length: 1249
Summarized using qwen-turbo
Append: [基于RGB-DN视频的高效四维世界模型学习方法](https://arxiv.org/abs/2504.20995)
Token length: 1430
Summarized using qwen-turbo
Append: [UniversalRAG：一种支持多模态异构知识检索的增强型生成框架](https://arxiv.org/abs/2504.20734)
Token length: 1326
Summarized using qwen-turbo
Append: [ReasonIR-8B：首个专为推理任务训练的检索器](https://arxiv.org/abs/2504.20595)
Token length: 1919
Summarized using qwen-turbo
Append: [通过1-shot强化学习实现大型语言模型数学推理能力的有效提升](https://arxiv.org/abs/2504.20571)
append_entries: 5
Finish: 2025-04-30 06:21:00.180645
------------------------------------------------------
Started: 2025-04-30 12:28:02.339226
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 815
Summarized using qwen-turbo
Append: [X-Fusion：一种保持语言能力的多模态任务扩展框架](https://arxiv.org/abs/2504.20996)
Token length: 1891
Summarized using qwen-turbo
Append: [Chatbot Arena排名体系中的系统性问题及改进建议](https://arxiv.org/abs/2504.20879)
Json decode failed:
{
  "title": "基于多模态提示的沉浸式空间戏剧生成研究",
  "short_summary": "提出首个沉浸式空间戏剧生成模型ISDrama，解决多模态输入下的空间信息与戏剧韵律建模难题。",
  "summary": "本文聚焦于多模态沉浸式空间戏剧生成，旨在基于多模态提示创建具有戏剧性韵律的连续双耳语音，适用于增强现实（AR）、虚拟现实（VR）等领域。然而，此任务面临高数据采集成本及同时处理空间信息和戏剧韵律的挑战。为此，我们构建了首个多模态记录的空间戏剧数据集MRSDrama，并提出了首个通过多模态提示生成沉浸式空间戏剧的模型ISDrama。该模型由多模态姿态编码器和沉浸式戏剧Transformer组成，前者利用对比学习考虑声源移动带来的多普勒效应，后者则采用基于流的mamba-transformer架构生成高质量戏剧，并通过Drama-MOE模块选择合适专家提升韵律表现。此外，我们设计了一种上下文一致的无分类器引导策略，实现连贯的戏剧生成。实验结果显示，ISDrama在客观和主观指标上均优于基线模型。相关演示和数据集可在https:
  "keyword": ["沉浸式空间戏剧", "多模态提示", "生成模型"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 381 (char 485). Line: 406.
Append: [ISDrama: Immersive Spatial Drama Generation through Multimodal Prompting](https://arxiv.org/abs/2504.20630)
Token length: 1445
Summarized using qwen-turbo
Append: [Meta Policy Optimization提升大语言模型奖励对齐的鲁棒性](https://arxiv.org/abs/2504.20157)
Token length: 1515
Summarized using qwen-turbo
Append: [TreeHop：一种高效的多跳问答系统](https://arxiv.org/abs/2504.20114)
Token length: 1660
Summarized using qwen-turbo
Append: [DICE-Talk：基于解耦身份与情感的高表现力可泛化口型同步虚拟头像生成](https://arxiv.org/abs/2504.18087)
Token length: 1392
Summarized using qwen-turbo
Append: [BloomScrub：一种高效的大语言模型版权清除方法](https://arxiv.org/abs/2504.16046)
append_entries: 7
Finish: 2025-04-30 12:28:34.625658
------------------------------------------------------
Started: 2025-04-30 18:19:58.089218
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1335
Summarized using qwen-turbo
Append: [基于上下文提示的大规模图像编辑方法](https://arxiv.org/abs/2504.20690)
Token length: 1280
Summarized using qwen-turbo
Append: [基于视觉语言模型的3D目标检测系统性综述](https://arxiv.org/abs/2504.18738)
append_entries: 2
Finish: 2025-04-30 18:20:05.568300
------------------------------------------------------
Started: 2025-05-01 01:14:53.179899
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1013
Summarized using qwen-turbo
Append: [通过防御性思维提升大语言模型鲁棒性的研究](https://arxiv.org/abs/2504.20769)
Token length: 1855
Summarized using qwen-turbo
Append: [LawFlow：构建端到端法律工作流程的数据集](https://arxiv.org/abs/2504.18942)
Json decode failed:
{
  "title": "StarPO框架用于训练多轮对话语言模型的强化学习研究",
  "short_summary": "提出StarPO框架解决LLMs多轮交互强化学习中的挑战。",
  "summary": "本文探讨了训练大型语言模型作为交互代理的独特挑战，如长期决策和随机环境反馈的交互问题。尽管强化学习在静态任务上取得了进展，但多轮代理强化学习仍处于探索阶段。我们提出了StarPO（状态-思考-动作-奖励策略优化），一种针对轨迹级代理强化学习的一般框架，并引入RAGEN系统用于训练和评估LLM代理。研究在三个风格化环境中发现三大核心成果：首先，我们的代理强化学习显示了回声陷阱模式，通过StarPO-S稳定变体解决了这一问题；其次，发现在强化学习轨迹塑造中初始状态多样性、中等交互粒度和频繁采样有益；最后，显示没有精细的、推理感知的奖励信号，代理推理很难通过多轮强化学习出现，可能表现出浅层策略或虚构想法。代码和环境可在https:
  "keyword": ["强化学习", "大型语言模型", "多轮对话"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 331 (char 426). Line: 406.
Append: [RAGEN: Understanding Self-Evolution in LLM Agents via Multi-Turn Reinforcement Learning](https://arxiv.org/abs/2504.20073)
Token length: 1551
Summarized using qwen-turbo
Append: [基于强化学习的自主驾驶特权规划研究](https://arxiv.org/abs/2504.17838)
Token length: 1146
Summarized using qwen-turbo
Append: [基于解释性方法的强化学习从人类反馈中优化奖励分配](https://arxiv.org/abs/2504.16272)
append_entries: 5
Finish: 2025-05-01 01:15:15.567362
------------------------------------------------------
Started: 2025-05-01 06:21:20.371471
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1622
Summarized using qwen-turbo
Append: [ReVision：通过参数化物理知识提升视频生成模型能力](https://arxiv.org/abs/2504.21855)
Token length: 1383
Summarized using qwen-turbo
Append: [COMPACT：提升多模态大语言模型复杂视觉-语言任务性能的新方法](https://arxiv.org/abs/2504.21850)
Token length: 1486
Summarized using qwen-turbo
Append: [WebThinker：增强大型推理模型复杂知识密集型任务处理能力](https://arxiv.org/abs/2504.21776)
Token length: 1513
Summarized using qwen-turbo
Append: [Phi-4-reasoning：高效推理模型在复杂任务中的表现](https://arxiv.org/abs/2504.21318)
Token length: 1375
Summarized using qwen-turbo
Append: [通过系统训练提升小规模语言模型的推理能力](https://arxiv.org/abs/2504.21233)
Token length: 886
Summarized using qwen-turbo
Append: [软选择（Softpick）：一种改进Transformer注意力机制的新方法](https://arxiv.org/abs/2504.20966)
Token length: 1904
Summarized using qwen-turbo
Append: [RoboVerse：机器人学习的综合框架](https://arxiv.org/abs/2504.18904)
append_entries: 7
Finish: 2025-05-01 06:21:53.548061
------------------------------------------------------
Started: 2025-05-01 12:27:24.729347
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1154
Summarized using qwen-turbo
Append: [Sadeed：基于轻量解码器模型的阿拉伯文变音标注新方法](https://arxiv.org/abs/2504.21635)
Token length: 1855
Summarized using qwen-turbo
Append: [UniBiomed：基于多模态大语言模型的生物医学图像统一解释框架](https://arxiv.org/abs/2504.21336)
Token length: 1642
Summarized using qwen-turbo
Append: [基于子思维分析的大语言模型推理性能提升方法](https://arxiv.org/abs/2504.20708)
Token length: 1336
Summarized using qwen-turbo
Append: [大规模语言模型推理服务优化方法综述](https://arxiv.org/abs/2504.19720)
Token length: 901
Summarized using qwen-turbo
Append: [Foundation-Sec-8B：面向网络安全部署的大型语言模型](https://arxiv.org/abs/2504.21039)
append_entries: 5
Finish: 2025-05-01 12:27:44.613427
------------------------------------------------------
Started: 2025-05-01 18:19:52.708610
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "生成式AI在角色动画中的应用综述",
  "short_summary": "生成式AI正在重塑动画行业，本文综述其在面部动画等领域的最新进展。",
  "summary": "近年来，基础模型和扩散模型的突破显著降低了动画制作的时间和成本，使角色动画成为研究热点。本文首次从综合视角审视生成式AI在角色动画中的所有主要应用，涵盖面部动画、表情渲染、图像合成、虚拟角色创建、手势建模、运动合成、物体生成及纹理合成等领域。我们分析了领先的研究成果、实际部署案例、常用数据集及新兴趋势，并为初学者提供了背景知识介绍。此外，文章还探讨了开放性挑战并指明未来研究方向，为推动AI驱动的角色动画技术发展提供路线图。该综述旨在为进入生成式AI动画领域或相关领域的研究人员和开发者提供资源支持。更多资料可访问：https:
  "keyword": ["生成式AI", "角色动画", "综述"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 280 (char 368). Line: 406.
Append: [Generative AI for Character Animation: A Comprehensive Survey of Techniques, Applications, and Future Directions](https://arxiv.org/abs/2504.19056)
Token length: 1702
Summarized using qwen-turbo
Append: [基于对抗性动态的联合分析优化候选人特征研究](https://arxiv.org/abs/2504.19043)
append_entries: 2
Finish: 2025-05-01 18:20:01.538367
------------------------------------------------------
Started: 2025-05-02 01:08:56.248991
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-02 01:08:56.421835
------------------------------------------------------
Started: 2025-05-02 06:20:38.088691
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-02 06:20:38.253639
------------------------------------------------------
Started: 2025-05-02 12:27:57.355501
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1141
Summarized using qwen-turbo
Append: [基于双层推理过程的文本到图像生成模型T2I-R1](https://arxiv.org/abs/2505.00703)
Token length: 1635
Summarized using qwen-turbo
Append: [基于两阶段框架提升大型语言模型数学解题批评能力的研究](https://arxiv.org/abs/2505.00662)
Json decode failed:
{
  "title": "KeySync：解决唇同步表达泄漏与遮挡问题的两阶段框架",
  "short_summary": "提出一种两阶段框架KeySync，改进唇同步的视觉质量和减少表达泄漏。",
  "summary": "唇同步（lip synchronization）通常被视为音频驱动面部动画的一个简化变体，但其面临新的挑战如表情泄露和面部遮挡等问题，这些常被现有研究忽视。为解决这些问题，本文提出KeySync，这是一个两阶段框架，不仅解决了时间一致性问题，还通过精心设计的掩码策略处理泄露和遮挡问题。实验表明，KeySync在唇重建和跨同步方面达到最先进水平，显著提升了视觉质量并减少了表情泄露。此外，通过引入新的泄露度量标准LipLeak验证了其性能，并通过消融研究证明了新掩码方法的有效性。代码和模型权重可在https:
  "keyword": ["唇同步", "表达泄露", "遮挡"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 270 (char 372). Line: 406.
Append: [KeySync: A Robust Approach for Leakage-free Lip Synchronization in High Resolution](https://arxiv.org/abs/2505.00497)
Token length: 1534
Summarized using qwen-turbo
Append: [交互生成视频技术综述及其在多领域的应用与挑战](https://arxiv.org/abs/2504.21853)
Json decode failed:
{
  "title": "自适应高效推理框架优化大型语言模型的复杂推理",
  "short_summary": "提出一种两阶段框架，通过混合推理模型和双层偏好训练显著降低推理开销。",
  "summary": "近年来，长推理路径（Long-CoT）模型在复杂推理任务中表现优异，但伴随较高的推理开销问题。我们的实证分析显示，不同问题对长推理路径的需求存在差异，部分问题甚至出现精度下降。这促使我们探索适应性推理策略，根据输入调整推理深度。然而，现有工作主要聚焦于减少长推理路径内的冗余，未能充分挖掘更高效的策略。为此，我们提出了一个创新的两阶段框架，旨在实现推理的自适应与高效性。首先，构建混合推理模型融合长推理路径和短推理路径，提供多样化的推理风格；其次，采用双层偏好训练指导模型选择合适的推理风格并优先选择简洁且正确的推理路径。实验结果显示，该方法相比其他基线模型显著降低了推理成本，同时保持了性能。特别是在五个数学数据集上，推理路径长度平均减少了超过50%，展示了适应性策略在优化大型语言模型推理效率方面的潜力。代码即将发布于https:
  "keyword": ["自适应推理", "高效推理", "混合推理模型"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 382 (char 477). Line: 406.
Append: [AdaR1: From Long-CoT to Hybrid-CoT via Bi-Level Adaptive Reasoning Optimization](https://arxiv.org/abs/2504.21659)
Token length: 1391
Summarized using qwen-turbo
Append: [TF1-EN-3M：大规模开放道德故事数据集的开创性成果](https://arxiv.org/abs/2504.20605)
Token length: 1492
Summarized using qwen-turbo
Append: [MediAug：医学影像数据增强统一评估框架](https://arxiv.org/abs/2504.18983)
append_entries: 7
Finish: 2025-05-02 12:28:26.335530
------------------------------------------------------
Started: 2025-05-02 18:19:35.887022
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1662
Summarized using qwen-turbo
Append: [基于深度学习的城市多目标多摄像头车辆跟踪框架](https://arxiv.org/abs/2505.00534)
Token length: 1542
Summarized using qwen-turbo
Append: [通过自我生成示例提升大语言模型的序列决策性能](https://arxiv.org/abs/2505.00234)
Token length: 992
Summarized using qwen-turbo
Append: [强化学习增强大型语言模型在高功率火箭设计中的应用研究](https://arxiv.org/abs/2504.19394)
append_entries: 3
Finish: 2025-05-02 18:19:47.367236
------------------------------------------------------
Started: 2025-05-03 01:07:13.341268
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1280
Summarized using qwen-turbo
Append: [空间语音翻译技术：让听觉空间语言无缝转换](https://arxiv.org/abs/2504.18715)
append_entries: 1
Finish: 2025-05-03 01:07:20.249551
------------------------------------------------------
Started: 2025-05-03 06:18:47.848416
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1664
Summarized using qwen-turbo
Append: [基于离线模拟框架的软件特定技能集生成方法](https://arxiv.org/abs/2504.20406)
append_entries: 1
Finish: 2025-05-03 06:18:51.095949
------------------------------------------------------
Started: 2025-05-03 12:25:16.838893
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-03 12:25:17.074254
------------------------------------------------------
Started: 2025-05-03 18:18:01.255398
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-03 18:18:01.473085
------------------------------------------------------
Started: 2025-05-04 01:15:41.378419
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-04 01:15:41.544623
------------------------------------------------------
Started: 2025-05-04 06:19:31.346113
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-04 06:19:31.543868
------------------------------------------------------
Started: 2025-05-04 12:25:56.390262
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-04 12:25:56.614387
------------------------------------------------------
Started: 2025-05-04 18:18:36.756738
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-04 18:18:36.988307
------------------------------------------------------
Started: 2025-05-05 01:11:54.412303
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-05 01:11:54.565055
------------------------------------------------------
Started: 2025-05-05 06:21:49.319903
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-05 06:21:49.547909
------------------------------------------------------
Started: 2025-05-05 12:28:32.257744
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1417
Summarized using qwen-turbo
Append: [基于层状记忆与一致性引导的多对象迭代图像编辑框架](https://arxiv.org/abs/2505.01079)
Token length: 1243
Summarized using qwen-turbo
Append: [基于图神经网络的信号时态逻辑学习框架TeLoGraF](https://arxiv.org/abs/2505.00562)
Token length: 929
Summarized using qwen-turbo
Append: [生成式人工智能研究焦点转移及其潜在风险](https://arxiv.org/abs/2505.00174)
Token length: 1484
Summarized using qwen-turbo
Append: [X-Cross：一种高效的跨域推荐模型](https://arxiv.org/abs/2504.20859)
Token length: 1424
Summarized using qwen-turbo
Append: [PixelHacker：基于扩散模型的图像修复新范式](https://arxiv.org/abs/2504.20438)
Token length: 1110
Summarized using qwen-turbo
Append: [Context Organizer (CORG): 处理跨文档知识关系的新框架](https://arxiv.org/abs/2505.00023)
append_entries: 5
Finish: 2025-05-05 12:28:55.072092
------------------------------------------------------
Started: 2025-05-05 18:16:39.603337
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1417
Summarized using qwen-turbo
Append: [基于多层记忆与一致性引导的迭代图像编辑框架](https://arxiv.org/abs/2505.01079)
Token length: 1409
Summarized using qwen-turbo
Append: [Llama-Nemotron系列模型：开放且高效的异构推理模型家族](https://arxiv.org/abs/2505.00949)
Token length: 918
Summarized using qwen-turbo
Append: [基于逆映射学习的大型语言模型评估方法](https://arxiv.org/abs/2504.21117)
append_entries: 3
Finish: 2025-05-05 18:16:51.879446
------------------------------------------------------
Started: 2025-05-06 01:09:40.793234
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-06 01:09:40.951805
------------------------------------------------------
Started: 2025-05-06 06:20:45.326417
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1593
Summarized using qwen-turbo
Append: [基于强化学习的多模态奖励模型优化研究](https://arxiv.org/abs/2505.02835)
Token length: 1688
Summarized using qwen-turbo
Append: [FormalMATH：大规模数学定理形式化基准及其挑战](https://arxiv.org/abs/2505.02735)
Token length: 893
Summarized using qwen-turbo
Append: [LLaMA-Omni 2：基于大语言模型的高质量实时语音交互](https://arxiv.org/abs/2505.02625)
Token length: 1241
Summarized using qwen-turbo
Append: [Ming-Lite-Uni：开源多模态框架实现文本到图像生成及指令驱动图像编辑](https://arxiv.org/abs/2505.02471)
Token length: 1884
Summarized using qwen-turbo
Append: [基于对比指令优化的图像编辑方法](https://arxiv.org/abs/2505.02370)
Token length: 1261
Summarized using qwen-turbo
Append: [自适应模式学习提升社会智能模拟中的动态推理能力](https://arxiv.org/abs/2505.02156)
Token length: 1353
Summarized using qwen-turbo
Append: [TEMPURA框架提升视频因果事件关系理解](https://arxiv.org/abs/2505.01583)
Json decode failed:
{
  "title": "大规模语言模型低精度训练方法综述",
  "short_summary": "本文综述了现有低精度训练方法，按数值格式分类并讨论未来方向。",
  "summary": "近年来，大规模语言模型（LLMs）在多个领域表现出色，但其高昂的硬件资源需求限制了效率和可扩展性。为解决这一问题，低精度训练技术被广泛采用，显著提高了训练效率。然而，由于权重、激活值和梯度等组件可以采用不同的数值格式，导致研究领域呈现碎片化，难以形成统一视角。本文对现有低精度训练方法进行了全面回顾，并根据数值格式将这些方法分为三大类：固定点与整数方法、基于浮点数的方法和自定义格式方法。此外，还探讨了量化感知训练方法，该方法在前向传播过程中与低精度训练有相似之处。最后，文章指出了推动该领域发展的几个有前景的研究方向。相关论文已整理在https:
  "keyword": ["低精度训练", "大规模语言模型", "数值格式"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 289 (char 374). Line: 406.
Append: [Low-Precision Training of Large Language Models: Methods, Challenges, and Opportunities](https://arxiv.org/abs/2505.01043)
append_entries: 8
Finish: 2025-05-06 06:21:34.541576
------------------------------------------------------
Started: 2025-05-06 12:30:22.564935
Existing_entries: 1008
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1296
Summarized using qwen-turbo
Append: [MUSAR：仅需单领域训练数据的多领域定制框架](https://arxiv.org/abs/2505.02823)
Token length: 1254
Summarized using qwen-turbo
Append: [ReplaceMe：无需训练的Transformer块剪枝方法](https://arxiv.org/abs/2505.02819)
Token length: 1562
Summarized using qwen-turbo
Append: [Voila：迈向自然人机交互的大型语音语言基础模型](https://arxiv.org/abs/2505.02707)
Json decode failed:
{
  "title": "GVM-RAFT：一种针对链式思维推理的大语言模型优化方法",
  "short_summary": "提出一种动态样本分配策略以加速链式思维推理训练。",
  "summary": "本文探讨了大型语言模型中的链式思维推理问题，将其形式化为潜在变量问题，其中模型需要生成中间推理步骤。尽管先前的方法如迭代奖励排名微调（RAFT）依赖于此公式化方式，但它们通常对提示应用统一的推理预算，未能考虑到难度和收敛行为的差异。研究发现，链式思维训练的主要瓶颈在于由于静态采样策略导致的低效随机梯度估计。为解决此问题，我们提出了GVM-RAFT，这是一种提示特定的动态样本分配策略，旨在在计算预算约束下最小化随机梯度方差。该方法通过监控提示接受率和随机梯度范数来动态分配计算资源，从而确保梯度方差最小化。理论分析表明，在合适条件下，所提出的动态采样策略可以加速收敛。数学推理实验显示，与原始RAFT相比，GVM-RAFT实现了2到4倍的速度提升和显著的准确性改进。此外，所提出的动态采样策略具有通用性，可集成到其他强化学习算法中，例如GRPO，从而带来类似的收敛和测试精度改善。相关代码可在https:
  "keyword": ["链式思维推理", "大语言模型", "动态采样"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 418 (char 510). Line: 406.
Append: [Optimizing Chain-of-Thought Reasoners via Gradient Variance Minimization in Rejection Sampling and RL](https://arxiv.org/abs/2505.02391)
Token length: 1843
Summarized using qwen-turbo
Append: [引入推理能力的生成型奖励模型提升奖励建模性能](https://arxiv.org/abs/2505.02387)
Token length: 808
Summarized using qwen-turbo
Append: [Muon优化器在计算效率与数据效能上的改进](https://arxiv.org/abs/2505.02222)
Token length: 1501
Summarized using qwen-turbo
Append: [基于演示交互强化学习的数据增强与技能获取](https://arxiv.org/abs/2505.02094)
Token length: 1616
Summarized using qwen-turbo
Append: [大规模语言模型推理引擎系统性评估与未来展望](https://arxiv.org/abs/2505.01658)
Token length: 1593
Summarized using qwen-turbo
Append: [多模态大型语言模型的目标遗忘评估基准研究](https://arxiv.org/abs/2505.01456)
Token length: 1508
Summarized using qwen-turbo
Append: [通过Grokking增强Transformer模型的多步事实推理能力](https://arxiv.org/abs/2504.20752)
Token length: 1407
Summarized using qwen-turbo
Append: [ARTIST：引入具身推理与工具集成的大语言模型框架](https://arxiv.org/abs/2505.01441)
append_entries: 11
Finish: 2025-05-06 12:31:07.530569
------------------------------------------------------
Started: 2025-05-06 18:20:08.608795
Existing_entries: 1011
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "Switch-NeRF++：一种高效可扩展的大规模场景神经辐射场方法",
  "short_summary": "提出一种基于哈希网络的异构混合专家模型，提升大规模场景NeRF建模效率和精度。",
  "summary": "近年来，大型场景下的神经辐射场（Neural Radiance Fields, NeRF）研究强调了场景分解的重要性。然而，现有方法在可学习分解、异质性建模及建模效率方面仍存在不足。本文介绍了一种名为Switch-NeRF++的新框架，它通过哈希基的门控网络和不同的异质哈希专家，在统一框架下解决了这些挑战。该框架能够端到端地高效学习异质分解并构建大规模场景的异质NeRF模型。实验表明，Switch-NeRF++不仅在现有大型NeRF数据集上表现优异，还在UrbanBIS提供的超大规模场景数据集（>6.5平方公里）中展现了卓越的渲染精度。与Switch-NeRF相比，该方法在训练速度上提高了8倍，渲染速度提高了16倍，同时代码将在https:
  "keyword": ["NeRF", "场景分解", "哈希网络"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 339 (char 451). Line: 406.
Append: [Learning Heterogeneous Mixture of Scene Experts for Large-scale Neural Radiance Fields](https://arxiv.org/abs/2505.02005)
append_entries: 1
Finish: 2025-05-06 18:20:14.375651
------------------------------------------------------
Started: 2025-05-07 01:09:48.861692
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1612
Summarized using qwen-turbo
Append: [大型语言模型在图结构数据中的注意力机制研究](https://arxiv.org/abs/2505.02130)
Token length: 1277
Summarized using qwen-turbo
Append: [基于Motion-enhanced Event Tensor的RGB-事件模态融合及其应用](https://arxiv.org/abs/2505.01548)
append_entries: 2
Finish: 2025-05-07 01:09:58.241232
------------------------------------------------------
Started: 2025-05-07 06:21:15.987043
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-07 06:21:16.187267
------------------------------------------------------
Started: 2025-05-07 12:30:20.550674
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1530
Summarized using qwen-turbo
Append: [VITA-Audio：基于多模态预测模块的低延迟语音生成大模型](https://arxiv.org/abs/2505.03739)
Token length: 1243
Summarized using qwen-turbo
Append: [面向综合理解的AI在足球领域的框架与贡献](https://arxiv.org/abs/2505.03735)
Token length: 1681
Summarized using qwen-turbo
Append: [FlexiAct：一种灵活的动作迁移方法](https://arxiv.org/abs/2505.03730)
Token length: 1802
Summarized using qwen-turbo
Append: [大型语言模型在地理空间解释性研究中的新框架](https://arxiv.org/abs/2505.03368)
Token length: 1717
Summarized using qwen-turbo
Append: [绝对零度范式下的自我进化推理模型](https://arxiv.org/abs/2505.03335)
Token length: 1907
Summarized using qwen-turbo
Append: [UnifiedReward-Think：基于长链条推理的多模态奖励模型](https://arxiv.org/abs/2505.03318)
Token length: 1113
Summarized using qwen-turbo
Append: [InfoVids：重塑演示者与可视化之间的关系](https://arxiv.org/abs/2505.03164)
Token length: 1070
Summarized using qwen-turbo
Append: [RADLADS协议：高效转换Transformer至线性注意力解码模型](https://arxiv.org/abs/2505.03005)
Token length: 1213
Summarized using qwen-turbo
Append: [RetroInfer：一种加速长上下文大语言模型推理的新系统](https://arxiv.org/abs/2505.02922)
Token length: 1349
Summarized using qwen-turbo
Append: [基于AttenHScore的大模型与小模型协作优化方法](https://arxiv.org/abs/2505.02311)
Token length: 1618
Summarized using qwen-turbo
Append: [Qwen3低比特量化性能评估与挑战](https://arxiv.org/abs/2505.02214)
Token length: 1106
Summarized using qwen-turbo
Append: [通过眼球运动自动解码开放性阅读目标的研究](https://arxiv.org/abs/2505.02872)
Token length: 1809
Summarized using qwen-turbo
Append: [HoloTime：通过扩散模型实现全景视频到4D场景的重建](https://arxiv.org/abs/2504.21650)
Token length: 1055
Summarized using qwen-turbo
Append: [Auto-SLURP：用于评估大型语言模型驱动多智能体框架的新基准数据集](https://arxiv.org/abs/2504.18373)
append_entries: 14
Finish: 2025-05-07 12:31:16.775942
------------------------------------------------------
Started: 2025-05-07 18:20:44.623899
Existing_entries: 1014
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-07 18:20:44.781764
------------------------------------------------------
Started: 2025-05-08 01:10:20.426546
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1169
Summarized using qwen-turbo
Append: [通过Selective Loss方法提升语言模型对高风险文本的理解能力](https://arxiv.org/abs/2505.03052)
Json decode failed:
{
  "title": "大型语言模型多智能体系统中的自动化失败归因研究",
  "short_summary": "提出新的研究领域并开发方法解决多智能体系统的失败归因问题。",
  "summary": "本文探讨了大型语言模型（LLM）多智能体系统中失败归因的重要性，即识别导致任务失败的责任代理及具体步骤，该领域目前尚未被充分探索且耗时费力。为了推动这一领域的研究，我们引入了Who&When数据集，它包含了来自127个LLM多智能体系统的广泛失败日志，并对失败与特定代理及关键错误步骤进行了细致标注。基于此数据集，我们开发并评估了三种自动化的失败归因方法，总结了各自的优缺点。其中最佳方法在识别负责失败的代理方面达到了53.5%的准确率，但在定位失败步骤上仅达14.2%，部分方法的表现甚至低于随机水平。即使如OpenAI o1和DeepSeek R1等最先进的推理模型也未能实现实际可用性。这些结果表明了该任务的高度复杂性以及进一步研究的需求。代码和数据集可在https:
  "keyword": ["多智能体系统", "失败归因", "大型语言模型"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 352 (char 443). Line: 406.
Append: [Which Agent Causes Task Failures and When? On Automated Failure Attribution of LLM Multi-Agent Systems](https://arxiv.org/abs/2505.00212)
Json decode failed:
{
  "title": "SWE-smith：大规模生成软件工程训练数据的创新管道",
  "short_summary": "SWE-smith通过自动化方法生成大规模软件工程训练数据，显著提升模型性能。",
  "summary": "尽管近年来语言模型在软件工程领域取得了进展，但收集训练数据仍然是一个重大挑战。现有数据集规模小且复杂，限制了其应用范围。为解决这一问题，本文介绍了一种名为SWE-smith的新管道，它能够根据任意Python代码库自动生成大量任务实例，从而构建更大规模的数据集。通过SWE-smith，研究团队创建了一个包含50k实例的数据集，来自128个GitHub仓库，比以往所有工作大一个数量级。该方法还帮助训练了SWE-agent-LM-32B模型，在SWE-bench Verified基准测试中达到40.2%的Pass@1解决率，成为开源模型中的最佳表现。此外，SWE-smith及其相关资源已完全开源，旨在降低基于语言模型进行自动化软件工程研究的门槛。所有资产可通过https:
  "keyword": ["软件工程", "语言模型", "训练数据"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 353 (char 459). Line: 406.
Append: [SWE-smith: Scaling Data for Software Engineering Agents](https://arxiv.org/abs/2504.21798)
append_entries: 3
Finish: 2025-05-08 01:10:39.336731
------------------------------------------------------
Started: 2025-05-08 06:21:40.832222
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-08 06:21:41.026781
------------------------------------------------------
Started: 2025-05-08 12:28:44.988917
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1453
Summarized using qwen-turbo
Append: [PrimitiveAnything：一种基于形状条件的几何元素组合生成框架](https://arxiv.org/abs/2505.04622)
Token length: 1829
Summarized using qwen-turbo
Append: [ZeroSearch：无需实时搜索引擎的大型语言模型检索能力强化学习框架](https://arxiv.org/abs/2505.04588)
Token length: 1391
Summarized using qwen-turbo
Append: [基于确定性马尔可夫决策过程的形式化问题求解框架](https://arxiv.org/abs/2505.04528)
Token length: 1635
Summarized using qwen-turbo
Append: [HunyuanCustom：多模态自定义视频生成框架提升身份一致性](https://arxiv.org/abs/2505.04512)
Json decode failed:
{
  "title": "SwarmBench：评估大语言模型在多智能体系统中的集群智能能力",
  "short_summary": "研究提出SwarmBench基准测试，评估大语言模型在有限感知和通信条件下的集群智能表现。",
  "summary": "现有研究对大规模语言模型（LLMs）在多智能体系统（MAS）中的协调潜力关注不足，尤其是面对自然集群所特有的局部感知和通信限制时的适应性。目前的基准测试未能充分反映分散式协调的独特挑战，即智能体需在不完整时空信息下运作。为解决这一问题，本文引入了SwarmBench，这是一个针对LLMs作为分散式代理的集群智能能力进行系统评估的新基准。SwarmBench包含五个基础的MAS协调任务，运行在一个可配置的二维网格环境中，要求智能体主要依赖局部感官输入和通信。我们提出了衡量协调效果的指标，并分析了群体动态的涌现特性。通过零样本设置评估多个领先的大语言模型，发现任务间性能差异显著，表明局部信息约束带来的挑战。尽管部分协调现象出现，但在不确定性的去中心化场景中仍存在规划和策略形成方面的局限性。评估LLMs在类似集群条件下的表现对于未来去中心化系统的开发至关重要。SwarmBench作为一个开放且可扩展的工具包发布，提供环境、提示、评估脚本及实验数据集，旨在促进基于LLM的MAS协调研究及其理论基础的研究。我们的代码库可在https:
  "keyword": ["大语言模型", "多智能体系统", "集群智能"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 484 (char 601). Line: 406.
Append: [Benchmarking LLMs' Swarm intelligence](https://arxiv.org/abs/2505.04364)
Json decode failed:
{
  "title": "双系统视觉-语言-动作架构的综述与开源模型探索",
  "short_summary": "论文总结并比较现有双系统架构设计，并提供低成本开源模型。",
  "summary": "近年来，双系统视觉-语言-动作（VLA）架构在具身智能研究中备受关注，然而缺乏足够的开源工作用于进一步性能分析与优化。本文旨在系统性地梳理和对比现有双系统架构的设计，并对这些架构的核心设计元素进行实证评估。通过这一系列工作，本文最终将提供一个低成本的开源模型，以促进相关领域的进一步探索。此外，该项目将持续更新，带来更多实验结论及改进性能的开源模型，供研究者自由选择使用。项目主页可访问：https:
  "keyword": ["双系统架构", "具身智能", "开源模型"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 215 (char 305). Line: 406.
Append: [OpenHelix: A Short Survey, Empirical Analysis, and Open-Source Dual-System VLA Model for Robotic Manipulation](https://arxiv.org/abs/2505.03912)
Json decode failed:
{
  "title": "OSUniverse：桌面级复杂多模态任务的高级GUI导航AI基准测试",
  "short_summary": "提出OSUniverse基准测试，评估高级GUI导航AI的能力。",
  "summary": "本文介绍了一个名为OSUniverse的桌面导向任务基准测试，用于评估高级图形用户界面(GUI)导航的人工智能代理。该基准测试涵盖了从基础点击到多步骤跨应用任务的多种复杂度级别，旨在提供易用性、可扩展性和全面的测试案例覆盖。版本一的测试案例难度经过校准，确保当时的顶级AI代理得分不超过50%，而普通白领工人可以完美完成这些任务。此外，还引入了一种自动化验证机制，平均误差率低于2%。因此，OSUniverse为短期和中期衡量GUI导航AI代理的进步、能力和有效性提供了坚实的基础。源代码可在https:
  "keyword": ["GUI导航", "AI基准测试", "自动化验证"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 267 (char 373). Line: 406.
Append: [OSUniverse: Benchmark for Multimodal GUI-navigation AI Agents](https://arxiv.org/abs/2505.03570)
Token length: 1330
Summarized using qwen-turbo
Append: [大型语言模型在复杂问题求解中的能力与挑战](https://arxiv.org/abs/2505.03418)
Token length: 1869
Summarized using qwen-turbo
Append: [多模态理解与图像生成统一模型的研究综述](https://arxiv.org/abs/2505.02567)
Json decode failed:
{
  "title": "基于图像-事件融合的视频异常检测新框架",
  "short_summary": "提出一种无需专用事件传感器的视频异常检测新方法。",
  "summary": "本文介绍了一种名为IEF-VAD（Image-Event Fusion for Video Anomaly Detection）的新框架，该框架通过直接从RGB视频合成事件表示并与图像特征融合，解决了仅依赖RGB帧的现有视频异常检测器缺乏时间分辨率的问题。IEF-VAD利用Student"s-t似然函数建模重尾传感器噪声，并通过拉普拉斯近似得到逆方差权重；采用类似卡尔曼滤波的时间帧更新平衡模态；迭代优化融合潜在状态以消除残余跨模态噪声。该方法无需专用事件传感器或帧级标签，在多个真实世界异常检测基准上达到最新技术水平，突显了合成事件表示在强调RGB帧中常被忽视的运动线索方面的效用，从而实现多样应用中的准确且鲁棒的视频理解。",
  "keyword": ["视频异常检测", "图像-事件融合", "重尾噪声"]
}Summarization failed, append the original article
error: Expecting ',' delimiter: line 4 column 160 (char 242). Line: 406.
Append: [Uncertainty-Weighted Image-Event Multimodal Fusion for Video Anomaly Detection](https://arxiv.org/abs/2505.02393)
Token length: 1312
Summarized using qwen-turbo
Append: [视觉语言模型在视觉视角转换中的能力评估](https://arxiv.org/abs/2505.03821)
Token length: 1284
Summarized using qwen-turbo
Append: [R&B框架通过语义重分区和高效优化提升数据混合策略性能](https://arxiv.org/abs/2505.00358)
append_entries: 12
Finish: 2025-05-08 12:29:38.441042
------------------------------------------------------
Started: 2025-05-08 18:20:13.508236
Existing_entries: 1012
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1538
Summarized using qwen-turbo
Append: [OmniGIRL：多语言、多模态、多领域的GitHub问题自动解决基准测试](https://arxiv.org/abs/2505.04606)
Token length: 846
Summarized using qwen-turbo
Append: [轻量级外部信息驱动的自适应检索方法](https://arxiv.org/abs/2505.04253)
Json decode failed:
{
  "title": "区域感知指导学习在CBCT牙科分割中的应用",
  "short_summary": "提出一种新的半监督框架RAIL，提升CBCT牙部分割性能。",
  "summary": "半监督学习在基于锥形束计算机断层扫描(CBCT)的三维牙齿分割中成为一种有吸引力的方法，但现有方法仍面临两大挑战：在结构模糊或标记错误区域的有限纠正监督，以及由不可靠伪标签导致的性能下降。为解决这些问题，我们提出了区域感知指导学习(RAIL)，这是一种双组双学生半监督框架。每个组包含两个受共享教师网络指导的学生模型。通过在两组之间交替训练，RAIL促进了组间知识转移和协作的区域感知指导，同时减少了对单一模型特性的过拟合。具体而言，RAIL引入了两种指导机制。分歧聚焦监督(DFS)控制器通过仅在学生输出与真实值和最佳学生模型相异的区域改进监督学习，从而集中监督于结构模糊或标记错误的区域。在无监督阶段，置信度感知学习(CAL)调节器增强了高模型确定性区域的一致性，同时减少了低置信度预测的影响，有助于防止模型学习不稳定模式并提高伪标签的整体可靠性。在四个CBCT牙齿分割数据集上的广泛实验表明，在有限标注的情况下，RAIL超越了最先进的方法。我们的代码将在https:
  "keyword": ["半监督学习", "牙齿分割", "CBCT"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 451 (char 540). Line: 406.
Append: [RAIL: Region-Aware Instructive Learning for Semi-Supervised Tooth Segmentation in CBCT](https://arxiv.org/abs/2505.03538)
Token length: 1906
Summarized using qwen-turbo
Append: [Cognitio Emergens框架：重新定义人机协作的科学知识创造](https://arxiv.org/abs/2505.03105)
Token length: 1650
Summarized using qwen-turbo
Append: [AutoLibra：基于开放反馈的智能体评估框架](https://arxiv.org/abs/2505.02820)
append_entries: 5
Finish: 2025-05-08 18:20:39.186033
------------------------------------------------------
Started: 2025-05-09 01:09:40.681145
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1119
Summarized using qwen-turbo
Append: [OpenVision：开源视觉编码器家族挑战CLIP](https://arxiv.org/abs/2505.04601)
Token length: 1245
Summarized using qwen-turbo
Append: [COSMOS：在资源约束下高效预测大语言模型适配结果](https://arxiv.org/abs/2505.01449)
append_entries: 2
Finish: 2025-05-09 01:09:50.585754
------------------------------------------------------
Started: 2025-05-09 06:21:17.678130
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-09 06:21:17.890358
------------------------------------------------------
Started: 2025-05-09 12:28:14.695062
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1615
Summarized using qwen-turbo
Append: [3D场景生成综述：技术进展与未来方向](https://arxiv.org/abs/2505.05474)
Token length: 1232
Summarized using qwen-turbo
Append: [Flow-GRPO：首个结合在线强化学习与流匹配模型的方法](https://arxiv.org/abs/2505.05470)
Json decode failed:
{
  "title": "LegoGPT：基于文本生成物理稳定乐高模型的新方法",
  "short_summary": "LegoGPT利用大规模物理稳定数据集和语言模型生成符合文本描述且稳定的乐高设计。",
  "summary": "本文介绍了LegoGPT，这是一种用于根据文本提示生成物理稳定乐高积木模型的新方法。为了实现这一目标，我们构建了一个大规模的物理稳定乐高设计数据集及其相关描述，并训练了一个自回归的大规模语言模型，通过下一个标记预测来预测要添加的下一个积木。为了提高生成设计的稳定性，我们在自回归推理过程中采用了高效的有效性检查和基于物理学的回滚机制，使用物理学定律和组装约束修剪不可行的标记预测。实验表明，LegoGPT生成的设计不仅稳定、多样化而且美观，与输入的文本提示高度一致。此外，我们还开发了一种基于文本的乐高纹理方法，以生成彩色和有纹理的设计。我们的设计不仅可以由人类手动组装，也可以由机器人手臂自动组装。我们还发布了新的数据集StableText2Lego，该数据集包含超过47,000个乐高结构和超过28,000个独特3D对象的详细描述，以及项目网站上的代码和模型：https:
  "keyword": ["乐高", "文本生成", "物理稳定性"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 403 (char 509). Line: 406.
Append: [Generating Physically Stable and Buildable LEGO Designs from Text](https://arxiv.org/abs/2505.05469)
Token length: 1182
Summarized using qwen-turbo
Append: [StreamBridge：将离线Video-LLMs转化为流式模型的高效框架](https://arxiv.org/abs/2505.05467)
Token length: 1401
Summarized using qwen-turbo
Append: [英语推理能力的跨语言泛化研究](https://arxiv.org/abs/2505.05408)
Token length: 1418
Summarized using qwen-turbo
Append: [基于情境学习的贡献度测量方法ICon提升大语言模型训练效率](https://arxiv.org/abs/2505.05327)
Token length: 1464
Summarized using qwen-turbo
Append: [弹性推理框架实现可控的大规模链式思维推理](https://arxiv.org/abs/2505.05315)
Token length: 925
Summarized using qwen-turbo
Append: [语言引导的3D场景物体放置任务及基准](https://arxiv.org/abs/2505.05288)
Token length: 1402
Summarized using qwen-turbo
Append: [Fine-Grained CLIP：通过多模态增强实现细粒度理解](https://arxiv.org/abs/2505.05071)
Token length: 1112
Summarized using qwen-turbo
Append: [链式思维令牌在复杂推理中的变量特性研究](https://arxiv.org/abs/2505.04955)
Token length: 1914
Summarized using qwen-turbo
Append: [多模态推理模型的研究进展与未来展望](https://arxiv.org/abs/2505.04921)
Token length: 1846
Summarized using qwen-turbo
Append: [迈向通用多模态模型：General-Level评估框架与General-Bench基准](https://arxiv.org/abs/2505.04620)
Token length: 1551
Summarized using qwen-turbo
Append: [X-Reasoner：通过文本后训练实现跨模态和跨领域可泛化推理](https://arxiv.org/abs/2505.03981)
Token length: 1197
Summarized using qwen-turbo
Append: [LiftFeat：通过三维几何特征增强视觉定位中的局部特征匹配](https://arxiv.org/abs/2505.03422)
Token length: 1337
Summarized using qwen-turbo
Append: [SAGE框架评估大语言模型的社会认知能力](https://arxiv.org/abs/2505.02847)
Json decode failed:
{
  "title": "BrowseComp-ZH：评估中文网络浏览能力的高难度基准测试",
  "short_summary": "研究引入了针对中文网络环境的高难度基准测试BrowseComp-ZH。",
  "summary": "随着大型语言模型发展为工具使用代理，实时浏览网络的能力成为衡量推理和检索能力的关键指标。然而，现有的基准测试如BrowseComp主要集中在英语，忽视了其他主要信息生态系统（特别是中文）的语言、基础设施和审查制度的复杂性。为填补这一空白，我们推出了BrowseComp-ZH，这是一个专门构建的高难度基准测试，用于全面评估LLM代理在中文网络上的表现。该基准测试由289个跨11个多样化领域的多跳问题组成，每个问题都逆向设计自易于验证的简短客观答案。通过两阶段的质量控制协议，确保问题难度和答案的独特性。我们对超过20个最先进的语言模型和自主搜索系统进行了基准测试，结果显示大多数模型表现不佳，大部分准确性低于10%，仅有少数超过20%。即使表现最好的系统OpenAI的DeepResearch也仅达到42.9%的准确率。这些结果表明，BrowseComp-ZH的难度极高，成功不仅需要有效的检索策略，还需要复杂的推理和信息协调能力，而这些都是当前模型仍难以掌握的能力。我们的数据集、构建指南和基准测试结果已在https:
  "keyword": ["LLM", "网络浏览", "中文基准测试"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 476 (char 582). Line: 406.
Append: [BrowseComp-ZH: Benchmarking Web Browsing Ability of Large Language Models in Chinese](https://arxiv.org/abs/2504.19314)
append_entries: 16
Finish: 2025-05-09 12:29:26.204912
------------------------------------------------------
Started: 2025-05-09 18:19:26.754248
Existing_entries: 1016
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-09 18:19:26.980517
------------------------------------------------------
Started: 2025-05-10 01:07:06.440159
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1125
Summarized using qwen-turbo
Append: [基于鲁棒文本水印的大语言模型高效遗忘评估方法](https://arxiv.org/abs/2505.05064)
Token length: 940
Summarized using qwen-turbo
Append: [RL^V：强化学习中引入验证能力提升LLM推理性能](https://arxiv.org/abs/2505.04842)
Token length: 1882
Summarized using qwen-turbo
Append: [视觉-语言-行动模型综述：架构创新与未来展望](https://arxiv.org/abs/2505.04769)
Token length: 1266
Summarized using qwen-turbo
Append: [结合策略优化语言模型对齐：on-policy与off-policy数据的互补优势](https://arxiv.org/abs/2505.02363)
append_entries: 4
Finish: 2025-05-10 01:07:31.306966
------------------------------------------------------
Started: 2025-05-10 06:18:20.255932
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-10 06:18:20.421190
------------------------------------------------------
Started: 2025-05-10 12:25:26.070934
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-10 12:25:26.278033
------------------------------------------------------
Started: 2025-05-10 18:17:39.786517
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-10 18:17:39.958838
------------------------------------------------------
Started: 2025-05-11 01:14:09.930458
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-11 01:14:10.094266
------------------------------------------------------
Started: 2025-05-11 06:19:14.400723
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-11 06:19:14.617969
------------------------------------------------------
Started: 2025-05-11 12:25:28.516033
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-11 12:25:28.746965
------------------------------------------------------
Started: 2025-05-11 18:17:48.392253
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-11 18:17:48.564698
------------------------------------------------------
Started: 2025-05-12 01:12:54.623166
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-12 01:12:54.791097
------------------------------------------------------
Started: 2025-05-12 06:21:55.475064
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-12 06:21:55.718889
------------------------------------------------------
Started: 2025-05-12 12:29:51.397056
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1474
Summarized using qwen-turbo
Append: [UniVLA：一种用于跨形态机器人视觉-语言-动作学习的新框架](https://arxiv.org/abs/2505.06111)
Token length: 1372
Summarized using qwen-turbo
Append: [大型语言模型在英国公共卫生信息领域的知识评估](https://arxiv.org/abs/2505.06046)
Token length: 1288
Summarized using qwen-turbo
Append: [WiserUI-Bench与G-FOCUS：提升UI设计说服力评估的创新方法](https://arxiv.org/abs/2505.05026)
Json decode failed:
{
  "title": "大规模语言模型中的奖励学习范式综述",
  "short_summary": "奖励学习范式推动大模型从静态数据学习转向动态反馈学习。",
  "summary": "近年来，大型语言模型的发展重点已从预训练规模扩展转向后训练和测试时调整。在此过程中，奖励学习成为一个重要且统一的范式，通过奖励信号指导模型行为，支撑了多种关键技术如强化学习（RLHF、DPO、GRPO）、奖励引导解码及事后校正。这一范式使模型从被动学习转变为基于动态反馈的主动学习，从而具备对齐偏好和深度推理能力。本文综述了奖励学习范式的相关内容，分类并分析了其在训练、推理及推理后阶段的策略，探讨了奖励模型的基准及其主要应用，并指出了面临的挑战和未来方向。我们还维护了一个相关论文的集合（https:
  "keyword": ["奖励学习", "大语言模型", "对齐偏好"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 266 (char 349). Line: 406.
Append: [Sailing AI by the Stars: A Survey of Learning from Rewards in Post-Training and Test-Time Scaling of Large Language Models](https://arxiv.org/abs/2505.02686)
Token length: 1280
Summarized using qwen-turbo
Append: [Bielik v3：优化波兰语处理的高效生成式文本模型](https://arxiv.org/abs/2505.02550)
Token length: 1180
Summarized using qwen-turbo
Append: [Bielik 11B v2：面向波兰语处理的高效语言模型](https://arxiv.org/abs/2505.02410)
append_entries: 6
Finish: 2025-05-12 12:30:18.592954
------------------------------------------------------
Started: 2025-05-12 18:20:13.921284
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1272
Summarized using qwen-turbo
Append: [GPT-4o在图像修复领域的潜力与挑战](https://arxiv.org/abs/2505.05621)
append_entries: 1
Finish: 2025-05-12 18:20:18.170055
------------------------------------------------------
Started: 2025-05-13 01:11:05.544981
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1263
Summarized using qwen-turbo
Append: [POLAR：高效多视角点云刚性配准方法](https://arxiv.org/abs/2504.21467)
append_entries: 1
Finish: 2025-05-13 01:11:10.534835
------------------------------------------------------
Started: 2025-05-13 06:21:13.685506
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1240
Summarized using qwen-turbo
Append: [基于强化学习的开源小规模LLM指令数据生成框架](https://arxiv.org/abs/2505.06548)
Token length: 1735
Summarized using qwen-turbo
Append: [WebGen-Bench：评估基于LLM的多文件网站代码生成能力的新基准](https://arxiv.org/abs/2505.03733)
append_entries: 2
Finish: 2025-05-13 06:21:24.819978
------------------------------------------------------
Started: 2025-05-13 12:30:09.455022
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1855
Summarized using qwen-turbo
Append: [DanceGRPO：首个统一强化学习框架实现视觉生成多领域适配](https://arxiv.org/abs/2505.07818)
Token length: 1242
Summarized using qwen-turbo
Append: [连续预训练中的学习动态及扩展定律研究](https://arxiv.org/abs/2505.07796)
Token length: 1209
Summarized using qwen-turbo
Append: [基于分块推理的LLMs长上下文处理效率提升研究](https://arxiv.org/abs/2505.07793)
Token length: 1655
Summarized using qwen-turbo
Append: [通过同伴学习解决大型推理模型的前缀主导陷阱](https://arxiv.org/abs/2505.07787)
Token length: 1570
Summarized using qwen-turbo
Append: [Step1X-3D：推动可控3D资产生成的开源框架](https://arxiv.org/abs/2505.07747)
Json decode failed:
{
  "title": "MiMo-7B：面向推理任务优化的大规模语言模型",
  "short_summary": "MiMo-7B通过预训练和后训练阶段优化，在数学、代码和一般推理任务上表现优异。",
  "summary": "MiMo-7B是一种针对推理任务设计的大规模语言模型，其优化贯穿预训练和后训练两个阶段。在预训练阶段，我们改进了数据预处理流程并采用三阶段数据混合策略增强基础模型的推理能力。MiMo-7B-Base在25万亿标记上进行预训练，并引入多标记预测目标以提升性能和加速推理速度。后训练阶段，我们整理了一个包含13万可验证的数学和编程问题的数据集，结合基于测试难度驱动的代码奖励方案解决稀疏奖励问题，并通过战略性数据重采样稳定训练过程。广泛的评估表明，MiMo-7B-Base在推理潜力方面表现出色，甚至优于更大规模的32B模型。经过强化学习微调的最终版本MiMo-7B-RL在数学、代码及一般推理任务上的表现超越了OpenAI o1-mini。模型权重已公开于https:
  "keyword": ["大规模语言模型", "推理任务", "强化学习"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 348 (char 451). Line: 406.
Append: [MiMo: Unlocking the Reasoning Potential of Language Model -- From Pretraining to Posttraining](https://arxiv.org/abs/2505.07608)
Token length: 1477
Summarized using qwen-turbo
Append: [基于强化学习的知识协同推理代理IKEA提升大语言模型性能](https://arxiv.org/abs/2505.07596)
Json decode failed:
{
  "title": "统一连续生成模型框架实现顶级性能",
  "short_summary": "提出统一框架UCGM，提升多步与少步生成模型性能。",
  "summary": "近期，连续生成模型在扩散模型、流匹配等多步方法（通常需要8-1000个采样步骤）以及一致性模型等少步方法（通常1-8步）方面取得了显著进展。然而，这些方法往往被视为独立范式，导致各自独立的训练和采样方式。我们提出了一个统一框架——统一连续生成模型训练器与采样器（UCGM-{T,S}），实现了最先进的性能。例如，在ImageNet 256x256上，使用一个6.75亿参数的扩散变压器，UCGM-T训练的多步模型在20步达到1.30的FID分数，而少步模型仅需2步即可达到1.42的FID分数。此外，将UCGM-S应用于一个预先训练的模型（此前在250步时的FID分数为1.26），可将其性能提高到仅40步时的1.06 FID分数。该代码已公开于https:
  "keyword": ["生成模型", "统一框架", "性能提升"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 344 (char 424). Line: 406.
Append: [Unified Continuous Generative Models](https://arxiv.org/abs/2505.07447)
Token length: 1429
Summarized using qwen-turbo
Append: [基于注意力影响机制的弱监督大规模推理数据选择方法](https://arxiv.org/abs/2505.07293)
Token length: 1374
Summarized using qwen-turbo
Append: [Multi-Objective-Guided Discrete Flow Matching用于多目标生物序列设计](https://arxiv.org/abs/2505.07086)
Token length: 1260
Summarized using qwen-turbo
Append: [Seed1.5-VL：高性能多模态基础模型](https://arxiv.org/abs/2505.07062)
Token length: 1195
Summarized using qwen-turbo
Append: [大型语言模型文档归因技术研究](https://arxiv.org/abs/2505.06324)
append_entries: 12
Finish: 2025-05-13 12:31:07.757126
------------------------------------------------------
Started: 2025-05-13 18:20:45.217344
Existing_entries: 1012
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1200
Summarized using qwen-turbo
Append: [Triply-Hierarchical Diffusion Policy: 强化机器人视觉-动作学习的层级结构方法](https://arxiv.org/abs/2505.07819)
Token length: 1205
Summarized using qwen-turbo
Append: [无需向量量化：连续视觉自回归生成框架](https://arxiv.org/abs/2505.07812)
Token length: 1244
Summarized using qwen-turbo
Append: [Skywork-VL Reward：一种多模态奖励模型](https://arxiv.org/abs/2505.07263)
Token length: 857
Summarized using qwen-turbo
Append: [UMoE：通过统一设计提升Transformer模型的稀疏混合专家性能](https://arxiv.org/abs/2505.07260)
Token length: 1266
Summarized using qwen-turbo
Append: [DynamicRAG：通过强化学习优化检索增强生成模型](https://arxiv.org/abs/2505.07233)
Token length: 1759
Summarized using qwen-turbo
Append: [基于多模态大语言模型的照片润色方法](https://arxiv.org/abs/2505.06176)
Token length: 1362
Summarized using qwen-turbo
Append: [PASSAT：一种融合物理与地形信息的天气预测深度学习模型](https://arxiv.org/abs/2505.04918)
Token length: 1176
Summarized using qwen-turbo
Append: [生成式人工智能评估中的危机与竞赛标准化](https://arxiv.org/abs/2505.00612)
append_entries: 8
Finish: 2025-05-13 18:21:22.967269
------------------------------------------------------
Started: 2025-05-14 01:09:51.313747
Existing_entries: 1008
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1251
Summarized using qwen-turbo
Append: [INTELLECT-2：首个全球分布式强化学习语言模型训练](https://arxiv.org/abs/2505.07291)
Token length: 1147
Summarized using qwen-turbo
Append: [LlamaPIE：首款实时主动对话助手提升人类交流体验](https://arxiv.org/abs/2505.04066)
append_entries: 2
Finish: 2025-05-14 01:10:01.672494
------------------------------------------------------
Started: 2025-05-14 06:21:00.358271
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-14 06:21:00.618745
------------------------------------------------------
Started: 2025-05-14 12:29:05.938965
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1652
Summarized using qwen-turbo
Append: [基于扩散模型的机器人导航策略NavDP](https://arxiv.org/abs/2505.08712)
Token length: 1004
Summarized using qwen-turbo
Append: [SkillFormer：基于多视角融合的技能评估高效架构](https://arxiv.org/abs/2505.08665)
Json decode failed:
{
  "title": "MiniMax-Speech：基于Transformer的高质量多语言文本转语音模型",
  "short_summary": "MiniMax-Speech实现高质量语音生成并支持零样本和单样本语音克隆。",
  "summary": "MiniMax-Speech是一种基于Transformer的自回归文本转语音(TTS)模型，通过可学习的说话人编码器提取参考音频的音色特征，无需转录即可生成高度表达且音色一致的语音，在零样本和单样本语音克隆任务中表现出色。此外，通过Flow-VAE优化合成音频质量，支持32种语言并在多个客观及主观评估中表现优异，特别是在语音克隆的Word Error Rate和Speaker Similarity指标上达到当前最佳(SOTA)水平。该模型还具备出色的扩展性，可通过LoRA实现任意语音情感控制，直接从文本描述合成音色特征进行文本到语音(T2V)转换，以及通过微调音色特征实现专业语音克隆(PVC)。访问https:
  "keyword": ["文本转语音", "语音克隆", "Transformer"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 325 (char 444). Line: 406.
Append: [MiniMax-Speech: Intrinsic Zero-Shot Text-to-Speech with a Learnable Speaker Encoder](https://arxiv.org/abs/2505.07916)
Token length: 1362
Summarized using qwen-turbo
Append: [多维度约束框架提升大语言模型指令跟随能力](https://arxiv.org/abs/2505.07591)
Json decode failed:
{
  "title": "ViMRHP：越南多模态评论有用性预测基准数据集",
  "short_summary": "本文提出ViMRHP数据集，用于解决越南语多模态评论有用性预测问题。",
  "summary": "多模态评论有用性预测（MRHP）在推荐系统中至关重要，特别是在电子商务平台中。然而，现有数据集主要集中在英语和印尼语，缺乏语言多样性，尤其是低资源语言如越南语。为了解决这一问题，本文引入ViMRHP，这是一个大规模的越南语MRHP任务基准数据集，涵盖四个领域，包含2000种产品和46000条评论。为了优化标注过程，我们利用人工智能辅助标注员构建ViMRHP数据集，使每项任务的标注时间从90到120秒减少到20到40秒，同时保持数据质量并降低约65%的成本。实验结果显示，AI辅助标注在复杂任务中仍存在局限性，我们通过详细性能分析进一步探讨。此外，在ViMRHP上评估基线模型时，我们比较了人工验证和AI生成注释的质量差异。ViMRHP数据集已公开发布在https:
  "keyword": ["多模态评论", "有用性预测", "越南语"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 349 (char 446). Line: 406.
Append: [ViMRHP: A Vietnamese Benchmark Dataset for Multimodal Review Helpfulness Prediction via Human-AI Collaborative Annotation](https://arxiv.org/abs/2505.07416)
Token length: 1176
Summarized using qwen-turbo
Append: [gg-bench：评估语言模型通用推理能力的游戏基准](https://arxiv.org/abs/2505.07215)
append_entries: 6
Finish: 2025-05-14 12:29:34.153894
------------------------------------------------------
Started: 2025-05-14 18:18:23.415159
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1584
Summarized using qwen-turbo
Append: [Aya-Vision：解决多语言多模态模型挑战的新方法](https://arxiv.org/abs/2505.08751)
Token length: 1413
Summarized using qwen-turbo
Append: [基于信息瓶颈的LLMs训练方法：压缩与记忆的平衡](https://arxiv.org/abs/2505.08727)
Token length: 1380
Summarized using qwen-turbo
Append: [面向复杂工作流的可扩展评估方法研究](https://arxiv.org/abs/2505.08638)
Token length: 1602
Summarized using qwen-turbo
Append: [检索增强生成系统中超参数对性能的影响分析](https://arxiv.org/abs/2505.08445)
Token length: 1275
Summarized using qwen-turbo
Append: [开源模型AM-Thinking-v1：32B规模下的推理能力新标杆](https://arxiv.org/abs/2505.08311)
Token length: 945
Summarized using qwen-turbo
Append: [基于对抗相对对比学习的文本转音频加速方法](https://arxiv.org/abs/2505.08175)
Token length: 1330
Summarized using qwen-turbo
Append: [跨模态模型融合：将语言模型推理能力融入视觉语言模型](https://arxiv.org/abs/2505.05464)
Token length: 1353
Summarized using qwen-turbo
Append: [基于Transformer的阿拉伯语反向词典系统研究](https://arxiv.org/abs/2504.21475)
append_entries: 8
Finish: 2025-05-14 18:18:52.493654
------------------------------------------------------
Started: 2025-05-15 01:07:40.842165
Existing_entries: 1008
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-15 01:07:41.092860
------------------------------------------------------
Started: 2025-05-15 06:21:41.097961
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1823
Summarized using qwen-turbo
Append: [BLIP3-o：统一图像理解和生成的创新多模态模型](https://arxiv.org/abs/2505.09568)
append_entries: 1
Finish: 2025-05-15 06:21:45.661722
------------------------------------------------------
Started: 2025-05-15 12:29:02.371879
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1414
Summarized using qwen-turbo
Append: [DeepSeek-V3模型的硬件感知设计及其对AI系统的启示](https://arxiv.org/abs/2505.09343)
Token length: 1692
Summarized using qwen-turbo
Append: [Video-based 长篇因果推理基准VCRBench及其评估](https://arxiv.org/abs/2505.08455)
Token length: 1332
Summarized using qwen-turbo
Append: [DeCLIP：通过解耦自注意力机制提升开放词汇密集预测性能](https://arxiv.org/abs/2505.04410)
append_entries: 3
Finish: 2025-05-15 12:29:18.325473
------------------------------------------------------
Started: 2025-05-15 18:20:33.288349
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 729
Summarized using qwen-turbo
Append: [Omni-R1：通过强化学习提升多模态大模型音频问答性能](https://arxiv.org/abs/2505.09439)
Token length: 1367
Summarized using qwen-turbo
Append: [Marigold：通过条件生成模型从预训练扩散模型中提取知识](https://arxiv.org/abs/2505.09358)
Json decode failed:
{
  "title": "UniSkill：一种跨形态技能迁移框架",
  "short_summary": "提出了一种无需标注的跨形态技能表示学习框架UniSkill。",
  "summary": "本文介绍了一种名为UniSkill的新框架，该框架通过大规模跨形态视频数据学习不依赖具体形态的技能表示，从而实现从人类演示到机器人策略的有效迁移，无需收集对齐的人类与机器人数据。实验表明，该框架能够在模拟和真实环境中指导机器人根据未见过的视频提示选择适当动作，展现了其强大的跨形态技能迁移能力。UniSkill项目网站可访问https:
  "keyword": ["模仿学习", "跨形态迁移", "机器人技能"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 183 (char 272). Line: 406.
Append: [UniSkill: Imitating Human Videos via Cross-Embodiment Skill Representations](https://arxiv.org/abs/2505.08787)
Json decode failed:
{
  "title": "VISTAR：基于子任务驱动的多模态大语言模型视觉推理框架",
  "short_summary": "提出一种提升视觉问答模型推理能力与可解释性的新框架。",
  "summary": "现有方法通过将复杂视觉问题分解为子任务程序来提高多模态大型语言模型（MLLMs）的可解释性，但这些方法计算成本高且准确性不足。本文介绍VISTAR（Visually Interpretable Subtask-Aware Reasoning Model），该框架通过在MLLMs内生成文本和视觉解释，基于子任务驱动的方式增强模型的推理能力和可解释性。VISTAR无需依赖外部模型，通过微调MLLMs生成结构化的子任务理性推理序列（逐步推理过程）。实验表明，VISTAR在两个基准测试中显著提升了推理准确性并保持了高水平的可解释性。相关代码和数据集将在https:
  "keyword": ["视觉推理", "多模态学习", "可解释AI"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 296 (char 390). Line: 406.
Append: [Visually Interpretable Subtask Reasoning for Visual Question Answering](https://arxiv.org/abs/2505.08084)
Token length: 1674
Summarized using qwen-turbo
Append: [DetReIDX：大规模空地视角下的人体再识别数据集](https://arxiv.org/abs/2505.04793)
Token length: 1379
Summarized using qwen-turbo
Append: [SweRank：高效代码定位框架解决软件问题描述匹配难题](https://arxiv.org/abs/2505.07849)
Token length: 1823
Summarized using qwen-turbo
Append: [基于单张RGB图像的高效3D场景重建方法CAST](https://arxiv.org/abs/2502.12894)
append_entries: 7
Finish: 2025-05-15 18:21:07.324374
------------------------------------------------------
Started: 2025-05-16 01:10:56.204829
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 934
Summarized using qwen-turbo
Append: [基于扩散模型的图像精确光照编辑方法](https://arxiv.org/abs/2505.09608)
Token length: 1652
Summarized using qwen-turbo
Append: [基于音频语言模型的对话系统评估方法WavReward](https://arxiv.org/abs/2505.09558)
Json decode failed:
{
  "title": "Maya：一种支持多语言的视觉-语言模型",
  "short_summary": "介绍Maya，一种支持多语言的开源视觉-语言模型。",
  "summary": "近期，大型视觉-语言模型(VLMs)取得了快速发展，在学术基准测试中表现出色，但主要局限于广泛使用的语言，对低资源语言及多样化文化背景的表现不足。为解决这些限制，我们引入了Maya，这是一个开源的多语言视觉-语言模型。我们的贡献包括：基于LLaVA预训练数据集创建了一个包含八种语言的多语言图像-文本预训练数据集；开发了一种支持这些语言的多语言图像-文本模型，提升了视觉-语言任务中的文化和语言理解能力。相关代码可在https:
  "keyword": ["多语言", "视觉-语言模型", "文化理解"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 229 (char 313). Line: 406.
Append: [Behind Maya: Building a Multilingual Vision Language Model](https://arxiv.org/abs/2505.08910)
Token length: 975
Summarized using qwen-turbo
Append: [LLaVA图像文本预训练数据集毒性分析与缓解策略](https://arxiv.org/abs/2505.06356)
Token length: 1407
Summarized using qwen-turbo
Append: [SteepGS：优化3D Gaussian Splatting密度控制以提升渲染效率](https://arxiv.org/abs/2505.05587)
append_entries: 5
Finish: 2025-05-16 01:11:19.963576
------------------------------------------------------
Started: 2025-05-16 06:21:29.776488
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1748
Summarized using qwen-turbo
Append: [ETT：端到端视觉标记器调优提升多模态任务性能](https://arxiv.org/abs/2505.10562)
Token length: 1311
Summarized using qwen-turbo
Append: [通过元能力对齐提升大规模推理模型的可扩展性和可靠性](https://arxiv.org/abs/2505.10554)
Token length: 1594
Summarized using qwen-turbo
Append: [世界偏好建模（WorldPM）揭示人类偏好建模中的规模法则](https://arxiv.org/abs/2505.10527)
Token length: 1175
Summarized using qwen-turbo
Append: [基于强化学习的AI法官模型训练方法J1](https://arxiv.org/abs/2505.10320)
Token length: 1288
Summarized using qwen-turbo
Append: [基于CoT百科全书的大语言模型推理分析与优化](https://arxiv.org/abs/2505.10185)
Token length: 943
Summarized using qwen-turbo
Append: [大型语言模型与扩散变压器融合在文本到图像合成中的探索](https://arxiv.org/abs/2505.10046)
Token length: 1470
Summarized using qwen-turbo
Append: [AdaptCLIP：基于CLIP的视觉异常检测新方法](https://arxiv.org/abs/2505.09926)
Token length: 1296
Summarized using qwen-turbo
Append: [构建具身世界模型评估基准EWMBench](https://arxiv.org/abs/2505.09694)
Token length: 1357
Summarized using qwen-turbo
Append: [双层优化框架：提升大规模语言模型系统提示的鲁棒性与迁移能力](https://arxiv.org/abs/2505.09666)
Token length: 1659
Summarized using qwen-turbo
Append: [基于纯视觉元学习框架的通用异常分割方法](https://arxiv.org/abs/2505.09265)
Token length: 1439
Summarized using qwen-turbo
Append: [基于单张正常图像提示的统一异常检测方法](https://arxiv.org/abs/2505.09264)
Token length: 1654
Summarized using qwen-turbo
Append: [基于少样本生成的工业异常检测方法](https://arxiv.org/abs/2505.09263)
Token length: 1725
Summarized using qwen-turbo
Append: [OpenThinkIMG：赋能视觉语言模型的工具增强框架](https://arxiv.org/abs/2505.08617)
Token length: 1560
Summarized using qwen-turbo
Append: [MLE-Dojo：用于自主大语言模型迭代训练的交互式框架](https://arxiv.org/abs/2505.07782)
append_entries: 14
Finish: 2025-05-16 06:22:57.561093
------------------------------------------------------
Started: 2025-05-16 12:29:09.705640
Existing_entries: 1014
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1345
Summarized using qwen-turbo
Append: [Prior Depth Anything框架实现任意场景高精度深度图生成](https://arxiv.org/abs/2505.10565)
Json decode failed:
{
  "title": "基于文本提示的可定制化SVG生成方法",
  "short_summary": "提出一种两阶段风格定制管道，解决现有文本到向量生成SVG时风格一致性问题。",
  "summary": "由于分辨率独立性和分层结构的优势，可缩放矢量图形（SVGs）深受设计师喜爱。然而，现有的文本到向量（T2V）生成方法虽能根据文本生成SVG，但往往忽视了实际应用中至关重要的风格定制需求，即保持视觉外观和美学的一致性。优化型T2V模型可通过文本到图像（T2I）模型先验进行风格定制，但难以维持结构规则性；而前馈型T2V模型虽能保证结构规则性，但在有限的SVG训练数据下难以解耦内容与风格。为应对这些挑战，本文提出了一种新的两阶段风格定制管道，结合前馈T2V模型和T2I模型先验的优点。第一阶段通过路径级表示训练T2V扩散模型，确保SVG的结构规则性并保留多样化的表达能力；第二阶段通过蒸馏定制的T2I模型实现对不同风格的定制。实验验证了该方法的有效性。项目页面为https:
  "keyword": ["SVG", "文本到向量", "风格定制"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 351 (char 445). Line: 406.
Append: [Style Customization of Text-to-Vector Generation with Image Diffusion Priors](https://arxiv.org/abs/2505.10558)
Token length: 1615
Summarized using qwen-turbo
Append: [PointArena：多模态指针能力评估平台](https://arxiv.org/abs/2505.09990)
Token length: 1915
Summarized using qwen-turbo
Append: [Tokenadapt：一种高效的多语言模型 tokenizer 移植框架](https://arxiv.org/abs/2505.09738)
Token length: 1157
Summarized using qwen-turbo
Append: [基于动作条件的世界模型EnerVerse-AC实现高效机器人模仿学习](https://arxiv.org/abs/2505.09723)
Token length: 1475
Summarized using qwen-turbo
Append: [ReSurgSAM2：一种高效的手术场景分割框架](https://arxiv.org/abs/2505.08581)
append_entries: 6
Finish: 2025-05-16 12:29:37.753056
------------------------------------------------------
Started: 2025-05-16 18:20:12.478644
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1483
Summarized using qwen-turbo
Append: [并行扩展(ParScale)：语言模型更高效的扩展方法](https://arxiv.org/abs/2505.10475)
Token length: 1625
Summarized using qwen-turbo
Append: [AI Agents与Agentic AI对比分析及发展路径](https://arxiv.org/abs/2505.10468)
Token length: 1489
Summarized using qwen-turbo
Append: [QuXAI：用于混合量子经典机器学习模型的可解释性框架](https://arxiv.org/abs/2505.10167)
Token length: 1127
Summarized using qwen-turbo
Append: [Unilogit：一种新颖的语言模型自蒸馏机删方法](https://arxiv.org/abs/2505.06027)
append_entries: 4
Finish: 2025-05-16 18:20:33.813686
------------------------------------------------------
Started: 2025-05-17 01:09:16.077640
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1299
Summarized using qwen-turbo
Append: [基于扩散模型的3D先验引导图像编辑框架3D-Fixup](https://arxiv.org/abs/2505.10566)
Token length: 1389
Summarized using qwen-turbo
Append: [Real2Render2Real：无需硬件操作的机器人训练数据生成方法](https://arxiv.org/abs/2505.09601)
Token length: 1401
Summarized using qwen-turbo
Append: [X-Sim：通过人类视频训练机器人操作策略的新框架](https://arxiv.org/abs/2505.07096)
append_entries: 3
Finish: 2025-05-17 01:09:28.388119
------------------------------------------------------
Started: 2025-05-17 06:18:48.981444
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-17 06:18:49.180840
------------------------------------------------------
Started: 2025-05-17 12:26:04.239798
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-17 12:26:04.468785
------------------------------------------------------
Started: 2025-05-17 18:18:21.659534
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-17 18:18:21.817975
------------------------------------------------------
Started: 2025-05-18 01:15:02.847114
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-18 01:15:03.085916
------------------------------------------------------
Started: 2025-05-18 06:19:50.594259
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-18 06:19:50.903380
------------------------------------------------------
Started: 2025-05-18 12:26:10.326870
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-18 12:26:10.509852
------------------------------------------------------
Started: 2025-05-18 18:18:20.377953
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-18 18:18:20.755976
------------------------------------------------------
Started: 2025-05-19 01:13:42.154250
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-19 01:13:42.330786
------------------------------------------------------
Started: 2025-05-19 06:22:04.499815
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-19 06:22:04.749122
------------------------------------------------------
Started: 2025-05-19 12:30:07.532108
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 825
Summarized using qwen-turbo
Append: [Mergenetic：用于语言模型的开源进化模型合并库](https://arxiv.org/abs/2505.11427)
Token length: 1422
Summarized using qwen-turbo
Append: [视觉规划：基于视觉表示的推理新范式](https://arxiv.org/abs/2505.11409)
Token length: 1636
Summarized using qwen-turbo
Append: [解决类别和空间不平衡问题的密集手部接触估计框架](https://arxiv.org/abs/2505.11152)
Token length: 1744
Summarized using qwen-turbo
Append: [大语言模型推理能力增强研究：开放领域问答中的测试时扩展](https://arxiv.org/abs/2505.11140)
Token length: 1650
Summarized using qwen-turbo
Append: [Group Think：基于单一大语言模型的并发推理新范式](https://arxiv.org/abs/2505.11107)
Token length: 1216
Summarized using qwen-turbo
Append: [GuardReasoner-VL：基于推理的视觉语言模型安全增强方法](https://arxiv.org/abs/2505.11049)
Token length: 1245
Summarized using qwen-turbo
Append: [人类在博弈实验中对大型语言模型对手的行为差异研究](https://arxiv.org/abs/2505.11011)
Token length: 1504
Summarized using qwen-turbo
Append: [基于多视角搜索的自动化定理证明系统MPS-Prover](https://arxiv.org/abs/2505.10962)
Token length: 1538
Summarized using qwen-turbo
Append: [MatTools：评估大型语言模型在材料科学工具应用中的能力](https://arxiv.org/abs/2505.10852)
Token length: 1583
Summarized using qwen-turbo
Append: [MMLongBench：首个全面评估长上下文视觉语言模型的基准测试](https://arxiv.org/abs/2505.10610)
Token length: 1130
Summarized using qwen-turbo
Append: [MuToR：一种高效多令牌预测方法](https://arxiv.org/abs/2505.10518)
Token length: 1781
Summarized using qwen-turbo
Append: [Qwen3：大型语言模型家族的新里程碑](https://arxiv.org/abs/2505.09388)
Token length: 1375
Summarized using qwen-turbo
Append: [一种用于视觉语言模型知识蒸馏的双头优化框架](https://arxiv.org/abs/2505.07675)
append_entries: 13
Finish: 2025-05-19 12:31:10.756351
------------------------------------------------------
Started: 2025-05-19 18:20:37.560756
Existing_entries: 1013
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1081
Summarized using qwen-turbo
Append: [大型语言模型在汇编代码优化中的强化学习应用](https://arxiv.org/abs/2505.11480)
Token length: 1287
Summarized using qwen-turbo
Append: [结合先验知识的实时优化风格迁移方法提升音频效果转换](https://arxiv.org/abs/2505.11315)
Token length: 1649
Summarized using qwen-turbo
Append: [CheXGenBench：医学影像生成模型的综合评估框架](https://arxiv.org/abs/2505.10496)
Token length: 1179
Summarized using qwen-turbo
Append: [一种结合Logits与采样策略的大语言模型鲁棒水印框架](https://arxiv.org/abs/2505.09924)
append_entries: 4
Finish: 2025-05-19 18:21:01.797619
------------------------------------------------------
Started: 2025-05-20 01:11:29.816382
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1512
Summarized using qwen-turbo
Append: [基于自然语言指令的图像编辑模型评估基准GIE-Bench](https://arxiv.org/abs/2505.11493)
Token length: 1587
Summarized using qwen-turbo
Append: [uLLSAM：利用多模态大语言模型提升显微镜跨域图像分割性能](https://arxiv.org/abs/2505.10769)
Token length: 934
Summarized using qwen-turbo
Append: [结合文本与图像结构引导的文生图模型](https://arxiv.org/abs/2505.05678)
append_entries: 3
Finish: 2025-05-20 01:11:49.495497
------------------------------------------------------
Started: 2025-05-20 06:21:28.959654
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1523
Summarized using qwen-turbo
Append: [大型视觉语言模型在图表理解中的视觉推理能力挑战](https://arxiv.org/abs/2505.13444)
Token length: 1366
Summarized using qwen-turbo
Append: [FinePhys：结合物理学的人类动作生成框架](https://arxiv.org/abs/2505.13437)
Token length: 1389
Summarized using qwen-turbo
Append: [通过过程奖励模型提升多模态推理逻辑一致性](https://arxiv.org/abs/2505.13427)
Token length: 1554
Summarized using qwen-turbo
Append: [AdaptThink：一种基于强化学习的自适应推理模式优化算法](https://arxiv.org/abs/2505.13417)
Token length: 1543
Summarized using qwen-turbo
Append: [Thinkless：让语言模型学会何时需要推理](https://arxiv.org/abs/2505.13379)
Token length: 1192
Summarized using qwen-turbo
Append: [混合3D-4D高斯泼溅技术提升动态场景重建效率](https://arxiv.org/abs/2505.13215)
Token length: 1617
Summarized using qwen-turbo
Append: [通过GS-Jacobi优化加速TarFlow图像生成模型采样](https://arxiv.org/abs/2505.12849)
Token length: 1596
Summarized using qwen-turbo
Append: [FedSVD：通过SVD实现联邦学习中高效的低秩适配](https://arxiv.org/abs/2505.12805)
Token length: 1176
Summarized using qwen-turbo
Append: [Clipped Policy Gradient Optimization with Policy Drift (CPGD) 提升语言模型强化学习稳定性](https://arxiv.org/abs/2505.12504)
Token length: 1044
Summarized using qwen-turbo
Append: [VisionReasoner：统一视觉推理框架在多任务感知中的卓越表现](https://arxiv.org/abs/2505.12081)
Token length: 942
Summarized using qwen-turbo
Append: [QCompiler：通过神经符号框架提升检索增强生成系统的复杂查询处理能力](https://arxiv.org/abs/2505.11932)
Token length: 1609
Summarized using qwen-turbo
Append: [AdaCoT：通过自适应推理提升大型语言模型效率](https://arxiv.org/abs/2505.11896)
Json decode failed:
{
  "title": "基于链式模型的高效可扩展语言模型研究",
  "short_summary": "提出一种引入因果关系的链式模型(CoM)，提升训练效率与推理灵活性。",
  "summary": "本文提出了一种名为链式模型(CoM)的新学习范式，通过在每一层隐藏状态中嵌入因果关系，形成链式结构，从而显著提高模型训练的扩展效率，并在部署时提供灵活的推理能力。文中进一步提出了链式表示(Chain-of-Representation, CoR)的概念，将每层的隐藏状态视为多个子表示(即链条)的组合。在此基础上构建的模型可以逐步扩展规模，并为弹性推理提供不同大小的子模型。基于此原理，设计了链式语言模型(CoLM)，并引入KV共享机制，进一步开发了CoLM-Air，实现了无缝切换语言模型、前填充加速等功能。实验结果表明，CoLM家族在性能上与标准Transformer相当，同时具备更高的灵活性，为构建语言模型开辟了新路径。未来将在https:
  "keyword": ["链式模型", "因果关系", "语言模型"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 339 (char 430). Line: 406.
Append: [Chain-of-Model Learning for Language Model](https://arxiv.org/abs/2505.11820)
Token length: 1366
Summarized using qwen-turbo
Append: [通过校正分布偏移提升Transformer稀疏注意力性能](https://arxiv.org/abs/2505.11254)
append_entries: 14
Finish: 2025-05-20 06:22:40.944955
------------------------------------------------------
Started: 2025-05-20 12:30:11.071314
Existing_entries: 1014
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1231
Summarized using qwen-turbo
Append: [VSA：一种高效的可训练稀疏注意力机制](https://arxiv.org/abs/2505.13389)
Token length: 1691
Summarized using qwen-turbo
Append: [LatentSeek：通过测试时实例级适应提升大语言模型推理能力](https://arxiv.org/abs/2505.13308)
Token length: 1555
Summarized using qwen-turbo
Append: [OSWorld-G与Jedi：提升图形用户界面定位能力的新基准与数据集](https://arxiv.org/abs/2505.13227)
Token length: 1409
Summarized using qwen-turbo
Append: [ViPlan：视觉规划领域的首个开源基准测试](https://arxiv.org/abs/2505.13180)
Token length: 1482
Summarized using qwen-turbo
Append: [基于强化学习的多语言机器翻译模型研究](https://arxiv.org/abs/2505.12996)
Token length: 1412
Summarized using qwen-turbo
Append: [Fractured Sampling：提升大语言模型推理效率的新策略](https://arxiv.org/abs/2505.12992)
Token length: 1223
Summarized using qwen-turbo
Append: [解决同形异义词消歧挑战的半自动化方法及快速规则系统](https://arxiv.org/abs/2505.12973)
Token length: 1753
Summarized using qwen-turbo
Append: [语言如何在合作中演化？基于多智能体觅食游戏的研究](https://arxiv.org/abs/2505.12872)
Token length: 1858
Summarized using qwen-turbo
Append: [通过结构化上下文条件化增强大语言模型在科学文档验证中的准确性](https://arxiv.org/abs/2505.12257)
Token length: 1030
Summarized using qwen-turbo
Append: [大规模预训练中的模型合并技术研究](https://arxiv.org/abs/2505.12082)
Token length: 1404
Summarized using qwen-turbo
Append: [Tiny QA Benchmark++：轻量级多语言模型安全测试套件](https://arxiv.org/abs/2505.12058)
Token length: 1431
Summarized using qwen-turbo
Append: [基于RAG框架的领域特定恶意技术识别方法](https://arxiv.org/abs/2505.11988)
Token length: 1267
Summarized using qwen-turbo
Append: [大型语言模型在学术验证中的局限性研究](https://arxiv.org/abs/2505.11855)
Token length: 1589
Summarized using qwen-turbo
Append: [QVGen：面向极低比特量化视频扩散模型的高效推理框架](https://arxiv.org/abs/2505.11497)
Json decode failed:
{
  "title": "SoftCoT++：通过对比学习增强连续空间推理的多样性",
  "short_summary": "引入SoftCoT++扩展测试时扩展(TTS)，通过扰动潜在思想实现多样化的推理路径探索。",
  "summary": "本文探讨了测试时扩展(Test-Time Scaling, TTS)方法，该方法通过在推理过程中分配更多计算资源来提升模型推理性能，而不改变模型参数。传统TTS方法通常在离散标记空间中操作，而近期研究如Coconut和SoftCoT展示了在连续潜在空间中推理的优势，即通过编码有信息量的思考过程，避免了自回归标记生成的信息丢失。然而，连续空间中的固定潜在表示限制了多样化探索，所有解码路径均源于相同的潜在思想。为解决此问题，我们提出了SoftCoT++，它通过引入多个专用初始标记来扰动潜在思想，并利用对比学习促进软思想表示的多样性。实验表明，在五个推理基准和两种不同架构的语言模型上，SoftCoT++显著提升了SoftCoT的表现，同时优于采用自一致性扩展的SoftCoT，并且与传统扩展技术具有良好的兼容性。源代码已公开于https:
  "keyword": ["测试时扩展", "连续空间推理", "对比学习"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 385 (char 497). Line: 406.
Append: [SoftCoT++: Test-Time Scaling with Soft Chain-of-Thought Reasoning](https://arxiv.org/abs/2505.11484)
Json decode failed:
{
  "title": "MTVCrafter：基于4D运动令牌的人体图像动画框架",
  "short_summary": "提出首个直接建模3D运动序列的人体图像动画框架。",
  "summary": "人体图像动画因数字人类的广泛应用而受到广泛关注并快速发展，但现有方法多依赖2D渲染姿态图像进行动作引导，限制了泛化能力且丢失了重要的3D信息。为解决这一问题，我们提出了MTVCrafter（Motion Tokenization Video Crafter），这是首个直接对原始3D运动序列（即4D运动）进行建模的框架。具体而言，我们引入了4DMoT（4D运动分词器）将3D运动序列量化为4D运动令牌，相比2D渲染的姿态图像，这些令牌提供了更强大的时空线索，并避免了姿态图像与角色之间严格的像素级对齐，从而实现了更灵活和解耦的控制。随后，我们设计了MV-DiT（Motion-aware Video DiT），通过独特的运动注意力机制和4D位置编码，有效利用运动令牌作为紧凑且具有表达力的上下文信息，在复杂的3D世界中指导人体视频生成。实验表明，MTVCrafter在FID-VID指标上达到6.98，比第二名高出65%，并且在多种风格和场景下的多样化开放世界角色中表现出色。我们的视频演示和代码可在https:
  "keyword": ["人体动画", "3D运动", "MTVCrafter"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 471 (char 562). Line: 406.
Append: [MTVCrafter: 4D Motion Tokenization for Open-World Human Image Animation](https://arxiv.org/abs/2505.10238)
Token length: 1829
Summarized using qwen-turbo
Append: [基于Persistent Workflow Prompting的科学手稿评审方法研究](https://arxiv.org/abs/2505.03332)
append_entries: 17
Finish: 2025-05-20 12:32:02.610268
------------------------------------------------------
Started: 2025-05-20 18:20:43.582513
Existing_entries: 1017
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 815
Summarized using qwen-turbo
Append: [R3框架：提升奖励模型的可控性和可解释性](https://arxiv.org/abs/2505.13388)
Token length: 1329
Summarized using qwen-turbo
Append: [低秩克隆方法大幅提升小语言模型训练效率](https://arxiv.org/abs/2505.12781)
Token length: 1403
Summarized using qwen-turbo
Append: [SEED-GRPO：基于语义熵的大语言模型不确定性感知优化](https://arxiv.org/abs/2505.12346)
Json decode failed:
{
  "title": "HISTAI：一个大规模开放获取的病理切片图像数据集",
  "short_summary": "介绍了一个包含超过60,000张切片的大规模多模态病理图像数据集。",
  "summary": "数字病理学领域的人工智能发展强调了大型、多样且注释丰富的数据集的重要性。然而，现有的公开全切片图像数据集往往缺乏足够的规模、组织多样性及临床元数据，制约了模型的鲁棒性和泛化能力。为解决这一问题，我们推出了HISTAI数据集，该数据集包含超过60,000张来自多种组织类型的全切片图像，每例病例均附带详细的临床元数据，如诊断信息、人口统计资料、病理注释及标准化诊断编码。此数据集旨在填补现有资源中的不足，推动计算病理学相关创新和临床应用的发展。数据集可通过https:
  "keyword": ["数字病理学", "人工智能", "数据集"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 248 (char 346). Line: 406.
Append: [HISTAI: An Open-Source, Large-Scale Whole Slide Image Dataset for Computational Pathology](https://arxiv.org/abs/2505.12120)
Token length: 1147
Summarized using qwen-turbo
Append: [HelpSteer3-Preference：高质量指令跟随语言模型偏好数据集](https://arxiv.org/abs/2505.11475)
Token length: 1917
Summarized using qwen-turbo
Append: [基于多模态观察的一般用户模型](https://arxiv.org/abs/2505.10831)
Token length: 1518
Summarized using qwen-turbo
Append: [基于非配对数据学习的智能手机图像信号处理器优化](https://arxiv.org/abs/2505.10420)
append_entries: 7
Finish: 2025-05-20 18:21:25.099038
------------------------------------------------------
Started: 2025-05-21 01:11:00.924442
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1480
Summarized using qwen-turbo
Append: [MedCaseReasoning：评估大型语言模型临床诊断推理能力的新基准](https://arxiv.org/abs/2505.11733)
Token length: 694
Summarized using qwen-turbo
Append: [通过镜像方法评估图像常识一致性](https://arxiv.org/abs/2505.07704)
append_entries: 2
Finish: 2025-05-21 01:11:12.985464
------------------------------------------------------
Started: 2025-05-21 06:21:41.588689
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "BAGEL：开源多模态理解与生成统一模型",
  "short_summary": "BAGEL是一种支持多模态理解与生成的开源统一解码器模型。",
  "summary": "本文介绍了一种名为BAGEL的开源基础模型，该模型原生支持多模态理解和生成。BAGEL通过在大规模混合文本、图像、视频和网络数据上进行预训练，展现出强大的复杂多模态推理能力。实验结果显示，BAGEL在多模态生成和理解方面显著优于其他开源统一模型，同时具备自由形式图像操作、未来帧预测、三维操作及世界导航等高级多模态推理功能。为了促进多模态研究的发展，研究团队分享了关键发现、预训练细节、数据创建协议，并公开了代码和检查点，项目页面为https:
  "keyword": ["多模态", "开源模型", "统一解码器"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 237 (char 325). Line: 406.
Append: [Emerging Properties in Unified Multimodal Pretraining](https://arxiv.org/abs/2505.14683)
Token length: 1917
Summarized using qwen-turbo
Append: [NExT-Search：重塑生成式AI搜索的反馈驱动范式](https://arxiv.org/abs/2505.14680)
Json decode failed:
{
  "title": "引入奖励推理模型以提升奖励建模性能",
  "short_summary": "提出奖励推理模型(RRMs)，通过推理过程提升奖励建模性能。",
  "summary": "奖励模型在引导大型语言模型满足人类期望方面起着至关重要的作用，但在有效利用测试时计算资源以提高奖励模型性能上仍面临挑战。本文介绍了一种名为奖励推理模型（RRMs）的新方法，该模型专门设计用于在生成最终奖励之前执行有意识的推理过程。通过思维链推理，RRMs在复杂的查询中适当利用额外的测试时计算资源。为了开发RRMs，我们实现了一个强化学习框架，促进了自我演化的奖励推理能力，而无需显式的推理痕迹作为训练数据。实验结果显示，RRMs在多个领域的奖励建模基准测试中表现出色，并且可以自适应地利用测试时计算资源进一步提高奖励准确性。预训练的奖励推理模型可以在https:
  "keyword": ["奖励模型", "推理模型", "强化学习"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 297 (char 383). Line: 406.
Append: [Reward Reasoning Model](https://arxiv.org/abs/2505.14674)
Token length: 1643
Summarized using qwen-turbo
Append: [General-Reasoner：一种增强大语言模型跨领域推理能力的训练范式](https://arxiv.org/abs/2505.14652)
Token length: 1876
Summarized using qwen-turbo
Append: [重新审视视频理解基准：VideoEval-Pro 的提出](https://arxiv.org/abs/2505.14640)
Token length: 1205
Summarized using qwen-turbo
Append: [基于流匹配的潜在流Transformer压缩大语言模型](https://arxiv.org/abs/2505.14513)
Token length: 1333
Summarized using qwen-turbo
Append: [推理模型在置信度表达上的优越表现](https://arxiv.org/abs/2505.14489)
Token length: 1480
Summarized using qwen-turbo
Append: [基于推理数据蒸馏提升开源语言模型性能的研究](https://arxiv.org/abs/2505.14464)
Token length: 1234
Summarized using qwen-turbo
Append: [语言模型中的分词对符号推理能力的影响](https://arxiv.org/abs/2505.14178)
Token length: 1895
Summarized using qwen-turbo
Append: [Hunyuan-Game：智能游戏创作的革新项目](https://arxiv.org/abs/2505.14135)
Token length: 1167
Summarized using qwen-turbo
Append: [推理路径压缩提升逻辑型大模型推理效率](https://arxiv.org/abs/2505.13866)
Token length: 1198
Summarized using qwen-turbo
Append: [CompeteSMoE：一种高效的大规模混合专家模型训练机制](https://arxiv.org/abs/2505.13380)
Token length: 1069
Summarized using qwen-turbo
Append: [跨语言切换对大语言模型的影响及评估基准CS-Sum](https://arxiv.org/abs/2505.13559)
Json decode failed:
{
    "title": "引入空间感与推理方法SSR提升视觉语言模型的空间理解能力",
    "short_summary": "提出SSR方法，利用深度数据增强视觉语言模型的空间推理能力。",
    "summary": "本文针对现有视觉-语言模型(VLMs)依赖RGB输入导致空间理解不精确的问题，提出了名为SSR的新框架，该框架通过将原始深度数据转化为结构化的可解释文本理由，显著提升了模型的空间推理能力。此外，SSR还借助知识蒸馏技术将这些理由压缩为紧凑的潜在嵌入，从而实现高效且无需重新训练的集成。为了全面评估SSR的效果，研究者创建了一个百万规模的视觉-语言推理数据集SSR-CoT，并开发了SSRBench多任务基准。实验结果显示，SSR大幅提高了深度数据的利用率并增强了空间推理能力，推动了VLMs向更接近人类的多模态理解发展。SSR项目页面可在https:
    "keyword": ["视觉语言模型", "空间推理", "深度数据"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 292 (char 393). Line: 406.
Append: [SSR: Enhancing Depth Perception in Vision-Language Models via Rationale-Guided Spatial Reasoning](https://arxiv.org/abs/2505.12448)
Token length: 1496
Summarized using qwen-turbo
Append: [WikiDYK基准测试揭示因果语言模型的知识记忆弱点](https://arxiv.org/abs/2505.12306)
Token length: 1219
Summarized using qwen-turbo
Append: [语言模型中的真相神经元：机制解析与验证](https://arxiv.org/abs/2505.12182)
Token length: 1406
Summarized using qwen-turbo
Append: [FlexiVe：一种灵活的大型语言模型推理验证方法](https://arxiv.org/abs/2505.11966)
Token length: 1087
Summarized using qwen-turbo
Append: [通过低比特注意力机制提升大规模模型训练效率](https://arxiv.org/abs/2505.11594)
Token length: 1565
Summarized using qwen-turbo
Append: [AI对Z世代数字语言的理解评估：在线安全的新挑战](https://arxiv.org/abs/2505.10588)
append_entries: 19
Finish: 2025-05-21 06:23:29.627291
------------------------------------------------------
Started: 2025-05-21 12:29:24.628312
Existing_entries: 1019
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1442
Summarized using qwen-turbo
Append: [通过强化认知专家提升大规模推理模型的推理效率](https://arxiv.org/abs/2505.14681)
Token length: 1406
Summarized using qwen-turbo
Append: [通过强化学习训练视觉语言模型实现无监督推理](https://arxiv.org/abs/2505.14677)
Token length: 1430
Summarized using qwen-turbo
Append: [IndexMark：一种无需训练的自回归图像生成模型水印框架](https://arxiv.org/abs/2505.14673)
Token length: 1417
Summarized using qwen-turbo
Append: [基于自适应混合推理的大规模模型研究](https://arxiv.org/abs/2505.14631)
Token length: 895
Summarized using qwen-turbo
Append: [Gemini模型对抗性鲁棒性评估方法及经验](https://arxiv.org/abs/2505.14534)
Token length: 1585
Summarized using qwen-turbo
Append: [基于推理诱导的无参考图像质量评估模型VisualQuality-R1](https://arxiv.org/abs/2505.14460)
Token length: 1286
Summarized using qwen-turbo
Append: [探索语言模型中的隐藏知识：Taboo模型与解密策略](https://arxiv.org/abs/2505.14352)
Token length: 1597
Summarized using qwen-turbo
Append: [视觉主动强化微调提升多模态大模型推理能力](https://arxiv.org/abs/2505.14246)
Token length: 1536
Summarized using qwen-turbo
Append: [基于双阶段训练策略构建少样本推理能力的大语言模型](https://arxiv.org/abs/2505.13718)
Token length: 1511
Summarized using qwen-turbo
Append: [AnytimeReasoner：优化语言模型在动态计算预算下的推理性能](https://arxiv.org/abs/2505.13438)
Token length: 1410
Summarized using qwen-turbo
Append: [基于量化零阶优化的高效大语言模型微调方法](https://arxiv.org/abs/2505.13430)
Token length: 1025
Summarized using qwen-turbo
Append: [神经符号扩散模型提升视觉推理能力](https://arxiv.org/abs/2505.13138)
Token length: 1247
Summarized using qwen-turbo
Append: [WILLIAMT：通过模板引导提升自动化程序修复效率](https://arxiv.org/abs/2505.13103)
Token length: 1336
Summarized using qwen-turbo
Append: [基于RoBERTa的媒体偏见检测模型性能提升研究](https://arxiv.org/abs/2505.13010)
Token length: 1243
Summarized using qwen-turbo
Append: [FedPrLLM：一种面向隐私保护的大型语言模型压缩框架](https://arxiv.org/abs/2505.13547)
Token length: 1599
Summarized using qwen-turbo
Append: [探究语言模型在多跳问答中的表现及优化策略](https://arxiv.org/abs/2505.11754)
Token length: 786
Summarized using qwen-turbo
Append: [Phare：多语言大语言模型安全性诊断框架](https://arxiv.org/abs/2505.11365)
Token length: 1789
Summarized using qwen-turbo
Append: [基于生物逆效应机制的多模态融合策略](https://arxiv.org/abs/2505.10176)
Token length: 1506
Summarized using qwen-turbo
Append: [MIGRATION-BENCH：面向代码迁移的大规模基准测试](https://arxiv.org/abs/2505.09569)
Token length: 1856
Summarized using qwen-turbo
Append: [Aloe Beta：开源医疗领域大型语言模型的标杆](https://arxiv.org/abs/2505.04388)
append_entries: 20
Finish: 2025-05-21 12:31:43.019622
------------------------------------------------------
Started: 2025-05-21 18:20:44.709059
Existing_entries: 1020
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1279
Summarized using qwen-turbo
Append: [Vox-Profile：基于语音基础模型的多维度说话人与语音特征基准](https://arxiv.org/abs/2505.14648)
Token length: 1032
Summarized using qwen-turbo
Append: [通过检测AI价值观预测潜在风险](https://arxiv.org/abs/2505.14633)
Token length: 1244
Summarized using qwen-turbo
Append: [KERL：基于知识图谱与大语言模型的个性化食品推荐与食谱生成系统](https://arxiv.org/abs/2505.14629)
Token length: 1137
Summarized using qwen-turbo
Append: [基于动态神经活动扩散的脑成像解码模型](https://arxiv.org/abs/2505.14556)
Token length: 848
Summarized using qwen-turbo
Append: [基于视觉视角理解的视觉语言模型训练框架](https://arxiv.org/abs/2505.14366)
Token length: 1460
Summarized using qwen-turbo
Append: [CoIn：提升闭源大语言模型计费透明性的验证框架](https://arxiv.org/abs/2505.13778)
Json decode failed:
{
  "title": "基于视觉引导的音频突出显示技术",
  "short_summary": "提出一种新方法，通过视觉引导提升音频效果。",
  "summary": "近年来视频内容的创作与消费显著增加，但音频与视频的协调性不足。本文引入“视觉引导的音频突出显示”任务，旨在通过视频指导优化音频效果，提升视听体验。为此，我们设计了一个基于Transformer的多模态框架，并创建了“泥泞混合数据集”进行训练，通过分离、调整和混音生成伪数据。实验表明，该方法在定量和主观评估中均优于多种基线模型，同时研究了不同上下文指导类型及数据集难度的影响。项目页面可访问：https:
  "keyword": ["视觉引导", "音频突出显示", "多模态框架"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 217 (char 292). Line: 406.
Append: [Learning to Highlight Audio by Watching Movies](https://arxiv.org/abs/2505.12154)
Token length: 1247
Summarized using qwen-turbo
Append: [可变粒度搜索提升大语言模型推理能力](https://arxiv.org/abs/2505.11730)
Token length: 1167
Summarized using qwen-turbo
Append: [基于对象中心表征的机器人操作策略鲁棒性研究](https://arxiv.org/abs/2505.11563)
Token length: 1148
Summarized using qwen-turbo
Append: [提升RAG系统性能的新方法：利用困难干扰片段](https://arxiv.org/abs/2505.06914)
append_entries: 10
Finish: 2025-05-21 18:21:47.909686
------------------------------------------------------
Started: 2025-05-22 01:10:30.961697
Existing_entries: 1010
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1553
Summarized using qwen-turbo
Append: [探究Transformer语言模型推理阶段中的非激活层](https://arxiv.org/abs/2505.14467)
Token length: 1274
Summarized using qwen-turbo
Append: [强化微调对大语言模型可信度的影响及“幻觉税”问题研究](https://arxiv.org/abs/2505.13988)
Token length: 1174
Summarized using qwen-turbo
Append: [通过信息瓶颈理论提升多模态大语言模型的分布外泛化能力](https://arxiv.org/abs/2505.13946)
Token length: 1108
Summarized using qwen-turbo
Append: [GeoRanker：基于视觉语言模型的地理排名框架](https://arxiv.org/abs/2505.13731)
append_entries: 4
Finish: 2025-05-22 01:10:58.333563
------------------------------------------------------
Started: 2025-05-22 06:21:24.807445
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "ProxyV：通过代理视觉标记减轻多模态模型计算负担",
  "short_summary": "提出一种新方法ProxyV，利用代理视觉标记减少视觉编码计算开销。",
  "summary": "大型多模态模型在多模态任务中表现出色，但因视觉标记的过度计算面临显著挑战。现有方法主要关注标记层面的冗余，而本文聚焦于计算层面的冗余，在不损失信息的前提下设计了一系列实验，揭示并逐步挤压视觉计算冗余。基于研究结果，我们提出了ProxyV方法，它通过引入代理视觉标记减轻原始视觉标记的计算负担，提升效率的同时不牺牲性能，甚至在适度效率改进场景下带来显著性能提升。此外，ProxyV具有灵活性，可与其他标记缩减方法结合进一步提高效率。代码将在https:
  "keyword": ["多模态模型", "计算冗余", "ProxyV"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 240 (char 338). Line: 406.
Append: [Streamline Without Sacrifice - Squeeze out Computation Redundancy in LMM](https://arxiv.org/abs/2505.15816)
Token length: 1837
Summarized using qwen-turbo
Append: [MMaDA：一种跨模态扩散基础模型的创新设计](https://arxiv.org/abs/2505.15809)
Token length: 1280
Summarized using qwen-turbo
Append: [VARD：基于价值函数的强化扩散模型优化方法](https://arxiv.org/abs/2505.15791)
Token length: 1525
Summarized using qwen-turbo
Append: [基于延迟键值缓存机制的扩散语言模型加速方法](https://arxiv.org/abs/2505.15781)
Token length: 1503
Summarized using qwen-turbo
Append: [互联网增强文本到图像生成框架解决不确定知识问题](https://arxiv.org/abs/2505.15779)
Token length: 1739
Summarized using qwen-turbo
Append: [Soft Thinking: 模拟人类软推理突破离散语言推理瓶颈](https://arxiv.org/abs/2505.15778)
Token length: 1591
Summarized using qwen-turbo
Append: [基于单张顶视图生成高质量3D场景的3DTown框架](https://arxiv.org/abs/2505.15765)
Json decode failed:
{
  "title": "开源大语言模型微调中的隐蔽数据窃取风险",
  "short_summary": "研究揭示通过后门训练可从黑盒访问的下游模型中提取私有微调数据。",
  "summary": "本文探讨了基于开源大语言模型（LLMs）微调时的一项新风险：即使仅拥有对下游微调模型的黑盒访问权限，开源LLMs的创建者也可能通过简单后门训练手段提取下游微调数据。我们针对四种参数规模从3B到32B的流行开源模型及两个下游数据集进行了广泛的实验，结果显示实际场景下最多可提取76.3%的微调数据，在理想条件下成功率甚至可达94.9%。尽管尝试采用检测性防御策略，但发现其容易被改进后的攻击方法绕过。总体而言，我们强调了这一新型数据泄露风险的紧迫性，并呼吁更多后续研究共同应对这一问题。相关代码和数据已公开于https:
  "keyword": ["开源模型", "微调风险", "数据窃取"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 274 (char 363). Line: 406.
Append: [Be Careful When Fine-tuning On Open-Source LLMs: Your Fine-tuning Data Could Be Secretly Stolen!](https://arxiv.org/abs/2505.15656)
Token length: 1915
Summarized using qwen-turbo
Append: [基于奖励塑形的高效推理模型研究](https://arxiv.org/abs/2505.15612)
Token length: 1600
Summarized using qwen-turbo
Append: [通过监督微调提升大规模推理模型的安全性研究](https://arxiv.org/abs/2505.15404)
Token length: 1393
Summarized using qwen-turbo
Append: [Web-Shepherd：首个用于网页导航的进程奖励模型](https://arxiv.org/abs/2505.15277)
Token length: 1509
Summarized using qwen-turbo
Append: [基于知识图谱的信任推理框架Deliberation over Priors](https://arxiv.org/abs/2505.15210)
Token length: 1193
Summarized using qwen-turbo
Append: [lmgame-Bench：通过视频游戏评估大型语言模型](https://arxiv.org/abs/2505.15146)
Token length: 1374
Summarized using qwen-turbo
Append: [PiFlow：基于信息论的自动化科学发现框架](https://arxiv.org/abs/2505.15047)
Token length: 1076
Summarized using qwen-turbo
Append: [基于扩散语言模型的文本嵌入方法超越传统大型语言模型](https://arxiv.org/abs/2505.15045)
Token length: 1731
Summarized using qwen-turbo
Append: [语言特定知识对多语言推理能力的影响研究](https://arxiv.org/abs/2505.14990)
Token length: 1186
Summarized using qwen-turbo
Append: [Mixture of Inputs提升大语言模型生成质量](https://arxiv.org/abs/2505.14827)
Token length: 1246
Summarized using qwen-turbo
Append: [Vid2World：利用视频扩散模型构建交互式世界模型](https://arxiv.org/abs/2505.14357)
Token length: 1721
Summarized using qwen-turbo
Append: [量化感知训练的统一缩放定律及其误差分析](https://arxiv.org/abs/2505.14302)
Json decode failed:
{
  "title": "UniVG-R1：基于强化学习的多模态大语言模型用于通用视觉定位",
  "short_summary": "提出一种结合强化学习的多模态大语言模型，提升跨模态复杂场景下的推理能力。",
  "summary": "本文针对传统视觉定位方法难以处理隐式复杂指令和多图像场景的问题，提出了UniVG-R1模型，该模型通过强化学习结合冷启动数据增强推理能力。首先构建了一个高质量的带有详细推理链的标注数据集，用于指导模型的推理路径。接着采用基于规则的强化学习，鼓励模型识别正确的推理链。此外，针对训练过程中容易出现的难度偏差，提出了一种难度感知权重调整策略。实验结果显示，UniVG-R1在MIG-Bench上相比前一方法提升了9.1%，并且在四个图像和视频推理定位基准测试中展现了强大的零样本泛化性能，平均提升了23.4%。项目页面可通过https:
  "keyword": ["视觉定位", "多模态推理", "强化学习"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 281 (char 388). Line: 406.
Append: [UniVG-R1: Reasoning Guided Universal Visual Grounding with Reinforcement Learning](https://arxiv.org/abs/2505.14231)
Token length: 1029
Summarized using qwen-turbo
Append: [基于强化学习与可验证奖励的世界模型优化框架](https://arxiv.org/abs/2505.13934)
Token length: 894
Summarized using qwen-turbo
Append: [基于少量高质量轨迹数据的高效计算机操作代理训练框架](https://arxiv.org/abs/2505.13909)
Token length: 1667
Summarized using qwen-turbo
Append: [AutoMat：基于深度学习将电子显微镜图像转化为晶体结构的自动化流水线](https://arxiv.org/abs/2505.12650)
Token length: 981
Summarized using qwen-turbo
Append: [BARREL框架提升大型推理模型的事实可靠性](https://arxiv.org/abs/2505.13529)
append_entries: 24
Finish: 2025-05-22 06:23:21.958919
------------------------------------------------------
Started: 2025-05-22 12:30:07.557709
Existing_entries: 1024
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1670
Summarized using qwen-turbo
Append: [Mixture-of-Thought框架：多模态推理提升逻辑推理性能](https://arxiv.org/abs/2505.15817)
Token length: 1395
Summarized using qwen-turbo
Append: [基于强化学习的会话查询重写框架ConvSearch-R1](https://arxiv.org/abs/2505.15776)
Token length: 1677
Summarized using qwen-turbo
Append: [BiasLens：基于模型向量空间结构的大语言模型偏见分析框架](https://arxiv.org/abs/2505.15524)
Token length: 1596
Summarized using qwen-turbo
Append: [AJailBench：评估大型音频语言模型的越狱攻击漏洞](https://arxiv.org/abs/2505.15406)
Token length: 1181
Summarized using qwen-turbo
Append: [自适应自我恢复推理框架提升大规模推理模型效率](https://arxiv.org/abs/2505.15400)
Token length: 1682
Summarized using qwen-turbo
Append: [Tango: 一种同时训练语言模型生成器和验证器的强化学习框架](https://arxiv.org/abs/2505.15034)
Token length: 1180
Summarized using qwen-turbo
Append: [WebNovelBench：评估大语言模型叙事能力的新基准](https://arxiv.org/abs/2505.14818)
Token length: 1144
Summarized using qwen-turbo
Append: [Toto：基于观测数据的时间序列预测基础模型](https://arxiv.org/abs/2505.14766)
Token length: 1512
Summarized using qwen-turbo
Append: [强化微调中的先验提示工程研究](https://arxiv.org/abs/2505.14157)
Token length: 1420
Summarized using qwen-turbo
Append: [基于知识图谱的多语言多跳幻觉评估基准MultiHal](https://arxiv.org/abs/2505.14101)
Json decode failed:
{
  "title": "HumaniBench：面向人类中心AI原则的大型多模态模型评估基准",
  "short_summary": "HumaniBench评估15个顶级大型多模态模型在公平性、伦理、同理心等人类中心标准上的表现。",
  "summary": "本文介绍了HumaniBench，这是一个由32K真实图像问题对组成的综合基准，通过可扩展的GPT4o辅助管道注释并经领域专家验证。该基准涵盖七项人类中心AI（HCAI）原则，包括公平性、伦理、理解力、推理能力、语言包容性、同理心及鲁棒性，在开放和封闭问答、多语言问答、视觉定位、共情描述及鲁棒性测试等七个多样化任务中进行评估。实验结果显示，闭源模型总体表现领先，但在鲁棒性和视觉定位方面仍显薄弱，而开源模型在平衡准确性与人类导向原则时也面临挑战。作为首个专门围绕HCAI原则构建的基准，HumaniBench为诊断对齐差距并引导大型多模态模型走向既准确又负责任的行为提供了严格的测试环境。相关数据集、注释提示和评估代码可在https:
  "keyword": ["大型多模态模型", "人类中心AI", "公平性"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 333 (char 454). Line: 406.
Append: [HumaniBench: A Human-Centric Framework for Large Multimodal Models Evaluation](https://arxiv.org/abs/2505.11454)
append_entries: 11
Finish: 2025-05-22 12:31:12.801539
------------------------------------------------------
Started: 2025-05-22 18:20:15.114279
Existing_entries: 1011
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 913
Summarized using qwen-turbo
Append: [Llama-SMoP：一种高效多模态大型语言模型用于视听语音识别](https://arxiv.org/abs/2505.14336)
append_entries: 1
Finish: 2025-05-22 18:20:20.199110
------------------------------------------------------
Started: 2025-05-23 01:10:27.155408
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1174
Summarized using qwen-turbo
Append: [评估参考型奖励系统的VerifyBench基准测试](https://arxiv.org/abs/2505.15801)
Token length: 1369
Summarized using qwen-turbo
Append: [基于多臂老虎机的自适应推测解码框架](https://arxiv.org/abs/2505.15141)
Token length: 1314
Summarized using qwen-turbo
Append: [熵最小化提升大语言模型在复杂任务中的表现](https://arxiv.org/abs/2505.15134)
Token length: 1546
Summarized using qwen-turbo
Append: [DiCo：基于标准卷积网络的高效扩散模型](https://arxiv.org/abs/2505.11196)
Json decode failed:
{
  "title": "BLEU作为奖励模型替代方案在指令跟随对齐中的应用",
  "short_summary": "研究发现，基于字符串匹配的BLEU指标可替代昂贵的奖励模型用于LLMs的对齐。",
  "summary": "奖励模型在使大型语言模型（LLMs）符合人类偏好方面至关重要，但其训练成本高昂，需要大规模的人类标注偏好数据和强大的预训练LLM骨干网络。然而，高质量合成指令跟随数据集的日益普及引发了疑问：在基于强化学习的对齐过程中，简单的参考度量是否可以作为奖励模型的可行替代方案？本文表明，基本的字符串匹配度量BLEU在一般指令跟随数据集上与人类偏好一致时，与强大的奖励模型相匹配。基于这一见解，我们开发了BLEUBERI方法，该方法首先识别具有挑战性的指令，然后利用BLEU直接作为奖励函数进行组相对策略优化（GRPO）。实验结果显示，BLEUBERI训练的模型在四个具有挑战性的指令跟随基准和三种不同的基础语言模型上表现出了竞争力。此外，人类评估进一步支持了BLEUBERI模型输出的质量与奖励模型对齐模型相当，且生成的内容在事实准确性方面优于竞争方法。总的来说，我们证明了在拥有高质量参考输出（可通过现有指令跟随数据集或合成数据生成轻松获得）的情况下，基于字符串匹配的度量可以作为奖励模型的有效且经济的替代方案。我们已公开代码和数据，可在https:
  "keyword": ["LLMs", "奖励模型", "BLEU"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 487 (char 590). Line: 406.
Append: [BLEUBERI: BLEU is a surprisingly effective reward for instruction following](https://arxiv.org/abs/2505.11080)
append_entries: 5
Finish: 2025-05-23 01:10:55.603429
------------------------------------------------------
Started: 2025-05-23 06:21:11.247305
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1685
Summarized using qwen-turbo
Append: [SophiaVL-R1：强化多模态大语言模型推理能力的新方法](https://arxiv.org/abs/2505.17018)
Token length: 1320
Summarized using qwen-turbo
Append: [多模态大语言模型的空间感知能力评估](https://arxiv.org/abs/2505.17012)
Json decode failed:
{
  "title": "Dimple：首个离散扩散多模态大语言模型",
  "short_summary": "Dimple结合自回归和扩散方法，性能超越LLaVA-NEXT。",
  "summary": "本文提出了一种名为Dimple的离散扩散多模态大语言模型（DMLLM）。研究发现，仅使用纯离散扩散训练会导致显著的训练不稳定性和次优表现，还存在严重的长度偏差问题。为此，设计了一种将初始自回归阶段与后续扩散阶段相结合的新训练范式，最终训练出的Dimple-7B模型在相同数据集和类似训练管道下表现出比LLaVA-NEXT高3.9%的性能。此外，为了提高推理效率，提出了自信解码策略，动态调整每次生成的令牌数量，大幅减少了生成迭代次数。同时，重新实现的预填充技术在大多数基准评估中对性能影响不大，但提升了1.5到7倍的速度。此外，Dimple还能通过结构先验精确控制响应，这种能力区别于基于指令或链式思维提示的方式，且难以在自回归模型中实现。本研究验证了DMLLM的可行性和优势，并提升了其推理效率和可控性。代码和模型可在https:
  "keyword": ["离散扩散", "多模态", "大语言模型"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 381 (char 473). Line: 406.
Append: [Dimple: Discrete Diffusion Multimodal Large Language Model with Parallel Decoding](https://arxiv.org/abs/2505.16990)
Token length: 1301
Summarized using qwen-turbo
Append: [NovelSeek：人工智能驱动的跨领域自主科学研究框架](https://arxiv.org/abs/2505.16938)
Token length: 1379
Summarized using qwen-turbo
Append: [LLaDA-V：一种基于扩散模型的多模态大型语言模型](https://arxiv.org/abs/2505.16933)
Token length: 1365
Summarized using qwen-turbo
Append: [Believe Your Eyes: 通过注意力熵模式防御多模态大语言模型后门攻击](https://arxiv.org/abs/2505.16916)
Token length: 1374
Summarized using qwen-turbo
Append: [Jenga：通过动态注意力裁剪和渐进分辨率生成提升视频扩散模型推理效率](https://arxiv.org/abs/2505.16864)
Token length: 1564
Summarized using qwen-turbo
Append: [通过两阶段训练策略实现视觉语言模型的人类化推理模式](https://arxiv.org/abs/2505.16854)
Token length: 1592
Summarized using qwen-turbo
Append: [LaViDa：基于离散扩散模型的多模态视觉语言模型](https://arxiv.org/abs/2505.16839)
Token length: 1167
Summarized using qwen-turbo
Append: [KRIS-Bench：基于知识推理的图像编辑系统评估基准](https://arxiv.org/abs/2505.16707)
Token length: 1489
Summarized using qwen-turbo
Append: [Tool-Star：基于强化学习的大语言模型多工具协作推理框架](https://arxiv.org/abs/2505.16410)
Token length: 1885
Summarized using qwen-turbo
Append: [强化学习显著提升中小规模模型推理能力](https://arxiv.org/abs/2505.16400)
Json decode failed:
{
  "title": "基于Reddit社区分析的图像编辑AI能力研究",
  "short_summary": "研究揭示AI图像编辑器在特定请求下的表现优于开放性任务。",
  "summary": "本研究通过分析Reddit社区2013年至2025年的83,000个图像编辑请求及其对应的305,000次人工修改，评估了当前AI图像编辑器（如GPT-4o、Gemini-2.0-Flash、SeedEdit）的能力。结果显示，仅有约33%的请求可被最佳AI编辑器成功完成。有趣的是，AI在低创意但需精确操作的任务上表现较差，而在开放性任务上表现更好。此外，AI常无法保留人物和动物的身份特征，且容易添加不必要的修饰。相比之下，视觉语言模型（VLM）评价与人类评价存在差异，可能更偏好AI编辑结果。研究代码和示例可在https:
  "keyword": ["图像编辑", "AI能力", "Reddit社区"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 279 (char 369). Line: 406.
Append: [Understanding Generative AI Capabilities in Everyday Image Editing Tasks](https://arxiv.org/abs/2505.16181)
Token length: 1421
Summarized using qwen-turbo
Append: [QuickVideo：加速长视频理解的系统-算法协同设计](https://arxiv.org/abs/2505.16175)
Token length: 1525
Summarized using qwen-turbo
Append: [无需微调的多模态大模型推理能力增强方法](https://arxiv.org/abs/2505.16151)
Token length: 1796
Summarized using qwen-turbo
Append: [引入像素空间推理提升视觉语言模型性能](https://arxiv.org/abs/2505.15966)
Token length: 1142
Summarized using qwen-turbo
Append: [基于在线对比学习的视觉语言模型幻觉抑制方法](https://arxiv.org/abs/2505.15963)
Token length: 1557
Summarized using qwen-turbo
Append: [最大更新参数化在扩散Transformer中的扩展及其在视觉生成模型中的应用](https://arxiv.org/abs/2505.15270)
Token length: 1167
Summarized using qwen-turbo
Append: [MathIF：评估数学推理任务中指令跟随能力的基准](https://arxiv.org/abs/2505.14810)
Token length: 1364
Summarized using qwen-turbo
Append: [解决大语言模型强化学习中验证器假阴性问题的研究](https://arxiv.org/abs/2505.14625)
Token length: 1616
Summarized using qwen-turbo
Append: [强化学习对大语言模型参数更新的稀疏性研究](https://arxiv.org/abs/2505.11711)
append_entries: 21
Finish: 2025-05-23 06:23:01.852490
------------------------------------------------------
Started: 2025-05-23 12:28:30.382906
Existing_entries: 1021
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1467
Summarized using qwen-turbo
Append: [通过强化学习提升视觉生成中的语义-空间推理能力](https://arxiv.org/abs/2505.17022)
Token length: 1585
Summarized using qwen-turbo
Append: [基于三阶段框架Let Androids Dream的图像隐含含义理解](https://arxiv.org/abs/2505.17019)
Token length: 1071
Summarized using qwen-turbo
Append: [多模态大语言模型的多帧空间理解增强](https://arxiv.org/abs/2505.17015)
Token length: 1748
Summarized using qwen-turbo
Append: [AgentIF：大型语言模型在具身场景下指令遵循能力的评估基准](https://arxiv.org/abs/2505.16944)
Token length: 1085
Summarized using qwen-turbo
Append: [基于Itakura-Saito散度的风险规避强化学习](https://arxiv.org/abs/2505.16925)
Token length: 1094
Summarized using qwen-turbo
Append: [基于大语言模型个性化文学翻译的研究](https://arxiv.org/abs/2505.16612)
Token length: 1434
Summarized using qwen-turbo
Append: [VLM-R^3：结合视觉区域识别与推理的多模态大语言模型](https://arxiv.org/abs/2505.16192)
Token length: 1565
Summarized using qwen-turbo
Append: [SafeKey：通过关键句激活提升大推理模型的安全泛化能力](https://arxiv.org/abs/2505.16186)
Token length: 1191
Summarized using qwen-turbo
Append: [大型语言模型如何承认错误？错误重述行为的研究](https://arxiv.org/abs/2505.16170)
Token length: 1303
Summarized using qwen-turbo
Append: [现代日期处理在语言模型中的挑战与改进](https://arxiv.org/abs/2505.16088)
Token length: 1045
Summarized using qwen-turbo
Append: [基于拓扑优化的大型语言模型物理与空间推理能力评估数据集](https://arxiv.org/abs/2505.16048)
Token length: 1120
Summarized using qwen-turbo
Append: [VideoGameQA-Bench：推动游戏开发质量保障自动化](https://arxiv.org/abs/2505.15952)
Token length: 1592
Summarized using qwen-turbo
Append: [引入视觉信息的强化学习推理模型GRIT](https://arxiv.org/abs/2505.15879)
Token length: 1431
Summarized using qwen-turbo
Append: [基于机器人轨迹数据增强视觉语言模型的VQA数据集生成框架](https://arxiv.org/abs/2505.15517)
Token length: 1235
Summarized using qwen-turbo
Append: [大型视觉语言模型中光学字符识别头的功能解析](https://arxiv.org/abs/2505.15865)
Token length: 1315
Summarized using qwen-turbo
Append: [通过填补思维跳跃提升大规模语言模型的数学推理能力](https://arxiv.org/abs/2505.14684)
Token length: 1571
Summarized using qwen-turbo
Append: [Self-Braking Tuning:缓解大模型过推理问题的新框架](https://arxiv.org/abs/2505.14604)
Token length: 1240
Summarized using qwen-turbo
Append: [MUG-Eval：一种评估多语言大型语言模型生成能力的新框架](https://arxiv.org/abs/2505.14395)
append_entries: 18
Finish: 2025-05-23 12:30:01.248459
------------------------------------------------------
Started: 2025-05-23 18:19:18.831178
Existing_entries: 1018
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1216
Summarized using qwen-turbo
Append: [通过高质量训练数据提升检索与重排序模型性能](https://arxiv.org/abs/2505.16967)
Token length: 1416
Summarized using qwen-turbo
Append: [WebAgent-R1：一种高效的多轮网络代理强化学习框架](https://arxiv.org/abs/2505.16421)
Token length: 1907
Summarized using qwen-turbo
Append: [Think-RM：一种基于生成式奖励模型的强化学习新框架](https://arxiv.org/abs/2505.16265)
Token length: 1672
Summarized using qwen-turbo
Append: [FoVer：基于形式验证的大规模语言模型过程奖励模型训练方法](https://arxiv.org/abs/2505.15960)
Token length: 1371
Summarized using qwen-turbo
Append: [RAVENEA：通过检索增强视觉文化理解](https://arxiv.org/abs/2505.14462)
Token length: 970
Summarized using qwen-turbo
Append: [SAKURA：评估大型音频语言模型多跳推理能力的新基准](https://arxiv.org/abs/2505.13237)
append_entries: 6
Finish: 2025-05-23 18:19:53.219455
------------------------------------------------------
Started: 2025-05-24 01:07:51.427890
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 964
Summarized using qwen-turbo
Append: [RoPECraft：基于旋转位置嵌入的无训练视频动作迁移方法](https://arxiv.org/abs/2505.13344)
append_entries: 1
Finish: 2025-05-24 01:07:56.058128
------------------------------------------------------
Started: 2025-05-24 06:18:41.297279
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1198
Summarized using qwen-turbo
Append: [利用生成模型的感知组织能力实现类别无关实例分割](https://arxiv.org/abs/2505.15263)
append_entries: 1
Finish: 2025-05-24 06:18:46.460758
------------------------------------------------------
Started: 2025-05-24 12:25:43.218235
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-24 12:25:43.406836
------------------------------------------------------
Started: 2025-05-24 18:18:08.462320
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-24 18:18:08.722926
------------------------------------------------------
Started: 2025-05-25 01:16:58.333182
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-25 01:16:58.593119
------------------------------------------------------
Started: 2025-05-25 06:19:20.846001
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-25 06:19:21.035545
------------------------------------------------------
Started: 2025-05-25 12:26:23.319285
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-25 12:26:23.598587
------------------------------------------------------
Started: 2025-05-25 18:18:02.502602
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Fetch error: HTTPSConnectionPool(host='rsshub.app', port=443): Read timed out. (read timeout=30)
Fetch failed from https://rsshub.app/huggingface/daily-papers
append_entries: 0
error when rendering xml, skip docs/Huggingface-Daliy-Papers
------------------------------------------------------
Started: 2025-05-26 01:12:37.343755
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-26 01:12:37.608471
------------------------------------------------------
Started: 2025-05-26 06:22:14.001596
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1850
Summarized using qwen-turbo
Append: [V-Triune：统一强化学习提升视觉语言模型的推理与感知能力](https://arxiv.org/abs/2505.18129)
Json decode failed:
{
  "title": "VeriThinker：通过辅助验证任务压缩Chain-of-Thought推理链",
  "short_summary": "VeriThinker通过辅助验证任务有效压缩复杂推理模型的推理链长度。",
  "summary": "大型推理模型（LRMs）在复杂任务中表现出色，但其过度思考倾向导致推理链条过长，增加了推理成本。为解决这一问题，我们提出了VeriThinker，这是一种新颖的Chain-of-Thought（CoT）压缩方法。不同于传统的直接微调方法，VeriThinker仅通过辅助验证任务对模型进行微调。这种方法训练LRMs准确验证CoT解决方案的正确性，从而使其在后续自省步骤中更具辨别力，有效抑制过度推理。实验表明，VeriThinker显著减少了推理链条长度，同时保持甚至略微提升了准确性。例如，在MATH500数据集上，应用到DeepSeek-R1-Distill-Qwen-7B模型后，推理令牌数量从3790减少至2125，而准确率提升0.8%；在AIME25数据集上，令牌数量从14321减少至10287，准确率提高2.1%。此外，实验还显示VeriThinker可以零样本推广到推测性推理任务中。代码已公开于https:
  "keyword": ["推理压缩", "Chain-of-Thought", "大型语言模型"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 427 (char 543). Line: 406.
Append: [VeriThinker: Learning to Verify Makes Reasoning Model Efficient](https://arxiv.org/abs/2505.17941)
Token length: 826
Summarized using qwen-turbo
Append: [Trinity-RFT：一种灵活可扩展的大语言模型强化微调框架](https://arxiv.org/abs/2505.17826)
Token length: 1449
Summarized using qwen-turbo
Append: [Agent Distillation：将大型语言模型推理能力迁移至小规模模型](https://arxiv.org/abs/2505.17612)
Token length: 1329
Summarized using qwen-turbo
Append: [ANSE：通过主动噪声选择提升视频扩散模型质量](https://arxiv.org/abs/2505.17561)
Token length: 1152
Summarized using qwen-turbo
Append: [基于课程学习的大语言模型幻觉检测方法](https://arxiv.org/abs/2505.17558)
Token length: 1330
Summarized using qwen-turbo
Append: [基于正则化策略梯度的在线强化学习方法研究](https://arxiv.org/abs/2505.17508)
Token length: 961
Summarized using qwen-turbo
Append: [基于语义表征的语音指令数据生成方法](https://arxiv.org/abs/2505.17417)
Token length: 1416
Summarized using qwen-turbo
Append: [大型语言模型中的推理刚性问题及其诊断研究](https://arxiv.org/abs/2505.17225)
Token length: 1127
Summarized using qwen-turbo
Append: [CANOE框架提升大语言模型生成任务的准确性](https://arxiv.org/abs/2505.16483)
Token length: 1430
Summarized using qwen-turbo
Append: [Transformer Copilot：通过日志驱动优化的大语言模型增强框架](https://arxiv.org/abs/2505.16270)
Token length: 1731
Summarized using qwen-turbo
Append: [AudioTrust：首个面向音频大语言模型的多维度可信性评估框架](https://arxiv.org/abs/2505.16211)
Token length: 1248
Summarized using qwen-turbo
Append: [TAPO：通过融入外部知识提升强化学习推理能力](https://arxiv.org/abs/2505.15692)
Token length: 1121
Summarized using qwen-turbo
Append: [基于真实表情包评估视觉语言模型的安全性](https://arxiv.org/abs/2505.15389)
Token length: 987
Summarized using qwen-turbo
Append: [基于文本大模型的跨模态学习能力研究](https://arxiv.org/abs/2505.17091)
append_entries: 15
Finish: 2025-05-26 06:23:37.654492
------------------------------------------------------
Started: 2025-05-26 12:28:45.222369
Existing_entries: 1015
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1292
Summarized using qwen-turbo
Append: [TabSTAR：一种具有语义目标感知表示的表格基础模型](https://arxiv.org/abs/2505.18125)
Token length: 1511
Summarized using qwen-turbo
Append: [QwenLong-CPRS：一种面向长上下文优化的动态压缩框架](https://arxiv.org/abs/2505.18092)
Token length: 1277
Summarized using qwen-turbo
Append: [基于模拟实验引导的假设排序方法](https://arxiv.org/abs/2505.17873)
Token length: 1410
Summarized using qwen-turbo
Append: [QwenLong-L1：通过渐进式上下文扩展提升长上下文推理能力](https://arxiv.org/abs/2505.17667)
Json decode failed:
{
  "title": "基于进化搜索的测试时扩展方法提升图像与视频生成模型性能",
  "short_summary": "提出一种新颖的测试时扩展方法EvoSearch，显著提高图像和视频生成模型性能。",
  "summary": "本文介绍了一种名为EvoSearch的新颖测试时扩展方法，用于增强扩散模型和流模型在图像和视频生成中的可扩展性。通过将测试时扩展问题转化为一个生物进化问题，EvoSearch利用选择和突变机制优化去噪轨迹，从而生成高质量样本并保持多样性。实验表明，该方法在多个扩散和流模型架构上优于现有方法，且具有更强的泛化能力。此外，该研究填补了视觉任务中测试时扩展理解的空白，克服了现有方法的局限性。项目地址：https:
  "keyword": ["测试时扩展", "图像生成", "视频生成"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 220 (char 326). Line: 406.
Append: [Scaling Image and Video Generation via Test-Time Evolutionary Search](https://arxiv.org/abs/2505.17618)
Token length: 1267
Summarized using qwen-turbo
Append: [RePrompt：通过强化学习增强文本到图像生成的提示](https://arxiv.org/abs/2505.17540)
Token length: 1477
Summarized using qwen-turbo
Append: [Direct3D S2：基于稀疏体素的高效3D形状生成框架](https://arxiv.org/abs/2505.17412)
Token length: 1433
Summarized using qwen-turbo
Append: [FullFront：前端工程全流程多模态大语言模型基准测试](https://arxiv.org/abs/2505.17399)
Token length: 1290
Summarized using qwen-turbo
Append: [RIPT-VLA：基于强化学习的轻量级视觉-语言-动作模型后训练范式](https://arxiv.org/abs/2505.17016)
Json decode failed:
{
  "title": "RBench-V：评估多模态模型视觉推理能力的新基准",
  "short_summary": "提出新基准RBench-V，用于评估多模态模型的视觉不可或缺的推理能力。",
  "summary": "本文介绍了一个名为RBench-V的新基准，旨在评估多模态模型的视觉不可或缺的推理能力。RBench-V包含803道涉及数学、物理、计数和游戏的问题，这些问题围绕多模态输出构建，需要生成新图像或构造辅助线等图像操作来支持推理过程。通过对开源和闭源模型（如o3、Gemini 2.5 Pro、Qwen2.5-VL等）的评估显示，即使表现最好的o3模型在RBench-V上的准确率仅为25.8%，远低于人类的82.3%得分，这表明当前模型在利用多模态推理方面仍存在显著不足。相关数据和代码可在https:
  "keyword": ["多模态模型", "视觉推理", "RBench-V"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 265 (char 366). Line: 406.
Append: [RBench-V: A Primary Assessment for Visual Reasoning Models with Multi-modal Outputs](https://arxiv.org/abs/2505.16770)
Token length: 1617
Summarized using qwen-turbo
Append: [ClearNight：多天气夜间图像复原框架](https://arxiv.org/abs/2505.16479)
Token length: 1124
Summarized using qwen-turbo
Append: [Notes Writing提升多跳问答中的迭代RAG性能](https://arxiv.org/abs/2505.16293)
Json decode failed:
{
  "title": "混合专家模型中局部路由一致性度量及其优化研究",
  "short_summary": "研究提出两种度量方法评估混合专家模型的局部路由一致性。",
  "summary": "本文探讨了如何在内存受限设备上高效部署大规模混合专家模型（MoE）。尽管已有研究利用了专家激活的空间局部性，但这种局部路由一致性在不同模型中的程度尚未充分研究。为此，我们提出了两个度量指标：段路由最佳性能（SRP）和段缓存最佳命中率（SCH），用于量化MoE模型的局部路由一致性。通过对20个具有不同规模和架构的MoE语言模型进行分析，发现逐层应用MoE且不使用共享专家的模型表现出最高的局部路由一致性。此外，领域专用专家比词汇专用专家对路由一致性贡献更大，大多数模型在缓存大小约为活跃专家数量两倍时可以平衡缓存效果与效率。这些发现为设计和部署内存高效的MoE模型提供了方向。实验代码已公开于https:
  "keyword": ["混合专家模型", "局部路由一致性", "内存优化"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 317 (char 405). Line: 406.
Append: [Not All Models Suit Expert Offloading: On Local Routing Consistency of Mixture-of-Expert Models](https://arxiv.org/abs/2505.16056)
Token length: 1115
Summarized using qwen-turbo
Append: [NOVER：无需外部验证器的强化学习框架](https://arxiv.org/abs/2505.16022)
Token length: 1441
Summarized using qwen-turbo
Append: [PhyX：首个大规模物理推理视觉场景基准测试](https://arxiv.org/abs/2505.15929)
Token length: 1406
Summarized using qwen-turbo
Append: [大规模语言模型在敏感领域的上下文安全保护研究](https://arxiv.org/abs/2505.15805)
Token length: 1195
Summarized using qwen-turbo
Append: [TIME：面向现实世界场景的大规模多层级时序推理基准](https://arxiv.org/abs/2505.12891)
Token length: 1316
Summarized using qwen-turbo
Append: [基于合成数据的强化学习方法提升大模型性能](https://arxiv.org/abs/2505.17063)
Token length: 1034
Summarized using qwen-turbo
Append: [引入正交残差更新以提升深度神经网络的特征学习能力](https://arxiv.org/abs/2505.11881)
Token length: 1852
Summarized using qwen-turbo
Append: [Time-R1：为大语言模型赋予全面的时间智能](https://arxiv.org/abs/2505.13508)
append_entries: 20
Finish: 2025-05-26 12:30:46.783868
------------------------------------------------------
Started: 2025-05-26 18:19:32.718237
Existing_entries: 1020
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1650
Summarized using qwen-turbo
Append: [DanceTogether：多角色交互可控视频生成框架](https://arxiv.org/abs/2505.18078)
Token length: 1566
Summarized using qwen-turbo
Append: [扩散分类器在组合性理解中的能力研究](https://arxiv.org/abs/2505.17955)
Token length: 1526
Summarized using qwen-turbo
Append: [FREESON框架：让大型推理模型自主检索知识](https://arxiv.org/abs/2505.16409)
Token length: 940
Summarized using qwen-turbo
Append: [大型语言模型中的位置偏差及其跨语言特性研究](https://arxiv.org/abs/2505.16134)
Token length: 1092
Summarized using qwen-turbo
Append: [ReflAct：强化LLM代理推理能力的新框架](https://arxiv.org/abs/2505.15182)
Token length: 1576
Summarized using qwen-turbo
Append: [Quartet：一种高效且精确的大语言模型低精度训练方法](https://arxiv.org/abs/2505.14669)
Token length: 1051
Summarized using qwen-turbo
Append: [轻量级模型不可知框架s3提升检索增强生成性能](https://arxiv.org/abs/2505.14146)
append_entries: 7
Finish: 2025-05-26 18:20:11.313200
------------------------------------------------------
Started: 2025-05-27 01:09:58.953919
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1495
Summarized using qwen-turbo
Append: [RankNovo：基于深度重排序框架的全新从头肽段测序方法](https://arxiv.org/abs/2505.17552)
Token length: 1058
Summarized using qwen-turbo
Append: [基于长上下文推理轨迹的高效价值模型训练方法](https://arxiv.org/abs/2505.17373)
Token length: 1244
Summarized using qwen-turbo
Append: [ScanBot：面向高精度表面扫描的指令条件机器人学习数据集](https://arxiv.org/abs/2505.17295)
Token length: 892
Summarized using qwen-turbo
Append: [基于稀疏大语言模型的中文多语言机器翻译系统FuxiMT](https://arxiv.org/abs/2505.14256)
append_entries: 4
Finish: 2025-05-27 01:10:23.603120
------------------------------------------------------
Started: 2025-05-27 06:21:14.916899
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1395
Summarized using qwen-turbo
Append: [面向低资源语言的文化适配大型语言模型研究](https://arxiv.org/abs/2505.18383)
append_entries: 1
Finish: 2025-05-27 06:21:21.760264
------------------------------------------------------
Started: 2025-05-27 12:30:14.020079
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 991
Summarized using qwen-turbo
Append: [GLEAM-Bench与GLEAM：提升移动机器人在复杂未知环境中的主动映射能力](https://arxiv.org/abs/2505.20294)
Token length: 1720
Summarized using qwen-turbo
Append: [基于覆盖原则的大规模语言模型系统性组合泛化能力分析](https://arxiv.org/abs/2505.20278)
Token length: 1267
Summarized using qwen-turbo
Append: [面向未知攻击的终身安全对齐框架](https://arxiv.org/abs/2505.20259)
Token length: 1645
Summarized using qwen-turbo
Append: [自适应推理模型（ARM）解决“过度思考”问题](https://arxiv.org/abs/2505.20258)
Token length: 1487
Summarized using qwen-turbo
Append: [Omni-R1：基于强化学习的多模态全局推理与细节理解模型](https://arxiv.org/abs/2505.20256)
Token length: 1351
Summarized using qwen-turbo
Append: [稀疏自编码器特征一致性对神经网络可解释性研究的重要性](https://arxiv.org/abs/2505.20254)
Token length: 1500
Summarized using qwen-turbo
Append: [基于硬负样本对比学习的大规模多模态模型在几何推理中的应用](https://arxiv.org/abs/2505.20152)
Token length: 1095
Summarized using qwen-turbo
Append: [StructEval：评估大型语言模型结构化输出能力的新基准](https://arxiv.org/abs/2505.20139)
Token length: 1514
Summarized using qwen-turbo
Append: [MLR-Bench：评估AI研究代理能力的综合基准](https://arxiv.org/abs/2505.19955)
Token length: 1456
Summarized using qwen-turbo
Append: [基于影响函数的大语言模型推理能力归因研究](https://arxiv.org/abs/2505.19949)
Json decode failed:
{
  "title": "Enigmata：提升大型语言模型逻辑推理能力的综合框架",
  "short_summary": "提出Enigmata框架，通过多任务强化学习显著提升大模型的逻辑推理能力。",
  "summary": "本文介绍Enigmata，首个专注于提升大型语言模型（LLMs）逻辑推理能力的综合性框架。该框架包含7大类共36项任务，每项任务均配备生成器和基于规则的验证器，支持自动评估和灵活的强化学习训练。研究进一步开发了Enigmata-Eval基准测试，并优化了多任务强化学习策略。实验表明，基于Enigmata训练的Qwen2.5-32B-Enigmata模型在多种逻辑推理和数学问题解决任务上表现优于o3-mini-high和o1。此外，当结合更大规模的Seed1.5-Thinking模型时，Enigmata数据显著提升了高级数学和STEM推理任务的表现，展现了良好的泛化能力。这项工作为逻辑推理能力的系统性提升提供了统一框架，相关资源可在https:
  "keyword": ["逻辑推理", "大型语言模型", "强化学习"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 340 (char 444). Line: 406.
Append: [Enigmata: Scaling Logical Reasoning in Large Language Models with Synthetic Verifiable Puzzles](https://arxiv.org/abs/2505.19914)
Token length: 1067
Summarized using qwen-turbo
Append: [基于元学习视角的大语言模型推理能力研究](https://arxiv.org/abs/2505.19815)
Json decode failed:
{
  "title": "MOLE框架：利用大语言模型自动化提取多语言科研论文元数据",
  "short_summary": "本文提出MOLE框架，通过大语言模型自动提取多语言科研论文元数据。",
  "summary": "元数据提取对数据集的编目和保存至关重要，特别是在科学研究呈指数增长的情况下。虽然Masader框架为阿拉伯自然语言处理数据集的学术文章提供了元数据属性提取的基础，但依赖大量人工标注。本研究介绍了一个名为MOLE的新框架，它利用大型语言模型（LLMs）自动提取非阿拉伯语数据集相关论文的元数据属性。MOLE采用基于模式的方法，能够处理多种输入格式的整篇文档，并集成强大的验证机制以保证输出一致性。此外，我们还引入了一个新的基准来评估该任务的研究进展。通过分析上下文长度、少量学习和网页浏览集成，我们展示了现代LLMs在自动化此任务中的潜力，同时强调了未来工作改进的必要性以确保性能的一致性和可靠性。代码和数据集已公开供研究社区使用：https:
  "keyword": ["元数据提取", "大型语言模型", "科研论文"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 336 (char 437). Line: 406.
Append: [MOLE: Metadata Extraction and Validation in Scientific Papers Using LLMs](https://arxiv.org/abs/2505.19800)
Token length: 1873
Summarized using qwen-turbo
Append: [基于多轮分解的大型推理模型高效推理方法](https://arxiv.org/abs/2505.19788)
Token length: 1243
Summarized using qwen-turbo
Append: [离散马尔可夫桥：一种新型的离散表示学习框架](https://arxiv.org/abs/2505.19752)
Token length: 1523
Summarized using qwen-turbo
Append: [基于纳什均衡的人类反馈强化学习算法及其在线实现](https://arxiv.org/abs/2505.19731)
Token length: 1205
Summarized using qwen-turbo
Append: [PathFinder-PRM：一种基于分层错误感知的数学推理奖励模型](https://arxiv.org/abs/2505.19706)
Token length: 1374
Summarized using qwen-turbo
Append: [基于强化学习的多跳推理改进方法](https://arxiv.org/abs/2505.19640)
Token length: 1703
Summarized using qwen-turbo
Append: [基于强化学习的多智能体协作框架提升医学问答系统性能](https://arxiv.org/abs/2505.19630)
Token length: 1431
Summarized using qwen-turbo
Append: [ScaleKV：针对视觉自回归模型的KV缓存压缩框架](https://arxiv.org/abs/2505.19602)
Token length: 1118
Summarized using qwen-turbo
Append: [利用内部反馈信号实现大规模语言模型的无监督强化学习](https://arxiv.org/abs/2505.19590)
Token length: 1822
Summarized using qwen-turbo
Append: [BizFinBench：首个面向金融应用的大语言模型评估基准](https://arxiv.org/abs/2505.19457)
Token length: 1553
Summarized using qwen-turbo
Append: [AI辅助软件开发中的两种新兴范式：氛围编码与自主编码对比分析](https://arxiv.org/abs/2505.19443)
Token length: 1656
Summarized using qwen-turbo
Append: [基于格式与长度代理信号的大规模语言模型数学问题求解训练研究](https://arxiv.org/abs/2505.19439)
Json decode failed:
{
  "title": "WINA：一种高效且无需训练的大语言模型稀疏激活框架",
  "short_summary": "提出WINA框架，通过结合隐藏状态幅值和权重矩阵列范数优化大语言模型推理效率。",
  "summary": "近年来，随着大规模语言模型计算需求的增长，高效的推理和激活策略变得愈发重要。尽管诸如Mixture-of-Experts（MoE）等方法利用选择性激活，但需要专门的训练。相比之下，无需训练的稀疏激活方法因其插拔式设计提供了更广泛的应用场景和更高的资源效率。然而，许多现有方法仅依赖隐藏状态的幅值来决定激活，导致较大的近似误差和次优的推理精度。为此，我们提出了WINA（Weight Informed Neuron Activation），这是一种新颖、简单且无需训练的稀疏激活框架，它同时考虑了隐藏状态幅值和权重矩阵的列范数。研究表明，这种联合策略能够在理论上提供比现有技术更紧致的近似误差界限。实验表明，在相同稀疏度下，WINA在多种大语言模型架构和数据集上的平均性能优于最先进的方法TEAL达2.94%。这些成果使WINA成为大语言模型推理领域新的性能标杆，推动了无需训练的稀疏激活方法的发展，并为高效推理设定了稳健基准。源代码可在https:
  "keyword": ["稀疏激活", "大语言模型", "推理优化"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 439 (char 543). Line: 406.
Append: [WINA: Weight Informed Neuron Activation for Accelerating Large Language Model Inference](https://arxiv.org/abs/2505.19427)
Token length: 1347
Summarized using qwen-turbo
Append: [通过生成模型筛选构建通用文本到图像精调数据集](https://arxiv.org/abs/2505.19297)
Token length: 1229
Summarized using qwen-turbo
Append: [基于过程级自适应推理模式的大语言模型高效推理方法](https://arxiv.org/abs/2505.19250)
Token length: 1312
Summarized using qwen-turbo
Append: [Variance-Reduced Preference Optimization提升掩码扩散模型对齐性能](https://arxiv.org/abs/2505.19223)
Token length: 1826
Summarized using qwen-turbo
Append: [大型语言模型在精细科学假设发现中的应用与优化研究](https://arxiv.org/abs/2505.19209)
Token length: 1675
Summarized using qwen-turbo
Append: [从模型压缩到令牌压缩：AI效率研究的新范式](https://arxiv.org/abs/2505.19147)
Append: [Jodi: Unification of Visual Generation and Understanding via Joint Modeling](https://arxiv.org/abs/2505.19084)
Append: [An Embarrassingly Simple Defense Against LLM Abliteration Attacks](https://arxiv.org/abs/2505.19056)
Append: [AdaCtrl: Towards Adaptive and Controllable Reasoning via Difficulty-Aware Budgeting](https://arxiv.org/abs/2505.18822)
Append: [Strong Membership Inference Attacks on Massive Datasets and (Moderately) Large Language Models](https://arxiv.org/abs/2505.18773)
Append: [The Quest for Efficient Reasoning: A Data-Centric Benchmark to CoT Distillation](https://arxiv.org/abs/2505.18759)
Append: [Can MLLMs Guide Me Home? A Benchmark Study on Fine-Grained Visual Reasoning from Transit Maps](https://arxiv.org/abs/2505.18675)
Append: [Flex-Judge: Think Once, Judge Anywhere](https://arxiv.org/abs/2505.18601)
Append: [B-score: Detecting biases in large language models using response history](https://arxiv.org/abs/2505.18545)
Append: [Reinforcement Fine-Tuning Powers Reasoning Capability of Multimodal Large Language Models](https://arxiv.org/abs/2505.18536)
Append: [Dynamic Risk Assessments for Offensive Cybersecurity Agents](https://arxiv.org/abs/2505.18384)
Append: [Architectural Backdoors for Within-Batch Data Stealing and Model Inference Manipulation](https://arxiv.org/abs/2505.18323)
Append: [Mutarjim: Advancing Bidirectional Arabic-English Translation with a Small Language Model](https://arxiv.org/abs/2505.17894)
Append: [Rethinking the Sampling Criteria in Reinforcement Learning for LLM Reasoning: A Competence-Difficulty Alignment Perspective](https://arxiv.org/abs/2505.17652)
Append: [From Tens of Hours to Tens of Thousands: Scaling Back-Translation for Speech Recognition](https://arxiv.org/abs/2505.16972)
Append: [Embodied Agents Meet Personalization: Exploring Memory Utilization for Personalized Assistance](https://arxiv.org/abs/2505.16348)
Append: [EquivPruner: Boosting Efficiency and Quality in LLM-Based Search via Action Pruning](https://arxiv.org/abs/2505.16312)
Append: [Towards Holistic Evaluation of Large Audio-Language Models: A Comprehensive Survey](https://arxiv.org/abs/2505.15957)
Append: [G1: Bootstrapping Perception and Reasoning Abilities of Vision-Language Model via Reinforcement Learning](https://arxiv.org/abs/2505.13426)
Append: [InfantAgent-Next: A Multimodal Generalist Agent for Automated Computer Interaction](https://arxiv.org/abs/2505.10887)
append_entries: 49
Finish: 2025-05-27 12:33:04.975913
------------------------------------------------------
Started: 2025-05-27 18:19:39.609757
Existing_entries: 1049
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
    "title": "TAGS：一种无需微调的医疗推理测试时框架",
    "short_summary": "结合广义模型与专科模型，TAGS显著提升了多个医疗问答基准的表现。",
    "summary": "近期如Chain-of-Thought提示等进展虽显著改善了大型语言模型（LLMs）的零样本医学推理能力，但基于提示的方法通常较浅显且不稳定，而经过微调的医学LLMs则在分布偏移下泛化性能差且对未知临床场景适应性有限。为此，我们提出了TAGS框架，该框架通过结合广义模型和领域专用模型提供互补视角，无需任何模型微调或参数更新。为支持这一广义-专科推理过程，我们引入了两个辅助模块：基于语义和理由级相似性的分层检索机制，以及评估推理一致性的可靠性评分器。TAGS在九个MedQA基准测试中表现出色，将GPT-4o的准确率提高了13.8%，DeepSeek-R1提高了16.8%，并将一个原始7B模型的准确率从14.1%提升至23.9%，超过了多个经过微调的医学LLMs。这些成果在不进行任何参数更新的情况下实现，代码将在https:
    "keyword": ["医疗推理", "大型语言模型", "测试时框架"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 382 (char 479). Line: 406.
Append: [TAGS: A Test-Time Generalist-Specialist Framework with Retrieval-Augmented Reasoning and Verification](https://arxiv.org/abs/2505.18283)
Json decode failed:
{
  "title": "STAR-R1：提升多模态大语言模型空间推理能力的新框架",
  "short_summary": "提出STAR-R1框架，显著提升多模态大语言模型在跨视角视觉推理中的性能。",
  "summary": "本文研究了多模态大型语言模型（MLLMs）在空间推理上的不足，特别是在Transformation-Driven Visual Reasoning（TVR）任务中的表现。传统监督微调（SFT）难以生成连贯的推理路径，而稀疏奖励强化学习（RL）则面临探索效率低和收敛慢的问题。为此，我们提出了STAR-R1框架，结合单阶段RL范式与针对TVR设计的精细奖励机制。STAR-R1通过奖励部分正确性并惩罚过度枚举和被动不作为，实现了高效探索与精确推理。实验结果显示，STAR-R1在所有11项指标上达到最优性能，在跨视角场景中比SFT提升了23%。此外，分析表明STAR-R1表现出类似人类的行为，能够通过比较所有对象来提高空间推理能力。本研究为MLLMs和推理模型的研究提供了重要见解。相关代码、模型权重及数据将在https:
  "keyword": ["多模态大语言模型", "空间推理", "强化学习"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 376 (char 480). Line: 406.
Append: [STAR-R1: Spatial TrAnsformation Reasoning by Reinforcing Multimodal LLMs](https://arxiv.org/abs/2505.15804)
Token length: 1013
Summarized using qwen-turbo
Append: [ModernGBERT：基于德语的透明高性能编码器模型](https://arxiv.org/abs/2505.13136)
Token length: 1497
Summarized using qwen-turbo
Append: [基于选项感知的时间抽象值学习的离线目标条件强化学习](https://arxiv.org/abs/2505.12737)
append_entries: 4
Finish: 2025-05-27 18:20:01.924681
------------------------------------------------------
Started: 2025-05-28 01:11:40.506412
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "EgoZero：利用人类演示实现机器人鲁棒操作策略学习",
  "short_summary": "提出EgoZero系统，仅依赖人类示范数据即可训练机器人执行复杂操作任务。",
  "summary": "尽管通用机器人技术取得了进展，但机器人政策仍远落后于人类的基本能力。本文提出EgoZero系统，该系统通过Project Aria智能眼镜捕捉的人类示范数据，无需任何机器人数据即可学习鲁棒的操作策略。EgoZero实现了从野外第一人称视角人类示范中提取完整可执行动作、将视觉观察压缩为与形态无关的状态表示以及闭环策略学习。在Franka Panda机械手上部署EgoZero策略后，在七个操作任务中展示了零样本迁移能力，成功率高达70%，每个任务的数据收集时间仅为20分钟。实验结果表明，在野外采集的人类数据可以作为现实世界机器人学习的可扩展基础，为机器人提供了丰富多样的自然训练数据来源。代码和视频可在https:
  "keyword": ["机器人学习", "人类示范", "零样本迁移"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 323 (char 426). Line: 406.
Append: [EgoZero: Robot Learning from Smart Glasses](https://arxiv.org/abs/2505.20290)
Json decode failed:
{
  "title": "FLAME-MoE：开源的混合专家模型研究平台",
  "short_summary": "发布FLAME-MoE，开源的Mixture-of-Experts架构研究工具。",
  "summary": "近期大型语言模型如Gemini-1.5、DeepSeek-V3和Llama-4广泛采用混合专家（MoE）架构，但学术界缺乏完全开放的研究平台。本文介绍了FLAME-MoE，一个由七个解码器-only模型组成的开源研究套件，参数范围从38M到1.7B。该架构具有64个专家、top-8门控和2个共享专家，与现代生产级LLMs相似。所有训练数据管道、脚本、日志和检查点均公开可用，以支持可重复实验。在六个评估任务中，FLAME-MoE相较于密集基线模型，在相同计算量下平均准确率提升高达3.4个百分点。通过全训练轨迹透明性，我们初步分析显示，专家逐渐对不同的标记子集进行专业化，共激活矩阵保持稀疏反映专家多样化使用，路由行为在训练早期趋于稳定。所有代码、训练日志和模型检查点均可在https:
  "keyword": ["MoE", "开源", "语言模型"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 359 (char 461). Line: 406.
Append: [FLAME-MoE: A Transparent End-to-End Research Platform for Mixture-of-Experts Language Models](https://arxiv.org/abs/2505.20225)
Token length: 768
Summarized using qwen-turbo
Append: [基于大语言模型的列表式推理重排序代理REARANK](https://arxiv.org/abs/2505.20046)
Token length: 697
Summarized using qwen-turbo
Append: [大型语言模型中可解释分类特征的涌现特性研究](https://arxiv.org/abs/2505.19440)
Token length: 1435
Summarized using qwen-turbo
Append: [MMIG-Bench：多模态图像生成综合基准测试](https://arxiv.org/abs/2505.19415)
Token length: 1920
Summarized using qwen-turbo
Append: [利用物理力作为视频生成控制信号的研究](https://arxiv.org/abs/2505.19386)
Json decode failed:
{
  "title": "基于WHISTRESS的无对齐句重音检测增强语音转录系统",
  "short_summary": "提出一种无需额外输入先验知识的无对齐句重音检测方法WHISTRESS。",
  "summary": "本文介绍了一种名为WHISTRESS的新方法，该方法是一种无对齐的方法，用于通过检测句子重音来增强转录系统。为了支持这一任务，我们提出了TINYSTRESS-15K，这是一个可扩展的合成训练数据集，用于句重音检测任务，它完全由自动化数据集创建过程生成。WHISTRESS在TINYSTRESS-15K上进行训练，并与多个竞争基线进行评估。结果显示，WHISTRESS在不需要任何额外输入先验的情况下优于现有方法，并且即使在合成数据上训练，它在多样化的基准测试中也表现出强大的零样本泛化能力。项目页面可访问https:
  "keyword": ["句重音检测", "语音转录", "无对齐方法"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 273 (char 375). Line: 406.
Append: [WHISTRESS: Enriching Transcriptions with Sentence Stress Detection](https://arxiv.org/abs/2505.19103)
Token length: 1317
Summarized using qwen-turbo
Append: [基于神经物理系统的实时交互流体模拟](https://arxiv.org/abs/2505.18926)
Token length: 1767
Summarized using qwen-turbo
Append: [基于强化学习的混合推理策略优化提升大语言模型的隐式推理能力](https://arxiv.org/abs/2505.18454)
Json decode failed:
{
  "title": "InstructPart：面向任务的物体部件分割新基准",
  "short_summary": "提出新的多模态基准InstructPart，评估视觉语言模型在日常任务中的部件级理解能力。",
  "summary": "大型多模态基础模型在语言和视觉领域取得了显著进展，但许多模型将物体视为不可分割的整体，忽视了构成物体的各个部分及其功能。为了解决这一问题，本文引入了一个名为InstructPart的新基准，该基准包含手工标注的部分分割注释和面向任务的指令，用于评估当前模型在日常情境中理解和执行部件级任务的能力。实验表明，即使是最先进的视觉语言模型，在任务导向型部件分割方面仍然面临挑战。除了基准之外，我们还提出了一种简单的基线方法，通过微调我们的数据集实现了性能的双倍提升。本研究旨在促进任务导向型部件分割的研究，并提高视觉语言模型在机器人、虚拟现实、信息检索等领域的适用性。项目网站：https:
  "keyword": ["多模态模型", "部件分割", "任务导向"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 307 (char 418). Line: 406.
Append: [InstructPart: Task-Oriented Part Segmentation with Instruction Reasoning](https://arxiv.org/abs/2505.18291)
Token length: 1513
Summarized using qwen-turbo
Append: [负反馈驱动的监督学习提升大模型数学推理能力](https://arxiv.org/abs/2505.18116)
Token length: 1167
Summarized using qwen-turbo
Append: [统一微调方法（UFT）提升大语言模型推理能力](https://arxiv.org/abs/2505.16984)
Token length: 1301
Summarized using qwen-turbo
Append: [大型语言模型中基于推理的段落重排序器的表现研究](https://arxiv.org/abs/2505.16886)
append_entries: 13
Finish: 2025-05-28 01:12:52.724284
------------------------------------------------------
Started: 2025-05-28 06:21:44.457881
Existing_entries: 1013
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1912
Summarized using qwen-turbo
Append: [基于多智能体系统的学术海报自动生成方法](https://arxiv.org/abs/2505.21497)
Token length: 793
Summarized using qwen-turbo
Append: [基于帧进出技术的可控视频生成研究](https://arxiv.org/abs/2505.21491)
Token length: 1724
Summarized using qwen-turbo
Append: [基于多模态大语言模型的主动感知能力研究与ACTIVE-O3框架](https://arxiv.org/abs/2505.21457)
Json decode failed:
{
  "title": "Video-Holmes：评估多模态大模型复杂视频推理能力的新基准",
  "short_summary": "提出基于福尔摩斯推理过程设计的Video-Holmes基准，测试多模态大模型复杂视频推理能力。",
  "summary": "近期，连续思维（CoT）推理及强化学习后训练的进步提升了多模态大型语言模型（MLLMs）的视频推理能力。然而，现有视频基准主要评估视觉感知与定位能力，缺乏对人类真实世界复杂推理过程的模拟。针对这一问题，我们提出了Video-Holmes，一个受福尔摩斯推理启发的视频推理基准。该基准包含来自270部悬疑短片的1,837个问题，涵盖七个精心设计的任务，要求模型整合分散在不同视频片段中的多个视觉线索。评估显示，最先进的MLLMs在视觉感知方面表现良好，但在信息整合上存在显著困难，最佳模型Gemini-2.5-Pro的准确率仅为45%。Video-Holmes旨在作为多模态推理的“福尔摩斯测试”，推动模型向更接近人类的推理方式发展，并强调该领域面临的持续挑战。基准代码已开源于https:
  "keyword": ["视频推理", "多模态大模型", "复杂推理"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 359 (char 478). Line: 406.
Append: [Video-Holmes: Can MLLM Think Like Holmes for Complex Video Reasoning?](https://arxiv.org/abs/2505.21374)
Token length: 1629
Summarized using qwen-turbo
Append: [MME-VideoOCR基准评测：视频OCR中的多模态大语言模型挑战](https://arxiv.org/abs/2505.21333)
Token length: 1569
Summarized using qwen-turbo
Append: [MME-Reasoning：评估多模态大型语言模型逻辑推理能力的新基准](https://arxiv.org/abs/2505.21327)
Json decode failed:
{
    "title": "rStar-Coder：通过大规模验证数据集提升大语言模型代码推理能力",
    "short_summary": "构建大规模验证数据集显著提高大语言模型的代码推理能力。",
    "summary": "本文介绍了一种名为rStar-Coder的新方法，该方法通过构建包含41.8万个竞争级代码问题及58万个长推理解决方案的大规模验证数据集，显著提升了大型语言模型（LLMs）的代码推理能力。rStar-Coder的核心贡献包括：从竞赛编程问题中合成新问题、引入可靠输入输出测试用例合成管道以及提供高质量的测试用例验证长推理解决方案。实验表明，在多个代码推理基准测试中，rStar-Coder使Qwen模型的表现超越了许多更大规模的前沿模型。例如，在LiveCodeBench上，Qwen2.5-7B的性能从17.4%提升至57.3%，Qwen2.5-14B从23.3%提升至62.5%。此外，在更具挑战性的USA Computing Olympiad中，7B模型的表现也优于QWQ-32B。相关代码和数据集将在https:
    "keyword": ["大语言模型", "代码推理", "rStar-Coder"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 377 (char 482). Line: 406.
Append: [rStar-Coder: Scaling Competitive Code Reasoning with a Large-Scale Verified Dataset](https://arxiv.org/abs/2505.21297)
Token length: 1778
Summarized using qwen-turbo
Append: [Sci-Fi框架：实现起始帧与结束帧对中间帧的对称约束](https://arxiv.org/abs/2505.21205)
Token length: 1656
Summarized using qwen-turbo
Append: [DualParal：基于扩散变换的分布式视频生成高效策略](https://arxiv.org/abs/2505.21070)
Token length: 1676
Summarized using qwen-turbo
Append: [OpenS2V-Nexus：推动Subject-to-Video生成的研究基础设施](https://arxiv.org/abs/2505.20292)
Token length: 1207
Summarized using qwen-turbo
Append: [VisTA：基于强化学习的视觉工具动态选择框架](https://arxiv.org/abs/2505.20289)
Token length: 1615
Summarized using qwen-turbo
Append: [ImgEdit：面向复杂图像编辑的大规模高质量数据集与模型](https://arxiv.org/abs/2505.20275)
Token length: 1348
Summarized using qwen-turbo
Append: [Granular Low-Rank Adaptation (GraLoRA): 提升参数高效微调性能的新方法](https://arxiv.org/abs/2505.20355)
Token length: 1211
Summarized using qwen-turbo
Append: [SoloSpeech：一种新颖的目标语音提取生成管道](https://arxiv.org/abs/2505.19314)
Token length: 1001
Summarized using qwen-turbo
Append: [SeePhys：基于物理学问题的大规模多模态基准测试](https://arxiv.org/abs/2505.19099)
Token length: 1817
Summarized using qwen-turbo
Append: [基于验证器引导迭代优化的视频大语言模型强化学习方法](https://arxiv.org/abs/2505.19000)
Token length: 1551
Summarized using qwen-turbo
Append: [MetaMind：通过多智能体框架实现类人社会推理](https://arxiv.org/abs/2505.18943)
Token length: 1508
Summarized using qwen-turbo
Append: [SVG2：通过语义感知聚类优化扩散Transformer视频生成效率](https://arxiv.org/abs/2505.18875)
Token length: 1111
Summarized using qwen-turbo
Append: [OmniConsistency：弥合扩散模型风格化一致性差距的通用插件](https://arxiv.org/abs/2505.18445)
Token length: 1124
Summarized using qwen-turbo
Append: [通过Steering Target Atoms实现语言模型精确控制](https://arxiv.org/abs/2505.20322)
Token length: 1581
Summarized using qwen-turbo
Append: [MMMR基准：评估多模态大语言模型的推理能力](https://arxiv.org/abs/2505.16459)
append_entries: 21
Finish: 2025-05-28 06:23:54.553452
------------------------------------------------------
Started: 2025-05-28 12:30:23.969162
Existing_entries: 1021
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1462
Summarized using qwen-turbo
Append: [基于神经元分析的大语言模型多语言对齐研究](https://arxiv.org/abs/2505.21505)
Token length: 1398
Summarized using qwen-turbo
Append: [ViewSpatial-Bench：多视角空间定位评估基准](https://arxiv.org/abs/2505.21500)
Token length: 1471
Summarized using qwen-turbo
Append: [UI-Genie：一种面向GUI代理的自提升框架](https://arxiv.org/abs/2505.21496)
Token length: 1660
Summarized using qwen-turbo
Append: [基于特征最优对齐的多模态大语言模型迁移对抗攻击方法](https://arxiv.org/abs/2505.21494)
Token length: 1400
Summarized using qwen-turbo
Append: [DetailFlow：基于粗到细1D自回归的高效图像生成方法](https://arxiv.org/abs/2505.21473)
Token length: 1741
Summarized using qwen-turbo
Append: [HoliTom：一种高效的视频大语言模型推理优化框架](https://arxiv.org/abs/2505.21334)
Token length: 1350
Summarized using qwen-turbo
Append: [基于贝叶斯自适应框架的反思性探索强化学习算法](https://arxiv.org/abs/2505.20561)
Json decode failed:
{
  "title": "DFIR-Metric：用于评估大语言模型在数字取证中的综合基准",
  "short_summary": "提出DFIR-Metric基准，用于评估大语言模型在数字取证中的性能。",
  "summary": "数字取证与事件响应（DFIR）涉及分析数字证据以支持法律调查。虽然大型语言模型（LLMs）在日志分析和内存取证等任务中提供了新机会，但其易出错和产生幻觉的问题在高风险环境中引发担忧。目前尚无全面基准评估LLMs在理论和实践DFIR领域的表现。为填补这一空白，我们提出了DFIR-Metric，该基准包含三个组成部分：知识评估、现实取证挑战和实际分析案例。通过对14个LLMs的评估，我们分析了它们的准确性和一致性。此外，我们还引入了任务理解评分（TUS），以更有效地评估在接近零准确率场景下的模型表现。此基准为推动人工智能在数字取证领域的发展提供了严格且可重复的基础。所有脚本、工件和结果均可在项目网站https:
  "keyword": ["数字取证", "大语言模型", "DFIR-Metric"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 322 (char 428). Line: 406.
Append: [DFIR-Metric: A Benchmark Dataset for Evaluating Large Language Models in Digital Forensics and Incident Response](https://arxiv.org/abs/2505.19973)
Token length: 1284
Summarized using qwen-turbo
Append: [基于全局绝对关节坐标的文本到运动生成模型](https://arxiv.org/abs/2505.19377)
Token length: 1529
Summarized using qwen-turbo
Append: [ComfyMind：一种协作式通用生成AI系统](https://arxiv.org/abs/2505.17908)
Token length: 1653
Summarized using qwen-turbo
Append: [挑战长推理链假设：高效推理语言模型的新方法](https://arxiv.org/abs/2505.17813)
Token length: 1234
Summarized using qwen-turbo
Append: [基于开放源代码大型语言模型的仓库级软件工程任务研究](https://arxiv.org/abs/2505.16901)
Json decode failed:
{
  "title": "基于共享推理轨迹的多模态大语言模型强化学习方法",
  "short_summary": "提出一种新型强化学习方法Share-GRPO，提升多模态大语言模型的推理能力。",
  "summary": "本文旨在通过强化学习（RL）激励多模态大型语言模型（MLLMs）的推理能力，并开发了一种有效的方法解决稀疏奖励和优势消失问题。为此，我们提出了Share-GRPO，这是一种新颖的RL方法，通过在扩展的问题空间中探索和共享多样化的推理轨迹来解决这些问题。具体而言，Share-GRPO首先利用数据转换技术扩展给定问题的空间，然后鼓励MLLM在扩展的问题空间中有效地探索多样化的推理轨迹，并在RL过程中跨扩展问题共享发现的推理轨迹。此外，Share-GRPO还在优势计算过程中共享奖励信息，允许在问题变体之间分层估计解决方案的优势，从而实现相对优势的更准确估计并提高策略训练的稳定性。广泛的评估显示了我们方法在六个广泛使用的推理基准上的优越性能。代码将在https:
  "keyword": ["多模态大语言模型", "强化学习", "推理能力"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 346 (char 447). Line: 406.
Append: [R1-ShareVL: Incentivizing Reasoning Capability of Multimodal Large Language Models via Share-GRPO](https://arxiv.org/abs/2505.16673)
Token length: 1061
Summarized using qwen-turbo
Append: [CLEANMOL：提升大语言模型解析分子结构能力的新框架](https://arxiv.org/abs/2505.16340)
Token length: 1121
Summarized using qwen-turbo
Append: [AutoRefine：通过强化学习提升大语言模型的推理能力](https://arxiv.org/abs/2505.11277)
append_entries: 15
Finish: 2025-05-28 12:31:51.334216
------------------------------------------------------
Started: 2025-05-28 18:19:27.581780
Existing_entries: 1015
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "AdInject：基于互联网广告注入的视觉语言模型网络代理环境攻击",
  "short_summary": "提出一种利用互联网广告注入恶意内容的新攻击方法AdInject。",
  "summary": "本文研究了基于视觉语言模型的网络代理在开放网络环境中面临的安全漏洞问题。传统对抗性环境注入攻击往往基于不切实际的假设，如直接HTML篡改或访问代理模型参数等，限制了其实用性。为解决这一问题，我们提出了AdInject，这是一种新型且真实的黑盒攻击方法，通过互联网广告传递在Web代理环境中注入恶意内容。AdInject采用更为现实的威胁模型，无需了解用户意图或代理模型参数，同时结合视觉语言模型优化恶意广告内容，使其更具迷惑性。实验结果显示，AdInject在多数场景下的攻击成功率超过60%，某些情况下接近100%，表明广告投放是网络代理环境注入攻击的有效途径。本研究揭示了网络代理安全中的关键漏洞，并强调了开发有效防御机制的重要性。代码已公开于https:
  "keyword": ["视觉语言模型", "网络代理", "广告注入"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 345 (char 449). Line: 406.
Append: [AdInject: Real-World Black-Box Attacks on Web Agents via Advertising Delivery](https://arxiv.org/abs/2505.21499)
Token length: 1442
Summarized using qwen-turbo
Append: [ExtAgents：一种多智能体框架提升大语言模型推理能力](https://arxiv.org/abs/2505.21471)
Token length: 901
Summarized using qwen-turbo
Append: [冻结的大语言模型通过两个嵌入实现多令牌生成](https://arxiv.org/abs/2505.21189)
Token length: 1483
Summarized using qwen-turbo
Append: [ConciseR：通过强化学习实现大型语言模型的简洁推理](https://arxiv.org/abs/2505.21178)
Token length: 1548
Summarized using qwen-turbo
Append: [Alita：通过极简预定义与最大化自演化实现通用智能代理](https://arxiv.org/abs/2505.20286)
Token length: 1163
Summarized using qwen-turbo
Append: [多任务预训练提升蛋白质语言模型性能](https://arxiv.org/abs/2505.20052)
Token length: 1885
Summarized using qwen-turbo
Append: [基于蛋白质语言模型的蛋白质相互作用亲和力预测架构优化](https://arxiv.org/abs/2505.20036)
Token length: 1764
Summarized using qwen-turbo
Append: [基于深度学习与大语言模型的神经退行性痴呆MRI诊断框架](https://arxiv.org/abs/2505.19954)
Json decode failed:
{
    "title": "UNITE框架：解决多模态信息检索挑战的系统性方法",
    "short_summary": "提出UNITE框架，通过数据整理和模态感知训练提升多模态信息检索性能。",
    "summary": "多模态信息检索(MIR)因数据源异构性和跨模态对齐复杂性而面临挑战。现有研究虽识别了特征空间中的模态差距，但缺乏系统性解决方案。本文引入UNITE框架，通过数据整理和模态感知训练配置应对这些挑战。我们首次全面分析模态特定数据属性对下游任务表现的影响，并提出模态感知掩码对比学习(MAMCL)，缓解不同模态实例间的竞争关系。实验表明，UNITE在多个基准测试中达到最先进水平，大幅超越现有方法。此框架不仅提升了MIR性能，还为未来多模态系统研究提供了基础蓝图。项目地址：https:
    "keyword": ["多模态信息检索", "数据整理", "模态感知训练"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 257 (char 360). Line: 406.
Append: [Modality Curation: Building Universal Embeddings for Advanced Multimodal Information Retrieval](https://arxiv.org/abs/2505.19650)
Token length: 1797
Summarized using qwen-turbo
Append: [SynLogic：通过逻辑推理数据增强大语言模型的泛化能力](https://arxiv.org/abs/2505.19641)
Json decode failed:
{
  "title": "Agent Compression Benchmark (ACBench):评估大语言模型压缩对自主能力的影响",
  "short_summary": "ACBench是首个评估大语言模型压缩对自主能力影响的综合基准。",
  "summary": "现有的大语言模型（LLMs）压缩基准主要关注语言建模和自然语言理解任务，而忽视了模型的自主能力，如工作流生成、工具使用、长上下文理解和实际应用等。本文介绍Agent Compression Benchmark (ACBench)，这是首个全面评估压缩对LLMs自主能力影响的基准。ACBench涵盖12项任务，涉及四种能力，包括量化（如GPTQ、AWQ）和剪枝（如Wanda、SparseGPT），并测试了15种模型，从小型到标准再到精馏推理模型。实验表明，4位量化在保持工作流生成和工具使用性能的同时，降低了真实世界应用的准确性。我们还引入了ERank、Top-k排名相关性和能耗等指标进行系统分析。ACBench为优化具有自主能力的大语言模型的压缩提供了实用见解。代码可在https:
  "keyword": ["大语言模型", "压缩", "自主能力"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 359 (char 485). Line: 406.
Append: [Can Compressed LLMs Truly Act? An Empirical Evaluation of Agentic Capabilities in LLM Compression](https://arxiv.org/abs/2505.19433)
Token length: 1708
Summarized using qwen-turbo
Append: [多模态大型语言模型中的模态偏差研究](https://arxiv.org/abs/2505.18657)
Token length: 1640
Summarized using qwen-turbo
Append: [AlphaMed：通过强化学习实现大型语言模型的医学推理能力](https://arxiv.org/abs/2505.17952)
Token length: 1226
Summarized using qwen-turbo
Append: [引入热带注意力机制以增强神经算法推理的鲁棒性](https://arxiv.org/abs/2505.17190)
Token length: 1229
Summarized using qwen-turbo
Append: [R1-Searcher++：一种高效的知识增强型大语言模型框架](https://arxiv.org/abs/2505.17005)
Token length: 1137
Summarized using qwen-turbo
Append: [检索增强生成中的位置偏差影响研究](https://arxiv.org/abs/2505.15561)
Token length: 1659
Summarized using qwen-turbo
Append: [NOVA基准测试：评估模型在罕见脑MRI异常检测中的泛化能力](https://arxiv.org/abs/2505.14064)
append_entries: 17
Finish: 2025-05-28 18:20:51.517750
------------------------------------------------------
Started: 2025-05-29 01:11:25.209865
Existing_entries: 1017
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1576
Summarized using qwen-turbo
Append: [Post Hoc Registers：无需重训的视觉Transformer补救方案](https://arxiv.org/abs/2505.21501)
Token length: 1560
Summarized using qwen-turbo
Append: [一种无需验证器的强化学习方法用于大规模语言模型训练](https://arxiv.org/abs/2505.21493)
Token length: 1376
Summarized using qwen-turbo
Append: [基于双重过程理论优化大语言模型推理能力的研究](https://arxiv.org/abs/2505.21097)
Token length: 1488
Summarized using qwen-turbo
Append: [通过渲染反馈强化学习提升可缩放矢量图形生成](https://arxiv.org/abs/2505.20793)
Token length: 1397
Summarized using qwen-turbo
Append: [FinTagging：首个全面的XBRL基准测试评估大型语言模型的财务报告结构化信息提取能力](https://arxiv.org/abs/2505.20650)
Token length: 1421
Summarized using qwen-turbo
Append: [MMPerspective：评估多模态大语言模型透视几何理解能力的新基准](https://arxiv.org/abs/2505.20426)
Token length: 1716
Summarized using qwen-turbo
Append: [MotionPro：用于精确图像到视频运动控制的新型生成模型](https://arxiv.org/abs/2505.20287)
Token length: 1619
Summarized using qwen-turbo
Append: [VLM-3R：一种基于视觉语言模型的统一三维重建框架](https://arxiv.org/abs/2505.20279)
Token length: 1356
Summarized using qwen-turbo
Append: [大型语言模型红队测试中的能力差距研究](https://arxiv.org/abs/2505.20162)
Token length: 1664
Summarized using qwen-turbo
Append: [ScienceBoard：助力科学发现的大语言模型综合评估平台](https://arxiv.org/abs/2505.19897)
Token length: 1425
Summarized using qwen-turbo
Append: [CoreMatching：融合Token稀疏性和Neuron稀疏性的视觉语言模型高效推理框架](https://arxiv.org/abs/2505.19235)
Json decode failed:
{
  "title": "SATORI：通过强化学习优化视觉问答任务中的空间锚定推理",
  "short_summary": "提出SATORI方法，通过分解VQA任务提升多模态推理性能。",
  "summary": "本文针对视觉问答（VQA）任务中基于强化学习（RL）的自由形式推理存在的两个主要局限性进行了改进。这些局限性包括推理链条扩散导致视觉焦点偏离关键区域，以及不可验证的中间步骤增加策略梯度方差和计算开销。为解决这些问题，我们引入了SATORI（Spatially Anchored Task Optimization with Reinforcement Learning），它将VQA分解为三个可验证阶段：全局图像描述、区域定位和答案预测，每个阶段提供明确的奖励信号。此外，我们还构建了一个包含12k样本的VQA-Verify数据集，用于辅助训练。实验结果显示，SATORI在七个VQA基准测试上均表现出一致的性能提升，在某些情况下比R1类基线提高了15.7%的准确性。注意力图的分析进一步证实了对关键区域的关注增强，从而带来了更高的准确性。我们的代码已公开在https:
  "keyword": ["视觉问答", "强化学习", "多模态推理"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 400 (char 498). Line: 406.
Append: [SATORI-R1: Incentivizing Multimodal Reasoning with Spatial Grounding and Verifiable Rewards](https://arxiv.org/abs/2505.19094)
Token length: 1250
Summarized using qwen-turbo
Append: [Guided by Gut：高效自引导测试时扩展框架提升大语言模型推理能力](https://arxiv.org/abs/2505.20325)
Token length: 1514
Summarized using qwen-turbo
Append: [BiomedSQL：评估科学推理的文本转SQL基准](https://arxiv.org/abs/2505.20321)
Token length: 1550
Summarized using qwen-turbo
Append: [VideoGameBench：评估视觉语言模型的人类技能](https://arxiv.org/abs/2505.18134)
Token length: 1571
Summarized using qwen-turbo
Append: [CLUE：一种基于冲突与共识的语言模型不确定性解释框架](https://arxiv.org/abs/2505.17855)
Token length: 1814
Summarized using qwen-turbo
Append: [PreMoe：高效部署大规模Mixture-of-Experts模型的新框架](https://arxiv.org/abs/2505.17639)
Token length: 1357
Summarized using qwen-turbo
Append: [MMMG：面向多模态生成的人类对齐基准测试](https://arxiv.org/abs/2505.17613)
Token length: 1187
Summarized using qwen-turbo
Append: [SweEval：评估大语言模型在企业场景中的伦理对齐性](https://arxiv.org/abs/2505.17332)
append_entries: 19
Finish: 2025-05-29 01:13:04.133852
------------------------------------------------------
Started: 2025-05-29 06:21:58.824688
Existing_entries: 1019
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "构建端到端自主信息检索代理的系统性框架",
  "short_summary": "提出一种基于数据驱动的多阶段训练方法，提升自主信息检索模型性能。",
  "summary": "本文介绍了一种从数据视角和训练阶段出发构建端到端自主信息检索代理的综合性范式。该方法包含浏览数据构建、轨迹采样、监督微调以及强化学习四个关键阶段，并通过基于ReAct的WebDancer网络代理实例化此框架。在GAIA和WebWalkerQA等复杂信息检索基准测试中，WebDancer展示了显著性能，验证了所提训练方法的有效性。此外，分析代理训练过程还提供了开发更强大自主模型的实用路径。相关代码和演示将在https:
  "keyword": ["自主信息检索", "多阶段训练", "WebDancer"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 225 (char 315). Line: 406.
Append: [WebDancer: Towards Autonomous Information Seeking Agency](https://arxiv.org/abs/2505.22648)
Token length: 1869
Summarized using qwen-turbo
Append: [大型语言模型在简体与繁体中文表现差异的研究](https://arxiv.org/abs/2505.22645)
Token length: 1826
Summarized using qwen-turbo
Append: [克服强化学习中大规模语言模型推理障碍：熵管理的重要性](https://arxiv.org/abs/2505.22617)
Token length: 1232
Summarized using qwen-turbo
Append: [通过视觉重建优化图像描述生成的RICO框架](https://arxiv.org/abs/2505.22613)
Json decode failed:
{
  "title": "通过生成图像进行思考：大模型视觉推理的新范式",
  "short_summary": "提出一种新范式，使大模型可通过生成中间视觉步骤实现跨模态思考。",
  "summary": "本文介绍了一种名为“通过生成图像进行思考”的新范式，该范式改变了大型多模态模型处理视觉推理的方式，使其能够在文本和视觉模态之间自然转换，并通过自发生成中间视觉思考步骤来增强认知能力。传统方法局限于固定用户提供的图像或仅依赖文本式链式思维（CoT），而新范式允许模型主动构建中间视觉想法、自我批评并优化其视觉假设。实验展示了两种互补机制的有效性：一是分解复杂视觉任务为目标导向的生成与整合；二是基于自我批评生成并改进初始视觉假设。这种方法在多个视觉生成基准测试中表现优异，相对提升了50%的性能，特别是在复杂多对象场景中的表现显著提高。未来，这种能力将广泛应用于生物化学家探索蛋白质结构、建筑师设计空间布局、法医分析犯罪现场及篮球运动员制定策略等领域。该项目已开源，代码地址为https:
  "keyword": ["视觉推理", "大模型", "生成图像"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 358 (char 450). Line: 406.
Append: [Thinking with Generated Images](https://arxiv.org/abs/2505.22525)
Token length: 1783
Summarized using qwen-turbo
Append: [ART+: 开创多层透明图像生成的新篇章](https://arxiv.org/abs/2505.22523)
Token length: 1549
Summarized using qwen-turbo
Append: [基于GRPO的无监督多模态大语言模型后训练框架MM-UPT](https://arxiv.org/abs/2505.22453)
Token length: 1551
Summarized using qwen-turbo
Append: [Text2Grad：基于文本反馈的细粒度强化学习优化](https://arxiv.org/abs/2505.22338)
Token length: 1488
Summarized using qwen-turbo
Append: [基于冷启动的强化学习提升多模态推理能力研究](https://arxiv.org/abs/2505.22334)
Token length: 1297
Summarized using qwen-turbo
Append: [Skywork-OR1：通过强化学习提升长链推理能力](https://arxiv.org/abs/2505.22312)
Token length: 1018
Summarized using qwen-turbo
Append: [RenderFormer：基于Transformer的神经渲染方法](https://arxiv.org/abs/2505.21925)
Token length: 1914
Summarized using qwen-turbo
Append: [EPiC：一种高效精确的视频扩散模型相机控制框架](https://arxiv.org/abs/2505.21876)
Token length: 1436
Summarized using qwen-turbo
Append: [Roads to Rome：高效结合大语言模型与小语言模型的方法](https://arxiv.org/abs/2505.21600)
Json decode failed:
{
  "title": "SageAttention2++：基于FP8矩阵乘法加速的高效注意力机制",
  "short_summary": "SageAttention2++通过FP8矩阵乘法实现3.9倍加速，保持与FlashAttention相当的精度。",
  "summary": "本文介绍了一种名为SageAttention2++的新方法，用于解决传统注意力机制时间复杂度随序列长度呈二次增长的问题。该方法在SageAttention2的基础上进一步优化，通过引入更快的FP8矩阵乘法指令，将计算速度提升至原方法的两倍。实验结果显示，SageAttention2++相比FlashAttention实现了3.9倍的速度提升，同时保持了相同的注意力计算精度。这种方法对多种模型，包括语言、图像和视频生成模型均有效，且对最终性能指标的影响极小。未来，相关代码将在https:
  "keyword": ["注意力机制", "矩阵乘法", "加速算法"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 260 (char 392). Line: 406.
Append: [SageAttention2++: A More Efficient Implementation of SageAttention2](https://arxiv.org/abs/2505.21136)
Json decode failed:
{
  "title": "DeepResearchGym：开源沙盒推动深度研究系统评估",
  "short_summary": "开发开源工具DeepResearchGym解决现有深度研究系统透明性和成本问题。",
  "summary": "深度研究系统是一种新兴的信息检索方法，旨在通过生成详尽报告回应复杂查询。然而，大多数现有框架依赖动态商业搜索API，存在可重复性、透明性挑战及高昂成本问题。为应对这些限制，我们推出了DeepResearchGym，这是一个开源沙盒，结合了可重复搜索API与严谨的评估协议，用于基准测试深度研究系统。该API利用先进的密集检索器和DiskANN技术对大规模公共网络语料库进行索引，与流行商业API相比具有更低延迟，并保证文档排名稳定，免费供研究使用。为了评估深度研究系统的输出，我们通过LLM作为裁判扩展了Researchy Questions基准，增加了自动指标，衡量其与用户信息需求的一致性、检索忠实度及报告质量。实验结果显示，集成DeepResearchGym的系统性能与使用商业API的系统相当，且在不同评估指标下的表现排名一致。此外，人类评估研究进一步验证了我们的自动协议符合人类偏好，证明了框架在支持深度研究系统受控评估方面的有效性。相关代码和API文档可在https:
  "keyword": ["深度研究系统", "开源沙盒", "评估协议"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 455 (char 564). Line: 406.
Append: [DeepResearchGym: A Free, Transparent, and Reproducible Evaluation Sandbox for Deep Research](https://arxiv.org/abs/2505.19253)
Token length: 1723
Summarized using qwen-turbo
Append: [PIR框架优化语言模型推理能力并减少计算开销](https://arxiv.org/abs/2505.19187)
Json decode failed:
{
  "title": "Geo Reason Enhancement Suite：提升视觉语言模型在地理定位中的推理能力",
  "short_summary": "提出Geo Reason Enhancement Suite框架，增强视觉语言模型的地理推理能力。",
  "summary": "本文针对现有视觉语言模型（VLMs）在地理定位（geo-localization）任务中缺乏鲁棒推理机制的问题，提出了一套名为Geo Reason Enhancement (GRE) Suite的新框架。该框架通过引入结构化推理链，显著提升了VLMs在多粒度视觉线索提取和外部世界知识整合方面的性能。GRE Suite包含三个核心部分：高精度的数据集GRE30K、多阶段推理模型GRE，以及综合评估基准GREval-Bench。实验结果显示，GRE在粗粒度（如国家、大陆）和细粒度（如城市、街道）地理定位任务上均优于现有方法，证明了推理增强型VLMs在复杂地理推理中的有效性。代码和数据将在https:
  "keyword": ["地理定位", "视觉语言模型", "推理增强"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 316 (char 452). Line: 406.
Append: [GRE Suite: Geo-localization Inference via Fine-Tuned Vision-Language Models and Enhanced Reasoning Chains](https://arxiv.org/abs/2505.18700)
Token length: 1131
Summarized using qwen-turbo
Append: [DynToM：评估大型语言模型动态心智理论能力的新基准](https://arxiv.org/abs/2505.17663)
Token length: 973
Summarized using qwen-turbo
Append: [构建HuggingKG知识图谱以促进开源机器学习资源管理](https://arxiv.org/abs/2505.17507)
Token length: 1485
Summarized using qwen-turbo
Append: [Safe-Sora：首个嵌入式AI视频生成水印框架](https://arxiv.org/abs/2505.12667)
append_entries: 20
Finish: 2025-05-29 06:23:49.331161
------------------------------------------------------
Started: 2025-05-29 12:29:43.056050
Existing_entries: 1020
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1271
Summarized using qwen-turbo
Append: [Sherlock：通过自纠正提升视觉语言模型推理能力](https://arxiv.org/abs/2505.22651)
Token length: 1306
Summarized using qwen-turbo
Append: [通过未来事件预测提升多模态大模型的时间推理能力](https://arxiv.org/abs/2505.22457)
Token length: 1162
Summarized using qwen-turbo
Append: [JQL：高效构建大规模高质量多语言数据集的方法](https://arxiv.org/abs/2505.22232)
Token length: 1690
Summarized using qwen-turbo
Append: [强化学习中可验证奖励方法的验证器可靠性分析](https://arxiv.org/abs/2505.22203)
Token length: 1689
Summarized using qwen-turbo
Append: [利用预训练语言模型实现抽象结构化推理](https://arxiv.org/abs/2505.22202)
Token length: 1565
Summarized using qwen-turbo
Append: [UniPano: 用于全景图像生成的统一扩散模型适配框架](https://arxiv.org/abs/2505.22129)
Token length: 1897
Summarized using qwen-turbo
Append: [基于强化学习的视觉丰富信息检索与推理框架VRAG-RL](https://arxiv.org/abs/2505.22019)
Token length: 1436
Summarized using qwen-turbo
Append: [时间无关统一编码器TiUE提升文本到图像扩散模型推理效率](https://arxiv.org/abs/2505.21960)
Token length: 999
Summarized using qwen-turbo
Append: [SVRPBench：首个城市规模车辆路径问题高保真随机动态基准](https://arxiv.org/abs/2505.21887)
Token length: 1223
Summarized using qwen-turbo
Append: [大语言模型微调机制解析：基于稀疏组件的功能特性研究](https://arxiv.org/abs/2505.21191)
Token length: 1421
Summarized using qwen-turbo
Append: [高效3D场景风格化方法：基于分离架构与身份损失的快速实现](https://arxiv.org/abs/2505.21060)
Token length: 1427
Summarized using qwen-turbo
Append: [基于代理的智能辅导系统AITEE提升电气工程教育](https://arxiv.org/abs/2505.21582)
Token length: 1094
Summarized using qwen-turbo
Append: [MUSEG：基于强化学习的多片段时间对齐提升视频时间理解](https://arxiv.org/abs/2505.20715)
Token length: 1447
Summarized using qwen-turbo
Append: [基于LLM的软件工程代理训练数据集及无污染基准构建](https://arxiv.org/abs/2505.20411)
Token length: 1713
Summarized using qwen-turbo
Append: [UniR：一种通用且高效的轻量级推理模块](https://arxiv.org/abs/2505.19075)
Token length: 1090
Summarized using qwen-turbo
Append: [Chain-of-Zoom：一种可扩展的单图像超分辨率框架](https://arxiv.org/abs/2505.18600)
Token length: 1441
Summarized using qwen-turbo
Append: [First Finish Search：一种高效的推理时间扩展策略](https://arxiv.org/abs/2505.18149)
Token length: 1112
Summarized using qwen-turbo
Append: [基于免疫原理的生成式AI模型虚假信息防控框架](https://arxiv.org/abs/2505.17870)
Token length: 1699
Summarized using qwen-turbo
Append: [BraInCoRL：利用少量样本预测神经响应的视觉皮层模型](https://arxiv.org/abs/2505.15813)
append_entries: 19
Finish: 2025-05-29 12:31:35.174055
------------------------------------------------------
Started: 2025-05-29 18:20:29.932837
Existing_entries: 1019
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1233
Summarized using qwen-turbo
Append: [通过大规模知识库CHIMERA探索科学创新中的概念重组](https://arxiv.org/abs/2505.20779)
Token length: 1100
Summarized using qwen-turbo
Append: [基于多模态漫画理解的基准与模型开发](https://arxiv.org/abs/2505.20298)
Token length: 1196
Summarized using qwen-turbo
Append: [Influence Distillation: 优化大型语言模型训练的数据选择框架](https://arxiv.org/abs/2505.19051)
append_entries: 3
Finish: 2025-05-29 18:20:48.441156
------------------------------------------------------
Started: 2025-05-30 01:09:35.155143
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 982
Summarized using qwen-turbo
Append: [零样本嫁接技术降低视觉语言模型训练成本](https://arxiv.org/abs/2505.22664)
Token length: 788
Summarized using qwen-turbo
Append: [FastTD3：加速人形机器人强化学习训练的高效算法](https://arxiv.org/abs/2505.22642)
Token length: 1275
Summarized using qwen-turbo
Append: [PISCES：一种精确擦除语言模型概念知识的新框架](https://arxiv.org/abs/2505.22586)
Token length: 1389
Summarized using qwen-turbo
Append: [HLIP：一种针对3D医学影像的语言-图像预训练框架](https://arxiv.org/abs/2505.21862)
Token length: 1792
Summarized using qwen-turbo
Append: [DORI基准测试：多模态系统物体方向感知能力评估](https://arxiv.org/abs/2505.21649)
Json decode failed:
{
    "title": "Prot2Token：统一框架推动蛋白质预测模型的高效多任务学习",
    "short_summary": "Prot2Token将多种蛋白质预测任务转化为标准化的下一步令牌预测格式，显著提升效率。",
    "summary": "本文介绍了一种名为Prot2Token的统一框架，通过将广泛的蛋白质相关预测任务（如序列属性、残基特性及蛋白间相互作用等）转换为标准的下一步令牌预测格式，解决了传统蛋白质语言模型（PLMs）因任务专业化而导致的计算效率低下的问题。Prot2Token的核心是一个条件化的自回归解码器，结合预训练的蛋白编码器嵌入和可学习的任务令牌，实现多样化预测。该架构支持多任务学习，在多项基准测试中表现出色，速度比AlphaFold2快近1000倍，并且性能通常优于专门化方法。此外，我们还提出了一种辅助的自监督解码器预训练方法，以提高空间敏感任务的表现。Prot2Token标志着向高通量蛋白质建模范式迈进的重要一步，有望加速生物发现和新型疗法的发展。代码已开源于https:
    "keyword": ["蛋白质预测", "多任务学习", "Prot2Token"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 349 (char 468). Line: 406.
Append: [Prot2Token: A Unified Framework for Protein Modeling via Next-Token Prediction](https://arxiv.org/abs/2505.20589)
Token length: 1485
Summarized using qwen-turbo
Append: [HoPE：提升视觉语言模型长上下文能力的混合位置嵌入方法](https://arxiv.org/abs/2505.20444)
Token length: 1449
Summarized using qwen-turbo
Append: [大型语言模型在真实文本因果推理中的挑战](https://arxiv.org/abs/2505.18931)
Token length: 1524
Summarized using qwen-turbo
Append: [个性化安全评估：大语言模型的安全性改进](https://arxiv.org/abs/2505.18882)
Token length: 1152
Summarized using qwen-turbo
Append: [面向企业专用领域的可扩展硬负采样框架](https://arxiv.org/abs/2505.18366)
Token length: 1661
Summarized using qwen-turbo
Append: [Transformer架构中的Token缩减：超越效率导向的潜力](https://arxiv.org/abs/2505.18227)
Token length: 1076
Summarized using qwen-turbo
Append: [Few Shot Domain Adapting Graph：高效文档理解模型](https://arxiv.org/abs/2505.17330)
Token length: 1326
Summarized using qwen-turbo
Append: [强化学习提升大语言模型多轮推理能力的研究](https://arxiv.org/abs/2505.11821)
append_entries: 13
Finish: 2025-05-30 01:10:47.386608
------------------------------------------------------
Started: 2025-05-30 06:21:20.880663
Existing_entries: 1013
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1881
Summarized using qwen-turbo
Append: [IQBench：评估视觉语言模型在人类智商测试中的推理能力](https://arxiv.org/abs/2505.12000)
append_entries: 1
Finish: 2025-05-30 06:21:30.146607
------------------------------------------------------
Started: 2025-05-30 12:29:16.547872
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1244
Summarized using qwen-turbo
Append: [ZeroGUI：无需人工成本的图形用户界面自动化训练框架](https://arxiv.org/abs/2505.23762)
Token length: 1911
Summarized using qwen-turbo
Append: [基于差分信息分布的直接偏好优化理论分析](https://arxiv.org/abs/2505.23761)
Token length: 1014
Summarized using qwen-turbo
Append: [LoRAShop：基于LoRA的多概念图像编辑框架](https://arxiv.org/abs/2505.23758)
Token length: 1511
Summarized using qwen-turbo
Append: [DeepTheorem：利用自然语言增强大语言模型数学推理能力的综合框架](https://arxiv.org/abs/2505.23754)
Token length: 1707
Summarized using qwen-turbo
Append: [基于2D观测的空间多模态大语言模型](https://arxiv.org/abs/2505.23747)
Json decode failed:
{
  "title": "TrustVLM：无需训练的视觉-语言模型预测可靠性评估框架",
  "short_summary": "提出TrustVLM框架提升视觉-语言模型在安全关键领域的预测可靠性。",
  "summary": "视觉-语言模型（VLMs）在多模态理解和生成任务中表现出色，但在零样本和迁移学习场景下容易误分类，存在潜在风险。本文介绍了一种名为TrustVLM的训练-free框架，通过利用图像嵌入空间中的概念差异性，设计了一种新的置信度评分函数，显著提升了误分类检测性能。在17个数据集上验证显示，相较于现有方法，AURC提升了51.87%，AUROC提升了9.14%，FPR95提升了32.42%。该方法无需重新训练即可增强模型可靠性，为VLM在实际应用中的安全部署提供了新途径。代码将在https:
  "keyword": ["视觉-语言模型", "误分类检测", "置信度评分"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 260 (char 364). Line: 406.
Append: [To Trust Or Not To Trust Your Vision-Language Model's Prediction](https://arxiv.org/abs/2505.23745)
Token length: 1483
Summarized using qwen-turbo
Append: [MAGREF：基于掩码引导的任意参考多主体视频生成框架](https://arxiv.org/abs/2505.23742)
Token length: 1751
Summarized using qwen-turbo
Append: [ATLAS：一种高效的长时记忆模块增强Transformer模型](https://arxiv.org/abs/2505.23735)
Json decode failed:
{
  "title": "AnySplat：一种无需标定图像集合的新视角合成网络",
  "short_summary": "AnySplat通过单次前馈预测场景几何、外观及相机内外参，实现实时新视角合成。",
  "summary": "本文介绍了一种名为AnySplat的前馈网络，用于从未标定图像集合中进行新视角合成。与传统需要已知相机姿态和场景特定优化的神经渲染管道不同，AnySplat在单一前馈过程中生成一组3D高斯基元，编码场景几何与外观，同时预测每张输入图像对应的相机内参和外参。这种方法不受密集视图计算负担的影响，可轻松扩展到随意捕捉的多视图数据集，无需任何姿态标注。在零样本评估中，AnySplat在稀疏和密集视图场景中均达到了姿态感知基线的质量，同时超越现有的无姿态方法，并显著降低了基于优化的神经场的渲染延迟，使非约束采集设置下的实时新视角合成成为可能。项目页面：https:
  "keyword": ["新视角合成", "前馈网络", "无姿态"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 295 (char 401). Line: 406.
Append: [AnySplat: Feed-forward 3D Gaussian Splatting from Unconstrained Views](https://arxiv.org/abs/2505.23716)
Token length: 1073
Summarized using qwen-turbo
Append: [提出新基准VF-Eval评估多模态大语言模型在AI生成内容视频中的能力](https://arxiv.org/abs/2505.23693)
Token length: 1538
Summarized using qwen-turbo
Append: [Diffusion via Autoregressive模型：一种新的图像扩散建模范式](https://arxiv.org/abs/2505.23660)
Token length: 1825
Summarized using qwen-turbo
Append: [大型推理模型中的幻觉现象研究](https://arxiv.org/abs/2505.23646)
Token length: 1314
Summarized using qwen-turbo
Append: [基于文本引导扩散模型的零样本音频源分离方法](https://arxiv.org/abs/2505.23625)
Token length: 1147
Summarized using qwen-turbo
Append: [推理时扩展的表格推理研究：基于蒸馏与可验证奖励强化学习的方法](https://arxiv.org/abs/2505.23621)
Token length: 1130
Summarized using qwen-turbo
Append: [Muddit：基于离散扩散的统一文本图像生成模型](https://arxiv.org/abs/2505.23606)
Token length: 1574
Summarized using qwen-turbo
Append: [EvoScale：通过进化提升小规模语言模型在软件工程任务中的性能](https://arxiv.org/abs/2505.23604)
Token length: 1279
Summarized using qwen-turbo
Append: [基于最优奖励基准的对策略强化学习算法](https://arxiv.org/abs/2505.23585)
Token length: 1572
Summarized using qwen-turbo
Append: [SafeScientist：强化AI科学家框架的安全性与伦理责任](https://arxiv.org/abs/2505.23559)
Token length: 1683
Summarized using qwen-turbo
Append: [SWE-bench-Live：面向动态软件修复的大规模可更新基准](https://arxiv.org/abs/2505.23419)
Token length: 1112
Summarized using qwen-turbo
Append: [KVzip：一种高效的Transformer语言模型KV缓存压缩方法](https://arxiv.org/abs/2505.23416)
Json decode failed:
{
  "title": "UniRL：一种无需外部图像数据的自提升多模态后训练方法",
  "short_summary": "UniRL通过模型自身生成图像作为训练数据，同时优化生成和理解任务。",
  "summary": "本文介绍了一种名为UniRL的自提升后训练方法，该方法能够在不依赖任何外部图像数据的情况下，通过模型自身生成图像进行训练。UniRL通过在每轮迭代中生成图像并将其用于训练，实现了生成与理解任务之间的相互增强。此外，我们采用了监督微调（SFT）和组相对策略优化（GRPO）来优化模型。UniRL具有三个主要优势：无需外部图像数据、平衡生成与理解任务性能、仅需少量额外训练步骤。实验表明，在Show-o和Janus模型上，UniRL分别取得了0.77和0.65的GenEval评分。代码和模型将在https:
  "keyword": ["多模态", "后训练", "自提升"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 267 (char 368). Line: 406.
Append: [UniRL: Self-Improving Unified Multimodal Models via Supervised and Reinforcement Learning](https://arxiv.org/abs/2505.23380)
Token length: 1730
Summarized using qwen-turbo
Append: [VideoReasonBench：评估视觉为中心的复杂视频推理能力](https://arxiv.org/abs/2505.23359)
Json decode failed:
{
  "title": "UniTEX：一种基于3D功能空间的高质量纹理生成框架",
  "short_summary": "提出一种新型两阶段3D纹理生成框架UniTEX，解决UV映射的拓扑模糊问题。",
  "summary": "本文介绍了一种名为UniTEX的创新性两阶段3D纹理生成框架，用于为3D资产创建高质量且一致的纹理。现有方法主要依赖于UV映射后的图像修复，这会带来拓扑模糊等挑战。为了解决这一问题，我们提议直接在统一的3D功能空间中操作，绕过UV映射的限制。具体来说，首先通过纹理函数（TFs）将纹理生成提升到3D空间，这是一种连续的体素表示，仅根据表面邻近性映射任意3D点到纹理值，而不依赖网格拓扑。然后，利用基于变压器的大规模纹理模型（LTM）直接从图像和几何输入预测这些TFs。此外，为了进一步提高纹理质量并利用强大的2D先验知识，我们开发了一种先进的LoRA策略，用于高效适配大规模扩散变压器（DiTs），用于高质量多视图纹理合成作为第一阶段。广泛的实验表明，UniTEX在视觉质量和纹理完整性方面优于现有方法，提供了一种可推广且可扩展的自动化3D纹理生成解决方案。代码将在https:
  "keyword": ["3D纹理", "功能空间", "自动化生成"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 404 (char 508). Line: 406.
Append: [UniTEX: Universal High Fidelity Generative Texturing for 3D Shapes](https://arxiv.org/abs/2505.23253)
Token length: 1761
Summarized using qwen-turbo
Append: [引入Theory of Mind增强的说服模型ToMAP](https://arxiv.org/abs/2505.22961)
Token length: 933
Summarized using qwen-turbo
Append: [Multimodal Adversarial Compositionality (MAC)基准测试提升多模态模型鲁棒性](https://arxiv.org/abs/2505.22943)
Token length: 1334
Summarized using qwen-turbo
Append: [多模态CAD重建模型结合视觉语言与强化学习](https://arxiv.org/abs/2505.22914)
Token length: 1572
Summarized using qwen-turbo
Append: [基于合成数据提升语音语言模型对句子重音的理解能力](https://arxiv.org/abs/2505.22765)
Token length: 1647
Summarized using qwen-turbo
Append: [大型语言模型后训练中奖励噪声的影响研究](https://arxiv.org/abs/2505.22653)
Token length: 1219
Summarized using qwen-turbo
Append: [基于双向扩散模型的高效非自回归文本生成](https://arxiv.org/abs/2505.22618)
Token length: 1503
Summarized using qwen-turbo
Append: [GeoDrive：提升自动驾驶世界模型的空间感知与安全性](https://arxiv.org/abs/2505.22421)
Append: [SridBench: Benchmark of Scientific Research Illustration Drawing of Image Generation Model](https://arxiv.org/abs/2505.22126)
Append: [Differentiable Solver Search for Fast Diffusion Sampling](https://arxiv.org/abs/2505.21114)
Append: [Uni-Instruct: One-step Diffusion Model through Unified Diffusion Divergence Instruction](https://arxiv.org/abs/2505.20755)
Append: [One-shot Entropy Minimization](https://arxiv.org/abs/2505.20282)
Append: [Adaptive Classifier-Free Guidance via Dynamic Low-Confidence Masking](https://arxiv.org/abs/2505.20199)
Append: [Multi-Domain Explainability of Preferences](https://arxiv.org/abs/2505.20088)
Append: [ChartLens: Fine-grained Visual Attribution in Charts](https://arxiv.org/abs/2505.19360)
Append: [A Graph Perspective to Probe Structural Patterns of Knowledge in Large Language Models](https://arxiv.org/abs/2505.19286)
Append: [Evaluating Text Creativity across Diverse Domains: A Dataset and Large Language Model Evaluator](https://arxiv.org/abs/2505.19236)
Append: [CXReasonBench: A Benchmark for Evaluating Structured Diagnostic Reasoning in Chest X-rays](https://arxiv.org/abs/2505.18087)
Append: [PatientSim: A Persona-Driven Simulator for Realistic Doctor-Patient Interactions](https://arxiv.org/abs/2505.17818)
append_entries: 41
Finish: 2025-05-30 12:32:10.747696
------------------------------------------------------
Started: 2025-05-30 18:20:26.064428
Existing_entries: 1041
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1106
Summarized using qwen-turbo
Append: [REOrder：通过优化补丁顺序提升视觉Transformer性能](https://arxiv.org/abs/2505.23751)
Token length: 1080
Summarized using qwen-turbo
Append: [基于强化学习的大语言模型代码效率优化框架](https://arxiv.org/abs/2505.23387)
Token length: 957
Summarized using qwen-turbo
Append: [基于语言模型解释性和不确定性量化提升机器翻译质量评估效率](https://arxiv.org/abs/2505.23183)
Token length: 1532
Summarized using qwen-turbo
Append: [Re-ttention：通过利用时间冗余实现视觉生成模型的极高稀疏注意力](https://arxiv.org/abs/2505.22918)
Json decode failed:
{
  "title": "多语言推理能力评估：大型推理模型的表现与挑战",
  "short_summary": "研究发现现有大型推理模型在多语言推理上存在显著差距。",
  "summary": "近期研究表明，带有推理轨迹的大规模推理模型（LRMs）在英语推理任务中表现优异，但其在其他语言中的推理能力尚缺乏系统研究。由于实际应用中用户需要通过自己熟悉的语言理解推理过程，这种跨语言推理能力的重要性不亚于答案准确性。本研究对两种领先的LRM家族进行了全面评估，发现即使是最先进的模型，在非英语环境中往往退化为英语或产生片段化的推理，揭示了当前模型在多语言推理上的重大不足。尽管基于提示的方法可以提高推理的可读性，却会牺牲部分答案准确性，形成显著的权衡问题。进一步实验表明，仅针对特定任务的少量后训练（如100个示例）能够缓解这一差距，但仍存在一定的精度损失。本研究强调了当前LRMs在多语言推理能力上的局限性，并为未来的研究方向提供了启示。代码和数据可在https:
  "keyword": ["多语言推理", "大型推理模型", "LRMs"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 350 (char 437). Line: 406.
Append: [When Models Reason in Your Language: Controlling Thinking Trace Language Comes at the Cost of Accuracy](https://arxiv.org/abs/2505.22888)
Token length: 1031
Summarized using qwen-turbo
Append: [CLIPGaussians：一种多模态风格迁移框架](https://arxiv.org/abs/2505.22854)
Token length: 1699
Summarized using qwen-turbo
Append: [VidText：视频文本理解的新基准](https://arxiv.org/abs/2505.22810)
Token length: 981
Summarized using qwen-turbo
Append: [FAMA：首个开源科学语音基础模型](https://arxiv.org/abs/2505.22759)
Token length: 818
Summarized using qwen-turbo
Append: [KronSAE：通过Kronecker分解提升稀疏自编码器效率](https://arxiv.org/abs/2505.22255)
Json decode failed:
{
  "title": "难度感知提示方法用于高效推理模型蒸馏",
  "short_summary": "提出一种动态缩短推理痕迹的方法，在不损失性能的前提下提高模型效率。",
  "summary": "现有的链式思维（CoT）蒸馏方法虽能有效转移推理能力，但存在推理痕迹冗长和对问题难度适应性不足的问题。为解决这些问题，我们提出了难度感知提示（DAP）方法，通过教师模型判断问题难度并重写推理痕迹，生成简洁完整的推理痕迹。利用DAP方法，我们创建了一个包含10万条简洁推理示例的数据集LiteCoT，其解决方案平均仅720个标记，比典型CoT短一个数量级。基于Qwen2.5架构，我们使用LiteCoT蒸馏出新的推理模型系列Liter（1.5B、7B和32B）。实验表明，仅使用10万条经过难度修剪的CoT样本进行微调的学生模型表现优于使用80万条原始长CoT样本的模型，同时大幅降低了训练和推理成本。此外，该方法在11个多样化基准测试中表现出色，较传统的长推理链精度更高且使用的标记数更少。例如，在AIME24考试中，我们的方法以约5K推理标记达到74.2%的Pass@1，超越其他消耗更多标记的方法。代码和数据可在https:
  "keyword": ["推理模型蒸馏", "难度感知", "简洁推理"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 429 (char 519). Line: 406.
Append: [Concise Reasoning, Big Gains: Pruning Long Reasoning Trace with Difficulty-Aware Prompting](https://arxiv.org/abs/2505.19716)
Token length: 1374
Summarized using qwen-turbo
Append: [VBenchComp：用于评估视频大模型时间推理能力的新基准](https://arxiv.org/abs/2505.14321)
append_entries: 11
Finish: 2025-05-30 18:21:29.397669
------------------------------------------------------
Started: 2025-05-31 01:09:31.886987
Existing_entries: 1011
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "MMSI-Bench：多图像空间智能评估基准",
  "short_summary": "提出MMSI-Bench评估多模态大语言模型的多图像空间推理能力。",
  "summary": "现有基准仅测试单张图片关系，无法衡量真实世界所需的多图像空间推理能力。本文引入MMSI-Bench，这是一个专门针对多图像空间智能的视觉问答基准。该基准由六名3D视觉研究者耗时超过300小时精心设计，包含1,000道高质量的选择题，每道题配有多重干扰项及逐步推理过程。实验结果显示，最强开源模型的准确率约为30%，而OpenAI的o3模型达到40%，远低于人类97%的得分。此外，利用标注的推理过程，我们开发了一个自动错误分析管道，诊断出四种主要失败模式，为提升多图像空间智能提供了宝贵参考。项目主页：https:
  "keyword": ["多模态", "空间推理", "视觉问答"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 272 (char 366). Line: 406.
Append: [MMSI-Bench: A Benchmark for Multi-Image Spatial Intelligence](https://arxiv.org/abs/2505.23764)
Token length: 940
Summarized using qwen-turbo
Append: [视觉语言模型在解码字谜中的能力评估](https://arxiv.org/abs/2505.23759)
Token length: 766
Summarized using qwen-turbo
Append: [基于关键帧的音乐同步动物舞蹈视频生成框架](https://arxiv.org/abs/2505.23738)
Token length: 1420
Summarized using qwen-turbo
Append: [ZPressor：通过信息瓶颈优化提升3D Gaussian Splatting模型的多视角扩展性](https://arxiv.org/abs/2505.23734)
Token length: 1752
Summarized using qwen-turbo
Append: [ViGoRL：通过视觉引导强化学习提升模型的视觉推理能力](https://arxiv.org/abs/2505.23678)
Token length: 1297
Summarized using qwen-turbo
Append: [基于轨迹输入的统一视频运动控制框架](https://arxiv.org/abs/2505.22944)
Token length: 1551
Summarized using qwen-turbo
Append: [AIDSAFE：通过多智能体迭代推敲提升LLMs安全推理能力](https://arxiv.org/abs/2505.21784)
Token length: 1397
Summarized using qwen-turbo
Append: [LUNGUAGE：基于多研究纵向评估的胸部X光报告生成基准数据集](https://arxiv.org/abs/2505.21190)
Token length: 1062
Summarized using qwen-turbo
Append: [大型语言模型与知识图谱结合用于复杂问答任务的研究综述](https://arxiv.org/abs/2505.20099)
Token length: 1714
Summarized using qwen-turbo
Append: [系统1.5推理：高效且适应性的大语言模型推理框架](https://arxiv.org/abs/2505.18962)
Token length: 1714
Summarized using qwen-turbo
Append: [视觉表征压缩对细粒度特征还原的影响及基准评测](https://arxiv.org/abs/2505.18142)
append_entries: 11
Finish: 2025-05-31 01:10:32.791232
------------------------------------------------------
Started: 2025-05-31 06:19:46.863036
Existing_entries: 1011
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1125
Summarized using qwen-turbo
Append: [GSO基准测试：评估语言模型在高性能软件开发中的能力](https://arxiv.org/abs/2505.23671)
Token length: 1107
Summarized using qwen-turbo
Append: [Yet Another Quantization Algorithm (YAQA) 改进大语言模型后量化性能](https://arxiv.org/abs/2505.22988)
Json decode failed:
{
  "title": "TruthHypo与KnowHD：评估大型语言模型生成可信生物医学假设的能力",
  "short_summary": "研究提出TruthHypo基准和KnowHD检测器以解决大型语言模型生成假说中的真实性问题。",
  "summary": "大型语言模型（LLMs）在生物医学等科学领域展现出了显著潜力，尤其是在假设生成方面，能够分析大量文献、识别模式并提出研究方向。然而，如何验证生成假设的真实性是一个重大挑战，因为这一过程通常需要耗费大量的时间和资源。此外，LLMs的幻觉问题可能导致看似合理但实际上错误的假设产生，影响其可靠性。为了系统性地研究这些挑战，我们引入了TruthHypo基准，用于评估LLMs生成可信生物医学假设的能力，并开发了基于知识的幻觉检测器KnowHD，以评估假设是否基于现有知识。研究结果显示，LLMs在生成真实假设方面存在困难。通过分析推理步骤中的幻觉现象，我们证明KnowHD提供的接地分数可以作为有效指标，用于从LLMs的多样化输出中筛选出真实的假设。进一步的人类评估验证了KnowHD在识别真实假设和加速科学研究中的实用性。我们的数据和源代码可在https:
  "keyword": ["大型语言模型", "生物医学", "假设生成"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 391 (char 514). Line: 406.
Append: [Toward Reliable Biomedical Hypothesis Generation: Evaluating Truthfulness and Hallucination in Large Language Models](https://arxiv.org/abs/2505.14599)
append_entries: 3
Finish: 2025-05-31 06:20:01.078024
------------------------------------------------------
Started: 2025-05-31 12:26:54.151352
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-31 12:26:54.459707
------------------------------------------------------
Started: 2025-05-31 18:18:42.519674
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-05-31 18:18:42.770661
------------------------------------------------------
Started: 2025-06-01 01:24:04.683596
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-01 01:24:05.049372
------------------------------------------------------
Started: 2025-06-01 06:20:34.905217
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-01 06:20:35.167837
------------------------------------------------------
Started: 2025-06-01 12:27:26.414476
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-01 12:27:26.693019
------------------------------------------------------
Started: 2025-06-01 18:18:58.495661
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-01 18:18:58.733335
------------------------------------------------------
Started: 2025-06-02 01:14:15.067077
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-02 01:14:15.337663
------------------------------------------------------
Started: 2025-06-02 06:22:35.665813
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 984
Summarized using qwen-turbo
Append: [AlphaOne：一种用于大模型推理过程动态调控的通用框架](https://arxiv.org/abs/2505.24863)
Token length: 1002
Summarized using qwen-turbo
Append: [基于扩散模型的多语言文本生成框架EasyText](https://arxiv.org/abs/2505.24417)
Token length: 1471
Summarized using qwen-turbo
Append: [一种自适应知识集成框架用于增强大型语言模型](https://arxiv.org/abs/2505.23844)
append_entries: 3
Finish: 2025-06-02 06:22:49.258718
------------------------------------------------------
Started: 2025-06-02 12:30:27.077642
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1299
Summarized using qwen-turbo
Append: [Open CaptchaWorld：评估多模态大型语言模型视觉推理能力的新基准](https://arxiv.org/abs/2505.24878)
Json decode failed:
{
  "title": "SpookyBench：揭示视觉语言模型对时间模式理解的局限性",
  "short_summary": "研究发现，当前最先进的视觉语言模型无法理解仅由时间序列噪声帧构成的模式。",
  "summary": "近年来，视觉-语言模型（VLMs）在理解视频中的时空关系方面取得了显著进展。然而，当空间信息被遮蔽时，这些模型难以捕捉纯粹的时间模式。为此，我们引入了SpookyBench这一基准测试，其中信息仅编码于时间序列的噪声帧中，模拟从生物信号到隐蔽通信的自然现象。令人惊讶的是，人类在这类序列中识别形状、文本和模式的准确率超过98%，而最先进的VLMs却完全无法识别。这种性能差距揭示了一个关键限制：这些模型过度依赖帧级的空间特征，无法从时间线索中提取意义。此外，在低空间信噪比的数据集中训练时，模型的时间理解能力下降速度远快于人类感知，尤其是在需要精细时间推理的任务中。无论模型规模和架构如何，这一问题依然存在。通过发布SpookyBench，我们希望推动时间模式识别的研究，并缩小人类与机器在视频理解上的差距。相关数据集和代码已在项目网站（https:
  "keyword": ["视觉-语言模型", "时间模式", "SpookyBench"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 390 (char 496). Line: 406.
Append: [Time Blindness: Why Video-Language Models Can't See What Humans Can?](https://arxiv.org/abs/2505.24867)
Token length: 1565
Summarized using qwen-turbo
Append: [强化学习如何扩展语言模型的推理边界](https://arxiv.org/abs/2505.24864)
Token length: 1235
Summarized using qwen-turbo
Append: [ViStoryBench：故事可视化评估基准的引入](https://arxiv.org/abs/2505.24862)
Token length: 1097
Summarized using qwen-turbo
Append: [大型语言模型的忠实置信校准研究](https://arxiv.org/abs/2505.24858)
Token length: 1557
Summarized using qwen-turbo
Append: [通过强化蒸馏优化大规模语言模型推理性能](https://arxiv.org/abs/2505.24850)
Json decode failed:
{
  "title": "基于大型语言模型的学术新颖性检测方法",
  "short_summary": "提出利用大语言模型进行学术新颖性检测并构建新数据集。",
  "summary": "在科学迅猛发展的背景下，识别新的研究想法对学术界至关重要且充满挑战。然而，缺乏适当的基准数据集阻碍了新颖性检测的研究。传统方法如文本检索和交叉验证由于文本相似性和概念形成之间的差距，难以普遍适用。本文提出了利用大型语言模型（LLMs）进行科学新颖性检测的方法，并构建了营销和自然语言处理领域的两个新数据集。为了创建考虑周全的数据集，我们建议基于论文之间的关系提取闭合集合，并利用LLMs总结其主要思想。此外，我们还提出通过蒸馏LLMs中的概念级知识来训练轻量级检索器，使相同概念的想法能够高效对齐，从而实现LLM新颖性检测的高效准确检索。实验表明，我们的方法在提出的基准数据集上始终优于其他方法。代码和数据可在https:
  "keyword": ["新颖性检测", "大型语言模型", "学术研究"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 326 (char 409). Line: 406.
Append: [Harnessing Large Language Models for Scientific Novelty Detection](https://arxiv.org/abs/2505.24615)
Token length: 1255
Summarized using qwen-turbo
Append: [利用扩散模型先验进行跨帧一致性几何估计](https://arxiv.org/abs/2505.24521)
Json decode failed:
{
  "title": "通过反演unCLIP改进CLIP模型以提升视觉细节捕捉能力",
  "short_summary": "本文提出通过反演unCLIP改进CLIP模型，显著提升了视觉细节捕捉能力和多模态任务表现。",
  "summary": "Contrastive Language-Image Pre-training (CLIP) 虽然已成为基础模型并广泛应用于多种视觉和多模态任务，但在区分图像细节和处理密集预测任务时表现欠佳。本文聚焦于改善现有CLIP模型，旨在尽可能捕捉更多图像细节。研究发现，一种特定的生成模型——unCLIP提供了合适框架。具体而言，unCLIP基于CLIP图像嵌入训练图像生成器，即反转CLIP图像编码器。由于生成模型优于判别模型在捕捉图像细节方面的能力，我们提议反演unCLIP（命名为un^2CLIP），以提升CLIP模型性能。这种方法使改进后的图像编码器不仅具备unCLIP的细节捕捉能力，还能同时保持与原始文本编码器的一致性。我们在多个任务上评估了改进后的CLIP，包括具有挑战性的MMVP-VLM基准测试、开放词汇密集预测分割任务以及多模态大型语言模型任务，实验表明un^2CLIP显著优于原始CLIP及先前的改进方法。代码和模型将在https:
  "keyword": ["CLIP", "unCLIP", "多模态"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 438 (char 551). Line: 406.
Append: [un^2CLIP: Improving CLIP's Visual Detail Capturing Ability via Inverting unCLIP](https://arxiv.org/abs/2505.24517)
Token length: 1401
Summarized using qwen-turbo
Append: [大型语言模型的近似线性分解及其语义结构解析](https://arxiv.org/abs/2505.24293)
Token length: 1273
Summarized using qwen-turbo
Append: [CLaSp：一种基于上下文层跳过的自推测解码策略](https://arxiv.org/abs/2505.24196)
Json decode failed:
{
  "title": "HARDTESTGEN：基于LLMs的高质量编程测试合成管道",
  "short_summary": "提出HARDTESTGEN管道解决复杂编程问题中可靠验证器难以获取的问题。",
  "summary": "可靠的验证器对大型语言模型（LLM）推理至关重要，但在处理复杂编码问题时面临挑战，因为精心设计的错误解决方案可能仅能通过人工编写的边缘案例检测。为了解决这一问题，我们提出了HARDTESTGEN，这是一种利用LLMs进行高质量测试合成的管道。通过该管道，我们整理了一个包含47k个问题及合成高质量测试的综合性竞争编程数据集HARDTESTS。相较于现有测试，HARDTESTGEN测试在评估LLM生成代码时表现出更高的精度（高出11.3个百分点）和召回率（高出17.5个百分点）。对于更难的问题，精度提升可达40个百分点。此外，HARDTESTS在下游代码生成性能方面也显示出更强的训练效果。我们将开源此数据集及其合成管道至https:
  "keyword": ["LLM", "验证器", "编程测试"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 333 (char 439). Line: 406.
Append: [HardTests: Synthesizing High-Quality Test Cases for LLM Coding](https://arxiv.org/abs/2505.24098)
Token length: 1195
Summarized using qwen-turbo
Append: [视觉语言模型在计数任务中的偏见研究](https://arxiv.org/abs/2505.23941)
Token length: 1403
Summarized using qwen-turbo
Append: [Point-MoE：实现大规模跨域3D点云理解的Mixture-of-Experts架构](https://arxiv.org/abs/2505.23926)
Token length: 1399
Summarized using qwen-turbo
Append: [EmergentTTS-Eval：语音合成模型的综合评估基准](https://arxiv.org/abs/2505.23009)
Token length: 836
Summarized using qwen-turbo
Append: [DexUMI：通过人类手部接口学习灵巧操作技能的框架](https://arxiv.org/abs/2505.21864)
Token length: 1354
Summarized using qwen-turbo
Append: [无需额外训练的音频-视觉大语言模型平衡模态理解方法](https://arxiv.org/abs/2505.20873)
Token length: 1156
Summarized using qwen-turbo
Append: [v1模型：多模态大语言模型的轻量级视觉重访扩展](https://arxiv.org/abs/2505.18842)
Token length: 1652
Summarized using qwen-turbo
Append: [LLMSynthor：利用大语言模型实现高保真数据合成](https://arxiv.org/abs/2505.14752)
append_entries: 19
Finish: 2025-06-02 12:32:25.760214
------------------------------------------------------
Started: 2025-06-02 18:20:49.707289
Existing_entries: 1019
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1061
Summarized using qwen-turbo
Append: [ReasonGen-R1：结合推理与强化学习的生成视觉模型](https://arxiv.org/abs/2505.24875)
Json decode failed:
{
  "title": "引入ConTEB与InSeNT：提升文档检索上下文嵌入性能",
  "short_summary": "现有文档检索方法常忽略文档内上下文信息，新研究提出结合InSeNT的对比学习方法提升检索质量。",
  "summary": "现代文档检索嵌入方法通常独立编码同一文档中的片段，忽视了文档整体上下文的重要性，导致片段表示不够精确。本文介绍了一个名为ConTEB的上下文感知文本嵌入基准，用于评估模型利用文档全局上下文的能力。实验表明，最先进的嵌入模型在需要上下文的检索场景中表现不佳。为解决这一问题，我们提出了InSeNT，一种新颖的对比后训练方法，结合晚期片段池化技术，不仅提升了上下文表示学习的效果，还保持了计算效率。该方法显著改善了ConTEB上的检索质量，同时不影响基础模型的表现。此外，我们的方法使片段嵌入对子优片段划分策略和更大的检索语料库更具鲁棒性。所有研究资源已开源，地址为https:
  "keyword": ["文档检索", "上下文嵌入", "InSeNT"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 302 (char 417). Line: 406.
Append: [Context is Gold to find the Gold Passage: Evaluating and Training Contextual Document Embeddings](https://arxiv.org/abs/2505.24782)
Token length: 1047
Summarized using qwen-turbo
Append: [基于Matryoshka表征学习的阿拉伯语文本语义相似度模型](https://arxiv.org/abs/2505.24581)
Token length: 719
Summarized using qwen-turbo
Append: [小语言模型在特定领域任务中的质量优势](https://arxiv.org/abs/2505.24189)
Token length: 980
Summarized using qwen-turbo
Append: [LLM安全研究中的语言多样性分析](https://arxiv.org/abs/2505.24119)
Token length: 1165
Summarized using qwen-turbo
Append: [基于角色的自适应奖励模型提升对话系统真实性](https://arxiv.org/abs/2505.23923)
Token length: 1215
Summarized using qwen-turbo
Append: [LEGAR BENCH与LegalSearchLM：解决法律案例检索难题](https://arxiv.org/abs/2505.23832)
Token length: 983
Summarized using qwen-turbo
Append: [双向线性运算在循环神经网络中的作用及其对记忆建模的影响](https://arxiv.org/abs/2505.21749)
Token length: 1865
Summarized using qwen-turbo
Append: [基于协调扩散噪声优化框架的全身操作合成](https://arxiv.org/abs/2505.21437)
Token length: 1216
Summarized using qwen-turbo
Append: [多模态大型语言模型的模态偏好研究与调控方法](https://arxiv.org/abs/2505.20977)
Token length: 1169
Summarized using qwen-turbo
Append: [面向形式化验证的大语言模型不确定性量化研究](https://arxiv.org/abs/2505.20047)
Token length: 1282
Summarized using qwen-turbo
Append: [多模态大型语言模型推理链长度对视觉接地的影响研究](https://arxiv.org/abs/2505.21523)
Token length: 663
Summarized using qwen-turbo
Append: [引入RPEval：评估大型语言模型角色扮演能力的新基准](https://arxiv.org/abs/2505.13157)
append_entries: 13
Finish: 2025-06-02 18:21:58.293106
------------------------------------------------------
Started: 2025-06-03 01:12:31.836082
Existing_entries: 1013
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1730
Summarized using qwen-turbo
Append: [多模态大模型强化学习框架提升泛化能力](https://arxiv.org/abs/2505.24871)
Json decode failed:
{
  "title": "SiLVR：基于语言的视频推理框架提升多模态大模型推理能力",
  "short_summary": "提出SiLVR框架，通过语言表示分解并解决复杂视频语言任务。",
  "summary": "近期研究显示，测试时优化显著提升了大型语言模型（LLMs）的推理能力，但在多模态LLMs（MLLMs）的推理能力上仍存在明显不足，特别是在复杂视频语言任务中的表现。本文介绍了一种名为SiLVR的新框架，它通过将视频理解分解为两个阶段来解决这一问题。首先，SiLVR利用多感官输入（如剪辑字幕和语音字幕）将原始视频转换为基于语言的表示形式；其次，这些语言描述被输入到强大的推理LLM中以完成复杂的视频语言理解任务。为了处理长上下文的多感官输入，我们采用了一种自适应令牌减少方案，动态确定采样的时间粒度。SiLVR在Video-MME（长期）、Video-MMMU（理解）、Video-MMLU、CGBench和EgoLife等基准测试中取得了最佳报告结果。此外，我们的实证研究表明，尽管强推理LLM没有经过显式视频训练，但它们能够有效聚合来自视频、语音和音频的多感官输入信息，用于视频中的复杂时间、因果、长上下文和知识获取推理任务。代码可在https:
  "keyword": ["多模态", "视频推理", "语言模型"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 440 (char 538). Line: 406.
Append: [SiLVR: A Simple Language-based Video Reasoning Framework](https://arxiv.org/abs/2505.24869)
Token length: 1490
Summarized using qwen-turbo
Append: [EXP-Bench：评估AI代理完成完整研究实验的能力](https://arxiv.org/abs/2505.24785)
Token length: 1496
Summarized using qwen-turbo
Append: [DINO-R1：通过强化学习实现视觉基础模型的上下文推理能力](https://arxiv.org/abs/2505.24025)
Token length: 1258
Summarized using qwen-turbo
Append: [OmNIGUARD：一种多语言跨模态有害提示检测方法](https://arxiv.org/abs/2505.23856)
append_entries: 5
Finish: 2025-06-03 01:13:00.365571
------------------------------------------------------
Started: 2025-06-03 06:22:15.897011
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1496
Summarized using qwen-turbo
Append: [RoboMaster：一种基于协作轨迹建模的多对象交互视频扩散模型](https://arxiv.org/abs/2506.01943)
Json decode failed:
{
  "title": "通过Token熵模式解析强化学习中可验证奖励机制",
  "short_summary": "研究揭示强化学习中仅高熵Token影响推理性能并提出优化策略。",
  "summary": "本文采用一种新颖的视角——Token熵模式，深入分析强化学习中可验证奖励（RLVR）机制的作用。研究发现，在Chain-of-Thought推理过程中，只有少量Token具有高熵值，这些Token作为关键分叉点引导模型走向多样化推理路径。此外，通过观察RLVR训练期间熵模式的变化，我们发现RLVR主要遵循基础模型的熵模式，主要调节高熵Token的熵值。基于此，我们限制策略梯度更新仅针对分叉Token，不仅在Qwen3系列模型上维持甚至超越了全梯度更新的效果，还显著提升了特定模型的表现。例如，在AIME"25和AIME"24测试集上，相较于全梯度更新，某些模型分别提升了11.04和7.71分。相反，若仅训练低熵Token，则会导致性能大幅下降。这些发现表明，RLVR的效能主要源于对决定推理方向的高熵少数Token的优化。总体而言，本研究强调了通过Token熵视角理解RLVR并优化其性能的重要性。",
  "keyword": ["强化学习", "可验证奖励", "Token熵"]
}Summarization failed, append the original article
error: Expecting ',' delimiter: line 4 column 269 (char 363). Line: 406.
Append: [Beyond the 80/20 Rule: High-Entropy Minority Tokens Drive Effective Reinforcement Learning for LLM Reasoning](https://arxiv.org/abs/2506.01939)
Token length: 1499
Summarized using qwen-turbo
Append: [STORM框架：任务型对话系统中的非对称信息处理与意图形成建模](https://arxiv.org/abs/2506.01881)
Token length: 1222
Summarized using qwen-turbo
Append: [ShapeLLM-Omni：一种支持文本与3D资产双向交互的原生大型语言模型](https://arxiv.org/abs/2506.01853)
Token length: 1574
Summarized using qwen-turbo
Append: [通过强化学习提升大语言模型处理复杂指令的能力](https://arxiv.org/abs/2506.01413)
Token length: 1151
Summarized using qwen-turbo
Append: [Scaling with Gradient Grouping (SGG): 改进大规模语言模型优化的新方法](https://arxiv.org/abs/2506.01049)
Json decode failed:
{
  "title": "高效灵活的文本到视频扩散模型微调方法：Temporal In-Context Fine-Tuning",
  "short_summary": "提出一种无需架构修改且高效的条件生成方法，仅需少量样本即可实现高质量视频合成。",
  "summary": "近期文本到视频扩散模型的进步使得高质量视频合成成为可能，但可控生成仍面临挑战，尤其是在有限数据和计算资源下。现有基于条件生成的微调方法通常依赖外部编码器或结构修改，需要大规模数据集，并局限于空间对齐条件，限制了灵活性和可扩展性。本文介绍了一种名为Temporal In-Context Fine-Tuning (TIC-FT) 的高效且多功能的方法，用于适应预训练视频扩散模型的不同条件生成任务。通过沿时间轴连接条件帧和目标帧，并插入具有逐步增加噪声级别的中间缓冲帧，TIC-FT 能够实现平滑过渡并符合预训练模型的时间动态特性。该方法无需进行架构改动，在仅使用10-30个训练样本的情况下就能表现出色。我们在多种任务上验证了这种方法，包括图像到视频生成和视频到视频生成，使用的大规模基础模型如 CogVideoX-5B 和 Wan-14B。大量实验表明，TIC-FT 在条件保真度和视觉质量方面优于现有基线，同时在训练和推理过程中保持高度效率。更多结果请访问 https:
  "keyword": ["文本到视频", "扩散模型", "条件生成"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 452 (char 580). Line: 406.
Append: [Temporal In-Context Fine-Tuning for Versatile Control of Video Diffusion Models](https://arxiv.org/abs/2506.00996)
Token length: 1414
Summarized using qwen-turbo
Append: [大型语言模型在多选题中的局限性及改进方法](https://arxiv.org/abs/2506.00643)
Token length: 1244
Summarized using qwen-turbo
Append: [通过后训练技术提升大型语言模型在多智能体系统中的经济推理能力](https://arxiv.org/abs/2506.00577)
Token length: 1274
Summarized using qwen-turbo
Append: [ARIA：通过意图空间奖励聚合提升语言模型强化学习效能](https://arxiv.org/abs/2506.00539)
Token length: 1606
Summarized using qwen-turbo
Append: [LoHoVLA：一种针对长时序任务的统一视觉语言动作框架](https://arxiv.org/abs/2506.00411)
Token length: 1354
Summarized using qwen-turbo
Append: [MagiCodec：一种基于Transformer的高效音频编解码器](https://arxiv.org/abs/2506.00385)
Token length: 1008
Summarized using qwen-turbo
Append: [基于YODAS扩展的Open Whisper-style Speech Models V4](https://arxiv.org/abs/2506.00338)
Token length: 1561
Summarized using qwen-turbo
Append: [MiCRo：基于大规模二元偏好数据的学习框架提升个性化奖励建模](https://arxiv.org/abs/2505.24846)
Token length: 710
Summarized using qwen-turbo
Append: [Reasoning Gym：基于可验证奖励的强化学习环境库](https://arxiv.org/abs/2505.24760)
Token length: 1164
Summarized using qwen-turbo
Append: [基于视频的3D几何大语言模型在场景理解中的应用](https://arxiv.org/abs/2505.24625)
Token length: 1741
Summarized using qwen-turbo
Append: [统一预算感知学习率调度器UBA的研究](https://arxiv.org/abs/2505.24452)
Token length: 1052
Summarized using qwen-turbo
Append: [VisualSphinx：首个大规模合成视觉逻辑推理训练数据集](https://arxiv.org/abs/2505.23977)
Token length: 1206
Summarized using qwen-turbo
Append: [Cora：一种基于语义对应的新图像编辑框架](https://arxiv.org/abs/2505.23907)
Json decode failed:
{
  "title": "基于规则的视觉强化学习研究：以拼图任务为例",
  "short_summary": "研究揭示多模态大语言模型通过微调可解决复杂拼图并泛化到其他视觉任务。",
  "summary": "本研究探讨了基于规则的视觉强化学习在多模态大型语言模型中的应用，以拼图任务作为实验框架。研究发现，初始表现接近随机猜测的模型经过微调后可以实现接近完美的准确性，并且能泛化到未见过的复杂配置；拼图训练还能够诱导对其他视觉任务的泛化能力，且效果取决于具体任务配置；模型能够无需显式推理进行学习和泛化，但开源模型通常倾向于直接回答问题；复杂推理模式似乎是预存而非新兴，其频率随训练和任务难度增加而上升。此外，强化学习相较于监督微调在泛化方面更为有效，且监督微调的冷启动阶段可能阻碍后续强化学习优化。尽管这些发现基于拼图任务，但在其他视觉任务中可能有所不同。本研究为理解基于规则的视觉强化学习及其在多模态学习中的潜力提供了重要参考。代码已公开：https:
  "keyword": ["强化学习", "多模态", "拼图任务"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 339 (char 433). Line: 406.
Append: [Jigsaw-R1: A Study of Rule-based Visual Reinforcement Learning with Jigsaw Puzzles](https://arxiv.org/abs/2505.23590)
Json decode failed:
{
  "title": "面向视频异常理解的数据高效框架VAU-R1及其基准VAU-Bench",
  "short_summary": "提出结合强化微调的VAU-R1框架及首个视频异常推理基准VAU-Bench。",
  "summary": "视频异常理解（VAU）在智能城市、安全监控和灾害预警系统等应用中至关重要，但由于需要精细的空间时间感知和在模糊环境下的稳健推理，其实现仍具挑战性。现有异常检测方法通常缺乏可解释性，难以捕捉异常事件的因果和上下文特性，且缺乏评估异常场景推理能力的综合基准。为解决这些问题，本文引入了基于多模态大语言模型（MLLMs）的数据高效框架VAU-R1，并通过强化微调（RFT）增强异常推理能力。同时，我们提出了VAU-Bench，这是首个面向视频异常推理的Chain-of-Thought基准，包含多项选择题、详细理由、时间标注和描述性标题。实验结果表明，VAU-R1在不同上下文中显著提高了问答准确性、时间定位和推理连贯性。我们的方法和基准共同为具有可解释性和推理意识的视频异常理解奠定了坚实基础。代码可在https:
  "keyword": ["视频异常理解", "多模态大语言模型", "强化微调"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 370 (char 481). Line: 406.
Append: [VAU-R1: Advancing Video Anomaly Understanding via Reinforcement Fine-Tuning](https://arxiv.org/abs/2505.23504)
Json decode failed:
{
  "title": "State Machine Reasoning优化复杂推理在信息检索中的应用",
  "short_summary": "提出State Machine Reasoning方法提升信息检索性能并减少计算开销。",
  "summary": "本文探讨了基于链式思维（CoT）提示的大语言模型（LLMs）在信息检索（IR）中的复杂推理能力，但指出其常因过量推理导致冗余和效率低下。研究发现两种主要问题：轨迹冗余（重复访问相似状态）及误导性推理（偏离用户意图）。为此，我们引入状态机推理（SMR），这是一种基于离散动作（如优化、重新排序、停止）的框架，支持早期终止和细粒度控制。实验表明，在BEIR和BRIGHT基准测试中，SMR提升了3.4%的nDCG@10检索性能，同时将令牌使用量减少了74.4%，且无需针对特定任务调优即可跨模型和检索器实现通用化。代码和详细信息可在https:
  "keyword": ["信息检索", "链式思维", "状态机推理"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 285 (char 405). Line: 406.
Append: [From Token to Action: State Machine Reasoning to Mitigate Overthinking in Information Retrieval](https://arxiv.org/abs/2505.23059)
Token length: 1352
Summarized using qwen-turbo
Append: [DyePack：通过后门攻击检测大语言模型对基准测试集的依赖](https://arxiv.org/abs/2505.23001)
append_entries: 23
Finish: 2025-06-03 06:24:24.169265
------------------------------------------------------
Started: 2025-06-03 12:30:32.947456
Existing_entries: 1023
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1389
Summarized using qwen-turbo
Append: [SmolVLA：高效社区驱动的视觉-语言-动作模型](https://arxiv.org/abs/2506.01844)
Token length: 1333
Summarized using qwen-turbo
Append: [EarthMind：面向多粒度多传感器地球观测数据的理解框架](https://arxiv.org/abs/2506.01667)
Token length: 1198
Summarized using qwen-turbo
Append: [zip2zip：通过动态词汇表优化大语言模型推理效率](https://arxiv.org/abs/2506.01084)
Token length: 1269
Summarized using qwen-turbo
Append: [基于渐进视图范式的文本引导3D编辑方法](https://arxiv.org/abs/2506.00512)
Token length: 1011
Summarized using qwen-turbo
Append: [大规模多语言连续预训练中的平行数据研究](https://arxiv.org/abs/2506.00469)
Token length: 1609
Summarized using qwen-turbo
Append: [蒸馏模型对抗性偏见注入漏洞及传播机制研究](https://arxiv.org/abs/2505.24842)
Token length: 1545
Summarized using qwen-turbo
Append: [AReaL：一种用于大规模语言模型强化学习的全异步系统](https://arxiv.org/abs/2505.24298)
Token length: 1657
Summarized using qwen-turbo
Append: [CodeV-R1：基于强化学习带验证奖励的硬件描述语言自动生成框架](https://arxiv.org/abs/2505.24183)
Token length: 1231
Summarized using qwen-turbo
Append: [大型语言模型主观倾向评估：Preference, Opinion, and Belief 调查](https://arxiv.org/abs/2505.19621)
append_entries: 9
Finish: 2025-06-03 12:31:29.964524
------------------------------------------------------
Started: 2025-06-03 18:21:16.992528
Existing_entries: 1009
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1798
Summarized using qwen-turbo
Append: [WebChoreArena：衡量大型语言模型处理复杂网络任务的能力](https://arxiv.org/abs/2506.01952)
Token length: 1099
Summarized using qwen-turbo
Append: [融合自回归与掩码扩散模型的Eso-LMs提升语言建模效率](https://arxiv.org/abs/2506.01928)
Token length: 1216
Summarized using qwen-turbo
Append: [阿拉伯语语言模型评估的理论指南与新框架](https://arxiv.org/abs/2506.01920)
Token length: 1401
Summarized using qwen-turbo
Append: [探索压缩表示中的规模定律：统一预测模型性能](https://arxiv.org/abs/2506.01863)
Token length: 1466
Summarized using qwen-turbo
Append: [基于组相对策略优化的多模态自反思增强推理方法](https://arxiv.org/abs/2506.01713)
Token length: 1195
Summarized using qwen-turbo
Append: [基于多模态去噪扩散模型的量子运算高效编译方法](https://arxiv.org/abs/2506.01666)
Token length: 1089
Summarized using qwen-turbo
Append: [基于LLM的自动化仇恨言论去毒化研究](https://arxiv.org/abs/2506.01484)
Token length: 1218
Summarized using qwen-turbo
Append: [个性化场景认知对齐的视觉语言模型评估基准与框架](https://arxiv.org/abs/2506.00930)
Json decode failed:
{
  "title": "低秩启发的稀疏微调方法在大语言模型中的高效推理能力提升",
  "short_summary": "提出低秩启发的稀疏微调方法LIFT，显著提升LLMs推理性能。",
  "summary": "近期研究表明，基于少量高质量数据集对大型语言模型（LLMs）进行有监督微调可以实现强大的推理能力。然而，全量微调（Full FT）虽然强大但计算成本高且易过拟合，特别是在数据受限时。稀疏微调通过仅更新小部分模型参数提供了一种效率与效果之间的平衡，但在LLM时代因难以确定真正对推理至关重要的参数而表现不佳。本研究指出，经过低秩近似后权重绝对值最大的参数是关键权重，即主权重（Principal Weights）。尽管基于幅度的稀疏微调作为基线在LLM微调中表现不佳，但在秩降低后却非常有效。这些见解促使我们提出了低秩启发的稀疏微调方法（LIFT），该方法在整个训练过程中仅更新前5%的主权重，不仅在推理任务上优于全量微调，还保持了与流行的参数高效微调方法相当的记忆效率。此外，LIFT在算术推理等目标领域表现出色，同时保留了比全量微调和LoRA多20%的源领域知识。我们的代码已公开：https:
  "keyword": ["稀疏微调", "低秩近似", "大语言模型"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 413 (char 510). Line: 406.
Append: [LIFT the Veil for the Truth: Principal Weights Emerge after Rank Reduction for Reasoning-Focused Supervised Fine-Tuning](https://arxiv.org/abs/2506.00772)
Token length: 807
Summarized using qwen-turbo
Append: [大型语言模型在预测任务中的表现评估挑战](https://arxiv.org/abs/2506.00723)
Token length: 1270
Summarized using qwen-turbo
Append: [CityLens：评估大语言-视觉模型预测城市社会经济指标的能力](https://arxiv.org/abs/2506.00530)
Json decode failed:
{
  "title": "SenseFlow：解决大规模文本到图像扩散模型的知识蒸馏难题",
  "short_summary": "提出新的方法IDA和ISG，成功解决大尺度文本到图像扩散模型的知识蒸馏收敛问题。",
  "summary": "本文研究了分布匹配蒸馏（DMD）在大型基于流的文本到图像扩散模型（如Stable Diffusion 3.5和FLUX）上的应用问题。首先分析了原始DMD方法在这些模型上遇到的收敛困难，随后提出隐式分布对齐（IDA）来正则化生成器与虚假分布之间的距离，并引入内部片段引导（ISG）重新分配教师模型的时间步重要性分布。实验表明，仅使用IDA即可使DMD在SD 3.5上收敛；结合IDA和ISG后，DMD不仅适用于SD 3.5，还能处理FLUX模型。此外，通过扩展判别器模型等其他改进措施，最终提出的SenseFlow模型在包括SDXL在内的多种扩散模型和flow-matching模型的蒸馏任务中表现出色。代码将在https:
  "keyword": ["知识蒸馏", "文本到图像", "扩散模型"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 327 (char 437). Line: 406.
Append: [SenseFlow: Scaling Distribution Matching for Flow-based Text-to-Image Distillation](https://arxiv.org/abs/2506.00523)
Token length: 1218
Summarized using qwen-turbo
Append: [对抗性攻击对机器生成文本检测器性能的影响研究](https://arxiv.org/abs/2505.24523)
Token length: 1508
Summarized using qwen-turbo
Append: [ComposeAnything：无需重新训练的文本到图像复合生成框架](https://arxiv.org/abs/2505.24086)
Token length: 1362
Summarized using qwen-turbo
Append: [OmniResponse：一种多模态大语言模型用于在线对话反馈生成](https://arxiv.org/abs/2505.21724)
Token length: 1733
Summarized using qwen-turbo
Append: [R1-Code-Interpreter：通过代码生成提升大语言模型推理能力](https://arxiv.org/abs/2505.21668)
Token length: 1316
Summarized using qwen-turbo
Append: [Normalized Attention Guidance (NAG)：一种高效的扩散模型负向引导机制](https://arxiv.org/abs/2505.21179)
Token length: 1879
Summarized using qwen-turbo
Append: [MaskSearch：通过预训练提升大语言模型的通用搜索能力](https://arxiv.org/abs/2505.20285)
Token length: 1386
Summarized using qwen-turbo
Append: [Frankentexts：LLMs生成的一种新型叙事文本研究](https://arxiv.org/abs/2505.18128)
Token length: 998
Summarized using qwen-turbo
Append: [MIKU-PAL：基于多模态自动化管道的情绪语音合成系统](https://arxiv.org/abs/2505.15772)
append_entries: 20
Finish: 2025-06-03 18:23:04.080450
------------------------------------------------------
Started: 2025-06-04 01:12:22.715464
Existing_entries: 1020
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1297
Summarized using qwen-turbo
Append: [多编程语言与英语在大语言模型概念空间中的关系研究](https://arxiv.org/abs/2506.01074)
Token length: 1408
Summarized using qwen-turbo
Append: [SealQA：评估搜索增强语言模型的新基准](https://arxiv.org/abs/2506.01062)
Json decode failed:
{
  "title": "IVY-FAKE：统一框架下的可解释AIGC检测数据集与模型",
  "short_summary": "提出IVY-FAKE数据集及模型，实现图像与视频AIGC检测的统一与可解释性。",
  "summary": "随着基于扩散架构等高级生成模型的发展，人工智能生成内容(AIGC)在视觉领域的应用取得了显著进展，但随之而来的是对内容真实性与完整性的担忧。当前大多数AIGC检测方法依赖于黑箱二分类器，缺乏透明性和可信度，且无法同时处理图像与视频内容。针对这些问题，我们开发了IVY-FAKE，这是一个大规模、多模态的新型数据集，包含超过15万训练样本和1.87万评估样本，每个样本均附带详细的自然语言推理说明。基于此数据集，我们进一步提出了Ivy Explainable Detector (IVY-XDETECTOR)，这是一种能够联合检测图像和视频的统一可解释架构。该模型在多个图像和视频检测基准上达到了最先进的性能，证明了新数据集和建模框架的重要价值。IVY-FAKE数据集现已公开，网址为https:
  "keyword": ["AIGC", "检测", "可解释性"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 362 (char 470). Line: 406.
Append: [IVY-FAKE: A Unified Explainable Framework and Benchmark for Image and Video AIGC Detection](https://arxiv.org/abs/2506.00979)
Token length: 1473
Summarized using qwen-turbo
Append: [RAG系统在动态语料库上的鲁棒性评估](https://arxiv.org/abs/2506.00789)
Token length: 923
Summarized using qwen-turbo
Append: [Neuro2Semantic：基于iEEG信号的语言语义解码新框架](https://arxiv.org/abs/2506.00381)
Token length: 1064
Summarized using qwen-turbo
Append: [源无关域自适应中的增强技术与伪标签重加权策略](https://arxiv.org/abs/2505.24216)
Token length: 1907
Summarized using qwen-turbo
Append: [达尔文Gödel机器：一种自我进化的AI系统](https://arxiv.org/abs/2505.22954)
Token length: 1424
Summarized using qwen-turbo
Append: [基于流匹配的双耳语音合成框架BinauralFlow](https://arxiv.org/abs/2505.22865)
Token length: 1519
Summarized using qwen-turbo
Append: [Plan-and-Budget：提升大语言模型推理效率的框架](https://arxiv.org/abs/2505.16122)
Token length: 1179
Summarized using qwen-turbo
Append: [多模态大语言模型推理机制研究：基于视觉矛盾数据集的分析](https://arxiv.org/abs/2505.17127)
append_entries: 10
Finish: 2025-06-04 01:13:25.968933
------------------------------------------------------
Started: 2025-06-04 06:21:39.845280
Existing_entries: 1010
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1316
Summarized using qwen-turbo
Append: [UniWorld：基于语义特征的统一生成框架](https://arxiv.org/abs/2506.03147)
Json decode failed:
{
  "title": "CURE框架：基于交互结果的强化学习代码与单元测试生成模型",
  "short_summary": "提出CURE框架，提升代码生成和单元测试生成能力。",
  "summary": "本文提出了一种名为CURE的新型强化学习框架，该框架通过专门设计的奖励机制，协同进化代码生成与单元测试生成的能力，而无需任何真实代码作为监督。此方法使得训练过程更加灵活且可扩展，并允许单元测试生成器直接从代码生成器的错误中学习。经过优化后，CURE衍生出的ReasonFlux-Coder-7B和14B模型在Qwen2.5-Instruct模型上提升了代码生成准确性达5.3%，Best-of-N准确性提高9.0%，优于同规模的其他模型如Qwen-Coder、DeepSeek-Coder和Seed-Coder。此外，这些模型还能自然扩展到下游任务，如测试时扩展和自主编码，相比基础模型提高了8.1%。针对长上下文任务，ReasonFlux-Coder-4B模型在单元测试生成方面持续优于Qwen3-4B，同时保持了64.8%的推理效率。值得注意的是，研究还发现CURE模型可用作基线模型的高效奖励模型。项目地址：https:
  "keyword": ["强化学习", "代码生成", "单元测试"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 428 (char 521). Line: 406.
Append: [Co-Evolving LLM Coder and Unit Tester via Reinforcement Learning](https://arxiv.org/abs/2506.03136)
Token length: 1362
Summarized using qwen-turbo
Append: [基于扩散Transformer的任意分辨率图像合成](https://arxiv.org/abs/2506.03131)
Token length: 1037
Summarized using qwen-turbo
Append: [基于视觉提示的可泛化图像编辑新范式](https://arxiv.org/abs/2506.02528)
Token length: 1308
Summarized using qwen-turbo
Append: [M^3FinMeeting：多语言金融会议理解基准的开创性研究](https://arxiv.org/abs/2506.02510)
Token length: 1460
Summarized using qwen-turbo
Append: [Multimodal DeepResearcher：结合文本与可视化的大语言模型深度研究框架](https://arxiv.org/abs/2506.02454)
Token length: 1590
Summarized using qwen-turbo
Append: [Visual Strategic Bench (VS-Bench): 多智能体环境中视觉语言模型的战略推理评估](https://arxiv.org/abs/2506.02387)
Token length: 1303
Summarized using qwen-turbo
Append: [基于合成数据增强的视觉语言模型强化学习研究](https://arxiv.org/abs/2506.02096)
Token length: 1604
Summarized using qwen-turbo
Append: [构建高质量数据集的挑战与系统性评估方法](https://arxiv.org/abs/2506.01789)
Token length: 1421
Summarized using qwen-turbo
Append: [MotionSight：零样本细粒度视频运动理解的新方法](https://arxiv.org/abs/2506.01674)
Token length: 1212
Summarized using qwen-turbo
Append: [金融领域多模态大型语言模型评估基准FinMME发布](https://arxiv.org/abs/2505.24714)
Token length: 1319
Summarized using qwen-turbo
Append: [RRec：具有内在推理能力的统一推荐模型](https://arxiv.org/abs/2505.16994)
append_entries: 12
Finish: 2025-06-04 06:22:56.752346
------------------------------------------------------
Started: 2025-06-04 12:30:34.903736
Existing_entries: 1012
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1846
Summarized using qwen-turbo
Append: [GUI-Actor: 一种无需坐标定位的视觉语言模型驱动GUI动作引导方法](https://arxiv.org/abs/2506.03143)
Token length: 1091
Summarized using qwen-turbo
Append: [OmniSpatial：面向空间推理的认知心理学基准测试](https://arxiv.org/abs/2506.03135)
Token length: 1816
Summarized using qwen-turbo
Append: [AnimeShooter：基于参考图像的多镜头动画数据集及生成模型](https://arxiv.org/abs/2506.03126)
Token length: 1291
Summarized using qwen-turbo
Append: [ORV：基于占用场的机器人视频生成框架](https://arxiv.org/abs/2506.03079)
Token length: 1636
Summarized using qwen-turbo
Append: [Sparse-vDiT：通过结构稀疏性加速视频扩散Transformer](https://arxiv.org/abs/2506.03065)
Token length: 1761
Summarized using qwen-turbo
Append: [基于运动引导的长视频生成框架LumosFlow](https://arxiv.org/abs/2506.02497)
Token length: 1267
Summarized using qwen-turbo
Append: [基于非推理规模训练的大规模推理模型长链思维数据集构建](https://arxiv.org/abs/2506.02338)
Token length: 1278
Summarized using qwen-turbo
Append: [基于Layer-wise Relevance Propagation的Transformer可解释性改进](https://arxiv.org/abs/2506.02138)
Token length: 1483
Summarized using qwen-turbo
Append: [Hanfu-Bench：探索文化的时间维度](https://arxiv.org/abs/2506.01565)
Token length: 1275
Summarized using qwen-turbo
Append: [ReFoCUS：通过强化学习优化视频帧选择提升多模态模型推理能力](https://arxiv.org/abs/2506.01274)
Token length: 1334
Summarized using qwen-turbo
Append: [FlowMo：无需训练的文本到视频扩散模型时间一致性增强方法](https://arxiv.org/abs/2506.01144)
Token length: 1441
Summarized using qwen-turbo
Append: [ActiveKD：结合主动学习与知识蒸馏的框架](https://arxiv.org/abs/2506.00910)
Token length: 1127
Summarized using qwen-turbo
Append: [自适应并行解码提升扩散大语言模型生成速度](https://arxiv.org/abs/2506.00413)
Token length: 1676
Summarized using qwen-turbo
Append: [Visual Embodied Brain (VeBrain): 统一多模态大型语言模型的机器人应用框架](https://arxiv.org/abs/2506.00123)
Token length: 1245
Summarized using qwen-turbo
Append: [基于自我反思与强化学习的大语言模型性能提升方法](https://arxiv.org/abs/2505.24726)
Token length: 1343
Summarized using qwen-turbo
Append: [零样本链式思维推理过程成功预测研究](https://arxiv.org/abs/2505.24362)
Token length: 1918
Summarized using qwen-turbo
Append: [大规模语言模型中回溯技术对推理能力提升的研究](https://arxiv.org/abs/2505.24273)
Json decode failed:
{
  "title": "CSVQA：评估视觉语言模型科学推理能力的新基准",
  "short_summary": "CSVQA通过领域驱动的视觉问答测试VLMs的科学推理能力。",
  "summary": "现有的多模态基准主要评估通用图像理解和文本引导推理，缺乏需要特定领域知识整合和视觉证据分析的真实科学情境。为了填补这一空白，我们提出了CSVQA，这是一个专门设计用于评估科学推理的诊断性多模态基准。CSVQA包含1378个精心构建的问题-答案对，覆盖广泛的STEM学科，每个问题都需要特定领域的知识、视觉证据的整合和高阶推理。与之前的多模态基准相比，CSVQA更加注重真实世界中的科学内容和复杂推理。我们还提出了一种严格的评估协议，系统地评估模型预测是否基于精心策划的解释支持的有效中间推理步骤。对15个视觉语言模型在该基准上的全面评估显示了显著的性能差异，即使是最顶级的专有模型也只达到了49.6%的准确率。这些实证结果突显了提升视觉语言模型科学推理能力的紧迫需求。CSVQA已发布在https:
  "keyword": ["视觉语言模型", "科学推理", "CSVQA"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 364 (char 457). Line: 406.
Append: [CSVQA: A Chinese Multimodal Benchmark for Evaluating STEM Reasoning Capabilities of VLMs](https://arxiv.org/abs/2505.24120)
Token length: 1278
Summarized using qwen-turbo
Append: [Robot-R1：通过强化学习提升机器人视觉语言模型的具身推理能力](https://arxiv.org/abs/2506.00070)
Token length: 1178
Summarized using qwen-turbo
Append: [DINGO：一种高效且分布保持的约束解码策略](https://arxiv.org/abs/2505.23061)
Token length: 1511
Summarized using qwen-turbo
Append: [基于深度视频发现代理的长视频理解方法](https://arxiv.org/abs/2505.18079)
append_entries: 21
Finish: 2025-06-04 12:32:35.256445
------------------------------------------------------
Started: 2025-06-04 18:20:49.593966
Existing_entries: 1021
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1576
Summarized using qwen-turbo
Append: [MERIT与Coral：多条件语义检索的新突破](https://arxiv.org/abs/2506.03144)
Token length: 1534
Summarized using qwen-turbo
Append: [Dual-Expert Consistency Model：加速视频扩散模型采样并提升视觉质量](https://arxiv.org/abs/2506.03123)
Token length: 1191
Summarized using qwen-turbo
Append: [FuseLIP：基于早期融合的多模态嵌入架构](https://arxiv.org/abs/2506.03096)
Token length: 1223
Summarized using qwen-turbo
Append: [OThink-R1：优化大型推理模型中的冗余推理](https://arxiv.org/abs/2506.02397)
Token length: 994
Summarized using qwen-turbo
Append: [Qari-OCR：基于Qwen2-VL优化的阿拉伯文光学字符识别新突破](https://arxiv.org/abs/2506.02295)
Token length: 1122
Summarized using qwen-turbo
Append: [基于自挑战框架的大语言模型工具使用能力增强](https://arxiv.org/abs/2506.01716)
Token length: 1247
Summarized using qwen-turbo
Append: [SHARE: 基于分层动作修正的文本转SQL自纠错方法](https://arxiv.org/abs/2506.00391)
append_entries: 7
Finish: 2025-06-04 18:21:30.151834
------------------------------------------------------
Started: 2025-06-05 01:11:39.113024
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1212
Summarized using qwen-turbo
Append: [PoseFuse3D-KI：基于3D人体引导的可控关键帧插值框架](https://arxiv.org/abs/2506.03119)
Token length: 1003
Summarized using qwen-turbo
Append: [基于动态比例训练的高效语言推理方法](https://arxiv.org/abs/2506.02678)
Json decode failed:
{
  "title": "基于梯度驱动的角度感知强化微调框架提升大语言模型训练效率",
  "short_summary": "提出GAIN-RL框架，利用模型内在角度集中信号动态选择训练数据，显著提高大语言模型微调效率。",
  "summary": "当前针对大规模语言模型的强化微调方法由于均匀采样导致对相同查询的冗余暴露，表现出样本效率低的问题。虽然已有研究尝试通过启发式难度指标进行课程学习，但这些策略忽视了模型自身产生的内在学习信号，从而导致次优训练方案。本文发现一种模型固有的角度集中信号，能够有效反映语言模型从特定数据中学习的能力，并证明了令牌隐藏状态向量的角度分布与梯度之间的理论相关性，揭示了对高角度集中数据的学习偏好。受此启发，我们提出了GAIN-RL框架，该框架通过利用模型的内在角度集中信号，在每轮训练中动态选择数据，确保一致的有影响力的梯度更新，显著提升了整体训练效率。实验评估表明，GAIN-RL（GRPO）在多种数学和编码任务及不同模型规模下实现了超过2.5倍的训练效率提升。此外，高效的采样使训练数据效率更高，在使用一半原始数据的情况下取得了比传统GRPO更好的性能。代码已发布于https:
  "keyword": ["大语言模型", "强化微调", "角度集中"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 400 (char 514). Line: 406.
Append: [Angles Don't Lie: Unlocking Training-Efficient RL Through the Model's Own Signals](https://arxiv.org/abs/2506.02281)
Token length: 1336
Summarized using qwen-turbo
Append: [LongGuide：通过任务分布引导提升长文本生成中的上下文学习性能](https://arxiv.org/abs/2506.01265)
Token length: 1369
Summarized using qwen-turbo
Append: [MoCA-Video：无需训练的视频语义混合框架](https://arxiv.org/abs/2506.01004)
Token length: 1014
Summarized using qwen-turbo
Append: [Ctrl-Crash：一种可控汽车碰撞视频生成模型](https://arxiv.org/abs/2506.00227)
Token length: 1208
Summarized using qwen-turbo
Append: [REAL: 通过强化学习提升大型语言模型代码生成质量](https://arxiv.org/abs/2505.22704)
append_entries: 7
Finish: 2025-06-05 01:12:37.792368
------------------------------------------------------
Started: 2025-06-05 06:22:31.644073
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1025
Summarized using qwen-turbo
Append: [Subject Fidelity Optimization：一种提升零样本主体驱动生成主体保真度的新框架](https://arxiv.org/abs/2506.03621)
Token length: 1119
Summarized using qwen-turbo
Append: [基于推理控制场的大规模推理模型可控长链推理研究](https://arxiv.org/abs/2506.00189)
append_entries: 2
Finish: 2025-06-05 06:22:43.307766
------------------------------------------------------
Started: 2025-06-05 12:30:14.853843
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1170
Summarized using qwen-turbo
Append: [LayerFlow：一种统一的层感知视频生成框架](https://arxiv.org/abs/2506.04228)
Token length: 1581
Summarized using qwen-turbo
Append: [Voyager：基于单张图像生成世界一致3D点云序列的视频扩散框架](https://arxiv.org/abs/2506.04225)
Token length: 1341
Summarized using qwen-turbo
Append: [ReVisual-R1：通过分阶段训练提升多模态大语言模型推理能力](https://arxiv.org/abs/2506.04207)
Token length: 1361
Summarized using qwen-turbo
Append: [SuperWriter-Agent：提升大语言模型长文本生成质量的新框架](https://arxiv.org/abs/2506.04180)
Json decode failed:
{
  "title": "基于Diffusion Transformer的图像编辑框架IEAP",
  "short_summary": "提出一种通过程序化分解指令实现复杂图像编辑的新方法IEAP。",
  "summary": "扩散模型在文本到图像生成方面取得了显著成就，但在指令驱动的图像编辑中面临重大挑战，尤其是在涉及大幅布局变化的结构性不一致编辑上表现不佳。针对这一问题，我们引入了Image Editing As Programs (IEAP)，这是一种基于Diffusion Transformer (DiT) 架构的统一图像编辑框架。IEAP通过还原论视角将复杂的编辑指令分解为一系列原子操作，每个操作由轻量级适配器实现并共享相同的DiT主干，专门处理特定类型的编辑。这些操作由基于视觉语言模型(VLM)的代理编程，共同支持任意且结构性不一致的转换。实验表明，IEAP在多种编辑场景的标准基准测试中显著优于现有技术，特别是在复杂多步指令的准确性及语义保真度方面表现优异。代码可在https:
  "keyword": ["图像编辑", "扩散模型", "指令驱动"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 352 (char 455). Line: 406.
Append: [Image Editing As Programs with Diffusion Models](https://arxiv.org/abs/2506.04158)
Json decode failed:
{
  "title": "基于快捷神经元分析的大语言模型公平性评估方法",
  "short_summary": "提出通过分析受污染模型自身机制来解决数据污染问题的方法。",
  "summary": "本文针对大语言模型（LLMs）评估中的数据污染问题展开研究。大多数现有评估依赖公共基准，但这些基准容易受到数据污染的影响，从而损害评估的公平性。尽管已有研究尝试通过构建动态基准来应对污染问题，但这通常成本高昂且具有周期性。我们的研究另辟蹊径，聚焦于分析受污染模型本身的机制。实验表明，受污染模型的过高估计可能源于训练过程中参数获取了捷径解决方案。为此，我们提出了通过对比和因果分析识别快捷神经元的新方法，并进一步设计了一种名为快捷神经元修补的评估方法，以抑制这些快捷神经元。实验验证了该方法在减轻污染方面的有效性。此外，我们的评估结果与最近发布的可信基准MixEval表现出极强的线性相关性（Spearman系数超过0.95），证明了此方法揭示模型真实能力的可靠性。我们还通过多种基准和超参数设置的实验展示了该方法的广泛适用性。代码已开源：https:
  "keyword": ["大语言模型", "数据污染", "快捷神经元"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 391 (char 480). Line: 406.
Append: [Establishing Trustworthy LLM Evaluation via Shortcut Neuron Analysis](https://arxiv.org/abs/2506.04142)
Token length: 1642
Summarized using qwen-turbo
Append: [MMR-V：视频多模态深度推理基准测试](https://arxiv.org/abs/2506.04141)
Token length: 1576
Summarized using qwen-turbo
Append: [基于大型语言模型的自主多智能体系统的信任、风险与安全管理](https://arxiv.org/abs/2506.04133)
Token length: 967
Summarized using qwen-turbo
Append: [Rectified Sparse Attention (ReSA)：高效长序列生成的新方法](https://arxiv.org/abs/2506.04108)
Json decode failed:
{
  "title": "AmbiK 数据集：厨房环境中机器人指令模糊性检测基准",
  "short_summary": "提出AmbiK数据集用于统一评估机器人指令模糊性检测方法。",
  "summary": "大型语言模型（LLMs）在具身代理中的主要应用是根据用户的自然语言指令进行行为规划，但在现实世界环境中处理模糊指令仍具挑战性。目前虽有多种任务模糊性检测方法，但缺乏统一比较的标准，因为它们基于不同的数据集。为此，我们提出了AmbiK数据集，这是一个完全文本化的数据集，专注于厨房环境中机器人接收到的模糊指令。AmbiK由大型语言模型辅助收集并经过人工验证，包含1000对模糊任务及其明确版本，按模糊类型（人类偏好、常识知识、安全性）分类，并附带环境描述、澄清问题与答案、用户意图及任务计划，总计2000项任务。我们希望AmbiK能帮助研究人员对模糊性检测方法进行标准化比较。AmbiK数据集可在https:
  "keyword": ["模糊性检测", "机器人指令", "数据集"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 318 (char 413). Line: 406.
Append: [AmbiK: Dataset of Ambiguous Tasks in Kitchen Environment](https://arxiv.org/abs/2506.04089)
Token length: 1897
Summarized using qwen-turbo
Append: [Rex-Thinker：通过显式推理提升物体指代任务的可解释性和可靠性](https://arxiv.org/abs/2506.04034)
Token length: 1167
Summarized using qwen-turbo
Append: [Adapting预训练模型以解决连续学习中的稳定性-可塑性权衡问题](https://arxiv.org/abs/2506.03956)
Token length: 1341
Summarized using qwen-turbo
Append: [Dual-Arch框架：解决连续学习中的稳定性与可塑性权衡问题](https://arxiv.org/abs/2506.03951)
Token length: 1193
Summarized using qwen-turbo
Append: [VisCode-200K：基于Python的可视化及自修正大规模指令调优数据集](https://arxiv.org/abs/2506.03930)
Token length: 1520
Summarized using qwen-turbo
Append: [主动学习中的超参数空间挑战与优化研究](https://arxiv.org/abs/2506.03817)
Token length: 1588
Summarized using qwen-turbo
Append: [视觉拼接能力对视觉语言模型安全性的挑战](https://arxiv.org/abs/2506.03614)
Json decode failed:
{
  "title": "开源双模态视觉语言模型MiMo-VL-7B-SFT与MiMo-VL-7B-RL",
  "short_summary": "两款新模型在多模态推理和视觉理解方面表现卓越。",
  "summary": "本文介绍了两个强大的开源视觉语言模型MiMo-VL-7B-SFT和MiMo-VL-7B-RL，这些模型在多项任务上表现出色。MiMo-VL-7B-RL在40项评估任务中有35项优于Qwen2.5-VL-7B，在OlympiadBench上得分59.4，超越了参数量高达78B的模型。在图形用户界面（GUI）定位应用中，该模型在OSWorld-G上的得分为56.1，甚至超过了专门设计的UI-TARS模型。训练过程结合了四阶段预训练（总计2.4万亿tokens）和混合对策略强化学习（MORL），整合了多样化的奖励信号。研究强调了在预训练阶段纳入高质量推理数据的重要性，并探讨了混合强化学习的优势及多领域优化挑战。此外，我们还提供了一个涵盖50多项任务的综合评估套件，以促进复现性和推动领域发展。模型检查点和完整评估套件可在https:
  "keyword": ["视觉语言模型", "多模态推理", "开源"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 382 (char 483). Line: 406.
Append: [MiMo-VL Technical Report](https://arxiv.org/abs/2506.03569)
Token length: 1583
Summarized using qwen-turbo
Append: [基于不对称双3D高斯点喷涂的野外图像三维重建](https://arxiv.org/abs/2506.03538)
Token length: 1442
Summarized using qwen-turbo
Append: [DenseDPO：提升文本到视频扩散模型训练的数据效率与性能](https://arxiv.org/abs/2506.03517)
Token length: 988
Summarized using qwen-turbo
Append: [RefEdit：基于指令的复杂场景图像编辑模型](https://arxiv.org/abs/2506.03448)
Token length: 1105
Summarized using qwen-turbo
Append: [LEAF: 提升CLIP文本编码器对抗鲁棒性的方法](https://arxiv.org/abs/2506.03355)
Token length: 1532
Summarized using qwen-turbo
Append: [通过一次微调释放大型语言模型的推理潜力](https://arxiv.org/abs/2506.03295)
Token length: 1447
Summarized using qwen-turbo
Append: [SVGenius：面向SVG处理的大规模基准测试](https://arxiv.org/abs/2506.03139)
Token length: 1581
Summarized using qwen-turbo
Append: [Critique-GRPO：结合自然语言反馈的强化学习优化框架](https://arxiv.org/abs/2506.03106)
Json decode failed:
{
  "title": "TalkingMachines：实时音频驱动的虚拟角色动画框架",
  "short_summary": "提出一种高效框架，将预训练视频生成模型转化为实时音频驱动的角色动画系统。",
  "summary": "本文介绍了一种名为TalkingMachines的高效框架，该框架通过整合大型语言模型（LLM）和视频生成基础模型，实现了自然对话体验。主要贡献包括：将SOTA图像到视频转换模型DiT适配为参数量达180亿的音频驱动化身生成模型；通过非对称知识蒸馏避免错误累积，实现无限视频流生成；设计高吞吐量、低延迟推理管道，采用设备分离、CUDA流重叠及冗余计算消除等优化技术。该框架可广泛应用于虚拟角色动画领域，详见演示视频：https:
  "keyword": ["虚拟角色", "音频驱动", "实时动画"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 229 (char 335). Line: 406.
Append: [TalkingMachines: Real-Time Audio-Driven FaceTime-Style Video via Autoregressive Diffusion Models](https://arxiv.org/abs/2506.03099)
Token length: 953
Summarized using qwen-turbo
Append: [基于回归模型的LLM自动评估框架](https://arxiv.org/abs/2506.02945)
Token length: 1823
Summarized using qwen-turbo
Append: [LongBioBench：一种用于评估长上下文语言模型的新基准](https://arxiv.org/abs/2506.02921)
Json decode failed:
{
  "title": "大型语言模型作为评判者时的自偏好偏差研究",
  "short_summary": "提出新的偏差度量方法DBG，用于评估大型语言模型的自偏好偏差。",
  "summary": "本文探讨了大型语言模型（LLMs）在担任评价者时表现出的自偏好偏差问题，即模型倾向于给自己生成的答案打更高分。传统方法通过比较模型对自己答案和他人工答案的评分差异来衡量偏差，但这种方法容易混淆模型的回答质量与偏差本身。为了解决这一问题，我们引入了黄金标准评分作为回答真实质量的代理，并提出了DBG评分方法，将模型对自身答案评分与黄金标准评分之间的差异作为偏差测量指标，从而有效排除了回答质量对偏差测量的干扰影响。基于此方法，我们进行了广泛的实验，评估了不同版本、规模和推理能力的语言模型的自偏好偏差，并进一步研究了影响及减轻这种偏差的因素，如响应文本风格和评价模型的后训练数据。此外，还从基于注意力机制的角度探索了自偏好偏差的潜在机制。我们的代码和数据可在https:
  "keyword": ["自偏好偏差", "大型语言模型", "DBG评分"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 349 (char 439). Line: 406.
Append: [Beyond the Surface: Measuring Self-Preference in LLM Judgments](https://arxiv.org/abs/2506.02592)
Token length: 1261
Summarized using qwen-turbo
Append: [基于扩散模型的数据增强策略解决知识蒸馏中的协变量偏移问题](https://arxiv.org/abs/2506.02294)
Token length: 1420
Summarized using qwen-turbo
Append: [通过神经符号代理解决流图解释难题](https://arxiv.org/abs/2506.01344)
Append: [Ψ-Sampler: Initial Particle Sampling for SMC-Based Inference-Time Reward Alignment in Score Models](https://arxiv.org/abs/2506.01320)
Append: [BenchHub: A Unified Benchmark Suite for Holistic and Customizable LLM Evaluation](https://arxiv.org/abs/2506.00482)
Append: [TimeHC-RL: Temporal-aware Hierarchical Cognitive Reinforcement Learning for Enhancing LLMs' Social Intelligence](https://arxiv.org/abs/2505.24500)
Append: [DLP: Dynamic Layerwise Pruning in Large Language Models](https://arxiv.org/abs/2505.23807)
Append: [DiffDecompose: Layer-Wise Decomposition of Alpha-Composited Images via Diffusion Transformers](https://arxiv.org/abs/2505.21541)
Append: [CASS: Nvidia to AMD Transpilation with Data, Models, and Benchmark](https://arxiv.org/abs/2505.16968)
append_entries: 36
Finish: 2025-06-05 12:33:31.407417
------------------------------------------------------
Started: 2025-06-06 01:11:42.633621
Existing_entries: 1036
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "基于交互式对象感知的复杂场景音频生成模型",
  "short_summary": "提出一种结合多模态注意力的对象感知音频生成模型。",
  "summary": "本文介绍了一种创新的交互式对象感知音频生成模型，该模型通过条件潜扩散模型将对象中心学习与图像区域关联起来，实现了对用户选定图像中的视觉对象生成对应声音的功能。测试阶段，模型利用图像分割技术允许用户在对象级别交互生成声音。理论分析表明，所提出的注意力机制能够近似测试时的分割掩码，从而确保生成的声音与选定对象对齐。定量和定性评估显示，该模型优于现有基线方法，实现了更好的对象与其关联声音的对齐效果。项目页面链接：https:
  "keyword": ["音频生成", "对象感知", "多模态"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 226 (char 309). Line: 406.
Append: [Sounding that Object: Interactive Object-Aware Image to Audio Generation](https://arxiv.org/abs/2506.04214)
Token length: 1109
Summarized using qwen-turbo
Append: [OpenThoughts项目推动开源推理模型发展](https://arxiv.org/abs/2506.04178)
Token length: 1300
Summarized using qwen-turbo
Append: [HTSC-2025：基于AI的高温超导材料基准数据集发布](https://arxiv.org/abs/2506.03837)
Token length: 1022
Summarized using qwen-turbo
Append: [CRAWLDoc：基于上下文关联的多源学术文档元数据提取方法](https://arxiv.org/abs/2506.03822)
Token length: 1414
Summarized using qwen-turbo
Append: [Orak：面向多类型游戏的大规模语言模型智能体基准测试平台](https://arxiv.org/abs/2506.03610)
Token length: 1070
Summarized using qwen-turbo
Append: [基于位置专家的推测解码优化大语言模型推理](https://arxiv.org/abs/2506.03566)
Token length: 1211
Summarized using qwen-turbo
Append: [Video-SKoT：一种领域自适应视频推理框架](https://arxiv.org/abs/2506.03525)
Json decode failed:
{
  "title": "IllumiCraft：结合几何线索的端到端扩散视频生成框架",
  "short_summary": "提出IllumiCraft框架，解决扩散模型在场景光照控制中的几何线索缺失问题。",
  "summary": "本文介绍了一种名为IllumiCraft的端到端扩散框架，该框架通过整合高动态范围（HDR）视频映射、随机照明变化的合成重光照帧以及3D点轨迹等互补输入，实现了对场景光照和视觉外观的有效控制。IllumiCraft不仅支持背景条件和文本条件下的视频重光照，还能生成时间上连贯且符合用户定义提示的高质量视频，相较于现有可控视频生成方法具有更高的保真度。项目页面：https:
  "keyword": ["扩散模型", "几何线索", "视频生成"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 201 (char 310). Line: 406.
Append: [IllumiCraft: Unified Geometry and Illumination Diffusion for Controllable Video Generation](https://arxiv.org/abs/2506.03150)
Token length: 1472
Summarized using qwen-turbo
Append: [CapSpeech：面向风格标注文本到语音合成的新基准](https://arxiv.org/abs/2506.02863)
Token length: 1456
Summarized using qwen-turbo
Append: [FLAIR：基于流模型的无训练变分框架用于逆向成像问题](https://arxiv.org/abs/2506.02680)
Json decode failed:
{
  "title": "FinChain：首个可验证链式金融推理基准测试",
  "short_summary": "FinChain是首个支持多步金融符号推理评估的基准测试。",
  "summary": "现有金融任务基准测试缺乏对符号推理多步过程的系统性评估，FinChain通过引入五类参数化模板覆盖54个主题及12个金融领域，提供可执行Python代码实现自动训练数据生成。同时提出ChainEval新指标评价最终答案与中间推理过程，发现顶级大模型在复杂金融推理方面仍有提升空间。所有资源开源于https:
  "keyword": ["金融推理", "符号推理", "链式思维"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 168 (char 260). Line: 406.
Append: [FinChain: A Symbolic Benchmark for Verifiable Chain-of-Thought Financial Reasoning](https://arxiv.org/abs/2506.02515)
Token length: 1604
Summarized using qwen-turbo
Append: [小语言模型在自主AI系统中的未来前景](https://arxiv.org/abs/2506.02153)
Json decode failed:
{
  "title": "RiOSWorld：评估基于多模态大语言模型的计算机操作代理安全风险的基准",
  "short_summary": "研究探讨多模态大语言模型在真实世界计算机应用中的安全风险评估问题。",
  "summary": "随着多模态大型语言模型(MLLMs)的快速发展，它们被越来越多地部署为能够完成复杂计算机任务的自主计算代理。然而，一个重要问题是：针对对话场景设计的安全风险原则能否有效转移到现实世界的计算机使用场景中？现有对基于MLLM的计算机使用代理的安全风险评估研究存在局限性，要么缺乏真实的交互环境，要么仅关注一两种特定的风险类型。为了应对这一挑战，我们引入了RiOSWorld，这是一个用于评估基于MLLM的代理在真实世界计算机操作中潜在风险的基准。该基准包含了涉及网页、社交媒体、多媒体、操作系统、电子邮件和办公软件等各类计算机应用的492项风险任务，并将其分为用户来源风险和环境风险两大类。此外，从风险目标意图和风险目标完成两个角度进行评估。通过在RiOSWorld上的大量实验表明，当前的计算机使用代理在真实场景中面临显著的安全风险。我们的研究强调了在真实计算机操作中对这些代理进行安全对齐的必要性和紧迫性，为开发可信的计算机使用代理提供了有价值的见解。RiOSWorld基准已公开发布在https:
  "keyword": ["多模态大语言模型", "计算机操作代理", "安全风险评估"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 464 (char 573). Line: 406.
Append: [RiOSWorld: Benchmarking the Risk of Multimodal Compter-Use Agents](https://arxiv.org/abs/2506.00618)
Token length: 1812
Summarized using qwen-turbo
Append: [Segment Policy Optimization: 中文标题](https://arxiv.org/abs/2505.23564)
append_entries: 14
Finish: 2025-06-06 01:13:01.990548
------------------------------------------------------
Started: 2025-06-06 06:22:40.563081
Existing_entries: 1014
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1370
Summarized using qwen-turbo
Append: [SparseMM：通过视觉注意力稀疏性优化多模态大语言模型推理](https://arxiv.org/abs/2506.05344)
Token length: 1591
Summarized using qwen-turbo
Append: [MINT-CoT：引入数学嵌入标记的视觉推理链式思维方法](https://arxiv.org/abs/2506.05331)
Token length: 1041
Summarized using qwen-turbo
Append: [CG-AV-Counting基准与AV-Reasoner模型提升视频计数能力](https://arxiv.org/abs/2506.05328)
Token length: 975
Summarized using qwen-turbo
Append: [基于PM-Loss的深度图优化提升3D高斯点云渲染质量](https://arxiv.org/abs/2506.05327)
Token length: 1416
Summarized using qwen-turbo
Append: [EOC-Bench：面向动态第一人称场景的对象中心认知评估基准](https://arxiv.org/abs/2506.05287)
Json decode failed:
{
  "title": "基于Rectified Point Flow的点云配准与形状组装统一方法",
  "short_summary": "提出一种统一参数化方法，将点云配准与形状组装视为条件生成问题。",
  "summary": "本文介绍了一种名为Rectified Point Flow的新方法，该方法通过连续点位速度场实现了点云配准和多部分形状组装的统一建模。与以往需要手动处理对称性的方法不同，Rectified Point Flow能够内在学习对称性，无需对称性标签。结合自监督编码器，该方法在六个基准测试中达到了新的性能高度，同时支持跨多样数据集的有效联合训练，有助于共享几何先验的学习，从而提升准确性。项目页面：https:
  "keyword": ["点云配准", "形状组装", "条件生成"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 218 (char 324). Line: 406.
Append: [Rectified Point Flow: Generic Point Cloud Pose Estimation](https://arxiv.org/abs/2506.05282)
Token length: 1338
Summarized using qwen-turbo
Append: [Micro-Act框架解决RAG系统中的知识冲突问题](https://arxiv.org/abs/2506.05278)
Token length: 1284
Summarized using qwen-turbo
Append: [基于流模型的可学习潜在空间对齐框架](https://arxiv.org/abs/2506.05240)
Token length: 1526
Summarized using qwen-turbo
Append: [Qwen3 Embedding系列：文本嵌入与重排序能力的重大突破](https://arxiv.org/abs/2506.05176)
Json decode failed:
{
  "title": "ComfyUI-Copilot：基于大型语言模型的AI艺术创作助手",
  "short_summary": "ComfyUI-Copilot通过智能推荐提升AI艺术创作平台ComfyUI的效率。",
  "summary": "本文介绍了一款名为ComfyUI-Copilot的插件，该插件由大型语言模型驱动，旨在提高ComfyUI这一开源AI艺术创作平台的可用性和效率。尽管ComfyUI具有灵活性和友好的用户界面，但对于新手来说仍存在一些挑战，如文档不足、模型配置错误以及工作流设计复杂等问题。ComfyUI-Copilot通过提供智能节点和模型推荐，以及自动化的一键式工作流构建功能来解决这些问题。系统的核心是一个分层多代理框架，其中包括一个中央助理代理负责任务分配，以及多个专门的工作代理处理不同的用途，这些代理得到了精心策划的ComfyUI知识库的支持，从而简化了调试和部署过程。我们通过离线定量评估和在线用户反馈验证了ComfyUI-Copilot的有效性，结果显示它能够准确推荐节点并加速工作流开发。此外，案例研究还表明，ComfyUI-Copilot降低了初学者的入门门槛，同时提升了有经验用户的效率。ComfyUI-Copilot安装包和演示视频可以在https:
  "keyword": ["AI艺术创作", "ComfyUI", "智能助手"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 442 (char 556). Line: 406.
Append: [ComfyUI-Copilot: An Intelligent Assistant for Automated Workflow Development](https://arxiv.org/abs/2506.05010)
Token length: 849
Summarized using qwen-turbo
Append: [开放源码社区广泛采用的Deepseek-R1-Distill系列模型性能评估波动性研究](https://arxiv.org/abs/2506.04734)
Token length: 1607
Summarized using qwen-turbo
Append: [STARE基准测试：评估多模态大语言模型的空间认知能力](https://arxiv.org/abs/2506.04633)
Token length: 1175
Summarized using qwen-turbo
Append: [MedAgentGYM：首个提升医学推理能力的LLM训练环境](https://arxiv.org/abs/2506.04405)
Token length: 1571
Summarized using qwen-turbo
Append: [RoboRefer：结合深度编码和强化微调的3D空间指代理解模型](https://arxiv.org/abs/2506.04308)
Token length: 1082
Summarized using qwen-turbo
Append: [基于固定大型语言模型的语言-图像对齐方法](https://arxiv.org/abs/2506.04209)
Token length: 1196
Summarized using qwen-turbo
Append: [基于多平面和全身扫描的CT图像自动异常定位与描述方法](https://arxiv.org/abs/2506.03238)
Token length: 1446
Summarized using qwen-turbo
Append: [StreamBP：一种高效且精确的长序列反向传播方法](https://arxiv.org/abs/2506.03077)
Token length: 1496
Summarized using qwen-turbo
Append: [FlexPainter：一种灵活多模态引导的高质量纹理生成方法](https://arxiv.org/abs/2506.02620)
Token length: 1358
Summarized using qwen-turbo
Append: [基于多模态输入的高保真语音驱动虚拟人像生成框架](https://arxiv.org/abs/2506.00830)
Token length: 1128
Summarized using qwen-turbo
Append: [自主代理中的上下文完整性研究：基于LLMs与强化学习的方法](https://arxiv.org/abs/2506.04245)
Json decode failed:
{
  "title": "VideoREPA：通过知识蒸馏提升文本到视频扩散模型的物理常识",
  "short_summary": "提出一种新框架VideoREPA，增强文本到视频模型的物理理解能力。",
  "summary": "近期，文本到视频（T2V）扩散模型在高保真视频合成方面取得了显著进展，但因对物理理解能力有限，常难以生成符合物理规律的内容。研究表明，T2V模型的表示虽具备一定物理理解潜力，但仍远不及视频自监督学习方法。为此，我们开发了一种名为VideoREPA的新框架，通过令牌级关系对齐，将视频理解基础模型中的物理理解能力传递至T2V模型，有效弥补物理理解差距。VideoREPA引入了Token Relation Distillation (TRD)损失函数，利用时空对齐提供适于微调的强大预训练T2V模型的软指导。作为首个针对T2V模型设计的REPA方法，VideoREPA显著提升了基线方法CogVideoX的物理常识，大幅改进相关基准测试的表现，并展示了生成符合直观物理规律视频的强大能力。更多视频示例可访问https:
  "keyword": ["文本到视频", "物理理解", "知识蒸馏"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 373 (char 478). Line: 406.
Append: [VideoREPA: Learning Physics for Video Generation through Relational Alignment with Foundation Models](https://arxiv.org/abs/2505.23656)
Token length: 1749
Summarized using qwen-turbo
Append: [引入可编辑几何和保真外观扩散模型用于目标对象合成](https://arxiv.org/abs/2505.20914)
append_entries: 22
Finish: 2025-06-06 06:25:01.965965
------------------------------------------------------
Started: 2025-06-06 12:29:15.970067
Existing_entries: 1022
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "VideoMathQA：评估视频跨模态数学推理的新基准",
  "short_summary": "引入VideoMathQA，用于评估模型在视频中的长时间跨模态数学推理能力。",
  "summary": "VideoMathQA是一项新设计的基准测试，旨在评估机器学习模型是否能在真实世界视频环境中进行复杂的跨模态数学推理。该基准涵盖10个不同的数学领域，涉及从10秒到超过1小时的多样化视频内容。它不仅要求模型解读结构化的视觉信息，理解教学叙述，还需在视觉、音频和文本三种模态间联合定位概念。为了保证高质量，该基准由研究生水平的专家完成，总标注时间为920人时以上。问题设计围绕直接问题求解、概念迁移和深度教学理解三大核心推理挑战展开，每道题均包含多步推理注释，以精细诊断模型能力。通过此基准，我们揭示了现有方法的局限性，并建立了系统性的评估框架，适用于需要长时间跨模态推理的数学问题场景。相关资源可在https:
  "keyword": ["数学推理", "跨模态", "视频"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 320 (char 424). Line: 406.
Append: [VideoMathQA: Benchmarking Mathematical Reasoning via Multimodal Understanding in Videos](https://arxiv.org/abs/2506.05349)
Token length: 1017
Summarized using qwen-turbo
Append: [FreeTimeGS：一种用于复杂动态场景重建的4D表示方法](https://arxiv.org/abs/2506.05348)
Token length: 1333
Summarized using qwen-turbo
Append: [通过动态内存稀疏化提升Transformer大模型推理精度](https://arxiv.org/abs/2506.05345)
Token length: 1351
Summarized using qwen-turbo
Append: [SeedVR2：基于扩散模型的一阶段高分辨率视频修复方法](https://arxiv.org/abs/2506.05301)
Token length: 907
Summarized using qwen-turbo
Append: [基于几何引导长期空间记忆的视频世界模型一致性增强](https://arxiv.org/abs/2506.05284)
Token length: 1155
Summarized using qwen-turbo
Append: [Diagonal Batching优化循环记忆Transformer模型的长上下文推理](https://arxiv.org/abs/2506.05229)
Token length: 1248
Summarized using qwen-turbo
Append: [基于开源许可文本的大规模语言模型训练数据集Common Pile v0.1发布](https://arxiv.org/abs/2506.05209)
Token length: 1291
Summarized using qwen-turbo
Append: [基于技能感知的时间采样方法提升运动技能自动化评估](https://arxiv.org/abs/2506.04996)
Token length: 812
Summarized using qwen-turbo
Append: [Surfer-H：结合视觉语言模型的高效网络代理](https://arxiv.org/abs/2506.02865)
Json decode failed:
{
  "title": "RobustSplat：针对瞬态物体优化的3D Gaussian Splatting方法",
  "short_summary": "提出RobustSplat，解决3D Gaussian Splatting中因瞬态物体导致的渲染伪影问题。",
  "summary": "本文探讨了3D Gaussian Splatting（3DGS）在新视图合成和3D建模中的实时、照片级真实感渲染优势，但现有方法在处理受瞬态物体影响的场景时存在困难，容易产生渲染伪影。研究发现，高斯密度增强过程虽然提升了场景细节捕获能力，却无意间通过增加对瞬态干扰建模的高斯分布，加剧了伪影问题。为解决此问题，我们提出了RobustSplat，采用两种关键设计：首先，引入延迟高斯增长策略，优先优化静态场景结构，避免早期优化过程中过度拟合瞬态物体；其次，设计了尺度级联掩码引导方法，利用低分辨率特征相似性监督实现初始瞬态掩码的可靠估计，并逐步过渡到高分辨率监督以获得更精确的掩码预测。多项挑战性数据集上的实验表明，我们的方法显著优于现有技术，充分验证了其鲁棒性和有效性。项目页面可访问https:
  "keyword": ["3D Gaussian Splatting", "瞬态物体", "渲染伪影"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 363 (char 499). Line: 406.
Append: [RobustSplat: Decoupling Densification and Dynamics for Transient-Free 3DGS](https://arxiv.org/abs/2506.02751)
Token length: 1351
Summarized using qwen-turbo
Append: [基于鸟瞰图特征的LiDAR-相机标定模型BEVCALIB](https://arxiv.org/abs/2506.02587)
Token length: 1401
Summarized using qwen-turbo
Append: [面向自回归图像生成模型的抗再生攻击水印框架](https://arxiv.org/abs/2506.01011)
Token length: 959
Summarized using qwen-turbo
Append: [基于扩散模型的3D占用预测在自动驾驶中的应用](https://arxiv.org/abs/2505.23115)
append_entries: 13
Finish: 2025-06-06 12:30:26.783007
------------------------------------------------------
Started: 2025-06-06 18:20:50.647348
Existing_entries: 1013
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "Search Arena: 大规模多轮交互搜索增强语言模型的人类偏好数据集",
  "short_summary": "提出大规模多轮交互用户与搜索增强语言模型的配对数据集Search Arena。",
  "summary": "本文介绍了一个名为Search Arena的大规模人类偏好数据集，该数据集包含超过24,000组多轮用户与搜索增强语言模型（SALMs）的交互记录，涵盖了多种意图和语言。数据集中包含约12,000个人类偏好投票，并提供了完整的系统跟踪记录。分析显示，用户的偏好受引用数量的影响，即使引用内容并未直接支持相关主张，也揭示了感知可信度与实际可信度之间的差距。此外，不同来源的引用对用户偏好有显著影响，社区驱动平台通常更受欢迎，而静态百科全书并非总是可靠。进一步研究发现，在非搜索场景中，网络搜索不仅不会降低性能，还可能提升表现；但在搜索密集型场景下，单纯依赖模型的参数化知识会导致质量大幅下降。为了支持该领域的未来研究，本文开源了此数据集，相关资源可在https:
  "keyword": ["搜索增强", "语言模型", "人类偏好"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 345 (char 460). Line: 406.
Append: [Search Arena: Analyzing Search-Augmented LLMs](https://arxiv.org/abs/2506.05334)
Token length: 1063
Summarized using qwen-turbo
Append: [基于CLIP空间的材料编辑方法MARBLE](https://arxiv.org/abs/2506.05313)
Token length: 1359
Summarized using qwen-turbo
Append: [FEAT：一种高效的全维度注意力Transformer用于动态医学视频合成](https://arxiv.org/abs/2506.04956)
Token length: 1881
Summarized using qwen-turbo
Append: [基于缩放定律的语言视觉模型CLIP与MaMMUT的比较研究](https://arxiv.org/abs/2506.04598)
Token length: 1512
Summarized using qwen-turbo
Append: [通过推理对齐的视觉描述优化提升多模态大语言模型性能](https://arxiv.org/abs/2506.04559)
Token length: 1697
Summarized using qwen-turbo
Append: [大型语言模型水印技术对对齐属性的影响及改进方法](https://arxiv.org/abs/2506.04462)
Token length: 1144
Summarized using qwen-turbo
Append: [DOVE：一种动态视觉编码器实现高效语义特征提取](https://arxiv.org/abs/2506.03643)
Token length: 1552
Summarized using qwen-turbo
Append: [同步扩散框架生成高保真手物交互视频与运动序列](https://arxiv.org/abs/2506.02444)
Token length: 966
Summarized using qwen-turbo
Append: [自监督模型学习的语言特异性语音表征研究](https://arxiv.org/abs/2506.00981)
append_entries: 9
Finish: 2025-06-06 18:21:40.881712
------------------------------------------------------
Started: 2025-06-07 01:10:49.864619
Existing_entries: 1009
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1541
Summarized using qwen-turbo
Append: [重新审视测试时间扩展定律：基于稀疏注意力的新范式](https://arxiv.org/abs/2506.05333)
Token length: 1569
Summarized using qwen-turbo
Append: [FlowDirector：无需反演的数据空间文本驱动视频编辑框架](https://arxiv.org/abs/2506.05046)
append_entries: 2
Finish: 2025-06-07 01:10:58.990507
------------------------------------------------------
Started: 2025-06-07 06:19:34.009635
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-07 06:19:34.245572
------------------------------------------------------
Started: 2025-06-07 12:26:41.108914
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-07 12:26:41.349761
------------------------------------------------------
Started: 2025-06-07 18:18:39.390847
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-07 18:18:39.665178
------------------------------------------------------
Started: 2025-06-08 01:18:22.935447
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-08 01:18:23.149068
------------------------------------------------------
Started: 2025-06-08 06:20:47.225688
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Fetch error: HTTPSConnectionPool(host='rsshub.app', port=443): Read timed out. (read timeout=30)
Fetch failed from https://rsshub.app/huggingface/daily-papers
append_entries: 0
error when rendering xml, skip docs/Huggingface-Daliy-Papers
------------------------------------------------------
Started: 2025-06-08 12:26:57.144363
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-08 12:26:57.367733
------------------------------------------------------
Started: 2025-06-08 18:18:39.189233
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-08 18:18:39.449999
------------------------------------------------------
Started: 2025-06-09 01:15:41.521341
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-09 01:15:41.753449
------------------------------------------------------
Started: 2025-06-09 06:23:26.558345
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-09 06:23:26.821109
------------------------------------------------------
Started: 2025-06-09 12:30:01.084406
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1858
Summarized using qwen-turbo
Append: [基于3D光流的世界模型实现跨机器人操控技能迁移](https://arxiv.org/abs/2506.06199)
Token length: 1048
Summarized using qwen-turbo
Append: [基于音频感知大语言模型的演讲风格自动评估](https://arxiv.org/abs/2506.05984)
Token length: 799
Summarized using qwen-turbo
Append: [基于输入依赖软提示的参数高效微调方法](https://arxiv.org/abs/2506.05629)
Json decode failed:
{
  "title": "基于跨模态融合的高质量音频描述生成方法",
  "short_summary": "提出一种结合多模态信息的两阶段音频描述生成新方法。",
  "summary": "本文针对现有自动化音频描述生成方法细节不足、上下文准确性差的问题，受到人类听觉感知整合多模态线索的启发，设计了一种新的两阶段自动管道。首先利用预训练模型提取多样化上下文线索（如语音、音乐、环境音及关联视频的视觉信息），然后通过大型语言模型整合这些丰富的多模态输入生成详尽且上下文敏感的音频描述。本研究贡献包括：一种可扩展的细粒度音频描述生成方法；FusionAudio数据集，包含120万条详尽描述和600万组问答对；以及基于FusionAudio开发的增强型音频模型，特别是具有卓越音频文本对齐和指令跟随能力的CLAP基础音频编码器。该研究为复杂音频环境的精细化自动化理解奠定了基础。相关代码和数据可在https:
  "keyword": ["音频描述", "跨模态融合", "FusionAudio"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 323 (char 406). Line: 406.
Append: [FusionAudio-1.2M: Towards Fine-grained Audio Captioning with Multimodal Contextual Fusion](https://arxiv.org/abs/2506.01111)
append_entries: 4
Finish: 2025-06-09 12:30:23.388314
------------------------------------------------------
Started: 2025-06-09 18:21:22.649183
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1468
Summarized using qwen-turbo
Append: [STARFlow：基于归一化流的高分辨率图像合成生成模型](https://arxiv.org/abs/2506.06276)
Json decode failed:
{
  "title": "从第一人称到第三人称视角：视频理解的双重视角综述",
  "short_summary": "综述从第一人称和第三人称视角进行视频理解的研究进展。",
  "summary": "本文对视频理解从第一人称（自我中心）和第三人称（外中心）视角进行了全面回顾。首先强调了整合这两种技术的实际应用及其跨领域的潜在协作可能性，并确定实现这些应用的关键研究任务。接着系统性地组织并审查了近年来在三个主要研究方向上的最新进展：一是利用第一人称数据增强第三人称理解；二是运用第三人称数据改善第一人称分析；三是统一两种视角的联合学习框架。此外，讨论了支持这两种视角研究的基准数据集，评估其范围、多样性和适用性。最后，探讨了现有工作的局限性并提出了有前景的未来研究方向。通过综合两种视角的见解，我们的目标是推动视频理解和人工智能的进步，使机器更接近人类的感知方式。相关工作GitHub仓库地址为https:
  "keyword": ["视频理解", "第一人称视角", "第三人称视角"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 319 (char 408). Line: 406.
Append: [Bridging Perspectives: A Survey on Cross-view Collaborative Intelligence with Egocentric-Exocentric Vision](https://arxiv.org/abs/2506.06253)
Token length: 1309
Summarized using qwen-turbo
Append: [基于大语言模型的编程竞赛测试用例生成系统](https://arxiv.org/abs/2506.05817)
Token length: 1586
Summarized using qwen-turbo
Append: [PartCrafter：基于单张RGB图像的多部件3D网格联合生成模型](https://arxiv.org/abs/2506.05573)
Token length: 1916
Summarized using qwen-turbo
Append: [MORSE-500：多模态推理新基准推动视觉语言模型发展](https://arxiv.org/abs/2506.05523)
Json decode failed:
{
  "title": "Sentinel：基于ModernBERT-large的大语言模型提示注入攻击检测系统",
  "short_summary": "提出Sentinel模型，有效检测大语言模型的提示注入攻击。",
  "summary": "本文介绍了一种名为Sentinel的新检测模型，用于应对大语言模型（LLMs）面临的提示注入攻击问题。Sentinel基于\answerdotai/ModernBERT-large架构，通过在涵盖多种开源和私有数据集的多样化训练数据上进行微调，实现了最先进的性能。这些数据集包含了各种攻击类型，如角色扮演、指令劫持及偏见内容生成尝试，同时结合了广泛的良性指令。此外，还特别设计了针对细微错误修正和实际误分类的私有数据集。在内部测试集上，Sentinel平均准确率为0.987，F1分数为0.980；在公开基准测试中也优于其他强基线模型如protectai/deberta-v3-base-prompt-injection-v2。文章详细描述了Sentinel的架构设计、数据集构建过程、训练方法及其卓越的检测能力评估。",
  "keyword": ["大语言模型", "提示注入攻击", "Sentinel"]
}Summarization failed, append the original article
error: Invalid \escape: line 4 column 76 (char 188). Line: 406.
Append: [Sentinel: SOTA model to protect against prompt injections](https://arxiv.org/abs/2506.05446)
Token length: 1787
Summarized using qwen-turbo
Append: [Prefix Grouper：一种高效增强版Group Relative Policy Optimization算法](https://arxiv.org/abs/2506.05433)
Token length: 1749
Summarized using qwen-turbo
Append: [通过认知激活潜力优化多模态大语言模型推理能力的数据选择方法](https://arxiv.org/abs/2506.04755)
Token length: 1363
Summarized using qwen-turbo
Append: [一种结合光场渲染与物理模拟的实时机器人仿真框架](https://arxiv.org/abs/2506.04120)
Token length: 1138
Summarized using qwen-turbo
Append: [探究多模态语言模型向全模态扩展的可行性](https://arxiv.org/abs/2506.01872)
Token length: 1708
Summarized using qwen-turbo
Append: [HASHIRU：一种灵活且高效的多智能体系统框架](https://arxiv.org/abs/2506.04255)
Token length: 998
Summarized using qwen-turbo
Append: [GUIDEX：提升零样本信息抽取性能的新方法](https://arxiv.org/abs/2506.00649)
Token length: 879
Summarized using qwen-turbo
Append: [EverGreenQA：首个带时间稳定性标签的多语言问答数据集及其应用](https://arxiv.org/abs/2505.21115)
append_entries: 13
Finish: 2025-06-09 18:22:28.055032
------------------------------------------------------
Started: 2025-06-10 01:13:11.857033
Existing_entries: 1013
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1920
Summarized using qwen-turbo
Append: [MIRIAD：构建高质量医疗知识库以提升大语言模型可靠性](https://arxiv.org/abs/2506.06091)
Token length: 1385
Summarized using qwen-turbo
Append: [从模型中心到数据中心：AI图像生成领域的范式转变](https://arxiv.org/abs/2506.05673)
Token length: 1197
Summarized using qwen-turbo
Append: [AI推理知识转移能力的评估与优化](https://arxiv.org/abs/2506.05579)
Token length: 1505
Summarized using qwen-turbo
Append: [缓解视觉场景文本理解中的语义幻觉问题](https://arxiv.org/abs/2506.05551)
Token length: 1173
Summarized using qwen-turbo
Append: [基于AI工业资产生命周期管理的下一代自动化系统](https://arxiv.org/abs/2506.03828)
Token length: 1348
Summarized using qwen-turbo
Append: [Simba: 通过层次化稀疏化提升状态空间模型性能](https://arxiv.org/abs/2505.20698)
append_entries: 6
Finish: 2025-06-10 01:13:41.532483
------------------------------------------------------
Started: 2025-06-10 06:21:41.874296
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1660
Summarized using qwen-turbo
Append: [引入自省与纠错能力的端到端多模态GUI自动化框架](https://arxiv.org/abs/2506.08012)
Token length: 942
Summarized using qwen-turbo
Append: [强化预训练（RPT）：语言模型与强化学习的新范式](https://arxiv.org/abs/2506.08007)
Token length: 1345
Summarized using qwen-turbo
Append: [小规模语言模型在长链式思维训练中的性能退化现象](https://arxiv.org/abs/2506.07712)
Token length: 1685
Summarized using qwen-turbo
Append: [GTR-Mol-VLM：基于图遍历机制的光学化学结构识别框架](https://arxiv.org/abs/2506.07553)
Json decode failed:
{
  "title": "BitVLA：首个用于机器人操作的1比特视觉-语言-动作模型",
  "short_summary": "提出首个1比特视觉-语言-动作模型BitVLA，在资源受限设备上实现高效推理。",
  "summary": "近年来，视觉-语言-动作（Vision-Language-Action, VLA）模型在机器人操作任务中展现出强大的能力，但其庞大的模型规模对资源受限的机器人系统部署提出了挑战。尽管1比特预训练已被证明可以有效提升大型语言模型的推理效率且性能损失极小，但其在VLA模型中的应用尚未得到充分探索。本研究推出了BitVLA，这是首个用于机器人操作的1比特VLA模型，其中每个参数均为三值参数（{-1, 0, 1}）。此外，为了进一步减少视觉编码器的内存占用，我们提出了蒸馏感知训练策略，将全精度编码器压缩至1.58比特权重。尽管缺乏大规模机器人预训练，BitVLA在LIBERO基准测试中通过4比特后量化实现了与最先进的OpenVLA-OFT模型相当的性能，同时仅需后者29.8%的内存。这些结果表明BitVLA在边缘设备上的部署前景广阔。相关代码和模型权重已在https:
  "keyword": ["机器人操作", "视觉-语言-动作模型", "1比特量化"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 400 (char 508). Line: 406.
Append: [BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation](https://arxiv.org/abs/2506.07530)
Token length: 1918
Summarized using qwen-turbo
Append: [Lingshu：面向医学应用的多模态大型语言模型](https://arxiv.org/abs/2506.07044)
append_entries: 6
Finish: 2025-06-10 06:22:15.667786
------------------------------------------------------
Started: 2025-06-10 12:30:33.995512
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-10 12:30:34.214395
------------------------------------------------------
Started: 2025-06-10 18:20:33.638170
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1367
Summarized using qwen-turbo
Append: [无需重训的视觉Transformer测试时异常值抑制方法](https://arxiv.org/abs/2506.08010)
Token length: 1258
Summarized using qwen-turbo
Append: [通过视觉游戏学习提升多模态大型语言模型的泛化推理能力](https://arxiv.org/abs/2506.08011)
Token length: 1195
Summarized using qwen-turbo
Append: [Dreamland：结合物理模拟器与生成模型的混合世界生成框架](https://arxiv.org/abs/2506.08006)
Token length: 1303
Summarized using qwen-turbo
Append: [Temperature-Adjusted Cross-modal Attention提升文本到图像扩散模型的对齐效果](https://arxiv.org/abs/2506.07986)
Token length: 1560
Summarized using qwen-turbo
Append: [OneIG-Bench：文本到图像模型的综合性评估基准](https://arxiv.org/abs/2506.07977)
Token length: 1808
Summarized using qwen-turbo
Append: [MiniCPM4：面向端侧设备的高效大型语言模型](https://arxiv.org/abs/2506.07900)
Token length: 1395
Summarized using qwen-turbo
Append: [PolyVivid：多主体视频定制框架实现精确身份控制](https://arxiv.org/abs/2506.07848)
Json decode failed:
{
  "title": "概念感知微调(CAFT)：重塑大语言模型学习方式",
  "short_summary": "引入概念感知微调方法，提升大语言模型的高阶概念理解能力。",
  "summary": "大型语言模型(LLMs)虽然已成为现代人工智能的核心，但其基于下一词预测的传统范式限制了它们形成连贯高阶概念的能力，阻碍了人类般的理解和推理发展。以“核糖核酸”为例，现有方法将其分解为多个片段进行逐一代入学习，而非作为一个整体语义实体处理。为解决这一问题，我们提出概念感知微调(CAFT)，这是一种全新的多令牌训练方法，重新定义了LLMs的微调过程。通过允许跨多个令牌序列的学习，该方法促进了更强的概念感知学习能力。实验表明，CAFT在文本摘要、蛋白质从头设计等任务中显著优于传统微调方法。此前，多令牌预测仅能在昂贵的预训练阶段实现，而CAFT首次将多令牌设置引入到微调阶段，使更多研究者受益。我们的方法不仅展示了在具体任务上的性能提升，还可能对机器学习研究领域产生更广泛的影响。所有代码和数据可在https:
  "keyword": ["大语言模型", "概念感知", "微调"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 370 (char 461). Line: 406.
Append: [Improving large language models with concept-aware fine-tuning](https://arxiv.org/abs/2506.07833)
Token length: 1145
Summarized using qwen-turbo
Append: [通过图像重建解析视觉特征编码器](https://arxiv.org/abs/2506.07803)
Token length: 1086
Summarized using qwen-turbo
Append: [大型语言模型对低资源语言的漏洞分析](https://arxiv.org/abs/2506.07645)
Token length: 1849
Summarized using qwen-turbo
Append: [通过ReLIFT提升大语言模型推理能力](https://arxiv.org/abs/2506.07527)
Token length: 1005
Summarized using qwen-turbo
Append: [SpatialLM：基于标准多模态LLM架构的3D场景理解模型](https://arxiv.org/abs/2506.07491)
Token length: 1487
Summarized using qwen-turbo
Append: [CCI4.0：构建高质量双语预训练数据集及其应用](https://arxiv.org/abs/2506.07463)
Token length: 1180
Summarized using qwen-turbo
Append: [弱到强解码框架提升大语言模型对齐能力](https://arxiv.org/abs/2506.07434)
Token length: 1203
Summarized using qwen-turbo
Append: [通过ConfQA策略降低大语言模型事实性陈述幻觉率](https://arxiv.org/abs/2506.07309)
Token length: 1146
Summarized using qwen-turbo
Append: [利用预训练语言模型通过上下文学习预测隐马尔可夫模型生成序列](https://arxiv.org/abs/2506.07298)
Token length: 1216
Summarized using qwen-turbo
Append: [通过内部进度编码优化大型语言模型的显式推理过程](https://arxiv.org/abs/2506.07240)
Token length: 1610
Summarized using qwen-turbo
Append: [GeometryZero：通过强化学习优化几何问题求解的辅助构造](https://arxiv.org/abs/2506.07160)
Token length: 1914
Summarized using qwen-turbo
Append: [大型推理模型的性能与局限性分析](https://arxiv.org/abs/2506.06941)
Token length: 1198
Summarized using qwen-turbo
Append: [通过元学习提升多模态大模型的小样本任务适应能力](https://arxiv.org/abs/2506.06905)
Token length: 1078
Summarized using qwen-turbo
Append: [大型语言模型在上下文与记忆冲突下的表现评估框架](https://arxiv.org/abs/2506.06485)
Token length: 1901
Summarized using qwen-turbo
Append: [面向LLM推理阶段的安全保障：SAFFRON范式的提出](https://arxiv.org/abs/2506.06444)
Token length: 1490
Summarized using qwen-turbo
Append: [通过自学习训练KV缓存以降低大语言模型长上下文推理成本](https://arxiv.org/abs/2506.06266)
Token length: 1198
Summarized using qwen-turbo
Append: [Astra双模型架构提升机器人室内导航性能](https://arxiv.org/abs/2506.06205)
Token length: 1435
Summarized using qwen-turbo
Append: [基于语言表达动作的视觉-语言基础模型世界模型与动力学模型研究](https://arxiv.org/abs/2506.06006)
Token length: 1142
Summarized using qwen-turbo
Append: [基于合成对话数据的实时感知任务引导对话系统](https://arxiv.org/abs/2506.05904)
Token length: 1013
Summarized using qwen-turbo
Append: [大型语言模型在辩论演讲评估中的表现分析](https://arxiv.org/abs/2506.05062)
Json decode failed:
{
  "title": "MegaHan97K：面向汉字 mega-category 的大规模数据集",
  "short_summary": "提出首个支持GB18030-2022标准的大规模汉字数据集MegaHan97K。",
  "summary": "汉字作为中国文化的重要组成部分，具有极其广泛的类别，最新的GB18030-2022标准包含了87,887个类别，其大规模类别识别（mega-category recognition）对文化遗产保护和数字应用至关重要。然而，由于缺乏综合性的数据集，现有最大数据集仅涵盖16,151个类别。针对这一问题，我们推出了MegaHan97K，该数据集包含97,455个汉字类别，首次全面支持GB18030-2022标准，且覆盖类别数量是现有数据集的至少六倍。通过手写、历史和合成三个子集，MegaHan97K有效解决了类别分布不均的问题。此外，基准实验揭示了mega-category场景下的新挑战，如存储需求增加、形态相似字符识别难度提高及零样本学习困难等，同时为未来研究提供了新的机遇。据我们所知，MegaHan97K可能是OCR领域乃至模式识别领域类别数最多的数据集之一。数据集可通过https:
  "keyword": ["汉字", "数据集", "OCR"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 411 (char 527). Line: 406.
Append: [MegaHan97K: A Large-Scale Dataset for Mega-Category Chinese Character Recognition with over 97K Categories](https://arxiv.org/abs/2506.04807)
Token length: 1336
Summarized using qwen-turbo
Append: [gamma-PO算法提升大语言模型对齐效率](https://arxiv.org/abs/2506.03690)
Token length: 1442
Summarized using qwen-turbo
Append: [ExpertLongBench：面向专家级任务的大规模语言模型评估基准](https://arxiv.org/abs/2506.01241)
Append: [EVOREFUSE: Evolutionary Prompt Optimization for Evaluation and Mitigation of LLM Over-Refusal to Pseudo-Malicious Instructions](https://arxiv.org/abs/2505.23473)
append_entries: 31
Finish: 2025-06-10 18:22:55.225041
------------------------------------------------------
Started: 2025-06-11 01:12:43.401013
Existing_entries: 1031
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1074
Summarized using qwen-turbo
Append: [无需权重更新的动态视图合成](https://arxiv.org/abs/2506.08004)
Token length: 1414
Summarized using qwen-turbo
Append: [tau^2-bench：引入双控环境评估对话AI代理](https://arxiv.org/abs/2506.07982)
Token length: 1660
Summarized using qwen-turbo
Append: [CyberV：基于控制论的视频多模态大语言模型自适应框架](https://arxiv.org/abs/2506.07971)
Token length: 1755
Summarized using qwen-turbo
Append: [SAFEFLOW：构建可信大型语言模型及视觉语言模型驱动代理的新框架](https://arxiv.org/abs/2506.07564)
Token length: 1512
Summarized using qwen-turbo
Append: [基于自适应提升循环的机器人视觉规划模型在线学习方法](https://arxiv.org/abs/2506.06658)
Token length: 1050
Summarized using qwen-turbo
Append: [SynthesizeMe：基于用户交互生成合成人格以实现个性化奖励建模](https://arxiv.org/abs/2506.05598)
Token length: 1283
Summarized using qwen-turbo
Append: [大型语言模型在策略规划中的自适应进化研究](https://arxiv.org/abs/2506.04651)
Token length: 1468
Summarized using qwen-turbo
Append: [多模态大语言模型在隐含推理场景中的表现分析](https://arxiv.org/abs/2506.00258)
Token length: 854
Summarized using qwen-turbo
Append: [基于条件数分析的模型免疫框架及其应用](https://arxiv.org/abs/2505.23760)
append_entries: 9
Finish: 2025-06-11 01:13:38.418502
------------------------------------------------------
Started: 2025-06-11 06:21:51.285678
Existing_entries: 1009
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1494
Summarized using qwen-turbo
Append: [基于正交匹配追踪的预训练语言模型跨分词器移植方法](https://arxiv.org/abs/2506.06607)
Json decode failed:
{
  "title": "NetPress：用于网络应用中大语言模型评估的自动化基准生成框架",
  "short_summary": "NetPress框架动态生成大规模查询集，支持可靠的大语言模型评估。",
  "summary": "尽管对特定领域大型语言模型(LLMs)及其代理的基准测试兴趣日益增长，但当前评估仍局限于静态的小规模数据集，尤其是在像网络操作这样高风险的任务中。我们提出了NetPress，这是一种自动化的基准生成框架，用于评估网络应用中的LLM代理。NetPress通过引入状态和动作的统一抽象，能够动态生成多样化的查询集合及其对应的地面真实值。运行时，用户可以指定基准配置以即时生成数百万个查询。除了动态基准构建外，NetPress还集成了网络模拟器以提供真实的环境反馈，从而支持在正确性、安全性及延迟方面的全面评估。我们在三个代表性应用上实例化了NetPress，揭示了静态、仅关注正确性的基准常常遗漏的代理行为的细微差异。NetPress推动了基础设施为中心的领域中现实且可扩展的LLM评估，有助于缩小基准性能与实际部署就绪性之间的差距。代码可在https:
  "keyword": ["大语言模型", "自动化基准", "网络应用"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 390 (char 496). Line: 406.
Append: [NetPress: Dynamically Generated LLM Benchmarks for Network Applications](https://arxiv.org/abs/2506.03231)
append_entries: 2
Finish: 2025-06-11 06:22:00.782513
------------------------------------------------------
Started: 2025-06-11 12:30:20.660647
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1325
Summarized using qwen-turbo
Append: [DiscoVLA：针对视频文本检索的CLIP参数高效适配方法](https://arxiv.org/abs/2506.08887)
Token length: 1334
Summarized using qwen-turbo
Append: [自回归视频扩散模型的新训练范式：Self Forcing](https://arxiv.org/abs/2506.08009)
Json decode failed:
{
  "title": "基于统一LLM框架的3D场景生成与多模态对齐研究",
  "short_summary": "提出一种结合语言、图像和3D场景的统一LLM框架，用于多模态对齐和3D任务处理。",
  "summary": "本文探索了自回归模型在结构化3D场景建模中的潜力，通过构建一个统一的语言-图像-3D场景框架，解决了数据表示、特定模态目标等关键设计问题。该框架在四个核心3D任务（渲染、识别、指令跟随和问答）及四种数据集上进行了评估，表现优异。此外，通过引入量化形状编码，该方法进一步扩展到复杂3D物体形状重建，展示了其在真实世界物体识别任务中的有效性。项目网页为https:
  "keyword": ["3D场景", "多模态对齐", "自回归模型"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 195 (char 298). Line: 406.
Append: [Aligning Text, Images, and 3D Structure Token-by-Token](https://arxiv.org/abs/2506.08002)
Token length: 1508
Summarized using qwen-turbo
Append: [Squeeze3D：基于隐式先验知识的高效3D数据压缩框架](https://arxiv.org/abs/2506.07932)
Token length: 1676
Summarized using qwen-turbo
Append: [大型语言模型在不等式证明中的挑战与研究进展](https://arxiv.org/abs/2506.07927)
Token length: 1023
Summarized using qwen-turbo
Append: [Frame Guidance：无需训练的可控视频生成引导方法](https://arxiv.org/abs/2506.07177)
Token length: 886
Summarized using qwen-turbo
Append: [大型语言模型中的地缘政治偏见研究](https://arxiv.org/abs/2506.06751)
Token length: 1317
Summarized using qwen-turbo
Append: [异构Mixture-of-Adapters方法提升大语言模型参数高效微调性能](https://arxiv.org/abs/2506.05928)
Token length: 713
Summarized using qwen-turbo
Append: [基于大型语言模型的知识增强金融推理模型RKEFino1](https://arxiv.org/abs/2506.05700)
Token length: 1124
Summarized using qwen-turbo
Append: [基于证据性引导的检索增强生成模型ECoRAG](https://arxiv.org/abs/2506.05167)
Token length: 1560
Summarized using qwen-turbo
Append: [基于预操作批评机制的多模态大语言模型在GUI自动化中的应用](https://arxiv.org/abs/2506.04614)
append_entries: 11
Finish: 2025-06-11 12:31:17.677565
------------------------------------------------------
Started: 2025-06-11 18:20:44.874515
Existing_entries: 1011
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1745
Summarized using qwen-turbo
Append: [引入Autoregressive Semantic Visual Reconstruction提升多模态理解](https://arxiv.org/abs/2506.09040)
Token length: 1505
Summarized using qwen-turbo
Append: [基于强化学习的小型规则推理模型的高效方法](https://arxiv.org/abs/2506.08672)
Token length: 1310
Summarized using qwen-turbo
Append: [Mathesis：结合强化学习的端到端数学定理证明系统](https://arxiv.org/abs/2506.07047)
append_entries: 3
Finish: 2025-06-11 18:20:57.933381
------------------------------------------------------
Started: 2025-06-12 01:11:47.467209
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-12 01:12:03.111042
------------------------------------------------------
Started: 2025-06-12 06:22:24.351970
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Fetch error: 503
Fetch failed from https://rsshub.app/huggingface/daily-papers
append_entries: 0
error when rendering xml, skip docs/Huggingface-Daliy-Papers
------------------------------------------------------
Started: 2025-06-12 12:29:52.609327
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1420
Summarized using qwen-turbo
Append: [PlayerOne：首个第一人称现实世界模拟器](https://arxiv.org/abs/2506.09995)
Token length: 1388
Summarized using qwen-turbo
Append: [基于多模态条件的端到端人体动画生成框架](https://arxiv.org/abs/2506.09984)
Token length: 1566
Summarized using qwen-turbo
Append: [SAFE：面向视觉语言动作模型的多任务故障检测器](https://arxiv.org/abs/2506.09937)
Token length: 1525
Summarized using qwen-turbo
Append: [ComfyUI-R1：首个用于自动化工作流生成的大规模推理模型](https://arxiv.org/abs/2506.09790)
Json decode failed:
{
  "title": "基于对抗后训练的实时交互式视频生成模型",
  "short_summary": "提出一种新方法将预训练模型转化为实时交互式视频生成器。",
  "summary": "现有大规模视频生成模型计算成本高，难以应用于实时和交互式应用。本文介绍了一种名为自回归对抗后训练（AAPT）的新方法，通过将其应用于预训练的潜在视频扩散模型，成功实现了实时、交互式的视频生成。AAPT采用单次神经函数评估生成潜伏帧，可实时向用户流式传输结果并接收交互反馈作为控制信号生成下一帧。与现有方法不同，AAPT探索了对抗训练作为自回归生成的有效范式，设计出更高效的一步生成架构，同时利用KV缓存减少长期视频生成中的误差累积。实验表明，8B参数模型在单个H100上以736x416分辨率实现24fps的实时流媒体视频生成，或在8个H100上以1280x720分辨率生成长达一分钟的视频（1440帧）。更多详情请访问我们的研究网站https:
  "keyword": ["视频生成", "实时交互", "对抗后训练"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 338 (char 423). Line: 406.
Append: [Autoregressive Adversarial Post-Training for Real-Time Interactive Video Generation](https://arxiv.org/abs/2506.09350)
Token length: 1549
Summarized using qwen-turbo
Append: [Seedance 1.0：高效高质量视频生成基础模型](https://arxiv.org/abs/2506.09113)
Token length: 1048
Summarized using qwen-turbo
Append: [Branched Schrödinger Bridge Matching：多模态分布转换的新框架](https://arxiv.org/abs/2506.09007)
Token length: 1119
Summarized using qwen-turbo
Append: [基于测试驱动开发的数据合成框架SWE-Flow](https://arxiv.org/abs/2506.09003)
Token length: 934
Summarized using qwen-turbo
Append: [SeerAttention-R：面向推理模型长解码的稀疏注意力框架](https://arxiv.org/abs/2506.08889)
Token length: 853
Summarized using qwen-turbo
Append: [POET：一种基于正交等价变换的大规模语言模型训练算法](https://arxiv.org/abs/2506.08001)
Token length: 803
Summarized using qwen-turbo
Append: [基于自我信心的大语言模型后训练强化学习方法](https://arxiv.org/abs/2506.06395)
append_entries: 11
Finish: 2025-06-12 12:31:03.515372
------------------------------------------------------
Started: 2025-06-12 18:20:32.461775
Existing_entries: 1011
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-12 18:20:48.842038
------------------------------------------------------
Started: 2025-06-13 01:12:56.498181
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1046
Summarized using qwen-turbo
Append: [ Retrieval Augmented Generation中的知识冲突类型及其处理研究](https://arxiv.org/abs/2506.08500)
Token length: 1662
Summarized using qwen-turbo
Append: [Institutional Books 1.0：基于哈佛图书馆公共领域书籍的历史文本数据集发布](https://arxiv.org/abs/2506.08300)
Token length: 1579
Summarized using qwen-turbo
Append: [Mirage：基于音频生成高质量视频的统一模型](https://arxiv.org/abs/2506.08279)
Token length: 1436
Summarized using qwen-turbo
Append: [测试时间交互扩展提升智能体性能](https://arxiv.org/abs/2506.07976)
Token length: 1281
Summarized using qwen-turbo
Append: [基于多模态大语言模型的可解释AI生成图像检测](https://arxiv.org/abs/2506.07045)
Token length: 795
Summarized using qwen-turbo
Append: [MMRefine：多模态大语言模型误差精化能力评估基准](https://arxiv.org/abs/2506.04688)
Token length: 1187
Summarized using qwen-turbo
Append: [基于查询聚焦的定量关键点摘要模型QQSUM-RAG](https://arxiv.org/abs/2506.04020)
append_entries: 7
Finish: 2025-06-13 01:13:49.600167
------------------------------------------------------
Started: 2025-06-13 06:21:50.917192
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-13 06:22:06.972677
------------------------------------------------------
Started: 2025-06-13 12:29:42.700085
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-13 12:29:58.765367
------------------------------------------------------
Started: 2025-06-13 18:20:35.501571
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-13 18:20:51.515061
------------------------------------------------------
Started: 2025-06-14 01:09:57.204197
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-14 01:10:13.277645
------------------------------------------------------
Started: 2025-06-14 06:19:37.791821
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-14 06:19:53.343541
------------------------------------------------------
Started: 2025-06-14 12:26:45.689232
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Fetch error: 503
Fetch failed from https://rsshub.app/huggingface/daily-papers
append_entries: 0
error when rendering xml, skip docs/Huggingface-Daliy-Papers
------------------------------------------------------
Started: 2025-06-14 18:18:06.829552
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1920
Summarized using qwen-turbo
Append: [HeadHunter: 针对扩散模型注意力扰动的细粒度控制方法](https://arxiv.org/abs/2506.10978)
Token length: 1285
Summarized using qwen-turbo
Append: [AutoMind：一种适应性强的知识驱动型大语言模型代理框架](https://arxiv.org/abs/2506.10974)
Json decode failed:
{
  "title": "中文内容有害检测的综合基准与知识增强方法",
  "short_summary": "提出中文有害内容检测的全面基准并引入知识增强模型。",
  "summary": "大型语言模型在自动化有害内容检测中得到广泛应用，但现有资源多以英语为主，中文数据集稀缺且范围有限。本文构建了一个涵盖六大类别的中文内容有害检测综合基准，全部基于真实世界数据，并通过注释过程生成了知识规则库，为LLMs提供明确的专业知识支持。此外，我们提出了知识增强基线模型，结合人工标注的知识规则与大语言模型的隐式知识，使较小的模型达到接近顶级LLMs的性能。代码和数据可在https:
  "keyword": ["大型语言模型", "中文有害内容检测", "知识增强"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 208 (char 292). Line: 406.
Append: [ChineseHarm-Bench: A Chinese Harmful Content Detection Benchmark](https://arxiv.org/abs/2506.10960)
Token length: 1857
Summarized using qwen-turbo
Append: [SWE-Factory：自动化构建大规模GitHub问题解决数据集](https://arxiv.org/abs/2506.10954)
Token length: 1458
Summarized using qwen-turbo
Append: [迈向自主网络代理的新交互范式：Agentic Web Interface 的提出](https://arxiv.org/abs/2506.10953)
Token length: 1364
Summarized using qwen-turbo
Append: [Domain2Vec：一种高效的数据集分解方法](https://arxiv.org/abs/2506.10952)
Token length: 1606
Summarized using qwen-turbo
Append: [基于半非负矩阵分解的大型语言模型可解释性特征提取](https://arxiv.org/abs/2506.10920)
Token length: 1837
Summarized using qwen-turbo
Append: [NoLoCo：一种无需显式同步的高效大规模语言模型训练方法](https://arxiv.org/abs/2506.10911)
Token length: 870
Summarized using qwen-turbo
Append: [Magistral：基于纯强化学习训练的语言模型](https://arxiv.org/abs/2506.10910)
Token length: 1569
Summarized using qwen-turbo
Append: [CreatiPoster：一种支持多层可编辑图形设计的AI框架](https://arxiv.org/abs/2506.10890)
Token length: 1230
Summarized using qwen-turbo
Append: [VRBench：首个长叙事视频基准用于评估大模型多步推理能力](https://arxiv.org/abs/2506.10857)
Token length: 1322
Summarized using qwen-turbo
Append: [基于文本推理模型的长视频理解框架](https://arxiv.org/abs/2506.10821)
Token length: 1339
Summarized using qwen-turbo
Append: [PosterCraft：一种统一框架用于高审美海报生成](https://arxiv.org/abs/2506.10741)
Token length: 1469
Summarized using qwen-turbo
Append: [TaxoAdapt：动态适配的科学文献自动分类框架](https://arxiv.org/abs/2506.10737)
Token length: 1599
Summarized using qwen-turbo
Append: [ClaimSpect：基于检索增强生成框架的复杂主张分解与视角表示](https://arxiv.org/abs/2506.10728)
Token length: 1339
Summarized using qwen-turbo
Append: [TeleMath：首个电信领域数学问题评估基准](https://arxiv.org/abs/2506.10674)
Json decode failed:
{
  "title": "EmbodiedGen：用于交互式3D世界生成的基础平台",
  "short_summary": "EmbodiedGen通过生成高质量、可控制且逼真的3D资产推动具身智能发展。",
  "summary": "构建物理上真实且按比例精确的模拟3D世界对具身智能任务的训练和评估至关重要。然而，目前大多数具身智能任务仍然依赖于传统的人工创建和标注的3D计算机图形资产，这些资产生产成本高且真实性有限，阻碍了数据驱动方法的扩展性。我们提出了EmbodiedGen，这是一个用于交互式3D世界生成的基础平台。它通过低成本生成高质量、可控且照片级真实的3D资产，在统一机器人描述格式（URDF）中实现准确的物理特性和现实世界的尺度。这些资产可以直接导入各种物理模拟引擎中，支持下游任务的训练和评估。EmbodiedGen由六个关键模块组成：Image-to-3D、Text-to-3D、Texture Generation、Articulated Object Generation、Scene Generation和Layout Generation，可以生成多样化的交互式3D世界，利用生成式AI解决具身智能相关研究中的泛化和评估挑战。代码可在https:
  "keyword": ["具身智能", "3D世界生成", "EmbodiedGen"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 436 (char 542). Line: 406.
Append: [EmbodiedGen: Towards a Generative 3D World Engine for Embodied Intelligence](https://arxiv.org/abs/2506.10600)
Json decode failed:
{
  "title": "基于Diffusion Transformer的人货交互高保真视频生成框架",
  "short_summary": "提出一种结合扩散模型和Transformer的方法，实现人货身份高保真生成。",
  "summary": "在电子商务和数字营销中，生成高质量的人货演示视频对产品展示至关重要。然而，现有方法往往无法同时保留人物和产品的身份细节，或缺乏对空间关系的理解，导致不自然的交互表现。为此，我们提出了一种基于Diffusion Transformer (DiT) 的新框架，通过注入配对手货参考信息并利用掩码交叉注意力机制，有效保留人物和产品的身份特征。该方法采用3D身体网格模板和产品边界框提供精确运动指导，并结合结构化文本编码增强类别级语义，提升小角度旋转下的3D一致性。经过大量数据增强训练，该框架在保持人货身份完整性及生成真实交互动作方面超越了现有技术。项目页面：https:
  "keyword": ["人货交互", "高保真人货视频", "Diffusion Transformer"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 298 (char 412). Line: 406.
Append: [DreamActor-H1: High-Fidelity Human-Product Demonstration Video Generation via Motion-designed Diffusion Transformers](https://arxiv.org/abs/2506.10568)
Token length: 1884
Summarized using qwen-turbo
Append: [AniMaker：基于多智能体框架的文本驱动故事动画生成](https://arxiv.org/abs/2506.10540)
Token length: 1485
Summarized using qwen-turbo
Append: [基于因果表示学习的语言模型能力评估框架](https://arxiv.org/abs/2506.10378)
Token length: 1295
Summarized using qwen-turbo
Append: [Optimus-3：面向Minecraft环境的多模态通用智能体](https://arxiv.org/abs/2506.10357)
Json decode failed:
{
  "title": "离散音频标记器的系统性回顾与基准测试",
  "short_summary": "本文对离散音频标记器进行了全面的回顾与评估。",
  "summary": "随着基于标记的音频处理方法日益受到关注，本文提供了对离散音频标记器的系统性回顾与基准测试。研究涵盖了语音、音乐和通用音频三个领域，并根据编码器-解码器架构、量化技术、训练范式、流媒体支持和应用领域提出了分类方法。通过多个基准测试，包括重建、下游性能和声学语言建模，我们评估了不同的标记器，并通过控制消融研究分析了权衡问题。研究结果揭示了现有方法的关键局限性、实际考虑因素及开放挑战，为该领域的未来发展提供了洞见和指导。更多详情可访问我们的网站：https:
  "keyword": ["离散音频标记器", "语音处理", "音频基准测试"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 243 (char 322). Line: 406.
Append: [Discrete Audio Tokens: More Than a Survey!](https://arxiv.org/abs/2506.10274)
Token length: 1424
Summarized using qwen-turbo
Append: [高效探针方法在自监督学习中的性能提升研究](https://arxiv.org/abs/2506.10178)
Token length: 1265
Summarized using qwen-turbo
Append: [面向文本恢复的图像修复方法研究](https://arxiv.org/abs/2506.09993)
Token length: 1494
Summarized using qwen-turbo
Append: [高效激发语言模型推理能力的稀疏自编码调优方法](https://arxiv.org/abs/2506.09967)
Token length: 1137
Summarized using qwen-turbo
Append: [UniPre3D：一种适用于任意尺度点云的统一预训练方法](https://arxiv.org/abs/2506.09952)
Token length: 1248
Summarized using qwen-turbo
Append: [结合规则与大模型推理的指令跟随强化学习](https://arxiv.org/abs/2506.09942)
Token length: 1040
Summarized using qwen-turbo
Append: [ReasonMed：大规模医学推理数据集推动LLMs在医疗问答中的性能提升](https://arxiv.org/abs/2506.09513)
Token length: 1356
Summarized using qwen-turbo
Append: [Ming-Omni：一种支持多模态处理与生成的统一模型](https://arxiv.org/abs/2506.09344)
Token length: 1384
Summarized using qwen-turbo
Append: [Token Perturbation Guidance提升扩散模型生成质量](https://arxiv.org/abs/2506.10036)
Append: [Comment on The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity](https://arxiv.org/abs/2506.09250)
Append: [StreamSplat: Towards Online Dynamic 3D Reconstruction from Uncalibrated Video Streams](https://arxiv.org/abs/2506.08862)
Append: [Draft-based Approximate Inference for LLMs](https://arxiv.org/abs/2506.08373)
Append: [Compound AI Systems Optimization: A Survey of Methods, Challenges, and Future Directions](https://arxiv.org/abs/2506.08234)
Append: [LLM Unlearning Should Be Form-Independent](https://arxiv.org/abs/2506.07795)
Append: [Eliciting Fine-Tuned Transformer Capabilities via Inference-Time Techniques](https://arxiv.org/abs/2506.08060)
Append: [LaTtE-Flow: Layerwise Timestep-Expert Flow-based Transformer](https://arxiv.org/abs/2506.06952)
Append: [What Makes a Good Natural Language Prompt?](https://arxiv.org/abs/2506.06950)
Append: [Breaking Data Silos: Towards Open and Scalable Mobility Foundation Models via Generative Continual Learning](https://arxiv.org/abs/2506.06694)
Append: [LaMP-Cap: Personalized Figure Caption Generation With Multimodal Figure Profiles](https://arxiv.org/abs/2506.06561)
Append: [MCA-Bench: A Multimodal Benchmark for Evaluating CAPTCHA Robustness Against VLM-based Attacks](https://arxiv.org/abs/2506.05982)
append_entries: 41
Finish: 2025-06-14 18:20:30.946637
------------------------------------------------------
Started: 2025-06-15 01:19:58.249996
Existing_entries: 1041
Fetching from https://rsshub.app/huggingface/daily-papers
Fetch error: HTTPSConnectionPool(host='rsshub.app', port=443): Read timed out. (read timeout=30)
Fetch failed from https://rsshub.app/huggingface/daily-papers
append_entries: 0
error when rendering xml, skip docs/Huggingface-Daliy-Papers
------------------------------------------------------
Started: 2025-06-15 06:20:07.312330
Existing_entries: 1041
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-15 06:20:07.630924
------------------------------------------------------
Started: 2025-06-15 12:27:27.150257
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-15 12:27:27.499153
------------------------------------------------------
Started: 2025-06-15 18:18:54.004352
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-15 18:18:54.361945
------------------------------------------------------
Started: 2025-06-16 01:14:56.094847
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-16 01:14:56.354366
------------------------------------------------------
Started: 2025-06-16 06:23:56.511309
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-16 06:23:56.883612
------------------------------------------------------
Started: 2025-06-16 12:31:14.405604
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1695
Summarized using qwen-turbo
Append: [多维线性循环神经网络在长距离依赖任务中的表现](https://arxiv.org/abs/2506.11997)
Token length: 1382
Summarized using qwen-turbo
Append: [大型语言模型在编程竞赛中的表现评估](https://arxiv.org/abs/2506.11928)
Token length: 1447
Summarized using qwen-turbo
Append: [基于扩散模型的对齐新视角图像与几何生成框架](https://arxiv.org/abs/2506.11924)
Token length: 1010
Summarized using qwen-turbo
Append: [FourierAttention：一种高效的大语言模型长上下文处理方法](https://arxiv.org/abs/2506.11886)
Token length: 1113
Summarized using qwen-turbo
Append: [Configurable Preference Tuning (CPT): 动态调整AI行为的新框架](https://arxiv.org/abs/2506.11702)
Token length: 1095
Summarized using qwen-turbo
Append: [Duo：通过高斯扩散改进离散扩散模型以提升文本生成性能](https://arxiv.org/abs/2506.10892)
Token length: 1677
Summarized using qwen-turbo
Append: [通过视觉描述幻觉批评提升视觉语言模型的感知能力](https://arxiv.org/abs/2506.10128)
Token length: 1360
Summarized using qwen-turbo
Append: [对抗性用户对政策合规AI代理的威胁及防御策略研究](https://arxiv.org/abs/2506.09600)
Token length: 1359
Summarized using qwen-turbo
Append: [InterSyn：基于自评估迭代精炼的大规模多模态数据集](https://arxiv.org/abs/2506.09427)
Token length: 1543
Summarized using qwen-turbo
Append: [SkillBlender：一种用于人形机器人灵活操控的分层强化学习框架](https://arxiv.org/abs/2506.09366)
Token length: 1002
Summarized using qwen-turbo
Append: [基于自精炼框架的无标注数据增强ASR性能研究](https://arxiv.org/abs/2506.11130)
Token length: 1011
Summarized using qwen-turbo
Append: [基于二值注意力掩码的图像预测方法](https://arxiv.org/abs/2506.08915)
Json decode failed:
{
  "title": "CapRetrieval：针对细粒度实体及事件检索的数据集与模型优化",
  "short_summary": "研究显示现有文本编码器在细粒度匹配上存在局限性，为此构建CapRetrieval数据集并提出优化策略。",
  "summary": "本文探讨了文本编码器的一个已知限制，即嵌入向量可能无法识别语义中的细粒度实体或事件，导致即使在简单情况下也未能成功实现密集检索。为了研究此类行为，我们首先引入了一个新的中文评估数据集CapRetrieval，其中段落为图像描述，查询为询问各种形式下的实体或事件的短语。零样本评估表明，无论训练来源或模型大小如何，编码器在这些细粒度匹配任务上可能会失败。为了解决这一问题，我们进一步提出了数据生成策略来微调编码器，从而在CapRetrieval上取得了最佳性能。在此过程中，我们还发现了粒度困境的问题，即嵌入向量在表达细粒度显著性的同时还要与整体语义对齐的挑战。本研究的数据集、代码和模型已在https:
  "keyword": ["文本编码", "细粒度匹配", "CapRetrieval"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 316 (char 440). Line: 406.
Append: [Dense Retrievers Can Fail on Simple Queries: Revealing The Granularity Dilemma of Embeddings](https://arxiv.org/abs/2506.08592)
Token length: 1428
Summarized using qwen-turbo
Append: [U-CoT+: 一种高效灵活的有害模因检测框架](https://arxiv.org/abs/2506.08477)
Token length: 1432
Summarized using qwen-turbo
Append: [基于Reg-GRPO的视频大型语言模型增强视频推理能力的研究](https://arxiv.org/abs/2506.07464)
append_entries: 15
Finish: 2025-06-16 12:32:34.322605
------------------------------------------------------
Started: 2025-06-16 18:21:00.846625
Existing_entries: 1015
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-16 18:21:01.053258
------------------------------------------------------
Started: 2025-06-17 01:12:55.368631
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1685
Summarized using qwen-turbo
Append: [大型语言模型对反馈的吸收能力研究](https://arxiv.org/abs/2506.11930)
Json decode failed:
{
  "title": "Med-PRM：基于过程奖励建模的医疗推理误差检测框架",
  "short_summary": "Med-PRM通过检索增强生成技术验证医疗推理每一步骤，显著提升临床决策模型性能。",
  "summary": "大型语言模型在临床决策中的应用潜力巨大，但目前的方法难以准确定位和修正推理过程中的具体错误，这在医学领域尤为重要。为解决这一问题，我们提出了Med-PRM，这是一种利用检索增强生成技术的过程奖励建模框架。Med-PRM通过对中间推理步骤进行证据验证（来自临床指南和文献），能够以细粒度方式精确评估推理质量。实验表明，在五个医疗问答基准测试和两个开放式诊断任务中，Med-PRM达到了最先进的性能，将基础模型的性能提高了高达13.50%。此外，通过与强大的策略模型如Meerkat结合，Med-PRM实现了在MedQA上首次使用80亿参数的小规模模型达到超过80%的准确率。我们的代码和数据可在https:
  "keyword": ["医疗推理", "过程奖励建模", "临床决策"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 317 (char 424). Line: 406.
Append: [Med-PRM: Medical Reasoning Models with Stepwise, Guideline-verified Process Rewards](https://arxiv.org/abs/2506.11474)
Token length: 1214
Summarized using qwen-turbo
Append: [通过学习继续思考令牌提升语言模型推理能力](https://arxiv.org/abs/2506.11274)
Token length: 1364
Summarized using qwen-turbo
Append: [Mirage-1：基于分层多模态技能的跨平台GUI代理](https://arxiv.org/abs/2506.10387)
Token length: 1452
Summarized using qwen-turbo
Append: [基于LoRA调优的掩码引导视频编辑方法](https://arxiv.org/abs/2506.10082)
Token length: 1141
Summarized using qwen-turbo
Append: [基于生成-修剪-排名范式的程序验证效率与准确性权衡](https://arxiv.org/abs/2506.10056)
Token length: 1142
Summarized using qwen-turbo
Append: [JAFAR：轻量且灵活的基础视觉编码器特征上采样方法](https://arxiv.org/abs/2506.11136)
Token length: 1517
Summarized using qwen-turbo
Append: [基于自我意识弱点驱动的问题合成框架提升大语言模型推理能力](https://arxiv.org/abs/2506.08989)
Token length: 1511
Summarized using qwen-turbo
Append: [Infinity-Instruct：提升大语言模型基础与对话能力的新基准数据集](https://arxiv.org/abs/2506.11116)
Token length: 1251
Summarized using qwen-turbo
Append: [基于候选标注的大语言模型数据标注方法](https://arxiv.org/abs/2506.03857)
append_entries: 10
Finish: 2025-06-17 01:14:00.804231
------------------------------------------------------
Started: 2025-06-17 06:22:15.605893
Existing_entries: 1010
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1284
Summarized using qwen-turbo
Append: [Avey：一种突破注意力与循环机制的新神经基础架构](https://arxiv.org/abs/2506.11305)
Token length: 1360
Summarized using qwen-turbo
Append: [大型语言模型在不确定场景下的拒绝回答能力评估](https://arxiv.org/abs/2506.09038)
append_entries: 2
Finish: 2025-06-17 06:22:25.141045
------------------------------------------------------
Started: 2025-06-17 12:31:15.354193
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1803
Summarized using qwen-turbo
Append: [离散扩散语言模型与多模态语言模型综述](https://arxiv.org/abs/2506.13759)
Token length: 1471
Summarized using qwen-turbo
Append: [预算引导：通过轻量级预测控制大语言模型推理长度](https://arxiv.org/abs/2506.13752)
Token length: 1159
Summarized using qwen-turbo
Append: [Test3R：通过测试时学习显著提升3D重建几何精度](https://arxiv.org/abs/2506.13750)
Token length: 1325
Summarized using qwen-turbo
Append: [Ego-R1框架：通过强化学习实现超长时间第一人称视频推理](https://arxiv.org/abs/2506.13654)
Token length: 1806
Summarized using qwen-turbo
Append: [MiniMax-M1：全球首个开放权重大规模混合注意力推理模型发布](https://arxiv.org/abs/2506.13585)
Token length: 1534
Summarized using qwen-turbo
Append: [结构化提示对大型语言模型文本分析能力的影响研究](https://arxiv.org/abs/2506.13172)
Token length: 841
Summarized using qwen-turbo
Append: [基于提示的大型语言模型时间序列预测方法](https://arxiv.org/abs/2506.12953)
Token length: 1900
Summarized using qwen-turbo
Append: [PersonaFeedback：评估大型语言模型个性化能力的新基准](https://arxiv.org/abs/2506.12915)
Token length: 1051
Summarized using qwen-turbo
Append: [面向用户界面教学视频的多模态摘要新基准](https://arxiv.org/abs/2506.12623)
Token length: 1298
Summarized using qwen-turbo
Append: [大型语言模型中的表示对齐及其跨语言控制方法](https://arxiv.org/abs/2506.12450)
Token length: 1369
Summarized using qwen-turbo
Append: [大型语言模型人格解读：基于Supernova Event Dataset的事件提取与基准测试](https://arxiv.org/abs/2506.12189)
Token length: 1250
Summarized using qwen-turbo
Append: [DeepResearch Bench：LLM驱动的研究代理能力评估基准](https://arxiv.org/abs/2506.11763)
Token length: 1277
Summarized using qwen-turbo
Append: [科学家首次考试（SFE）基准评测科学多模态大语言模型](https://arxiv.org/abs/2506.10521)
Token length: 1041
Summarized using qwen-turbo
Append: [ALE-Bench：评估AI系统在算法工程中的表现](https://arxiv.org/abs/2506.09050)
Token length: 814
Summarized using qwen-turbo
Append: [NoWait：高效多模态推理的插件式解决方案](https://arxiv.org/abs/2506.08343)
Token length: 1774
Summarized using qwen-turbo
Append: [BridgeVLA：一种高效的三维视觉-语言-动作模型](https://arxiv.org/abs/2506.07961)
Json decode failed:
{
  "title": "基于属性接地的大规模复杂指令合成方法",
  "short_summary": "提出一种利用属性接地生成大规模复杂指令的方法。",
  "summary": "本文介绍了一种新的方法来合成具有认知洞察力且基于真实应用场景的高效对齐指令。该方法通过自上而下的属性接地过程将真实指令分配给具体用户，并利用网络文档自下而上生成情境和有意义的指令。这种方法能够大规模获取多样化和复杂的指令，构建了一个包含1百万条指令的数据集SynthQuestions，训练出的模型在多个常见基准测试中表现出色，并且随着更多网络语料库的增加，性能持续提升。数据、模型和代码将在https:
  "keyword": ["语言模型", "指令合成", "网络文档"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 217 (char 297). Line: 406.
Append: [From Real to Synthetic: Synthesizing Millions of Diversified and Complicated User Instructions with Attributed Grounding](https://arxiv.org/abs/2506.03968)
Token length: 1454
Summarized using qwen-turbo
Append: [构建AI代理行为科学：从模型到行为的系统性研究](https://arxiv.org/abs/2506.06366)
append_entries: 18
Finish: 2025-06-17 12:33:23.134191
------------------------------------------------------
Started: 2025-06-17 18:20:59.674867
Existing_entries: 1018
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1097
Summarized using qwen-turbo
Append: [基于视觉Transformer的寿命预测模型](https://arxiv.org/abs/2506.13430)
Token length: 1317
Summarized using qwen-turbo
Append: [提升小规模推理语言模型性能的研究](https://arxiv.org/abs/2506.13404)
Token length: 1613
Summarized using qwen-turbo
Append: [SeqPE：一种统一且完全可学习的位置编码框架](https://arxiv.org/abs/2506.13277)
Token length: 1106
Summarized using qwen-turbo
Append: [DoTA-RAG：面向大规模网络知识索引的高效检索增强生成系统](https://arxiv.org/abs/2506.12571)
Token length: 1492
Summarized using qwen-turbo
Append: [利用大型语言模型评估新闻媒体可信度与政治偏见的研究](https://arxiv.org/abs/2506.12552)
Token length: 1271
Summarized using qwen-turbo
Append: [QGuard：一种基于问题提示的大语言模型安全防护方法](https://arxiv.org/abs/2506.12299)
Token length: 1463
Summarized using qwen-turbo
Append: [EgoPrivacy：第一人称视角隐私风险评估基准](https://arxiv.org/abs/2506.12258)
Token length: 744
Summarized using qwen-turbo
Append: [语言模型在动态仇恨言论检测中的时间敏感性评估](https://arxiv.org/abs/2506.12148)
Token length: 1483
Summarized using qwen-turbo
Append: [VGR：增强视觉感知能力的多模态链式推理大模型](https://arxiv.org/abs/2506.11991)
Token length: 929
Summarized using qwen-turbo
Append: [TaskCraft：自动化生成可扩展的多工具交互型任务](https://arxiv.org/abs/2506.10055)
Token length: 1552
Summarized using qwen-turbo
Append: [基于LLM辅助系统的自主学习能力培养研究](https://arxiv.org/abs/2506.09968)
Token length: 1351
Summarized using qwen-turbo
Append: [TransDiff：结合Transformer与扩散模型的图像生成新方法](https://arxiv.org/abs/2506.09482)
Token length: 1159
Summarized using qwen-turbo
Append: [MATTER：结合材料知识的新型分词方法提升科学文本处理性能](https://arxiv.org/abs/2506.11115)
Token length: 1136
Summarized using qwen-turbo
Append: [DeepEDM：结合深度学习与非线性动力学系统的时序预测框架](https://arxiv.org/abs/2506.06454)
append_entries: 14
Finish: 2025-06-17 18:22:27.821761
------------------------------------------------------
Started: 2025-06-18 01:12:25.754564
Existing_entries: 1014
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-18 01:12:41.806432
------------------------------------------------------
Started: 2025-06-18 06:22:10.283729
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-18 06:22:25.970307
------------------------------------------------------
Started: 2025-06-18 12:30:56.325732
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-18 12:31:12.010488
------------------------------------------------------
Started: 2025-06-18 18:20:51.485891
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-18 18:21:06.723901
------------------------------------------------------
Started: 2025-06-19 01:12:50.906391
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-19 01:13:07.229516
------------------------------------------------------
Started: 2025-06-19 06:22:06.199976
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-19 06:22:22.515338
------------------------------------------------------
Started: 2025-06-19 12:30:21.704944
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-19 12:30:37.057228
------------------------------------------------------
Started: 2025-06-19 18:20:22.413867
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-19 18:20:38.146927
------------------------------------------------------
Started: 2025-06-20 01:12:14.605039
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-20 01:12:30.981161
------------------------------------------------------
Started: 2025-06-20 06:21:56.301429
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-20 06:22:20.945897
------------------------------------------------------
Started: 2025-06-20 12:30:21.548447
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-20 12:30:37.218032
------------------------------------------------------
Started: 2025-06-20 18:20:18.983304
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1307
Summarized using qwen-turbo
Append: [SonicVerse：融合多任务特征检测的音乐描述生成模型](https://arxiv.org/abs/2506.15154)
Json decode failed:
{
  "title": "Guru：跨越六大学科的大规模强化学习推理数据集",
  "short_summary": "引入Guru数据集，提升大语言模型在多样化推理任务中的表现。",
  "summary": "本文介绍了一个名为Guru的强化学习推理数据集，该数据集包含92K个可验证的例子，覆盖数学、代码、科学、逻辑、模拟和表格六个推理领域。通过领域特定的奖励设计、去重和过滤，确保了数据集的可靠性和有效性。研究发现，虽然先前的工作表明强化学习主要唤起预训练模型中已有的知识，但我们的结果显示了一个更为复杂的模式：在数学、代码和科学等频繁出现在预训练数据中的领域，跨域强化学习训练可以轻松受益；而在逻辑、模拟和表格等领域，由于预训练数据暴露有限，需要进行领域内训练才能实现显著的性能提升。此外，我们发布了Guru-7B和Guru-32B两个模型，在17项任务的评估套件中，分别比最佳基线高出7.9%和6.7%，特别是在复杂任务上有效提升了基础模型的Pass@k性能。最后，我们将数据、模型、训练和评估代码开源，网址为https:
  "keyword": ["强化学习", "大语言模型", "推理"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 375 (char 468). Line: 406.
Append: [Revisiting Reinforcement Learning for LLM Reasoning from A Cross-Domain Perspective](https://arxiv.org/abs/2506.14965)
Token length: 1602
Summarized using qwen-turbo
Append: [基于迭代精化的图表到代码生成方法](https://arxiv.org/abs/2506.14837)
Token length: 1503
Summarized using qwen-turbo
Append: [EmoNet-Voice：基于新基准的数据集推动语音情感识别发展](https://arxiv.org/abs/2506.09827)
append_entries: 4
Finish: 2025-06-20 18:20:45.694493
------------------------------------------------------
Started: 2025-06-21 01:11:17.549166
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Fetch error: HTTPSConnectionPool(host='rsshub.app', port=443): Read timed out. (read timeout=30)
Fetch failed from https://rsshub.app/huggingface/daily-papers
append_entries: 0
error when rendering xml, skip docs/Huggingface-Daliy-Papers
------------------------------------------------------
Started: 2025-06-21 06:19:48.867259
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 957
Summarized using qwen-turbo
Append: [Show-o2：基于流匹配与自回归建模的多模态统一模型](https://arxiv.org/abs/2506.15564)
Token length: 1182
Summarized using qwen-turbo
Append: [RE-IMAGINE框架评估大型语言模型的推理能力](https://arxiv.org/abs/2506.15455)
append_entries: 2
Finish: 2025-06-21 06:19:58.698054
------------------------------------------------------
Started: 2025-06-21 12:27:07.186048
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-21 12:27:07.409628
------------------------------------------------------
Started: 2025-06-21 18:18:40.406012
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-21 18:18:40.595302
------------------------------------------------------
Started: 2025-06-22 01:19:21.836930
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-22 01:19:22.035026
------------------------------------------------------
Started: 2025-06-22 06:20:36.759011
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-22 06:20:36.874452
------------------------------------------------------
Started: 2025-06-22 12:27:05.362327
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-22 12:27:05.497633
------------------------------------------------------
Started: 2025-06-22 18:19:06.245543
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-22 18:19:06.446788
------------------------------------------------------
Started: 2025-06-23 01:17:15.776611
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-23 01:17:16.189173
------------------------------------------------------
Started: 2025-06-23 06:23:53.311988
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1008
Summarized using qwen-turbo
Append: [基于多平面同步的3D全景图扩散模型DreamCube](https://arxiv.org/abs/2506.17206)
Token length: 1674
Summarized using qwen-turbo
Append: [Hunyuan-GameCraft：面向游戏环境的高动态交互视频生成框架](https://arxiv.org/abs/2506.17201)
Token length: 1008
Summarized using qwen-turbo
Append: [Hunyuan3D 2.5：高保真3D资产生成的新突破](https://arxiv.org/abs/2506.16504)
Token length: 1085
Summarized using qwen-turbo
Append: [大型语言模型在无偏视角摘要中的应用与评估](https://arxiv.org/abs/2506.15925)
Token length: 1487
Summarized using qwen-turbo
Append: [VIKI-Bench与VIKI-R：多智能体协作新基准与框架](https://arxiv.org/abs/2506.09049)
append_entries: 5
Finish: 2025-06-23 06:24:27.293385
------------------------------------------------------
Started: 2025-06-23 12:31:48.563789
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 878
Summarized using qwen-turbo
Append: [InfGen：一种用于长期交通仿真的统一模型](https://arxiv.org/abs/2506.17213)
Token length: 1501
Summarized using qwen-turbo
Append: [UniFork：一种新型的统一图像理解与生成架构](https://arxiv.org/abs/2506.17202)
Token length: 1295
Summarized using qwen-turbo
Append: [基于提示的参数生成方法DnD实现高效大语言模型微调](https://arxiv.org/abs/2506.16406)
Token length: 1545
Summarized using qwen-turbo
Append: [PAROAttention：通过重新排序提升视觉生成中的注意力效率](https://arxiv.org/abs/2506.16054)
Token length: 1068
Summarized using qwen-turbo
Append: [基于多模态模型的文档分块方法提升RAG系统性能](https://arxiv.org/abs/2506.16035)
Token length: 1194
Summarized using qwen-turbo
Append: [Hunyuan3D 2.1：3D AI生成内容的全面教程](https://arxiv.org/abs/2506.15442)
Token length: 1209
Summarized using qwen-turbo
Append: [InfiniPot-V：突破视频流理解的内存瓶颈](https://arxiv.org/abs/2506.15745)
append_entries: 7
Finish: 2025-06-23 12:32:29.956812
------------------------------------------------------
Started: 2025-06-23 18:21:03.052178
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1572
Summarized using qwen-turbo
Append: [多语言语音合成中文化敏感情感与口音建模的新方法](https://arxiv.org/abs/2506.16310)
append_entries: 1
Finish: 2025-06-23 18:21:09.087929
------------------------------------------------------
Started: 2025-06-24 01:13:09.863892
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1341
Summarized using qwen-turbo
Append: [基于隐式视觉标记的多模态推理框架 Mirage](https://arxiv.org/abs/2506.17218)
Token length: 1498
Summarized using qwen-turbo
Append: [MEXA：一种无需训练的多模态推理框架](https://arxiv.org/abs/2506.17113)
Token length: 1682
Summarized using qwen-turbo
Append: [基于对数概率序列的提示逆向方法研究](https://arxiv.org/abs/2506.17090)
Token length: 999
Summarized using qwen-turbo
Append: [图像生成模型输出的令牌级水印方法](https://arxiv.org/abs/2506.16349)
Token length: 1807
Summarized using qwen-turbo
Append: [Vision-Language-Action模型的泛化能力评估与基准测试](https://arxiv.org/abs/2506.09930)
append_entries: 5
Finish: 2025-06-24 01:13:36.732562
------------------------------------------------------
Started: 2025-06-24 06:23:21.907670
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-24 06:23:22.147735
------------------------------------------------------
Started: 2025-06-24 12:30:47.473326
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1077
Summarized using qwen-turbo
Append: [基于Surfel索引视图记忆的视频生成方法](https://arxiv.org/abs/2506.18903)
Token length: 1237
Summarized using qwen-turbo
Append: [基于统一离散语义表示的多模态框架Tar](https://arxiv.org/abs/2506.18898)
Token length: 1706
Summarized using qwen-turbo
Append: [ReasonFlux-PRM：一种新型轨迹感知的奖励模型框架](https://arxiv.org/abs/2506.18896)
Token length: 758
Summarized using qwen-turbo
Append: [通用光度立体技术中的光照与表面法线耦合问题研究](https://arxiv.org/abs/2506.18882)
Token length: 1325
Summarized using qwen-turbo
Append: [基于Commutative Vector Quantization的长上下文大语言模型优化方法](https://arxiv.org/abs/2506.18879)
Token length: 1493
Summarized using qwen-turbo
Append: [OmniGen2：一种多功能生成模型的开源实现](https://arxiv.org/abs/2506.18871)
Token length: 1184
Summarized using qwen-turbo
Append: [Phantom-Data数据集提升文本到视频生成的准确性](https://arxiv.org/abs/2506.18851)
Token length: 1621
Summarized using qwen-turbo
Append: [无需合成数据的超长文本生成方法研究](https://arxiv.org/abs/2506.18841)
Token length: 1295
Summarized using qwen-turbo
Append: [基于扩散模型的动态新视角合成方法ViDAR](https://arxiv.org/abs/2506.18792)
Token length: 1323
Summarized using qwen-turbo
Append: [ReDit：通过奖励抖动提升大语言模型训练效率](https://arxiv.org/abs/2506.18631)
Token length: 1784
Summarized using qwen-turbo
Append: [基于自回归模型的多视角图像生成方法](https://arxiv.org/abs/2506.18527)
Token length: 1916
Summarized using qwen-turbo
Append: [SlimMoE：高效压缩大型Mixture of Experts模型的方法](https://arxiv.org/abs/2506.18349)
Token length: 1519
Summarized using qwen-turbo
Append: [基于大语言模型的自适应用户画像框架LettinGo](https://arxiv.org/abs/2506.18309)
Token length: 1548
Summarized using qwen-turbo
Append: [无需验证器的强化学习框架提升大语言模型推理能力](https://arxiv.org/abs/2506.18254)
Token length: 1313
Summarized using qwen-turbo
Append: [FaithfulSAE提升稀疏自编码器的稳定性与模型内部特征捕捉能力](https://arxiv.org/abs/2506.17673)
Token length: 1328
Summarized using qwen-turbo
Append: [ConsumerBench：评估端侧GenAI系统效率的基准框架](https://arxiv.org/abs/2506.17538)
Token length: 1643
Summarized using qwen-turbo
Append: [基于MICS的医学多模态大语言模型推理路径优化](https://arxiv.org/abs/2506.16962)
Token length: 1219
Summarized using qwen-turbo
Append: [基于LSTM的新生儿死亡风险预测研究](https://arxiv.org/abs/2506.16929)
Token length: 1723
Summarized using qwen-turbo
Append: [Crome：一种因果鲁棒的奖励建模框架以防止奖励黑客](https://arxiv.org/abs/2506.16507)
Token length: 1431
Summarized using qwen-turbo
Append: [FinCoT：基于领域专家推理的结构化思维链提示方法](https://arxiv.org/abs/2506.16123)
Token length: 1578
Summarized using qwen-turbo
Append: [基于CodeT5的LLM代码作者归属识别研究](https://arxiv.org/abs/2506.17323)
Token length: 1221
Summarized using qwen-turbo
Append: [Agentic AI研究中的标准化与评估协议改进](https://arxiv.org/abs/2506.15741)
Token length: 1242
Summarized using qwen-turbo
Append: [LLM jailbreak攻击防护机制的系统性分析](https://arxiv.org/abs/2506.10597)
append_entries: 23
Finish: 2025-06-24 12:32:56.708048
------------------------------------------------------
Started: 2025-06-24 18:21:13.240922
Existing_entries: 1023
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1207
Summarized using qwen-turbo
Append: [基于两阶段优化的长视频照明编辑方法TC-Light](https://arxiv.org/abs/2506.18904)
Token length: 1213
Summarized using qwen-turbo
Append: [RealPlay：基于神经网络的实时交互视频生成引擎](https://arxiv.org/abs/2506.18901)
Token length: 1048
Summarized using qwen-turbo
Append: [多面板故事可视化中的协作多智能体框架](https://arxiv.org/abs/2506.18900)
Token length: 1493
Summarized using qwen-turbo
Append: [基于梯度优化的隐空间激活控制方法提升科学代码生成语言偏向性](https://arxiv.org/abs/2506.18887)
Token length: 1579
Summarized using qwen-turbo
Append: [3D Arena平台：基于人类偏好的生成式3D模型评估](https://arxiv.org/abs/2506.18787)
Token length: 1094
Summarized using qwen-turbo
Append: [DIP：一种用于提升密集图像表示的无监督后训练方法](https://arxiv.org/abs/2506.18463)
Token length: 1159
Summarized using qwen-turbo
Append: [基于视觉定位的医学视觉问答方法研究](https://arxiv.org/abs/2506.17939)
Token length: 1845
Summarized using qwen-turbo
Append: [大语言模型输出稳定性的概率集中现象研究](https://arxiv.org/abs/2506.17871)
Token length: 1537
Summarized using qwen-turbo
Append: [多文化音乐基础模型CultureMERT-95M提升跨文化音乐表示学习](https://arxiv.org/abs/2506.17818)
Token length: 1228
Summarized using qwen-turbo
Append: [TPTT框架提升大语言模型效率与准确性](https://arxiv.org/abs/2506.17671)
Token length: 1062
Summarized using qwen-turbo
Append: [基于前馈架构的4D视频与3D高斯粒子联合生成框架](https://arxiv.org/abs/2506.18839)
Token length: 1425
Summarized using qwen-turbo
Append: [视觉质量对多模态大语言模型性能的影响及优化方法](https://arxiv.org/abs/2506.15645)
append_entries: 12
Finish: 2025-06-24 18:22:26.308843
------------------------------------------------------
Started: 2025-06-25 01:13:42.293069
Existing_entries: 1012
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1052
Summarized using qwen-turbo
Append: [4D-LRM：大规模时空重建模型实现任意视角与时间的高质量渲染](https://arxiv.org/abs/2506.18890)
Token length: 1080
Summarized using qwen-turbo
Append: [基于强化学习的多模态大语言模型个性化图像描述方法](https://arxiv.org/abs/2506.18369)
Token length: 1911
Summarized using qwen-turbo
Append: [基于LLM代理的复杂规格到RTL代码生成系统](https://arxiv.org/abs/2506.13905)
append_entries: 3
Finish: 2025-06-25 01:14:00.080463
------------------------------------------------------
Started: 2025-06-25 06:23:03.926506
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1310
Summarized using qwen-turbo
Append: [AnimaX：一种基于视频扩散模型的3D动画生成框架](https://arxiv.org/abs/2506.19851)
Token length: 1732
Summarized using qwen-turbo
Append: [ScaleCap：一种可扩展的图像描述生成策略](https://arxiv.org/abs/2506.19848)
Token length: 1653
Summarized using qwen-turbo
Append: [基于级联视频超分辨率的高效视频生成方法研究](https://arxiv.org/abs/2506.19838)
Token length: 1498
Summarized using qwen-turbo
Append: [基于知识增强的强化学习缓解大语言模型幻觉问题](https://arxiv.org/abs/2506.19807)
Token length: 923
Summarized using qwen-turbo
Append: [提升开源大语言模型数据分析能力的研究](https://arxiv.org/abs/2506.19794)
Token length: 1163
Summarized using qwen-turbo
Append: [SRFT：统一SFT与RL的单阶段语言模型微调方法](https://arxiv.org/abs/2506.19767)
Token length: 1920
Summarized using qwen-turbo
Append: [自动化数据集构建提升LLM在软件工程任务中的表现](https://arxiv.org/abs/2506.19290)
Token length: 777
Summarized using qwen-turbo
Append: [统一音频表示学习方法USAD在多类型音频任务中表现优异](https://arxiv.org/abs/2506.18843)
Token length: 1622
Summarized using qwen-turbo
Append: [基于多模态大语言模型的智能照片修图系统 JarvisArt](https://arxiv.org/abs/2506.17612)
Token length: 1897
Summarized using qwen-turbo
Append: [提升多模态大语言模型推理一致性的强化学习方法研究](https://arxiv.org/abs/2506.16141)
Token length: 981
Summarized using qwen-turbo
Append: [代码转换对大语言模型理解能力的影响研究](https://arxiv.org/abs/2506.14012)
append_entries: 11
Finish: 2025-06-25 06:24:14.532067
------------------------------------------------------
Started: 2025-06-25 12:31:14.797015
Existing_entries: 1011
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-25 12:31:15.091124
------------------------------------------------------
Started: 2025-06-25 18:21:22.380088
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-25 18:21:22.751590
------------------------------------------------------
Started: 2025-06-26 01:12:39.597408
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-26 01:12:39.899963
------------------------------------------------------
Started: 2025-06-26 06:22:13.838293
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-26 06:22:14.149916
------------------------------------------------------
Started: 2025-06-26 12:30:40.975286
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-26 12:30:41.254430
------------------------------------------------------
Started: 2025-06-26 18:21:07.874207
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-26 18:21:08.241620
------------------------------------------------------
Started: 2025-06-27 01:13:26.436828
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-27 01:13:26.767524
------------------------------------------------------
Started: 2025-06-27 06:22:35.142438
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-27 06:22:35.407813
------------------------------------------------------
Started: 2025-06-27 12:29:35.893288
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-27 12:29:36.233285
------------------------------------------------------
Started: 2025-06-27 18:20:37.000421
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-27 18:20:37.271240
------------------------------------------------------
Started: 2025-06-28 01:10:30.511639
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-28 01:10:30.897486
------------------------------------------------------
Started: 2025-06-28 06:20:14.092492
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-28 06:20:14.394307
------------------------------------------------------
Started: 2025-06-28 12:27:15.048258
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 880
Summarized using qwen-turbo
Append: [基于人体动作的自我中心视频预测模型PEVA](https://arxiv.org/abs/2506.21552)
Token length: 1885
Summarized using qwen-turbo
Append: [大语言模型预训练中的grokking现象与泛化机制研究](https://arxiv.org/abs/2506.21551)
Token length: 1148
Summarized using qwen-turbo
Append: [SAM4D：多模态时序基础模型用于相机与激光雷达的可提示分割](https://arxiv.org/abs/2506.21547)
Token length: 1298
Summarized using qwen-turbo
Append: [WorldVLA：统一动作与图像理解的自回归世界模型](https://arxiv.org/abs/2506.21539)
Token length: 1214
Summarized using qwen-turbo
Append: [MADrive：基于记忆增强的自动驾驶场景重建方法](https://arxiv.org/abs/2506.21520)
Token length: 1478
Summarized using qwen-turbo
Append: [Mind2Web 2：面向智能搜索系统的长期任务基准与评估框架](https://arxiv.org/abs/2506.21506)
Token length: 1903
Summarized using qwen-turbo
Append: [FairyGen：基于单幅儿童画生成叙事动画视频的系统](https://arxiv.org/abs/2506.21272)
Token length: 1360
Summarized using qwen-turbo
Append: [DiLoCoX：一种用于超大规模模型的低通信去中心化训练框架](https://arxiv.org/abs/2506.21263)
Token length: 1285
Summarized using qwen-turbo
Append: [动态跳过中间层的Transformer架构优化研究](https://arxiv.org/abs/2506.21103)
Token length: 1595
Summarized using qwen-turbo
Append: [PhysRig：基于物理的可微分皮肤绑定与骨骼框架](https://arxiv.org/abs/2506.20936)
Token length: 1461
Summarized using qwen-turbo
Append: [基于神经符号的高效图像编辑代理FaSTA^*](https://arxiv.org/abs/2506.20911)
Token length: 907
Summarized using qwen-turbo
Append: [基于生成块的世界：通过几何抽象交互生成图像场景](https://arxiv.org/abs/2506.20703)
Token length: 1418
Summarized using qwen-turbo
Append: [基于强化学习的多模态搜索框架MMSearch-R1](https://arxiv.org/abs/2506.20670)
Token length: 1880
Summarized using qwen-turbo
Append: [DeepRare：基于大语言模型的罕见病诊断系统](https://arxiv.org/abs/2506.20430)
Token length: 1167
Summarized using qwen-turbo
Append: [MuseControlLite：轻量级文本到音乐生成模型微调机制](https://arxiv.org/abs/2506.18729)
Token length: 1061
Summarized using qwen-turbo
Append: [DuaShepherd：融合正确性与潜力的奖励建模框架提升大语言模型数学推理能力](https://arxiv.org/abs/2506.17533)
Token length: 1406
Summarized using qwen-turbo
Append: [基于用户偏好的大语言模型路由框架](https://arxiv.org/abs/2506.16655)
Token length: 1333
Summarized using qwen-turbo
Append: [基于大语言模型的超启发式框架HeurAgenix在组合优化中的应用](https://arxiv.org/abs/2506.15196)
append_entries: 18
Finish: 2025-06-28 12:29:11.956748
------------------------------------------------------
Started: 2025-06-28 18:18:53.990580
Existing_entries: 1018
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-28 18:18:54.367658
------------------------------------------------------
Started: 2025-06-29 01:20:39.780577
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-29 01:20:39.959601
------------------------------------------------------
Started: 2025-06-29 06:20:45.464237
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-29 06:20:45.716370
------------------------------------------------------
Started: 2025-06-29 12:27:50.264366
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-29 12:27:50.485536
------------------------------------------------------
Started: 2025-06-29 18:19:06.229326
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-29 18:19:06.480133
------------------------------------------------------
Started: 2025-06-30 01:17:32.804529
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-06-30 01:17:33.000878
------------------------------------------------------
Started: 2025-06-30 06:23:14.242413
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1272
Summarized using qwen-turbo
Append: [LLaVA-Scissor：一种用于视频多模态大语言模型的无训练令牌压缩策略](https://arxiv.org/abs/2506.21862)
Token length: 1225
Summarized using qwen-turbo
Append: [SpatialReasoner-R1：提升视觉语言模型空间推理能力的新方法](https://arxiv.org/abs/2506.21656)
append_entries: 2
Finish: 2025-06-30 06:23:25.273378
------------------------------------------------------
Started: 2025-06-30 12:30:49.625481
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1406
Summarized using qwen-turbo
Append: [基于视觉对比的链式推理方法研究](https://arxiv.org/abs/2506.22434)
Token length: 1337
Summarized using qwen-turbo
Append: [评估大语言模型在科学再现任务中的能力](https://arxiv.org/abs/2506.22419)
Token length: 1524
Summarized using qwen-turbo
Append: [基于视觉-语言预训练的RetFiner提升OCT图像分类性能](https://arxiv.org/abs/2506.22149)
Token length: 889
Summarized using qwen-turbo
Append: [XVerse：实现多主体精细控制的文本生成模型](https://arxiv.org/abs/2506.21416)
Token length: 1600
Summarized using qwen-turbo
Append: [ShotBench与ShotVL：推动电影语言理解的AI基准与模型](https://arxiv.org/abs/2506.21356)
Token length: 1311
Summarized using qwen-turbo
Append: [DenseDiT：基于生成模型的密集预测方法在真实场景中的应用](https://arxiv.org/abs/2506.20279)
Token length: 1567
Summarized using qwen-turbo
Append: [ARK：一个面向自主机器人的Python优先开源框架](https://arxiv.org/abs/2506.21628)
Token length: 1753
Summarized using qwen-turbo
Append: [基于噪声一致性的高效可控生成方法NCT](https://arxiv.org/abs/2506.19741)
Token length: 913
Summarized using qwen-turbo
Append: [BlenderFusion：一种生成式视觉合成框架](https://arxiv.org/abs/2506.17450)
Token length: 1555
Summarized using qwen-turbo
Append: [Gazal-R1：医疗推理领域的高性能语言模型](https://arxiv.org/abs/2506.21594)
Token length: 1909
Summarized using qwen-turbo
Append: [Mixture of Grouped Experts 提升大模型推理效率与负载均衡](https://arxiv.org/abs/2505.21411)
append_entries: 11
Finish: 2025-06-30 12:31:49.286597
------------------------------------------------------
Started: 2025-06-30 18:20:52.735978
Existing_entries: 1011
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1640
Summarized using qwen-turbo
Append: [基于3D代理的视频编辑框架Shape-for-Motion](https://arxiv.org/abs/2506.22432)
Token length: 1159
Summarized using qwen-turbo
Append: [GPAS提升预归一化Transformer的训练效果](https://arxiv.org/abs/2506.22049)
Token length: 1020
Summarized using qwen-turbo
Append: [基于文本到文本回归的系统资源效率预测方法](https://arxiv.org/abs/2506.21718)
Token length: 1035
Summarized using qwen-turbo
Append: [基于RCME框架的视觉-语言模型层次结构学习](https://arxiv.org/abs/2506.21476)
Token length: 1635
Summarized using qwen-turbo
Append: [多模态上下文学习在医学任务中的挑战与评估](https://arxiv.org/abs/2506.21355)
Token length: 1409
Summarized using qwen-turbo
Append: [Confucius3-Math：面向中国K-12数学教育的高效大语言模型](https://arxiv.org/abs/2506.18330)
Token length: 1842
Summarized using qwen-turbo
Append: [基于贝叶斯框架的上下文学习策略分析](https://arxiv.org/abs/2506.17859)
append_entries: 7
Finish: 2025-06-30 18:21:29.174687
------------------------------------------------------
Started: 2025-07-01 01:20:55.724042
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1477
Summarized using qwen-turbo
Append: [视觉语言模型在世界建模能力上的系统评估](https://arxiv.org/abs/2506.21876)
Token length: 1379
Summarized using qwen-turbo
Append: [提升视觉语言模型的空间想象能力：MindCube基准与新方法](https://arxiv.org/abs/2506.21458)
Token length: 931
Summarized using qwen-turbo
Append: [TAPAS：基于多智能体的复杂任务求解框架](https://arxiv.org/abs/2506.19592)
Token length: 1321
Summarized using qwen-turbo
Append: [Fractional Reasoning：动态调整推理强度提升大语言模型性能](https://arxiv.org/abs/2506.15882)
append_entries: 4
Finish: 2025-07-01 01:21:18.437931
------------------------------------------------------
Started: 2025-07-01 06:23:21.097816
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1335
Summarized using qwen-turbo
Append: [Calligrapher：基于扩散模型的数字书法与设计框架](https://arxiv.org/abs/2506.24123)
Token length: 1629
Summarized using qwen-turbo
Append: [视频扩散模型中的稀疏注意力机制VMoBA](https://arxiv.org/abs/2506.23858)
Token length: 1200
Summarized using qwen-turbo
Append: [推理时技术在视觉语言模型中的有效性研究](https://arxiv.org/abs/2506.17417)
append_entries: 3
Finish: 2025-07-01 06:23:36.900933
------------------------------------------------------
Started: 2025-07-01 12:30:54.149389
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1698
Summarized using qwen-turbo
Append: [基于自对弈的强化学习框架SPIRAL提升语言模型推理能力](https://arxiv.org/abs/2506.24119)
Token length: 1427
Summarized using qwen-turbo
Append: [基于运动不变图融合的ToF深度去噪网络](https://arxiv.org/abs/2506.23542)
Token length: 1485
Summarized using qwen-turbo
Append: [多语言模型工具调用能力提升方法研究](https://arxiv.org/abs/2506.23394)
Token length: 1504
Summarized using qwen-turbo
Append: [UrbanLLaVA：面向城市研究的多模态大语言模型](https://arxiv.org/abs/2506.23219)
Token length: 1401
Summarized using qwen-turbo
Append: [RoboScape：一种融合物理知识的统一世界模型](https://arxiv.org/abs/2506.23135)
Token length: 1258
Summarized using qwen-turbo
Append: [Ovis-U1：一款融合多模态理解与生成能力的大型统一模型](https://arxiv.org/abs/2506.23044)
Token length: 1481
Summarized using qwen-turbo
Append: [提出MARBLE基准测试，推动多模态推理模型发展](https://arxiv.org/abs/2506.22992)
Token length: 1594
Summarized using qwen-turbo
Append: [基于监听器增强的GRPO框架提升视觉语言模型对齐效果](https://arxiv.org/abs/2506.22832)
Token length: 1629
Summarized using qwen-turbo
Append: [基于语言模型头的无训练优化方法提升推测解码性能](https://arxiv.org/abs/2506.22694)
Token length: 1413
Summarized using qwen-turbo
Append: [ThinkSound：基于思维链推理的视频到音频生成框架](https://arxiv.org/abs/2506.21448)
Token length: 1591
Summarized using qwen-turbo
Append: [基于随机演示剪枝的新型提示设计范式](https://arxiv.org/abs/2506.17930)
Token length: 938
Summarized using qwen-turbo
Append: [SparseLoRA：通过上下文稀疏性加速大模型微调](https://arxiv.org/abs/2506.16500)
append_entries: 12
Finish: 2025-07-01 12:31:52.126466
------------------------------------------------------
Started: 2025-07-01 18:20:55.100051
Existing_entries: 1012
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1321
Summarized using qwen-turbo
Append: [MEMFOF：高效多帧光流估计方法](https://arxiv.org/abs/2506.23151)
Token length: 1320
Summarized using qwen-turbo
Append: [基于多路径扩散的可调金属镜头摄影方法](https://arxiv.org/abs/2506.22753)
Token length: 1446
Summarized using qwen-turbo
Append: [评估大型语言模型代理在研究扩展任务中的能力](https://arxiv.org/abs/2506.22598)
Token length: 1734
Summarized using qwen-turbo
Append: [Tower+：在翻译与多语言通用能力之间实现性能平衡的模型](https://arxiv.org/abs/2506.17080)
append_entries: 4
Finish: 2025-07-01 18:21:15.318810
------------------------------------------------------
Started: 2025-07-02 01:13:17.627639
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-07-02 01:13:17.883693
------------------------------------------------------
Started: 2025-07-02 06:22:50.587821
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1285
Summarized using qwen-turbo
Append: [数学推理模型的泛化能力与训练方法研究](https://arxiv.org/abs/2507.00432)
Token length: 1464
Summarized using qwen-turbo
Append: [MoCa：提升多模态嵌入模型性能的两阶段框架](https://arxiv.org/abs/2506.23115)
Token length: 1886
Summarized using qwen-turbo
Append: [提升多模态大语言模型推理能力的研究](https://arxiv.org/abs/2506.21277)
append_entries: 3
Finish: 2025-07-02 06:23:02.458418
------------------------------------------------------
Started: 2025-07-02 12:30:36.431472
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1479
Summarized using qwen-turbo
Append: [GLM-4.1V-Thinking：多模态推理模型的进展与性能评估](https://arxiv.org/abs/2507.01006)
Token length: 1496
Summarized using qwen-turbo
Append: [SciArena：科学文献任务的开放协作评估平台](https://arxiv.org/abs/2507.01001)
Token length: 1841
Summarized using qwen-turbo
Append: [迈向通用人工智能：跨学科视角下的认知与架构分析](https://arxiv.org/abs/2507.00951)
Token length: 1485
Summarized using qwen-turbo
Append: [AI生成内容激增与新型水印技术PECCAVI的提出](https://arxiv.org/abs/2506.22960)
Token length: 1669
Summarized using qwen-turbo
Append: [提升语言模型训练效果的数据效能研究](https://arxiv.org/abs/2506.21545)
Token length: 1576
Summarized using qwen-turbo
Append: [扩散语言模型在代码生成中的应用与优化](https://arxiv.org/abs/2506.20639)
Token length: 1552
Summarized using qwen-turbo
Append: [基于时空能量衰减的径向注意力机制提升视频生成效率](https://arxiv.org/abs/2506.19852)
append_entries: 7
Finish: 2025-07-02 12:31:07.365569
------------------------------------------------------
Started: 2025-07-02 18:21:16.447280
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1891
Summarized using qwen-turbo
Append: [FreeLong++：提升长视频生成质量的训练无关框架](https://arxiv.org/abs/2507.00162)
Token length: 1256
Summarized using qwen-turbo
Append: [IR3D-Bench：通过主动创造评估视觉语言模型的场景理解能力](https://arxiv.org/abs/2506.23329)
append_entries: 2
Finish: 2025-07-02 18:21:25.828090
------------------------------------------------------
Started: 2025-07-03 01:13:13.757914
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 945
Summarized using qwen-turbo
Append: [Mixture of Reasoning：提升大语言模型推理能力的新框架](https://arxiv.org/abs/2507.00606)
Token length: 1126
Summarized using qwen-turbo
Append: [基于频率修正的神经材质表示方法FreNBRDF](https://arxiv.org/abs/2507.00476)
Token length: 1788
Summarized using qwen-turbo
Append: [MOVi-MC-AC：首个多摄像头视图的非模态分割与内容数据集](https://arxiv.org/abs/2507.00339)
Token length: 1014
Summarized using qwen-turbo
Append: [MusiXQA：推动多模态大模型理解乐谱的基准数据集](https://arxiv.org/abs/2506.23009)
Token length: 840
Summarized using qwen-turbo
Append: [基于置信度的3D高斯点云压缩方法](https://arxiv.org/abs/2506.22973)
append_entries: 5
Finish: 2025-07-03 01:13:35.860281
------------------------------------------------------
Started: 2025-07-03 06:22:48.156934
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1768
Summarized using qwen-turbo
Append: [Kwai Keye-VL：面向短视频理解的多模态大模型](https://arxiv.org/abs/2507.01949)
Token length: 1645
Summarized using qwen-turbo
Append: [基于动态全局-局部范式的长动画上色方法研究](https://arxiv.org/abs/2507.01945)
Token length: 1229
Summarized using qwen-turbo
Append: [DepthAnything-AC：一种适应多种环境的单目深度估计模型](https://arxiv.org/abs/2507.01634)
Token length: 1243
Summarized using qwen-turbo
Append: [JAM-Flow：统一生成面部动作与语音的框架](https://arxiv.org/abs/2506.23552)
append_entries: 4
Finish: 2025-07-03 06:23:06.027784
------------------------------------------------------
Started: 2025-07-03 12:30:46.885102
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1293
Summarized using qwen-turbo
Append: [Locality-aware Parallel Decoding加速自回归图像生成](https://arxiv.org/abs/2507.01957)
Token length: 1340
Summarized using qwen-turbo
Append: [FreeMorph：无需微调的高效图像形态转换方法](https://arxiv.org/abs/2507.01953)
Token length: 1516
Summarized using qwen-turbo
Append: [视觉-语言-动作模型中的动作标记化研究综述](https://arxiv.org/abs/2507.01925)
Token length: 1142
Summarized using qwen-turbo
Append: [STR-Match：一种无需训练的视频编辑算法](https://arxiv.org/abs/2506.22868)
append_entries: 4
Finish: 2025-07-03 12:31:02.959341
------------------------------------------------------
Started: 2025-07-03 18:20:45.972970
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1103
Summarized using qwen-turbo
Append: [MARVIS：一种无需训练的多模态推理方法](https://arxiv.org/abs/2507.01544)
Token length: 1585
Summarized using qwen-turbo
Append: [基于自回归框架的实时交互式头部生成方法](https://arxiv.org/abs/2507.00472)
append_entries: 2
Finish: 2025-07-03 18:20:54.053669
------------------------------------------------------
Started: 2025-07-04 01:12:41.288211
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1089
Summarized using qwen-turbo
Append: [多尺度多模态大语言模型在自动放射学报告生成中的应用](https://arxiv.org/abs/2507.00316)
append_entries: 1
Finish: 2025-07-04 01:12:46.804576
------------------------------------------------------
Started: 2025-07-04 06:22:24.040441
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1562
Summarized using qwen-turbo
Append: [基于语言理解的3D场景重建框架LangScene-X](https://arxiv.org/abs/2507.02813)
Token length: 1202
Summarized using qwen-turbo
Append: [2-单纯形Transformer提升token效率的研究](https://arxiv.org/abs/2507.02754)
Token length: 982
Summarized using qwen-turbo
Append: [基于自生成目标条件MDPs的自动定理证明方法](https://arxiv.org/abs/2507.02726)
Token length: 1393
Summarized using qwen-turbo
Append: [HiRA：一种分层框架提升复杂信息检索与推理效率](https://arxiv.org/abs/2507.02652)
Token length: 1046
Summarized using qwen-turbo
Append: [提升大模型信息检索能力的WebSailor方法](https://arxiv.org/abs/2507.02592)
Token length: 1917
Summarized using qwen-turbo
Append: [提升奖励模型性能：基于高质量数据集的Skywork-Reward-V2研究](https://arxiv.org/abs/2507.01352)
append_entries: 6
Finish: 2025-07-04 06:22:47.940579
------------------------------------------------------
Started: 2025-07-04 12:29:49.011042
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1192
Summarized using qwen-turbo
Append: [大型语言模型的自我纠正盲点研究](https://arxiv.org/abs/2507.02778)
Token length: 1206
Summarized using qwen-turbo
Append: [利用LLM辅助科学论文局限性识别的基准研究](https://arxiv.org/abs/2507.02694)
Token length: 1909
Summarized using qwen-turbo
Append: [基于能量模型的系统2思维推理方法研究](https://arxiv.org/abs/2507.02092)
Token length: 718
Summarized using qwen-turbo
Append: [IntFold：一种可控制的生物分子结构预测基础模型](https://arxiv.org/abs/2507.02025)
Token length: 1563
Summarized using qwen-turbo
Append: [AsyncFlow：一种高效的异步流式强化学习框架](https://arxiv.org/abs/2507.01663)
Token length: 1635
Summarized using qwen-turbo
Append: [ZeCO：实现线性注意力模型高效序列并行的新方法](https://arxiv.org/abs/2507.01004)
Token length: 1679
Summarized using qwen-turbo
Append: [多模态推理中‘思考与图像’范式的演进与展望](https://arxiv.org/abs/2506.23918)
Token length: 1361
Summarized using qwen-turbo
Append: [动态选择与合并专家模型提升跨领域信息抽取性能](https://arxiv.org/abs/2506.22813)
append_entries: 8
Finish: 2025-07-04 12:30:20.599737
------------------------------------------------------
Started: 2025-07-04 18:20:00.422741
Existing_entries: 1008
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1177
Summarized using qwen-turbo
Append: [InnerControl：提升扩散模型空间控制精度的新方法](https://arxiv.org/abs/2507.02321)
append_entries: 1
Finish: 2025-07-04 18:20:04.030539
------------------------------------------------------
Started: 2025-07-05 01:10:10.081671
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1223
Summarized using qwen-turbo
Append: [视觉语言分割中的幻觉评估基准研究](https://arxiv.org/abs/2506.21546)
append_entries: 1
Finish: 2025-07-05 01:10:13.469077
------------------------------------------------------
Started: 2025-07-05 06:20:15.550153
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1599
Summarized using qwen-turbo
Append: [基于文本描述的多器官医学分割模型CRISP-SAM2](https://arxiv.org/abs/2506.23121)
append_entries: 1
Finish: 2025-07-05 06:20:18.426593
------------------------------------------------------
Started: 2025-07-05 12:27:16.787895
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-07-05 12:27:16.994713
------------------------------------------------------
Started: 2025-07-05 18:18:30.635982
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-07-05 18:18:30.797679
------------------------------------------------------
Started: 2025-07-06 01:19:28.988513
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-07-06 01:19:29.166841
------------------------------------------------------
Started: 2025-07-06 06:20:39.294632
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-07-06 06:20:39.458434
------------------------------------------------------
Started: 2025-07-06 12:27:32.654987
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-07-06 12:27:32.885347
------------------------------------------------------
Started: 2025-07-06 18:19:19.928395
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-07-06 18:19:20.148717
------------------------------------------------------
Started: 2025-07-07 01:17:33.183553
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-07-07 01:17:33.337042
------------------------------------------------------
Started: 2025-07-07 06:23:43.068936
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-07-07 06:23:43.216166
------------------------------------------------------
Started: 2025-07-07 12:30:40.393918
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1805
Summarized using qwen-turbo
Append: [多模态基础模型在计算机视觉任务中的性能评估](https://arxiv.org/abs/2507.01955)
Token length: 1143
Summarized using qwen-turbo
Append: [EKA-EVAL：面向多语言大模型的统一评估框架](https://arxiv.org/abs/2507.01853)
append_entries: 2
Finish: 2025-07-07 12:30:49.411834
------------------------------------------------------
Started: 2025-07-07 18:20:55.719019
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 872
Summarized using qwen-turbo
Append: [扩散模型在动态系统模拟中的潜在应用](https://arxiv.org/abs/2507.02608)
Token length: 1494
Summarized using qwen-turbo
Append: [LitBench：首个用于创意写作评估的标准化基准与数据集](https://arxiv.org/abs/2507.00769)
append_entries: 2
Finish: 2025-07-07 18:21:03.333496
------------------------------------------------------
Started: 2025-07-08 01:13:41.931483
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-07-08 01:13:42.162485
------------------------------------------------------
Started: 2025-07-08 06:22:28.952176
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-07-08 06:22:29.107677
------------------------------------------------------
Started: 2025-07-08 12:31:13.564814
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1008
Summarized using qwen-turbo
Append: [基于多模态大语言模型的图像编辑系统X-Planner](https://arxiv.org/abs/2507.05259)
Token length: 1783
Summarized using qwen-turbo
Append: [基于策略判别器的奖励建模方法POLAR及其性能提升](https://arxiv.org/abs/2507.05197)
Token length: 1330
Summarized using qwen-turbo
Append: [基于低帧率相机的高速4D捕捉系统](https://arxiv.org/abs/2507.05163)
Token length: 1450
Summarized using qwen-turbo
Append: [自动化历史文献修复方法与全页数据集研究](https://arxiv.org/abs/2507.05108)
Token length: 1658
Summarized using qwen-turbo
Append: [ArtifactsBench：自动化评估视觉代码生成的新基准](https://arxiv.org/abs/2507.04952)
Token length: 1560
Summarized using qwen-turbo
Append: [VLM2Vec-V2：跨多种视觉形式的统一嵌入框架](https://arxiv.org/abs/2507.04590)
Token length: 530
Summarized using qwen-turbo
Append: [大型语言模型在预测任务中的表现评估](https://arxiv.org/abs/2507.04562)
Token length: 1651
Summarized using qwen-turbo
Append: [DreamVLA：融合世界知识预测的视觉-语言-动作框架](https://arxiv.org/abs/2507.04447)
Token length: 1362
Summarized using qwen-turbo
Append: [MOD-X：面向异构智能体的模块化开放去中心化交换框架](https://arxiv.org/abs/2507.04376)
Token length: 1916
Summarized using qwen-turbo
Append: [SeqTex：基于视频预训练模型的端到端3D纹理生成框架](https://arxiv.org/abs/2507.04285)
Token length: 1430
Summarized using qwen-turbo
Append: [PresentAgent：将长文档转化为同步视听演示的多模态代理](https://arxiv.org/abs/2507.04036)
Token length: 1270
Summarized using qwen-turbo
Append: [基于GUI的统一数据集合成框架Easy Dataset提升领域语言模型性能](https://arxiv.org/abs/2507.04009)
Token length: 1478
Summarized using qwen-turbo
Append: [StreamDiT：实现实时视频生成的流式模型](https://arxiv.org/abs/2507.03745)
Token length: 1906
Summarized using qwen-turbo
Append: [MemOS：面向持续学习与个性化建模的内存操作系统](https://arxiv.org/abs/2507.03724)
Token length: 448
Summarized using qwen-turbo
Append: [基于Transformer的软件漏洞严重性预测模型VLAI](https://arxiv.org/abs/2507.03607)
Token length: 1742
Summarized using qwen-turbo
Append: [BMMR：多语言、多模态、跨学科推理数据集的构建与应用](https://arxiv.org/abs/2507.03483)
Token length: 1226
Summarized using qwen-turbo
Append: [DiaFORGE提升企业API调用成功率的对话框架研究](https://arxiv.org/abs/2507.03336)
Token length: 1783
Summarized using qwen-turbo
Append: [RefineX：大规模预训练数据的精准优化框架](https://arxiv.org/abs/2507.03253)
Token length: 1407
Summarized using qwen-turbo
Append: [OmniDraft：一种支持多模型协同的高效推测解码框架](https://arxiv.org/abs/2507.02659)
Token length: 1267
Summarized using qwen-turbo
Append: [RoboBrain 2.0：面向物理环境的多模态AI模型](https://arxiv.org/abs/2507.02029)
Token length: 1534
Summarized using qwen-turbo
Append: [对比MLM与CLM在文本表示学习中的效果与优化策略](https://arxiv.org/abs/2507.00994)
append_entries: 21
Finish: 2025-07-08 12:32:41.051740
------------------------------------------------------
Started: 2025-07-08 18:21:12.646244
Existing_entries: 1021
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 824
Summarized using qwen-turbo
Append: [视觉嵌入模型中的有序属性捕捉研究](https://arxiv.org/abs/2507.03683)
Token length: 1143
Summarized using qwen-turbo
Append: [UnMix-NeRF：结合光谱解混的神经辐射场方法](https://arxiv.org/abs/2506.21884)
append_entries: 2
Finish: 2025-07-08 18:21:20.511260
------------------------------------------------------
Started: 2025-07-09 01:14:30.471322
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1526
Summarized using qwen-turbo
Append: [面向记忆代理的基准测试MemoryAgentBench](https://arxiv.org/abs/2507.05257)
Token length: 991
Summarized using qwen-turbo
Append: [基于强化学习的实体关系抽取方法研究](https://arxiv.org/abs/2507.04642)
Token length: 1897
Summarized using qwen-turbo
Append: [基于Llama 3.2 1B的隐私保护医疗转录系统研究](https://arxiv.org/abs/2507.03033)
append_entries: 3
Finish: 2025-07-09 01:14:41.251192
------------------------------------------------------
Started: 2025-07-09 06:22:54.424304
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1240
Summarized using qwen-turbo
Append: [基于FLOPs的LLM重排序器效率评估方法研究](https://arxiv.org/abs/2507.06223)
Token length: 1612
Summarized using qwen-turbo
Append: [数据多样性在机器人操作中的关键作用研究](https://arxiv.org/abs/2507.06219)
Token length: 1514
Summarized using qwen-turbo
Append: [潜层推理：大语言模型的多步骤推理新范式](https://arxiv.org/abs/2507.06203)
Token length: 1464
Summarized using qwen-turbo
Append: [CriticLean：提升形式化语义准确性的强化学习框架](https://arxiv.org/abs/2507.06181)
Token length: 1230
Summarized using qwen-turbo
Append: [OmniPart：支持语义解耦与结构一致的3D对象生成框架](https://arxiv.org/abs/2507.06165)
Token length: 1179
Summarized using qwen-turbo
Append: [Code Triangle框架评估大语言模型的编程能力](https://arxiv.org/abs/2507.06138)
Token length: 1403
Summarized using qwen-turbo
Append: [Tora2：多实体视频生成的运动引导模型改进](https://arxiv.org/abs/2507.05963)
Token length: 1699
Summarized using qwen-turbo
Append: [基于多轮定位的策略优化方法提升大模型视觉理解能力](https://arxiv.org/abs/2507.05920)
Token length: 1914
Summarized using qwen-turbo
Append: [GUI代理任务规划与视觉定位的优化方法](https://arxiv.org/abs/2507.05791)
Token length: 1238
Summarized using qwen-turbo
Append: [医学视频生成新进展：MedVideoCap-55K数据集与MedGen模型](https://arxiv.org/abs/2507.05675)
Token length: 1370
Summarized using qwen-turbo
Append: [大型语言模型中的数据记忆现象研究](https://arxiv.org/abs/2507.05578)
Token length: 1835
Summarized using qwen-turbo
Append: [PRING：首个基于图级别的蛋白质相互作用预测基准](https://arxiv.org/abs/2507.05101)
Token length: 1109
Summarized using qwen-turbo
Append: [any4：一种无需预处理的4位权重量化方法](https://arxiv.org/abs/2507.04610)
Token length: 1333
Summarized using qwen-turbo
Append: [基于LLM的网络代理计算资源优化研究](https://arxiv.org/abs/2507.04103)
Token length: 1168
Summarized using qwen-turbo
Append: [SAMed-2：基于SAM-2架构的医学图像分割基础模型](https://arxiv.org/abs/2507.03698)
Token length: 1497
Summarized using qwen-turbo
Append: [基于可验证情感奖励的强化学习框架提升语言模型情感智能](https://arxiv.org/abs/2507.03112)
append_entries: 16
Finish: 2025-07-09 06:24:27.351392
------------------------------------------------------
Started: 2025-07-09 12:31:07.480809
Existing_entries: 1016
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1255
Summarized using qwen-turbo
Append: [改进Mamba模型的注意力分配机制](https://arxiv.org/abs/2507.06204)
Token length: 1349
Summarized using qwen-turbo
Append: [SingLoRA：一种更稳定且参数更少的低秩微调方法](https://arxiv.org/abs/2507.05566)
Token length: 1173
Summarized using qwen-turbo
Append: [AXLearn：模块化深度学习系统的设计与实现](https://arxiv.org/abs/2507.05411)
Token length: 1286
Summarized using qwen-turbo
Append: [StreamVLN：一种高效的多模态视觉语言导航框架](https://arxiv.org/abs/2507.05240)
Token length: 907
Summarized using qwen-turbo
Append: [LOOM-Scope：一种高效且全面的长上下文评估框架](https://arxiv.org/abs/2507.04723)
Token length: 918
Summarized using qwen-turbo
Append: [Nile-Chat系列模型：支持阿拉伯语和拉丁语的埃及方言大语言模型](https://arxiv.org/abs/2507.04569)
Token length: 1437
Summarized using qwen-turbo
Append: [基于属性切换的公平图生成框架FAROS](https://arxiv.org/abs/2507.03728)
append_entries: 7
Finish: 2025-07-09 12:31:35.674885
------------------------------------------------------
Started: 2025-07-09 18:21:13.433277
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1121
Summarized using qwen-turbo
Append: [无监督语义场景补全方法SceneDINO的研究](https://arxiv.org/abs/2507.06230)
append_entries: 1
Finish: 2025-07-09 18:21:17.692279
------------------------------------------------------
Started: 2025-07-10 01:14:28.908666
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1056
Summarized using qwen-turbo
Append: [Agent KB：提升智能体错误纠正与跨领域知识复用的框架](https://arxiv.org/abs/2507.06229)
Token length: 1810
Summarized using qwen-turbo
Append: [NeoBabel：多语言图像生成的新范式](https://arxiv.org/abs/2507.06137)
Token length: 1905
Summarized using qwen-turbo
Append: [MedGemma：医疗视觉-语言基础模型的开发与应用](https://arxiv.org/abs/2507.05201)
Token length: 1097
Summarized using qwen-turbo
Append: [世界模型的理论探讨与新型架构设计](https://arxiv.org/abs/2507.05169)
append_entries: 4
Finish: 2025-07-10 01:14:52.173298
------------------------------------------------------
Started: 2025-07-10 06:23:27.564858
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1368
Summarized using qwen-turbo
Append: [推动文本到动作生成的零样本泛化能力](https://arxiv.org/abs/2507.07095)
Token length: 839
Summarized using qwen-turbo
Append: [FR3E框架提升大语言模型的推理能力](https://arxiv.org/abs/2507.07017)
Token length: 1562
Summarized using qwen-turbo
Append: [提升代码生成评估的测试用例生成方法研究](https://arxiv.org/abs/2507.06920)
Token length: 1814
Summarized using qwen-turbo
Append: [基于多模态光谱数据的分子结构生成框架DiffSpectra](https://arxiv.org/abs/2507.06853)
Token length: 1561
Summarized using qwen-turbo
Append: [混合线性注意力机制在长序列建模中的研究与优化](https://arxiv.org/abs/2507.06457)
Token length: 1676
Summarized using qwen-turbo
Append: [PAPO：一种增强多模态推理的感知意识强化学习方法](https://arxiv.org/abs/2507.06448)
Token length: 1734
Summarized using qwen-turbo
Append: [AutoTriton：基于强化学习的Triton编程模型](https://arxiv.org/abs/2507.05687)
Token length: 1562
Summarized using qwen-turbo
Append: [解耦推理与证明：提升自动化定理证明的新框架](https://arxiv.org/abs/2507.06804)
Token length: 1041
Summarized using qwen-turbo
Append: [Nova Premier模型的安全评估与公开发布](https://arxiv.org/abs/2507.06260)
Token length: 1413
Summarized using qwen-turbo
Append: [面向自动驾驶的视觉-语言-行动模型综述](https://arxiv.org/abs/2506.24044)
append_entries: 10
Finish: 2025-07-10 06:24:06.714117
------------------------------------------------------
Started: 2025-07-10 12:31:32.024430
Existing_entries: 1010
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1766
Summarized using qwen-turbo
Append: [4KAgent：一种统一的图像超分辨率通用系统](https://arxiv.org/abs/2507.07105)
Token length: 1310
Summarized using qwen-turbo
Append: [面向包容性内容审核的多视角毒性语言检测研究](https://arxiv.org/abs/2507.05455)
Token length: 1075
Summarized using qwen-turbo
Append: [基于多智能体的mLLM有害模因评估框架AdamMeme](https://arxiv.org/abs/2507.01702)
append_entries: 3
Finish: 2025-07-10 12:31:45.683038
------------------------------------------------------
Started: 2025-07-10 18:21:21.320903
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Fetch error: HTTPSConnectionPool(host='rsshub.app', port=443): Read timed out. (read timeout=30)
Fetch failed from https://rsshub.app/huggingface/daily-papers
append_entries: 0
error when rendering xml, skip docs/Huggingface-Daliy-Papers
------------------------------------------------------
Started: 2025-07-11 01:15:10.210189
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1428
Summarized using qwen-turbo
Append: [利用扩散模型提升多模态大语言模型的视觉理解能力](https://arxiv.org/abs/2507.07106)
Token length: 1607
Summarized using qwen-turbo
Append: [基于门控记忆单元的高效序列建模架构SambaY](https://arxiv.org/abs/2507.06607)
Token length: 1475
Summarized using qwen-turbo
Append: [Video-RTS：提升视频推理能力的高效强化学习方法](https://arxiv.org/abs/2507.06485)
Token length: 1595
Summarized using qwen-turbo
Append: [PERK：一种高效长上下文推理方法](https://arxiv.org/abs/2507.06415)
Token length: 1293
Summarized using qwen-turbo
Append: [基于分层框架的自主外科手术研究](https://arxiv.org/abs/2505.10251)
append_entries: 5
Finish: 2025-07-11 01:15:36.703256
------------------------------------------------------
Started: 2025-07-11 06:22:56.687516
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1536
Summarized using qwen-turbo
Append: [TreeBench与TreeVGR：推动视觉基础推理的新基准与训练方法](https://arxiv.org/abs/2507.07999)
Token length: 904
Summarized using qwen-turbo
Append: [PyVision：动态工具生成框架提升视觉推理能力](https://arxiv.org/abs/2507.07998)
Token length: 1258
Summarized using qwen-turbo
Append: [几何引导提升视频扩散模型的3D一致性](https://arxiv.org/abs/2507.07982)
Token length: 1725
Summarized using qwen-turbo
Append: [提升视觉语言模型长视频推理能力的全栈框架](https://arxiv.org/abs/2507.07966)
Token length: 1396
Summarized using qwen-turbo
Append: [机器谎言：大语言模型中虚假陈述的机制与评估](https://arxiv.org/abs/2507.07484)
Token length: 1053
Summarized using qwen-turbo
Append: [长视频生成技术的现状与分类研究](https://arxiv.org/abs/2507.07202)
Token length: 1596
Summarized using qwen-turbo
Append: [LangSplatV2：提升3D语言场推理速度与精度的高效方法](https://arxiv.org/abs/2507.07136)
append_entries: 7
Finish: 2025-07-11 06:23:24.236736
------------------------------------------------------
Started: 2025-07-11 12:30:06.307322
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1752
Summarized using qwen-turbo
Append: [通过动态调整预训练模型结构提升推理效率与准确性](https://arxiv.org/abs/2507.07996)
Token length: 1049
Summarized using qwen-turbo
Append: [视频大模型中的时空令牌合并方法STTM](https://arxiv.org/abs/2507.07990)
Token length: 1670
Summarized using qwen-turbo
Append: [在线时空理解基准OST-Bench推动多模态大语言模型发展](https://arxiv.org/abs/2507.07984)
Token length: 1224
Summarized using qwen-turbo
Append: [视觉-语言模型的线性推理瓶颈与对齐优化研究](https://arxiv.org/abs/2507.07574)
Token length: 1318
Summarized using qwen-turbo
Append: [基于时间感知的视觉表示学习方法ToBo](https://arxiv.org/abs/2507.06543)
Token length: 1396
Summarized using qwen-turbo
Append: [基于单图定制的扩散模型微调方法T-LoRA](https://arxiv.org/abs/2507.05964)
Json decode failed:
{
  "title": "X-Masters：突破科学AI代理新高度",
  "short_summary": "X-Masters在HLE测试中取得32.1%高分，超越多家科技巨头。",
  "summary": "文章介绍了X-Masters这一工具增强型推理代理，旨在模拟人类研究人员的思维过程，通过灵活调用内置Python库和定制工具来提升推理能力。该系统采用分散与堆叠的智能体工作流，显著增强了推理的广度和深度。在Humanity"s Last Exam（HLE）测试中，X-Masters以32.1%的得分创下新纪录，成为首个突破30%门槛的系统，优于OpenAI和Google Deep Research的表现。这项研究不仅推动了科学AI代理的发展，也为未来模型训练提供了宝贵经验。",
  "keyword": "AI代理, 科学研究, X-Masters"
}Summarization failed, append the original article
error: Expecting ',' delimiter: line 4 column 127 (char 222). Line: 406.
Append: [SciMaster: Towards General-Purpose Scientific AI Agents, Part I. X-Master as Foundation: Can We Lead on Humanity's Last Exam?](https://arxiv.org/abs/2507.05241)
append_entries: 7
Finish: 2025-07-11 12:30:33.636401
------------------------------------------------------
Started: 2025-07-11 18:21:02.007324
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1285
Summarized using qwen-turbo
Append: [基于Re-Bottleneck的神经音频编码器结构优化](https://arxiv.org/abs/2507.07867)
Token length: 1916
Summarized using qwen-turbo
Append: [基于固定嵌入的模块化与分层扩展方法提升大语言模型性能](https://arxiv.org/abs/2507.07129)
Token length: 1387
Summarized using qwen-turbo
Append: [非语义嵌入在Transformer模型中的有效性研究](https://arxiv.org/abs/2507.04886)
append_entries: 3
Finish: 2025-07-11 18:21:12.715302
------------------------------------------------------
Started: 2025-07-12 01:16:42.979551
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1731
Summarized using qwen-turbo
Append: [基于动态分块机制的端到端语言模型研究](https://arxiv.org/abs/2507.07955)
append_entries: 1
Finish: 2025-07-12 01:16:47.051583
------------------------------------------------------
Started: 2025-07-12 06:20:53.399104
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-07-12 06:20:53.575280
------------------------------------------------------
Started: 2025-07-12 12:27:57.832905
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Fetch error: 503
Fetch failed from https://rsshub.app/huggingface/daily-papers
append_entries: 0
error when rendering xml, skip docs/Huggingface-Daliy-Papers
------------------------------------------------------
Started: 2025-07-12 18:19:34.624891
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-07-12 18:19:34.831065
------------------------------------------------------
Started: 2025-07-13 01:21:52.729432
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-07-13 01:21:52.980273
------------------------------------------------------
Started: 2025-07-13 06:21:38.424889
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-07-13 06:21:38.641538
------------------------------------------------------
Started: 2025-07-13 12:28:13.910617
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-07-13 12:28:14.154698
------------------------------------------------------
Started: 2025-07-13 18:19:29.868178
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-07-13 18:19:30.015611
------------------------------------------------------
Started: 2025-07-14 01:18:41.137564
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-07-14 01:18:41.357939
------------------------------------------------------
Started: 2025-07-14 06:24:41.510369
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1596
Summarized using qwen-turbo
Append: [基于LLM架构的自回归视频生成模型Lumos-1](https://arxiv.org/abs/2507.08801)
Token length: 951
Summarized using qwen-turbo
Append: [NeuralOS：基于神经网络的GUI模拟框架](https://arxiv.org/abs/2507.08800)
Token length: 1504
Summarized using qwen-turbo
Append: [生成式奖励模型的脆弱性与改进方法](https://arxiv.org/abs/2507.08794)
Token length: 1189
Summarized using qwen-turbo
Append: [基于压缩光场令牌的神经渲染方法](https://arxiv.org/abs/2507.08776)
Token length: 1426
Summarized using qwen-turbo
Append: [CoPart：基于部件感知的3D生成框架](https://arxiv.org/abs/2507.08772)
Token length: 1289
Summarized using qwen-turbo
Append: [多模态大语言模型中的模态冲突与幻觉研究](https://arxiv.org/abs/2507.07151)
Token length: 1059
Summarized using qwen-turbo
Append: [MetaStone-S1：基于自监督奖励模型的生成式模型](https://arxiv.org/abs/2507.01951)
append_entries: 7
Finish: 2025-07-14 06:25:08.230312
------------------------------------------------------
Started: 2025-07-14 12:32:11.656016
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 969
Summarized using qwen-turbo
Append: [基于缓存引导的语言模型隐式控制方法](https://arxiv.org/abs/2507.08799)
Token length: 1576
Summarized using qwen-turbo
Append: [BlockFFN：一种高效的稀疏激活MoE架构及其加速技术](https://arxiv.org/abs/2507.08771)
Token length: 1176
Summarized using qwen-turbo
Append: [基于视觉基础模型的图像分词器设计与优化](https://arxiv.org/abs/2507.08441)
Token length: 1072
Summarized using qwen-turbo
Append: [评估基础模型的归纳偏置与世界模型的对齐性](https://arxiv.org/abs/2507.06952)
Token length: 1725
Summarized using qwen-turbo
Append: [基于神经信号的无手图像编辑方法LoongX](https://arxiv.org/abs/2507.05397)
append_entries: 5
Finish: 2025-07-14 12:32:34.085550
------------------------------------------------------
Started: 2025-07-14 18:22:56.525069
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1190
Summarized using qwen-turbo
Append: [多模态大语言模型的视觉推理能力提升研究](https://arxiv.org/abs/2507.05255)
Token length: 1001
Summarized using qwen-turbo
Append: [Gemini 2.X 模型家族发布：提升代码与推理能力](https://arxiv.org/abs/2507.06261)
append_entries: 2
Finish: 2025-07-14 18:23:05.931215
------------------------------------------------------
Started: 2025-07-15 01:18:49.365058
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-07-15 01:18:49.618107
------------------------------------------------------
Started: 2025-07-15 06:24:00.014125
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1890
Summarized using qwen-turbo
Append: [EmRACE-3K数据集推动视觉语言模型在具身环境中的推理能力研究](https://arxiv.org/abs/2507.10548)
Token length: 1520
Summarized using qwen-turbo
Append: [SpeakerVid-5M数据集推动音视频双人交互虚拟人研究](https://arxiv.org/abs/2507.09862)
Token length: 1211
Summarized using qwen-turbo
Append: [CompassJudger-2：提升大语言模型评估能力的通用判官模型](https://arxiv.org/abs/2507.09104)
Token length: 1200
Summarized using qwen-turbo
Append: [基于令牌感知与层局部对比解码的真相生成方法](https://arxiv.org/abs/2507.04404)
append_entries: 4
Finish: 2025-07-15 06:24:17.128349
------------------------------------------------------
Started: 2025-07-15 12:32:18.414199
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1889
Summarized using qwen-turbo
Append: [REST：一种评估大模型多任务推理能力的新框架](https://arxiv.org/abs/2507.10541)
Token length: 1396
Summarized using qwen-turbo
Append: [强化学习在大语言模型推理能力中的作用与评估挑战](https://arxiv.org/abs/2507.10532)
Token length: 1508
Summarized using qwen-turbo
Append: [Mixture-of-Recursions：提升语言模型效率的新框架](https://arxiv.org/abs/2507.10524)
Token length: 962
Summarized using qwen-turbo
Append: [MoVieS：一种高效的4D动态视图合成模型](https://arxiv.org/abs/2507.10065)
Token length: 1920
Summarized using qwen-turbo
Append: [利用ICO图像透明通道的可执行隐写术研究](https://arxiv.org/abs/2507.09074)
Token length: 719
Summarized using qwen-turbo
Append: [构建韩国专业级大语言模型评估基准](https://arxiv.org/abs/2507.08924)
Token length: 1544
Summarized using qwen-turbo
Append: [结合SFT与GRPO提升大语言模型的数学推理能力](https://arxiv.org/abs/2507.08267)
Token length: 1165
Summarized using qwen-turbo
Append: [DreamPoster：基于文本和图像生成高质量海报的框架](https://arxiv.org/abs/2507.04218)
append_entries: 8
Finish: 2025-07-15 12:32:49.257920
------------------------------------------------------
Started: 2025-07-15 18:22:31.832960
Existing_entries: 1008
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-07-15 18:22:32.147732
------------------------------------------------------
Started: 2025-07-16 01:16:28.598657
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 814
Summarized using qwen-turbo
Append: [将大语言模型集成到非一致性逻辑的形式语义中](https://arxiv.org/abs/2507.09751)
append_entries: 1
Finish: 2025-07-16 01:16:32.211075
------------------------------------------------------
Started: 2025-07-16 06:23:21.132062
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1301
Summarized using qwen-turbo
Append: [NeuralMark：一种鲁棒的神经网络水印方法](https://arxiv.org/abs/2507.11137)
Token length: 1297
Summarized using qwen-turbo
Append: [CoDi框架实现文本到图像的主体一致性与姿态多样性生成](https://arxiv.org/abs/2507.08396)
append_entries: 2
Finish: 2025-07-16 06:23:30.400341
------------------------------------------------------
Started: 2025-07-16 12:32:44.400596
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 867
Summarized using qwen-turbo
Append: [EXAONE 4.0：融合推理与非推理模式的多语言AI模型](https://arxiv.org/abs/2507.11407)
Token length: 921
Summarized using qwen-turbo
Append: [MISS-QA：评估模型解读科学文献示意图能力的基准测试](https://arxiv.org/abs/2507.10787)
Token length: 1378
Summarized using qwen-turbo
Append: [LLM在恶意软件变种生成中的应用研究](https://arxiv.org/abs/2507.09411)
Token length: 1233
Summarized using qwen-turbo
Append: [基于缩放定律的大型基础模型数据混合优化方法](https://arxiv.org/abs/2507.09404)
Token length: 1287
Summarized using qwen-turbo
Append: [OpenCodeReasoning-II数据集与代码生成及评估的改进](https://arxiv.org/abs/2507.09075)
Token length: 1406
Summarized using qwen-turbo
Append: [多智能体系统在复杂网络中的协作与推理能力评估](https://arxiv.org/abs/2507.08616)
Token length: 1331
Summarized using qwen-turbo
Append: [探究大语言模型中认知偏见的成因与影响](https://arxiv.org/abs/2507.07186)
Token length: 1445
Summarized using qwen-turbo
Append: [基于预训练模型的高效视觉语言模型构建方法](https://arxiv.org/abs/2507.07104)
append_entries: 8
Finish: 2025-07-16 12:33:37.112383
------------------------------------------------------
Started: 2025-07-16 18:22:02.832623
Existing_entries: 1008
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1542
Summarized using qwen-turbo
Append: [面向用户生成视频的多模态字幕生成基准与模型](https://arxiv.org/abs/2507.11336)
Token length: 1711
Summarized using qwen-turbo
Append: [基于多代理架构的视觉分类框架提升零样本场景下的AI可信度](https://arxiv.org/abs/2507.10571)
append_entries: 2
Finish: 2025-07-16 18:22:10.795132
------------------------------------------------------
Started: 2025-07-17 01:17:08.637630
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1903
Summarized using qwen-turbo
Append: [无需微调的视频光流提取方法](https://arxiv.org/abs/2507.09082)
Token length: 1166
Summarized using qwen-turbo
Append: [基于离散扩散模型的音频补全方法研究](https://arxiv.org/abs/2507.08333)
Token length: 1288
Summarized using qwen-turbo
Append: [BYOKG-RAG：一种增强知识图谱问答的框架](https://arxiv.org/abs/2507.04127)
append_entries: 3
Finish: 2025-07-17 01:17:20.856654
------------------------------------------------------
Started: 2025-07-17 06:23:24.471266
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1642
Summarized using qwen-turbo
Append: [物理引导的3D资产生成方法PhysX](https://arxiv.org/abs/2507.12465)
Token length: 1400
Summarized using qwen-turbo
Append: [面向土木工程的技术图纸修订评估基准 DrafterBench](https://arxiv.org/abs/2507.11527)
Token length: 1091
Summarized using qwen-turbo
Append: [融合检索与推理的先进方法研究](https://arxiv.org/abs/2507.09477)
Token length: 1610
Summarized using qwen-turbo
Append: [Lizard：一种用于无限上下文生成的线性化框架](https://arxiv.org/abs/2507.09025)
append_entries: 4
Finish: 2025-07-17 06:23:50.275247
------------------------------------------------------
Started: 2025-07-17 12:31:40.527868
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1216
Summarized using qwen-turbo
Append: [MMHU：大规模人类行为分析基准数据集](https://arxiv.org/abs/2507.12463)
Token length: 892
Summarized using qwen-turbo
Append: [SpatialTrackerV2：一种高效的单目视频3D点跟踪方法](https://arxiv.org/abs/2507.12462)
Token length: 1136
Summarized using qwen-turbo
Append: [SWE-Perf：首个针对代码性能优化的基准测试](https://arxiv.org/abs/2507.12415)
Token length: 1465
Summarized using qwen-turbo
Append: [基于空间音频的人类运动生成方法研究](https://arxiv.org/abs/2507.11949)
Token length: 1113
Summarized using qwen-turbo
Append: [RLEP：一种用于大语言模型的强化学习框架](https://arxiv.org/abs/2507.07451)
Token length: 1018
Summarized using qwen-turbo
Append: [基于推理时扩展计算的大型语言模型训练方法](https://arxiv.org/abs/2507.05065)
Token length: 1427
Summarized using qwen-turbo
Append: [AnyI2V：一种无需训练的视频生成框架](https://arxiv.org/abs/2507.02857)
append_entries: 7
Finish: 2025-07-17 12:32:08.554107
------------------------------------------------------
Started: 2025-07-17 18:22:05.700108
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1092
Summarized using qwen-turbo
Append: [AI Wizards在CLEF 2025主题性检测任务中的表现](https://arxiv.org/abs/2507.11764)
append_entries: 1
Finish: 2025-07-17 18:22:10.467734
------------------------------------------------------
Started: 2025-07-18 01:16:30.207884
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1437
Summarized using qwen-turbo
Append: [对比编码器与解码器语言模型的性能与适应性](https://arxiv.org/abs/2507.11412)
append_entries: 1
Finish: 2025-07-18 01:16:40.557235
------------------------------------------------------
Started: 2025-07-18 06:23:49.832862
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1434
Summarized using qwen-turbo
Append: [GitChameleon：面向库版本的代码生成评估基准](https://arxiv.org/abs/2507.12367)
Token length: 1269
Summarized using qwen-turbo
Append: [基于超网络的多模态模型对齐方法](https://arxiv.org/abs/2507.10015)
Token length: 1535
Summarized using qwen-turbo
Append: [跨模态知识蒸馏框架MST-Distill的提出与实验验证](https://arxiv.org/abs/2507.07015)
append_entries: 3
Finish: 2025-07-18 06:24:02.971935
------------------------------------------------------
Started: 2025-07-18 12:31:40.244999
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1578
Summarized using qwen-turbo
Append: [动态视觉令牌压缩方法VisionThink提升视觉语言模型效率](https://arxiv.org/abs/2507.13348)
Token length: 877
Summarized using qwen-turbo
Append: [pi^3：一种无需固定参考视角的视觉几何重建方法](https://arxiv.org/abs/2507.13347)
Token length: 1478
Summarized using qwen-turbo
Append: [上下文工程：大型语言模型推理的系统优化方法](https://arxiv.org/abs/2507.13334)
Token length: 1858
Summarized using qwen-turbo
Append: [基于图灵机模拟的Transformer模型长度泛化方法](https://arxiv.org/abs/2507.13332)
Token length: 1183
Summarized using qwen-turbo
Append: [AbGen：评估大语言模型设计消融实验能力的基准](https://arxiv.org/abs/2507.13300)
Token length: 1568
Summarized using qwen-turbo
Append: [基于扩散Transformer的多角色面部表情动画生成方法](https://arxiv.org/abs/2507.12956)
Token length: 1272
Summarized using qwen-turbo
Append: [AnyCap项目提升多模态生成的可控性与评估可靠性](https://arxiv.org/abs/2507.12841)
Token length: 1289
Summarized using qwen-turbo
Append: [可学习分词器提升语言模型适应性](https://arxiv.org/abs/2507.12720)
Token length: 1246
Summarized using qwen-turbo
Append: [MindJourney：通过世界模型提升视觉语言模型的3D空间推理能力](https://arxiv.org/abs/2507.12508)
Token length: 1519
Summarized using qwen-turbo
Append: [基于时序感知扩散模型的视频帧插值方法](https://arxiv.org/abs/2507.04984)
append_entries: 10
Finish: 2025-07-18 12:32:16.793488
------------------------------------------------------
Started: 2025-07-18 18:21:29.592570
Existing_entries: 1010
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1409
Summarized using qwen-turbo
Append: [基于4D扩散模型的高保真人体视角合成方法](https://arxiv.org/abs/2507.13344)
Token length: 662
Summarized using qwen-turbo
Append: [Voxtral Mini和Voxtral Small多模态音频聊天模型发布](https://arxiv.org/abs/2507.13264)
Token length: 1209
Summarized using qwen-turbo
Append: [提升多模态大模型安全性：AutoSteer技术研究](https://arxiv.org/abs/2507.13255)
Token length: 1072
Summarized using qwen-turbo
Append: [基于残差学习的稀疏自编码器改进方法](https://arxiv.org/abs/2507.12990)
Token length: 1126
Summarized using qwen-turbo
Append: [基于黎曼几何的LoRA优化方法研究](https://arxiv.org/abs/2507.12142)
Token length: 1125
Summarized using qwen-turbo
Append: [Einstein Fields：基于神经张量场的四维时空压缩方法](https://arxiv.org/abs/2507.11589)
append_entries: 6
Finish: 2025-07-18 18:21:53.761102
------------------------------------------------------
Started: 2025-07-19 01:14:27.767335
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-07-19 01:14:27.982488
------------------------------------------------------
Started: 2025-07-19 06:21:37.702617
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-07-19 06:21:37.850119
------------------------------------------------------
Started: 2025-07-19 12:28:46.179935
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-07-19 12:28:46.385487
------------------------------------------------------
Started: 2025-07-19 18:20:08.789226
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-07-19 18:20:09.031375
------------------------------------------------------
Started: 2025-07-20 01:23:49.356898
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-07-20 01:23:49.608083
------------------------------------------------------
Started: 2025-07-20 06:21:15.258365
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-07-20 06:21:15.494096
------------------------------------------------------
Started: 2025-07-20 12:29:31.928794
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-07-20 12:29:32.142254
------------------------------------------------------
Started: 2025-07-20 18:20:18.804642
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-07-20 18:20:19.079036
------------------------------------------------------
Started: 2025-07-21 01:21:01.842133
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Fetch error: HTTPSConnectionPool(host='rsshub.app', port=443): Read timed out. (read timeout=30)
Fetch failed from https://rsshub.app/huggingface/daily-papers
append_entries: 0
error when rendering xml, skip docs/Huggingface-Daliy-Papers
------------------------------------------------------
Started: 2025-07-21 06:24:26.784239
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Fetch error: HTTPSConnectionPool(host='rsshub.app', port=443): Read timed out. (read timeout=30)
Fetch failed from https://rsshub.app/huggingface/daily-papers
append_entries: 0
error when rendering xml, skip docs/Huggingface-Daliy-Papers
------------------------------------------------------
Started: 2025-07-21 12:33:22.003459
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Fetch error: HTTPSConnectionPool(host='rsshub.app', port=443): Read timed out. (read timeout=30)
Fetch failed from https://rsshub.app/huggingface/daily-papers
append_entries: 0
error when rendering xml, skip docs/Huggingface-Daliy-Papers
------------------------------------------------------
Started: 2025-07-21 18:23:11.843180
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Fetch error: HTTPSConnectionPool(host='rsshub.app', port=443): Read timed out. (read timeout=30)
Fetch failed from https://rsshub.app/huggingface/daily-papers
append_entries: 0
error when rendering xml, skip docs/Huggingface-Daliy-Papers
------------------------------------------------------
Started: 2025-07-22 01:16:58.106520
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Fetch error: HTTPSConnectionPool(host='rsshub.app', port=443): Read timed out. (read timeout=30)
Fetch failed from https://rsshub.app/huggingface/daily-papers
append_entries: 0
error when rendering xml, skip docs/Huggingface-Daliy-Papers
------------------------------------------------------
Started: 2025-07-22 06:23:43.818887
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Fetch error: HTTPSConnectionPool(host='rsshub.app', port=443): Read timed out. (read timeout=30)
Fetch failed from https://rsshub.app/huggingface/daily-papers
append_entries: 0
error when rendering xml, skip docs/Huggingface-Daliy-Papers
------------------------------------------------------
Started: 2025-07-22 12:32:52.465728
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Fetch error: HTTPSConnectionPool(host='rsshub.app', port=443): Read timed out. (read timeout=30)
Fetch failed from https://rsshub.app/huggingface/daily-papers
append_entries: 0
error when rendering xml, skip docs/Huggingface-Daliy-Papers
------------------------------------------------------
Started: 2025-07-22 18:22:37.348325
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1103
Summarized using qwen-turbo
Append: [基于去噪的潜在令牌化器设计研究](https://arxiv.org/abs/2507.15856)
Token length: 1750
Summarized using qwen-turbo
Append: [基于概念驱动的视频目标分割框架SeC及其性能评估](https://arxiv.org/abs/2507.15852)
Token length: 1745
Summarized using qwen-turbo
Append: [GUI-G^2：基于高斯分布的图形用户界面定位奖励框架](https://arxiv.org/abs/2507.15846)
Token length: 1489
Summarized using qwen-turbo
Append: [基于大语言模型的经济政策模拟框架](https://arxiv.org/abs/2507.15815)
Token length: 1301
Summarized using qwen-turbo
Append: [基于熵感知的强化学习方法提升大语言模型推理能力](https://arxiv.org/abs/2507.15778)
Token length: 1517
Summarized using qwen-turbo
Append: [TokensGen：基于压缩标记的长视频生成框架](https://arxiv.org/abs/2507.15728)
Token length: 1428
Summarized using qwen-turbo
Append: [基于数据混合代理的持续预训练方法](https://arxiv.org/abs/2507.15640)
Token length: 1636
Summarized using qwen-turbo
Append: [基于离散SDF的3D高斯点云逆渲染方法](https://arxiv.org/abs/2507.15629)
Token length: 1582
Summarized using qwen-turbo
Append: [Being-H0：基于人类视频的多模态机器人操作模型](https://arxiv.org/abs/2507.15597)
Token length: 1193
Summarized using qwen-turbo
Append: [PhysGym：评估大语言模型科学发现能力的新基准](https://arxiv.org/abs/2507.15550)
Token length: 1340
Summarized using qwen-turbo
Append: [GR-3：通用机器人策略的进展与ByteMini集成](https://arxiv.org/abs/2507.15493)
Token length: 1518
Summarized using qwen-turbo
Append: [Stitch：实现语音模型同步思考与回答的新方法](https://arxiv.org/abs/2507.15375)
Token length: 1325
Summarized using qwen-turbo
Append: [基于知识投影的网页信息检索数据合成框架WebShaper](https://arxiv.org/abs/2507.15061)
Token length: 1002
Summarized using qwen-turbo
Append: [视频理解测试：评估视频大语言模型的准确性和鲁棒性](https://arxiv.org/abs/2507.15028)
Token length: 1859
Summarized using qwen-turbo
Append: [RLVR在推理边界扩展中的局限性研究](https://arxiv.org/abs/2507.14843)
Token length: 1913
Summarized using qwen-turbo
Append: [开源数学推理语言模型MiroMind-M1的开发与性能评估](https://arxiv.org/abs/2507.14683)
Token length: 1221
Summarized using qwen-turbo
Append: [长推理下大推理模型性能下降现象研究](https://arxiv.org/abs/2507.14417)
Token length: 1502
Summarized using qwen-turbo
Append: [基于单值反馈的多轮强化学习方法提升语言模型推理能力](https://arxiv.org/abs/2507.14295)
Token length: 1489
Summarized using qwen-turbo
Append: [自动化生成高质量图像编辑数据集提升AI图像处理能力](https://arxiv.org/abs/2507.14119)
Token length: 1456
Summarized using qwen-turbo
Append: [基于不确定性引导的渐进学习框架在CT图像分类中的应用](https://arxiv.org/abs/2507.14102)
Token length: 1658
Summarized using qwen-turbo
Append: [PhyWorldBench：评估视频生成模型物理模拟能力的基准测试](https://arxiv.org/abs/2507.13428)
Token length: 1368
Summarized using qwen-turbo
Append: [基于流式处理的4D时空几何重建方法](https://arxiv.org/abs/2507.11539)
Token length: 1685
Summarized using qwen-turbo
Append: [RoMaP：基于3D高斯编辑的精准局部3D内容修改方法](https://arxiv.org/abs/2507.11061)
Token length: 1521
Summarized using qwen-turbo
Append: [基于几何引导的弱监督自蒸馏框架GeoDistill用于跨视角定位](https://arxiv.org/abs/2507.10935)
append_entries: 24
Finish: 2025-07-22 18:24:13.436507
------------------------------------------------------
Started: 2025-07-23 01:18:18.283123
Existing_entries: 1024
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 838
Summarized using qwen-turbo
Append: [基于MCP的LLM智能体评估框架MCPEval](https://arxiv.org/abs/2507.12806)
Token length: 1021
Summarized using qwen-turbo
Append: [LLM生成学生风格代码的系统研究](https://arxiv.org/abs/2507.12674)
Token length: 794
Summarized using qwen-turbo
Append: [机器学习中的串行计算挑战与未来发展方向](https://arxiv.org/abs/2507.12549)
append_entries: 3
Finish: 2025-07-23 01:18:30.940185
------------------------------------------------------
Started: 2025-07-23 06:24:11.021944
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1114
Summarized using qwen-turbo
Append: [ThinkAct：基于视觉潜在规划的多模态推理与动作执行框架](https://arxiv.org/abs/2507.16815)
Token length: 1737
Summarized using qwen-turbo
Append: [SOPHIA提升视觉语言模型的慢思考推理能力](https://arxiv.org/abs/2507.16814)
Token length: 1641
Summarized using qwen-turbo
Append: [基于多模态大模型的人-物交互合成方法研究](https://arxiv.org/abs/2507.16813)
Token length: 1800
Summarized using qwen-turbo
Append: [构建科学推理数据集与模型提升AI在自然科学中的表现](https://arxiv.org/abs/2507.16812)
Token length: 1222
Summarized using qwen-turbo
Append: [无需修改训练数据的大型语言模型泛化控制方法](https://arxiv.org/abs/2507.16795)
Token length: 1406
Summarized using qwen-turbo
Append: [突破大语言模型推理瓶颈的Thread Inference Model](https://arxiv.org/abs/2507.16784)
Token length: 1347
Summarized using qwen-turbo
Append: [Zebra-CoT数据集提升多模态视觉链式推理能力](https://arxiv.org/abs/2507.16746)
Token length: 1299
Summarized using qwen-turbo
Append: [Step-Audio 2：面向工业级音频理解与语音对话的端到端多模态大语言模型](https://arxiv.org/abs/2507.16632)
Token length: 1275
Summarized using qwen-turbo
Append: [推理时计算增强模型鲁棒性的安全风险分析](https://arxiv.org/abs/2507.15974)
Token length: 984
Summarized using qwen-turbo
Append: [ObjectGS：融合语义理解的3D场景重建框架](https://arxiv.org/abs/2507.15454)
Token length: 904
Summarized using qwen-turbo
Append: [SPAR：基于多智能体框架的学术文献检索新方法](https://arxiv.org/abs/2507.15245)
Token length: 1434
Summarized using qwen-turbo
Append: [基于强化学习的RefCritic模块提升语言模型批判能力](https://arxiv.org/abs/2507.15024)
append_entries: 12
Finish: 2025-07-23 06:25:01.026880
------------------------------------------------------
Started: 2025-07-23 12:33:06.187315
Existing_entries: 1012
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1367
Summarized using qwen-turbo
Append: [区域自适应潜在上采样提升扩散模型推理效率](https://arxiv.org/abs/2507.08422)
append_entries: 1
Finish: 2025-07-23 12:33:10.176668
------------------------------------------------------
Started: 2025-07-23 18:22:47.878019
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1401
Summarized using qwen-turbo
Append: [面向目标检测的新型零样本量化框架](https://arxiv.org/abs/2507.16782)
Token length: 1242
Summarized using qwen-turbo
Append: [ExpTeach：通过自我生成记忆实现视觉语言模型与机器人的有效融合](https://arxiv.org/abs/2507.16713)
append_entries: 2
Finish: 2025-07-23 18:22:56.179652
------------------------------------------------------
Started: 2025-07-24 01:17:22.350075
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1631
Summarized using qwen-turbo
Append: [PrefPalette：基于属性分解的人类偏好建模框架](https://arxiv.org/abs/2507.13541)
append_entries: 1
Finish: 2025-07-24 01:17:26.969421
------------------------------------------------------
Started: 2025-07-24 06:23:50.027081
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1373
Summarized using qwen-turbo
Append: [高效3D生成框架Ultra3D提升稀疏体素建模速度](https://arxiv.org/abs/2507.17745)
Token length: 1900
Summarized using qwen-turbo
Append: [多领域推理在强化学习中的系统研究](https://arxiv.org/abs/2507.17512)
Token length: 1362
Summarized using qwen-turbo
Append: [多模态大语言模型的感知能力评估与Turing Eye Test基准](https://arxiv.org/abs/2507.16863)
Token length: 1101
Summarized using qwen-turbo
Append: [Elevate3D：提升低质量3D模型质量的新框架](https://arxiv.org/abs/2507.11465)
append_entries: 4
Finish: 2025-07-24 06:24:05.410226
------------------------------------------------------
Started: 2025-07-24 12:33:06.067109
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "Yume：基于输入图像生成动态交互世界的框架",
  "short_summary": "Yume通过图像生成动态世界并支持键盘交互。",
  "summary": "Yume旨在利用图像、文本或视频创建一个可交互、逼真且动态的世界，并通过外设或神经信号进行控制。本文介绍了\method的预览版本，该方法从输入图像生成动态世界，并允许通过键盘操作进行探索。框架包含四个主要组件：相机运动量化、视频生成架构、高级采样器和模型加速。研究引入了Masked Video Diffusion Transformer（MVDT）和记忆模块，以实现无限视频生成；同时采用训练-free Anti-Artifact Mechanism（AAM）和基于随机微分方程的Time Travel Sampling（TTS-SDE）提升视觉质量和控制精度。此外，通过对抗性蒸馏和缓存机制优化模型加速。实验使用\sekai数据集训练\method，在多种场景中取得显著效果。所有数据、代码和模型权重已公开。",
  "keyword": ["Yume", "动态世界生成", "交互式视频"]
}Summarization failed, append the original article
error: Invalid \escape: line 4 column 68 (char 151). Line: 406.
Append: [Yume: An Interactive World Generation Model](https://arxiv.org/abs/2507.17744)
Token length: 1149
Summarized using qwen-turbo
Append: [DesignLab：通过迭代优化提升幻灯片设计质量](https://arxiv.org/abs/2507.17202)
Token length: 1373
Summarized using qwen-turbo
Append: [RAVine：面向代理式搜索的现实对齐评估框架](https://arxiv.org/abs/2507.16725)
Token length: 1452
Summarized using qwen-turbo
Append: [文本到图像扩散模型中的记忆与隐私问题研究](https://arxiv.org/abs/2507.16880)
Token length: 1824
Summarized using qwen-turbo
Append: [基于形式语言的大型语言模型验证方法研究](https://arxiv.org/abs/2507.16331)
append_entries: 5
Finish: 2025-07-24 12:33:25.703046
------------------------------------------------------
Started: 2025-07-24 18:22:42.556322
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1800
Summarized using qwen-turbo
Append: [Pusa：基于向量化时间步适应的视频扩散模型新范式](https://arxiv.org/abs/2507.16116)
append_entries: 1
Finish: 2025-07-24 18:22:46.846051
------------------------------------------------------
Started: 2025-07-25 01:16:53.162697
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 907
Summarized using qwen-turbo
Append: [Promptomatix：自动提示优化框架提升大语言模型性能](https://arxiv.org/abs/2507.14241)
append_entries: 1
Finish: 2025-07-25 01:16:57.010708
------------------------------------------------------
Started: 2025-07-25 06:24:02.129012
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1169
Summarized using qwen-turbo
Append: [Captain Cinema：基于文本生成高质量短片的框架](https://arxiv.org/abs/2507.18634)
Token length: 1690
Summarized using qwen-turbo
Append: [TTS-VAR：一种高效的视觉自回归模型测试时扩展框架](https://arxiv.org/abs/2507.18537)
Token length: 1389
Summarized using qwen-turbo
Append: [TeEFusion：一种高效的文本到图像生成蒸馏方法](https://arxiv.org/abs/2507.18192)
Token length: 1764
Summarized using qwen-turbo
Append: [大规模地球3D生成技术的创新与应用](https://arxiv.org/abs/2507.16535)
Token length: 1671
Summarized using qwen-turbo
Append: [Hierarchical Budget Policy Optimization提升推理效率与能力](https://arxiv.org/abs/2507.15844)
Token length: 1246
Summarized using qwen-turbo
Append: [LAPO：通过自适应策略优化实现高效推理的框架](https://arxiv.org/abs/2507.15758)
Token length: 1414
Summarized using qwen-turbo
Append: [DMOSpeech 2：通过强化学习优化语音合成的持续预测器](https://arxiv.org/abs/2507.14988)
append_entries: 7
Finish: 2025-07-25 06:24:27.376254
------------------------------------------------------
Started: 2025-07-25 12:31:52.826322
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1329
Summarized using qwen-turbo
Append: [基于深度学习的面部年龄与性别联合分类方法研究](https://arxiv.org/abs/2507.18565)
Token length: 951
Summarized using qwen-turbo
Append: [GLiNER2：统一的高效信息抽取框架](https://arxiv.org/abs/2507.18546)
Token length: 1688
Summarized using qwen-turbo
Append: [DriftMoE：一种应对概念漂移的在线专家混合模型](https://arxiv.org/abs/2507.18464)
Token length: 926
Summarized using qwen-turbo
Append: [2024年更新的英文GloVe模型评估报告](https://arxiv.org/abs/2507.18103)
Token length: 1577
Summarized using qwen-turbo
Append: [TeleChat系列模型升级：性能显著提升的多版本发布](https://arxiv.org/abs/2507.18013)
Token length: 1698
Summarized using qwen-turbo
Append: [基于Spelke对象的视觉分割方法研究](https://arxiv.org/abs/2507.16038)
Token length: 1064
Summarized using qwen-turbo
Append: [基于扩散变换器的皮肤病变分割模型SegDT](https://arxiv.org/abs/2507.15595)
Token length: 1223
Summarized using qwen-turbo
Append: [基于动量不确定性的高效语言模型推理优化方法](https://arxiv.org/abs/2507.14958)
append_entries: 8
Finish: 2025-07-25 12:32:24.667898
------------------------------------------------------
Started: 2025-07-25 18:22:08.405578
Existing_entries: 1008
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1193
Summarized using qwen-turbo
Append: [Iwin Transformer：一种无需位置嵌入的层次化视觉Transformer](https://arxiv.org/abs/2507.18405)
Token length: 706
Summarized using qwen-turbo
Append: [Group Sequence Policy Optimization: 提升大语言模型训练效率与稳定性的强化学习算法](https://arxiv.org/abs/2507.18071)
Token length: 1822
Summarized using qwen-turbo
Append: [Agentar-Fin-R1系列金融大模型提升推理与可信度](https://arxiv.org/abs/2507.16802)
Token length: 1061
Summarized using qwen-turbo
Append: [NABLA：提升视频生成效率的自适应块级注意力机制](https://arxiv.org/abs/2507.13546)
append_entries: 4
Finish: 2025-07-25 18:22:24.919468
------------------------------------------------------
Started: 2025-07-26 01:15:13.772045
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1249
Summarized using qwen-turbo
Append: [基于双空间建模的局部相关视频检索方法](https://arxiv.org/abs/2507.17402)
Token length: 1591
Summarized using qwen-turbo
Append: [提升多模态上下文学习能力的动态注意力重分配方法](https://arxiv.org/abs/2507.15807)
append_entries: 2
Finish: 2025-07-26 01:15:22.624057
------------------------------------------------------
Started: 2025-07-26 06:21:38.704742
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-07-26 06:21:38.937957
------------------------------------------------------
Started: 2025-07-26 12:29:10.597060
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-07-26 12:29:10.823950
------------------------------------------------------
Started: 2025-07-26 18:20:49.587524
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-07-26 18:20:49.819281
------------------------------------------------------
Started: 2025-07-27 01:23:58.871949
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-07-27 01:23:59.093433
------------------------------------------------------
Started: 2025-07-27 06:22:26.476781
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-07-27 06:22:26.700615
------------------------------------------------------
Started: 2025-07-27 12:29:58.975537
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-07-27 12:29:59.147135
------------------------------------------------------
Started: 2025-07-27 18:20:34.197771
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-07-27 18:20:34.360554
------------------------------------------------------
Started: 2025-07-28 01:22:16.332974
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-07-28 01:22:16.605220
------------------------------------------------------
Started: 2025-07-28 06:26:00.094809
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-07-28 06:26:00.372394
------------------------------------------------------
Started: 2025-07-28 12:33:42.306426
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1135
Summarized using qwen-turbo
Append: [Specification Self-Correction: 提升语言模型对规范漏洞的自我修正能力](https://arxiv.org/abs/2507.18742)
Token length: 1313
Summarized using qwen-turbo
Append: [基于纯视觉的高效端到端自动驾驶架构PRIX](https://arxiv.org/abs/2507.17596)
Token length: 1377
Summarized using qwen-turbo
Append: [TTD-DR：基于扩散过程的深度研究生成框架](https://arxiv.org/abs/2507.16075)
Token length: 1395
Summarized using qwen-turbo
Append: [AI视频聊天：实时通信的新范式与优化框架](https://arxiv.org/abs/2507.10510)
append_entries: 4
Finish: 2025-07-28 12:33:58.348667
------------------------------------------------------
Started: 2025-07-28 18:23:41.551983
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1397
Summarized using qwen-turbo
Append: [MMBench-GUI：跨平台GUI自动化代理评估基准](https://arxiv.org/abs/2507.19478)
Token length: 1212
Summarized using qwen-turbo
Append: [GPTQ与格点算法的数学等价性研究](https://arxiv.org/abs/2507.18553)
Token length: 1037
Summarized using qwen-turbo
Append: [基于LLM的错误分析工具CLEAR提升模型评估深度](https://arxiv.org/abs/2507.18392)
append_entries: 3
Finish: 2025-07-28 18:23:54.247430
------------------------------------------------------
Started: 2025-07-29 01:26:10.557707
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1293
Summarized using qwen-turbo
Append: [GEPA：利用自然语言反思提升LLM任务优化的提示优化器](https://arxiv.org/abs/2507.19457)
Token length: 1789
Summarized using qwen-turbo
Append: [前沿人工智能模型的风险评估与管理](https://arxiv.org/abs/2507.16534)
append_entries: 2
Finish: 2025-07-29 01:26:19.453677
------------------------------------------------------
Started: 2025-07-29 06:24:29.751804
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1517
Summarized using qwen-turbo
Append: [基于表示空间的多任务学习方法Rep-MTL](https://arxiv.org/abs/2507.21049)
Token length: 1458
Summarized using qwen-turbo
Append: [4D空间智能重建的多层级方法综述](https://arxiv.org/abs/2507.21045)
Token length: 1540
Summarized using qwen-turbo
Append: [GPT-IMAGE-EDIT-1.5M：推动指令引导图像编辑的开源数据集](https://arxiv.org/abs/2507.21033)
Token length: 1753
Summarized using qwen-turbo
Append: [SmallThinker：本地设备上高效运行的大语言模型](https://arxiv.org/abs/2507.20984)
Token length: 1908
Summarized using qwen-turbo
Append: [ARC-Hunyuan-Video：提升短视频多模态理解能力的模型](https://arxiv.org/abs/2507.20939)
Token length: 1577
Summarized using qwen-turbo
Append: [Music Arena：开放平台推动文本到音乐模型的人类偏好评估](https://arxiv.org/abs/2507.20900)
Token length: 1305
Summarized using qwen-turbo
Append: [基于流匹配的JAM模型实现歌词到歌曲的精细控制](https://arxiv.org/abs/2507.20880)
Token length: 1206
Summarized using qwen-turbo
Append: [GMPO：一种更稳定的大型语言模型策略优化方法](https://arxiv.org/abs/2507.20673)
Token length: 1184
Summarized using qwen-turbo
Append: [RICE：提升区域级视觉与OCR能力的对比学习方法](https://arxiv.org/abs/2507.20025)
Token length: 1722
Summarized using qwen-turbo
Append: [基于可验证奖励的强化学习算法ARPO提升多轮语言模型推理能力](https://arxiv.org/abs/2507.19849)
Token length: 1246
Summarized using qwen-turbo
Append: [基于前景感知的文档图像校正方法研究](https://arxiv.org/abs/2507.19804)
append_entries: 11
Finish: 2025-07-29 06:25:09.903069
------------------------------------------------------
Started: 2025-07-29 12:33:59.867659
Existing_entries: 1011
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1910
Summarized using qwen-turbo
Append: [自演化智能体：从静态模型到动态适应的范式转变](https://arxiv.org/abs/2507.21046)
Token length: 1536
Summarized using qwen-turbo
Append: [GenoMAS：结合LLM的基因表达分析新方法](https://arxiv.org/abs/2507.21035)
Token length: 1366
Summarized using qwen-turbo
Append: [基于超长输出强化学习的大型语言模型推理能力提升研究](https://arxiv.org/abs/2507.19766)
Token length: 1084
Summarized using qwen-turbo
Append: [ScenePainter：解决3D场景生成语义漂移问题的新框架](https://arxiv.org/abs/2507.19058)
Token length: 1506
Summarized using qwen-turbo
Append: [基于隐式两阶段训练的多变量天气预测方法](https://arxiv.org/abs/2507.17189)
Token length: 1844
Summarized using qwen-turbo
Append: [基于校准奖励的强化学习提升语言模型推理可靠性](https://arxiv.org/abs/2507.16806)
append_entries: 6
Finish: 2025-07-29 12:34:28.118850
------------------------------------------------------
Started: 2025-07-29 18:23:35.329178
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1319
Summarized using qwen-turbo
Append: [SAND-Math：提升数学推理大语言模型性能的合成数据生成方法](https://arxiv.org/abs/2507.20527)
Token length: 1440
Summarized using qwen-turbo
Append: [提升主观推理能力的多角色增强框架研究](https://arxiv.org/abs/2507.20187)
append_entries: 2
Finish: 2025-07-29 18:23:42.280282
------------------------------------------------------
Started: 2025-07-30 01:18:47.456312
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1098
Summarized using qwen-turbo
Append: [基于用户目标状态追踪的对话模拟器研究](https://arxiv.org/abs/2507.20152)
append_entries: 1
Finish: 2025-07-30 01:18:51.293673
------------------------------------------------------
Started: 2025-07-30 06:25:46.327121
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1035
Summarized using qwen-turbo
Append: [基于运动引导的少样本视频目标分割研究](https://arxiv.org/abs/2507.22061)
Token length: 1500
Summarized using qwen-turbo
Append: [基于强化学习的离散自回归模型在图像与语言生成中的应用](https://arxiv.org/abs/2507.22058)
Token length: 1437
Summarized using qwen-turbo
Append: [HunyuanWorld 1.0：融合文本与图像生成沉浸式3D场景的新框架](https://arxiv.org/abs/2507.21809)
Token length: 1358
Summarized using qwen-turbo
Append: [深度学习在非洲野生动物图像分类中的应用与评估](https://arxiv.org/abs/2507.21364)
Token length: 1541
Summarized using qwen-turbo
Append: [AnimalClue：首个基于间接证据的物种识别大规模数据集](https://arxiv.org/abs/2507.20240)
Token length: 1358
Summarized using qwen-turbo
Append: [基于最大后验估计的偏好优化方法MaPPO](https://arxiv.org/abs/2507.21183)
append_entries: 6
Finish: 2025-07-30 06:26:14.676740
------------------------------------------------------
Started: 2025-07-30 12:34:03.172589
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1832
Summarized using qwen-turbo
Append: [基于强化学习的CUDA自动优化框架CUDA-L1](https://arxiv.org/abs/2507.14111)
append_entries: 1
Finish: 2025-07-30 12:34:07.856930
------------------------------------------------------
Started: 2025-07-30 18:23:00.270874
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1439
Summarized using qwen-turbo
Append: [多模态大语言模型诚实行为的系统评估与基准测试](https://arxiv.org/abs/2507.21503)
append_entries: 1
Finish: 2025-07-30 18:23:05.269087
------------------------------------------------------
Started: 2025-07-31 01:18:31.295251
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1070
Summarized using qwen-turbo
Append: [ChemDFM-R：提升化学领域推理能力的大型语言模型](https://arxiv.org/abs/2507.21990)
append_entries: 1
Finish: 2025-07-31 01:18:35.070043
------------------------------------------------------
Started: 2025-07-31 06:24:36.014243
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1163
Summarized using qwen-turbo
Append: [提出OmniAVS数据集与OISA模型推动多模态指代音频视觉分割研究](https://arxiv.org/abs/2507.22886)
Token length: 1664
Summarized using qwen-turbo
Append: [基于测试前置的自动化程序修复方法 Repair-R1](https://arxiv.org/abs/2507.22853)
Token length: 1565
Summarized using qwen-turbo
Append: [基于多智能体框架的UI到代码自动化转换方法](https://arxiv.org/abs/2507.22827)
Token length: 1666
Summarized using qwen-turbo
Append: [Falcon-H1：混合架构大语言模型系列提升性能与效率](https://arxiv.org/abs/2507.22448)
Token length: 1767
Summarized using qwen-turbo
Append: [BANG：一种基于生成爆炸动态的3D对象分解方法](https://arxiv.org/abs/2507.21493)
Token length: 1525
Summarized using qwen-turbo
Append: [基于生成AI的航空图像车辆检测域适应方法](https://arxiv.org/abs/2507.20976)
append_entries: 6
Finish: 2025-07-31 06:25:12.367456
------------------------------------------------------
Started: 2025-07-31 12:32:07.710348
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1446
Summarized using qwen-turbo
Append: [VL-Cogito：基于多阶段渐进式强化学习的多模态推理模型](https://arxiv.org/abs/2507.22607)
Token length: 1801
Summarized using qwen-turbo
Append: [基于强化学习的差分隐私优化框架RLDP提升语言模型性能](https://arxiv.org/abs/2507.22565)
append_entries: 2
Finish: 2025-07-31 12:32:14.696724
------------------------------------------------------
Started: 2025-07-31 18:23:45.601260
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1339
Summarized using qwen-turbo
Append: [MetaCLIP 2：在多语言网络数据上训练的对比语言-图像预训练模型](https://arxiv.org/abs/2507.22062)
Token length: 1586
Summarized using qwen-turbo
Append: [MixGRPO：提升图像生成中人类偏好对齐效率的新框架](https://arxiv.org/abs/2507.21802)
append_entries: 2
Finish: 2025-07-31 18:23:54.586388
------------------------------------------------------
Started: 2025-08-01 01:26:11.668094
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1426
Summarized using qwen-turbo
Append: [Step-3：面向解码效率优化的超大规模视觉语言模型](https://arxiv.org/abs/2507.19427)
Token length: 1249
Summarized using qwen-turbo
Append: [DreamScene：基于自然语言的高质量可编辑3D场景生成框架](https://arxiv.org/abs/2507.13985)
append_entries: 2
Finish: 2025-08-01 01:26:26.514498
------------------------------------------------------
Started: 2025-08-01 06:26:27.921912
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1344
Summarized using qwen-turbo
Append: [Seed-Prover：基于形式验证的数学定理证明模型](https://arxiv.org/abs/2507.23726)
Token length: 1284
Summarized using qwen-turbo
Append: [构建多语言语音对话模型评估基准](https://arxiv.org/abs/2507.22968)
Token length: 1888
Summarized using qwen-turbo
Append: [基于用户意图的下一代推荐系统RecGPT](https://arxiv.org/abs/2507.22879)
append_entries: 3
Finish: 2025-08-01 06:26:39.231197
------------------------------------------------------
Started: 2025-08-01 12:32:39.107733
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1467
Summarized using qwen-turbo
Append: [Phi-Ground模型提升GUI接地性能，推动计算机使用代理发展](https://arxiv.org/abs/2507.23779)
Token length: 1500
Summarized using qwen-turbo
Append: [强化学习在3D环境中的空间推理与泛化能力研究](https://arxiv.org/abs/2507.23698)
Token length: 996
Summarized using qwen-turbo
Append: [ViLLA框架提升机器人操作策略的泛化能力](https://arxiv.org/abs/2507.23682)
Token length: 1377
Summarized using qwen-turbo
Append: [软最大化注意力机制的递归形式及其表达能力分析](https://arxiv.org/abs/2507.23632)
Token length: 1198
Summarized using qwen-turbo
Append: [基于KAN的双教师知识蒸馏艺术风格分类方法](https://arxiv.org/abs/2507.23436)
Token length: 978
Summarized using qwen-turbo
Append: [面向阿拉伯语的增强型密集段落检索框架](https://arxiv.org/abs/2507.23404)
Token length: 1127
Summarized using qwen-turbo
Append: [NeRF-GS：融合NeRF与3D高斯散射的新型框架](https://arxiv.org/abs/2507.23374)
Token length: 1526
Summarized using qwen-turbo
Append: [TARS：一种改进多模态大语言模型幻觉的偏好优化方法](https://arxiv.org/abs/2507.21584)
Token length: 1196
Summarized using qwen-turbo
Append: [基于人格向量的大型语言模型行为分析与控制](https://arxiv.org/abs/2507.21509)
Token length: 1227
Summarized using qwen-turbo
Append: [农业视觉语言模型评估基准AgroBench的引入与分析](https://arxiv.org/abs/2507.20519)
Token length: 1505
Summarized using qwen-turbo
Append: [时间对称性在序列模型中的应用研究](https://arxiv.org/abs/2507.14793)
append_entries: 11
Finish: 2025-08-01 12:33:23.064911
------------------------------------------------------
Started: 2025-08-01 18:22:14.356455
Existing_entries: 1011
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1707
Summarized using qwen-turbo
Append: [基于增量学习的高效机器遗忘算法研究](https://arxiv.org/abs/2507.23257)
append_entries: 1
Finish: 2025-08-01 18:22:17.358165
------------------------------------------------------
Started: 2025-08-02 01:15:21.329488
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1551
Summarized using qwen-turbo
Append: [基于迭代优化的高效3D重建模型iLRM](https://arxiv.org/abs/2507.23277)
append_entries: 1
Finish: 2025-08-02 01:15:26.165277
------------------------------------------------------
Started: 2025-08-02 06:21:19.994833
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-02 06:21:20.139891
------------------------------------------------------
Started: 2025-08-02 12:29:48.483241
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-02 12:29:48.695621
------------------------------------------------------
Started: 2025-08-02 18:21:03.989176
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-02 18:21:04.263901
------------------------------------------------------
Started: 2025-08-03 01:29:44.666494
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-03 01:29:44.865268
------------------------------------------------------
Started: 2025-08-03 06:21:16.384623
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-03 06:21:16.572224
------------------------------------------------------
Started: 2025-08-03 12:30:48.064512
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-03 12:30:48.311603
------------------------------------------------------
Started: 2025-08-03 18:21:20.935672
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-03 18:21:21.224928
------------------------------------------------------
Started: 2025-08-04 01:24:05.294982
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-04 01:24:05.697716
------------------------------------------------------
Started: 2025-08-04 06:30:19.942142
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1844
Summarized using qwen-turbo
Append: [DAEDAL：动态自适应长度扩展提升扩散语言模型性能](https://arxiv.org/abs/2508.00819)
Token length: 1222
Summarized using qwen-turbo
Append: [基于多模型共识的高效对话评估方法](https://arxiv.org/abs/2508.00454)
Token length: 1290
Summarized using qwen-turbo
Append: [多模态指代分割研究综述](https://arxiv.org/abs/2508.00265)
Token length: 1377
Summarized using qwen-turbo
Append: [基于经验增强的软件问题解决方法SWE-Exp](https://arxiv.org/abs/2507.23361)
Token length: 1383
Summarized using qwen-turbo
Append: [SWE-Debate：通过多智能体辩论提升代码问题定位与修复](https://arxiv.org/abs/2507.23348)
Token length: 1023
Summarized using qwen-turbo
Append: [PixelNerd：一种高效的单阶段像素神经场扩散模型](https://arxiv.org/abs/2507.23268)
append_entries: 6
Finish: 2025-08-04 06:30:48.890370
------------------------------------------------------
Started: 2025-08-04 12:35:02.861612
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1594
Summarized using qwen-turbo
Append: [基于3D高斯的增量图像目标导航方法](https://arxiv.org/abs/2508.00823)
Token length: 1724
Summarized using qwen-turbo
Append: [基于音频空间信息的视频生成方法研究](https://arxiv.org/abs/2508.00782)
Token length: 1454
Summarized using qwen-turbo
Append: [3D-R1：提升3D场景理解的视觉语言模型](https://arxiv.org/abs/2507.23478)
Token length: 832
Summarized using qwen-turbo
Append: [多语言对话中大语言模型的幻觉现象研究](https://arxiv.org/abs/2507.22720)
append_entries: 4
Finish: 2025-08-04 12:35:17.547807
------------------------------------------------------
Started: 2025-08-04 18:23:33.599852
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1748
Summarized using qwen-turbo
Append: [AI生成交互式音视频内容的新方法与挑战](https://arxiv.org/abs/2508.00632)
append_entries: 1
Finish: 2025-08-04 18:23:37.424697
------------------------------------------------------
Started: 2025-08-05 01:20:17.369055
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1394
Summarized using qwen-turbo
Append: [Cognitive Kernel-Pro：开源AI代理框架提升研究可复现性与性能](https://arxiv.org/abs/2508.00414)
Token length: 1406
Summarized using qwen-turbo
Append: [多模态大语言模型评估新基准MCIF发布](https://arxiv.org/abs/2507.19634)
append_entries: 2
Finish: 2025-08-05 01:20:25.918685
------------------------------------------------------
Started: 2025-08-05 06:26:16.479384
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "面向多模态大语言模型的高效训练框架研究",
  "short_summary": "提出一种高效多模态大模型训练框架，提升训练效率与扩展性。",
  "summary": "本文介绍了 \veomni 框架，旨在加速多模态大语言模型（LLMs）的开发。该框架采用模型中心的分布式策略，将通信与计算解耦，实现高效的三维并行。同时提供灵活的配置接口，便于集成新模态。实验表明，在128块GPU上，该框架可支持30B参数的多模态Mixture-of-Experts模型，每GPU每秒处理超过2800个token，并支持160K上下文长度，展示了其在大规模多模态LLM训练中的高效性和可扩展性。",
  "keyword": ["多模态大语言模型", "分布式训练", "3D并行"]
}Summarization failed, append the original article
error: Invalid \escape: line 4 column 21 (char 107). Line: 406.
Append: [VeOmni: Scaling Any Modality Model Training with Model-Centric Distributed Recipe Zoo](https://arxiv.org/abs/2508.02317)
Token length: 1907
Summarized using qwen-turbo
Append: [CellForge：基于多智能体框架的虚拟细胞建模系统](https://arxiv.org/abs/2508.02276)
Token length: 1072
Summarized using qwen-turbo
Append: [个性化安全对齐框架提升文本到图像生成模型的安全性](https://arxiv.org/abs/2508.01151)
Token length: 1340
Summarized using qwen-turbo
Append: [Foundation-Sec-8B-Instruct：面向网络安全的对话型大语言模型](https://arxiv.org/abs/2508.01059)
Token length: 1328
Summarized using qwen-turbo
Append: [无需运行时环境的网络安全LLM训练框架Cyber-Zero](https://arxiv.org/abs/2508.00910)
Token length: 1538
Summarized using qwen-turbo
Append: [InstructVLA：融合多模态推理与精准动作生成的机器人模型](https://arxiv.org/abs/2507.17520)
append_entries: 6
Finish: 2025-08-05 06:26:46.500551
------------------------------------------------------
Started: 2025-08-05 12:34:36.967416
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1622
Summarized using qwen-turbo
Append: [Qwen-Image：在文本渲染与图像编辑上的重大突破](https://arxiv.org/abs/2508.02324)
Token length: 870
Summarized using qwen-turbo
Append: [基于自监督强化学习的指令遵循能力提升方法](https://arxiv.org/abs/2508.02150)
Token length: 1669
Summarized using qwen-turbo
Append: [基于情境嵌入的长文档检索增强生成方法](https://arxiv.org/abs/2508.01959)
Token length: 966
Summarized using qwen-turbo
Append: [动态视觉标记压缩框架GlimpsePrune提升大视觉语言模型效率](https://arxiv.org/abs/2508.01548)
Token length: 1603
Summarized using qwen-turbo
Append: [RoboMemory：一种面向物理机器人系统的多记忆框架](https://arxiv.org/abs/2508.01415)
Token length: 1716
Summarized using qwen-turbo
Append: [基于贪婪目标的元强化学习中涌现探索行为的研究](https://arxiv.org/abs/2508.01287)
Token length: 1578
Summarized using qwen-turbo
Append: [多阶段复杂任务中的测试时计算最优缩放研究](https://arxiv.org/abs/2508.00890)
append_entries: 7
Finish: 2025-08-05 12:35:14.232998
------------------------------------------------------
Started: 2025-08-05 18:25:13.744744
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1419
Summarized using qwen-turbo
Append: [ReMoMask：一种提升文本到动作生成性能的统一框架](https://arxiv.org/abs/2508.02605)
Token length: 1166
Summarized using qwen-turbo
Append: [Sparse-dLLM：提升扩散大语言模型推理效率的稀疏缓存方法](https://arxiv.org/abs/2508.02558)
Token length: 1285
Summarized using qwen-turbo
Append: [SHAMI-MT：连接标准阿拉伯语与叙利亚方言的机器翻译系统](https://arxiv.org/abs/2508.02268)
Token length: 1416
Summarized using qwen-turbo
Append: [AuroBind：一种用于高通量分子筛选的结构功能学习框架](https://arxiv.org/abs/2508.02137)
Token length: 1328
Summarized using qwen-turbo
Append: [基于不确定性驱动的流程奖励数据构建框架](https://arxiv.org/abs/2508.01773)
Token length: 1306
Summarized using qwen-turbo
Append: [Voxlect：全球方言与区域语言的语音基础模型基准测试](https://arxiv.org/abs/2508.01691)
Token length: 1136
Summarized using qwen-turbo
Append: [人工智能在绘画归属中的挑战与研究](https://arxiv.org/abs/2508.01408)
Token length: 1897
Summarized using qwen-turbo
Append: [多模态数据融合预测家庭财富的研究](https://arxiv.org/abs/2508.01109)
Token length: 864
Summarized using qwen-turbo
Append: [基于ViT嵌入的量子支持向量机可扩展性研究](https://arxiv.org/abs/2508.00024)
Token length: 1691
Summarized using qwen-turbo
Append: [Dens3R：统一几何预测的3D基础模型](https://arxiv.org/abs/2507.16290)
append_entries: 10
Finish: 2025-08-05 18:25:58.818915
------------------------------------------------------
Started: 2025-08-06 01:18:56.033143
Existing_entries: 1010
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Large-scale datasets are foundational for research and development in natural language processing. However, current approaches face three key challenges: (1) reliance on ambiguously licensed sources restricting use, sharing, and derivative works; (2) static dataset releases that prevent community contributions and diminish longevity; and (3) quality assurance processes restricted to publishing teams rather than leveraging community expertise.   To address these limitations, we introduce two contributions: the Dynaword approach and Danish Dynaword. The Dynaword approach is a framework for creating large-scale, open datasets that can be continuously updated through community collaboration. Danish Dynaword is a concrete implementation that validates this approach and demonstrates its potential. Danish Dynaword contains over four times as many tokens as comparable releases, is exclusively openly licensed, and has received multiple contributions across industry and research. The repository includes light-weight tests to ensure data formatting, quality, and documentation, establishing a sustainable framework for ongoing community contributions and dataset evolution.'}]}]Summarization failed, append the original article
error: Request timed out.. Line: 406.
Append: [Dynaword: From One-shot to Continuously Developed Datasets](https://arxiv.org/abs/2508.02271)
append_entries: 1
Finish: 2025-08-06 01:19:13.447008
------------------------------------------------------
Started: 2025-08-06 06:26:21.657211
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-06 06:26:21.830116
------------------------------------------------------
Started: 2025-08-06 12:34:20.024216
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1464
Summarized using qwen-turbo
Append: [可控超长视频生成方法LongVie及其基准测试](https://arxiv.org/abs/2508.03694)
Token length: 1578
Summarized using qwen-turbo
Append: [CompassVerifier：多领域答案验证与评估框架](https://arxiv.org/abs/2508.03686)
Token length: 1455
Summarized using qwen-turbo
Append: [Skywork UniPic：统一多模态任务的高效大模型](https://arxiv.org/abs/2508.03320)
Token length: 1350
Summarized using qwen-turbo
Append: [多人群体说话视频生成数据集MIT与基线模型CovOG](https://arxiv.org/abs/2508.03050)
Token length: 1337
Summarized using qwen-turbo
Append: [ToolTrain提升代码问题定位能力](https://arxiv.org/abs/2508.03012)
Token length: 702
Summarized using qwen-turbo
Append: [Seed Diffusion Preview：高效代码生成的扩散模型](https://arxiv.org/abs/2508.02193)
Token length: 1254
Summarized using qwen-turbo
Append: [基于强化学习的近似最近邻搜索算法CRINN](https://arxiv.org/abs/2508.02091)
Token length: 1599
Summarized using qwen-turbo
Append: [AlignGuard-LoRA：一种防止大语言模型微调中对齐漂移的方法](https://arxiv.org/abs/2508.02079)
Token length: 1779
Summarized using qwen-turbo
Append: [TraceAlign：追踪并缓解大语言模型对齐漂移的框架](https://arxiv.org/abs/2508.02063)
Token length: 1677
Summarized using qwen-turbo
Append: [LiveMCPBench：首个大规模MCP环境下的LLM代理评估基准](https://arxiv.org/abs/2508.01780)
Token length: 1706
Summarized using qwen-turbo
Append: [LAMIC：一种无需训练的多参考图像合成框架](https://arxiv.org/abs/2508.00477)
append_entries: 11
Finish: 2025-08-06 12:35:05.928822
------------------------------------------------------
Started: 2025-08-06 18:23:41.552850
Existing_entries: 1011
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1689
Summarized using qwen-turbo
Append: [Goedel-Prover-V2：开源语言模型在自动定理证明中取得新突破](https://arxiv.org/abs/2508.03613)
Token length: 1372
Summarized using qwen-turbo
Append: [ChartCap数据集提升图表描述准确性](https://arxiv.org/abs/2508.03164)
Token length: 1346
Summarized using qwen-turbo
Append: [Representation Shift：一种与FlashAttention兼容的无训练令牌压缩方法](https://arxiv.org/abs/2508.00367)
append_entries: 3
Finish: 2025-08-06 18:23:52.855265
------------------------------------------------------
Started: 2025-08-07 01:19:30.182388
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1669
Summarized using qwen-turbo
Append: [AI代理在电商中的购物行为研究](https://arxiv.org/abs/2508.02630)
Token length: 1420
Summarized using qwen-turbo
Append: [HyCodePolicy：一种融合多模态推理的自主控制框架](https://arxiv.org/abs/2508.02629)
Token length: 1340
Summarized using qwen-turbo
Append: [基于语言模型的代码补全排序方法研究](https://arxiv.org/abs/2508.02455)
Token length: 1755
Summarized using qwen-turbo
Append: [基于场景上下文的自中心人体运动生成与预测方法](https://arxiv.org/abs/2508.01126)
Token length: 871
Summarized using qwen-turbo
Append: [基于自回归与强化学习的图像编辑模型EARL](https://arxiv.org/abs/2508.01119)
Token length: 1430
Summarized using qwen-turbo
Append: [基于多模态大语言模型的文本-视频检索方法研究](https://arxiv.org/abs/2507.23284)
append_entries: 6
Finish: 2025-08-07 01:19:51.598810
------------------------------------------------------
Started: 2025-08-07 06:25:48.269650
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1881
Summarized using qwen-turbo
Append: [基于注意力权重的上下文回溯方法AttnTrace](https://arxiv.org/abs/2508.03793)
append_entries: 1
Finish: 2025-08-07 06:25:52.097871
------------------------------------------------------
Started: 2025-08-07 12:34:16.356204
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1722
Summarized using qwen-turbo
Append: [SEAgent：通过自主学习提升计算机使用代理的性能](https://arxiv.org/abs/2508.04700)
Token length: 1434
Summarized using qwen-turbo
Append: [通过主动上下文管理提升大语言模型的长文本处理能力](https://arxiv.org/abs/2508.04664)
Token length: 1285
Summarized using qwen-turbo
Append: [基于IFDecorator的强化学习框架提升指令遵循能力](https://arxiv.org/abs/2508.04632)
Token length: 1280
Summarized using qwen-turbo
Append: [AI学术会议的可持续转型：社区联邦会议模型的提出](https://arxiv.org/abs/2508.04586)
Token length: 1822
Summarized using qwen-turbo
Append: [EvoC2Rust：一种用于C到Rust项目级转换的自动化框架](https://arxiv.org/abs/2508.04295)
Token length: 1525
Summarized using qwen-turbo
Append: [基于VL-DAC的视觉语言模型强化学习方法研究](https://arxiv.org/abs/2508.04280)
Token length: 1442
Summarized using qwen-turbo
Append: [VeriGUI：推动长链GUI任务的可验证数据集研究](https://arxiv.org/abs/2508.04026)
Token length: 1263
Summarized using qwen-turbo
Append: [MiDashengLM：一种基于开放数据的高效音频语言模型](https://arxiv.org/abs/2508.03983)
Token length: 1735
Summarized using qwen-turbo
Append: [Sotopia-RL：提升大语言模型社会智能的强化学习框架](https://arxiv.org/abs/2508.03905)
Token length: 1376
Summarized using qwen-turbo
Append: [Agent Lightning：一种用于强化学习训练大型语言模型的灵活框架](https://arxiv.org/abs/2508.03680)
Token length: 1093
Summarized using qwen-turbo
Append: [HPSv3：提升文本生成图像质量的新评估方法](https://arxiv.org/abs/2508.03789)
Token length: 1619
Summarized using qwen-turbo
Append: [基于布局思维的网页设计代码转换方法研究](https://arxiv.org/abs/2508.03560)
Token length: 1306
Summarized using qwen-turbo
Append: [强化学习在大型语言模型软件工程任务中的应用](https://arxiv.org/abs/2508.03501)
Token length: 1486
Summarized using qwen-turbo
Append: [基于文本控制的音乐修复与母带处理模型SonicMaster](https://arxiv.org/abs/2508.03448)
Token length: 1805
Summarized using qwen-turbo
Append: [基于大语言模型的多毒性预测框架CoTox](https://arxiv.org/abs/2508.03159)
Token length: 1762
Summarized using qwen-turbo
Append: [基于扩散Transformer的视频虚拟试穿技术DreamVVT](https://arxiv.org/abs/2508.02807)
Token length: 835
Summarized using qwen-turbo
Append: [LeanK：一种基于学习的KV缓存剪枝方法提升大语言模型效率](https://arxiv.org/abs/2508.02215)
Token length: 1317
Summarized using qwen-turbo
Append: [基于查询的U-Net架构IAUNet在生物医学实例分割中的应用](https://arxiv.org/abs/2508.01928)
Token length: 1914
Summarized using qwen-turbo
Append: [基于多模态知识的网络代理框架与推理系统](https://arxiv.org/abs/2508.01858)
Token length: 1905
Summarized using qwen-turbo
Append: [OpenMed NER：高效且开源的医学实体识别模型](https://arxiv.org/abs/2508.01630)
Token length: 1429
Summarized using qwen-turbo
Append: [3D占用定位基准与GroundingOcc模型研究](https://arxiv.org/abs/2508.01197)
Token length: 1435
Summarized using qwen-turbo
Append: [CoT推理的脆弱性：数据分布视角下的分析](https://arxiv.org/abs/2508.01191)
Token length: 1483
Summarized using qwen-turbo
Append: [RL-PLUS：突破大语言模型能力边界的新方法](https://arxiv.org/abs/2508.00222)
Token length: 1190
Summarized using qwen-turbo
Append: [基于视频生成动态4D内容的新框架](https://arxiv.org/abs/2507.23785)
Token length: 1503
Summarized using qwen-turbo
Append: [文本到图像扩散模型中的内容与风格表示研究](https://arxiv.org/abs/2507.23313)
Token length: 1267
Summarized using qwen-turbo
Append: [基于大语言模型的移动网络根因分析框架](https://arxiv.org/abs/2507.21974)
Token length: 1425
Summarized using qwen-turbo
Append: [高效代理框架的研究与优化](https://arxiv.org/abs/2508.02694)
append_entries: 27
Finish: 2025-08-07 12:36:24.501597
------------------------------------------------------
Started: 2025-08-07 18:24:42.116426
Existing_entries: 1027
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1324
Summarized using qwen-turbo
Append: [提升数学命题自动形式化的ThinkingF方法](https://arxiv.org/abs/2508.04440)
Token length: 1702
Summarized using qwen-turbo
Append: [提升大模型指令遵循能力的框架与实验验证](https://arxiv.org/abs/2508.03178)
Token length: 1533
Summarized using qwen-turbo
Append: [持续学习的3D异常检测框架C3D-AD](https://arxiv.org/abs/2508.01311)
Token length: 1035
Summarized using qwen-turbo
Append: [Sel3DCraft：提升文本到3D生成的视觉提示工程系统](https://arxiv.org/abs/2508.00428)
append_entries: 4
Finish: 2025-08-07 18:24:57.445209
------------------------------------------------------
Started: 2025-08-08 01:19:03.942381
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1603
Summarized using qwen-turbo
Append: [HarmonyGuard：多智能体协作框架提升网络代理的安全与效率](https://arxiv.org/abs/2508.04010)
Token length: 1344
Summarized using qwen-turbo
Append: [机器学习模型全生命周期中的偏见治理与公平性评估](https://arxiv.org/abs/2508.03970)
Token length: 1535
Summarized using qwen-turbo
Append: [基于DiffSemanticFusion的自动驾驶场景理解与轨迹预测方法](https://arxiv.org/abs/2508.01778)
Token length: 1234
Summarized using qwen-turbo
Append: [DPoser-X：基于扩散模型的全身人体姿态生成方法](https://arxiv.org/abs/2508.00599)
Token length: 917
Summarized using qwen-turbo
Append: [FACTORY：一种用于评估模型事实准确性的大型人工验证基准](https://arxiv.org/abs/2508.00109)
append_entries: 5
Finish: 2025-08-08 01:19:25.397690
------------------------------------------------------
Started: 2025-08-08 06:25:30.485317
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1794
Summarized using qwen-turbo
Append: [MOSEv2：推动视频目标分割向真实场景演进的挑战性数据集](https://arxiv.org/abs/2508.05630)
Token length: 1054
Summarized using qwen-turbo
Append: [动态微调提升大语言模型的泛化能力](https://arxiv.org/abs/2508.05629)
Token length: 1587
Summarized using qwen-turbo
Append: [Hi3DEval：面向3D生成内容的层次化评估框架](https://arxiv.org/abs/2508.05609)
Token length: 1266
Summarized using qwen-turbo
Append: [R-Zero：一种自进化大型语言模型框架](https://arxiv.org/abs/2508.05004)
Token length: 1212
Summarized using qwen-turbo
Append: [探索语言模型在多跳问答任务中的推理失败](https://arxiv.org/abs/2508.04699)
Token length: 1313
Summarized using qwen-turbo
Append: [构建结构化客户服务对话框架与数据集提升客服质量](https://arxiv.org/abs/2508.04423)
Token length: 1270
Summarized using qwen-turbo
Append: [提升大语言模型在福祉解释中的质量与适配性](https://arxiv.org/abs/2508.03990)
append_entries: 7
Finish: 2025-08-08 06:25:56.966493
------------------------------------------------------
Started: 2025-08-08 12:33:04.076491
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1206
Summarized using qwen-turbo
Append: [Genie Envisioner：统一的机器人操作基础平台](https://arxiv.org/abs/2508.05635)
Token length: 1901
Summarized using qwen-turbo
Append: [基于大语言模型的隐私保护个人身份信息去标识化研究](https://arxiv.org/abs/2508.05545)
Token length: 1768
Summarized using qwen-turbo
Append: [InfiAlign：一种高效且可扩展的大型语言模型后训练框架](https://arxiv.org/abs/2508.05496)
Token length: 1068
Summarized using qwen-turbo
Append: [DeepPHY：评估视觉语言模型物理推理能力的新基准](https://arxiv.org/abs/2508.05405)
Token length: 1136
Summarized using qwen-turbo
Append: [基于REINA的实时语音翻译系统优化研究](https://arxiv.org/abs/2508.04946)
Token length: 1132
Summarized using qwen-turbo
Append: [评估大语言模型对语言标志的敏感性基准研究](https://arxiv.org/abs/2508.04939)
Token length: 1530
Summarized using qwen-turbo
Append: [RPCANet++：融合RPCA与深度网络的稀疏目标分割框架](https://arxiv.org/abs/2508.04190)
Token length: 1406
Summarized using qwen-turbo
Append: [大型多模态模型输入审查能力评估研究](https://arxiv.org/abs/2508.04017)
Token length: 1522
Summarized using qwen-turbo
Append: [结合GUI与编程的多智能体系统提升计算机自动化效率](https://arxiv.org/abs/2508.03923)
Token length: 1614
Summarized using qwen-turbo
Append: [Double-Bench：多模态文档RAG系统的全面评估框架](https://arxiv.org/abs/2508.03644)
Token length: 1689
Summarized using qwen-turbo
Append: [高效推理方法在大型推理模型中的研究进展](https://arxiv.org/abs/2508.02120)
Token length: 1280
Summarized using qwen-turbo
Append: [多模态语音合成系统Marco-Voice：语音克隆与情感控制的统一框架](https://arxiv.org/abs/2508.02038)
Token length: 982
Summarized using qwen-turbo
Append: [基于草图的逼真发丝生成模型](https://arxiv.org/abs/2508.01650)
append_entries: 13
Finish: 2025-08-08 12:33:57.399331
------------------------------------------------------
Started: 2025-08-08 18:21:01.101603
Existing_entries: 1013
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1231
Summarized using qwen-turbo
Append: [SODEC：一种高效的单步扩散图像压缩模型](https://arxiv.org/abs/2508.04979)
Token length: 1595
Summarized using qwen-turbo
Append: [MACT：多智能体协作框架提升文档理解与视觉问答性能](https://arxiv.org/abs/2508.03404)
Token length: 1317
Summarized using qwen-turbo
Append: [基于多模态协同反思的实体链接框架研究](https://arxiv.org/abs/2508.02243)
append_entries: 3
Finish: 2025-08-08 18:21:12.467895
------------------------------------------------------
Started: 2025-08-09 01:12:50.310787
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1344
Summarized using qwen-turbo
Append: [基于注意力机制的文档重排序方法AttnRank提升大语言模型性能](https://arxiv.org/abs/2508.05128)
Token length: 1417
Summarized using qwen-turbo
Append: [MLLMSeg：一种高效且精确的参考表达分割框架](https://arxiv.org/abs/2508.04107)
append_entries: 2
Finish: 2025-08-09 01:12:58.477957
------------------------------------------------------
Started: 2025-08-09 06:21:32.920371
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1229
Summarized using qwen-turbo
Append: [提升长文本事实性推理的在线强化学习方法](https://arxiv.org/abs/2508.05618)
append_entries: 1
Finish: 2025-08-09 06:21:36.551939
------------------------------------------------------
Started: 2025-08-09 12:28:51.581262
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-09 12:28:51.741789
------------------------------------------------------
Started: 2025-08-09 18:20:20.501266
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-09 18:20:20.743767
------------------------------------------------------
Started: 2025-08-10 01:22:38.577254
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-10 01:22:38.855998
------------------------------------------------------
Started: 2025-08-10 06:21:39.253962
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-10 06:21:39.434973
------------------------------------------------------
Started: 2025-08-10 12:29:27.792301
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-10 12:29:27.956362
------------------------------------------------------
Started: 2025-08-10 18:19:32.725471
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-10 18:19:33.008421
------------------------------------------------------
Started: 2025-08-11 01:19:36.142188
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-11 01:19:36.451144
------------------------------------------------------
Started: 2025-08-11 06:25:41.554510
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1630
Summarized using qwen-turbo
Append: [基于锚点和意外度的代码推理压缩方法研究](https://arxiv.org/abs/2508.05988)
Token length: 1502
Summarized using qwen-turbo
Append: [基于AEPO的多模态大模型GUI语义对齐研究](https://arxiv.org/abs/2508.05731)
Token length: 1520
Summarized using qwen-turbo
Append: [提升低资源语言多模态大模型性能的研究](https://arxiv.org/abs/2508.05502)
Token length: 1113
Summarized using qwen-turbo
Append: [Voost：一种统一且可扩展的虚拟试穿与脱下框架](https://arxiv.org/abs/2508.04825)
append_entries: 4
Finish: 2025-08-11 06:25:59.820372
------------------------------------------------------
Started: 2025-08-11 12:33:24.553262
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Fetch error: HTTPSConnectionPool(host='rsshub.app', port=443): Read timed out. (read timeout=30)
Fetch failed from https://rsshub.app/huggingface/daily-papers
append_entries: 0
error when rendering xml, skip docs/Huggingface-Daliy-Papers
------------------------------------------------------
Started: 2025-08-11 18:22:47.009207
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1234
Summarized using qwen-turbo
Append: [Lightswitch：基于多视角与材质信息的高效3D光照重渲染方法](https://arxiv.org/abs/2508.06494)
Token length: 903
Summarized using qwen-turbo
Append: [GLM-4.5：高性能开源混合专家大语言模型](https://arxiv.org/abs/2508.06471)
Token length: 1046
Summarized using qwen-turbo
Append: [基于可学习程序记忆的智能代理研究](https://arxiv.org/abs/2508.06433)
Token length: 1416
Summarized using qwen-turbo
Append: [无监督视觉语言模型适应方法综述](https://arxiv.org/abs/2508.05547)
Token length: 1589
Summarized using qwen-turbo
Append: [操作系统代理研究综述：从基础到未来方向](https://arxiv.org/abs/2508.04482)
Token length: 1845
Summarized using qwen-turbo
Append: [GENIE：结合NeRF与高斯点云的交互式3D场景编辑方法](https://arxiv.org/abs/2508.02831)
Token length: 1035
Summarized using qwen-turbo
Append: [MeshLLM：基于大语言模型的3D网格文本序列化框架](https://arxiv.org/abs/2508.01242)
Token length: 1306
Summarized using qwen-turbo
Append: [UI-AGILE框架提升GUI代理性能](https://arxiv.org/abs/2507.22025)
append_entries: 8
Finish: 2025-08-11 18:23:28.671944
------------------------------------------------------
Started: 2025-08-12 01:11:47.111474
Existing_entries: 1008
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1452
Summarized using qwen-turbo
Append: [Transformer模型中大规模激活的动态演化分析](https://arxiv.org/abs/2508.03616)
append_entries: 1
Finish: 2025-08-12 01:11:50.692220
------------------------------------------------------
Started: 2025-08-12 06:23:23.883455
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1508
Summarized using qwen-turbo
Append: [VLM4D：评估视觉语言模型时空推理能力的基准](https://arxiv.org/abs/2508.02095)
append_entries: 1
Finish: 2025-08-12 06:23:29.535640
------------------------------------------------------
Started: 2025-08-12 12:31:01.274508
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1529
Summarized using qwen-turbo
Append: [强化学习在大语言模型推理中的研究与实践综述](https://arxiv.org/abs/2508.08221)
Token length: 1382
Summarized using qwen-turbo
Append: [视觉强化学习的最新进展与综述](https://arxiv.org/abs/2508.08189)
Token length: 1282
Summarized using qwen-turbo
Append: [无需训练的精准形状编辑框架Follow-Your-Shape](https://arxiv.org/abs/2508.08134)
Token length: 1748
Summarized using qwen-turbo
Append: [评估智能搜索代理在大规模信息收集中的可靠性](https://arxiv.org/abs/2508.07999)
Token length: 1857
Summarized using qwen-turbo
Append: [Omni-Effects：统一的视觉特效生成框架](https://arxiv.org/abs/2508.07981)
Token length: 1874
Summarized using qwen-turbo
Append: [Action Reasoning Models: 提升机器人感知与行动的结构化推理方法](https://arxiv.org/abs/2508.07917)
Token length: 1131
Summarized using qwen-turbo
Append: [Grove MoE：一种动态可扩展的专家混合架构](https://arxiv.org/abs/2508.07785)
Token length: 1435
Summarized using qwen-turbo
Append: [GLiClass：一种高效的序列分类方法](https://arxiv.org/abs/2508.07662)
Token length: 1596
Summarized using qwen-turbo
Append: [Klear-Reasoner：具备强大推理能力的模型及其优化方法](https://arxiv.org/abs/2508.07629)
Token length: 1254
Summarized using qwen-turbo
Append: [多语言文档视觉检索基准VisR-Bench的引入与评估](https://arxiv.org/abs/2508.07493)
Token length: 1910
Summarized using qwen-turbo
Append: [自进化智能代理系统的研究综述](https://arxiv.org/abs/2508.07407)
Token length: 1367
Summarized using qwen-turbo
Append: [LessIsMore：一种高效的稀疏注意力机制提升推理模型性能](https://arxiv.org/abs/2508.07101)
Token length: 1713
Summarized using qwen-turbo
Append: [基于推理的列表排序模型ReasonRank的优化与性能提升](https://arxiv.org/abs/2508.07050)
Token length: 1570
Summarized using qwen-turbo
Append: [通过数据过滤提升开放权重AI系统的安全性](https://arxiv.org/abs/2508.06601)
Token length: 1698
Summarized using qwen-turbo
Append: [BrowseComp-Plus：提升深度研究系统评估的基准测试](https://arxiv.org/abs/2508.06600)
Token length: 1549
Summarized using qwen-turbo
Append: [研究通用机器人策略的泛化能力与快捷学习问题](https://arxiv.org/abs/2508.06426)
Token length: 1601
Summarized using qwen-turbo
Append: [Temporal Self-Rewarding Language Models提升模型生成能力](https://arxiv.org/abs/2508.06026)
Token length: 1453
Summarized using qwen-turbo
Append: [Bifrost-1：融合多模态大模型与扩散模型的高效图像生成框架](https://arxiv.org/abs/2508.05954)
Token length: 1663
Summarized using qwen-turbo
Append: [OmniEAR：评估语言模型在具身任务中的推理能力](https://arxiv.org/abs/2508.05614)
Token length: 810
Summarized using qwen-turbo
Append: [SONAR-LLM：基于连续SONAR嵌入空间的生成模型](https://arxiv.org/abs/2508.05305)
Token length: 1376
Summarized using qwen-turbo
Append: [基于MoBE的专家混合模型压缩方法研究](https://arxiv.org/abs/2508.05257)
Token length: 1676
Summarized using qwen-turbo
Append: [数学表达式语音转录的挑战与新数据集的提出](https://arxiv.org/abs/2508.03542)
Token length: 1424
Summarized using qwen-turbo
Append: [音频攻击框架WhisperInject可操控先进语音语言模型生成有害内容](https://arxiv.org/abs/2508.03365)
Token length: 1206
Summarized using qwen-turbo
Append: [UserBench：评估语言模型协作能力的新基准](https://arxiv.org/abs/2507.22034)
append_entries: 24
Finish: 2025-08-12 12:32:41.355206
------------------------------------------------------
Started: 2025-08-12 18:22:50.820765
Existing_entries: 1024
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1040
Summarized using qwen-turbo
Append: [针对智能事实核查系统的新型攻击框架研究](https://arxiv.org/abs/2508.06059)
Token length: 1404
Summarized using qwen-turbo
Append: [基于步骤熵的思维链压缩框架提升大语言模型推理效率](https://arxiv.org/abs/2508.03346)
Token length: 1255
Summarized using qwen-turbo
Append: [TextQuests：评估AI代理长期推理能力的新基准](https://arxiv.org/abs/2507.23701)
append_entries: 3
Finish: 2025-08-12 18:23:01.661176
------------------------------------------------------
Started: 2025-08-13 01:13:24.706940
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-13 01:13:24.982326
------------------------------------------------------
Started: 2025-08-13 06:23:35.271739
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1369
Summarized using qwen-turbo
Append: [利用时间一致性提升扩散语言模型的生成质量](https://arxiv.org/abs/2508.09138)
Token length: 1895
Summarized using qwen-turbo
Append: [AutoCodeGen：自动化生成多语言代码生成基准数据集](https://arxiv.org/abs/2508.09101)
Token length: 1415
Summarized using qwen-turbo
Append: [提升大语言模型工具使用能力的强化学习方法](https://arxiv.org/abs/2508.08791)
Token length: 1708
Summarized using qwen-turbo
Append: [基于Diffusion Transformer的电影级镜头生成方法](https://arxiv.org/abs/2508.08244)
Token length: 1427
Summarized using qwen-turbo
Append: [基于分层强化学习的深度搜索框架研究](https://arxiv.org/abs/2508.08088)
Token length: 1383
Summarized using qwen-turbo
Append: [基于单图或文本提示的全景3D世界生成方法](https://arxiv.org/abs/2508.08086)
Token length: 1609
Summarized using qwen-turbo
Append: [基于大规模强化学习的搜索代理ASearcher研究](https://arxiv.org/abs/2508.07976)
Token length: 1281
Summarized using qwen-turbo
Append: [多模态深度研究代理WebWatcher的开发与评估](https://arxiv.org/abs/2508.05748)
Token length: 1673
Summarized using qwen-turbo
Append: [基于空间一致性提升GUI接地任务的性能](https://arxiv.org/abs/2508.05615)
Token length: 1250
Summarized using qwen-turbo
Append: [基于对比注意力引导的无掩码文本到图像生成方法](https://arxiv.org/abs/2508.05399)
append_entries: 10
Finish: 2025-08-13 06:24:19.942883
------------------------------------------------------
Started: 2025-08-13 12:31:33.452914
Existing_entries: 1010
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1545
Summarized using qwen-turbo
Append: [OpenCUA：开源框架推动计算机使用代理研究](https://arxiv.org/abs/2508.09123)
Token length: 696
Summarized using qwen-turbo
Append: [VertexRegen：一种连续细节层次的网格生成框架](https://arxiv.org/abs/2508.09062)
Token length: 1311
Summarized using qwen-turbo
Append: [量子博弈论在真实硬件上的实验验证](https://arxiv.org/abs/2508.09050)
Token length: 1421
Summarized using qwen-turbo
Append: [基于课程学习的长度控制推理方法研究](https://arxiv.org/abs/2508.08940)
Token length: 997
Summarized using qwen-turbo
Append: [DeCRED：提升编码器-解码器ASR模型鲁棒性的解码器中心正则化方法](https://arxiv.org/abs/2508.08938)
Token length: 1430
Summarized using qwen-turbo
Append: [AffordDex：一种具备通用抓取能力的仿人手控制框架](https://arxiv.org/abs/2508.08896)
Token length: 1273
Summarized using qwen-turbo
Append: [BiasGym：一种用于分析和减轻大语言模型偏见的框架](https://arxiv.org/abs/2508.08855)
Token length: 1300
Summarized using qwen-turbo
Append: [Aryabhata 1.0：专为印度高考优化的7B参数数学推理模型](https://arxiv.org/abs/2508.08665)
Token length: 1279
Summarized using qwen-turbo
Append: [基于单张参考图和2D姿态序列的可控4D角色动画框架CharacterShot](https://arxiv.org/abs/2508.07409)
Token length: 1560
Summarized using qwen-turbo
Append: [视频推广攻击：文本到视频检索中的对抗性威胁](https://arxiv.org/abs/2508.06964)
Token length: 1808
Summarized using qwen-turbo
Append: [基于时空融合的10米日地表温度估计方法研究](https://arxiv.org/abs/2508.06485)
Token length: 1576
Summarized using qwen-turbo
Append: [基于通用样本重放的大型语言模型持续学习方法](https://arxiv.org/abs/2508.04676)
Token length: 1687
Summarized using qwen-turbo
Append: [NVSpeech：面向中文的语音情感识别与合成系统](https://arxiv.org/abs/2508.04195)
append_entries: 13
Finish: 2025-08-13 12:32:24.691031
------------------------------------------------------
Started: 2025-08-13 18:21:02.818699
Existing_entries: 1013
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1141
Summarized using qwen-turbo
Append: [逻辑指令理解挑战与基准测试研究](https://arxiv.org/abs/2508.09125)
Token length: 1478
Summarized using qwen-turbo
Append: [基于LLM的低资源语言数据生成方法TopXGen](https://arxiv.org/abs/2508.08680)
Token length: 1324
Summarized using qwen-turbo
Append: [无需微调的大型语言模型在《外交》游戏中的评估框架](https://arxiv.org/abs/2508.07485)
Token length: 1580
Summarized using qwen-turbo
Append: [基于Q语言的大型语言模型适配与优化研究](https://arxiv.org/abs/2508.06813)
Token length: 1004
Summarized using qwen-turbo
Append: [无需重建与优化的3D高斯点云风格迁移方法](https://arxiv.org/abs/2508.05813)
Token length: 920
Summarized using qwen-turbo
Append: [基于部分卷积的图像局部风格迁移方法](https://arxiv.org/abs/2508.05769)
append_entries: 6
Finish: 2025-08-13 18:21:25.233613
------------------------------------------------------
Started: 2025-08-14 01:13:48.594830
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1755
Summarized using qwen-turbo
Append: [面向域适应的变更检测视觉问答方法研究](https://arxiv.org/abs/2508.08974)
Token length: 1459
Summarized using qwen-turbo
Append: [RedDino：面向红细胞图像分析的自监督基础模型](https://arxiv.org/abs/2508.08180)
Token length: 1395
Summarized using qwen-turbo
Append: [ASTRA：系统化检测AI代码生成安全缺陷的自动化代理系统](https://arxiv.org/abs/2508.03936)
Token length: 1435
Summarized using qwen-turbo
Append: [Putnam-AXIOM：评估大语言模型数学推理的新基准](https://arxiv.org/abs/2508.08292)
append_entries: 4
Finish: 2025-08-14 01:14:05.437806
------------------------------------------------------
Started: 2025-08-14 06:23:25.108415
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1886
Summarized using qwen-turbo
Append: [GPT-4o合成数据提升开放模型图像生成能力](https://arxiv.org/abs/2508.09987)
Token length: 1355
Summarized using qwen-turbo
Append: [基于噪声超网络的测试时扩展优化方法](https://arxiv.org/abs/2508.09968)
Token length: 1362
Summarized using qwen-turbo
Append: [基于动态监督的多智能体系统提升问题解决稳定性](https://arxiv.org/abs/2508.09889)
Token length: 1459
Summarized using qwen-turbo
Append: [输入感知后门攻击方法在视觉语言模型中的应用](https://arxiv.org/abs/2508.09456)
Token length: 1585
Summarized using qwen-turbo
Append: [Mol-R1：提升分子生成推理能力的新型框架](https://arxiv.org/abs/2508.08401)
Token length: 1296
Summarized using qwen-turbo
Append: [基于D2F的扩散语言模型加速方法](https://arxiv.org/abs/2508.09192)
Token length: 1646
Summarized using qwen-turbo
Append: [MathReal：面向真实教育场景的多模态数学推理数据集](https://arxiv.org/abs/2508.06009)
Token length: 1743
Summarized using qwen-turbo
Append: [Cooper框架提升大语言模型推理能力与奖励模型鲁棒性](https://arxiv.org/abs/2508.05613)
append_entries: 8
Finish: 2025-08-14 06:23:52.932164
------------------------------------------------------
Started: 2025-08-14 12:32:10.436421
Existing_entries: 1008
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1393
Summarized using qwen-turbo
Append: [Story2Board：无需训练的叙事分镜生成框架](https://arxiv.org/abs/2508.09983)
Token length: 1313
Summarized using qwen-turbo
Append: [VisCodex：融合视觉与代码的多模态语言模型框架](https://arxiv.org/abs/2508.09945)
Token length: 1192
Summarized using qwen-turbo
Append: [自动化生成文本解释提升NLP模型性能](https://arxiv.org/abs/2508.09776)
Token length: 1607
Summarized using qwen-turbo
Append: [M3-Agent：具备长期记忆的多模态智能体框架](https://arxiv.org/abs/2508.09736)
Token length: 1011
Summarized using qwen-turbo
Append: [轻量级身份保持视频生成框架Stand-In](https://arxiv.org/abs/2508.07901)
Token length: 1428
Summarized using qwen-turbo
Append: [GRAO：融合SFT与RL的高效语言模型对齐方法](https://arxiv.org/abs/2508.07750)
Token length: 1717
Summarized using qwen-turbo
Append: [基于隐式奖励的自适应元微调方法提升大语言模型推理能力](https://arxiv.org/abs/2508.06944)
append_entries: 7
Finish: 2025-08-14 12:32:37.025441
------------------------------------------------------
Started: 2025-08-14 18:22:03.516146
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1423
Summarized using qwen-turbo
Append: [基于3DGS的场景重建与修复方法GSFixer](https://arxiv.org/abs/2508.09667)
Token length: 1119
Summarized using qwen-turbo
Append: [基于自适应扫描的细粒度医学图像分割方法ASM-UNet](https://arxiv.org/abs/2508.07237)
Token length: 1384
Summarized using qwen-turbo
Append: [CannyEdit：一种改进的文本到图像区域编辑框架](https://arxiv.org/abs/2508.06937)
Token length: 1418
Summarized using qwen-turbo
Append: [基于多智能体强化学习的无人机协同操控方法](https://arxiv.org/abs/2508.01522)
append_entries: 4
Finish: 2025-08-14 18:22:19.096331
------------------------------------------------------
Started: 2025-08-15 01:14:34.390889
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 655
Summarized using qwen-turbo
Append: [基于mu参数化的Mixture-of-Experts模型研究](https://arxiv.org/abs/2508.09752)
Token length: 1384
Summarized using qwen-turbo
Append: [GFPO：通过优化训练策略减少大模型响应长度膨胀](https://arxiv.org/abs/2508.09726)
Token length: 1028
Summarized using qwen-turbo
Append: [评估大语言模型在模糊问题下的鲁棒性](https://arxiv.org/abs/2508.07321)
append_entries: 3
Finish: 2025-08-15 01:14:45.978370
------------------------------------------------------
Started: 2025-08-15 06:23:12.483276
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1316
Summarized using qwen-turbo
Append: [基于可解释机器学习的自动口译质量评估框架](https://arxiv.org/abs/2508.10860)
Token length: 1566
Summarized using qwen-turbo
Append: [UI-Venus：基于多模态大语言模型的高效UI代理系统](https://arxiv.org/abs/2508.10833)
Token length: 1553
Summarized using qwen-turbo
Append: [HumanSense：评估多模态大语言模型的人类中心交互能力](https://arxiv.org/abs/2508.10576)
Token length: 1854
Summarized using qwen-turbo
Append: [We-Math 2.0：提升多模态大模型数学推理能力的统一系统](https://arxiv.org/abs/2508.10433)
Token length: 1040
Summarized using qwen-turbo
Append: [PRELUDE基准测试：评估长上下文理解能力](https://arxiv.org/abs/2508.09848)
append_entries: 5
Finish: 2025-08-15 06:23:33.151896
------------------------------------------------------
Started: 2025-08-15 12:29:36.066971
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1513
Summarized using qwen-turbo
Append: [ToonComposer：统一动画中间帧生成与上色的AI模型](https://arxiv.org/abs/2508.10881)
Token length: 1693
Summarized using qwen-turbo
Append: [扩散语言模型的现状与展望](https://arxiv.org/abs/2508.10875)
Token length: 1165
Summarized using qwen-turbo
Append: [基于Pass@k的强化学习探索能力研究](https://arxiv.org/abs/2508.10751)
Token length: 883
Summarized using qwen-turbo
Append: [NextStep-1：基于离散文本与连续图像标记的先进文本到图像生成模型](https://arxiv.org/abs/2508.10711)
Token length: 1109
Summarized using qwen-turbo
Append: [视觉编码器对图像采集参数的敏感性分析](https://arxiv.org/abs/2508.10637)
append_entries: 5
Finish: 2025-08-15 12:29:53.775147
------------------------------------------------------
Started: 2025-08-15 18:21:23.459601
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1614
Summarized using qwen-turbo
Append: [Puppeteer：自动3D模型绑定与动画生成框架](https://arxiv.org/abs/2508.10898)
Token length: 1249
Summarized using qwen-turbo
Append: [STream3R：基于Transformer的实时3D重建方法](https://arxiv.org/abs/2508.10893)
Token length: 1171
Summarized using qwen-turbo
Append: [自然语言处理中隐私与可解释性的权衡研究](https://arxiv.org/abs/2508.10482)
append_entries: 3
Finish: 2025-08-15 18:21:34.914252
------------------------------------------------------
Started: 2025-08-16 01:10:40.920268
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-16 01:10:41.079415
------------------------------------------------------
Started: 2025-08-16 06:20:27.298355
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-16 06:20:27.528916
------------------------------------------------------
Started: 2025-08-16 12:27:47.308129
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-16 12:27:47.507169
------------------------------------------------------
Started: 2025-08-16 18:18:44.274398
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-16 18:18:44.495799
------------------------------------------------------
Started: 2025-08-17 01:18:40.611999
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-17 01:18:40.839647
------------------------------------------------------
Started: 2025-08-17 06:21:11.153791
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-17 06:21:11.321417
------------------------------------------------------
Started: 2025-08-17 12:28:36.120231
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-17 12:28:36.337752
------------------------------------------------------
Started: 2025-08-17 18:19:59.158846
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-17 18:19:59.362573
------------------------------------------------------
Started: 2025-08-18 01:18:09.445051
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-18 01:18:09.648538
------------------------------------------------------
Started: 2025-08-18 06:25:21.909297
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1879
Summarized using qwen-turbo
Append: [Thyme：通过代码实现图像处理与逻辑推理的新型多模态大模型框架](https://arxiv.org/abs/2508.11630)
Token length: 1386
Summarized using qwen-turbo
Append: [StyleMM：基于文本描述的风格化3D可变形模型框架](https://arxiv.org/abs/2508.11203)
Token length: 1217
Summarized using qwen-turbo
Append: [PaperRegister：支持细粒度论文检索的系统](https://arxiv.org/abs/2508.11116)
Token length: 1702
Summarized using qwen-turbo
Append: [基于GAN的半监督学习框架在低标注数据医学影像中的应用](https://arxiv.org/abs/2508.06429)
append_entries: 4
Finish: 2025-08-18 06:25:37.012751
------------------------------------------------------
Started: 2025-08-18 12:32:13.393461
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1328
Summarized using qwen-turbo
Append: [基于奖励引导解码的多模态大语言模型适应方法](https://arxiv.org/abs/2508.11616)
Token length: 1668
Summarized using qwen-turbo
Append: [基于多维人类偏好优化的音频驱动肖像动画方法](https://arxiv.org/abs/2508.11255)
Token length: 936
Summarized using qwen-turbo
Append: [MAESTRO：面向多模态遥感数据的自监督学习方法](https://arxiv.org/abs/2508.10894)
Token length: 1505
Summarized using qwen-turbo
Append: [大型语言模型在强化学习中的模拟搜索应用研究](https://arxiv.org/abs/2508.10874)
Token length: 1115
Summarized using qwen-turbo
Append: [TexVerse：大规模高分辨率3D纹理数据集发布](https://arxiv.org/abs/2508.10868)
Token length: 1549
Summarized using qwen-turbo
Append: [X-Node：一种可解释的图神经网络框架](https://arxiv.org/abs/2508.10461)
Token length: 1850
Summarized using qwen-turbo
Append: [XQuant：通过低比特量化提升大语言模型推理效率](https://arxiv.org/abs/2508.10395)
Token length: 1548
Summarized using qwen-turbo
Append: [DINOv3：实现自监督学习愿景的视觉基础模型](https://arxiv.org/abs/2508.10104)
append_entries: 8
Finish: 2025-08-18 12:32:44.528044
------------------------------------------------------
Started: 2025-08-18 18:22:43.171093
Existing_entries: 1008
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1706
Summarized using qwen-turbo
Append: [BeyondWeb：提升预训练语言模型合成数据质量的新框架](https://arxiv.org/abs/2508.10975)
append_entries: 1
Finish: 2025-08-18 18:22:46.673321
------------------------------------------------------
Started: 2025-08-19 01:10:36.707644
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-19 01:10:37.099929
------------------------------------------------------
Started: 2025-08-19 06:22:15.691529
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1199
Summarized using qwen-turbo
Append: [4DNeX：基于单张图像的高效4D场景生成框架](https://arxiv.org/abs/2508.13154)
Token length: 1290
Summarized using qwen-turbo
Append: [Matrix-Game 2.0：基于扩散模型的实时交互视频生成框架](https://arxiv.org/abs/2508.13009)
Token length: 1829
Summarized using qwen-turbo
Append: [基于大规模视频生成模型的视频重新照明方法](https://arxiv.org/abs/2508.12945)
Token length: 1151
Summarized using qwen-turbo
Append: [S^2-Guidance：提升扩散模型生成质量的新方法](https://arxiv.org/abs/2508.12880)
Token length: 1106
Summarized using qwen-turbo
Append: [基于视觉粒度序列的图像生成方法研究](https://arxiv.org/abs/2508.12811)
Token length: 1755
Summarized using qwen-turbo
Append: [逆向多模态学习方法Invers-LLaVA突破传统对齐预训练范式](https://arxiv.org/abs/2508.12466)
Token length: 988
Summarized using qwen-turbo
Append: [基于生物听觉机制的语音表示学习模型AuriStream](https://arxiv.org/abs/2508.11598)
Token length: 1842
Summarized using qwen-turbo
Append: [Ovis2.5：提升多模态推理与视觉感知的新型模型](https://arxiv.org/abs/2508.11737)
Token length: 1748
Summarized using qwen-turbo
Append: [基于动态记忆的长文本推理方法ComoRAG](https://arxiv.org/abs/2508.10419)
Token length: 1296
Summarized using qwen-turbo
Append: [高效大语言模型架构研究综述](https://arxiv.org/abs/2508.09834)
append_entries: 10
Finish: 2025-08-19 06:22:54.934286
------------------------------------------------------
Started: 2025-08-19 12:30:06.098517
Existing_entries: 1010
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1269
Summarized using qwen-turbo
Append: [多模态模型在空间智能方面的进展与挑战](https://arxiv.org/abs/2508.13142)
Token length: 1364
Summarized using qwen-turbo
Append: [视觉动作提示：跨领域复杂交互视频生成的新方法](https://arxiv.org/abs/2508.13104)
Token length: 1678
Summarized using qwen-turbo
Append: [HeroBench：评估大语言模型长程规划能力的新基准](https://arxiv.org/abs/2508.12782)
Token length: 992
Summarized using qwen-turbo
Append: [评估提升大语言模型提示鲁棒性的方法](https://arxiv.org/abs/2508.11383)
Token length: 996
Summarized using qwen-turbo
Append: [大型推理模型在主动信息获取能力上的不足与挑战](https://arxiv.org/abs/2508.11252)
append_entries: 5
Finish: 2025-08-19 12:30:28.556416
------------------------------------------------------
Started: 2025-08-19 18:20:06.036254
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1471
Summarized using qwen-turbo
Append: [基于可验证奖励的强化学习在大型语言模型中的应用](https://arxiv.org/abs/2508.12790)
Token length: 1537
Summarized using qwen-turbo
Append: [面向机器遗忘方法的可视化评估系统研究](https://arxiv.org/abs/2508.12730)
Token length: 929
Summarized using qwen-turbo
Append: [G-CUT3R：一种融合先验信息的3D场景重建方法](https://arxiv.org/abs/2508.11379)
append_entries: 3
Finish: 2025-08-19 18:20:15.677930
------------------------------------------------------
Started: 2025-08-20 01:08:36.474515
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-20 01:08:36.705450
------------------------------------------------------
Started: 2025-08-20 06:22:17.064292
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1031
Summarized using qwen-turbo
Append: [LongSplat：解决长视频新视角合成的3D高斯点云框架](https://arxiv.org/abs/2508.14041)
Token length: 1726
Summarized using qwen-turbo
Append: [MMAU-Pro：评估AI音频智能的全面基准](https://arxiv.org/abs/2508.13992)
Token length: 1049
Summarized using qwen-turbo
Append: [POML：一种用于复杂提示管理的标记语言](https://arxiv.org/abs/2508.13948)
Token length: 1450
Summarized using qwen-turbo
Append: [OmniTry：一种扩展至多种可穿戴物品的虚拟试穿框架](https://arxiv.org/abs/2508.13632)
Token length: 1184
Summarized using qwen-turbo
Append: [基于大语言模型的人类痛苦感知预测研究](https://arxiv.org/abs/2508.12669)
Token length: 1658
Summarized using qwen-turbo
Append: [无需训练的图像与视频颜色编辑方法ColorCtrl](https://arxiv.org/abs/2508.09131)
Token length: 1463
Summarized using qwen-turbo
Append: [多视觉参考的可控图像生成研究](https://arxiv.org/abs/2508.06905)
Token length: 1725
Summarized using qwen-turbo
Append: [Chain-of-Agents：一种新型的端到端多智能体推理范式](https://arxiv.org/abs/2508.13167)
append_entries: 8
Finish: 2025-08-20 06:23:00.724014
------------------------------------------------------
Started: 2025-08-20 12:29:52.032448
Existing_entries: 1008
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1425
Summarized using qwen-turbo
Append: [基于指向表示的具身AI模型提升泛化能力](https://arxiv.org/abs/2508.13998)
Token length: 947
Summarized using qwen-turbo
Append: [大型语言模型在道德理解上的表现分析](https://arxiv.org/abs/2508.13804)
Token length: 1380
Summarized using qwen-turbo
Append: [跨骨骼拓扑动画迁移方法研究](https://arxiv.org/abs/2508.13139)
Token length: 1233
Summarized using qwen-turbo
Append: [基于相关性的稀疏自编码器自动调优方法CorrSteer](https://arxiv.org/abs/2508.12535)
Token length: 1783
Summarized using qwen-turbo
Append: [大语言模型版权保护技术综述](https://arxiv.org/abs/2508.11548)
Token length: 1683
Summarized using qwen-turbo
Append: [MedSAMix：一种无需训练的医学图像分割模型融合方法](https://arxiv.org/abs/2508.11032)
Token length: 1501
Summarized using qwen-turbo
Append: [深度学习在语音分离中的系统综述](https://arxiv.org/abs/2508.10830)
Token length: 1277
Summarized using qwen-turbo
Append: [统一生成模型中语义ID的构建与性能研究](https://arxiv.org/abs/2508.10478)
Token length: 1485
Summarized using qwen-turbo
Append: [利用多模态大语言模型提升视频推荐系统的语义理解能力](https://arxiv.org/abs/2508.09789)
Token length: 1443
Summarized using qwen-turbo
Append: [基于大语言模型的播客推荐评估框架](https://arxiv.org/abs/2508.08777)
Token length: 1147
Summarized using qwen-turbo
Append: [辐射场在扩展现实中的研究现状与挑战](https://arxiv.org/abs/2508.04326)
Token length: 1515
Summarized using qwen-turbo
Append: [基于时间结构的流匹配模型强化学习优化方法](https://arxiv.org/abs/2508.04324)
Token length: 1455
Summarized using qwen-turbo
Append: [ZARA：基于代理的零样本可解释运动时间序列识别框架](https://arxiv.org/abs/2508.04038)
append_entries: 13
Finish: 2025-08-20 12:30:33.212124
------------------------------------------------------
Started: 2025-08-20 18:21:06.266529
Existing_entries: 1013
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 988
Summarized using qwen-turbo
Append: [基于少样本学习的合成语音检测方法研究](https://arxiv.org/abs/2508.13320)
Token length: 1208
Summarized using qwen-turbo
Append: [提出PASR方法提升大语言模型自我优化能力](https://arxiv.org/abs/2508.12903)
Token length: 1101
Summarized using qwen-turbo
Append: [CAMAR：多智能体路径规划的新型MARL基准](https://arxiv.org/abs/2508.12845)
Token length: 1561
Summarized using qwen-turbo
Append: [基于原子思维的增强型检索生成框架Atom-Searcher](https://arxiv.org/abs/2508.12800)
Token length: 1541
Summarized using qwen-turbo
Append: [FineCE：一种用于大语言模型的细粒度置信度估计方法](https://arxiv.org/abs/2508.12040)
Token length: 1198
Summarized using qwen-turbo
Append: [MM-BrowseComp：评估AI代理多模态检索与推理能力的新基准](https://arxiv.org/abs/2508.13186)
append_entries: 6
Finish: 2025-08-20 18:21:24.705252
------------------------------------------------------
Started: 2025-08-21 01:08:05.064264
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1415
Summarized using qwen-turbo
Append: [轻量级语言模型中的推理与检索增强生成方法](https://arxiv.org/abs/2508.11386)
append_entries: 1
Finish: 2025-08-21 01:08:09.765812
------------------------------------------------------
Started: 2025-08-21 06:31:57.190685
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-21 06:31:57.453899
------------------------------------------------------
Started: 2025-08-21 12:29:23.552593
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1490
Summarized using qwen-turbo
Append: [扩散语言模型的量化研究与部署分析](https://arxiv.org/abs/2508.14896)
Token length: 1319
Summarized using qwen-turbo
Append: [MeshCoder：将3D物体重建为可编辑的Python脚本](https://arxiv.org/abs/2508.14879)
Token length: 1489
Summarized using qwen-turbo
Append: [Tinker：无需微调的高保真3D编辑框架](https://arxiv.org/abs/2508.14811)
Token length: 1360
Summarized using qwen-turbo
Append: [DuPO：一种无需标注的双学习偏好优化框架](https://arxiv.org/abs/2508.14460)
Token length: 1335
Summarized using qwen-turbo
Append: [Nemotron-Nano-9B-v2：提升推理性能的混合Mamba-Transformer语言模型](https://arxiv.org/abs/2508.14444)
Token length: 841
Summarized using qwen-turbo
Append: [提升模型局部尺度不变性的深度均衡校准器](https://arxiv.org/abs/2508.14187)
Token length: 1138
Summarized using qwen-turbo
Append: [RynnEC：面向具身认知的视频多模态大语言模型](https://arxiv.org/abs/2508.14160)
Token length: 1807
Summarized using qwen-turbo
Append: [基于多模态对比学习与同构关系的推荐系统框架REARM](https://arxiv.org/abs/2508.13745)
Token length: 1360
Summarized using qwen-turbo
Append: [越南语多模态教育评估中视觉语言模型的表现研究](https://arxiv.org/abs/2508.13680)
Token length: 1827
Summarized using qwen-turbo
Append: [FinCDM：面向金融大语言模型的认知诊断评估框架](https://arxiv.org/abs/2508.13491)
Token length: 1448
Summarized using qwen-turbo
Append: [人工智能在科学发现中的自主化：Agentic Science的演进与展望](https://arxiv.org/abs/2508.14111)
Token length: 1753
Summarized using qwen-turbo
Append: [面向未来预测的动态评估基准FutureX及其对LLM代理的性能分析](https://arxiv.org/abs/2508.11987)
Token length: 1634
Summarized using qwen-turbo
Append: [CHORD：融合SFT与RL的可控强化学习框架](https://arxiv.org/abs/2508.11408)
Token length: 1493
Summarized using qwen-turbo
Append: [多语言常识推理基准mSCoRe的构建与分析](https://arxiv.org/abs/2508.10137)
append_entries: 14
Finish: 2025-08-21 12:30:09.704507
------------------------------------------------------
Started: 2025-08-21 18:21:19.482364
Existing_entries: 1014
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1920
Summarized using qwen-turbo
Append: [MCP-Universe：首个评估大语言模型与外部工具交互的综合基准](https://arxiv.org/abs/2508.14704)
Token length: 1333
Summarized using qwen-turbo
Append: [基于全同态加密的Levenshtein距离优化算法](https://arxiv.org/abs/2508.14568)
append_entries: 2
Finish: 2025-08-21 18:21:27.419855
------------------------------------------------------
Started: 2025-08-22 01:08:31.892537
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 898
Summarized using qwen-turbo
Append: [FLARE：一种线性复杂度的自注意力机制](https://arxiv.org/abs/2508.12594)
append_entries: 1
Finish: 2025-08-22 01:08:35.962510
------------------------------------------------------
Started: 2025-08-22 06:22:10.350542
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1457
Summarized using qwen-turbo
Append: [SceneGen：基于单图和多图输入的3D场景资产生成框架](https://arxiv.org/abs/2508.15769)
Token length: 1912
Summarized using qwen-turbo
Append: [Intern-S1：面向科学领域的高性能开源基础模型](https://arxiv.org/abs/2508.15763)
Token length: 1010
Summarized using qwen-turbo
Append: [DeepConf提升大语言模型推理效率与准确性](https://arxiv.org/abs/2508.15260)
Token length: 1674
Summarized using qwen-turbo
Append: [Fin-PRM：面向金融领域的过程奖励模型](https://arxiv.org/abs/2508.15202)
Token length: 1649
Summarized using qwen-turbo
Append: [GUI-Owl与Mobile-Agent-v3：开源GUI代理模型的最新进展](https://arxiv.org/abs/2508.15144)
append_entries: 5
Finish: 2025-08-22 06:22:25.990418
------------------------------------------------------
Started: 2025-08-22 12:28:41.800009
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1416
Summarized using qwen-turbo
Append: [ATLAS：一种高保真人体建模方法](https://arxiv.org/abs/2508.15767)
Token length: 1459
Summarized using qwen-turbo
Append: [Waver：统一图像与视频生成的高性能基础模型](https://arxiv.org/abs/2508.15761)
Token length: 1337
Summarized using qwen-turbo
Append: [LiveMCP-101：评估AI代理多工具协作能力的新基准](https://arxiv.org/abs/2508.15760)
Token length: 847
Summarized using qwen-turbo
Append: [Geo-Visual Agents：基于多模态AI的地理视觉问答系统](https://arxiv.org/abs/2508.15752)
Token length: 1154
Summarized using qwen-turbo
Append: [Grounded VideoDiT：提升视频理解的时序感知与实体对齐能力](https://arxiv.org/abs/2508.15641)
Token length: 1274
Summarized using qwen-turbo
Append: [大型语言模型评估基准的现状与挑战](https://arxiv.org/abs/2508.15361)
Token length: 1694
Summarized using qwen-turbo
Append: [aiXiv：面向人工智能科学家的开放科研平台](https://arxiv.org/abs/2508.15126)
Token length: 1403
Summarized using qwen-turbo
Append: [基于双视角图像的3D人体重建方法](https://arxiv.org/abs/2508.14892)
append_entries: 8
Finish: 2025-08-22 12:29:08.224492
------------------------------------------------------
Started: 2025-08-22 18:20:15.761231
Existing_entries: 1008
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1601
Summarized using qwen-turbo
Append: [基于自回归框架的高效图像编辑方法VAREdit](https://arxiv.org/abs/2508.15772)
Token length: 1495
Summarized using qwen-turbo
Append: [LLaSO：首个全面开源的大规模语音语言建模框架](https://arxiv.org/abs/2508.15418)
Token length: 1074
Summarized using qwen-turbo
Append: [AI伴侣行为评估基准INTIMA揭示情感互动模式](https://arxiv.org/abs/2508.09998)
append_entries: 3
Finish: 2025-08-22 18:20:26.189051
------------------------------------------------------
Started: 2025-08-23 01:06:06.603959
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-23 01:06:07.071177
------------------------------------------------------
Started: 2025-08-23 06:19:46.166892
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-23 06:19:46.388063
------------------------------------------------------
Started: 2025-08-23 12:26:18.536281
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-23 12:26:18.795930
------------------------------------------------------
Started: 2025-08-23 18:18:04.956832
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-23 18:18:05.175952
------------------------------------------------------
Started: 2025-08-24 01:16:04.994781
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-24 01:16:05.221726
------------------------------------------------------
Started: 2025-08-24 06:20:45.202556
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-24 06:20:45.435766
------------------------------------------------------
Started: 2025-08-24 12:26:58.637634
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-24 12:26:58.899875
------------------------------------------------------
Started: 2025-08-24 18:18:42.600957
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-24 18:18:42.875646
------------------------------------------------------
Started: 2025-08-25 01:11:28.464659
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-25 01:11:28.721609
------------------------------------------------------
Started: 2025-08-25 06:23:58.045153
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1052
Summarized using qwen-turbo
Append: [AetherCode：评估大型语言模型代码能力的新基准](https://arxiv.org/abs/2508.16402)
Token length: 1348
Summarized using qwen-turbo
Append: [基于语言指令的机器人任务处理框架研究](https://arxiv.org/abs/2508.16292)
Token length: 1562
Summarized using qwen-turbo
Append: [AgentScope 1.0：支持高效工具交互的智能代理框架](https://arxiv.org/abs/2508.16279)
Token length: 1570
Summarized using qwen-turbo
Append: [基于记忆的在线强化学习实现LLM代理的持续适应](https://arxiv.org/abs/2508.16153)
Token length: 1475
Summarized using qwen-turbo
Append: [评估大语言模型在社交推理游戏中的个性化推理能力](https://arxiv.org/abs/2508.16072)
Token length: 1917
Summarized using qwen-turbo
Append: [基于强化学习的医疗诊断增强系统Deep-DxSearch](https://arxiv.org/abs/2508.15746)
Token length: 1496
Summarized using qwen-turbo
Append: [Tensor-Parallel Latent Attention 提升模型推理效率](https://arxiv.org/abs/2508.15881)
Token length: 1168
Summarized using qwen-turbo
Append: [基于LLM与人工辅助的恶意内容检测框架及其在越狱攻击评估中的应用](https://arxiv.org/abs/2508.10390)
append_entries: 8
Finish: 2025-08-25 06:24:25.147335
------------------------------------------------------
Started: 2025-08-25 12:30:28.812359
Existing_entries: 1008
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1692
Summarized using qwen-turbo
Append: [基于对比学习的链式思维强化微调方法提升大语言模型推理能力](https://arxiv.org/abs/2508.15868)
Token length: 1398
Summarized using qwen-turbo
Append: [基于自我对弈与变分问题生成的强化学习方法提升大语言模型推理能力](https://arxiv.org/abs/2508.14029)
Token length: 1129
Summarized using qwen-turbo
Append: [基于稀疏自编码器的持久概念遗忘方法CRISP](https://arxiv.org/abs/2508.13650)
Token length: 1459
Summarized using qwen-turbo
Append: [Learnable SMPLify：基于神经网络的3D人体姿态估计方法](https://arxiv.org/abs/2508.13562)
Token length: 1334
Summarized using qwen-turbo
Append: [EgoTwin：联合生成第一视角视频与人体运动的框架](https://arxiv.org/abs/2508.13013)
Token length: 1915
Summarized using qwen-turbo
Append: [ODYSSEY：面向复杂环境的移动操作框架研究](https://arxiv.org/abs/2508.08240)
Token length: 1629
Summarized using qwen-turbo
Append: [基于CLIP的弱监督可操作性定位方法研究](https://arxiv.org/abs/2508.07877)
append_entries: 7
Finish: 2025-08-25 12:30:51.178639
------------------------------------------------------
Started: 2025-08-25 18:21:24.114055
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1123
Summarized using qwen-turbo
Append: [基于旋转与循环移位等变性的轮廓数据深度学习框架](https://arxiv.org/abs/2508.16359)
Token length: 1792
Summarized using qwen-turbo
Append: [基于草图的3D视频编辑方法Sketch3DVE](https://arxiv.org/abs/2508.13797)
append_entries: 2
Finish: 2025-08-25 18:21:31.072204
------------------------------------------------------
Started: 2025-08-26 01:09:47.678799
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1196
Summarized using qwen-turbo
Append: [基于知识蒸馏的3D高斯点云渲染优化方法](https://arxiv.org/abs/2508.14037)
append_entries: 1
Finish: 2025-08-26 01:09:51.677542
------------------------------------------------------
Started: 2025-08-26 06:22:36.510225
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1920
Summarized using qwen-turbo
Append: [UQ：一种基于未解问题的AI模型评估新范式](https://arxiv.org/abs/2508.17580)
Token length: 1437
Summarized using qwen-turbo
Append: [基于多智能体系统的论文转海报生成框架PosterGen](https://arxiv.org/abs/2508.17188)
append_entries: 2
Finish: 2025-08-26 06:22:43.847418
------------------------------------------------------
Started: 2025-08-26 12:32:03.941566
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1456
Summarized using qwen-turbo
Append: [InternVL 3.5：多模态模型的推理与效率提升](https://arxiv.org/abs/2508.18265)
Token length: 1877
Summarized using qwen-turbo
Append: [基于大语言模型的半结构化表格问答框架ST-Raptor](https://arxiv.org/abs/2508.18190)
Token length: 942
Summarized using qwen-turbo
Append: [SpotEdit：评估视觉引导图像编辑的基准测试](https://arxiv.org/abs/2508.18159)
Token length: 1280
Summarized using qwen-turbo
Append: [评估大型语言模型作为评判者在自然语言生成中的有效性](https://arxiv.org/abs/2508.18076)
Token length: 1276
Summarized using qwen-turbo
Append: [基于视觉链引导的文本到图像生成方法研究](https://arxiv.org/abs/2508.18032)
Token length: 420
Summarized using qwen-turbo
Append: [T2I-ReasonBench：评估文本到图像模型推理能力的基准](https://arxiv.org/abs/2508.17472)
Token length: 1863
Summarized using qwen-turbo
Append: [ compositional visual reasoning 研究综述](https://arxiv.org/abs/2508.17298)
Token length: 1136
Summarized using qwen-turbo
Append: [MEENA：首个评估波斯语视觉语言模型的基准数据集](https://arxiv.org/abs/2508.17290)
Token length: 1671
Summarized using qwen-turbo
Append: [RuscaRL：突破大语言模型推理瓶颈的新方法](https://arxiv.org/abs/2508.16949)
Token length: 1715
Summarized using qwen-turbo
Append: [TaDiCodec：一种高效端到端的语音编码器](https://arxiv.org/abs/2508.16790)
Token length: 1417
Summarized using qwen-turbo
Append: [基于多视角检索的文本到3D生成方法MV-RAG](https://arxiv.org/abs/2508.16577)
append_entries: 11
Finish: 2025-08-26 12:32:46.503226
------------------------------------------------------
Started: 2025-08-26 18:20:05.708361
Existing_entries: 1011
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 799
Summarized using qwen-turbo
Append: [德国语料库German4All助力多级文本简化](https://arxiv.org/abs/2508.17973)
Token length: 1042
Summarized using qwen-turbo
Append: [注意力机制中归一化方法的局限性研究](https://arxiv.org/abs/2508.17821)
Token length: 1323
Summarized using qwen-turbo
Append: [基于高斯点云的稀疏视图表面重建方法MeshSplat](https://arxiv.org/abs/2508.17811)
Token length: 1719
Summarized using qwen-turbo
Append: [基于生成对抗网络的游戏实时摄影级画质增强方法](https://arxiv.org/abs/2508.17061)
Token length: 905
Summarized using qwen-turbo
Append: [神经网络在细胞自动机框架下的多步推理能力研究](https://arxiv.org/abs/2508.16745)
append_entries: 5
Finish: 2025-08-26 18:20:21.325042
------------------------------------------------------
Started: 2025-08-27 01:07:16.350448
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1678
Summarized using qwen-turbo
Append: [基于覆盖准则的多模态视觉语言模型令牌选择方法](https://arxiv.org/abs/2508.18264)
Token length: 678
Summarized using qwen-turbo
Append: [Hermes 4：融合结构化推理与指令遵循的混合模型](https://arxiv.org/abs/2508.18255)
Token length: 819
Summarized using qwen-turbo
Append: [基于无预设分解问题的声明验证框架研究](https://arxiv.org/abs/2508.16838)
append_entries: 3
Finish: 2025-08-27 01:07:26.365332
------------------------------------------------------
Started: 2025-08-27 06:21:06.452016
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1440
Summarized using qwen-turbo
Append: [基于3D潜在空间的精准编辑方法VoxHammer](https://arxiv.org/abs/2508.19247)
Token length: 1722
Summarized using qwen-turbo
Append: [OmniHuman-1.5：生成具有语义一致性的视频虚拟角色动画](https://arxiv.org/abs/2508.19209)
Token length: 830
Summarized using qwen-turbo
Append: [VibeVoice：基于扩散模型的多说话人长时语音合成技术](https://arxiv.org/abs/2508.19205)
Token length: 1345
Summarized using qwen-turbo
Append: [基于顶点与面分离的高效艺术网格生成方法](https://arxiv.org/abs/2508.19188)
Token length: 1497
Summarized using qwen-turbo
Append: [ThinkDial：实现可控推理的开源框架](https://arxiv.org/abs/2508.18773)
Token length: 1618
Summarized using qwen-turbo
Append: [UltraMemV2：实现与MoE模型性能相当的高效内存层架构](https://arxiv.org/abs/2508.18756)
Token length: 1054
Summarized using qwen-turbo
Append: [音频驱动角色动画模型Wan-S2V在影视级表现上的提升](https://arxiv.org/abs/2508.18621)
Token length: 1517
Summarized using qwen-turbo
Append: [CTF-Dojo：基于可执行环境的大型语言模型训练新范式](https://arxiv.org/abs/2508.18370)
Token length: 1512
Summarized using qwen-turbo
Append: [基于认知科学的大型语言模型分析框架](https://arxiv.org/abs/2508.18192)
Token length: 1592
Summarized using qwen-turbo
Append: [Spacer：一种无需外部干预的科学发现系统](https://arxiv.org/abs/2508.17661)
Token length: 1662
Summarized using qwen-turbo
Append: [CineScale：提升高分辨率视觉生成能力的新方法](https://arxiv.org/abs/2508.15774)
Token length: 1287
Summarized using qwen-turbo
Append: [基于视觉信息预测3D场景物理属性的新方法PIXIE](https://arxiv.org/abs/2508.17437)
append_entries: 12
Finish: 2025-08-27 06:21:47.899448
------------------------------------------------------
Started: 2025-08-27 12:29:24.021091
Existing_entries: 1012
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1108
Summarized using qwen-turbo
Append: [AUSM：统一提示与无提示视频分割的通用模型](https://arxiv.org/abs/2508.19242)
Token length: 1530
Summarized using qwen-turbo
Append: [科学推理任务的评估与模型优化研究](https://arxiv.org/abs/2508.19202)
Token length: 1320
Summarized using qwen-turbo
Append: [MovieCORE：推动电影内容深度理解的视频问答数据集](https://arxiv.org/abs/2508.19026)
Token length: 1438
Summarized using qwen-turbo
Append: [MoE模型稀疏性对记忆与推理能力的影响研究](https://arxiv.org/abs/2508.18672)
Token length: 1437
Summarized using qwen-turbo
Append: [ObjFiller-3D：提升3D物体补全质量的新方法](https://arxiv.org/abs/2508.18271)
Token length: 1193
Summarized using qwen-turbo
Append: [CMPhysBench：评估大语言模型在凝聚态物理中的能力基准](https://arxiv.org/abs/2508.18124)
Token length: 1680
Summarized using qwen-turbo
Append: [TreePO：提升语言模型推理效率的强化学习方法](https://arxiv.org/abs/2508.17445)
Token length: 1619
Summarized using qwen-turbo
Append: [QueryBandits：通过查询重写主动减少大语言模型的幻觉](https://arxiv.org/abs/2508.16697)
Token length: 1665
Summarized using qwen-turbo
Append: [ReportBench：评估大语言模型生成研究报告质量的基准](https://arxiv.org/abs/2508.15804)
append_entries: 9
Finish: 2025-08-27 12:29:59.902052
------------------------------------------------------
Started: 2025-08-27 18:20:15.310243
Existing_entries: 1009
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1153
Summarized using qwen-turbo
Append: [深度学习在金融收益分布预测中的应用研究](https://arxiv.org/abs/2508.18921)
Token length: 1737
Summarized using qwen-turbo
Append: [基于推理的大型语言模型DrugReasoner在药物审批预测中的应用](https://arxiv.org/abs/2508.18579)
Token length: 1322
Summarized using qwen-turbo
Append: [基于回溯机制的灵活激活调控方法提升大语言模型行为对齐](https://arxiv.org/abs/2508.17621)
Token length: 1077
Summarized using qwen-turbo
Append: [中文法律主张生成研究与数据集构建](https://arxiv.org/abs/2508.17234)
Token length: 1156
Summarized using qwen-turbo
Append: [Selct2Know：一种高效融合内外部知识的领域问答框架](https://arxiv.org/abs/2508.15213)
append_entries: 5
Finish: 2025-08-27 18:20:33.230953
------------------------------------------------------
Started: 2025-08-28 01:06:40.802486
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-28 01:06:41.259049
------------------------------------------------------
Started: 2025-08-28 06:21:47.193183
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1551
Summarized using qwen-turbo
Append: [CODA：一种结合规划器与执行器的可训练组合框架](https://arxiv.org/abs/2508.20096)
Token length: 1561
Summarized using qwen-turbo
Append: [AudioStory：生成结构化长时音频叙事的统一框架](https://arxiv.org/abs/2508.20088)
Token length: 1575
Summarized using qwen-turbo
Append: [基于离散扩散的视觉-语言-动作模型设计与应用](https://arxiv.org/abs/2508.20072)
Token length: 1803
Summarized using qwen-turbo
Append: [Vision-SR1：一种无需外部视觉监督的自奖励视觉语言模型训练方法](https://arxiv.org/abs/2508.19652)
Token length: 1502
Summarized using qwen-turbo
Append: [智能手机代理的隐私意识评估与基准测试](https://arxiv.org/abs/2508.19493)
Token length: 1061
Summarized using qwen-turbo
Append: [基于生成式判断的多步骤推理模型优化方法](https://arxiv.org/abs/2508.19229)
Token length: 828
Summarized using qwen-turbo
Append: [Token Order Prediction提升语言模型训练效果](https://arxiv.org/abs/2508.19228)
append_entries: 7
Finish: 2025-08-28 06:22:12.229485
------------------------------------------------------
Started: 2025-08-28 12:29:05.087618
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1889
Summarized using qwen-turbo
Append: [DeepScholar-bench：评估生成式研究综合能力的新基准](https://arxiv.org/abs/2508.20033)
Token length: 1749
Summarized using qwen-turbo
Append: [基于早期答案收敛的扩散语言模型快速解码方法](https://arxiv.org/abs/2508.19982)
Token length: 1240
Summarized using qwen-turbo
Append: [HeteroScale：解决LLM服务中P/D解耦架构的高效自动扩展框架](https://arxiv.org/abs/2508.19559)
Token length: 1370
Summarized using qwen-turbo
Append: [基于TAPO与MotionFLUX的高效动作生成系统](https://arxiv.org/abs/2508.19527)
Token length: 1368
Summarized using qwen-turbo
Append: [基于多模态控制的实时数字人视频生成框架](https://arxiv.org/abs/2508.19320)
Token length: 1093
Summarized using qwen-turbo
Append: [提升语音识别系统可解释性的方法研究](https://arxiv.org/abs/2508.15882)
append_entries: 6
Finish: 2025-08-28 12:29:25.426871
------------------------------------------------------
Started: 2025-08-28 18:20:27.328004
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1051
Summarized using qwen-turbo
Append: [大规模多视角rPPG与健康指标数据集的构建与应用](https://arxiv.org/abs/2508.17924)
append_entries: 1
Finish: 2025-08-28 18:20:31.654418
------------------------------------------------------
Started: 2025-08-29 01:06:39.437080
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 493
Summarized using qwen-turbo
Append: [链式思维在软推理任务中的有效性与忠实性研究](https://arxiv.org/abs/2508.19827)
Token length: 1197
Summarized using qwen-turbo
Append: [SEAM基准测试评估视觉语言模型的跨模态一致性](https://arxiv.org/abs/2508.18179)
append_entries: 2
Finish: 2025-08-29 01:06:48.112686
------------------------------------------------------
Started: 2025-08-29 06:21:15.009822
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 908
Summarized using qwen-turbo
Append: [Dress&Dance：基于视频扩散的高质量虚拟试穿框架](https://arxiv.org/abs/2508.21070)
Token length: 1078
Summarized using qwen-turbo
Append: [OnGoal：提升用户在LLM对话中目标管理的界面设计](https://arxiv.org/abs/2508.21061)
Token length: 1159
Summarized using qwen-turbo
Append: [基于稀疏注意力路由的长视频生成方法](https://arxiv.org/abs/2508.21058)
Token length: 1172
Summarized using qwen-turbo
Append: [FakeParts：针对局部深度伪造视频的检测挑战与基准数据集](https://arxiv.org/abs/2508.21052)
Token length: 1594
Summarized using qwen-turbo
Append: [CogVLA：一种高效多模态视觉-语言-动作框架](https://arxiv.org/abs/2508.21046)
Token length: 993
Summarized using qwen-turbo
Append: [工具增强语言模型在事实回忆中的优势](https://arxiv.org/abs/2508.20755)
Token length: 1541
Summarized using qwen-turbo
Append: [基于偏好奖励的GRPO方法与统一文本到图像基准研究](https://arxiv.org/abs/2508.20751)
Token length: 1594
Summarized using qwen-turbo
Append: [rStar2-Agent：基于代理强化学习的14B数学推理模型](https://arxiv.org/abs/2508.20722)
Token length: 1354
Summarized using qwen-turbo
Append: [MCP-Bench：评估大型语言模型多步骤任务能力的基准](https://arxiv.org/abs/2508.20453)
Token length: 1062
Summarized using qwen-turbo
Append: [AWorld系统提升Agentic AI训练效率与性能](https://arxiv.org/abs/2508.20404)
Token length: 1620
Summarized using qwen-turbo
Append: [任务导向的指令增强方法提升大语言模型的实际应用性能](https://arxiv.org/abs/2508.20374)
Token length: 1383
Summarized using qwen-turbo
Append: [统一风格与主题生成框架USO的提出与实验验证](https://arxiv.org/abs/2508.18966)
Token length: 1719
Summarized using qwen-turbo
Append: [ROSE：一种针对视频中物体及其副作用的去除框架](https://arxiv.org/abs/2508.18633)
Token length: 1701
Summarized using qwen-turbo
Append: [TriMM：首个基于多模态的3D生成模型](https://arxiv.org/abs/2508.15228)
append_entries: 14
Finish: 2025-08-29 06:22:02.438365
------------------------------------------------------
Started: 2025-08-29 12:28:31.700764
Existing_entries: 1014
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1369
Summarized using qwen-turbo
Append: [多视角3D点追踪技术的创新与应用](https://arxiv.org/abs/2508.21060)
Token length: 1297
Summarized using qwen-turbo
Append: [通过ROSI方法提升大语言模型的安全对齐](https://arxiv.org/abs/2508.20766)
append_entries: 2
Finish: 2025-08-29 12:28:38.688755
------------------------------------------------------
Started: 2025-08-29 18:19:39.062738
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1529
Summarized using qwen-turbo
Append: [OneReward：基于单一奖励模型的多任务生成框架](https://arxiv.org/abs/2508.21066)
Token length: 1076
Summarized using qwen-turbo
Append: [基于多模态预训练的社交行为感知模型Social-MAE](https://arxiv.org/abs/2508.17502)
Token length: 1219
Summarized using qwen-turbo
Append: [提升大语言模型在说服对话中的可信度评估与训练方法](https://arxiv.org/abs/2508.17450)
append_entries: 3
Finish: 2025-08-29 18:19:49.325910
------------------------------------------------------
Started: 2025-08-30 01:03:31.219089
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-30 01:03:31.421057
------------------------------------------------------
Started: 2025-08-30 06:18:44.849718
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-30 06:18:45.038942
------------------------------------------------------
Started: 2025-08-30 12:25:49.210809
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-30 12:25:49.395452
------------------------------------------------------
Started: 2025-08-30 18:17:43.236459
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-30 18:17:43.481411
------------------------------------------------------
Started: 2025-08-31 01:11:26.046857
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-31 01:11:26.302846
------------------------------------------------------
Started: 2025-08-31 06:19:34.113481
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-31 06:19:34.395157
------------------------------------------------------
Started: 2025-08-31 12:26:14.440866
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-31 12:26:14.689313
------------------------------------------------------
Started: 2025-08-31 18:18:06.766638
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-08-31 18:18:07.915905
------------------------------------------------------
Started: 2025-09-01 01:18:02.857216
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-09-01 01:18:03.204994
------------------------------------------------------
Started: 2025-09-01 06:24:01.186870
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1917
Summarized using qwen-turbo
Append: [UItron：面向GUI自动化的开源基础模型](https://arxiv.org/abs/2508.21767)
Token length: 1293
Summarized using qwen-turbo
Append: [Morae：提升盲人和低视力用户UI交互体验的混合决策代理](https://arxiv.org/abs/2508.21456)
Token length: 1300
Summarized using qwen-turbo
Append: [R-4B：一种自适应思考的多模态大语言模型](https://arxiv.org/abs/2508.21113)
Token length: 1695
Summarized using qwen-turbo
Append: [EO-Robotics：多模态具身推理与机器人控制的新模型与数据集](https://arxiv.org/abs/2508.21112)
Token length: 1244
Summarized using qwen-turbo
Append: [AI代码生成安全评估基准A.S.E的提出与实验分析](https://arxiv.org/abs/2508.18106)
Token length: 1373
Summarized using qwen-turbo
Append: [TalkVid：解决语音驱动人脸合成多样性不足的新数据集](https://arxiv.org/abs/2508.13618)
append_entries: 6
Finish: 2025-09-01 06:24:24.095033
------------------------------------------------------
Started: 2025-09-01 12:29:44.682230
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1908
Summarized using qwen-turbo
Append: [AHELM：首个全面评估音频语言模型的基准测试](https://arxiv.org/abs/2508.21376)
Token length: 1625
Summarized using qwen-turbo
Append: [Think in Games：通过游戏环境提升大语言模型的程序性知识](https://arxiv.org/abs/2508.21365)
Token length: 554
Summarized using qwen-turbo
Append: [Jina Code Embeddings：跨语言代码检索与语义相似性识别](https://arxiv.org/abs/2508.21290)
Token length: 1614
Summarized using qwen-turbo
Append: [视频数据在3D生成中的应用与探索](https://arxiv.org/abs/2508.20470)
Token length: 1577
Summarized using qwen-turbo
Append: [HERMES：基于人类运动数据的移动双臂灵巧操作框架](https://arxiv.org/abs/2508.20085)
Token length: 1505
Summarized using qwen-turbo
Append: [动态调整数据混合策略提升语言模型性能](https://arxiv.org/abs/2508.17677)
Token length: 1164
Summarized using qwen-turbo
Append: [基于CLIP的对称性检测方法CLIPSym](https://arxiv.org/abs/2508.14197)
append_entries: 7
Finish: 2025-09-01 12:30:09.756282
------------------------------------------------------
Started: 2025-09-01 18:19:32.483960
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1457
Summarized using qwen-turbo
Append: [强化学习在大语言模型中的新发现与挑战](https://arxiv.org/abs/2508.21188)
Token length: 1034
Summarized using qwen-turbo
Append: [基于时间残差连接的深度非训练循环神经网络研究](https://arxiv.org/abs/2508.21172)
Token length: 1798
Summarized using qwen-turbo
Append: [科学大语言模型的发展与数据驱动的未来](https://arxiv.org/abs/2508.21148)
Token length: 1676
Summarized using qwen-turbo
Append: [Post-training Quantization对YOLO模型在不同精度下的鲁棒性评估](https://arxiv.org/abs/2508.19600)
Token length: 1714
Summarized using qwen-turbo
Append: [基于多模态的物理定律自动发现模型VIPER-R1](https://arxiv.org/abs/2508.17380)
Token length: 1799
Summarized using qwen-turbo
Append: [EduRABSA：首个教育评论的公开ABSA数据集](https://arxiv.org/abs/2508.17008)
append_entries: 6
Finish: 2025-09-01 18:19:52.141991
------------------------------------------------------
Started: 2025-09-02 01:07:53.931007
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-09-02 01:07:54.165609
------------------------------------------------------
Started: 2025-09-02 06:22:25.394791
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1222
Summarized using qwen-turbo
Append: [PVPO：基于优势参考锚点的高效强化学习方法](https://arxiv.org/abs/2508.21104)
Token length: 1575
Summarized using qwen-turbo
Append: [SuperSimpleNet：一种高效且适应性强的表面缺陷检测模型](https://arxiv.org/abs/2508.19060)
append_entries: 2
Finish: 2025-09-02 06:22:32.374177
------------------------------------------------------
Started: 2025-09-02 12:29:30.506740
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1203
Summarized using qwen-turbo
Append: [基于输入重构的多智能体框架提升语言模型推理能力](https://arxiv.org/abs/2508.20931)
Token length: 1211
Summarized using qwen-turbo
Append: [表到报告任务与T2R-bench基准构建](https://arxiv.org/abs/2508.19813)
Token length: 1500
Summarized using qwen-turbo
Append: [ALLaM-34B阿拉伯语大模型性能评估与应用分析](https://arxiv.org/abs/2508.17378)
Token length: 1269
Summarized using qwen-turbo
Append: [基于生物启发的空间认知框架提升智能体导航能力](https://arxiv.org/abs/2508.17198)
append_entries: 4
Finish: 2025-09-02 12:29:45.275047
------------------------------------------------------
Started: 2025-09-02 18:18:08.917555
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-09-02 18:18:09.390117
------------------------------------------------------
Started: 2025-09-03 01:03:29.310932
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1340
Summarized using qwen-turbo
Append: [AI代理社会的制度设计与权力平衡模拟研究](https://arxiv.org/abs/2508.19562)
append_entries: 1
Finish: 2025-09-03 01:03:33.500072
------------------------------------------------------
Started: 2025-09-03 06:20:36.673388
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1387
Summarized using qwen-turbo
Append: [代理强化学习：从被动生成到自主决策的范式转变](https://arxiv.org/abs/2509.02547)
Token length: 1771
Summarized using qwen-turbo
Append: [UI-TARS-2：提升GUI代理性能的系统性方法](https://arxiv.org/abs/2509.02544)
Token length: 1467
Summarized using qwen-turbo
Append: [DARLING：提升大语言模型多样性与质量的强化学习框架](https://arxiv.org/abs/2509.02534)
Token length: 1628
Summarized using qwen-turbo
Append: [PACS：一种基于监督学习的强化学习框架提升大语言模型推理能力](https://arxiv.org/abs/2509.02522)
Token length: 1497
Summarized using qwen-turbo
Append: [SimpleTIR：提升多轮工具集成推理的稳定性方法](https://arxiv.org/abs/2509.02479)
Token length: 1328
Summarized using qwen-turbo
Append: [MedDINOv3：基于视觉基础模型的医学影像分割方法](https://arxiv.org/abs/2509.02379)
Token length: 1211
Summarized using qwen-turbo
Append: [基于遗传算法的合成数据生成框架Genetic Prompt](https://arxiv.org/abs/2509.02040)
Token length: 1163
Summarized using qwen-turbo
Append: [基于VAR的文本引导图像编辑方法VARIN研究](https://arxiv.org/abs/2509.01984)
Token length: 1219
Summarized using qwen-turbo
Append: [OpenVision 2：简化架构提升训练效率](https://arxiv.org/abs/2509.01644)
Token length: 1138
Summarized using qwen-turbo
Append: [基于同侪学习的大型视觉语言模型对齐方法](https://arxiv.org/abs/2509.01610)
Token length: 1713
Summarized using qwen-turbo
Append: [Keye-VL-1.5：提升视频理解能力的多模态大模型创新](https://arxiv.org/abs/2509.01563)
Token length: 1585
Summarized using qwen-turbo
Append: [多模态医学图像检索模型M3Ret的构建与应用](https://arxiv.org/abs/2509.01360)
Token length: 1478
Summarized using qwen-turbo
Append: [基于双视角的点云自监督学习方法Point-PQAE](https://arxiv.org/abs/2509.01250)
Token length: 1637
Summarized using qwen-turbo
Append: [无需蒸馏的自动化文档提取框架](https://arxiv.org/abs/2509.01215)
Token length: 1603
Summarized using qwen-turbo
Append: [基于批评模型的多模态生成与评估统一系统](https://arxiv.org/abs/2509.00676)
Token length: 723
Summarized using qwen-turbo
Append: [通用深度研究系统UDR的提出与应用](https://arxiv.org/abs/2509.00244)
append_entries: 16
Finish: 2025-09-03 06:21:38.989939
------------------------------------------------------
Started: 2025-09-03 12:28:31.923952
Existing_entries: 1016
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1640
Summarized using qwen-turbo
Append: [基于生成模型的视频合成技术研究](https://arxiv.org/abs/2509.02460)
Token length: 1608
Summarized using qwen-turbo
Append: [动态验证框架提升医疗大模型临床实用性](https://arxiv.org/abs/2509.02208)
Token length: 1752
Summarized using qwen-turbo
Append: [基于印度宪法的LLM公平性增强框架AMBEDKAR](https://arxiv.org/abs/2509.02133)
Token length: 1616
Summarized using qwen-turbo
Append: [优化器比较研究：AdamW与替代方案的公平评估](https://arxiv.org/abs/2509.02046)
Token length: 1485
Summarized using qwen-turbo
Append: [通过任务向量迁移模型推理能力](https://arxiv.org/abs/2509.01363)
Token length: 1869
Summarized using qwen-turbo
Append: [VerlTool：统一的强化学习工具框架提升多轮交互性能](https://arxiv.org/abs/2509.01055)
Token length: 1087
Summarized using qwen-turbo
Append: [基于LLM的GUI代理在冒险游戏中的表现与改进研究](https://arxiv.org/abs/2509.01052)
Token length: 832
Summarized using qwen-turbo
Append: [基于思维链和上下文学习的文本到SQL框架研究](https://arxiv.org/abs/2509.00581)
Token length: 1107
Summarized using qwen-turbo
Append: [基于上下文感知融合的细粒度目标检测方法研究](https://arxiv.org/abs/2509.00578)
Token length: 1279
Summarized using qwen-turbo
Append: [Metis框架提升低比特量化大语言模型训练性能](https://arxiv.org/abs/2509.00404)
append_entries: 10
Finish: 2025-09-03 12:29:09.609035
------------------------------------------------------
Started: 2025-09-03 18:19:44.119685
Existing_entries: 1010
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1783
Summarized using qwen-turbo
Append: [动态剪切策略提升大语言模型强化学习性能](https://arxiv.org/abs/2509.02333)
Token length: 961
Summarized using qwen-turbo
Append: [ViSTA-SLAM：无需相机内参的实时单目SLAM系统](https://arxiv.org/abs/2509.01584)
Token length: 1000
Summarized using qwen-turbo
Append: [大规模语言模型优化方法的系统评估](https://arxiv.org/abs/2509.01440)
Token length: 946
Summarized using qwen-turbo
Append: [MobiAgent：提升移动代理系统性能的综合方案](https://arxiv.org/abs/2509.00531)
Token length: 1772
Summarized using qwen-turbo
Append: [Camlang测试揭示大型语言模型在元语言推理上的局限性](https://arxiv.org/abs/2509.00425)
Token length: 1839
Summarized using qwen-turbo
Append: [长视频中的语义聚合幻觉研究与ELV-Halluc基准构建](https://arxiv.org/abs/2508.21496)
Token length: 1531
Summarized using qwen-turbo
Append: [FastFit：一种高效多参考虚拟试穿框架](https://arxiv.org/abs/2508.20586)
append_entries: 7
Finish: 2025-09-03 18:20:05.859831
------------------------------------------------------
Started: 2025-09-04 01:03:19.664497
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 810
Summarized using qwen-turbo
Append: [动态守护模型提升聊天机器人内容监管效率](https://arxiv.org/abs/2509.02563)
Token length: 1049
Summarized using qwen-turbo
Append: [小型自动语音识别模型在低资源语言中的应用](https://arxiv.org/abs/2509.02523)
Token length: 1274
Summarized using qwen-turbo
Append: [重新评估大语言模型的提示敏感性问题](https://arxiv.org/abs/2509.01790)
Token length: 1414
Summarized using qwen-turbo
Append: [Gated Associative Memory：一种高效的序列建模架构](https://arxiv.org/abs/2509.00605)
Token length: 983
Summarized using qwen-turbo
Append: [推荐系统中群体公平与个体公平的关系研究](https://arxiv.org/abs/2508.21334)
Token length: 1431
Summarized using qwen-turbo
Append: [向量嵌入在现实任务中的理论限制](https://arxiv.org/abs/2508.21038)
append_entries: 6
Finish: 2025-09-04 01:03:37.854673
------------------------------------------------------
Started: 2025-09-04 06:21:22.202931
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1541
Summarized using qwen-turbo
Append: [Robix：一种集成机器人推理与自然语言交互的统一模型](https://arxiv.org/abs/2509.01106)
Token length: 1836
Summarized using qwen-turbo
Append: [InfoSeek：构建复杂深度研究任务的框架](https://arxiv.org/abs/2509.00375)
append_entries: 2
Finish: 2025-09-04 06:21:30.089823
------------------------------------------------------
Started: 2025-09-04 12:28:48.369918
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1451
Summarized using qwen-turbo
Append: [LMEnt：用于研究语言模型知识获取的工具套件](https://arxiv.org/abs/2509.03405)
Token length: 1714
Summarized using qwen-turbo
Append: [MOSAIC：多主体图像生成的语义对齐与特征解耦方法](https://arxiv.org/abs/2509.01977)
Token length: 1231
Summarized using qwen-turbo
Append: [Face-MoGLE：一种可控制的人脸生成框架](https://arxiv.org/abs/2509.00428)
append_entries: 3
Finish: 2025-09-04 12:29:08.756730
------------------------------------------------------
Started: 2025-09-04 18:19:31.856716
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1334
Summarized using qwen-turbo
Append: [视觉语言世界模型提升智能规划性能](https://arxiv.org/abs/2509.02722)
append_entries: 1
Finish: 2025-09-04 18:19:35.466385
------------------------------------------------------
Started: 2025-09-05 01:05:15.193592
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1602
Summarized using qwen-turbo
Append: [利用深度相机提升机器人操作的泛化能力](https://arxiv.org/abs/2509.02530)
Token length: 1651
Summarized using qwen-turbo
Append: [SATQuest：一种用于评估和提升大语言模型逻辑推理能力的系统验证工具](https://arxiv.org/abs/2509.00930)
append_entries: 2
Finish: 2025-09-05 01:05:22.164342
------------------------------------------------------
Started: 2025-09-05 06:21:22.773035
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1433
Summarized using qwen-turbo
Append: [统一策略梯度与混合后训练方法的理论与实践](https://arxiv.org/abs/2509.04419)
Token length: 1285
Summarized using qwen-turbo
Append: [探究基于探测的LLM安全检测方法的局限性](https://arxiv.org/abs/2509.03888)
Token length: 1416
Summarized using qwen-turbo
Append: [DeepResearch Arena：构建高质量研究任务的基准平台](https://arxiv.org/abs/2509.01396)
Token length: 1511
Summarized using qwen-turbo
Append: [从二维工程图生成参数化CAD模型的框架研究](https://arxiv.org/abs/2508.18733)
append_entries: 4
Finish: 2025-09-05 06:21:37.864870
------------------------------------------------------
Started: 2025-09-05 12:27:48.752095
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1068
Summarized using qwen-turbo
Append: [Delta Activations：一种用于微调模型表示的新方法](https://arxiv.org/abs/2509.04442)
Token length: 1473
Summarized using qwen-turbo
Append: [Durian：基于零样本面部属性迁移的肖像动画生成方法](https://arxiv.org/abs/2509.04434)
Token length: 1670
Summarized using qwen-turbo
Append: [基于流的3D生成模型少步蒸馏方法研究](https://arxiv.org/abs/2509.04406)
Token length: 1271
Summarized using qwen-turbo
Append: [基于连续时间动力学的高效生成模型TiM](https://arxiv.org/abs/2509.04394)
Token length: 1789
Summarized using qwen-turbo
Append: [基于图像编辑模型的密集几何预测框架FE2E](https://arxiv.org/abs/2509.04338)
Token length: 1364
Summarized using qwen-turbo
Append: [评估大语言模型对抗性指令遵循能力的基准测试](https://arxiv.org/abs/2509.04292)
Token length: 1386
Summarized using qwen-turbo
Append: [NER Retriever：一种无需预定义类型的实体检索框架](https://arxiv.org/abs/2509.04011)
Token length: 1662
Summarized using qwen-turbo
Append: [Drivelology：语言中的无意义与深度](https://arxiv.org/abs/2509.03867)
append_entries: 8
Finish: 2025-09-05 12:28:16.274222
------------------------------------------------------
Started: 2025-09-05 18:18:41.728004
Existing_entries: 1008
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1434
Summarized using qwen-turbo
Append: [Video-MTR：基于多轮推理的长视频理解框架](https://arxiv.org/abs/2508.20478)
append_entries: 1
Finish: 2025-09-05 18:18:45.476036
------------------------------------------------------
Started: 2025-09-06 01:03:39.907943
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1663
Summarized using qwen-turbo
Append: [Loong项目：基于可验证奖励的大型语言模型推理提升框架](https://arxiv.org/abs/2509.03059)
append_entries: 1
Finish: 2025-09-06 01:03:44.083863
------------------------------------------------------
Started: 2025-09-06 06:18:21.782590
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-09-06 06:18:22.036782
------------------------------------------------------
Started: 2025-09-06 12:24:37.225201
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-09-06 12:24:37.467880
------------------------------------------------------
Started: 2025-09-06 18:17:01.290606
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-09-06 18:17:01.583403
------------------------------------------------------
Started: 2025-09-07 01:10:26.417299
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-09-07 01:10:26.601491
------------------------------------------------------
Started: 2025-09-07 06:18:34.907271
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-09-07 06:18:35.253527
------------------------------------------------------
Started: 2025-09-07 12:25:05.195512
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-09-07 12:25:05.451349
------------------------------------------------------
Started: 2025-09-07 18:17:19.589575
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-09-07 18:17:19.818139
------------------------------------------------------
Started: 2025-09-08 01:09:08.255786
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-09-08 01:09:24.089604
------------------------------------------------------
Started: 2025-09-08 06:22:55.532413
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1735
Summarized using qwen-turbo
Append: [LatticeWorld：基于轻量级大模型的高效3D世界生成框架](https://arxiv.org/abs/2509.05263)
Token length: 1245
Summarized using qwen-turbo
Append: [WildScore：首个多模态符号音乐推理与分析基准](https://arxiv.org/abs/2509.04744)
Token length: 1272
Summarized using qwen-turbo
Append: [语言模型的幻觉问题及其成因分析](https://arxiv.org/abs/2509.04664)
Token length: 1442
Summarized using qwen-turbo
Append: [MedVista3D：解决3D影像诊断误差的多尺度语义增强框架](https://arxiv.org/abs/2509.03800)
Token length: 1341
Summarized using qwen-turbo
Append: [基于行为指纹的大型语言模型评估框架研究](https://arxiv.org/abs/2509.04504)
append_entries: 5
Finish: 2025-09-08 06:23:23.875343
------------------------------------------------------
Started: 2025-09-08 12:30:30.494939
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 944
Summarized using qwen-turbo
Append: [WinT3R：一种高效的在线相机位姿与点云重建模型](https://arxiv.org/abs/2509.05296)
Token length: 1719
Summarized using qwen-turbo
Append: [提升大语言模型生成符号图形程序的能力](https://arxiv.org/abs/2509.05208)
Token length: 1426
Summarized using qwen-turbo
Append: [基于自迭代的强化学习方法ExIt提升模型推理时的自我优化能力](https://arxiv.org/abs/2509.04575)
Token length: 1522
Summarized using qwen-turbo
Append: [评估大语言模型对改写问题的鲁棒性](https://arxiv.org/abs/2509.04013)
Token length: 1244
Summarized using qwen-turbo
Append: [基于视频扩散Transformer的HDR环境光照估计方法](https://arxiv.org/abs/2509.03680)
Token length: 1282
Summarized using qwen-turbo
Append: [U-Arm：低成本且可快速适配的遥操作框架](https://arxiv.org/abs/2509.02437)
append_entries: 6
Finish: 2025-09-08 12:30:49.969169
------------------------------------------------------
Started: 2025-09-08 18:20:46.839347
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1161
Summarized using qwen-turbo
Append: [Set Block Decoding：提升语言模型生成效率的新方法](https://arxiv.org/abs/2509.04185)
append_entries: 1
Finish: 2025-09-08 18:20:50.749512
------------------------------------------------------
Started: 2025-09-09 01:06:16.934325
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-09-09 01:06:18.026430
------------------------------------------------------
Started: 2025-09-09 06:22:07.559641
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1549
Summarized using qwen-turbo
Append: [基于轨迹感知的强化学习框架提升扩散语言模型性能](https://arxiv.org/abs/2509.06949)
Token length: 1194
Summarized using qwen-turbo
Append: [基于共演化机制的AI安全框架研究](https://arxiv.org/abs/2509.06786)
Token length: 1861
Summarized using qwen-turbo
Append: [深度研究系统中的强化学习基础综述](https://arxiv.org/abs/2509.06733)
Token length: 1414
Summarized using qwen-turbo
Append: [UniVerse-1：一种统一的音频视频生成模型](https://arxiv.org/abs/2509.06155)
Token length: 1330
Summarized using qwen-turbo
Append: [Llama-GENBA-10B：多语言基础模型应对英语中心偏见](https://arxiv.org/abs/2509.05668)
Token length: 1343
Summarized using qwen-turbo
Append: [基于强化学习的多模态大模型视觉推理方法研究](https://arxiv.org/abs/2509.01656)
append_entries: 6
Finish: 2025-09-09 06:22:31.219106
------------------------------------------------------
Started: 2025-09-09 12:30:43.570672
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1837
Summarized using qwen-turbo
Append: [Interleaving Reasoning Generation提升文本到图像生成质量](https://arxiv.org/abs/2509.06945)
Token length: 1637
Summarized using qwen-turbo
Append: [Paper2Agent：将研究论文转化为AI代理的自动化框架](https://arxiv.org/abs/2509.06917)
Token length: 1265
Summarized using qwen-turbo
Append: [测试时缩放在知识密集型任务中的局限性](https://arxiv.org/abs/2509.06861)
Token length: 1259
Summarized using qwen-turbo
Append: [基于自动定理证明的高质量逻辑数据生成方法](https://arxiv.org/abs/2509.06809)
Token length: 1574
Summarized using qwen-turbo
Append: [基于多模态推理的黑暗幽默检测方法研究](https://arxiv.org/abs/2509.06771)
Token length: 1697
Summarized using qwen-turbo
Append: [WebExplorer：构建高效长周期网络搜索代理的系统方法](https://arxiv.org/abs/2509.06501)
Token length: 1690
Summarized using qwen-turbo
Append: [BFS-Prover-V2：解决大型语言模型在自动定理证明中的扩展挑战](https://arxiv.org/abs/2509.06493)
Token length: 1407
Summarized using qwen-turbo
Append: [GUI与快捷方式混合代理的基准评估研究](https://arxiv.org/abs/2509.06477)
Token length: 1847
Summarized using qwen-turbo
Append: [DINOv3在医学影像任务中的表现与局限性研究](https://arxiv.org/abs/2509.06467)
Token length: 1466
Summarized using qwen-turbo
Append: [基于对比注意力机制的视觉增强方法研究](https://arxiv.org/abs/2509.06461)
Token length: 1285
Summarized using qwen-turbo
Append: [REER：一种基于逆向推理的开放性生成方法](https://arxiv.org/abs/2509.06160)
Token length: 1868
Summarized using qwen-turbo
Append: [T2I-CoReBench：评估文本到图像生成模型的综合基准](https://arxiv.org/abs/2509.03516)
append_entries: 12
Finish: 2025-09-09 12:31:24.102220
------------------------------------------------------
Started: 2025-09-09 18:17:38.544545
Existing_entries: 1012
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 962
Summarized using qwen-turbo
Append: [ guided decoding 在 RAG 系统中的应用与比较研究](https://arxiv.org/abs/2509.06631)
Token length: 1871
Summarized using qwen-turbo
Append: [基于DCReg的点云配准优化方法研究](https://arxiv.org/abs/2509.06285)
Token length: 1260
Summarized using qwen-turbo
Append: [Inpaint4Drag：基于像素空间的实时拖拽图像编辑框架](https://arxiv.org/abs/2509.04582)
append_entries: 3
Finish: 2025-09-09 18:17:48.614903
------------------------------------------------------
Started: 2025-09-10 01:04:28.956980
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "基于持续强化学习的自主单智能体深度研究模型开发",
  "short_summary": "提升LLM自主推理与工具使用能力，用于深度研究。",
  "summary": "本文聚焦于开发具备自主推理和工具集成能力的单智能体模型，以支持深度研究任务。不同于多智能体系统，该模型能根据上下文动态决定下一步行动。研究采用持续强化学习方法，在不损害推理能力的前提下提升智能体技能。通过使用全合成数据的简单强化学习方案，应用于多个开源大语言模型，其中最佳版本SFR-DR-20B在Humanity"s Last Exam基准测试中达到28.7%的准确率。同时，文章还进行了关键实验分析，进一步验证了方法的有效性。",
  "keyword": "大语言模型, 自主推理, 强化学习"
}Summarization failed, append the original article
error: Expecting ',' delimiter: line 4 column 173 (char 259). Line: 406.
Append: [SFR-DeepResearch: Towards Effective Reinforcement Learning for Autonomously Reasoning Single Agents](https://arxiv.org/abs/2509.06283)
Token length: 1517
Summarized using qwen-turbo
Append: [CLIP-SVD：一种高效的多模态模型微调方法](https://arxiv.org/abs/2509.03740)
Token length: 731
Summarized using qwen-turbo
Append: [基于任务算术的多任务学习模型融合方法](https://arxiv.org/abs/2509.02108)
Token length: 1526
Summarized using qwen-turbo
Append: [基于内部表示的视觉-语言-动作模型可解释与控制方法](https://arxiv.org/abs/2509.00328)
append_entries: 4
Finish: 2025-09-10 01:04:45.921070
------------------------------------------------------
Started: 2025-09-10 06:21:12.029407
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1740
Summarized using qwen-turbo
Append: [基于强化学习的并行思维框架提升大语言模型推理能力](https://arxiv.org/abs/2509.07980)
Token length: 1296
Summarized using qwen-turbo
Append: [VIRAL：提升多模态大模型视觉推理能力的对齐策略](https://arxiv.org/abs/2509.07979)
Token length: 1667
Summarized using qwen-turbo
Append: [Mini-o3：提升视觉搜索任务的多轮推理系统](https://arxiv.org/abs/2509.07969)
Token length: 972
Summarized using qwen-turbo
Append: [SimpleQA Verified：提升大语言模型事实性评估的基准测试](https://arxiv.org/abs/2509.07968)
Token length: 915
Summarized using qwen-turbo
Append: [基于自博弈的大型语言模型强化学习方法](https://arxiv.org/abs/2509.07414)
Token length: 880
Summarized using qwen-turbo
Append: [CASTLE：一种改进的因果注意力机制](https://arxiv.org/abs/2509.07301)
Token length: 1388
Summarized using qwen-turbo
Append: [Reconstruction Alignment提升统一多模态模型的生成性能](https://arxiv.org/abs/2509.07295)
Token length: 1482
Summarized using qwen-turbo
Append: [F1：一种融合视觉预见的视觉-语言-动作框架](https://arxiv.org/abs/2509.06951)
Token length: 1741
Summarized using qwen-turbo
Append: [动态调整难度的强化学习框架提升大语言模型推理能力](https://arxiv.org/abs/2509.06923)
Token length: 1383
Summarized using qwen-turbo
Append: [UMO框架提升多身份图像定制的一致性与可扩展性](https://arxiv.org/abs/2509.06818)
append_entries: 10
Finish: 2025-09-10 06:21:52.640108
------------------------------------------------------
Started: 2025-09-10 12:28:10.992593
Existing_entries: 1010
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1217
Summarized using qwen-turbo
Append: [Delta L Normalization：提升RLVR中动态生成长度的损失聚合方法](https://arxiv.org/abs/2509.07558)
Token length: 1119
Summarized using qwen-turbo
Append: [Curia：基于大规模医学影像数据的放射学基础模型](https://arxiv.org/abs/2509.06830)
Token length: 1631
Summarized using qwen-turbo
Append: [Q-Sched：通过调整扩散模型调度器实现高效量化生成](https://arxiv.org/abs/2509.01624)
append_entries: 3
Finish: 2025-09-10 12:28:21.578631
------------------------------------------------------
Started: 2025-09-10 18:20:02.750647
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1857
Summarized using qwen-turbo
Append: [复杂检索任务评估与大语言模型影响研究](https://arxiv.org/abs/2509.07253)
Token length: 1353
Summarized using qwen-turbo
Append: [基于直接对齐和语义相对偏好优化的扩散模型改进方法](https://arxiv.org/abs/2509.06942)
Token length: 1424
Summarized using qwen-turbo
Append: [基于强化学习的大型语言模型推理机制研究](https://arxiv.org/abs/2509.03646)
append_entries: 3
Finish: 2025-09-10 18:20:13.566641
------------------------------------------------------
Started: 2025-09-11 01:05:45.350267
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1647
Summarized using qwen-turbo
Append: [Transformer模型幻觉机制及其对AI安全的影响](https://arxiv.org/abs/2509.06938)
append_entries: 1
Finish: 2025-09-11 01:05:48.597631
------------------------------------------------------
Started: 2025-09-11 06:21:45.760859
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1228
Summarized using qwen-turbo
Append: [强化学习在大语言模型推理中的应用与挑战](https://arxiv.org/abs/2509.08827)
Token length: 1809
Summarized using qwen-turbo
Append: [RewardDance：一种可扩展的视觉生成奖励建模框架](https://arxiv.org/abs/2509.08826)
Token length: 1757
Summarized using qwen-turbo
Append: [AgentGym-RL：一种用于训练智能代理的强化学习框架](https://arxiv.org/abs/2509.08755)
Token length: 1451
Summarized using qwen-turbo
Append: [人工智能与人类自主性的关系研究](https://arxiv.org/abs/2509.08494)
Token length: 1858
Summarized using qwen-turbo
Append: [EnvX：通过智能代理提升开源代码库的自动化利用](https://arxiv.org/abs/2509.08088)
Token length: 1077
Summarized using qwen-turbo
Append: [基于P3-SAM的3D点提示部件分割方法研究](https://arxiv.org/abs/2509.06784)
Token length: 1825
Summarized using qwen-turbo
Append: [多语言翻译模型Hunyuan-MT-7B及其改进版本Hunyuan-MT-Chimera-7B的发布](https://arxiv.org/abs/2509.05209)
Token length: 1278
Summarized using qwen-turbo
Append: [3D与4D世界建模的全面综述](https://arxiv.org/abs/2509.07996)
append_entries: 8
Finish: 2025-09-11 06:22:13.964806
------------------------------------------------------
Started: 2025-09-11 12:27:49.575555
Existing_entries: 1008
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-09-11 12:27:49.833165
------------------------------------------------------
Started: 2025-09-11 18:17:28.083765
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1103
Summarized using qwen-turbo
Append: [LLM生成的有毒数据在文本净化任务中的局限性研究](https://arxiv.org/abs/2509.08358)
Token length: 1190
Summarized using qwen-turbo
Append: [通过学习聚合提升大语言模型的推理能力](https://arxiv.org/abs/2509.06870)
append_entries: 2
Finish: 2025-09-11 18:17:34.925115
------------------------------------------------------
Started: 2025-09-12 01:02:58.882874
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 837
Summarized using qwen-turbo
Append: [统计方法在生成式人工智能中的应用与展望](https://arxiv.org/abs/2509.07054)
append_entries: 1
Finish: 2025-09-12 01:03:01.497277
------------------------------------------------------
Started: 2025-09-12 06:21:12.714827
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1595
Summarized using qwen-turbo
Append: [FLUX-Reason-6M与PRISM-Bench推动开放源代码文本到图像生成模型发展](https://arxiv.org/abs/2509.09680)
Token length: 1318
Summarized using qwen-turbo
Append: [SpatialVID：大规模动态视频数据集推动空间智能发展](https://arxiv.org/abs/2509.09676)
Token length: 1505
Summarized using qwen-turbo
Append: [基于强化学习的视觉-语言-动作模型优化研究](https://arxiv.org/abs/2509.09674)
Token length: 1894
Summarized using qwen-turbo
Append: [LoCoBench：评估长上下文语言模型在软件开发中的基准测试](https://arxiv.org/abs/2509.09614)
Token length: 1882
Summarized using qwen-turbo
Append: [Kling-Avatar：基于多模态指令的高保真语音驱动虚拟人生成框架](https://arxiv.org/abs/2509.09595)
Token length: 1787
Summarized using qwen-turbo
Append: [OmniEVA：提升多模态大语言模型在具身智能中的适应性与规划能力](https://arxiv.org/abs/2509.09332)
Token length: 1764
Summarized using qwen-turbo
Append: [基于代码思维的图表理解方法提升视觉语言模型推理能力](https://arxiv.org/abs/2509.09286)
Token length: 1461
Summarized using qwen-turbo
Append: [基于熵调节的策略梯度方法提升长期任务性能](https://arxiv.org/abs/2509.09265)
Token length: 898
Summarized using qwen-turbo
Append: [EchoX：提升语音大语言模型知识与推理能力的新方法](https://arxiv.org/abs/2509.09174)
Token length: 1416
Summarized using qwen-turbo
Append: [基于CLIP的行人表征学习改进方法研究](https://arxiv.org/abs/2509.09118)
Token length: 1807
Summarized using qwen-turbo
Append: [通过Divergence项提升RLVR中的模型多样性与性能](https://arxiv.org/abs/2509.07430)
append_entries: 11
Finish: 2025-09-12 06:21:52.682439
------------------------------------------------------
Started: 2025-09-12 12:27:31.250705
Existing_entries: 1011
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1682
Summarized using qwen-turbo
Append: [基于自编码器框架的统一多模态学习方法研究](https://arxiv.org/abs/2509.09666)
Token length: 1474
Summarized using qwen-turbo
Append: [VLA-Adapter：高效连接视觉语言与动作空间的轻量级方法](https://arxiv.org/abs/2509.09372)
Token length: 1752
Summarized using qwen-turbo
Append: [HuMo：统一的人类视频生成框架](https://arxiv.org/abs/2509.08519)
Token length: 1136
Summarized using qwen-turbo
Append: [分解推理中毒攻击与大语言模型的后门鲁棒性](https://arxiv.org/abs/2509.05739)
Token length: 1459
Summarized using qwen-turbo
Append: [基于高斯点云的图像修复方法研究](https://arxiv.org/abs/2509.01964)
append_entries: 5
Finish: 2025-09-12 12:27:46.905876
------------------------------------------------------
Started: 2025-09-12 18:17:16.911147
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1852
Summarized using qwen-turbo
Append: [基于物体相对控制的视觉导航方法研究](https://arxiv.org/abs/2509.09594)
Token length: 1798
Summarized using qwen-turbo
Append: [面向全景牙科X光片的多模态大模型研究与应用](https://arxiv.org/abs/2509.09254)
Token length: 1762
Summarized using qwen-turbo
Append: [MambaRec：一种基于注意力引导的多模态推荐框架](https://arxiv.org/abs/2509.09114)
Token length: 911
Summarized using qwen-turbo
Append: [基于LLM的自主漏洞发现与修复系统在DARPA竞赛中的应用](https://arxiv.org/abs/2509.07225)
Token length: 1073
Summarized using qwen-turbo
Append: [mmBERT：多语言编码器模型的性能提升研究](https://arxiv.org/abs/2509.06888)
append_entries: 5
Finish: 2025-09-12 18:17:35.480043
------------------------------------------------------
Started: 2025-09-13 01:00:37.502613
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1531
Summarized using qwen-turbo
Append: [工业场景下深度学习漏洞检测技术的应用与评估](https://arxiv.org/abs/2509.09313)
Token length: 1540
Summarized using qwen-turbo
Append: [AU-Harness：提升大音频语言模型评估效率与全面性的框架](https://arxiv.org/abs/2509.08031)
Token length: 1590
Summarized using qwen-turbo
Append: [提升大语言模型的少样本学习能力：MachineLearningLM框架研究](https://arxiv.org/abs/2509.06806)
Token length: 1453
Summarized using qwen-turbo
Append: [Ego3D-Bench与Ego3D-VLM提升视觉语言模型的三维空间推理能力](https://arxiv.org/abs/2509.06266)
append_entries: 4
Finish: 2025-09-13 01:00:50.075134
------------------------------------------------------
Started: 2025-09-13 06:18:24.376368
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-09-13 06:18:24.657541
------------------------------------------------------
Started: 2025-09-13 12:25:00.515340
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-09-13 12:25:00.791852
------------------------------------------------------
Started: 2025-09-13 18:16:36.972456
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-09-13 18:16:37.255934
------------------------------------------------------
Started: 2025-09-14 01:09:42.347521
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-09-14 01:09:42.578103
------------------------------------------------------
Started: 2025-09-14 06:18:53.976335
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-09-14 06:18:54.261540
------------------------------------------------------
Started: 2025-09-14 12:24:35.978071
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-09-14 12:24:36.252843
------------------------------------------------------
Started: 2025-09-14 18:17:08.905909
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-09-14 18:17:29.309995
------------------------------------------------------
Started: 2025-09-15 01:10:01.278302
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-09-15 01:10:01.627722
------------------------------------------------------
Started: 2025-09-15 06:23:01.745364
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1050
Summarized using qwen-turbo
Append: [基于固定潜在空间的任意分辨率图像生成方法](https://arxiv.org/abs/2509.10441)
Token length: 1298
Summarized using qwen-turbo
Append: [无需训练的文本到图像颜色对齐方法](https://arxiv.org/abs/2509.10058)
Token length: 1566
Summarized using qwen-turbo
Append: [QuantAgent：面向高频交易的多智能体语言模型框架](https://arxiv.org/abs/2509.09995)
Token length: 1640
Summarized using qwen-turbo
Append: [大型语言模型的持续扩展是否带来边际收益递减？](https://arxiv.org/abs/2509.09677)
Token length: 1512
Summarized using qwen-turbo
Append: [MCP-AgentBench：评估语言代理在MCP工具交互中的能力基准](https://arxiv.org/abs/2509.09734)
Token length: 1457
Summarized using qwen-turbo
Append: [语音语言模型的语音风格适应研究](https://arxiv.org/abs/2509.09716)
append_entries: 6
Finish: 2025-09-15 06:23:23.984032
------------------------------------------------------
Started: 2025-09-15 12:29:13.134809
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1507
Summarized using qwen-turbo
Append: [基于修复能力的强化学习框架提升掩码扩散语言模型性能](https://arxiv.org/abs/2509.10396)
Token length: 1268
Summarized using qwen-turbo
Append: [构建可调控的AI代理经济体系](https://arxiv.org/abs/2509.10147)
Token length: 875
Summarized using qwen-turbo
Append: [中国少数民族语言新闻标题生成数据集CMHG发布](https://arxiv.org/abs/2509.09990)
Token length: 1322
Summarized using qwen-turbo
Append: [基于基础模型微调的长尾半监督学习方法研究](https://arxiv.org/abs/2509.09926)
Token length: 963
Summarized using qwen-turbo
Append: [X-Part：可控的3D形状部件生成模型](https://arxiv.org/abs/2509.08643)
Token length: 1418
Summarized using qwen-turbo
Append: [基于对话的第二语言学习兴趣研究与IntrEx数据集构建](https://arxiv.org/abs/2509.06652)
Token length: 1449
Summarized using qwen-turbo
Append: [HANRAG：提升多跳问答任务的检索增强生成框架](https://arxiv.org/abs/2509.09713)
Token length: 1079
Summarized using qwen-turbo
Append: [高效视觉-语言-动作策略FLOWER的开发与应用](https://arxiv.org/abs/2509.04996)
append_entries: 8
Finish: 2025-09-15 12:29:38.213543
------------------------------------------------------
Started: 2025-09-15 18:20:37.846211
Existing_entries: 1008
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 779
Summarized using qwen-turbo
Append: [DeMeVa团队在LeWiDi 2025中的方法研究](https://arxiv.org/abs/2509.09524)
append_entries: 1
Finish: 2025-09-15 18:20:41.452094
------------------------------------------------------
Started: 2025-09-16 01:04:11.362100
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1455
Summarized using qwen-turbo
Append: [Probabilistic Structure Integration：构建可控世界模型的新方法](https://arxiv.org/abs/2509.09737)
Token length: 1878
Summarized using qwen-turbo
Append: [大型语言模型在社会科学中的潜在风险与验证方法](https://arxiv.org/abs/2509.08825)
Token length: 1387
Summarized using qwen-turbo
Append: [Visual-TableQA：面向结构化数据的多模态视觉推理数据集](https://arxiv.org/abs/2509.07966)
Token length: 1569
Summarized using qwen-turbo
Append: [基于Rescorla-Wagner模型的LLM上下文处理与安全优化研究](https://arxiv.org/abs/2509.04500)
Token length: 1178
Summarized using qwen-turbo
Append: [基于因果知识的大型语言模型优化方法研究](https://arxiv.org/abs/2509.01535)
append_entries: 5
Finish: 2025-09-16 01:04:30.286525
------------------------------------------------------
Started: 2025-09-16 06:21:29.508130
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1610
Summarized using qwen-turbo
Append: [LazyDrag：基于多模态扩散Transformer的拖拽图像编辑方法](https://arxiv.org/abs/2509.12203)
Token length: 1606
Summarized using qwen-turbo
Append: [OmniWorld：推动4D世界建模发展的多模态数据集](https://arxiv.org/abs/2509.12201)
Token length: 1374
Summarized using qwen-turbo
Append: [构建心理健康伦理决策评估框架：EthicsMH数据集的引入](https://arxiv.org/abs/2509.11648)
Token length: 1616
Summarized using qwen-turbo
Append: [半在线强化学习提升GUI代理多步骤任务执行能力](https://arxiv.org/abs/2509.11543)
Token length: 1526
Summarized using qwen-turbo
Append: [动态奖励加权在多目标强化学习中的应用](https://arxiv.org/abs/2509.11452)
Token length: 1169
Summarized using qwen-turbo
Append: [CognitiveSky：基于去中心化社交平台的实时话语分析框架](https://arxiv.org/abs/2509.11444)
Token length: 1689
Summarized using qwen-turbo
Append: [PersonaX：多模态数据集推动行为特质分析与因果推理](https://arxiv.org/abs/2509.11362)
Token length: 1784
Summarized using qwen-turbo
Append: [基于领域重要性的模型剪枝方法GAPrune](https://arxiv.org/abs/2509.10844)
Token length: 1531
Summarized using qwen-turbo
Append: [InternScenes：构建大规模可模拟的室内场景数据集](https://arxiv.org/abs/2509.10813)
Token length: 1697
Summarized using qwen-turbo
Append: [HumbleBench：评估多模态大语言模型拒绝错误选项的能力](https://arxiv.org/abs/2509.09658)
append_entries: 10
Finish: 2025-09-16 06:22:12.799041
------------------------------------------------------
Started: 2025-09-16 12:29:06.710746
Existing_entries: 1010
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1356
Summarized using qwen-turbo
Append: [提升视觉语言模型视觉反思能力的研究](https://arxiv.org/abs/2509.12132)
Token length: 1256
Summarized using qwen-turbo
Append: [视觉-语言模型中信息损失分析与量化研究](https://arxiv.org/abs/2509.11986)
Token length: 1478
Summarized using qwen-turbo
Append: [Nav-R1：一种统一的具身导航基础模型](https://arxiv.org/abs/2509.10884)
Token length: 1464
Summarized using qwen-turbo
Append: [深度扩散模型中的局部性源于图像数据集的统计特性](https://arxiv.org/abs/2509.09672)
append_entries: 4
Finish: 2025-09-16 12:29:32.455255
------------------------------------------------------
Started: 2025-09-16 18:20:54.000052
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1249
Summarized using qwen-turbo
Append: [Dr.V：一种用于诊断视频幻觉的层次化框架](https://arxiv.org/abs/2509.11866)
Token length: 1467
Summarized using qwen-turbo
Append: [SearchInstruct：构建高质量指令数据集以提升大语言模型性能](https://arxiv.org/abs/2509.10708)
append_entries: 2
Finish: 2025-09-16 18:21:00.601451
------------------------------------------------------
Started: 2025-09-17 01:04:12.891456
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1771
Summarized using qwen-turbo
Append: [LongEmotion：面向长上下文情感智能的基准与方法研究](https://arxiv.org/abs/2509.07403)
append_entries: 1
Finish: 2025-09-17 01:04:17.436286
------------------------------------------------------
Started: 2025-09-17 06:21:46.148903
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1066
Summarized using qwen-turbo
Append: [SR-3D：连接2D图像与3D数据的视觉语言模型](https://arxiv.org/abs/2509.13317)
Token length: 1350
Summarized using qwen-turbo
Append: [WebWeaver：一种用于开放性深度研究的双代理框架](https://arxiv.org/abs/2509.13312)
Token length: 1301
Summarized using qwen-turbo
Append: [提升大语言模型功能调用能力的智能代理框架研究](https://arxiv.org/abs/2509.13311)
Token length: 1351
Summarized using qwen-turbo
Append: [WebResearcher：一种新型深度研究框架提升AI自主知识发现能力](https://arxiv.org/abs/2509.13309)
Token length: 1786
Summarized using qwen-turbo
Append: [单流策略梯度优化提升大语言模型性能](https://arxiv.org/abs/2509.13232)
Token length: 1255
Summarized using qwen-turbo
Append: [Hunyuan3D Studio：AI驱动的3D资产生成平台革新游戏开发流程](https://arxiv.org/abs/2509.12815)
Token length: 647
Summarized using qwen-turbo
Append: [改进量子格点算法中的周期性问题](https://arxiv.org/abs/2509.12341)
Token length: 1532
Summarized using qwen-turbo
Append: [基于掩码硬实例挖掘的多实例学习框架在计算病理学中的应用](https://arxiv.org/abs/2509.11526)
Token length: 730
Summarized using qwen-turbo
Append: [基于图像描述的多模态推理框架在数学物理挑战中取得优异成绩](https://arxiv.org/abs/2509.06079)
append_entries: 9
Finish: 2025-09-17 06:22:20.014789
------------------------------------------------------
Started: 2025-09-17 12:29:15.434976
Existing_entries: 1009
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1303
Summarized using qwen-turbo
Append: [ReSum：突破上下文限制的大型语言模型网络代理新范式](https://arxiv.org/abs/2509.13313)
Token length: 1066
Summarized using qwen-turbo
Append: [基于Agentic CPT的深度研究代理模型AgentFounder性能提升](https://arxiv.org/abs/2509.13310)
Token length: 1047
Summarized using qwen-turbo
Append: [WebSailor提升开源模型信息检索能力](https://arxiv.org/abs/2509.13305)
Token length: 1534
Summarized using qwen-turbo
Append: [高效自动化定理证明模型的优化研究](https://arxiv.org/abs/2509.12603)
Token length: 1235
Summarized using qwen-turbo
Append: [结合量化与剪枝的高效大语言模型压缩方法](https://arxiv.org/abs/2509.11177)
append_entries: 5
Finish: 2025-09-17 12:29:38.528549
------------------------------------------------------
Started: 2025-09-17 18:20:18.749364
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1490
Summarized using qwen-turbo
Append: [ROOM模拟框架提升支气管镜手术训练数据生成](https://arxiv.org/abs/2509.13177)
append_entries: 1
Finish: 2025-09-17 18:20:21.885000
------------------------------------------------------
Started: 2025-09-18 01:03:45.820951
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 822
Summarized using qwen-turbo
Append: [基于zELO方法的高效检索模型训练与应用](https://arxiv.org/abs/2509.12541)
Token length: 1066
Summarized using qwen-turbo
Append: [多模态大语言模型输出偏好被图像操控的安全风险研究](https://arxiv.org/abs/2509.12521)
Token length: 1731
Summarized using qwen-turbo
Append: [基于元模仿学习的通用四旋翼控制策略研究](https://arxiv.org/abs/2509.11481)
Token length: 1273
Summarized using qwen-turbo
Append: [基于数字信号处理的虚拟模拟建模与优化方法](https://arxiv.org/abs/2509.10706)
Token length: 1576
Summarized using qwen-turbo
Append: [结构化数据合成评估框架 Struct-Bench 的提出](https://arxiv.org/abs/2509.10696)
Token length: 1647
Summarized using qwen-turbo
Append: [SP4D：基于单目输入生成RGB与运动部件视频的框架](https://arxiv.org/abs/2509.10687)
append_entries: 6
Finish: 2025-09-18 01:04:05.242819
------------------------------------------------------
Started: 2025-09-18 06:21:14.732544
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1122
Summarized using qwen-turbo
Append: [GenExam：首个多学科文本到图像考试基准](https://arxiv.org/abs/2509.14232)
Token length: 1484
Summarized using qwen-turbo
Append: [MARS2 2025挑战赛：多模态推理与大语言模型应用](https://arxiv.org/abs/2509.14142)
Token length: 1431
Summarized using qwen-turbo
Append: [Wan-Animate：统一角色动画与替换框架](https://arxiv.org/abs/2509.14055)
Token length: 1416
Summarized using qwen-turbo
Append: [SAIL-VL2：新一代多模态基础模型的突破与应用](https://arxiv.org/abs/2509.14033)
Token length: 1662
Summarized using qwen-turbo
Append: [THOR：一种基于强化学习的工具集成优化方法提升大语言模型数学推理能力](https://arxiv.org/abs/2509.13761)
append_entries: 5
Finish: 2025-09-18 06:21:34.415176
------------------------------------------------------
Started: 2025-09-18 12:28:26.734669
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 903
Summarized using qwen-turbo
Append: [Hala：面向阿拉伯语的指令与翻译模型系列](https://arxiv.org/abs/2509.14008)
Token length: 1752
Summarized using qwen-turbo
Append: [CLM中敏感信息的高效擦除方法研究](https://arxiv.org/abs/2509.13755)
Token length: 1150
Summarized using qwen-turbo
Append: [SteeringControl：评估表示操控方法的基准研究](https://arxiv.org/abs/2509.13450)
Token length: 1400
Summarized using qwen-turbo
Append: [全景视觉在具身AI时代的进展与展望](https://arxiv.org/abs/2509.12989)
append_entries: 4
Finish: 2025-09-18 12:28:38.165743
------------------------------------------------------
Started: 2025-09-18 18:21:03.479292
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1164
Summarized using qwen-turbo
Append: [基于行为金融的个性化财务顾问框架研究](https://arxiv.org/abs/2509.14180)
Token length: 1486
Summarized using qwen-turbo
Append: [量子变分激活函数与量子启发KAN的融合研究](https://arxiv.org/abs/2509.14026)
Token length: 1160
Summarized using qwen-turbo
Append: [CARE框架提升大语言模型的上下文推理能力](https://arxiv.org/abs/2509.13683)
Token length: 1124
Summarized using qwen-turbo
Append: [LLM-Interleaved：一种动态图像文本生成框架](https://arxiv.org/abs/2509.13642)
Token length: 1064
Summarized using qwen-turbo
Append: [基于扩散模型的高分辨率天气预测系统AERIS](https://arxiv.org/abs/2509.13523)
Token length: 1898
Summarized using qwen-turbo
Append: [混合量子-经典神经网络在图像分类任务中的性能分析](https://arxiv.org/abs/2509.13353)
Token length: 1861
Summarized using qwen-turbo
Append: [医学深度研究代理的创新与性能突破](https://arxiv.org/abs/2508.14880)
append_entries: 7
Finish: 2025-09-18 18:21:26.009679
------------------------------------------------------
Started: 2025-09-19 01:05:55.523815
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1761
Summarized using qwen-turbo
Append: [改进离散潜在空间的图像生成模型训练方法](https://arxiv.org/abs/2509.12474)
append_entries: 1
Finish: 2025-09-19 01:05:58.458615
------------------------------------------------------
Started: 2025-09-19 06:21:21.460844
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 979
Summarized using qwen-turbo
Append: [ScaleCUA：大规模开源计算机使用代理的进展](https://arxiv.org/abs/2509.15221)
Token length: 1071
Summarized using qwen-turbo
Append: [基于人类示范的视觉-语言-动作模型RynnVLA-001研究](https://arxiv.org/abs/2509.15212)
Token length: 1103
Summarized using qwen-turbo
Append: [FlowRL：通过流平衡匹配奖励分布提升大语言模型强化学习](https://arxiv.org/abs/2509.15207)
Token length: 1907
Summarized using qwen-turbo
Append: [EVOL-RL：一种无需标签的强化学习方法防止多样性崩溃](https://arxiv.org/abs/2509.15194)
Token length: 1199
Summarized using qwen-turbo
Append: [自回归模型在视觉领域的改进与应用](https://arxiv.org/abs/2509.15185)
Token length: 1757
Summarized using qwen-turbo
Append: [基于多模态大语言模型的零样本时空视频定位方法](https://arxiv.org/abs/2509.15178)
Token length: 1632
Summarized using qwen-turbo
Append: [无需训练的视频生成框架WorldForge提升运动控制与一致性](https://arxiv.org/abs/2509.15130)
Token length: 1337
Summarized using qwen-turbo
Append: [基于测试时反思的规范对齐方法研究](https://arxiv.org/abs/2509.14760)
Token length: 1493
Summarized using qwen-turbo
Append: [MultiEdit：提升图像编辑能力的高质量数据集](https://arxiv.org/abs/2509.14638)
Token length: 1492
Summarized using qwen-turbo
Append: [AToken：统一视觉分词器实现图像、视频与3D资产的高保真重建与语义理解](https://arxiv.org/abs/2509.14476)
Token length: 1737
Summarized using qwen-turbo
Append: [FinSearchComp：首个开放金融搜索与推理基准](https://arxiv.org/abs/2509.13160)
Token length: 1620
Summarized using qwen-turbo
Append: [基于频域-空域协同门控网络的高分辨率遥感图像变化检测方法](https://arxiv.org/abs/2509.06482)
append_entries: 12
Finish: 2025-09-19 06:22:08.461231
------------------------------------------------------
Started: 2025-09-19 12:29:12.591617
Existing_entries: 1012
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1497
Summarized using qwen-turbo
Append: [EchoVLM：面向超声医学影像的视觉语言模型](https://arxiv.org/abs/2509.14977)
append_entries: 1
Finish: 2025-09-19 12:29:15.628407
------------------------------------------------------
Started: 2025-09-19 18:19:29.020780
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1063
Summarized using qwen-turbo
Append: [多选题问答中分词策略对大语言模型评估的影响](https://arxiv.org/abs/2509.15020)
Token length: 1271
Summarized using qwen-turbo
Append: [Apertus：开源大语言模型解决数据合规与多语言覆盖问题](https://arxiv.org/abs/2509.14233)
Token length: 1829
Summarized using qwen-turbo
Append: [开发者与大语言模型交互行为及代码生成质量分析](https://arxiv.org/abs/2509.10402)
Token length: 1438
Summarized using qwen-turbo
Append: [RecoWorld：面向智能推荐系统的模拟环境构建](https://arxiv.org/abs/2509.10397)
Token length: 1415
Summarized using qwen-turbo
Append: [MatCha：首个材料表征图像理解基准](https://arxiv.org/abs/2509.09307)
Token length: 1903
Summarized using qwen-turbo
Append: [结构化代理软件工程的愿景与未来展望](https://arxiv.org/abs/2509.06216)
append_entries: 6
Finish: 2025-09-19 18:19:50.106331
------------------------------------------------------
Started: 2025-09-20 01:02:59.369470
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1858
Summarized using qwen-turbo
Append: [基于对象视角的多轮指令图像编辑评估框架EdiVal-Agent](https://arxiv.org/abs/2509.13399)
append_entries: 1
Finish: 2025-09-20 01:03:03.072995
------------------------------------------------------
Started: 2025-09-20 06:19:16.464550
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-09-20 06:19:16.712458
------------------------------------------------------
Started: 2025-09-20 12:26:04.409100
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-09-20 12:26:04.671017
------------------------------------------------------
Started: 2025-09-20 18:17:35.665743
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-09-20 18:17:35.906573
------------------------------------------------------
Started: 2025-09-21 01:11:19.435299
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-09-21 01:11:19.616525
------------------------------------------------------
Started: 2025-09-21 06:19:42.211606
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-09-21 06:19:42.577615
------------------------------------------------------
Started: 2025-09-21 12:25:32.585765
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-09-21 12:25:32.795402
------------------------------------------------------
Started: 2025-09-21 18:18:06.820759
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-09-21 18:18:07.034733
------------------------------------------------------
Started: 2025-09-22 01:10:42.079008
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-09-22 01:10:42.348771
------------------------------------------------------
Started: 2025-09-22 06:22:37.491795
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1665
Summarized using qwen-turbo
Append: [基于RPG的代码仓库生成框架ZeroRepo提升代码生成效率](https://arxiv.org/abs/2509.16198)
Token length: 1238
Summarized using qwen-turbo
Append: [Manzano：一种统一的多模态大语言模型框架](https://arxiv.org/abs/2509.16197)
Token length: 1833
Summarized using qwen-turbo
Append: [构建高性能多模态奖励模型的系统研究与BaseReward基准](https://arxiv.org/abs/2509.16127)
Token length: 1533
Summarized using qwen-turbo
Append: [基于视觉-语言-动作模型的强化学习方法提升真实世界任务成功率](https://arxiv.org/abs/2509.15937)
Token length: 1553
Summarized using qwen-turbo
Append: [基于Blink-Think-Link框架的人机交互自动化研究](https://arxiv.org/abs/2509.15566)
Token length: 945
Summarized using qwen-turbo
Append: [Lynx：基于单张图像的个性化视频生成模型](https://arxiv.org/abs/2509.15496)
Token length: 1608
Summarized using qwen-turbo
Append: [基于单目RGB视频的动态场景相机参数优化方法](https://arxiv.org/abs/2509.15123)
Token length: 1262
Summarized using qwen-turbo
Append: [动态角色扮演代理框架与视频数据集构建](https://arxiv.org/abs/2509.15233)
Token length: 871
Summarized using qwen-turbo
Append: [基于文本的WhisTLE方法提升ASR模型领域适应性](https://arxiv.org/abs/2509.10452)
append_entries: 9
Finish: 2025-09-22 06:23:03.530602
------------------------------------------------------
Started: 2025-09-22 12:29:39.944969
Existing_entries: 1009
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1891
Summarized using qwen-turbo
Append: [基于潜在区域网络的统一机器学习框架](https://arxiv.org/abs/2509.15591)
Token length: 1910
Summarized using qwen-turbo
Append: [Ask-to-Clarify框架：提升具身智能体协作能力的新方法](https://arxiv.org/abs/2509.15061)
Token length: 1328
Summarized using qwen-turbo
Append: [基于扩散模型的高保真室内场景生成方法](https://arxiv.org/abs/2509.14981)
Token length: 1165
Summarized using qwen-turbo
Append: [语音合成中指令与感知的对齐研究](https://arxiv.org/abs/2509.13989)
append_entries: 4
Finish: 2025-09-22 12:29:53.571559
------------------------------------------------------
Started: 2025-09-22 18:20:25.877839
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-09-22 18:20:26.073284
------------------------------------------------------
Started: 2025-09-23 01:04:13.983840
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-09-23 01:04:14.173977
------------------------------------------------------
Started: 2025-09-23 06:21:50.342507
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1841
Summarized using qwen-turbo
Append: [OnePiece：融合上下文工程与多步推理的工业搜索框架](https://arxiv.org/abs/2509.18091)
Token length: 1487
Summarized using qwen-turbo
Append: [ByteWrist：一种高柔性仿人并联手腕的设计与应用](https://arxiv.org/abs/2509.18084)
Token length: 1780
Summarized using qwen-turbo
Append: [基于Diffusion Transformers的无训练视频对象编辑框架ContextFlow](https://arxiv.org/abs/2509.17818)
Token length: 1819
Summarized using qwen-turbo
Append: [Qwen3-Omni：多模态模型在音频与视频任务中取得突破性进展](https://arxiv.org/abs/2509.17765)
Token length: 1681
Summarized using qwen-turbo
Append: [无需掩码的视频插入方法研究](https://arxiv.org/abs/2509.17627)
Token length: 1575
Summarized using qwen-turbo
Append: [EpiCache：在固定内存预算下提升长对话问答的KV缓存管理](https://arxiv.org/abs/2509.17396)
Token length: 1245
Summarized using qwen-turbo
Append: [基于多模态模型的GUI自动化交互系统Mano研究](https://arxiv.org/abs/2509.17336)
Token length: 1399
Summarized using qwen-turbo
Append: [Meta Agents Research Environments与Gaia2基准介绍](https://arxiv.org/abs/2509.17158)
Token length: 1756
Summarized using qwen-turbo
Append: [SWE-Bench Pro：面向企业级软件开发的挑战性基准测试](https://arxiv.org/abs/2509.16941)
Token length: 1166
Summarized using qwen-turbo
Append: [监督微调对大语言模型知识影响的实证研究](https://arxiv.org/abs/2509.16596)
Token length: 1408
Summarized using qwen-turbo
Append: [基于流匹配的扩散模型在线强化学习方法](https://arxiv.org/abs/2509.16117)
Token length: 1220
Summarized using qwen-turbo
Append: [合成自举预训练提升语言模型性能](https://arxiv.org/abs/2509.15248)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Hidden license conflicts in the open-source AI ecosystem pose serious legal and ethical risks, exposing organizations to potential litigation and users to undisclosed risk. However, the field lacks a data-driven understanding of how frequently these conflicts occur, where they originate, and which communities are most affected. We present the first end-to-end audit of licenses for datasets and models on Hugging Face, as well as their downstream integration into open-source software applications, covering 364 thousand datasets, 1.6 million models, and 140 thousand GitHub projects. Our empirical analysis reveals systemic non-compliance in which 35.5% of model-to-application transitions eliminate restrictive license clauses by relicensing under permissive terms. In addition, we prototype an extensible rule engine that encodes almost 200 SPDX and model-specific clauses for detecting license conflicts, which can solve 86.4% of license conflicts in software applications. To support future research, we release our dataset and the prototype engine. Our study highlights license compliance as a critical governance challenge in open-source AI and provides both the data and tools necessary to enable automated, AI-aware compliance at scale.'}]}]Summarization failed, append the original article
error: Error code: 400 - {'error': {'code': 'data_inspection_failed', 'param': None, 'message': 'Output data may contain inappropriate content.', 'type': 'data_inspection_failed'}, 'id': 'chatcmpl-50989164-d143-475f-931c-5bcbd15c8f97', 'request_id': '50989164-d143-475f-931c-5bcbd15c8f97'}. Line: 406.
Append: [From Hugging Face to GitHub: Tracing License Drift in the Open-Source AI Ecosystem](https://arxiv.org/abs/2509.09873)
append_entries: 13
Finish: 2025-09-23 06:22:29.863836
------------------------------------------------------
Started: 2025-09-23 12:28:31.522411
Existing_entries: 1013
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1365
Summarized using qwen-turbo
Append: [MetaEmbed：一种高效且可扩展的多模态检索框架](https://arxiv.org/abs/2509.18095)
Token length: 897
Summarized using qwen-turbo
Append: [Reasoning Core：推进大语言模型符号推理的新环境](https://arxiv.org/abs/2509.18083)
Token length: 1630
Summarized using qwen-turbo
Append: [TempSamp-R1：提升多模态大模型视频时间定位任务的强化微调框架](https://arxiv.org/abs/2509.18056)
Token length: 1553
Summarized using qwen-turbo
Append: [基于3D场景的高质量视频生成方法VideoFrom3D](https://arxiv.org/abs/2509.17985)
Token length: 1774
Summarized using qwen-turbo
Append: [Turk-LettuceDetect：面向土耳其语RAG系统的幻觉检测模型](https://arxiv.org/abs/2509.17671)
Token length: 1125
Summarized using qwen-turbo
Append: [AuditoryBench++与AIR-CoT：提升语言模型的听觉推理能力](https://arxiv.org/abs/2509.17641)
Token length: 1856
Summarized using qwen-turbo
Append: [LIMI模型通过少量高质量示范实现高效AI自主性](https://arxiv.org/abs/2509.17567)
Token length: 1230
Summarized using qwen-turbo
Append: [提升多模态大语言模型几何推理能力的两阶段强化学习方法](https://arxiv.org/abs/2509.17437)
Token length: 1489
Summarized using qwen-turbo
Append: [基于沃尔什-哈达玛变换的高效量化微调方法QWHA](https://arxiv.org/abs/2509.17428)
Token length: 1088
Summarized using qwen-turbo
Append: [VaseVL：提升大语言模型在古希腊陶器分析中的推理能力](https://arxiv.org/abs/2509.17191)
Token length: 1381
Summarized using qwen-turbo
Append: [通过模型对齐提升小型视觉语言模型性能](https://arxiv.org/abs/2509.16633)
Token length: 1503
Summarized using qwen-turbo
Append: [基于token感知的强化学习算法HAPO提升大模型推理能力](https://arxiv.org/abs/2509.16591)
Token length: 1679
Summarized using qwen-turbo
Append: [基于蒙特卡洛估计的自去噪标注框架提升过程奖励模型性能](https://arxiv.org/abs/2509.16548)
Token length: 1363
Summarized using qwen-turbo
Append: [基于LoRA的水下立体深度估计方法StereoAdapter](https://arxiv.org/abs/2509.16415)
Token length: 1322
Summarized using qwen-turbo
Append: [协同过滤模型中嵌入维度的性能双峰与对数现象研究](https://arxiv.org/abs/2509.15709)
Token length: 1400
Summarized using qwen-turbo
Append: [CodeFuse-CR-Bench：首个面向代码审查的全面性评估基准](https://arxiv.org/abs/2509.14856)
append_entries: 16
Finish: 2025-09-23 12:29:19.742293
------------------------------------------------------
Started: 2025-09-23 18:21:05.960822
Existing_entries: 1016
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1618
Summarized using qwen-turbo
Append: [UniPixel：一种支持像素级理解的多模态模型](https://arxiv.org/abs/2509.18094)
Token length: 1463
Summarized using qwen-turbo
Append: [大型语言模型中的策略性不诚实行为及其安全影响](https://arxiv.org/abs/2509.18058)
Token length: 1185
Summarized using qwen-turbo
Append: [基于多模态大语言模型的V2V协作自动驾驶图思维框架](https://arxiv.org/abs/2509.18053)
Token length: 1430
Summarized using qwen-turbo
Append: [跨注意力机制在语音到文本模型中的解释力分析](https://arxiv.org/abs/2509.18010)
Token length: 1329
Summarized using qwen-turbo
Append: [基于上下文感知核进化算法的贝叶斯优化方法](https://arxiv.org/abs/2509.17998)
Token length: 1670
Summarized using qwen-turbo
Append: [构建印度文化语境下的语言模型评估数据集](https://arxiv.org/abs/2509.17399)
Token length: 1116
Summarized using qwen-turbo
Append: [BeepBank-500：一个用于人机交互和音频机器学习的合成音效数据集](https://arxiv.org/abs/2509.17277)
Token length: 395
Summarized using qwen-turbo
Append: [大型推理模型评估与 ROME 基准发布](https://arxiv.org/abs/2509.17177)
append_entries: 8
Finish: 2025-09-23 18:21:30.775589
------------------------------------------------------
Started: 2025-09-24 01:05:13.496218
Existing_entries: 1008
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1467
Summarized using qwen-turbo
Append: [检测大语言模型的隐性欺骗推理：D-REX数据集的引入](https://arxiv.org/abs/2509.17938)
Token length: 1119
Summarized using qwen-turbo
Append: [Core Space框架提升低秩适配模型融合效率与准确性](https://arxiv.org/abs/2509.17786)
Token length: 1174
Summarized using qwen-turbo
Append: [DEXOP：一种提升机器人操作能力的传感数据采集系统](https://arxiv.org/abs/2509.04441)
append_entries: 3
Finish: 2025-09-24 01:05:22.803704
------------------------------------------------------
Started: 2025-09-24 06:21:29.218292
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1647
Summarized using qwen-turbo
Append: [VolSplat：基于体素对齐的3D高斯点云重建方法](https://arxiv.org/abs/2509.19297)
Token length: 1368
Summarized using qwen-turbo
Append: [基于视频扩散模型的3D场景生成框架](https://arxiv.org/abs/2509.19296)
Token length: 1425
Summarized using qwen-turbo
Append: [有效链式推理的特征与优化方法研究](https://arxiv.org/abs/2509.19284)
Token length: 1854
Summarized using qwen-turbo
Append: [基于预训练数据的强化学习方法提升大语言模型性能](https://arxiv.org/abs/2509.19249)
Token length: 1907
Summarized using qwen-turbo
Append: [多光谱图像与通用多模态模型的零样本融合方法](https://arxiv.org/abs/2509.19087)
Token length: 1111
Summarized using qwen-turbo
Append: [基于混合优势策略的强化学习方法改进](https://arxiv.org/abs/2509.18849)
Token length: 1344
Summarized using qwen-turbo
Append: [Hyper-Bagel：提升多模态理解和生成效率的加速框架](https://arxiv.org/abs/2509.18824)
Token length: 1493
Summarized using qwen-turbo
Append: [HyRF：结合显式高斯与神经场的高效场景表示方法](https://arxiv.org/abs/2509.17083)
Token length: 1269
Summarized using qwen-turbo
Append: [MiniCPM-V 4.5：高效多模态大语言模型的突破](https://arxiv.org/abs/2509.18154)
append_entries: 9
Finish: 2025-09-24 06:21:54.580791
------------------------------------------------------
Started: 2025-09-24 12:29:11.266738
Existing_entries: 1009
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1035
Summarized using qwen-turbo
Append: [Condition-Aware Reparameterization for Flow Matching (CAR-Flow)](https://arxiv.org/abs/2509.19300)
Token length: 1320
Summarized using qwen-turbo
Append: [VIR-Bench：评估多模态大语言模型长距离轨迹理解的新基准](https://arxiv.org/abs/2509.19002)
Token length: 1320
Summarized using qwen-turbo
Append: [无状态视觉运动策略提升机器人空间泛化能力](https://arxiv.org/abs/2509.18644)
Token length: 1273
Summarized using qwen-turbo
Append: [OpenGVL：用于任务进度估计的开放基准与数据集评估](https://arxiv.org/abs/2509.17321)
Token length: 1153
Summarized using qwen-turbo
Append: [Baseer：针对阿拉伯文文档OCR的视觉语言模型](https://arxiv.org/abs/2509.18174)
Token length: 1406
Summarized using qwen-turbo
Append: [语言模型中的方言刻板印象研究](https://arxiv.org/abs/2509.13835)
append_entries: 6
Finish: 2025-09-24 12:29:34.112263
------------------------------------------------------
Started: 2025-09-24 18:19:56.349913
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1163
Summarized using qwen-turbo
Append: [DRISHTIKON：首个聚焦印度文化的多模态多语言基准测试](https://arxiv.org/abs/2509.19274)
Token length: 1456
Summarized using qwen-turbo
Append: [基于稀疏体素的GeoSVR表面重建方法研究](https://arxiv.org/abs/2509.18090)
Token length: 1207
Summarized using qwen-turbo
Append: [SimulST系统延迟评估方法的改进与分析](https://arxiv.org/abs/2509.17349)
Token length: 1612
Summarized using qwen-turbo
Append: [CommonForms：大规模表单字段检测数据集与模型研究](https://arxiv.org/abs/2509.16506)
append_entries: 4
Finish: 2025-09-24 18:20:09.643231
------------------------------------------------------
Started: 2025-09-25 01:06:00.499450
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1689
Summarized using qwen-turbo
Append: [连续思维链在大语言模型中的应用与优化](https://arxiv.org/abs/2509.19170)
Token length: 1287
Summarized using qwen-turbo
Append: [PEEK：通过视觉语言模型提升机器人操作策略的泛化能力](https://arxiv.org/abs/2509.18282)
append_entries: 2
Finish: 2025-09-25 01:06:06.950108
------------------------------------------------------
Started: 2025-09-25 06:22:05.925420
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1344
Summarized using qwen-turbo
Append: [统一视频与图像生成编辑框架EditVerse的提出](https://arxiv.org/abs/2509.20360)
Token length: 1221
Summarized using qwen-turbo
Append: [基于物理参数的视频生成框架PhysCtrl](https://arxiv.org/abs/2509.20358)
Token length: 1170
Summarized using qwen-turbo
Append: [EmbeddingGemma：轻量级高效文本嵌入模型](https://arxiv.org/abs/2509.20354)
Token length: 1028
Summarized using qwen-turbo
Append: [视频模型迈向通用视觉理解的潜力](https://arxiv.org/abs/2509.20328)
Token length: 1883
Summarized using qwen-turbo
Append: [提升隐式思维链方法稳定性的SIM-CoT框架](https://arxiv.org/abs/2509.20317)
Token length: 1494
Summarized using qwen-turbo
Append: [基于强化学习的端到端文档解析模型Logics-Parsing](https://arxiv.org/abs/2509.19760)
Token length: 1641
Summarized using qwen-turbo
Append: [大型语言模型在多学科领域的应用与挑战](https://arxiv.org/abs/2509.19580)
Token length: 1344
Summarized using qwen-turbo
Append: [Lavida-O：多模态理解与生成的统一扩散模型](https://arxiv.org/abs/2509.19244)
Token length: 1197
Summarized using qwen-turbo
Append: [AI代理生成的代码拉取请求在开源项目中的接受情况研究](https://arxiv.org/abs/2509.14745)
append_entries: 9
Finish: 2025-09-25 06:22:36.840602
------------------------------------------------------
Started: 2025-09-25 12:29:49.755921
Existing_entries: 1009
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 925
Summarized using qwen-turbo
Append: [基于GRPO的语音感知大语言模型训练方法研究](https://arxiv.org/abs/2509.16990)
append_entries: 1
Finish: 2025-09-25 12:29:52.994260
------------------------------------------------------
Started: 2025-09-25 18:21:16.974430
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-09-25 18:21:17.203087
------------------------------------------------------
Started: 2025-09-26 01:05:50.359369
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1609
Summarized using qwen-turbo
Append: [基于流匹配的通用Transformer蛋白折叠模型SimpleFold](https://arxiv.org/abs/2509.18480)
Token length: 1269
Summarized using qwen-turbo
Append: [HTS代码分类研究：模型性能与成本分析](https://arxiv.org/abs/2509.18400)
Token length: 1152
Summarized using qwen-turbo
Append: [二维不可压缩Kelvin-Helmholtz不稳定性模拟库研究](https://arxiv.org/abs/2509.16080)
append_entries: 3
Finish: 2025-09-26 01:06:04.200303
------------------------------------------------------
Started: 2025-09-26 06:21:02.401433
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1190
Summarized using qwen-turbo
Append: [科学推理基础模型的构建与应用](https://arxiv.org/abs/2509.21320)
Token length: 1009
Summarized using qwen-turbo
Append: [SD3.5-Flash：高效图像生成框架助力消费级设备](https://arxiv.org/abs/2509.21318)
Token length: 1535
Summarized using qwen-turbo
Append: [交互式推荐系统：通过自然语言命令提升用户意图理解](https://arxiv.org/abs/2509.21317)
Token length: 1429
Summarized using qwen-turbo
Append: [SHINE：无需训练的高质量图像合成框架](https://arxiv.org/abs/2509.21278)
Token length: 1640
Summarized using qwen-turbo
Append: [提升多模态推理模型性能的策略与数据资源发布](https://arxiv.org/abs/2509.21268)
Token length: 1201
Summarized using qwen-turbo
Append: [Hunyuan3D-Omni：多模态控制的3D资产生成框架](https://arxiv.org/abs/2509.21245)
Token length: 1237
Summarized using qwen-turbo
Append: [基于树搜索的强化学习方法提升语言模型代理能力](https://arxiv.org/abs/2509.21240)
Token length: 1634
Summarized using qwen-turbo
Append: [CHARM：一种用于动漫发型建模的参数化表示与生成框架](https://arxiv.org/abs/2509.21114)
Token length: 1352
Summarized using qwen-turbo
Append: [MOSS-ChatV：提升视频推理一致性的强化学习框架](https://arxiv.org/abs/2509.21113)
Token length: 1916
Summarized using qwen-turbo
Append: [ScaleDiff：高效生成复杂数学问题的模型训练方法](https://arxiv.org/abs/2509.21070)
Token length: 978
Summarized using qwen-turbo
Append: [因果掩码在Transformer解码器中的位置信息作用分析](https://arxiv.org/abs/2509.21042)
Token length: 1406
Summarized using qwen-turbo
Append: [感知优化与图像质量评估的不对称性研究](https://arxiv.org/abs/2509.20878)
Token length: 1502
Summarized using qwen-turbo
Append: [不同推理风格在大型语言模型中的效果分析](https://arxiv.org/abs/2509.20868)
Token length: 1232
Summarized using qwen-turbo
Append: [基于梯度保留的策略优化算法提升大语言模型的强化学习性能](https://arxiv.org/abs/2509.20712)
Token length: 1793
Summarized using qwen-turbo
Append: [Seedream 4.0：高效多模态图像生成系统](https://arxiv.org/abs/2509.20427)
Token length: 1491
Summarized using qwen-turbo
Append: [提升大语言模型训练数据效率的思维轨迹增强方法](https://arxiv.org/abs/2509.20186)
Token length: 1273
Summarized using qwen-turbo
Append: [V-GameGym：面向视觉游戏开发的多模态基准测试框架](https://arxiv.org/abs/2509.20136)
Token length: 1678
Summarized using qwen-turbo
Append: [ReflectDrive：基于反射机制的自动驾驶安全轨迹生成框架](https://arxiv.org/abs/2509.20109)
Token length: 1450
Summarized using qwen-turbo
Append: [SceneWeaver：一种统一场景合成的反射代理框架](https://arxiv.org/abs/2509.20414)
Token length: 980
Summarized using qwen-turbo
Append: [基于奖励方差的课程强化学习方法提升LLM数学推理能力](https://arxiv.org/abs/2509.19803)
Token length: 999
Summarized using qwen-turbo
Append: [基于Schoenfeld理论的大型推理模型认知分析框架](https://arxiv.org/abs/2509.14662)
append_entries: 21
Finish: 2025-09-26 06:22:07.486046
------------------------------------------------------
Started: 2025-09-26 12:28:43.963910
Existing_entries: 1021
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1795
Summarized using qwen-turbo
Append: [面向VGGT的高效量化框架QuantVGGT研究](https://arxiv.org/abs/2509.21302)
Token length: 1918
Summarized using qwen-turbo
Append: [TrustJudge：解决LLM自动评估框架中的不一致性问题](https://arxiv.org/abs/2509.21117)
Token length: 1130
Summarized using qwen-turbo
Append: [基于MI-Fuse框架的语音情感识别模型适应方法](https://arxiv.org/abs/2509.20706)
Token length: 1498
Summarized using qwen-turbo
Append: [结合行为克隆与强化学习的高效机器人控制方法](https://arxiv.org/abs/2509.19301)
Token length: 959
Summarized using qwen-turbo
Append: [HASC：提升AI系统透明度与责任性的新框架](https://arxiv.org/abs/2509.20394)
append_entries: 5
Finish: 2025-09-26 12:28:59.129076
------------------------------------------------------
Started: 2025-09-26 18:18:46.211854
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 563
Summarized using qwen-turbo
Append: [AutoIntent：自动化文本分类工具](https://arxiv.org/abs/2509.21138)
Token length: 1449
Summarized using qwen-turbo
Append: [构建个性化搜索增强大语言模型的基准测试BESPOKE](https://arxiv.org/abs/2509.21106)
Token length: 1473
Summarized using qwen-turbo
Append: [Recon-Act：基于侦察-行动范式的自进化多智能体框架](https://arxiv.org/abs/2509.21072)
Token length: 1344
Summarized using qwen-turbo
Append: [LLM-judged基准评估中的设计缺陷与诊断方法](https://arxiv.org/abs/2509.20293)
Token length: 1050
Summarized using qwen-turbo
Append: [基于思考机制的音频分类框架研究](https://arxiv.org/abs/2509.19676)
append_entries: 5
Finish: 2025-09-26 18:18:59.518840
------------------------------------------------------
Started: 2025-09-27 01:02:54.920591
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1447
Summarized using qwen-turbo
Append: [CompLLM：一种高效的长上下文压缩技术](https://arxiv.org/abs/2509.19228)
Token length: 988
Summarized using qwen-turbo
Append: [基于上下文定义的反犹太主义内容检测研究](https://arxiv.org/abs/2509.18293)
append_entries: 2
Finish: 2025-09-27 01:03:01.912752
------------------------------------------------------
Started: 2025-09-27 06:18:30.722120
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1365
Summarized using qwen-turbo
Append: [UserRL：基于用户交互的强化学习框架研究](https://arxiv.org/abs/2509.19736)
Token length: 1260
Summarized using qwen-turbo
Append: [解决布局到图像生成中的重叠问题](https://arxiv.org/abs/2509.19282)
append_entries: 2
Finish: 2025-09-27 06:18:39.493987
------------------------------------------------------
Started: 2025-09-27 12:25:17.284192
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-09-27 12:25:17.553497
------------------------------------------------------
Started: 2025-09-27 18:18:04.368397
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-09-27 18:18:04.588168
------------------------------------------------------
Started: 2025-09-28 01:12:20.001340
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-09-28 01:12:20.256804
------------------------------------------------------
Started: 2025-09-28 06:19:29.793803
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-09-28 06:19:29.988215
------------------------------------------------------
Started: 2025-09-28 12:25:39.179523
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-09-28 12:25:39.381731
------------------------------------------------------
Started: 2025-09-28 18:17:50.385616
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-09-28 18:17:50.644523
------------------------------------------------------
Started: 2025-09-29 01:07:18.334922
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-09-29 01:07:18.549174
------------------------------------------------------
Started: 2025-09-29 06:23:22.042126
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1623
Summarized using qwen-turbo
Append: [VoiceAssistant-Eval：评估语音优先AI助手的新基准](https://arxiv.org/abs/2509.22651)
Token length: 1834
Summarized using qwen-turbo
Append: [基于强化学习的图像描述生成方法研究](https://arxiv.org/abs/2509.22647)
Token length: 1790
Summarized using qwen-turbo
Append: [基于多级视觉反馈的网站生成代理系统WebGen-Agent](https://arxiv.org/abs/2509.22644)
Token length: 973
Summarized using qwen-turbo
Append: [基于语言反馈的条件策略学习方法](https://arxiv.org/abs/2509.22638)
Token length: 1054
Summarized using qwen-turbo
Append: [基于变分推理的语言模型优化框架](https://arxiv.org/abs/2509.22637)
Token length: 1723
Summarized using qwen-turbo
Append: [LongLive：面向实时交互的长视频生成框架](https://arxiv.org/abs/2509.22622)
Token length: 1146
Summarized using qwen-turbo
Append: [基于分位优势估计的强化学习方法提升大模型推理稳定性](https://arxiv.org/abs/2509.22611)
Token length: 1920
Summarized using qwen-turbo
Append: [基于课程的自模仿学习提升LLM的探索与利用平衡](https://arxiv.org/abs/2509.22601)
Token length: 1487
Summarized using qwen-turbo
Append: [多轮稀疏奖励环境下LLM代理的强化学习方法研究](https://arxiv.org/abs/2509.22576)
Token length: 1325
Summarized using qwen-turbo
Append: [EAGLE框架提升多模态大语言模型的可解释性](https://arxiv.org/abs/2509.22496)
Token length: 1475
Summarized using qwen-turbo
Append: [无提示通用图像修复框架LucidFlux的提出](https://arxiv.org/abs/2509.22414)
Token length: 1017
Summarized using qwen-turbo
Append: [FlashEdit：高效实时图像编辑框架](https://arxiv.org/abs/2509.22244)
Token length: 1196
Summarized using qwen-turbo
Append: [MinerU2.5：高效文档解析的视觉语言模型](https://arxiv.org/abs/2509.22186)
Token length: 1402
Summarized using qwen-turbo
Append: [D-Artemis：基于认知循环的GUI自动化框架](https://arxiv.org/abs/2509.21799)
Token length: 1792
Summarized using qwen-turbo
Append: [UltraHorizon：评估长时序智能体能力的新基准](https://arxiv.org/abs/2509.21766)
Token length: 1706
Summarized using qwen-turbo
Append: [基于视频生成模型的统一视觉任务框架UniVid](https://arxiv.org/abs/2509.21760)
Token length: 1901
Summarized using qwen-turbo
Append: [Think-on-Graph 3.0：动态图增强的检索生成框架](https://arxiv.org/abs/2509.21710)
Token length: 1515
Summarized using qwen-turbo
Append: [X-Streamer：多模态数字人类建模框架实现持续交互](https://arxiv.org/abs/2509.21574)
Token length: 1296
Summarized using qwen-turbo
Append: [CHURRO：专为历史文本识别设计的视觉语言模型](https://arxiv.org/abs/2509.19768)
append_entries: 19
Finish: 2025-09-29 06:24:26.876922
------------------------------------------------------
Started: 2025-09-29 12:30:07.774161
Existing_entries: 1019
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1368
Summarized using qwen-turbo
Append: [无需训练的空中视觉语言导航框架SPF](https://arxiv.org/abs/2509.22653)
Token length: 1604
Summarized using qwen-turbo
Append: [无需微调的扩散模型注意力分割方法](https://arxiv.org/abs/2509.22650)
Token length: 1657
Summarized using qwen-turbo
Append: [基于真实交互的物理直觉生成模型研究](https://arxiv.org/abs/2509.22642)
Token length: 1293
Summarized using qwen-turbo
Append: [StateX：高效扩展RNN状态以提升长上下文记忆能力](https://arxiv.org/abs/2509.22630)
Token length: 1815
Summarized using qwen-turbo
Append: [SPARK：一种协同进化框架提升大模型性能](https://arxiv.org/abs/2509.22624)
Token length: 1368
Summarized using qwen-turbo
Append: [基于历史引导采样的扩散模型优化方法](https://arxiv.org/abs/2509.22300)
Token length: 1488
Summarized using qwen-turbo
Append: [基于任务导向的桌面场景生成方法研究](https://arxiv.org/abs/2509.22281)
Token length: 1423
Summarized using qwen-turbo
Append: [基于扩散模型的视觉与语义特征解耦方法](https://arxiv.org/abs/2509.21989)
Token length: 1168
Summarized using qwen-turbo
Append: [RL-ZVP：利用零方差提示提升大语言模型的强化学习方法](https://arxiv.org/abs/2509.21880)
Token length: 1161
Summarized using qwen-turbo
Append: [AI会议中低质量评审的检测与ReviewScore评估研究](https://arxiv.org/abs/2509.21679)
Token length: 1138
Summarized using qwen-turbo
Append: [X-CoT：一种基于LLM思维链的可解释文本-视频检索框架](https://arxiv.org/abs/2509.21559)
Token length: 1213
Summarized using qwen-turbo
Append: [基于评分体系的强化微调方法缓解奖励过优化问题](https://arxiv.org/abs/2509.21500)
Token length: 1573
Summarized using qwen-turbo
Append: [DEIMv2：基于DINOv3的高效实时目标检测框架](https://arxiv.org/abs/2509.20787)
Token length: 1250
Summarized using qwen-turbo
Append: [IFEval-FC：评估函数调用中指令遵循能力的新基准](https://arxiv.org/abs/2509.18420)
append_entries: 14
Finish: 2025-09-29 12:30:52.097290
------------------------------------------------------
Started: 2025-09-29 18:21:19.268691
Existing_entries: 1014
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1104
Summarized using qwen-turbo
Append: [基于扩散视角的视觉自回归生成方法研究](https://arxiv.org/abs/2509.22636)
Token length: 1904
Summarized using qwen-turbo
Append: [基于稀疏字典学习的大型语言模型压缩方法](https://arxiv.org/abs/2509.22075)
Token length: 1598
Summarized using qwen-turbo
Append: [重新评估微调在模型编辑中的有效性](https://arxiv.org/abs/2509.22072)
Token length: 1798
Summarized using qwen-turbo
Append: [ERGO：高效视觉语言模型的粗到精推理方法](https://arxiv.org/abs/2509.21991)
Token length: 1872
Summarized using qwen-turbo
Append: [多语言AI系统中的文化语境合成数据研究](https://arxiv.org/abs/2509.21294)
Token length: 1417
Summarized using qwen-turbo
Append: [基于多模态分词的文本引导CAD原型生成方法](https://arxiv.org/abs/2509.21150)
Token length: 1152
Summarized using qwen-turbo
Append: [基于相机测量序列的3D目标定位方法研究](https://arxiv.org/abs/2509.20906)
Token length: 1915
Summarized using qwen-turbo
Append: [PromptCoT 2.0：提升大语言模型推理能力的合成问题生成框架](https://arxiv.org/abs/2509.19894)
Token length: 1307
Summarized using qwen-turbo
Append: [TUN3D：基于多视角图像的联合布局估计与3D目标检测方法](https://arxiv.org/abs/2509.21388)
append_entries: 9
Finish: 2025-09-29 18:21:47.016261
------------------------------------------------------
Started: 2025-09-30 01:06:31.458073
Existing_entries: 1009
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1662
Summarized using qwen-turbo
Append: [RLBFF：结合人类反馈与规则验证的强化学习方法](https://arxiv.org/abs/2509.21319)
append_entries: 1
Finish: 2025-09-30 01:06:34.920648
------------------------------------------------------
Started: 2025-09-30 06:22:01.598045
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1650
Summarized using qwen-turbo
Append: [基于强化学习的视觉增强后训练框架Visual Jigsaw](https://arxiv.org/abs/2509.25190)
Token length: 1660
Summarized using qwen-turbo
Append: [PixelCraft：提升结构化图像推理的多智能体系统](https://arxiv.org/abs/2509.25185)
Token length: 1660
Summarized using qwen-turbo
Append: [SIRI：一种提升大推理模型效率与准确性的强化学习方法](https://arxiv.org/abs/2509.25176)
Token length: 1231
Summarized using qwen-turbo
Append: [EasySteer：高效可扩展的大型语言模型控制框架](https://arxiv.org/abs/2509.25175)
Token length: 1511
Summarized using qwen-turbo
Append: [Rolling Forcing：减少误差累积的流式视频生成技术](https://arxiv.org/abs/2509.25161)
Token length: 1655
Summarized using qwen-turbo
Append: [构建多图像数学推理基准GSM8K-V以推动视觉语言模型发展](https://arxiv.org/abs/2509.25160)
Token length: 1312
Summarized using qwen-turbo
Append: [MGM-Omni：统一的多模态理解与长时语音生成大模型](https://arxiv.org/abs/2509.25131)
Token length: 1518
Summarized using qwen-turbo
Append: [基于自我改进演示的目标导向语言导航方法SID](https://arxiv.org/abs/2509.24910)
Token length: 1443
Summarized using qwen-turbo
Append: [OpenGPT-4o-Image：构建系统化多模态数据集提升图像生成与编辑性能](https://arxiv.org/abs/2509.24900)
Token length: 1909
Summarized using qwen-turbo
Append: [RealUnify基准测试统一多模态模型的双向能力协同](https://arxiv.org/abs/2509.24897)
Token length: 1507
Summarized using qwen-turbo
Append: [ LOVE-R1：一种自适应视频理解模型](https://arxiv.org/abs/2509.24786)
Token length: 1792
Summarized using qwen-turbo
Append: [面向交互网页重建的新型基准IWR-Bench](https://arxiv.org/abs/2509.24709)
Token length: 1595
Summarized using qwen-turbo
Append: [SANA-Video：高效生成高质量长视频的扩散模型](https://arxiv.org/abs/2509.24695)
Token length: 1653
Summarized using qwen-turbo
Append: [基于欧几里得几何的多模态大模型空间智能提升研究](https://arxiv.org/abs/2509.24473)
Token length: 1202
Summarized using qwen-turbo
Append: [SphereAR：通过球面约束提升自回归图像生成性能](https://arxiv.org/abs/2509.24335)
Token length: 1322
Summarized using qwen-turbo
Append: [AdvChain：提升推理模型安全性的对抗性链式调优方法](https://arxiv.org/abs/2509.24269)
Token length: 1302
Summarized using qwen-turbo
Append: [AceSearcher：一种高效解决复杂推理任务的自博弈框架](https://arxiv.org/abs/2509.24193)
Token length: 1748
Summarized using qwen-turbo
Append: [基于稀疏注意力机制的扩散语言模型优化方法](https://arxiv.org/abs/2509.24014)
Token length: 1333
Summarized using qwen-turbo
Append: [基于序列扩散的语言模型SDLM提升生成效率与适应性](https://arxiv.org/abs/2509.24007)
Token length: 1416
Summarized using qwen-turbo
Append: [SLA：一种用于视频生成的高效注意力机制](https://arxiv.org/abs/2509.24006)
Token length: 1768
Summarized using qwen-turbo
Append: [基于高保真奖励模型的指令图像编辑强化学习方法](https://arxiv.org/abs/2509.23909)
Token length: 1810
Summarized using qwen-turbo
Append: [DART框架提升GUI代理在视觉语言模型中的强化学习效率](https://arxiv.org/abs/2509.23866)
Json decode failed:
{
  "title": "构建AI科学家的统一生态系统ToolUniverse",
  "short_summary": "ToolUniverse为AI科学家提供统一开发环境。",
  "summary": "文章介绍了ToolUniverse，这是一个用于构建AI科学家的统一生态系统，能够整合超过600个机器学习模型、数据集、API和科学工具，支持多语言和推理模型。该系统自动优化工具接口，从自然语言生成新工具，并组合工具形成智能工作流。在高胆固醇血症的研究中，ToolUniverse被用来创建一个AI科学家，以识别具有优良预测特性的药物类似物。ToolUniverse是开源的，可访问https:
  "keyword": "AI科学家, ToolUniverse, 统一生态系统"
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 212 (char 304). Line: 406.
Append: [Democratizing AI scientists using ToolUniverse](https://arxiv.org/abs/2509.23426)
Token length: 1170
Summarized using qwen-turbo
Append: [MetaAPO：动态对齐的偏好优化框架](https://arxiv.org/abs/2509.23371)
Token length: 1533
Summarized using qwen-turbo
Append: [Tool-Light：提升大语言模型工具集成推理效率的框架](https://arxiv.org/abs/2509.23285)
Token length: 1424
Summarized using qwen-turbo
Append: [基于推理痕迹的I2S方法提升少样本思维链性能](https://arxiv.org/abs/2509.23196)
Token length: 1070
Summarized using qwen-turbo
Append: [MathBode：一种用于大语言模型数学推理的动态诊断方法](https://arxiv.org/abs/2509.23143)
Token length: 1851
Summarized using qwen-turbo
Append: [多玩家纳什偏好优化：提升大语言模型与人类偏好的对齐](https://arxiv.org/abs/2509.23102)
Token length: 1802
Summarized using qwen-turbo
Append: [基于对话模板的LLM代理攻击方法研究](https://arxiv.org/abs/2509.22830)
Token length: 1427
Summarized using qwen-turbo
Append: [动态专家搜索提升大语言模型推理能力](https://arxiv.org/abs/2509.22572)
Append: [UniMIC: Token-Based Multimodal Interactive Coding for Human-AI Collaboration](https://arxiv.org/abs/2509.22570)
Append: [REMA: A Unified Reasoning Manifold Framework for Interpreting Large Language Model](https://arxiv.org/abs/2509.22518)
Append: [MultiCrafter: High-Fidelity Multi-Subject Generation via Spatially Disentangled Attention and Identity-Aware Reinforcement Learning](https://arxiv.org/abs/2509.21953)
append_entries: 33
Finish: 2025-09-30 06:23:53.424492
------------------------------------------------------
Started: 2025-09-30 12:30:08.447458
Existing_entries: 1033
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1474
Summarized using qwen-turbo
Append: [3D基础模型在密集新视角合成中的应用与优化](https://arxiv.org/abs/2509.25191)
Token length: 1872
Summarized using qwen-turbo
Append: [基于NVFP4的高效大语言模型训练方法研究](https://arxiv.org/abs/2509.25149)
Token length: 1826
Summarized using qwen-turbo
Append: [强化学习是否让大语言模型获得新技能](https://arxiv.org/abs/2509.25123)
Token length: 1096
Summarized using qwen-turbo
Append: [个性化深度研究基准与评估框架的提出](https://arxiv.org/abs/2509.25106)
Token length: 1875
Summarized using qwen-turbo
Append: [DataMind：构建通用数据分析代理的新方法](https://arxiv.org/abs/2509.25084)
Token length: 999
Summarized using qwen-turbo
Append: [基于强化学习的单目深度估计框架BRIDGE](https://arxiv.org/abs/2509.25077)
Token length: 1565
Summarized using qwen-turbo
Append: [基于语言模型的自主学习智能体CEL在复杂环境中的应用](https://arxiv.org/abs/2509.25052)
Token length: 1870
Summarized using qwen-turbo
Append: [基于随机策略评估的强化学习方法提升大语言模型数学推理能力](https://arxiv.org/abs/2509.24981)
Token length: 1004
Summarized using qwen-turbo
Append: [BOE-XSUM数据集提升西班牙法律文档摘要性能](https://arxiv.org/abs/2509.24908)
Token length: 1682
Summarized using qwen-turbo
Append: [InfLLM-V2：一种高效的长序列处理框架](https://arxiv.org/abs/2509.24663)
Token length: 825
Summarized using qwen-turbo
Append: [BPMN Assistant：基于大语言模型的流程图创建与编辑工具](https://arxiv.org/abs/2509.24592)
Token length: 1713
Summarized using qwen-turbo
Append: [构建跨学科科学验证框架提升大语言模型可靠性](https://arxiv.org/abs/2509.24285)
Token length: 1017
Summarized using qwen-turbo
Append: [UniVid：统一视频建模架构提升视频生成与理解能力](https://arxiv.org/abs/2509.24200)
Token length: 1298
Summarized using qwen-turbo
Append: [HunyuanImage 3.0：开源多模态图像生成模型的突破](https://arxiv.org/abs/2509.23951)
Token length: 1852
Summarized using qwen-turbo
Append: [面向掩码扩散语言模型的优化策略研究](https://arxiv.org/abs/2509.23924)
Token length: 1584
Summarized using qwen-turbo
Append: [探索与利用的解耦：基于隐状态空间的强化学习新方法](https://arxiv.org/abs/2509.23808)
Token length: 1351
Summarized using qwen-turbo
Append: [PARROT：跨数据库系统SQL翻译基准测试](https://arxiv.org/abs/2509.23338)
Token length: 1472
Summarized using qwen-turbo
Append: [基于LLM的维基百科不一致检测系统CLAIRE与WIKICOLLIDE基准](https://arxiv.org/abs/2509.23233)
Token length: 1460
Summarized using qwen-turbo
Append: [无线数学领域小型语言模型的突破性进展](https://arxiv.org/abs/2509.23219)
Token length: 1327
Summarized using qwen-turbo
Append: [基于层次时间分词的人类移动预测框架RHYTHM](https://arxiv.org/abs/2509.23115)
Token length: 908
Summarized using qwen-turbo
Append: [DafnyCOMP：评估大语言模型在组合规范生成中的基准](https://arxiv.org/abs/2509.23061)
Token length: 1702
Summarized using qwen-turbo
Append: [基于批判性强化学习的模型优化与应用](https://arxiv.org/abs/2509.22824)
Token length: 1557
Summarized using qwen-turbo
Append: [面向视觉-语言模型的个性化评估基准MMPB研究](https://arxiv.org/abs/2509.22820)
Token length: 1570
Summarized using qwen-turbo
Append: [VideoScore2：多维可解释的视频生成评估框架](https://arxiv.org/abs/2509.22799)
Token length: 953
Summarized using qwen-turbo
Append: [推理能力对大型语言模型性能的影响研究](https://arxiv.org/abs/2509.22193)
Token length: 1050
Summarized using qwen-turbo
Append: [意大利计算语言学与自然语言处理研究趋势分析](https://arxiv.org/abs/2509.19033)
Token length: 1596
Summarized using qwen-turbo
Append: [无需参考的视频字幕质量评估框架VC-Inspector](https://arxiv.org/abs/2509.16538)
append_entries: 27
Finish: 2025-09-30 12:31:31.717118
------------------------------------------------------
Started: 2025-09-30 18:19:02.483442
Existing_entries: 1027
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1250
Summarized using qwen-turbo
Append: [基于约束强化学习的大型语言模型蒸馏方法](https://arxiv.org/abs/2509.22921)
Token length: 1108
Summarized using qwen-turbo
Append: [提升语音分词器稳定性的StableToken方法](https://arxiv.org/abs/2509.22220)
append_entries: 2
Finish: 2025-09-30 18:19:09.543365
------------------------------------------------------
Started: 2025-10-01 01:13:44.647651
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1571
Summarized using qwen-turbo
Append: [VLMs通过文本微调实现专家级3D理解](https://arxiv.org/abs/2509.25413)
Token length: 1632
Summarized using qwen-turbo
Append: [LLM代理的错误分类与调试框架研究](https://arxiv.org/abs/2509.25370)
Token length: 1184
Summarized using qwen-turbo
Append: [基于树搜索的离散扩散轨迹优化方法TR2-D2](https://arxiv.org/abs/2509.25171)
Token length: 1158
Summarized using qwen-turbo
Append: [通过人类互动实现模型持续改进与多维对齐](https://arxiv.org/abs/2509.25137)
Token length: 1480
Summarized using qwen-turbo
Append: [基于扩散模型的强化学习方法优化研究](https://arxiv.org/abs/2509.25050)
Token length: 1912
Summarized using qwen-turbo
Append: [基于历史预测的通用正确性模型提升大语言模型置信度估计](https://arxiv.org/abs/2509.24988)
Token length: 1348
Summarized using qwen-turbo
Append: [基于潜在空间和纯Transformer的可扩展GAN研究](https://arxiv.org/abs/2509.24935)
Token length: 1468
Summarized using qwen-turbo
Append: [基于自适应流的RGB-热图像翻译模型ThermalGen](https://arxiv.org/abs/2509.24878)
Token length: 1740
Summarized using qwen-turbo
Append: [Socratic-Zero框架提升大语言模型推理能力](https://arxiv.org/abs/2509.24726)
Token length: 1144
Summarized using qwen-turbo
Append: [GRPO-MA：提升大模型链式推理训练效率的新方法](https://arxiv.org/abs/2509.24494)
Token length: 1117
Summarized using qwen-turbo
Append: [进化策略在大型语言模型微调中的成功应用](https://arxiv.org/abs/2509.24372)
Token length: 1696
Summarized using qwen-turbo
Append: [SALT：一种高效且可扩展的视频表示学习方法](https://arxiv.org/abs/2509.24317)
Token length: 1825
Summarized using qwen-turbo
Append: [基于TDD的LLM代码生成框架TENET研究](https://arxiv.org/abs/2509.24148)
Token length: 1270
Summarized using qwen-turbo
Append: [面向LLM对齐的偏好数据清洗基准研究](https://arxiv.org/abs/2509.23564)
Token length: 1294
Summarized using qwen-turbo
Append: [分析大型视觉语言模型中的语言先验机制](https://arxiv.org/abs/2509.23050)
Token length: 1305
Summarized using qwen-turbo
Append: [ADAM：多模态大语言模型在传记推理中的评估与改进框架](https://arxiv.org/abs/2509.22991)
Token length: 1327
Summarized using qwen-turbo
Append: [LUMINA：一种基于上下文与知识信号的RAG系统幻觉检测框架](https://arxiv.org/abs/2509.21875)
Token length: 1502
Summarized using qwen-turbo
Append: [评估人工智能在创造性任务中的表现与局限](https://arxiv.org/abs/2509.21043)
Token length: 1774
Summarized using qwen-turbo
Append: [提升多模态大模型美学理解能力的研究](https://arxiv.org/abs/2509.18582)
append_entries: 19
Finish: 2025-10-01 01:14:56.350763
------------------------------------------------------
Started: 2025-10-01 06:21:19.122234
Existing_entries: 1019
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1155
Summarized using qwen-turbo
Append: [基于注意力机制的高效过程监督强化学习方法](https://arxiv.org/abs/2509.26628)
Token length: 1912
Summarized using qwen-turbo
Append: [语言预训练中视觉先验的形成与应用研究](https://arxiv.org/abs/2509.26625)
Token length: 1920
Summarized using qwen-turbo
Append: [评估大语言模型在前沿物理研究中的推理能力](https://arxiv.org/abs/2509.26574)
Token length: 1715
Summarized using qwen-turbo
Append: [评估语音交互系统推理能力的基准测试VERA](https://arxiv.org/abs/2509.26542)
Token length: 1065
Summarized using qwen-turbo
Append: [轻量级GUI交互代理Ferret-UI Lite的开发与性能评估](https://arxiv.org/abs/2509.26539)
Token length: 1395
Summarized using qwen-turbo
Append: [OceanGym：推动水下具身智能发展的首个综合性基准平台](https://arxiv.org/abs/2509.26536)
Token length: 1699
Summarized using qwen-turbo
Append: [LLM操作安全性评估与提升方法研究](https://arxiv.org/abs/2509.26495)
Token length: 1637
Summarized using qwen-turbo
Append: [VitaBench：评估AI代理在现实场景中表现的新基准](https://arxiv.org/abs/2509.26490)
Token length: 1455
Summarized using qwen-turbo
Append: [dParallel：提升扩散大语言模型并行解码效率的方法](https://arxiv.org/abs/2509.26488)
Token length: 1064
Summarized using qwen-turbo
Append: [基于统一语言模型的代码指标回归研究](https://arxiv.org/abs/2509.26476)
Token length: 1607
Summarized using qwen-turbo
Append: [MotionRAG：基于检索增强的视频生成运动真实性提升方法](https://arxiv.org/abs/2509.26391)
Token length: 943
Summarized using qwen-turbo
Append: [构建本地化音频基准以评估文化感知能力](https://arxiv.org/abs/2509.26329)
Token length: 1283
Summarized using qwen-turbo
Append: [基于隐式多模态引导的扩散图像对齐方法](https://arxiv.org/abs/2509.26231)
Token length: 1306
Summarized using qwen-turbo
Append: [提升多模态推理能力：VAPO方法解决视觉遗忘问题](https://arxiv.org/abs/2509.25848)
Token length: 1826
Summarized using qwen-turbo
Append: [基于强化学习的大型语言模型真实性优化方法](https://arxiv.org/abs/2509.25760)
Token length: 1894
Summarized using qwen-turbo
Append: [后训练提升复杂推理能力的机制分析](https://arxiv.org/abs/2509.25758)
Token length: 1896
Summarized using qwen-turbo
Append: [Vision-Zero：一种无需标注数据的视觉语言模型自优化框架](https://arxiv.org/abs/2509.25541)
Token length: 1601
Summarized using qwen-turbo
Append: [VisualOverload基准测试揭示当前视觉语言模型的局限性](https://arxiv.org/abs/2509.25339)
Token length: 1019
Summarized using qwen-turbo
Append: [DC-VideoGen：高效视频生成的后训练加速框架](https://arxiv.org/abs/2509.25182)
Token length: 1504
Summarized using qwen-turbo
Append: [LLM生成判断的检测方法研究](https://arxiv.org/abs/2509.25154)
Token length: 1342
Summarized using qwen-turbo
Append: [MCPMark：评估大语言模型与外部系统交互的新基准](https://arxiv.org/abs/2509.24002)
Token length: 1367
Summarized using qwen-turbo
Append: [基于图神经网络的大型语言模型知识能力评估研究](https://arxiv.org/abs/2509.23773)
Token length: 1353
Summarized using qwen-turbo
Append: [轻量级音视同步语音分离方法Dolphin](https://arxiv.org/abs/2509.23610)
Token length: 1134
Summarized using qwen-turbo
Append: [强化学习在大型语言模型规划中的理论分析](https://arxiv.org/abs/2509.22613)
append_entries: 24
Finish: 2025-10-01 06:22:31.039203
------------------------------------------------------
Started: 2025-10-01 12:30:58.618429
Existing_entries: 1024
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 997
Summarized using qwen-turbo
Append: [基于测试时训练的3D重建方法提升长度泛化能力](https://arxiv.org/abs/2509.26645)
Token length: 1674
Summarized using qwen-turbo
Append: [DA²：一种端到端的全景深度估计方法](https://arxiv.org/abs/2509.26618)
Token length: 1386
Summarized using qwen-turbo
Append: [DeepScientist：实现超越人类水平的自主科学发现系统](https://arxiv.org/abs/2509.26603)
Token length: 1506
Summarized using qwen-turbo
Append: [Stable Cinemetrics：专业视频生成的结构化评估框架](https://arxiv.org/abs/2509.26555)
Token length: 1012
Summarized using qwen-turbo
Append: [基于生成式视觉语言模型的技能水平评估方法](https://arxiv.org/abs/2509.26278)
Token length: 1725
Summarized using qwen-turbo
Append: [Mem-alpha：基于强化学习的高效记忆管理系统](https://arxiv.org/abs/2509.25911)
Token length: 1738
Summarized using qwen-turbo
Append: [开放大语言模型的协作模式与生态系统研究](https://arxiv.org/abs/2509.25397)
Token length: 1373
Summarized using qwen-turbo
Append: [InfoAgent：基于数据合成与自建搜索的大型语言模型研究代理](https://arxiv.org/abs/2509.25189)
Token length: 883
Summarized using qwen-turbo
Append: [LayerD：一种将位图图形设计分解为可编辑图层的方法](https://arxiv.org/abs/2509.25134)
Token length: 1290
Summarized using qwen-turbo
Append: [基于频谱自适应的对抗净化方法MANI-Pure](https://arxiv.org/abs/2509.25082)
Token length: 279
Summarized using qwen-turbo
Append: [深度残差学习的演进与发明者](https://arxiv.org/abs/2509.24732)
Token length: 1300
Summarized using qwen-turbo
Append: [在线对齐与离线对齐的性能差异：基于行为经济学的解释](https://arxiv.org/abs/2509.24207)
Token length: 1338
Summarized using qwen-turbo
Append: [基于用户反馈的多轮交互自适应方法研究](https://arxiv.org/abs/2509.23166)
Token length: 1546
Summarized using qwen-turbo
Append: [构建BUILD-BENCH基准与LLM代理在开源软件编译中的应用](https://arxiv.org/abs/2509.25248)
Token length: 1614
Summarized using qwen-turbo
Append: [人类能否识别AI生成视频并提供合理依据](https://arxiv.org/abs/2509.22646)
append_entries: 15
Finish: 2025-10-01 12:31:44.257645
------------------------------------------------------
Started: 2025-10-01 18:20:23.408390
Existing_entries: 1015
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1251
Summarized using qwen-turbo
Append: [视频对象分割感知的音频生成方法研究](https://arxiv.org/abs/2509.26604)
Token length: 1898
Summarized using qwen-turbo
Append: [基于生物网络的新型语言模型BDH及其可解释性研究](https://arxiv.org/abs/2509.26507)
Token length: 1262
Summarized using qwen-turbo
Append: [TFPI：一种提升RLVR训练效率的简单方法](https://arxiv.org/abs/2509.26226)
Token length: 1500
Summarized using qwen-turbo
Append: [基于熵引导的动态分块编码器提升时间序列预测](https://arxiv.org/abs/2509.26157)
Json decode failed:
{
  "title": "Jina-Reranker-v3：一种高效的多语言文档重排序模型",
  "short_summary": "Jina-Reranker-v3实现高效多语言文档重排序，性能领先。",
  "summary": "Jina-Reranker-v3 是一个拥有 0.6B 参数的多语言文档重排序模型，引入了新颖的 "last but not late" 交互机制。与传统的 ColBERT 等晚期交互模型不同，该模型在相同的上下文窗口内对查询和文档进行因果自注意力计算，从而在提取每个文档最后一个标记的上下文嵌入之前实现丰富的跨文档交互。这种紧凑的架构在 BEIR 基准测试中取得了 61.94 nDCG@10 的最佳性能，且体积仅为生成式列表重排序器的十分之一。",
  "keyword": "Jina-Reranker-v3, 文档重排序, 多语言"
}Summarization failed, append the original article
error: Expecting ',' delimiter: line 4 column 65 (char 170). Line: 406.
Append: [jina-reranker-v3: Last but Not Late Interaction for Document Reranking](https://arxiv.org/abs/2509.25085)
Token length: 1305
Summarized using qwen-turbo
Append: [测试时训练的有效性与基础模型的专精机制](https://arxiv.org/abs/2509.24510)
Token length: 1797
Summarized using qwen-turbo
Append: [Q-Tuning：一种联合样本与令牌剪枝的高效大语言模型微调方法](https://arxiv.org/abs/2509.23873)
Token length: 1582
Summarized using qwen-turbo
Append: [TimeTic：基于上下文学习的时间序列模型迁移性评估框架](https://arxiv.org/abs/2509.23695)
Token length: 1135
Summarized using qwen-turbo
Append: [基于扩散模型的d^2Cache加速框架研究](https://arxiv.org/abs/2509.23094)
Token length: 1303
Summarized using qwen-turbo
Append: [Convolutional Set Transformer：处理异构图像集的新神经架构](https://arxiv.org/abs/2509.22889)
Token length: 1623
Summarized using qwen-turbo
Append: [基于几何感知的图像对象移除方法](https://arxiv.org/abs/2509.18538)
Token length: 1224
Summarized using qwen-turbo
Append: [大型语言模型上下文窗口的有效性测试研究](https://arxiv.org/abs/2509.21361)
append_entries: 12
Finish: 2025-10-01 18:21:27.652066
------------------------------------------------------
Started: 2025-10-02 01:04:08.811473
Existing_entries: 1012
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1566
Summarized using qwen-turbo
Append: [Muon优化器在LLM训练中的优势机制分析](https://arxiv.org/abs/2509.26030)
Token length: 1726
Summarized using qwen-turbo
Append: [中段训练提升大语言模型强化学习性能的研究](https://arxiv.org/abs/2509.25810)
Token length: 1148
Summarized using qwen-turbo
Append: [基于API预测的代码生成与检索优化方法](https://arxiv.org/abs/2509.25716)
Token length: 1912
Summarized using qwen-turbo
Append: [NuRL：通过自我生成提示提升大语言模型推理上限](https://arxiv.org/abs/2509.25666)
Token length: 960
Summarized using qwen-turbo
Append: [Swift模型实现高效子季节到季节天气预测](https://arxiv.org/abs/2509.25631)
Token length: 1582
Summarized using qwen-turbo
Append: [基于错误模式的多智能体系统错误识别框架CORRECT](https://arxiv.org/abs/2509.24088)
Token length: 885
Summarized using qwen-turbo
Append: [针对大语言模型水印的偏置反转重写攻击研究](https://arxiv.org/abs/2509.23019)
append_entries: 7
Finish: 2025-10-02 01:04:32.384659
------------------------------------------------------
Started: 2025-10-02 06:21:06.048979
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1730
Summarized using qwen-turbo
Append: [Code2Video：通过代码生成专业教育视频的框架](https://arxiv.org/abs/2510.01174)
Token length: 1346
Summarized using qwen-turbo
Append: [GEM：面向大语言模型的通用经验生成环境框架](https://arxiv.org/abs/2510.01051)
Token length: 1576
Summarized using qwen-turbo
Append: [FusioN：一种融合多模型生成的协作方法](https://arxiv.org/abs/2510.00931)
Token length: 1254
Summarized using qwen-turbo
Append: [在位反馈提升大语言模型的多轮推理性能](https://arxiv.org/abs/2510.00777)
Token length: 1213
Summarized using qwen-turbo
Append: [基于强化学习的大型语言模型参数动态研究与加速框架](https://arxiv.org/abs/2510.00553)
Token length: 1826
Summarized using qwen-turbo
Append: [GUI-KV：提升GUI代理效率的键值缓存压缩方法](https://arxiv.org/abs/2510.00536)
Token length: 1327
Summarized using qwen-turbo
Append: [后训练大语言模型的优化目标研究](https://arxiv.org/abs/2510.00526)
Token length: 911
Summarized using qwen-turbo
Append: [面向复杂任务的通用智能体架构设计与评估](https://arxiv.org/abs/2510.00510)
Token length: 1226
Summarized using qwen-turbo
Append: [基于世界模型的VLA强化微调框架提升机器人决策能力](https://arxiv.org/abs/2510.00406)
Token length: 1388
Summarized using qwen-turbo
Append: [构建统一的偏见缓解评估基准：BiasFreeBench](https://arxiv.org/abs/2510.00232)
Token length: 1555
Summarized using qwen-turbo
Append: [揭秘语言模型在多位数乘法中的失败原因及改进方法](https://arxiv.org/abs/2510.00184)
Token length: 1668
Summarized using qwen-turbo
Append: [基于背包问题的探索预算优化方法提升LLM训练效率](https://arxiv.org/abs/2509.25849)
Token length: 1905
Summarized using qwen-turbo
Append: [DeepSearch：通过系统搜索提升RLVR训练效果](https://arxiv.org/abs/2509.25454)
Token length: 1064
Summarized using qwen-turbo
Append: [基于模仿学习的CDCL求解器分支策略ImitSAT](https://arxiv.org/abs/2509.25411)
Token length: 1506
Summarized using qwen-turbo
Append: [Flash-Searcher：一种基于DAG的并行代理推理框架](https://arxiv.org/abs/2509.25301)
Token length: 1799
Summarized using qwen-turbo
Append: [面向视觉语言模型的进程奖励模型设计与优化](https://arxiv.org/abs/2509.23250)
Token length: 1077
Summarized using qwen-turbo
Append: [基于心智理论的对话代理提升语言模型社交智能](https://arxiv.org/abs/2509.22887)
Token length: 1755
Summarized using qwen-turbo
Append: [基础模型驱动的AI代理测试实践研究](https://arxiv.org/abs/2509.19185)
append_entries: 18
Finish: 2025-10-02 06:21:59.159467
------------------------------------------------------
Started: 2025-10-02 12:27:55.631437
Existing_entries: 1018
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1730
Summarized using qwen-turbo
Append: [基于广度探索的强化学习方法提升大语言模型性能](https://arxiv.org/abs/2510.01180)
Token length: 1108
Summarized using qwen-turbo
Append: [秘密提取：揭示AI未明确表达的知识](https://arxiv.org/abs/2510.01070)
Token length: 818
Summarized using qwen-turbo
Append: [Reservoir SWD：一种高效稳定的 sliced Wasserstein 距离方法](https://arxiv.org/abs/2510.01061)
Token length: 1419
Summarized using qwen-turbo
Append: [基于强化学习的CurES方法提升大语言模型训练效率](https://arxiv.org/abs/2510.01037)
Token length: 1388
Summarized using qwen-turbo
Append: [Agent Context Optimization: 提升长周期任务中语言模型效率的框架](https://arxiv.org/abs/2510.00615)
Token length: 1467
Summarized using qwen-turbo
Append: [VLM-FO1：提升视觉语言模型细粒度感知能力的新框架](https://arxiv.org/abs/2509.25916)
Token length: 1434
Summarized using qwen-turbo
Append: [基于超维度探针的大型语言模型信息解码方法](https://arxiv.org/abs/2509.25045)
append_entries: 7
Finish: 2025-10-02 12:28:16.305112
------------------------------------------------------
Started: 2025-10-02 18:20:08.212773
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 847
Summarized using qwen-turbo
Append: [2-GRPO：重新定义GRPO的最小化训练方案](https://arxiv.org/abs/2510.00977)
Token length: 1380
Summarized using qwen-turbo
Append: [基于强化学习的量子电路生成与优化框架QUASAR](https://arxiv.org/abs/2510.00967)
Token length: 1250
Summarized using qwen-turbo
Append: [BindWeave：提升视频生成中主体一致性的新框架](https://arxiv.org/abs/2510.00438)
Json decode failed:
{
  "title": "基于人类偏好数据的图像编辑奖励模型 \mname 的研究与应用",
  "short_summary": "\mname 提升图像编辑与人类偏好的一致性。",
  "summary": "本文介绍了一种名为 \mname 的图像编辑奖励模型，该模型通过大规模人工偏好数据集进行训练，包含超过20万对偏好样本。实验表明，\mname 在多个基准测试中表现出色，优于多种视觉语言模型。此外，\mname 被用于筛选高质量图像数据集，显著提升了后续模型的性能。研究还展示了其在强化学习后训练和测试时扩展图像编辑模型中的潜力。\mname 及其训练数据集将公开发布，以促进高质量图像编辑数据集的构建。",
  "keyword": "图像编辑, 奖励模型, 人类偏好"
}Summarization failed, append the original article
error: Invalid \escape: line 2 column 31 (char 32). Line: 406.
Append: [EditReward: A Human-Aligned Reward Model for Instruction-Guided Image Editing](https://arxiv.org/abs/2509.26346)
Token length: 1024
Summarized using qwen-turbo
Append: [基于强化学习的自动化环境配置方法研究](https://arxiv.org/abs/2509.25455)
Token length: 1268
Summarized using qwen-turbo
Append: [SINQ：提升低精度大语言模型量化效果的新方法](https://arxiv.org/abs/2509.22944)
append_entries: 6
Finish: 2025-10-02 18:20:28.761111
------------------------------------------------------
Started: 2025-10-03 01:04:07.107537
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1634
Summarized using qwen-turbo
Append: [MASH：通过选择性求助实现模型弃权的训练框架](https://arxiv.org/abs/2510.01152)
Token length: 1732
Summarized using qwen-turbo
Append: [基于时间约束的强化学习策略优化方法TGPO](https://arxiv.org/abs/2510.00225)
Token length: 1405
Summarized using qwen-turbo
Append: [基于操作主义的语音合成框架BatonVoice提升大语言模型的语言智能应用](https://arxiv.org/abs/2509.26514)
Token length: 1414
Summarized using qwen-turbo
Append: [MixtureVitae：一种风险可控的预训练语料库](https://arxiv.org/abs/2509.25531)
Token length: 1257
Summarized using qwen-turbo
Append: [基于预训练视觉编码器的图像生成扩散模型对齐方法](https://arxiv.org/abs/2509.25162)
append_entries: 5
Finish: 2025-10-03 01:04:25.254393
------------------------------------------------------
Started: 2025-10-03 06:20:50.619133
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1444
Summarized using qwen-turbo
Append: [多主体文本生成图像模型的优化方法研究](https://arxiv.org/abs/2510.02315)
Token length: 1032
Summarized using qwen-turbo
Append: [3DGS防御漏洞分析与隐蔽攻击方法研究](https://arxiv.org/abs/2510.02314)
Token length: 1000
Summarized using qwen-turbo
Append: [Interactive Training：一种实时反馈驱动的神经网络训练框架](https://arxiv.org/abs/2510.02297)
Token length: 907
Summarized using qwen-turbo
Append: [F2LLM：高效且可复现的嵌入模型系列](https://arxiv.org/abs/2510.02294)
Token length: 1830
Summarized using qwen-turbo
Append: [提升长视频生成质量的扩散模型方法](https://arxiv.org/abs/2510.02283)
Token length: 1820
Summarized using qwen-turbo
Append: [跨语言推理泛化能力研究：基于强化后训练的分析](https://arxiv.org/abs/2510.02272)
Token length: 1654
Summarized using qwen-turbo
Append: [Transformer在分子建模中的表现优于传统GNN](https://arxiv.org/abs/2510.02259)
Token length: 1755
Summarized using qwen-turbo
Append: [DragFlow：利用FLUX强大先验的拖拽图像编辑框架](https://arxiv.org/abs/2510.02253)
Token length: 1092
Summarized using qwen-turbo
Append: [Behavior Best-of-N 提升计算机使用代理的可靠性与性能](https://arxiv.org/abs/2510.02250)
Token length: 1336
Summarized using qwen-turbo
Append: [基于可验证奖励的强化学习中经验管理的研究](https://arxiv.org/abs/2510.02245)
Token length: 1700
Summarized using qwen-turbo
Append: [提升多模态大模型视觉推理能力的RewardMap方法](https://arxiv.org/abs/2510.02240)
Token length: 1661
Summarized using qwen-turbo
Append: [StockBench：评估大语言模型在股票交易中的表现](https://arxiv.org/abs/2510.02209)
Token length: 1462
Summarized using qwen-turbo
Append: [深度研究代理系统的评估基准与多维框架研究](https://arxiv.org/abs/2510.02190)
Token length: 1201
Summarized using qwen-turbo
Append: [基于强化学习的幻觉检测方法研究](https://arxiv.org/abs/2510.02173)
Token length: 1462
Summarized using qwen-turbo
Append: [Hourglass MLP：一种新型的多层感知机结构设计](https://arxiv.org/abs/2510.01796)
Token length: 1789
Summarized using qwen-turbo
Append: [MedQ-Bench：基于多模态大语言模型的医学图像质量评估基准](https://arxiv.org/abs/2510.01691)
Token length: 1554
Summarized using qwen-turbo
Append: [计算机使用代理的盲目标导向性分析与BLIND-ACT基准研究](https://arxiv.org/abs/2510.01670)
Token length: 1544
Summarized using qwen-turbo
Append: [VLA-R1：提升视觉-语言-动作模型推理与执行能力的新方法](https://arxiv.org/abs/2510.01623)
Token length: 1669
Summarized using qwen-turbo
Append: [基于隐藏状态的大型语言模型输出验证方法](https://arxiv.org/abs/2510.01591)
Token length: 1837
Summarized using qwen-turbo
Append: [TimeSeriesScientist：首个基于大语言模型的时间序列预测框架](https://arxiv.org/abs/2510.01538)
Token length: 1464
Summarized using qwen-turbo
Append: [基于视觉不确定性引导探索的多模态强化学习方法](https://arxiv.org/abs/2510.01444)
Token length: 1742
Summarized using qwen-turbo
Append: [AGILE：提升视觉语言模型感知与推理能力的新方法](https://arxiv.org/abs/2510.01304)
Token length: 1334
Summarized using qwen-turbo
Append: [Toucan数据集推动开源语言模型代理发展](https://arxiv.org/abs/2510.01179)
Token length: 1247
Summarized using qwen-turbo
Append: [神经网络宽度与潜在空间利用的不对称性研究](https://arxiv.org/abs/2510.00537)
Token length: 1659
Summarized using qwen-turbo
Append: [VIRTUE：一种具备视觉交互能力的多模态嵌入模型](https://arxiv.org/abs/2510.00523)
Token length: 1530
Summarized using qwen-turbo
Append: [LongCodeZip：提升代码大模型长上下文处理效率的压缩框架](https://arxiv.org/abs/2510.00446)
Token length: 1308
Summarized using qwen-turbo
Append: [基于临床背景的自动化放射报告生成方法研究](https://arxiv.org/abs/2510.00428)
Token length: 1116
Summarized using qwen-turbo
Append: [AReUReDi：一种用于多目标生物分子序列设计的离散优化算法](https://arxiv.org/abs/2510.00352)
Token length: 1207
Summarized using qwen-turbo
Append: [Ovi：统一的音视频生成模型](https://arxiv.org/abs/2510.01284)
Token length: 1387
Summarized using qwen-turbo
Append: [ScalingAR：面向NTP的自回归图像生成测试时缩放框架](https://arxiv.org/abs/2509.26376)
Append: [FrameThinker: Learning to Think with Long Videos via Multi-Turn Frame Spotlighting](https://arxiv.org/abs/2509.24304)
Append: [Group-Relative REINFORCE Is Secretly an Off-Policy Algorithm: Demystifying Some Myths About GRPO and Its Friends](https://arxiv.org/abs/2509.24203)
Append: [RLP: Reinforcement as a Pretraining Objective](https://arxiv.org/abs/2510.01265)
Append: [SKYLENAGE Technical Report: Mathematical Reasoning and Contest-Innovation Benchmarks for Multi-Level Math Evaluation](https://arxiv.org/abs/2510.01241)
append_entries: 34
Finish: 2025-10-03 06:22:34.962243
------------------------------------------------------
Started: 2025-10-03 12:28:17.897417
Existing_entries: 1034
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 959
Summarized using qwen-turbo
Append: [VideoNSA：提升多模态语言模型长视频理解能力](https://arxiv.org/abs/2510.02295)
Token length: 1490
Summarized using qwen-turbo
Append: [基于强化学习的多轮攻击策略自动发现方法](https://arxiv.org/abs/2510.02286)
Token length: 1537
Summarized using qwen-turbo
Append: [基于抽象引导的强化学习方法提升模型推理能力](https://arxiv.org/abs/2510.02263)
Token length: 958
Summarized using qwen-turbo
Append: [提升文档检索的多模态嵌入模型研究](https://arxiv.org/abs/2510.01149)
Token length: 1098
Summarized using qwen-turbo
Append: [Bridge：提升并行大语言模型推理质量的新方法](https://arxiv.org/abs/2510.01143)
Token length: 1376
Summarized using qwen-turbo
Append: [基于多模态大语言模型的零样本图像检索方法](https://arxiv.org/abs/2509.26330)
Token length: 1092
Summarized using qwen-turbo
Append: [激活引导可能破坏大模型的安全机制](https://arxiv.org/abs/2509.22067)
Token length: 1268
Summarized using qwen-turbo
Append: [多智能体系统中视觉幻觉雪球效应的缓解方法ViF](https://arxiv.org/abs/2509.21789)
Token length: 1122
Summarized using qwen-turbo
Append: [基于IoT-MCP框架的LLM与物联网系统集成研究](https://arxiv.org/abs/2510.01260)
append_entries: 9
Finish: 2025-10-03 12:28:42.761590
------------------------------------------------------
Started: 2025-10-03 18:19:44.674119
Existing_entries: 1009
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1239
Summarized using qwen-turbo
Append: [重新审视LLM对战中的平局意义与评分机制](https://arxiv.org/abs/2510.02306)
Token length: 1919
Summarized using qwen-turbo
Append: [TRAAC：自适应压缩提升模型推理效率与准确性](https://arxiv.org/abs/2510.01581)
Token length: 1429
Summarized using qwen-turbo
Append: [基于MW损失的双编码器检索方法优化](https://arxiv.org/abs/2510.00137)
Token length: 1682
Summarized using qwen-turbo
Append: [基于策略梯度的单令牌滚动微调方法提升大语言模型泛化能力](https://arxiv.org/abs/2509.26313)
append_entries: 4
Finish: 2025-10-03 18:19:59.195421
------------------------------------------------------
Started: 2025-10-04 01:01:47.478378
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1904
Summarized using qwen-turbo
Append: [Sparse Query Attention：提升Transformer模型效率的新架构](https://arxiv.org/abs/2510.01817)
Token length: 487
Summarized using qwen-turbo
Append: [Aristotle：结合形式验证与非形式推理的AI系统在数学竞赛中表现卓越](https://arxiv.org/abs/2510.01346)
Token length: 1785
Summarized using qwen-turbo
Append: [基于并行-蒸馏-精炼的推理训练方法提升模型性能](https://arxiv.org/abs/2510.01123)
Token length: 939
Summarized using qwen-turbo
Append: [隐私保护的合成文本生成方法研究](https://arxiv.org/abs/2509.25729)
Token length: 1417
Summarized using qwen-turbo
Append: [基于大模型的幻觉定位研究](https://arxiv.org/abs/2509.22582)
append_entries: 5
Finish: 2025-10-04 01:02:04.562490
------------------------------------------------------
Started: 2025-10-04 06:18:50.766264
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-10-04 06:18:51.044117
------------------------------------------------------
Started: 2025-10-04 12:25:12.778360
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-10-04 12:25:13.066258
------------------------------------------------------
Started: 2025-10-04 18:18:05.421438
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-10-04 18:18:05.732776
------------------------------------------------------
Started: 2025-10-05 01:11:40.348885
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-10-05 01:11:40.640196
------------------------------------------------------
Started: 2025-10-05 06:18:57.516591
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-10-05 06:18:57.827029
------------------------------------------------------
Started: 2025-10-05 12:25:28.507947
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-10-05 12:25:28.963491
------------------------------------------------------
Started: 2025-10-05 18:18:06.433110
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-10-05 18:18:06.734510
------------------------------------------------------
Started: 2025-10-06 01:06:25.665042
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-10-06 01:06:26.196884
------------------------------------------------------
Started: 2025-10-06 06:22:07.724812
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1301
Summarized using qwen-turbo
Append: [提升GUI定位准确性的RULER与I-MRoPE方法](https://arxiv.org/abs/2510.03230)
Token length: 1331
Summarized using qwen-turbo
Append: [FocusAgent：基于LLM的网页代理高效安全优化方法](https://arxiv.org/abs/2510.03204)
Token length: 1678
Summarized using qwen-turbo
Append: [SpineMed：推动脊柱疾病AI诊断的多模态数据与评估框架](https://arxiv.org/abs/2510.03160)
Token length: 1181
Summarized using qwen-turbo
Append: [基于Quiz的学术综述评估框架SurveyBench](https://arxiv.org/abs/2510.03120)
Token length: 892
Summarized using qwen-turbo
Append: [多模态大语言模型自我提升的综述](https://arxiv.org/abs/2510.02665)
Token length: 1490
Summarized using qwen-turbo
Append: [生成视频模型的不确定性量化研究](https://arxiv.org/abs/2510.02571)
Token length: 1097
Summarized using qwen-turbo
Append: [REPAIR：一种高效且稳定的大型语言模型编辑框架](https://arxiv.org/abs/2510.01879)
Token length: 1901
Summarized using qwen-turbo
Append: [基于扩散模型的策略组合提升机器人控制性能](https://arxiv.org/abs/2510.01068)
Token length: 1489
Summarized using qwen-turbo
Append: [无需配对图像偏好数据的文本到图像模型对齐方法](https://arxiv.org/abs/2509.25771)
append_entries: 9
Finish: 2025-10-06 06:22:32.399112
------------------------------------------------------
Started: 2025-10-06 12:29:39.784312
Existing_entries: 1009
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 931
Summarized using qwen-turbo
Append: [LEAML：一种高效适应框架提升多模态大模型在专业领域的表现](https://arxiv.org/abs/2510.03232)
Token length: 1211
Summarized using qwen-turbo
Append: [多智能体协作提升数据可视化自动化](https://arxiv.org/abs/2510.03194)
Token length: 871
Summarized using qwen-turbo
Append: [基于长度感知采样的强化学习方法提升大语言模型训练效果](https://arxiv.org/abs/2510.01459)
Token length: 1228
Summarized using qwen-turbo
Append: [首次针对网络代理的提示注入攻击检测基准研究](https://arxiv.org/abs/2510.01354)
Token length: 1714
Summarized using qwen-turbo
Append: [Apriel-1.5-15B-Thinker：通过训练设计实现前沿多模态推理的模型](https://arxiv.org/abs/2510.01141)
Token length: 1654
Summarized using qwen-turbo
Append: [多轮强化学习中训练大语言模型代理的有效方法研究](https://arxiv.org/abs/2510.01132)
Token length: 1295
Summarized using qwen-turbo
Append: [基于流形对齐的快速一致性模型训练方法](https://arxiv.org/abs/2510.00658)
Token length: 1195
Summarized using qwen-turbo
Append: [基于渐进一致性蒸馏的高效多模态大模型研究](https://arxiv.org/abs/2510.00515)
Token length: 1478
Summarized using qwen-turbo
Append: [研究自我进化的风险：Misevolution及其对大语言模型的影响](https://arxiv.org/abs/2509.26354)
Token length: 1418
Summarized using qwen-turbo
Append: [NuRisk：面向自动驾驶的时空风险推理数据集与模型优化](https://arxiv.org/abs/2509.25944)
Token length: 1661
Summarized using qwen-turbo
Append: [Triangle Splatting+：基于三角形的实时3D场景重建与视图合成方法](https://arxiv.org/abs/2509.25122)
append_entries: 11
Finish: 2025-10-06 12:30:09.803114
------------------------------------------------------
Started: 2025-10-06 18:21:05.487095
Existing_entries: 1011
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1112
Summarized using qwen-turbo
Append: [MaskGRPO：一种用于离散扩散模型的高效强化学习方法](https://arxiv.org/abs/2510.02880)
Token length: 1918
Summarized using qwen-turbo
Append: [基于生物启发的对数正态分布生成模型](https://arxiv.org/abs/2510.02730)
Token length: 1255
Summarized using qwen-turbo
Append: [基于工具调用的音乐推荐系统研究](https://arxiv.org/abs/2510.01698)
Token length: 1273
Summarized using qwen-turbo
Append: [CADD：改进离散扩散模型的连续增强框架](https://arxiv.org/abs/2510.01329)
Token length: 1140
Summarized using qwen-turbo
Append: [RECAP：通过反向对齐预填充提升模型安全对齐的强化学习方法](https://arxiv.org/abs/2510.00938)
Token length: 1253
Summarized using qwen-turbo
Append: [评估对话语音语言模型的时空能力：Game-Time 基准测试](https://arxiv.org/abs/2509.26388)
Token length: 1440
Summarized using qwen-turbo
Append: [基于记忆增强的高效语言模型架构研究](https://arxiv.org/abs/2510.02375)
Token length: 1742
Summarized using qwen-turbo
Append: [基于扩散语言模型的高效单元测试生成框架 DiffTester](https://arxiv.org/abs/2509.24975)
Token length: 1099
Summarized using qwen-turbo
Append: [利用政策推理轨迹提升大模型的合规评估能力](https://arxiv.org/abs/2509.23291)
Token length: 1645
Summarized using qwen-turbo
Append: [FP4量化技术的性能分析与优化方法研究](https://arxiv.org/abs/2509.23202)
Token length: 1137
Summarized using qwen-turbo
Append: [Orthogonal SAE提升神经网络特征分解的可解释性](https://arxiv.org/abs/2509.22033)
append_entries: 11
Finish: 2025-10-06 18:21:43.847279
------------------------------------------------------
Started: 2025-10-07 01:05:06.951572
Existing_entries: 1011
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1168
Summarized using qwen-turbo
Append: [提升小规模视觉语言模型性能的高效测试时扩展方法](https://arxiv.org/abs/2510.03574)
Token length: 1011
Summarized using qwen-turbo
Append: [扩大语料库可有效提升RAG性能，减少对大模型的依赖](https://arxiv.org/abs/2510.02657)
Token length: 1629
Summarized using qwen-turbo
Append: [帧级在线视频到音频生成模型SoundReactor](https://arxiv.org/abs/2510.02110)
Token length: 1901
Summarized using qwen-turbo
Append: [OpenTSLM：将时间序列融入大语言模型的创新方法](https://arxiv.org/abs/2510.02410)
Token length: 1868
Summarized using qwen-turbo
Append: [个性化推理：LLM在用户需求匹配中的挑战与解决方案](https://arxiv.org/abs/2510.00177)
append_entries: 5
Finish: 2025-10-07 01:05:26.734422
------------------------------------------------------
Started: 2025-10-07 06:21:27.468757
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-10-07 06:21:27.740221
------------------------------------------------------
Started: 2025-10-07 12:29:41.724487
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1572
Summarized using qwen-turbo
Append: [PaperTalker：首个学术演示视频生成框架与基准数据集](https://arxiv.org/abs/2510.05096)
Token length: 1088
Summarized using qwen-turbo
Append: [VChain：通过视觉推理提升视频生成质量的框架](https://arxiv.org/abs/2510.05094)
Token length: 1608
Summarized using qwen-turbo
Append: [面向结构化视觉的生成与编辑研究](https://arxiv.org/abs/2510.05091)
Token length: 1076
Summarized using qwen-turbo
Append: [基于文本嵌入的可分离与连续图像编辑方法](https://arxiv.org/abs/2510.05081)
Token length: 1586
Summarized using qwen-turbo
Append: [SwiReasoning：一种提升大语言模型推理效率的框架](https://arxiv.org/abs/2510.05069)
Token length: 1791
Summarized using qwen-turbo
Append: [视频大模型后训练方法综述](https://arxiv.org/abs/2510.05034)
Token length: 971
Summarized using qwen-turbo
Append: [利用Unicode变体选择器实现不可见的越狱攻击](https://arxiv.org/abs/2510.05025)
Token length: 1461
Summarized using qwen-turbo
Append: [基于自适应采样的强化学习框架提升大语言模型推理性能](https://arxiv.org/abs/2510.04996)
Token length: 1515
Summarized using qwen-turbo
Append: [LLM代理的对齐衰减风险研究](https://arxiv.org/abs/2510.04860)
Token length: 1204
Summarized using qwen-turbo
Append: [混合架构在大语言模型中的性能分析与优化设计](https://arxiv.org/abs/2510.04800)
Token length: 1584
Summarized using qwen-turbo
Append: [基于网络视频的人类操作演示学习框架W&L](https://arxiv.org/abs/2510.04673)
Token length: 1569
Summarized using qwen-turbo
Append: [ACE：一种用于大型语言模型上下文工程的框架](https://arxiv.org/abs/2510.04618)
Token length: 1092
Summarized using qwen-turbo
Append: [NLP for Social Good的学术分布与影响分析](https://arxiv.org/abs/2510.04434)
Token length: 1150
Summarized using qwen-turbo
Append: [自修改系统中的效用与学习张力分析](https://arxiv.org/abs/2510.04399)
Token length: 1530
Summarized using qwen-turbo
Append: [ChronoEdit：通过视频生成实现物理一致性的图像编辑框架](https://arxiv.org/abs/2510.04290)
Token length: 1313
Summarized using qwen-turbo
Append: [大型语言模型知识同质化与认知多样性研究](https://arxiv.org/abs/2510.04226)
Token length: 1675
Summarized using qwen-turbo
Append: [MoME：结合多尺度表示学习与专家混合的高效语音识别框架](https://arxiv.org/abs/2510.04136)
Token length: 916
Summarized using qwen-turbo
Append: [泰国语语音交互中端到端检测方法研究](https://arxiv.org/abs/2510.04016)
Token length: 1315
Summarized using qwen-turbo
Append: [模型与数据集规模下最优超参数的范数转移现象研究](https://arxiv.org/abs/2510.03871)
Token length: 1312
Summarized using qwen-turbo
Append: [Code4MeV2：开源代码补全插件助力AI开发研究](https://arxiv.org/abs/2510.03755)
Token length: 1358
Summarized using qwen-turbo
Append: [基于互信息的树搜索框架提升大语言模型推理性能](https://arxiv.org/abs/2510.03632)
Token length: 1761
Summarized using qwen-turbo
Append: [Reactive Transformer：提升对话AI效率的新架构](https://arxiv.org/abs/2510.03561)
Token length: 1748
Summarized using qwen-turbo
Append: [SRGen：一种基于测试时自我反思的轻量级语言模型推理增强方法](https://arxiv.org/abs/2510.02919)
Token length: 1752
Summarized using qwen-turbo
Append: [AdvEvo-MARL：一种内化安全的多智能体强化学习框架](https://arxiv.org/abs/2510.01586)
Token length: 1414
Summarized using qwen-turbo
Append: [基于数据增强的大型语言模型在形式定理证明中的应用](https://arxiv.org/abs/2510.00732)
Token length: 1909
Summarized using qwen-turbo
Append: [基于知识图谱的多模态代理评估框架Graph2Eval](https://arxiv.org/abs/2510.00507)
Token length: 1149
Summarized using qwen-turbo
Append: [基于偏好分布的自动评分器校准方法研究](https://arxiv.org/abs/2510.00263)
Token length: 1122
Summarized using qwen-turbo
Append: [HiKE：首个韩英混合语言语音识别基准框架](https://arxiv.org/abs/2509.24613)
Token length: 1202
Summarized using qwen-turbo
Append: [LLMSQL：面向大语言模型的SQL生成数据集优化](https://arxiv.org/abs/2510.02350)
Token length: 1912
Summarized using qwen-turbo
Append: [推理数据在LLM训练阶段的影响研究](https://arxiv.org/abs/2510.03264)
append_entries: 30
Finish: 2025-10-07 12:31:06.662310
------------------------------------------------------
Started: 2025-10-07 18:20:47.844885
Existing_entries: 1030
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1251
Summarized using qwen-turbo
Append: [跨角色互动的文本生成视频研究](https://arxiv.org/abs/2510.05093)
Token length: 1511
Summarized using qwen-turbo
Append: [基于扩散的大型语言模型推理优化方法HEX](https://arxiv.org/abs/2510.05040)
Token length: 774
Summarized using qwen-turbo
Append: [改进幂变换在联邦学习中的稳定性研究](https://arxiv.org/abs/2510.04995)
Token length: 1241
Summarized using qwen-turbo
Append: [联邦学习中ROC与PR曲线的隐私保护近似方法](https://arxiv.org/abs/2510.04979)
Token length: 1169
Summarized using qwen-turbo
Append: [基于测试时课程的强化学习方法提升模型性能](https://arxiv.org/abs/2510.04786)
Token length: 1021
Summarized using qwen-turbo
Append: [指令微调中引入扰动对大语言模型性能的影响](https://arxiv.org/abs/2510.03528)
Token length: 1106
Summarized using qwen-turbo
Append: [MOSS-Speech：一种无需文本引导的端到端语音对话系统](https://arxiv.org/abs/2510.00499)
append_entries: 7
Finish: 2025-10-07 18:21:10.176227
------------------------------------------------------
Started: 2025-10-08 01:04:37.997833
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1122
Summarized using qwen-turbo
Append: [基于慢-快策略优化的强化学习方法提升大语言模型推理性能](https://arxiv.org/abs/2510.04072)
Token length: 1363
Summarized using qwen-turbo
Append: [巴黎：首个完全去中心化训练的扩散模型](https://arxiv.org/abs/2510.03434)
Token length: 1380
Summarized using qwen-turbo
Append: [大型语言模型隐私风险的多维分析与研究方向重构](https://arxiv.org/abs/2510.01645)
Token length: 1246
Summarized using qwen-turbo
Append: [M2PO：提升异步强化学习中过时数据利用效率的新方法](https://arxiv.org/abs/2510.01161)
Token length: 1327
Summarized using qwen-turbo
Append: [Code World Model (CWM)发布：提升代码生成的推理与规划能力](https://arxiv.org/abs/2510.02387)
append_entries: 5
Finish: 2025-10-08 01:04:56.558598
------------------------------------------------------
Started: 2025-10-08 06:21:34.787446
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1741
Summarized using qwen-turbo
Append: [EgoNight：首个夜间第一视角视觉理解基准](https://arxiv.org/abs/2510.06218)
Token length: 1696
Summarized using qwen-turbo
Append: [TaTToo：一种用于表格推理的新型奖励模型框架](https://arxiv.org/abs/2510.06217)
Token length: 1544
Summarized using qwen-turbo
Append: [基于连续流的视频目标分割方法研究](https://arxiv.org/abs/2510.06139)
Token length: 1549
Summarized using qwen-turbo
Append: [多模态医学生成模型MeDiM的提出与应用](https://arxiv.org/abs/2510.06131)
Token length: 1566
Summarized using qwen-turbo
Append: [HoloScene：实现高保真虚拟环境的交互式3D重建框架](https://arxiv.org/abs/2510.05560)
Token length: 1554
Summarized using qwen-turbo
Append: [AInstein框架评估大语言模型的科学问题求解能力](https://arxiv.org/abs/2510.05432)
Token length: 1049
Summarized using qwen-turbo
Append: [基于扩散模型的视频生成无训练加速方法](https://arxiv.org/abs/2510.05367)
Token length: 1881
Summarized using qwen-turbo
Append: [MADPO：一种更稳健的偏好对齐方法](https://arxiv.org/abs/2510.05342)
Token length: 1343
Summarized using qwen-turbo
Append: [基于外部选项的奖励模型与自适应推理策略提升系统可靠性](https://arxiv.org/abs/2510.04087)
Token length: 1860
Summarized using qwen-turbo
Append: [Caco：基于代码的链式思维框架提升大语言模型推理能力](https://arxiv.org/abs/2510.04081)
Token length: 1450
Summarized using qwen-turbo
Append: [VeriGuard：基于LLM的自主AI代理安全验证框架](https://arxiv.org/abs/2510.05156)
Token length: 1732
Summarized using qwen-turbo
Append: [WebDetective：评估多跳推理系统的新型基准与框架](https://arxiv.org/abs/2510.05137)
Token length: 1553
Summarized using qwen-turbo
Append: [Fast-dLLM v2：高效并行文本生成的扩散语言模型](https://arxiv.org/abs/2509.26328)
Token length: 721
Summarized using qwen-turbo
Append: [CoDA：轻量级扩散语言模型在代码生成任务中的表现](https://arxiv.org/abs/2510.03270)
Token length: 1649
Summarized using qwen-turbo
Append: [基于用户隐式不满信号的DRIFT模型训练方法](https://arxiv.org/abs/2510.02341)
append_entries: 15
Finish: 2025-10-08 06:22:20.737586
------------------------------------------------------
Started: 2025-10-08 12:30:01.278860
Existing_entries: 1015
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1606
Summarized using qwen-turbo
Append: [Human3R：基于单目视频的4D人体与场景统一重建框架](https://arxiv.org/abs/2510.06219)
Token length: 1503
Summarized using qwen-turbo
Append: [语言模型中的实体绑定与检索机制研究](https://arxiv.org/abs/2510.06182)
Token length: 1490
Summarized using qwen-turbo
Append: [揭示大语言模型幻觉的内在机制](https://arxiv.org/abs/2510.06107)
Token length: 1338
Summarized using qwen-turbo
Append: [改进大语言模型强化学习中的重要性采样策略](https://arxiv.org/abs/2510.06062)
Token length: 1098
Summarized using qwen-turbo
Append: [MixReasoning：动态调整推理深度以提升模型效率](https://arxiv.org/abs/2510.06052)
Token length: 1420
Summarized using qwen-turbo
Append: [揭示推理模型安全对齐失败机制及修复方法](https://arxiv.org/abs/2510.06036)
Token length: 1804
Summarized using qwen-turbo
Append: [面向多情感预测的语音情感识别系统研究](https://arxiv.org/abs/2510.05934)
Token length: 1465
Summarized using qwen-turbo
Append: [TensorBLEU：高效GPU加速的BLEU评估工具](https://arxiv.org/abs/2510.05485)
Token length: 1821
Summarized using qwen-turbo
Append: [BIRD-INTERACT：多轮文本到SQL任务的现实基准测试](https://arxiv.org/abs/2510.05318)
Token length: 1350
Summarized using qwen-turbo
Append: [长格式生物医学图像-文本模型的预训练研究](https://arxiv.org/abs/2510.03978)
Token length: 862
Summarized using qwen-turbo
Append: [OneFlow：首个非自回归多模态生成模型](https://arxiv.org/abs/2510.03506)
Token length: 1116
Summarized using qwen-turbo
Append: [Equilibrium Matching：一种基于平衡动力学的生成建模框架](https://arxiv.org/abs/2510.02300)
Token length: 1155
Summarized using qwen-turbo
Append: [HalluGuard：一种用于减少检索增强生成中幻觉的小型推理模型](https://arxiv.org/abs/2510.00880)
Token length: 998
Summarized using qwen-turbo
Append: [提升情感支持对话的推理能力：CARE框架的研究](https://arxiv.org/abs/2510.05122)
Token length: 1663
Summarized using qwen-turbo
Append: [Fathom-DeepResearch：基于工具集成的深度研究代理系统](https://arxiv.org/abs/2509.24107)
append_entries: 15
Finish: 2025-10-08 12:30:47.651548
------------------------------------------------------
Started: 2025-10-08 18:21:09.876793
Existing_entries: 1015
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1173
Summarized using qwen-turbo
Append: [量化鲁棒性与训练动态的关系研究](https://arxiv.org/abs/2510.06213)
Token length: 962
Summarized using qwen-turbo
Append: [基于视频的4D形状生成方法研究](https://arxiv.org/abs/2510.06208)
Token length: 1156
Summarized using qwen-turbo
Append: [代码推理知识蒸馏的性能缩放研究](https://arxiv.org/abs/2510.06101)
Token length: 1183
Summarized using qwen-turbo
Append: [散点图任务中的AI模型性能评估与数据集构建](https://arxiv.org/abs/2510.06071)
Token length: 1256
Summarized using qwen-turbo
Append: [DeepEvolve：融合深度研究与算法演化的科学助手](https://arxiv.org/abs/2510.06056)
Token length: 1490
Summarized using qwen-turbo
Append: [基于高斯过程的鞍点搜索优化方法](https://arxiv.org/abs/2510.06030)
Token length: 1497
Summarized using qwen-turbo
Append: [基于内部分布引导的选择方法提升视觉-语言-动作模型性能](https://arxiv.org/abs/2510.05681)
Token length: 1672
Summarized using qwen-turbo
Append: [AgentFlow：一种基于多模块协作的可训练代理框架](https://arxiv.org/abs/2510.05592)
Token length: 1694
Summarized using qwen-turbo
Append: [EvoPresent：一种提升学术论文展示效果的自优化框架](https://arxiv.org/abs/2510.05571)
Token length: 854
Summarized using qwen-turbo
Append: [小型递归模型TRM在硬问题求解中的表现优于HRM和LLM](https://arxiv.org/abs/2510.04871)
Token length: 1521
Summarized using qwen-turbo
Append: [GRACE：通过对比策略优化实现可解释的生成表示学习](https://arxiv.org/abs/2510.04506)
Token length: 1000
Summarized using qwen-turbo
Append: [基于离散流匹配的非自回归语音识别方法](https://arxiv.org/abs/2510.04162)
Token length: 1334
Summarized using qwen-turbo
Append: [提升医学影像报告生成准确性的临床对比编码方法](https://arxiv.org/abs/2509.23379)
Token length: 1426
Summarized using qwen-turbo
Append: [代码结构对大语言模型推理能力的影响研究](https://arxiv.org/abs/2509.21499)
append_entries: 14
Finish: 2025-10-08 18:21:57.073073
------------------------------------------------------
Started: 2025-10-09 01:05:38.216613
Existing_entries: 1014
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1886
Summarized using qwen-turbo
Append: [基于块的上下文排序方法提升信息检索效率](https://arxiv.org/abs/2510.05396)
Token length: 1513
Summarized using qwen-turbo
Append: [基于探索性退火解码的强化学习方法提升大语言模型推理能力](https://arxiv.org/abs/2510.05251)
Token length: 1486
Summarized using qwen-turbo
Append: [ChartAgent：基于视觉推理的图表问答框架](https://arxiv.org/abs/2510.04514)
append_entries: 3
Finish: 2025-10-09 01:05:48.787363
------------------------------------------------------
Started: 2025-10-09 06:22:18.169268
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1292
Summarized using qwen-turbo
Append: [基于认知科学的混合记忆框架提升长序列建模效率](https://arxiv.org/abs/2510.07318)
Token length: 1627
Summarized using qwen-turbo
Append: [Vibe Check：一种基于指令遵循的代码评估方法](https://arxiv.org/abs/2510.07315)
Token length: 1380
Summarized using qwen-turbo
Append: [WristWorld：首个仅从锚点视角生成手腕视角视频的4D世界模型](https://arxiv.org/abs/2510.07313)
Token length: 1298
Summarized using qwen-turbo
Append: [基于多实例交互的视频生成模型优化研究](https://arxiv.org/abs/2510.07310)
Token length: 1499
Summarized using qwen-turbo
Append: [MLE-Smith：自动化生成高质量机器学习工程任务的多智能体管道](https://arxiv.org/abs/2510.07307)
Token length: 1159
Summarized using qwen-turbo
Append: [评估基准老化对大语言模型事实性评测的影响](https://arxiv.org/abs/2510.07238)
Token length: 1856
Summarized using qwen-turbo
Append: [U-Bench：首个大规模U-Net分割模型基准测试](https://arxiv.org/abs/2510.07041)
Token length: 1634
Summarized using qwen-turbo
Append: [SHANKS：实现语音交互中实时推理的框架](https://arxiv.org/abs/2510.06917)
Token length: 1533
Summarized using qwen-turbo
Append: [无需标注数据的测试时强化学习方法TTRV提升视觉语言理解](https://arxiv.org/abs/2510.06783)
Token length: 1405
Summarized using qwen-turbo
Append: [OBS-Diff：一种高效的文本到图像扩散模型压缩框架](https://arxiv.org/abs/2510.06751)
Token length: 992
Summarized using qwen-turbo
Append: [Lumina-DiMOO：一种多模态生成与理解的开源基础模型](https://arxiv.org/abs/2510.06308)
Token length: 1248
Summarized using qwen-turbo
Append: [基于D^3QE的视觉自回归模型生成图像检测方法](https://arxiv.org/abs/2510.05891)
Token length: 1282
Summarized using qwen-turbo
Append: [基于上下文去噪训练的长序列模型优化研究](https://arxiv.org/abs/2510.05862)
Token length: 1863
Summarized using qwen-turbo
Append: [文本到视频生成技术的全面综述](https://arxiv.org/abs/2510.04999)
Token length: 1380
Summarized using qwen-turbo
Append: [多智能体工具集成策略优化方法MATPO提升复杂任务性能](https://arxiv.org/abs/2510.04678)
Token length: 1216
Summarized using qwen-turbo
Append: [AlphaApollo：提升基础模型推理能力的自进化代理系统](https://arxiv.org/abs/2510.06261)
Token length: 1106
Summarized using qwen-turbo
Append: [低精度训练中注意力机制不稳定性的机制分析与解决方案](https://arxiv.org/abs/2510.04212)
Token length: 1433
Summarized using qwen-turbo
Append: [多LLM系统通过KV缓存实现语义通信提升性能](https://arxiv.org/abs/2510.03215)
append_entries: 18
Finish: 2025-10-09 06:23:16.498921
------------------------------------------------------
Started: 2025-10-09 12:29:30.395038
Existing_entries: 1018
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1319
Summarized using qwen-turbo
Append: [视觉令牌压缩评估框架VTC-Bench的提出](https://arxiv.org/abs/2510.07143)
Token length: 999
Summarized using qwen-turbo
Append: [多语言NLP中的代码切换研究综述](https://arxiv.org/abs/2510.07037)
Token length: 1259
Summarized using qwen-turbo
Append: [Native Hybrid Attention：结合线性与全注意力的高效序列建模方法](https://arxiv.org/abs/2510.07019)
Token length: 1489
Summarized using qwen-turbo
Append: [在线通用事件边界检测框架Estimator的提出与实验验证](https://arxiv.org/abs/2510.06855)
Token length: 1892
Summarized using qwen-turbo
Append: [RLinf-VLA：一种统一的视觉-语言-动作模型强化学习框架](https://arxiv.org/abs/2510.06710)
Token length: 924
Summarized using qwen-turbo
Append: [Heptapod：一种基于2D分布预测的图像自回归模型](https://arxiv.org/abs/2510.06673)
Token length: 1648
Summarized using qwen-turbo
Append: [MingTok：基于连续潜在空间的统一视觉分词方法](https://arxiv.org/abs/2510.06590)
Token length: 1850
Summarized using qwen-turbo
Append: [Delethink：通过马尔可夫式思考实现高效长序列推理](https://arxiv.org/abs/2510.06557)
Token length: 1254
Summarized using qwen-turbo
Append: [非洲语言在NLP中的研究突破与技术发展](https://arxiv.org/abs/2510.05644)
Token length: 1750
Summarized using qwen-turbo
Append: [NorMuon：结合正交化与自适应学习率的高效优化器](https://arxiv.org/abs/2510.05491)
Token length: 1623
Summarized using qwen-turbo
Append: [基于紧凑状态表示的机器人运动学习方法 StaMo](https://arxiv.org/abs/2510.05057)
Token length: 1502
Summarized using qwen-turbo
Append: [基于流模型的Granular-GRPO框架提升生成模型与人类偏好对齐](https://arxiv.org/abs/2510.01982)
Token length: 1361
Summarized using qwen-turbo
Append: [PaDT：一种统一的多模态大语言模型视觉输出方法](https://arxiv.org/abs/2510.01954)
Token length: 1677
Summarized using qwen-turbo
Append: [基于深度强化学习的自主旅行规划框架DeepTravel](https://arxiv.org/abs/2509.21842)
append_entries: 14
Finish: 2025-10-09 12:30:17.738956
------------------------------------------------------
Started: 2025-10-09 18:20:32.421306
Existing_entries: 1014
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1303
Summarized using qwen-turbo
Append: [信息密度均匀性在大语言模型推理中的应用研究](https://arxiv.org/abs/2510.06953)
Token length: 1256
Summarized using qwen-turbo
Append: [评估基础模型在复杂环境中的推理与规划能力](https://arxiv.org/abs/2510.06475)
Token length: 1322
Summarized using qwen-turbo
Append: [FinLFQA：评估金融领域大语言模型长文本回答与引用能力的基准](https://arxiv.org/abs/2510.06426)
Token length: 1533
Summarized using qwen-turbo
Append: [Glocal-IB：一种改进时间序列填补的新训练范式](https://arxiv.org/abs/2510.04910)
Token length: 1461
Summarized using qwen-turbo
Append: [多语言思维链推理提升模型性能研究](https://arxiv.org/abs/2510.04230)
Token length: 1598
Summarized using qwen-turbo
Append: [基于动态提示的大型推理模型优化方法研究](https://arxiv.org/abs/2510.04204)
Token length: 1232
Summarized using qwen-turbo
Append: [分隔符对大型语言模型评估结果的影响研究](https://arxiv.org/abs/2510.05152)
append_entries: 7
Finish: 2025-10-09 18:20:53.534892
------------------------------------------------------
Started: 2025-10-10 01:05:36.027479
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1707
Summarized using qwen-turbo
Append: [CUA框架在操作系统安全中的潜在风险与评估](https://arxiv.org/abs/2510.06607)
append_entries: 1
Finish: 2025-10-10 01:05:39.853008
------------------------------------------------------
Started: 2025-10-10 06:21:44.410743
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1174
Summarized using qwen-turbo
Append: [原生训练多模态大语言模型的探索与NaViL模型研究](https://arxiv.org/abs/2510.08565)
Token length: 1437
Summarized using qwen-turbo
Append: [DeepPrune：通过动态剪枝提升大语言模型并行推理效率](https://arxiv.org/abs/2510.08483)
append_entries: 2
Finish: 2025-10-10 06:21:51.074804
------------------------------------------------------
Started: 2025-10-10 12:29:43.887275
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1637
Summarized using qwen-turbo
Append: [SciVideoBench：评估科学领域视频推理能力的新基准](https://arxiv.org/abs/2510.08559)
Token length: 1675
Summarized using qwen-turbo
Append: [利用早期经验提升语言代理的自主学习能力](https://arxiv.org/abs/2510.08558)
Token length: 1761
Summarized using qwen-turbo
Append: [基于模拟到现实的泛化抓取旋转方法研究](https://arxiv.org/abs/2510.08556)
Token length: 1671
Summarized using qwen-turbo
Append: [视频画布：任意时空补全的新框架](https://arxiv.org/abs/2510.08555)
Token length: 1379
Summarized using qwen-turbo
Append: [ARTDECO：高效实时的单目3D重建框架](https://arxiv.org/abs/2510.08551)
Token length: 800
Summarized using qwen-turbo
Append: [ERA：通过输出激活控制熵的新方法](https://arxiv.org/abs/2510.08549)
Token length: 1528
Summarized using qwen-turbo
Append: [基于真实数据生成的移动操作通用策略研究](https://arxiv.org/abs/2510.08547)
Token length: 1878
Summarized using qwen-turbo
Append: [提升多模态大模型的长链反思推理能力](https://arxiv.org/abs/2510.08540)
Token length: 1424
Summarized using qwen-turbo
Append: [基于多智能体协同演化的大型语言模型自主提升方法](https://arxiv.org/abs/2510.08529)
Token length: 1248
Summarized using qwen-turbo
Append: [InstructX：统一图像与视频编辑的多模态大模型框架](https://arxiv.org/abs/2510.08485)
Token length: 1750
Summarized using qwen-turbo
Append: [基于rCM的连续时间一致性蒸馏在大规模扩散模型中的应用](https://arxiv.org/abs/2510.08431)
Token length: 1174
Summarized using qwen-turbo
Append: [DGPO：一种提升扩散模型训练效率的在线强化学习算法](https://arxiv.org/abs/2510.08425)
Token length: 1649
Summarized using qwen-turbo
Append: [UniVideo：统一多模态视频生成与编辑框架](https://arxiv.org/abs/2510.08377)
Token length: 1521
Summarized using qwen-turbo
Append: [反思在大语言模型推理中的作用分析与优化方法](https://arxiv.org/abs/2510.08308)
Token length: 1568
Summarized using qwen-turbo
Append: [DeepMiner：提升多轮交互模型长视野推理能力的新框架](https://arxiv.org/abs/2510.08276)
Token length: 1872
Summarized using qwen-turbo
Append: [WaltzRL：一种多智能体强化学习框架提升大语言模型的安全性与实用性](https://arxiv.org/abs/2510.08240)
Token length: 1475
Summarized using qwen-turbo
Append: [LLM在高风险场景下的不诚实与欺骗行为研究](https://arxiv.org/abs/2510.08211)
Token length: 1553
Summarized using qwen-turbo
Append: [函数标记在大语言模型中的记忆检索与整合机制](https://arxiv.org/abs/2510.08203)
Token length: 1758
Summarized using qwen-turbo
Append: [无需参数更新的高效LLM代理优化方法](https://arxiv.org/abs/2510.08191)
Token length: 1325
Summarized using qwen-turbo
Append: [UniMMVSR：首个融合多模态条件的视频超分辨率框架](https://arxiv.org/abs/2510.08143)
Token length: 1233
Summarized using qwen-turbo
Append: [通过回收预训练检查点提升大语言模型效率](https://arxiv.org/abs/2510.08008)
Token length: 1641
Summarized using qwen-turbo
Append: [MUSE：一种具备持续学习能力的AI代理框架](https://arxiv.org/abs/2510.08002)
Token length: 1540
Summarized using qwen-turbo
Append: [A^2Search：一种无需标注的开放域问答框架](https://arxiv.org/abs/2510.07958)
Token length: 1186
Summarized using qwen-turbo
Append: [基于思维模板的长上下文语言模型优化方法](https://arxiv.org/abs/2510.07499)
Token length: 1281
Summarized using qwen-turbo
Append: [基于偏好反馈的高效大语言模型路由方法](https://arxiv.org/abs/2510.07429)
Token length: 1228
Summarized using qwen-turbo
Append: [HERO框架提升大语言模型推理能力](https://arxiv.org/abs/2510.07242)
Token length: 1912
Summarized using qwen-turbo
Append: [NewtonBench：推动科学定律发现的基准测试](https://arxiv.org/abs/2510.07172)
Token length: 1423
Summarized using qwen-turbo
Append: [Long-RewardBench：面向长上下文的奖励模型评估与优化](https://arxiv.org/abs/2510.06915)
Token length: 1543
Summarized using qwen-turbo
Append: [UniDoc-Bench：首个大规模多模态检索增强生成基准](https://arxiv.org/abs/2510.03663)
Token length: 1795
Summarized using qwen-turbo
Append: [基于低概率正则化的强化学习方法提升大语言模型推理能力](https://arxiv.org/abs/2510.03222)
Append: [Towards Scalable and Consistent 3D Editing](https://arxiv.org/abs/2510.02994)
Append: [UP2You: Fast Reconstruction of Yourself from Unconstrained Photo Collections](https://arxiv.org/abs/2509.24817)
Append: [Fidelity-Aware Data Composition for Robust Robot Generalization](https://arxiv.org/abs/2509.24797)
Append: [MemMamba: Rethinking Memory Patterns in State Space Model](https://arxiv.org/abs/2510.03279)
Append: [From What to Why: A Multi-Agent System for Evidence-based Chemical Reaction Condition Reasoning](https://arxiv.org/abs/2509.23768)
Append: [Beyond Outliers: A Study of Optimizers Under Quantization](https://arxiv.org/abs/2509.23500)
Append: [Meta-Awareness Enhances Reasoning Models: Self-Alignment Reinforcement Learning](https://arxiv.org/abs/2510.03259)
append_entries: 37
Finish: 2025-10-10 12:31:26.014462
------------------------------------------------------
Started: 2025-10-10 18:20:37.118201
Existing_entries: 1037
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1067
Summarized using qwen-turbo
Append: [基于单张图像生成多视角物理渲染材质的SViM3D框架](https://arxiv.org/abs/2510.08271)
Token length: 1238
Summarized using qwen-turbo
Append: [基于外部参考答案的强化学习方法提升语言模型推理能力](https://arxiv.org/abs/2510.07790)
Token length: 1438
Summarized using qwen-turbo
Append: [基于扩散模型的视频风格迁移方法研究](https://arxiv.org/abs/2510.07546)
Token length: 1602
Summarized using qwen-turbo
Append: [基于5D神经代理模型的等离子体湍流模拟研究](https://arxiv.org/abs/2510.07314)
Token length: 1329
Summarized using qwen-turbo
Append: [Search-R3：通过推理生成搜索嵌入的框架](https://arxiv.org/abs/2510.07048)
Token length: 1673
Summarized using qwen-turbo
Append: [生成模型与端到端驾驶的融合：提升自动驾驶仿真与泛化能力](https://arxiv.org/abs/2510.06209)
Token length: 1462
Summarized using qwen-turbo
Append: [文本到音视频生成的跨模态对齐方法研究](https://arxiv.org/abs/2510.03117)
Token length: 1701
Summarized using qwen-turbo
Append: [OmniRetarget：保留交互关系的人形机器人运动重定向方法](https://arxiv.org/abs/2509.26633)
append_entries: 8
Finish: 2025-10-10 18:21:00.319392
------------------------------------------------------
Started: 2025-10-11 01:02:49.151610
Existing_entries: 1008
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1433
Summarized using qwen-turbo
Append: [基于评分标准的奖励模型提升大语言模型对齐效果](https://arxiv.org/abs/2510.07743)
Token length: 1746
Summarized using qwen-turbo
Append: [多模态指令图像编辑与生成方法研究](https://arxiv.org/abs/2510.06679)
Token length: 1227
Summarized using qwen-turbo
Append: [MINTO：一种结合目标网络与在线网络的稳定高效强化学习方法](https://arxiv.org/abs/2510.02590)
append_entries: 3
Finish: 2025-10-11 01:03:00.391739
------------------------------------------------------
Started: 2025-10-11 06:18:52.557645
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-10-11 06:18:52.768771
------------------------------------------------------
Started: 2025-10-11 12:25:20.682270
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-10-11 12:25:21.076741
------------------------------------------------------
Started: 2025-10-11 18:17:08.317198
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-10-11 18:17:08.607459
------------------------------------------------------
Started: 2025-10-12 01:08:53.312496
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-10-12 01:08:53.538893
------------------------------------------------------
Started: 2025-10-12 06:19:07.988644
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-10-12 06:19:08.252247
------------------------------------------------------
Started: 2025-10-12 12:25:47.585812
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-10-12 12:25:47.879618
------------------------------------------------------
Started: 2025-10-12 18:18:21.374626
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-10-12 18:18:21.660538
------------------------------------------------------
Started: 2025-10-13 01:10:34.766266
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-10-13 01:10:35.070837
------------------------------------------------------
Started: 2025-10-13 06:23:21.980866
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 889
Summarized using qwen-turbo
Append: [基于参数空间修正的鲁棒语音识别方法](https://arxiv.org/abs/2510.08047)
append_entries: 1
Finish: 2025-10-13 06:23:54.528412
