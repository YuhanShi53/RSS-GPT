------------------------------------------------------
Started: 2024-10-13 17:10:56.094056
Existing_entries: 0
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1500
Summarized using gpt-4o-mini
Append: [利用加速偏好优化加快人类反馈下的强化学习](https://arxiv.org/abs/2410.06293)
Token length: 1022
Summarized using gpt-4o-mini
Append: [Data Advisor：提升数据生成质量的增强LLM方法](https://arxiv.org/abs/2410.05269)
Token length: 1603
Summarized using gpt-4o-mini
Append: [基于神经符号学习的LLM世界模型对齐与探索](https://arxiv.org/abs/2410.07484)
Token length: 1104
Summarized using gpt-4o-mini
Append: [向量-内联学习：扩展大型语言模型的能力](https://arxiv.org/abs/2410.05629)
Token length: 1300
Summarized using gpt-4o-mini
Append: [Zebra：一种新型生成自回归变换器用于解决时间依赖性参数偏微分方程](https://arxiv.org/abs/2410.03437)
Token length: 1092
Summarized using gpt-4o-mini
Append: [DART：一种新型的非马尔可夫扩散模型](https://arxiv.org/abs/2410.08159)
Token length: 1050
Summarized using gpt-4o-mini
Append: [大型语言模型的任务超叠现象及其内在机制研究](https://arxiv.org/abs/2410.05603)
Token length: 1427
Summarized using gpt-4o-mini
Append: [自动化基准测试中的作弊现象及其影响](https://arxiv.org/abs/2410.07137)
Token length: 1340
Summarized using gpt-4o-mini
Append: [LPZero：自动设计零成本代理的框架](https://arxiv.org/abs/2410.04808)
Token length: 1449
Summarized using gpt-4o-mini
Append: [GLOV：利用大语言模型优化视觉语言模型的隐式优化方法](https://arxiv.org/abs/2410.06154)
Token length: 1393
Summarized using gpt-4o-mini
Append: [WorFBench：一个用于评估工作流生成能力的统一基准](https://arxiv.org/abs/2410.07869)
Token length: 1305
Summarized using gpt-4o-mini
Append: [基于运动先验的变形3D高斯点云重建框架MotionGS](https://arxiv.org/abs/2410.07707)
Token length: 1817
Summarized using gpt-4o-mini
Append: [基于数学推理和代码生成的数学继续预训练方法](https://arxiv.org/abs/2410.08196)
Token length: 1841
Summarized using gpt-4o-mini
Append: [SFTMix: 基于Mixup的指令调优方法研究](https://arxiv.org/abs/2410.05248)
Token length: 1329
Summarized using gpt-4o-mini
Append: [Agent S: 基于多模态大语言模型的自主交互框架](https://arxiv.org/abs/2410.08164)
Token length: 1722
Summarized using gpt-4o-mini
Append: [大语言与视觉模型（LLVMs）的感知能力研究](https://arxiv.org/abs/2410.04751)
Token length: 1273
Summarized using gpt-4o-mini
Append: [AlphaLLM-CPL：一种基于MCTS行为蒸馏的自我改进框架](https://arxiv.org/abs/2410.06508)
Token length: 951
Summarized using gpt-4o-mini
Append: [自回归视频扩散模型的进展及应用](https://arxiv.org/abs/2410.08151)
Token length: 1424
Summarized using gpt-4o-mini
Append: [大卷积核在现代卷积神经网络设计中的应用](https://arxiv.org/abs/2410.08049)
Token length: 1582
Summarized using gpt-4o-mini
Append: [简化和扩展扩散模型 rectification 的新策略](https://arxiv.org/abs/2410.07303)
Token length: 1323
Summarized using gpt-4o-mini
Append: [基于偏好学习的多模态轨迹检索增强方法](https://arxiv.org/abs/2410.03450)
Token length: 1369
Summarized using gpt-4o-mini
Append: [PrefixQuant：一种高效的稀疏化量化技术用于大型语言模型的推理加速](https://arxiv.org/abs/2410.05265)
Token length: 1676
Summarized using gpt-4o-mini
Append: [Optima：提升大语言模型多智能体系统通信效率与任务有效性的框架](https://arxiv.org/abs/2410.08115)
Token length: 888
Summarized using gpt-4o-mini
Append: [重复训练示例在变压器模型中的效益研究](https://arxiv.org/abs/2410.07041)
Token length: 1161
Summarized using gpt-4o-mini
Append: [基于局部对抗负例损失的视觉语言模型增强方法](https://arxiv.org/abs/2410.05210)
Token length: 983
Summarized using gpt-4o-mini
Append: [DICE：用于可控编辑的离散反演方法](https://arxiv.org/abs/2410.08207)
append_entries: 26
Finish: 2024-10-13 17:14:57.885928
------------------------------------------------------
Started: 2024-10-13 18:01:19.275531
Existing_entries: 26
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-13 18:01:19.455683
------------------------------------------------------
Started: 2024-10-13 21:00:58.752846
Existing_entries: 26
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-13 21:00:58.923574
------------------------------------------------------
Started: 2024-10-14 00:35:45.371870
Existing_entries: 26
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-14 00:35:45.457562
------------------------------------------------------
Started: 2024-10-14 03:17:28.552221
Existing_entries: 26
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-14 03:17:28.635374
------------------------------------------------------
Started: 2024-10-14 06:11:06.727934
Existing_entries: 26
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1388
Summarized using gpt-4o-mini
Append: [VITask：提升大型视觉语言模型任务适应性的框架](https://arxiv.org/abs/2410.06456)
Token length: 1070
Summarized using gpt-4o-mini
Append: [增强大型语言模型的长度控制与复制粘贴能力](https://arxiv.org/abs/2410.07035)
Token length: 1401
Summarized using gpt-4o-mini
Append: [Meissonic：高效的非自回归文本到图像建模](https://arxiv.org/abs/2410.08261)
Token length: 1022
Summarized using gpt-4o-mini
Append: [Baichuan-Omni：首个开源7B多模态大语言模型](https://arxiv.org/abs/2410.08565)
Token length: 1608
Summarized using gpt-4o-mini
Append: [基于语义得分蒸馏采样的复杂3D内容生成研究](https://arxiv.org/abs/2410.09009)
Token length: 1754
Summarized using gpt-4o-mini
Append: [SuperCorrect：一种改进小型模型推理能力的两阶段框架](https://arxiv.org/abs/2410.09008)
Token length: 1717
Summarized using gpt-4o-mini
Append: [EvolveDirector：基于公共资源训练文本到图像生成模型的框架](https://arxiv.org/abs/2410.07133)
append_entries: 7
Finish: 2024-10-14 06:13:10.138301
------------------------------------------------------
Started: 2024-10-14 09:00:49.927237
Existing_entries: 33
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 953
Summarized using gpt-4o-mini
Append: [多智能体协作数据选择机制在大型语言模型预训练中的应用](https://arxiv.org/abs/2410.08102)
Token length: 1118
Summarized using gpt-4o-mini
Append: [StructRAG：基于结构化知识增强大语言模型的推理能力](https://arxiv.org/abs/2410.08815)
Token length: 1520
Summarized using gpt-4o-mini
Append: [通过KV预测减少变换器模型的首次输出时间](https://arxiv.org/abs/2410.08391)
append_entries: 3
Finish: 2024-10-14 09:01:20.518015
------------------------------------------------------
Started: 2024-10-14 12:13:01.745440
Existing_entries: 36
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-14 12:13:01.838307
------------------------------------------------------
Started: 2024-10-14 16:37:54.712380
Existing_entries: 36
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1023
Summarized using gpt-4o-mini
Append: [I-Max框架：提升文本到图像RFTs的分辨率潜力](https://arxiv.org/abs/2410.07536)
Token length: 1019
Summarized using gpt-4o-mini
Append: [ZeroComp：一种有效的零样本3D物体合成方法](https://arxiv.org/abs/2410.08168)
Token length: 1053
Summarized using gpt-4o-mini
Append: [Mentor-KD：多步推理能力的知识蒸馏方法](https://arxiv.org/abs/2410.09037)
Token length: 1200
Summarized using gpt-4o-mini
Append: [SAE Match：基于稀疏自编码器的神经网络层间特征对齐](https://arxiv.org/abs/2410.07656)
Token length: 1173
Summarized using gpt-4o-mini
Append: [DA-Code：针对代理的数据科学任务的代码生成基准](https://arxiv.org/abs/2410.07331)
append_entries: 5
Finish: 2024-10-14 16:38:40.822699
------------------------------------------------------
Started: 2024-10-14 17:34:59.285214
Existing_entries: 41
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 938
Summarized using gpt-4o-mini
Append: [MiRAGeNews数据集：对抗AI生成假新闻的多模态检测](https://arxiv.org/abs/2410.09045)
append_entries: 1
Finish: 2024-10-14 17:35:08.279838
------------------------------------------------------
Started: 2024-10-14 18:09:05.554135
Existing_entries: 42
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-14 18:09:05.674064
------------------------------------------------------
Started: 2024-10-14 21:00:37.323072
Existing_entries: 42
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-14 21:00:37.471781
------------------------------------------------------
Started: 2024-10-15 00:34:13.903689
Existing_entries: 42
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1116
Summarized using gpt-4o-mini
Append: [基于计划去噪的离散扩散框架DDPD](https://arxiv.org/abs/2410.06264)
Token length: 1412
Summarized using gpt-4o-mini
Append: [Synth-SONAR：基于扩散模型与GPT提示的声纳图像合成框架](https://arxiv.org/abs/2410.08612)
Token length: 1578
Summarized using gpt-4o-mini
Append: [GenARM：一种有效的自回归奖励模型用于无重训练的大型语言模型对齐](https://arxiv.org/abs/2410.08193)
Token length: 1266
Summarized using gpt-4o-mini
Append: [利用简单分层方法提高大型语言模型生成的多样性](https://arxiv.org/abs/2410.09038)
append_entries: 4
Finish: 2024-10-15 00:35:08.354631
------------------------------------------------------
Started: 2024-10-15 03:14:57.370987
Existing_entries: 46
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-15 03:14:57.533362
------------------------------------------------------
Started: 2024-10-15 06:10:28.515778
Existing_entries: 46
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1521
Summarized using gpt-4o-mini
Append: [Animate-X：针对各种角色类型的通用动画框架](https://arxiv.org/abs/2410.10306)
Token length: 1194
Summarized using gpt-4o-mini
Append: [MEGA-Bench：一种大规模多模态评估套件](https://arxiv.org/abs/2410.10563)
Summarization failed, append the original article
error: 'NoneType' object has no attribute 'group'. Line: 363.
Append: [TVBench: Redesigning Video-Language Evaluation](https://arxiv.org/abs/2410.07752)
Token length: 1337
Summarized using gpt-4o-mini
Append: [大规模数据选择在监督微调中的关键性研究](https://arxiv.org/abs/2410.09335)
Token length: 1445
Summarized using gpt-4o-mini
Append: [LOKI: 评估大型多模态模型Synthetic Data检测能力的新基准](https://arxiv.org/abs/2410.09732)
Token length: 1750
Summarized using gpt-4o-mini
Append: [VIF-RAG：提高检索增强生成系统指令跟随对齐的自动化框架](https://arxiv.org/abs/2410.09584)
Token length: 1696
Summarized using gpt-4o-mini
Append: [MMIE：评估大型视觉语言模型的交错多模态理解与生成的基准](https://arxiv.org/abs/2410.10139)
Token length: 1231
Summarized using gpt-4o-mini
Append: [针对大型语言模型的数学推理能力的奥林匹亚级基准测试](https://arxiv.org/abs/2410.07985)
append_entries: 8
Finish: 2024-10-15 06:12:23.323317
------------------------------------------------------
Started: 2024-10-15 09:01:06.479047
Existing_entries: 54
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1601
Summarized using gpt-4o-mini
Append: [LiveXiv：基于科学ArXiv论文的可扩展实时基准测试](https://arxiv.org/abs/2410.10783)
Token length: 915
Summarized using gpt-4o-mini
Append: [问题树（ToP）：解决复杂推理任务的新方法](https://arxiv.org/abs/2410.06634)
Token length: 1320
Summarized using gpt-4o-mini
Append: [基于动态最优控制的矩形流模型图像反演与编辑](https://arxiv.org/abs/2410.10792)
Token length: 1613
Summarized using gpt-4o-mini
Append: [长时记忆评估框架：提升聊天助手的记忆能力](https://arxiv.org/abs/2410.10813)
Token length: 1629
Summarized using gpt-4o-mini
Append: [TemporalBench：评估视频中的细粒度时间理解的新基准](https://arxiv.org/abs/2410.10818)
Token length: 1016
Summarized using gpt-4o-mini
Append: [自主操作的改进型3D扩散政策（iDP3）在多样化环境下的应用](https://arxiv.org/abs/2410.10803)
Token length: 1337
Summarized using gpt-4o-mini
Append: [Cavia：一种可控相机的多视角视频生成框架](https://arxiv.org/abs/2410.10774)
append_entries: 7
Finish: 2024-10-15 09:02:14.960054
------------------------------------------------------
Started: 2024-10-15 12:12:36.872253
Existing_entries: 61
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-15 12:12:36.986809
------------------------------------------------------
Started: 2024-10-15 15:00:52.415283
Existing_entries: 61
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-15 15:00:52.790455
------------------------------------------------------
Started: 2024-10-15 18:00:42.518383
Existing_entries: 61
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-15 18:00:42.627264
------------------------------------------------------
Started: 2024-10-15 21:01:00.850579
Existing_entries: 61
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1289
Summarized using gpt-4o-mini
Append: [大语言模型中的语言结构与内部电路的对应关系研究](https://arxiv.org/abs/2410.09223)
Token length: 1476
Summarized using gpt-4o-mini
Append: [VisRAG：面向多模态文档的视觉-语言检索增强生成](https://arxiv.org/abs/2410.10594)
Token length: 1111
Summarized using gpt-4o-mini
Append: [提升大型语言模型推理能力的训练方法](https://arxiv.org/abs/2410.10630)
Token length: 1570
Summarized using gpt-4o-mini
Append: [MMCOMPOSITION：评估大规模视觉-语言模型的组合能力的新基准](https://arxiv.org/abs/2410.09733)
append_entries: 4
Finish: 2024-10-15 21:01:31.996973
------------------------------------------------------
Started: 2024-10-16 00:33:52.596737
Existing_entries: 65
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-16 00:33:52.708729
------------------------------------------------------
Started: 2024-10-16 03:16:05.116811
Existing_entries: 65
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1283
Summarized using gpt-4o-mini
Append: [探索去规范化解码器中激活函数的优化](https://arxiv.org/abs/2410.09637)
append_entries: 1
Finish: 2024-10-16 03:16:11.950736
------------------------------------------------------
Started: 2024-10-16 06:01:02.163991
Existing_entries: 66
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1367
Summarized using gpt-4o-mini
Append: [MTU-Bench：一种多粒度的大语言模型工具使用基准](https://arxiv.org/abs/2410.11710)
Token length: 1794
Summarized using gpt-4o-mini
Append: [SecCodePLT：全面评估代码生成AI安全风险的平台](https://arxiv.org/abs/2410.11096)
Token length: 1460
Summarized using gpt-4o-mini
Append: [利用多语言大模型解决低资源语言医疗数据稀缺问题](https://arxiv.org/abs/2410.10626)
Token length: 1308
Summarized using gpt-4o-mini
Append: [基于空间和角度高斯表示的实时高质量照明与视图合成](https://arxiv.org/abs/2410.11419)
append_entries: 4
Finish: 2024-10-16 06:01:36.958851
------------------------------------------------------
Started: 2024-10-16 09:01:07.039308
Existing_entries: 70
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1356
Summarized using gpt-4o-mini
Append: [RoboDual：协同的通用与专业政策机器人系统](https://arxiv.org/abs/2410.08001)
Summarization failed, append the original article
error: Invalid \escape: line 4 column 179 (char 285). Line: 363.
Append: [What Matters in Transformers? Not All Attention is Needed](https://arxiv.org/abs/2406.15786)
Token length: 1121
Summarized using gpt-4o-mini
Append: [动态修正解码方法（DeCo）在多模态大型语言模型中的应用](https://arxiv.org/abs/2410.11779)
append_entries: 3
Finish: 2024-10-16 09:01:35.653736
------------------------------------------------------
Started: 2024-10-16 12:12:25.148412
Existing_entries: 73
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1339
Summarized using gpt-4o-mini
Append: [MoE LLMs在嵌入模型中的应用研究](https://arxiv.org/abs/2410.10814)
Token length: 1191
Summarized using gpt-4o-mini
Append: [扩散模型的高效性综述：理论与实践](https://arxiv.org/abs/2410.11795)
Token length: 1601
Summarized using gpt-4o-mini
Append: [LVD-2M：用于长视频生成的新型长拍视频数据集](https://arxiv.org/abs/2410.10816)
append_entries: 3
Finish: 2024-10-16 12:13:00.325377
------------------------------------------------------
Started: 2024-10-16 15:00:56.298169
Existing_entries: 76
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1776
Summarized using gpt-4o-mini
Append: [基于COCO的互动图像抠图数据集与方法研究](https://arxiv.org/abs/2410.06593)
Token length: 1243
Summarized using gpt-4o-mini
Append: [基于LLMtimesMapReduce框架的长文本处理研究](https://arxiv.org/abs/2410.09342)
Token length: 1104
Summarized using gpt-4o-mini
Append: [互惠增强效应：文本分类中词级与文本级分类的协同关系](https://arxiv.org/abs/2410.09745)
Token length: 1325
Summarized using gpt-4o-mini
Append: [SimBa：通过注入简约偏差来提升深度强化学习的网络规模](https://arxiv.org/abs/2410.09754)
append_entries: 4
Finish: 2024-10-16 15:02:09.536494
------------------------------------------------------
Started: 2024-10-16 18:01:06.580192
Existing_entries: 80
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-16 18:01:06.665630
------------------------------------------------------
Started: 2024-10-16 21:00:53.857265
Existing_entries: 80
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1716
Summarized using gpt-4o-mini
Append: [EchoPrime：一种多视角视频基础模型用于全面心脏超声学解读](https://arxiv.org/abs/2410.09704)
Token length: 1077
Summarized using gpt-4o-mini
Append: [NesTools：评估大型语言模型的嵌套工具学习能力的新基准](https://arxiv.org/abs/2410.11805)
Token length: 1230
Summarized using gpt-4o-mini
Append: [Agent-as-a-Judge框架：针对智能体系统的新评估方法](https://arxiv.org/abs/2410.10934)
append_entries: 3
Finish: 2024-10-16 21:01:33.623967
------------------------------------------------------
Started: 2024-10-17 00:33:43.255644
Existing_entries: 83
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1166
Summarized using gpt-4o-mini
Append: [MultiVENT 2.0：多语言事件驱动的视频检索基准](https://arxiv.org/abs/2410.11619)
append_entries: 1
Finish: 2024-10-17 00:33:51.739098
------------------------------------------------------
Started: 2024-10-17 03:14:03.622023
Existing_entries: 84
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-17 03:14:03.687082
------------------------------------------------------
Started: 2024-10-17 06:00:56.658104
Existing_entries: 84
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1255
Summarized using gpt-4o-mini
Append: [ProSA：评估大型语言模型提示敏感性的框架](https://arxiv.org/abs/2410.12405)
Token length: 1062
Summarized using gpt-4o-mini
Append: [基于模型亲缘关系的高效语言模型合并策略](https://arxiv.org/abs/2410.12613)
Token length: 1458
Summarized using gpt-4o-mini
Append: [DocLayout-YOLO：一种高速高准确率的文档布局分析方法](https://arxiv.org/abs/2410.12628)
Token length: 1665
Summarized using gpt-4o-mini
Append: [长文本对齐的文本到图像生成模型的优化方法 LongAlign](https://arxiv.org/abs/2410.11817)
Token length: 1390
Summarized using gpt-4o-mini
Append: [限制因素与问题影响：语言智能体规划能力的挑战](https://arxiv.org/abs/2410.12409)
append_entries: 5
Finish: 2024-10-17 06:01:30.407776
------------------------------------------------------
Started: 2024-10-17 09:00:39.029158
Existing_entries: 89
Fetching from https://rsshub.app/huggingface/daily-papers
Summarization failed, append the original article
error: Invalid \escape: line 4 column 103 (char 188). Line: 363.
Append: [Large Language Model Evaluation via Matrix Nuclear-Norm](https://arxiv.org/abs/2410.10672)
Token length: 1422
Summarized using gpt-4o-mini
Append: [VidEgoThink：评估自我视角视频理解能力的综合基准](https://arxiv.org/abs/2410.11623)
Token length: 1854
Summarized using gpt-4o-mini
Append: [ZipVL：针对大规模视觉语言模型的高效推理框架](https://arxiv.org/abs/2410.08584)
Token length: 1271
Summarized using gpt-4o-mini
Append: [多模态模型中的幻觉问题研究：挑战与前景](https://arxiv.org/abs/2410.12787)
Token length: 1899
Summarized using gpt-4o-mini
Append: [HumanEval-V：评估大型多模态模型的视觉理解与编程能力的基准](https://arxiv.org/abs/2410.12381)
Token length: 1380
Summarized using gpt-4o-mini
Append: [跨模态时间理解的新模型与数据集研究](https://arxiv.org/abs/2410.12109)
append_entries: 6
Finish: 2024-10-17 09:01:17.183413
------------------------------------------------------
Started: 2024-10-17 12:00:48.689242
Existing_entries: 95
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-17 12:00:48.840077
------------------------------------------------------
Started: 2024-10-17 15:00:33.468237
Existing_entries: 95
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1011
Summarized using gpt-4o-mini
Append: [动态词汇头（DyVo）提升稀疏检索模型的实体识别效果](https://arxiv.org/abs/2410.07722)
Token length: 693
Summarized using gpt-4o-mini
Append: [特征在不同文本领域之间的稳定性与转变研究](https://arxiv.org/abs/2410.12391)
Token length: 1037
Summarized using gpt-4o-mini
Append: [通过逆向强化学习解读大型语言模型的隐性奖励函数](https://arxiv.org/abs/2410.12491)
Token length: 1502
Summarized using gpt-4o-mini
Append: [神经形态变换（NeuMeta）：自适应神经网络的连续权重学习](https://arxiv.org/abs/2410.11878)
Token length: 1059
Summarized using gpt-4o-mini
Append: [基于连续时间的生成模型的稳定训练与快速采样](https://arxiv.org/abs/2410.11081)
Token length: 1195
Summarized using gpt-4o-mini
Append: [WorldMedQA-V：多语言多模态医疗基准测试数据集](https://arxiv.org/abs/2410.12722)
append_entries: 6
Finish: 2024-10-17 15:01:15.928914
------------------------------------------------------
Started: 2024-10-17 18:01:04.672294
Existing_entries: 101
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1908
Summarized using gpt-4o-mini
Append: [ChroKnowBench：评估大规模语言模型的时间知识积累](https://arxiv.org/abs/2410.09870)
Token length: 1613
Summarized using gpt-4o-mini
Append: [可控安全对齐框架：满足多样化安全需求的语言模型适应性](https://arxiv.org/abs/2410.08968)
append_entries: 2
Finish: 2024-10-17 18:01:18.527387
------------------------------------------------------
Started: 2024-10-17 21:01:08.606590
Existing_entries: 103
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1695
Summarized using gpt-4o-mini
Append: [语言模型校准：应对RLHF中的过度自信现象](https://arxiv.org/abs/2410.09724)
Token length: 1788
Summarized using gpt-4o-mini
Append: [优化潜在空间的图像生成模型：DiGIT的探索](https://arxiv.org/abs/2410.12490)
append_entries: 2
Finish: 2024-10-17 21:01:20.759734
------------------------------------------------------
Started: 2024-10-18 00:33:39.298857
Existing_entries: 105
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-18 00:33:39.390609
------------------------------------------------------
Started: 2024-10-18 03:14:48.880558
Existing_entries: 105
Fetching from https://rsshub.app/huggingface/daily-papers
Summarization failed, append the original article
error: 'NoneType' object has no attribute 'group'. Line: 363.
Append: [From Commands to Prompts: LLM-based Semantic File System for AIOS](https://arxiv.org/abs/2410.11843)
Summarization failed, append the original article
error: Invalid \escape: line 4 column 71 (char 169). Line: 363.
Append: [FLARE: Faithful Logic-Aided Reasoning and Exploration](https://arxiv.org/abs/2410.11900)
append_entries: 2
Finish: 2024-10-18 03:15:03.905972
------------------------------------------------------
Started: 2024-10-18 06:00:40.849342
Existing_entries: 107
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-18 06:00:40.995030
------------------------------------------------------
Started: 2024-10-18 09:00:50.409107
Existing_entries: 107
Fetching from https://rsshub.app/huggingface/daily-papers
Summarization failed, append the original article
error: Error code: 401 - {'error': {'err_code': -10004, 'message': 'Insufficient account balance. Create your own tool, for details please view 302.AI', 'message_cn': '账户余额不足，创建属于自己的工具，更多请访问 302.AI', 'message_jp': 'アカウント残高が不足しています。独自のツールを作成するには、302.AI をご覧ください。', 'type': 'api_error'}}. Line: 363.
Append: [MuVi: Video-to-Music Generation with Semantic Alignment and Rhythmic Synchronization](https://arxiv.org/abs/2410.12957)
Summarization failed, append the original article
error: Error code: 401 - {'error': {'err_code': -10004, 'message': 'Insufficient account balance. Create your own tool, for details please view 302.AI', 'message_cn': '账户余额不足，创建属于自己的工具，更多请访问 302.AI', 'message_jp': 'アカウント残高が不足しています。独自のツールを作成するには、302.AI をご覧ください。', 'type': 'api_error'}}. Line: 363.
Append: [Do LLMs Have Political Correctness? Analyzing Ethical Biases and Jailbreak Vulnerabilities in AI Systems](https://arxiv.org/abs/2410.13334)
Summarization failed, append the original article
error: Error code: 401 - {'error': {'err_code': -10004, 'message': 'Insufficient account balance. Create your own tool, for details please view 302.AI', 'message_cn': '账户余额不足，创建属于自己的工具，更多请访问 302.AI', 'message_jp': 'アカウント残高が不足しています。独自のツールを作成するには、302.AI をご覧ください。', 'type': 'api_error'}}. Line: 363.
Append: [Janus: Decoupling Visual Encoding for Unified Multimodal Understanding and Generation](https://arxiv.org/abs/2410.13848)
Summarization failed, append the original article
error: Error code: 401 - {'error': {'err_code': -10004, 'message': 'Insufficient account balance. Create your own tool, for details please view 302.AI', 'message_cn': '账户余额不足，创建属于自己的工具，更多请访问 302.AI', 'message_jp': 'アカウント残高が不足しています。独自のツールを作成するには、302.AI をご覧ください。', 'type': 'api_error'}}. Line: 363.
Append: [MixEval-X: Any-to-Any Evaluations from Real-World Data Mixtures](https://arxiv.org/abs/2410.13754)
Summarization failed, append the original article
error: Error code: 401 - {'error': {'err_code': -10004, 'message': 'Insufficient account balance. Create your own tool, for details please view 302.AI', 'message_cn': '账户余额不足，创建属于自己的工具，更多请访问 302.AI', 'message_jp': 'アカウント残高が不足しています。独自のツールを作成するには、302.AI をご覧ください。', 'type': 'api_error'}}. Line: 363.
Append: [MoH: Multi-Head Attention as Mixture-of-Head Attention](https://arxiv.org/abs/2410.11842)
Summarization failed, append the original article
error: Error code: 401 - {'error': {'err_code': -10004, 'message': 'Insufficient account balance. Create your own tool, for details please view 302.AI', 'message_cn': '账户余额不足，创建属于自己的工具，更多请访问 302.AI', 'message_jp': 'アカウント残高が不足しています。独自のツールを作成するには、302.AI をご覧ください。', 'type': 'api_error'}}. Line: 363.
Append: [SBI-RAG: Enhancing Math Word Problem Solving for Students through Schema-Based Instruction and Retrieval-Augmented Generation](https://arxiv.org/abs/2410.13293)
Summarization failed, append the original article
error: Error code: 401 - {'error': {'err_code': -10004, 'message': 'Insufficient account balance. Create your own tool, for details please view 302.AI', 'message_cn': '账户余额不足，创建属于自己的工具，更多请访问 302.AI', 'message_jp': 'アカウント残高が不足しています。独自のツールを作成するには、302.AI をご覧ください。', 'type': 'api_error'}}. Line: 363.
Append: [LoLDU: Low-Rank Adaptation via Lower-Diag-Upper Decomposition for Parameter-Efficient Fine-Tuning](https://arxiv.org/abs/2410.13618)
Summarization failed, append the original article
error: Error code: 401 - {'error': {'err_code': -10004, 'message': 'Insufficient account balance. Create your own tool, for details please view 302.AI', 'message_cn': '账户余额不足，创建属于自己的工具，更多请访问 302.AI', 'message_jp': 'アカウント残高が不足しています。独自のツールを作成するには、302.AI をご覧ください。', 'type': 'api_error'}}. Line: 363.
Append: [VidPanos: Generative Panoramic Videos from Casual Panning Videos](https://arxiv.org/abs/2410.13832)
Summarization failed, append the original article
error: Error code: 401 - {'error': {'err_code': -10004, 'message': 'Insufficient account balance. Create your own tool, for details please view 302.AI', 'message_cn': '账户余额不足，创建属于自己的工具，更多请访问 302.AI', 'message_jp': 'アカウント残高が不足しています。独自のツールを作成するには、302.AI をご覧ください。', 'type': 'api_error'}}. Line: 363.
Append: [Movie Gen: A Cast of Media Foundation Models](https://arxiv.org/abs/2410.13720)
Summarization failed, append the original article
error: Error code: 401 - {'error': {'err_code': -10004, 'message': 'Insufficient account balance. Create your own tool, for details please view 302.AI', 'message_cn': '账户余额不足，创建属于自己的工具，更多请访问 302.AI', 'message_jp': 'アカウント残高が不足しています。独自のツールを作成するには、302.AI をご覧ください。', 'type': 'api_error'}}. Line: 363.
Append: [BenTo: Benchmark Task Reduction with In-Context Transferability](https://arxiv.org/abs/2410.13804)
Summarization failed, append the original article
error: Error code: 401 - {'error': {'err_code': -10004, 'message': 'Insufficient account balance. Create your own tool, for details please view 302.AI', 'message_cn': '账户余额不足，创建属于自己的工具，更多请访问 302.AI', 'message_jp': 'アカウント残高が不足しています。独自のツールを作成するには、302.AI をご覧ください。', 'type': 'api_error'}}. Line: 363.
Append: [PopAlign: Diversifying Contrasting Patterns for a More Comprehensive Alignment](https://arxiv.org/abs/2410.13785)
Summarization failed, append the original article
error: Error code: 401 - {'error': {'err_code': -10004, 'message': 'Insufficient account balance. Create your own tool, for details please view 302.AI', 'message_cn': '账户余额不足，创建属于自己的工具，更多请访问 302.AI', 'message_jp': 'アカウント残高が不足しています。独自のツールを作成するには、302.AI をご覧ください。', 'type': 'api_error'}}. Line: 363.
Append: [MedMobile: A mobile-sized language model with expert-level clinical capabilities](https://arxiv.org/abs/2410.09019)
Summarization failed, append the original article
error: Error code: 401 - {'error': {'err_code': -10004, 'message': 'Insufficient account balance. Create your own tool, for details please view 302.AI', 'message_cn': '账户余额不足，创建属于自己的工具，更多请访问 302.AI', 'message_jp': 'アカウント残高が不足しています。独自のツールを作成するには、302.AI をご覧ください。', 'type': 'api_error'}}. Line: 363.
Append: [Harnessing Webpage UIs for Text-Rich Visual Understanding](https://arxiv.org/abs/2410.13824)
Summarization failed, append the original article
error: Error code: 401 - {'error': {'err_code': -10004, 'message': 'Insufficient account balance. Create your own tool, for details please view 302.AI', 'message_cn': '账户余额不足，创建属于自己的工具，更多请访问 302.AI', 'message_jp': 'アカウント残高が不足しています。独自のツールを作成するには、302.AI をご覧ください。', 'type': 'api_error'}}. Line: 363.
Append: [DreamVideo-2: Zero-Shot Subject-Driven Video Customization with Precise Motion Control](https://arxiv.org/abs/2410.13830)
Summarization failed, append the original article
error: Error code: 401 - {'error': {'err_code': -10004, 'message': 'Insufficient account balance. Create your own tool, for details please view 302.AI', 'message_cn': '账户余额不足，创建属于自己的工具，更多请访问 302.AI', 'message_jp': 'アカウント残高が不足しています。独自のツールを作成するには、302.AI をご覧ください。', 'type': 'api_error'}}. Line: 363.
Append: [MMed-RAG: Versatile Multimodal RAG System for Medical Vision Language Models](https://arxiv.org/abs/2410.13085)
Summarization failed, append the original article
error: Error code: 401 - {'error': {'err_code': -10004, 'message': 'Insufficient account balance. Create your own tool, for details please view 302.AI', 'message_cn': '账户余额不足，创建属于自己的工具，更多请访问 302.AI', 'message_jp': 'アカウント残高が不足しています。独自のツールを作成するには、302.AI をご覧ください。', 'type': 'api_error'}}. Line: 363.
Append: [A Unified View of Delta Parameter Editing in Post-Trained Large-Scale Models](https://arxiv.org/abs/2410.13841)
Summarization failed, append the original article
error: Error code: 401 - {'error': {'err_code': -10004, 'message': 'Insufficient account balance. Create your own tool, for details please view 302.AI', 'message_cn': '账户余额不足，创建属于自己的工具，更多请访问 302.AI', 'message_jp': 'アカウント残高が不足しています。独自のツールを作成するには、302.AI をご覧ください。', 'type': 'api_error'}}. Line: 363.
Append: [AERO: Softmax-Only LLMs for Efficient Private Inference](https://arxiv.org/abs/2410.13060)
Summarization failed, append the original article
error: Error code: 401 - {'error': {'err_code': -10004, 'message': 'Insufficient account balance. Create your own tool, for details please view 302.AI', 'message_cn': '账户余额不足，创建属于自己的工具，更多请访问 302.AI', 'message_jp': 'アカウント残高が不足しています。独自のツールを作成するには、302.AI をご覧ください。', 'type': 'api_error'}}. Line: 363.
Append: [Retrospective Learning from Interactions](https://arxiv.org/abs/2410.13852)
Summarization failed, append the original article
error: Error code: 401 - {'error': {'err_code': -10004, 'message': 'Insufficient account balance. Create your own tool, for details please view 302.AI', 'message_cn': '账户余额不足，创建属于自己的工具，更多请访问 302.AI', 'message_jp': 'アカウント残高が不足しています。独自のツールを作成するには、302.AI をご覧ください。', 'type': 'api_error'}}. Line: 363.
Append: [Failing Forward: Improving Generative Error Correction for ASR with Synthetic Data and Retrieval Augmentation](https://arxiv.org/abs/2410.13198)
Summarization failed, append the original article
error: Error code: 401 - {'error': {'err_code': -10004, 'message': 'Insufficient account balance. Create your own tool, for details please view 302.AI', 'message_cn': '账户余额不足，创建属于自己的工具，更多请访问 302.AI', 'message_jp': 'アカウント残高が不足しています。独自のツールを作成するには、302.AI をご覧ください。', 'type': 'api_error'}}. Line: 363.
Append: [FlatQuant: Flatness Matters for LLM Quantization](https://arxiv.org/abs/2410.09426)
append_entries: 20
Finish: 2024-10-18 09:01:04.850853
------------------------------------------------------
Started: 2024-10-18 12:12:12.180042
Existing_entries: 127
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1022
Summarized using gpt-4o-mini
Append: [Long-LRM：基于3D高斯重建的长序列图像大场景重建模型](https://arxiv.org/abs/2410.12781)
Token length: 1904
Summarized using gpt-4o-mini
Append: [中文图像含义理解基准CII-Bench的提出与评估](https://arxiv.org/abs/2410.13854)
Token length: 1611
Summarized using gpt-4o-mini
Append: [基于检索增强个性化的多模态大语言模型框架](https://arxiv.org/abs/2410.13360)
append_entries: 3
Finish: 2024-10-18 12:12:26.788308
------------------------------------------------------
Started: 2024-10-18 15:01:05.164358
Existing_entries: 130
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 997
Summarized using gpt-4o-mini
Append: [MobA：基于多模态大语言模型的移动助手](https://arxiv.org/abs/2410.13757)
Token length: 1640
Summarized using gpt-4o-mini
Append: [gamma-MoD: 提升多模态大语言模型计算效率的新策略](https://arxiv.org/abs/2410.13859)
Token length: 1427
Summarized using gpt-4o-mini
Append: [基于高质量数据的长输出能力模型调优研究](https://arxiv.org/abs/2410.10210)
Token length: 1470
Summarized using gpt-4o-mini
Append: [无指导自回归视觉生成的条件对比对齐方法](https://arxiv.org/abs/2410.09347)
Token length: 1337
Summarized using gpt-4o-mini
Append: [TransAgent：通过多源知识蒸馏提升视觉-语言基础模型](https://arxiv.org/abs/2410.12183)
append_entries: 5
Finish: 2024-10-18 15:01:42.129464
------------------------------------------------------
Started: 2024-10-18 18:00:41.924719
Existing_entries: 135
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1434
Summarized using gpt-4o-mini
Append: [Open Materials 2024: 大规模开放数据集及预训练模型的发布](https://arxiv.org/abs/2410.12771)
Token length: 1146
Summarized using gpt-4o-mini
Append: [推进语音大语言模型的五级发展路线图与评估基准](https://arxiv.org/abs/2410.13268)
append_entries: 2
Finish: 2024-10-18 18:00:52.699643
------------------------------------------------------
Started: 2024-10-18 21:00:43.720190
Existing_entries: 137
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1480
Summarized using gpt-4o-mini
Append: [JudgeBench：评估LLM基础评判模型的新基准](https://arxiv.org/abs/2410.12784)
Token length: 1081
Summarized using gpt-4o-mini
Append: [WorldCuisines：多元文化的视觉问答基准](https://arxiv.org/abs/2410.12705)
append_entries: 2
Finish: 2024-10-18 21:00:52.466612
------------------------------------------------------
Started: 2024-10-19 00:33:18.154426
Existing_entries: 139
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1279
Summarized using gpt-4o-mini
Append: [探索视觉自回归模型的规模化问题：连续与离散代币、随机与固定生成顺序的影响](https://arxiv.org/abs/2410.13863)
append_entries: 1
Finish: 2024-10-19 00:33:23.375445
------------------------------------------------------
Started: 2024-10-19 03:12:24.355053
Existing_entries: 140
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-19 03:12:24.532868
------------------------------------------------------
Started: 2024-10-19 06:00:44.883462
Existing_entries: 140
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1497
Summarized using gpt-4o-mini
Append: [o1模型在推理能力提升中的研究：对比测试时计算方法的深入分析](https://arxiv.org/abs/2410.13639)
append_entries: 1
Finish: 2024-10-19 06:00:51.621335
------------------------------------------------------
Started: 2024-10-19 09:00:35.455791
Existing_entries: 141
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-19 09:00:35.541518
------------------------------------------------------
Started: 2024-10-19 12:11:19.465294
Existing_entries: 141
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-19 12:11:19.568134
------------------------------------------------------
Started: 2024-10-19 15:00:23.909747
Existing_entries: 141
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-19 15:00:24.039566
------------------------------------------------------
Started: 2024-10-19 18:00:49.367750
Existing_entries: 141
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-19 18:00:49.537880
------------------------------------------------------
Started: 2024-10-19 21:00:51.454359
Existing_entries: 141
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-19 21:00:51.540823
------------------------------------------------------
Started: 2024-10-20 00:37:29.538104
Existing_entries: 141
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-20 00:37:29.662534
------------------------------------------------------
Started: 2024-10-20 03:18:38.130370
Existing_entries: 141
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-20 03:18:38.248015
------------------------------------------------------
Started: 2024-10-20 06:00:58.507365
Existing_entries: 141
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-20 06:00:58.583893
------------------------------------------------------
Started: 2024-10-20 09:00:27.062497
Existing_entries: 141
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-20 09:00:27.227918
------------------------------------------------------
Started: 2024-10-20 12:12:09.718215
Existing_entries: 141
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-20 12:12:09.801011
------------------------------------------------------
Started: 2024-10-20 15:00:43.100477
Existing_entries: 141
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-20 15:00:43.205081
------------------------------------------------------
Started: 2024-10-20 18:00:50.224926
Existing_entries: 141
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-20 18:00:50.396642
------------------------------------------------------
Started: 2024-10-20 21:01:07.479631
Existing_entries: 141
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-20 21:01:07.698831
------------------------------------------------------
Started: 2024-10-21 00:35:29.947071
Existing_entries: 141
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-21 00:35:30.085409
------------------------------------------------------
Started: 2024-10-21 03:17:54.106518
Existing_entries: 141
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-21 03:17:54.284579
------------------------------------------------------
Started: 2024-10-21 06:11:11.411711
Existing_entries: 141
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1401
Summarized using gpt-4o-mini
Append: [MagicTailor：组件可控的个性化文本到图像生成](https://arxiv.org/abs/2410.13370)
append_entries: 1
Finish: 2024-10-21 06:11:16.325726
------------------------------------------------------
Started: 2024-10-21 09:00:40.393701
Existing_entries: 142
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1762
Summarized using gpt-4o-mini
Append: [自我演化的AI训练：借助扩散模型改善低质量数据学习](https://arxiv.org/abs/2410.13674)
append_entries: 1
Finish: 2024-10-21 09:00:48.012855
------------------------------------------------------
Started: 2024-10-21 12:00:58.790313
Existing_entries: 143
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1161
Summarized using gpt-4o-mini
Append: [训练方法对神经网络层重要性的影响](https://arxiv.org/abs/2410.14470)
Token length: 1900
Summarized using gpt-4o-mini
Append: [视觉语言模型的挑战：自然图像中的对抗样本研究](https://arxiv.org/abs/2410.14669)
Token length: 1383
Summarized using gpt-4o-mini
Append: [DAWN：非自回归扩散模型的动态头像生成框架](https://arxiv.org/abs/2410.13726)
Token length: 1899
Summarized using gpt-4o-mini
Append: [关于强化学习中人为反馈的边际损失问题及其影响](https://arxiv.org/abs/2410.13828)
Token length: 1170
Summarized using gpt-4o-mini
Append: [用户中心的金融专业能力评估基准：UCFE](https://arxiv.org/abs/2410.14059)
Token length: 1799
Summarized using gpt-4o-mini
Append: [DPLM-2：一种多模态蛋白质基础模型](https://arxiv.org/abs/2410.13782)
Token length: 1376
Summarized using gpt-4o-mini
Append: [机器生成文本检测器的评估方法研究](https://arxiv.org/abs/2410.14677)
Token length: 1646
Summarized using gpt-4o-mini
Append: [基于学习门控的稀疏注意力机制SeerAttention](https://arxiv.org/abs/2410.13276)
Token length: 1279
Summarized using gpt-4o-mini
Append: [利用KeyNMF研究中国媒体中的信息动态：以2024年欧洲议会选举为例](https://arxiv.org/abs/2410.12791)
Token length: 1327
Summarized using gpt-4o-mini
Append: [世界模型增强的自主网络代理研究](https://arxiv.org/abs/2410.13232)
append_entries: 10
Finish: 2024-10-21 12:02:06.588014
------------------------------------------------------
Started: 2024-10-21 15:00:59.223800
Existing_entries: 153
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1893
Summarized using gpt-4o-mini
Append: [大语言模型的自我预测：内省能力的探索](https://arxiv.org/abs/2410.13787)
append_entries: 1
Finish: 2024-10-21 15:01:08.662994
------------------------------------------------------
Started: 2024-10-21 18:09:40.496368
Existing_entries: 154
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 712
Summarized using gpt-4o-mini
Append: [Shakti：为边缘设备优化的高效语言模型](https://arxiv.org/abs/2410.11331)
Token length: 1838
Summarized using gpt-4o-mini
Append: [灵活视觉变换器 FiTv2：一种针对任意分辨率图像生成的变换器架构](https://arxiv.org/abs/2410.13925)
Token length: 1306
Summarized using gpt-4o-mini
Append: [Mini-Omni2：一款多模态视觉音频助手](https://arxiv.org/abs/2410.11190)
Token length: 1278
Summarized using gpt-4o-mini
Append: [混合自回归变换器（HART）：一种高效的图像生成模型](https://arxiv.org/abs/2410.10812)
Token length: 1075
Summarized using gpt-4o-mini
Append: [BiGR：一种基于紧凑二进制潜在代码的条件图像生成模型](https://arxiv.org/abs/2410.14672)
Token length: 1350
Summarized using gpt-4o-mini
Append: [Montessori-Instruct：针对学生学习过程的合成数据框架](https://arxiv.org/abs/2410.14208)
Token length: 1413
Summarized using gpt-4o-mini
Append: [平衡式说服训练：提升模型对正负说服的适应性](https://arxiv.org/abs/2410.14596)
append_entries: 7
Finish: 2024-10-21 18:10:25.775042
------------------------------------------------------
Started: 2024-10-21 21:00:36.984282
Existing_entries: 161
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-21 21:00:37.126975
------------------------------------------------------
Started: 2024-10-22 00:34:27.340533
Existing_entries: 161
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-22 00:34:27.466951
------------------------------------------------------
Started: 2024-10-22 03:14:43.049187
Existing_entries: 161
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-22 03:14:43.131013
------------------------------------------------------
Started: 2024-10-22 06:00:40.122315
Existing_entries: 161
Fetching from https://rsshub.app/huggingface/daily-papers
Summarization failed, append the original article
error: 'NoneType' object has no attribute 'group'. Line: 363.
Append: [RM-Bench: Benchmarking Reward Models of Language Models with Subtlety and Style](https://arxiv.org/abs/2410.16184)
Token length: 1054
Summarized using gpt-4o-mini
Append: [FrugalNeRF：高效的少样本神经辐射场框架](https://arxiv.org/abs/2410.16271)
Token length: 1486
Summarized using gpt-4o-mini
Append: [Meta-Chunking: 基于深层语义关系的文本分块方法](https://arxiv.org/abs/2410.12788)
Token length: 1240
Summarized using gpt-4o-mini
Append: [Pangea：面向多语言和多文化背景的多模态大语言模型](https://arxiv.org/abs/2410.16153)
Token length: 1563
Summarized using gpt-4o-mini
Append: [跨语言自动评估套件：Hercule的设计与实现](https://arxiv.org/abs/2410.13394)
Token length: 1173
Summarized using gpt-4o-mini
Append: [PUMA：赋能统一的多模态大语言模型的多粒度视觉生成](https://arxiv.org/abs/2410.13861)
Token length: 1463
Summarized using gpt-4o-mini
Append: [CompassJudger-1：开源全能评估模型及其基准测试](https://arxiv.org/abs/2410.16256)
Token length: 1817
Summarized using gpt-4o-mini
Append: [融合上下文信息的综合语音标记器DM-Codec的研究](https://arxiv.org/abs/2410.15017)
Token length: 1626
Summarized using gpt-4o-mini
Append: [Baichuan Alignment：提升AI模型对齐技术的深入分析](https://arxiv.org/abs/2410.14940)
Token length: 1150
Summarized using gpt-4o-mini
Append: [SemiEvol：一种半监督微调框架用于大规模语言模型的适应性](https://arxiv.org/abs/2410.14745)
Token length: 1334
Summarized using gpt-4o-mini
Append: [利用大型语言模型评估认知行为疗法的潜力：CBT-BENCH基准的提出](https://arxiv.org/abs/2410.13218)
append_entries: 11
Finish: 2024-10-22 06:01:49.854019
------------------------------------------------------
Started: 2024-10-22 09:00:48.768171
Existing_entries: 172
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1878
Summarized using gpt-4o-mini
Append: [面向长指令的长距离依赖样本选择框架 GATEAU](https://arxiv.org/abs/2410.15633)
Token length: 1142
Summarized using gpt-4o-mini
Append: [AutoTrain Advanced：简化训练自定义数据集的开源工具](https://arxiv.org/abs/2410.15735)
Token length: 1232
Summarized using gpt-4o-mini
Append: [预训练蒸馏：扩大知识蒸馏在大语言模型中的应用](https://arxiv.org/abs/2410.16215)
Token length: 1796
Summarized using gpt-4o-mini
Append: [SAM2Long：面向复杂长视频的改进训练自由视频目标分割策略](https://arxiv.org/abs/2410.16268)
append_entries: 4
Finish: 2024-10-22 09:01:18.577872
------------------------------------------------------
Started: 2024-10-22 12:12:55.557953
Existing_entries: 176
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1078
Summarized using gpt-4o-mini
Append: [基于大型语言模型的连续马尔可夫决策过程动态预测](https://arxiv.org/abs/2410.11711)
Token length: 1411
Summarized using gpt-4o-mini
Append: [Alchemy：通过符号变换合成形式化定理的框架](https://arxiv.org/abs/2410.15748)
append_entries: 2
Finish: 2024-10-22 12:13:07.442153
------------------------------------------------------
Started: 2024-10-22 15:01:04.661055
Existing_entries: 178
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1364
Summarized using gpt-4o-mini
Append: [简约模型与上下文学习：关联探索与改进建议](https://arxiv.org/abs/2410.14086)
Token length: 1276
Summarized using gpt-4o-mini
Append: [基于动态深度的混合层跳过模型](https://arxiv.org/abs/2410.13184)
Summarization failed, append the original article
error: 'NoneType' object has no attribute 'group'. Line: 363.
Append: [Hallucination Detox: Sensitive Neuron Dropout (SeND) for Large Language Model Training](https://arxiv.org/abs/2410.15460)
Token length: 1280
Summarized using gpt-4o-mini
Append: [Ichigo：一种基于混合模态的语音与文本处理模型](https://arxiv.org/abs/2410.15316)
append_entries: 4
Finish: 2024-10-22 15:01:39.432236
------------------------------------------------------
Started: 2024-10-22 18:01:07.308263
Existing_entries: 182
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-22 18:01:07.493789
------------------------------------------------------
Started: 2024-10-22 21:01:22.546924
Existing_entries: 182
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1644
Summarized using gpt-4o-mini
Append: [寻找模仿阈值：对文本到图像模型版权侵权的研究](https://arxiv.org/abs/2410.15002)
Token length: 1115
Summarized using gpt-4o-mini
Append: [Agent-to-Sim (ATS)：从视频学习3D代理的交互行为模型](https://arxiv.org/abs/2410.16259)
append_entries: 2
Finish: 2024-10-22 21:01:37.415156
------------------------------------------------------
Started: 2024-10-23 00:33:46.986033
Existing_entries: 184
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-23 00:33:47.128121
------------------------------------------------------
Started: 2024-10-23 03:14:01.644365
Existing_entries: 184
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-23 03:14:01.847907
------------------------------------------------------
Started: 2024-10-23 06:00:48.196655
Existing_entries: 184
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-23 06:00:48.310171
------------------------------------------------------
Started: 2024-10-23 09:00:48.797729
Existing_entries: 184
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-23 09:00:48.928682
------------------------------------------------------
Started: 2024-10-23 12:12:45.107375
Existing_entries: 184
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1355
Summarized using gpt-4o-mini
Append: [自我引导优化：一种无人工标注的偏好信号生成方法](https://arxiv.org/abs/2410.17131)
Token length: 997
Summarized using gpt-4o-mini
Append: [SpectroMotion：结合3D高斯点云与物理基础渲染的动态高光场景重建新方法](https://arxiv.org/abs/2410.17249)
Token length: 1876
Summarized using gpt-4o-mini
Append: [PyramidDrop：提高大型视觉语言模型效率的视觉冗余降低策略](https://arxiv.org/abs/2410.17247)
Token length: 1440
Summarized using gpt-4o-mini
Append: [JMMMU：首个针对日语的大规模多模态模型基准测试](https://arxiv.org/abs/2410.17250)
Token length: 1646
Summarized using gpt-4o-mini
Append: [EvoPress：一种适应性动态压缩的广义框架](https://arxiv.org/abs/2410.14649)
Token length: 1602
Summarized using gpt-4o-mini
Append: [MiniPLM：高效灵活的知识蒸馏框架用于预训练语言模型](https://arxiv.org/abs/2410.17215)
append_entries: 6
Finish: 2024-10-23 12:13:19.987115
------------------------------------------------------
Started: 2024-10-23 15:00:28.676285
Existing_entries: 190
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-23 15:00:28.813041
------------------------------------------------------
Started: 2024-10-23 18:00:45.621722
Existing_entries: 190
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1283
Summarized using gpt-4o-mini
Append: [数学推理参数的隔离与干预：Math Neurosurgery 方法](https://arxiv.org/abs/2410.16930)
Token length: 1478
Summarized using gpt-4o-mini
Append: [减轻长距离视觉-指令交互影响的新方法：同心因果注意力](https://arxiv.org/abs/2410.15926)
append_entries: 2
Finish: 2024-10-23 18:01:01.990042
------------------------------------------------------
Started: 2024-10-23 21:01:00.223875
Existing_entries: 192
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 955
Summarized using gpt-4o-mini
Append: [xGen-MM-Vid：高效捕捉视频时序信息的多模态语言模型](https://arxiv.org/abs/2410.16267)
Token length: 1291
Summarized using gpt-4o-mini
Append: [增强视觉语言模型的推理能力：基于详细理由的训练与强化学习](https://arxiv.org/abs/2410.16198)
append_entries: 2
Finish: 2024-10-23 21:01:16.634407
------------------------------------------------------
Started: 2024-10-24 00:33:52.232115
Existing_entries: 194
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1331
Summarized using gpt-4o-mini
Append: [3DGS-增强器：提升3D高斯点云渲染质量的创新管道](https://arxiv.org/abs/2410.16266)
append_entries: 1
Finish: 2024-10-24 00:33:58.665625
------------------------------------------------------
Started: 2024-10-24 03:13:55.973287
Existing_entries: 195
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1003
Summarized using gpt-4o-mini
Append: [基于大型语言模型的复合人工智能系统优化研究](https://arxiv.org/abs/2410.16392)
Token length: 1025
Summarized using gpt-4o-mini
Append: [智能内窥镜技术在结肠镜检查中的前沿探索](https://arxiv.org/abs/2410.17241)
append_entries: 2
Finish: 2024-10-24 03:14:11.928364
------------------------------------------------------
Started: 2024-10-24 06:10:40.136276
Existing_entries: 197
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1631
Summarized using gpt-4o-mini
Append: [多图像增强直接偏好优化(MIA-DPO)在视觉偏好对齐中的应用](https://arxiv.org/abs/2410.17637)
Token length: 1320
Summarized using gpt-4o-mini
Append: [基于自回归语言模型的扩散语言模型构建与评估](https://arxiv.org/abs/2410.17891)
Token length: 1708
Summarized using gpt-4o-mini
Append: [面向世界模拟器的双重评估框架：WorldSimBench](https://arxiv.org/abs/2410.18072)
append_entries: 3
Finish: 2024-10-24 06:10:57.345370
------------------------------------------------------
Started: 2024-10-24 09:00:56.797737
Existing_entries: 200
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1091
Summarized using gpt-4o-mini
Append: [基于轻量级多模态应用控制的手机应用代理架构](https://arxiv.org/abs/2410.17883)
append_entries: 1
Finish: 2024-10-24 09:01:03.583182
------------------------------------------------------
Started: 2024-10-24 12:00:43.059523
Existing_entries: 201
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-24 12:00:43.158270
------------------------------------------------------
Started: 2024-10-24 15:00:51.942814
Existing_entries: 201
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1409
Summarized using gpt-4o-mini
Append: [多语言奖励模型评估基准 M-RewardBench 的构建与分析](https://arxiv.org/abs/2410.15522)
Token length: 1474
Summarized using gpt-4o-mini
Append: [基于合成数据集的直接偏好优化推动文本到图像模型的进步](https://arxiv.org/abs/2410.18013)
Token length: 1297
Summarized using gpt-4o-mini
Append: [针对多模态大语言模型的TP-Eval评估框架](https://arxiv.org/abs/2410.18071)
append_entries: 3
Finish: 2024-10-24 15:01:15.500663
------------------------------------------------------
Started: 2024-10-24 18:01:03.669765
Existing_entries: 204
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1809
Summarized using gpt-4o-mini
Append: [DynamicCity：一种动态城市四维激光雷达生成框架](https://arxiv.org/abs/2410.18084)
Token length: 969
Summarized using gpt-4o-mini
Append: [MedINST: 一种多领域多任务的生物医学指令元数据集](https://arxiv.org/abs/2410.13458)
Token length: 1144
Summarized using gpt-4o-mini
Append: [ARKit LabelMaker：首个大规模真实世界3D数据集及其语义标注](https://arxiv.org/abs/2410.13924)
append_entries: 3
Finish: 2024-10-24 18:01:28.143856
------------------------------------------------------
Started: 2024-10-24 21:00:42.550955
Existing_entries: 207
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-24 21:00:42.649308
------------------------------------------------------
Started: 2024-10-25 00:34:23.009846
Existing_entries: 207
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1282
Summarized using gpt-4o-mini
Append: [LongVU: 一种用于长视频理解的时空自适应压缩机制](https://arxiv.org/abs/2410.17434)
append_entries: 1
Finish: 2024-10-25 00:34:29.271414
------------------------------------------------------
Started: 2024-10-25 03:16:02.411213
Existing_entries: 208
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1417
Summarized using gpt-4o-mini
Append: [基于价值引导的策略引导：提升通用机器人政策的部署性能](https://arxiv.org/abs/2410.13816)
Token length: 1376
Summarized using gpt-4o-mini
Append: [大视野合成模型 (LVSM)：一种可扩展的新视角合成方法](https://arxiv.org/abs/2410.17242)
append_entries: 2
Finish: 2024-10-25 03:16:16.065174
------------------------------------------------------
Started: 2024-10-25 06:00:43.427390
Existing_entries: 210
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-25 06:00:43.510312
------------------------------------------------------
Started: 2024-10-25 09:01:04.595895
Existing_entries: 210
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1597
Summarized using gpt-4o-mini
Append: [W-Bench：评估图像水印在高级编辑技巧下的鲁棒性与VINE方法](https://arxiv.org/abs/2410.18775)
Token length: 1319
Summarized using gpt-4o-mini
Append: [多草稿投机采样的优化选择方案研究](https://arxiv.org/abs/2410.18234)
Token length: 1393
Summarized using gpt-4o-mini
Append: [ScaleQuest: 可扩展的数学推理数据合成方法](https://arxiv.org/abs/2410.18693)
Token length: 1495
Summarized using gpt-4o-mini
Append: [LOGO：通过高效偏好优化实现长上下文对齐的训练策略](https://arxiv.org/abs/2410.18533)
Token length: 1263
Summarized using gpt-4o-mini
Append: [基于分块计算的对比损失优化策略](https://arxiv.org/abs/2410.17243)
Token length: 1265
Summarized using gpt-4o-mini
Append: [STRING：提升大语言模型长上下文有效性的新方法](https://arxiv.org/abs/2410.18745)
Token length: 1256
Summarized using gpt-4o-mini
Append: [Framer：互动帧插值与创意过渡](https://arxiv.org/abs/2410.18978)
Token length: 840
Summarized using gpt-4o-mini
Append: [通过数据中心化技术提升大语言模型的奖励建模](https://arxiv.org/abs/2410.18451)
Token length: 822
Summarized using gpt-4o-mini
Append: [CCI3.0-HQ：优化数据质量的高质量汉语语料库](https://arxiv.org/abs/2410.18505)
Token length: 1540
Summarized using gpt-4o-mini
Append: [模型编辑对语言模型表现的影响评估](https://arxiv.org/abs/2410.18785)
Token length: 1179
Summarized using gpt-4o-mini
Append: [一致性模型的稳定一致性调优](https://arxiv.org/abs/2410.18958)
Token length: 1440
Summarized using gpt-4o-mini
Append: [无界：基于生成模型的无尽角色生活模拟游戏](https://arxiv.org/abs/2410.18975)
append_entries: 12
Finish: 2024-10-25 09:05:14.591110
------------------------------------------------------
Started: 2024-10-25 12:00:40.196859
Existing_entries: 222
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1916
Summarized using gpt-4o-mini
Append: [ADEM-VL：一种高效的视觉语言模型融合方法](https://arxiv.org/abs/2410.17779)
Token length: 1358
Summarized using gpt-4o-mini
Append: [为阿拉伯语大型多模态模型开发的综合评估基准——CAMEL-Bench](https://arxiv.org/abs/2410.18976)
Token length: 1452
Summarized using gpt-4o-mini
Append: [成本高效的复杂图表问答生成方法——Code-as-Intermediary Translation](https://arxiv.org/abs/2410.18798)
Token length: 1063
Summarized using gpt-4o-mini
Append: [Waffle：一种提升大型语言模型HTML结构理解能力的新策略](https://arxiv.org/abs/2410.18362)
Token length: 1584
Summarized using gpt-4o-mini
Append: [HalluEditBench：基于真实幻觉的知识编辑方法基准评估](https://arxiv.org/abs/2410.16251)
Token length: 1404
Summarized using gpt-4o-mini
Append: [基于注意力机制的人类运动生成交互编辑研究](https://arxiv.org/abs/2410.18977)
Token length: 1336
Summarized using gpt-4o-mini
Append: [大型语言模型在算术学习中的符号学习能力研究](https://arxiv.org/abs/2410.15580)
append_entries: 7
Finish: 2024-10-25 12:01:39.598921
------------------------------------------------------
Started: 2024-10-25 15:00:38.467702
Existing_entries: 229
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1165
Summarized using gpt-4o-mini
Append: [Taipan：高效处理超长上下文的混合架构](https://arxiv.org/abs/2410.18572)
Token length: 1301
Summarized using gpt-4o-mini
Append: [基于残差值的变换器：ResFormer与SVFormer](https://arxiv.org/abs/2410.17897)
append_entries: 2
Finish: 2024-10-25 15:00:50.980554
------------------------------------------------------
Started: 2024-10-25 18:00:41.652597
Existing_entries: 231
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1583
Summarized using gpt-4o-mini
Append: [数据扩展在机器人操控中的应用研究](https://arxiv.org/abs/2410.18647)
append_entries: 1
Finish: 2024-10-25 18:00:50.486086
------------------------------------------------------
Started: 2024-10-25 21:01:00.679094
Existing_entries: 232
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 634
Summarized using gpt-4o-mini
Append: [基于文本到图像扩散模型的视频对象分割方法研究](https://arxiv.org/abs/2410.18538)
Token length: 1256
Summarized using gpt-4o-mini
Append: [利用稀疏自编码器解决大语言模型中的知识冲突](https://arxiv.org/abs/2410.15999)
Token length: 1167
Summarized using gpt-4o-mini
Append: [通过对比检索头减少大型语言模型的幻觉](https://arxiv.org/abs/2410.18860)
append_entries: 3
Finish: 2024-10-25 21:01:15.696852
------------------------------------------------------
Started: 2024-10-26 00:33:14.915253
Existing_entries: 235
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1032
Summarized using gpt-4o-mini
Append: [Pantograph：基于 Lean 4 的机器辅助定理证明工具](https://arxiv.org/abs/2410.16429)
Token length: 1796
Summarized using gpt-4o-mini
Append: [ZIP-FIT：基于压缩测量任务对齐的数据选择框架](https://arxiv.org/abs/2410.18194)
Token length: 1585
Summarized using gpt-4o-mini
Append: [变压器模型及生成AI关键组件的数学问题与概率优化分析](https://arxiv.org/abs/2410.18441)
Token length: 1361
Summarized using gpt-4o-mini
Append: [异步强化学习人类反馈的研究与实践](https://arxiv.org/abs/2410.18252)
append_entries: 4
Finish: 2024-10-26 00:33:41.745713
------------------------------------------------------
Started: 2024-10-26 03:11:23.743815
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-26 03:11:23.913916
------------------------------------------------------
Started: 2024-10-26 06:00:39.381036
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-26 06:00:39.481202
------------------------------------------------------
Started: 2024-10-26 09:00:38.390047
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-26 09:00:38.562716
------------------------------------------------------
Started: 2024-10-26 12:11:35.981385
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-26 12:11:36.062345
------------------------------------------------------
Started: 2024-10-26 15:01:01.307591
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-26 15:01:01.481154
------------------------------------------------------
Started: 2024-10-26 18:01:00.930603
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-26 18:01:01.108747
------------------------------------------------------
Started: 2024-10-26 21:00:36.521227
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-26 21:00:36.680799
------------------------------------------------------
Started: 2024-10-27 00:37:19.765373
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-27 00:37:19.843331
------------------------------------------------------
Started: 2024-10-27 03:17:46.987945
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-27 03:17:47.160417
------------------------------------------------------
Started: 2024-10-27 06:00:50.996516
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-27 06:00:51.156568
------------------------------------------------------
Started: 2024-10-27 09:00:27.087205
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-27 09:00:27.245957
------------------------------------------------------
Started: 2024-10-27 12:11:06.138736
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-27 12:11:06.251998
------------------------------------------------------
Started: 2024-10-27 15:00:45.886877
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-27 15:00:46.006186
------------------------------------------------------
Started: 2024-10-27 16:53:24.315722
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-27 16:53:24.565096
------------------------------------------------------
Started: 2024-10-27 17:05:57.362623
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-27 17:05:57.461139
------------------------------------------------------
Started: 2024-10-27 17:15:50.848531
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-27 17:15:50.969125
------------------------------------------------------
Started: 2024-10-27 17:19:19.714426
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-27 17:19:19.886190
------------------------------------------------------
Started: 2024-10-27 17:27:48.236116
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-27 17:27:48.411235
------------------------------------------------------
Started: 2024-10-27 18:00:38.951843
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-27 18:00:39.081952
------------------------------------------------------
Started: 2024-10-27 21:00:40.575524
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-27 21:00:40.740796
------------------------------------------------------
Started: 2024-10-27 23:53:47.513193
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-27 23:53:47.636391
------------------------------------------------------
Started: 2024-10-28 00:36:23.436752
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-28 00:36:23.562490
------------------------------------------------------
Started: 2024-10-28 02:07:27.483847
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-28 02:07:27.582051
------------------------------------------------------
Started: 2024-10-28 02:19:20.658486
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-28 02:19:20.781491
------------------------------------------------------
Started: 2024-10-28 02:41:35.494299
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-28 02:41:35.603278
------------------------------------------------------
Started: 2024-10-28 03:18:54.870136
Existing_entries: 239
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1375
Summarized using gpt-4o-mini
Append: [通过未标记轨迹数据学习强化学习中的高效探索策略](https://arxiv.org/abs/2410.18076)
Token length: 837
Summarized using gpt-4o-mini
Append: [Infinity-MM: 规模化多模态指令数据集与高性能模型的突破](https://arxiv.org/abs/2410.18558)
Token length: 1289
Summarized using gpt-4o-mini
Append: [MMAU：评估多模态音频理解模型的新基准](https://arxiv.org/abs/2410.19168)
Token length: 1405
Summarized using gpt-4o-mini
Append: [基于大语言模型的ECG图像解读新工具PULSE的开发与评估](https://arxiv.org/abs/2410.19008)
append_entries: 4
Finish: 2024-10-28 03:19:13.737940
------------------------------------------------------
Started: 2024-10-28 06:00:38.852276
Existing_entries: 243
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-28 06:00:39.001576
------------------------------------------------------
Started: 2024-10-28 09:01:03.937673
Existing_entries: 243
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1647
Summarized using gpt-4o-mini
Append: [视觉-语言模型在身体决策中的应用和挑战](https://arxiv.org/abs/2410.17856)
Token length: 1158
Summarized using gpt-4o-mini
Append: [基于Prereq-Tune的LLM幻觉减少策略研究](https://arxiv.org/abs/2410.19290)
Token length: 1851
Summarized using gpt-4o-mini
Append: [结合人类反馈与语言模型提升偏好注释质量的路由框架](https://arxiv.org/abs/2410.19133)
Token length: 1294
Summarized using gpt-4o-mini
Append: [FasterCache：加速视频扩散模型推断的新策略](https://arxiv.org/abs/2410.19355)
append_entries: 4
Finish: 2024-10-28 09:01:26.509937
------------------------------------------------------
Started: 2024-10-28 12:13:28.766483
Existing_entries: 247
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "Reflection-Bench：评估大型语言模型反射能力的基准",
  "keyword": ["反射能力", "大型语言模型", "基准测试"],
  "short_summary": "本文介绍了Reflection-Bench基准，用于评估大型语言模型的反射能力。",
  "summary": "本文提出了Reflection-Bench，这是一个全面的基准测试，旨在评估大型语言模型（LLMs）在反射能力方面的表现。反射能力是智能系统与环境互动时适应信念或行为的关键能力，涉及感知、记忆、信念更新、决策、预测、反事实思维和元反思等核心认知功能。通过评估13个知名LLMs的表现，例如OpenAI o1和GPT-4，结果显示当前LLMs在反射能力上仍显不足。我们分析了这些结果的原因，并探讨了未来研究的潜在方向。Reflection-Bench为开发能与环境可靠互动的AI提供了评价工具和灵感，相关数据和代码可在https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 279 (char 431). Line: 406.
Append: [Reflection-Bench: probing AI intelligence with reflection](https://arxiv.org/abs/2410.16270)
Token length: 1086
Summarized using gpt-4o-mini
Append: [SALAD：一种基于令牌的连续表示的零-shot文本到语音模型](https://arxiv.org/abs/2410.16048)
Token length: 1675
Summarized using gpt-4o-mini
Append: [探究tokenization对大型语言模型计数能力的影响](https://arxiv.org/abs/2410.19730)
append_entries: 3
Finish: 2024-10-28 12:13:42.540786
------------------------------------------------------
Started: 2024-10-28 15:01:05.242656
Existing_entries: 250
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1500
Summarized using gpt-4o-mini
Append: [利用多视图视频学习物体动态的机器人交互框架](https://arxiv.org/abs/2410.18912)
append_entries: 1
Finish: 2024-10-28 15:01:22.092273
------------------------------------------------------
Started: 2024-10-28 18:09:27.206237
Existing_entries: 251
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1354
Summarized using gpt-4o-mini
Append: [大型语言模型中的知识冲突检测与管理](https://arxiv.org/abs/2410.16090)
Token length: 1278
Summarized using gpt-4o-mini
Append: [新闻源偏见评估方法的改进与应用](https://arxiv.org/abs/2410.17655)
Token length: 1507
Summarized using gpt-4o-mini
Append: [利用大语言模型优化数据集标注质量研究](https://arxiv.org/abs/2410.18889)
append_entries: 3
Finish: 2024-10-28 18:09:42.891270
------------------------------------------------------
Started: 2024-10-28 21:00:36.671562
Existing_entries: 254
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-28 21:00:36.953488
------------------------------------------------------
Started: 2024-10-29 00:35:08.290366
Existing_entries: 254
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-29 00:35:08.403430
------------------------------------------------------
Started: 2024-10-29 03:17:58.723048
Existing_entries: 254
Fetching from https://rsshub.app/huggingface/daily-papers
Summarization failed, append the original article
error: 'NoneType' object has no attribute 'group'. Line: 406.
Append: [Read-ME: Refactorizing LLMs as Router-Decoupled Mixture of Experts with System Co-Design](https://arxiv.org/abs/2410.19123)
append_entries: 1
Finish: 2024-10-29 03:19:57.255246
------------------------------------------------------
Started: 2024-10-29 06:00:54.754359
Existing_entries: 255
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1243
Summarized using gpt-4o-mini
Append: [MarDini：融合影片扩散模型与受限自回归的创新方法](https://arxiv.org/abs/2410.20280)
Token length: 1767
Summarized using gpt-4o-mini
Append: [基于双重策略的图像恢复研究](https://arxiv.org/abs/2410.18666)
Token length: 1299
Summarized using gpt-4o-mini
Append: [视觉搜索助手：提升视觉语言模型的信息检索能力](https://arxiv.org/abs/2410.21220)
Token length: 1193
Summarized using gpt-4o-mini
Append: [LongReward：提升长上下文模型性能的重强化学习方法](https://arxiv.org/abs/2410.21252)
Token length: 928
Summarized using gpt-4o-mini
Append: [小型语言模型的全面综述](https://arxiv.org/abs/2410.20011)
Token length: 1667
Summarized using gpt-4o-mini
Append: [LARP: 一种新型视频标记化工具提升自回归生成模型性能](https://arxiv.org/abs/2410.21264)
append_entries: 6
Finish: 2024-10-29 06:01:22.082468
------------------------------------------------------
Started: 2024-10-29 09:01:04.634435
Existing_entries: 261
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-29 09:01:04.732111
------------------------------------------------------
Started: 2024-10-29 12:00:44.806637
Existing_entries: 261
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "GPT-4o is an autoregressive omni model that accepts as input any combination of text, audio, image, and video, and generates any combination of text, audio, and image outputs. It's trained end-to-end across text, vision, and audio, meaning all inputs and outputs are processed by the same neural network. GPT-4o can respond to audio inputs in as little as 232 milliseconds, with an average of 320 milliseconds, which is similar to human response time in conversation. It matches GPT-4 Turbo performance on text in English and code, with significant improvement on text in non-English languages, while also being much faster and 50\\% cheaper in the API. GPT-4o is especially better at vision and audio understanding compared to existing models. In line with our commitment to building AI safely and consistent with our voluntary commitments to the White House, we are sharing the GPT-4o System Card, which includes our Preparedness Framework evaluations. In this System Card, we provide a detailed look at GPT-4o's capabilities, limitations, and safety evaluations across multiple categories, focusing on speech-to-speech while also evaluating text and image capabilities, and measures we've implemented to ensure the model is safe and aligned. We also include third-party assessments on dangerous capabilities, as well as discussion of potential societal impacts of GPT-4o's text and vision capabilities."}]}]Summarization failed, append the original article
error: Request timed out.. Line: 406.
Append: [GPT-4o System Card](https://arxiv.org/abs/2410.21276)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "The safe and effective deployment of Large Language Models (LLMs) involves a critical step called alignment, which ensures that the model's responses are in accordance with human preferences. Prevalent alignment techniques, such as DPO, PPO and their variants, align LLMs by changing the pre-trained model weights during a phase called post-training. While predominant, these post-training methods add substantial complexity before LLMs can be deployed. Inference-time alignment methods avoid the complex post-training step and instead bias the generation towards responses that are aligned with human preferences. The best-known inference-time alignment method, called Best-of-N, is as effective as the state-of-the-art post-training procedures. Unfortunately, Best-of-N requires vastly more resources at inference time than standard decoding strategies, which makes it computationally not viable. In this work, we introduce Speculative Rejection, a computationally-viable inference-time alignment algorithm. It generates high-scoring responses according to a given reward model, like Best-of-N does, while being between 16 to 32 times more computationally efficient."}]}]Summarization failed, append the original article
error: Request timed out.. Line: 406.
Append: [Fast Best-of-N Decoding via Speculative Rejection](https://arxiv.org/abs/2410.20290)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Neural Fields have emerged as a transformative approach for 3D scene representation in computer vision and robotics, enabling accurate inference of geometry, 3D semantics, and dynamics from posed 2D data. Leveraging differentiable rendering, Neural Fields encompass both continuous implicit and explicit neural representations enabling high-fidelity 3D reconstruction, integration of multi-modal sensor data, and generation of novel viewpoints. This survey explores their applications in robotics, emphasizing their potential to enhance perception, planning, and control. Their compactness, memory efficiency, and differentiability, along with seamless integration with foundation and generative models, make them ideal for real-time applications, improving robot adaptability and decision-making. This paper provides a thorough review of Neural Fields in robotics, categorizing applications across various domains and evaluating their strengths and limitations, based on over 200 papers. First, we present four key Neural Fields frameworks: Occupancy Networks, Signed Distance Fields, Neural Radiance Fields, and Gaussian Splatting. Second, we detail Neural Fields' applications in five major robotics domains: pose estimation, manipulation, navigation, physics, and autonomous driving, highlighting key works and discussing takeaways and open challenges. Finally, we outline the current limitations of Neural Fields in robotics and propose promising directions for future research. Project page: https://robonerf.github.io"}]}]Summarization failed, append the original article
error: Request timed out.. Line: 406.
Append: [Neural Fields in Robotics: A Survey](https://arxiv.org/abs/2410.20220)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We introduce a novel training-free spatial grounding technique for text-to-image generation using Diffusion Transformers (DiT). Spatial grounding with bounding boxes has gained attention for its simplicity and versatility, allowing for enhanced user control in image generation. However, prior training-free approaches often rely on updating the noisy image during the reverse diffusion process via backpropagation from custom loss functions, which frequently struggle to provide precise control over individual bounding boxes. In this work, we leverage the flexibility of the Transformer architecture, demonstrating that DiT can generate noisy patches corresponding to each bounding box, fully encoding the target object and allowing for fine-grained control over each region. Our approach builds on an intriguing property of DiT, which we refer to as semantic sharing. Due to semantic sharing, when a smaller patch is jointly denoised alongside a generatable-size image, the two become "semantic clones". Each patch is denoised in its own branch of the generation process and then transplanted into the corresponding region of the original noisy image at each timestep, resulting in robust spatial grounding for each bounding box. In our experiments on the HRS and DrawBench benchmarks, we achieve state-of-the-art performance compared to previous training-free spatial grounding approaches.'}]}]Summarization failed, append the original article
error: Request timed out.. Line: 406.
Append: [GrounDiT: Grounding Diffusion Transformers via Noisy Patch Transplantation](https://arxiv.org/abs/2410.20474)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "FP8 training has emerged as a promising method for improving training efficiency. Existing frameworks accelerate training by applying FP8 computation to linear layers while leaving optimizer states and activations in higher precision, which fails to fully optimize memory usage. This paper introduces COAT (Compressing Optimizer States and Activations for FP8 Training), a novel FP8 training framework designed to significantly reduce memory footprint when training large models. COAT addresses current limitations through two key innovations: (1) Dynamic Range Expansion, which aligns optimizer state distributions more closely with the FP8 representation range, thereby reducing quantization error, and (2) Mixed-Granularity Activation Quantization, which optimizes activation memory using a combination of per-tensor and per-group quantization strategies. Experiments demonstrate that COAT effectively reduces end-to-end training memory footprint by 1.54x compared to BF16 while achieving nearly lossless performance across various tasks, such as Large Language Model pretraining and fine-tuning and Vision Language Model training. COAT also achieves a 1.43x end-to-end training speedup compared to BF16, performing on par with or surpassing TransformerEngine's speedup. COAT enables efficient full-parameter training of large models on fewer GPUs, and facilitates doubling the batch size in distributed training settings, providing a practical solution for scaling large-scale model training. The code is available at https://github.com/NVlabs/COAT."}]}]Summarization failed, append the original article
error: Request timed out.. Line: 406.
Append: [COAT: Compressing Optimizer states and Activation for Memory-Efficient FP8 Training](https://arxiv.org/abs/2410.19313)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "This research tests the role of Large Language Models (LLMs) as formal second opinion tools in professional decision-making, particularly focusing on complex medical cases where even experienced physicians seek peer consultation. The work analyzed 183 challenging medical cases from Medscape over a 20-month period, testing multiple LLMs' performance against crowd-sourced physician responses. A key finding was the high overall score possible in the latest foundational models (>80% accuracy compared to consensus opinion), which exceeds most human metrics reported on the same clinical cases (450 pages of patient profiles, test results). The study rates the LLMs' performance disparity between straightforward cases (>81% accuracy) and complex scenarios (43% accuracy), particularly in these cases generating substantial debate among human physicians. The research demonstrates that LLMs may be valuable as generators of comprehensive differential diagnoses rather than as primary diagnostic tools, potentially helping to counter cognitive biases in clinical decision-making, reduce cognitive loads, and thus remove some sources of medical error. The inclusion of a second comparative legal dataset (Supreme Court cases, N=21) provides added empirical context to the AI use to foster second opinions, though these legal challenges proved considerably easier for LLMs to analyze. In addition to the original contributions of empirical evidence for LLM accuracy, the research aggregated a novel benchmark for others to score highly contested question and answer reliability between both LLMs and disagreeing human practitioners. These results suggest that the optimal deployment of LLMs in professional settings may differ substantially from current approaches that emphasize automation of routine tasks."}]}]Summarization failed, append the original article
error: Request timed out.. Line: 406.
Append: [Language Models And A Second Opinion Use Case: The Pocket Professional](https://arxiv.org/abs/2410.20636)
append_entries: 6
Finish: 2024-10-29 12:02:23.345852
------------------------------------------------------
Started: 2024-10-29 15:00:48.032151
Existing_entries: 267
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1119
Summarized using gpt-4o-mini
Append: [SGRv2：一种提高样本效率的模仿学习框架](https://arxiv.org/abs/2406.10615)
Token length: 1188
Summarized using gpt-4o-mini
Append: [文档解析的现状与挑战](https://arxiv.org/abs/2410.21169)
Token length: 1061
Summarized using gpt-4o-mini
Append: [Bielik 7B v0.1：波兰语处理的七十亿参数生成文本模型](https://arxiv.org/abs/2410.18565)
Token length: 1561
Summarized using gpt-4o-mini
Append: [AgentStore：一种创新的动态异构代理集成平台](https://arxiv.org/abs/2410.18603)
append_entries: 4
Finish: 2024-10-29 15:01:14.084119
------------------------------------------------------
Started: 2024-10-29 18:00:42.528576
Existing_entries: 271
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-29 18:00:42.859353
------------------------------------------------------
Started: 2024-10-29 21:01:03.392268
Existing_entries: 271
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1491
Summarized using gpt-4o-mini
Append: [从无标注对话中高效推导结构化工作流的研究](https://arxiv.org/abs/2410.18481)
append_entries: 1
Finish: 2024-10-29 21:01:08.078352
------------------------------------------------------
Started: 2024-10-30 00:34:26.631316
Existing_entries: 272
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1157
Summarized using gpt-4o-mini
Append: [基于双层优化的模仿学习框架改善类人机器人运动模仿](https://arxiv.org/abs/2410.01968)
Token length: 1524
Summarized using gpt-4o-mini
Append: [VideoWebArena: 评估长文本视频理解的基准测试](https://arxiv.org/abs/2410.19100)
Token length: 1472
Summarized using gpt-4o-mini
Append: [递归变换器：参数共享和性能优化的新方法](https://arxiv.org/abs/2410.20672)
append_entries: 3
Finish: 2024-10-30 00:34:42.575225
------------------------------------------------------
Started: 2024-10-30 03:15:10.629121
Existing_entries: 275
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1635
Summarized using gpt-4o-mini
Append: [EoRA：一种无训练的低秩近似模型压缩补偿方法](https://arxiv.org/abs/2410.21271)
append_entries: 1
Finish: 2024-10-30 03:15:16.587428
------------------------------------------------------
Started: 2024-10-30 06:10:59.713363
Existing_entries: 276
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1335
Summarized using gpt-4o-mini
Append: [自主多模态网络代理的开发框架](https://arxiv.org/abs/2410.19609)
Token length: 1199
Summarized using gpt-4o-mini
Append: [AutoKaggle：数据科学任务的智能协作框架](https://arxiv.org/abs/2410.20424)
Token length: 1726
Summarized using gpt-4o-mini
Append: [社交关系推理框架：结合视觉基础模型与大型语言模型](https://arxiv.org/abs/2410.21411)
Token length: 1701
Summarized using gpt-4o-mini
Append: [基于操作中心性表示的机器人视觉预训练研究](https://arxiv.org/abs/2410.22325)
Token length: 855
Summarized using gpt-4o-mini
Append: [基于在线学习流的高质量推理轨迹生成方法](https://arxiv.org/abs/2410.22304)
Token length: 1539
Summarized using gpt-4o-mini
Append: [ShadowKV：高吞吐量长上下文LLM推理系统](https://arxiv.org/abs/2410.21465)
Token length: 1459
Summarized using gpt-4o-mini
Append: [基于人机协同的视觉强化学习在复杂机器人操作中的应用](https://arxiv.org/abs/2410.21845)
append_entries: 7
Finish: 2024-10-30 06:11:31.263517
------------------------------------------------------
Started: 2024-10-30 09:00:45.928077
Existing_entries: 283
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1007
Summarized using gpt-4o-mini
Append: [CLEAR: 跨模态遗忘的新基准与挑战](https://arxiv.org/abs/2410.18057)
append_entries: 1
Finish: 2024-10-30 09:00:51.948643
------------------------------------------------------
Started: 2024-10-30 12:13:07.580210
Existing_entries: 284
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-30 12:13:07.759637
------------------------------------------------------
Started: 2024-10-30 15:00:43.738504
Existing_entries: 284
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-10-30 15:00:43.885364
------------------------------------------------------
Started: 2024-10-30 18:01:05.525408
Existing_entries: 284
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1781
Summarized using gpt-4o-mini
Append: [链式推理对大型语言模型性能影响的研究](https://arxiv.org/abs/2410.21333)
append_entries: 1
Finish: 2024-10-30 18:01:15.240740
------------------------------------------------------
Started: 2024-10-30 21:00:41.407714
Existing_entries: 285
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1178
Summarized using gpt-4o-mini
Append: [引入前缀共享的偏好调优新方法](https://arxiv.org/abs/2410.20305)
Token length: 1328
Summarized using gpt-4o-mini
Append: [利用相关反馈的真实文档嵌入优化稠密检索系统](https://arxiv.org/abs/2410.21242)
Token length: 1351
Summarized using gpt-4o-mini
Append: [新方法评估大语言模型的记忆化风险](https://arxiv.org/abs/2410.19482)
Token length: 1083
Summarized using gpt-4o-mini
Append: [利用RARe方法提升嵌入模型在检索任务中的性能](https://arxiv.org/abs/2410.20088)
append_entries: 4
Finish: 2024-10-30 21:01:05.379451
------------------------------------------------------
Started: 2024-10-31 00:34:52.521030
Existing_entries: 289
Fetching from https://rsshub.app/huggingface/daily-papers
Fetch error: HTTPSConnectionPool(host='rsshub.app', port=443): Read timed out. (read timeout=30)
Fetch failed from https://rsshub.app/huggingface/daily-papers
append_entries: 0
error when rendering xml, skip docs/Huggingface-Daliy-Papers
------------------------------------------------------
Started: 2024-10-31 03:16:43.086059
Existing_entries: 289
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1076
Summarized using gpt-4o-mini
Append: [视觉语言模型中任务表示的内部机制研究](https://arxiv.org/abs/2410.22330)
Token length: 1001
Summarized using gpt-4o-mini
Append: [REPOCOD：评估大型语言模型在真实代码生成中的应用](https://arxiv.org/abs/2410.21647)
append_entries: 2
Finish: 2024-10-31 03:17:56.095098
------------------------------------------------------
Started: 2024-10-31 06:00:52.068280
Existing_entries: 291
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1062
Summarized using gpt-4o-mini
Append: [CORAL: 针对多轮对话的检索增强生成基准](https://arxiv.org/abs/2410.23090)
Token length: 1547
Summarized using gpt-4o-mini
Append: [自学习假设文档嵌入法在医疗信息检索中的应用](https://arxiv.org/abs/2410.20050)
append_entries: 2
Finish: 2024-10-31 06:01:04.566401
------------------------------------------------------
Started: 2024-10-31 09:00:52.680153
Existing_entries: 293
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 872
Summarized using gpt-4o-mini
Append: [通过专家选择路由攻击Mixture-of-Experts模型以披露用户提示](https://arxiv.org/abs/2410.22884)
Token length: 1033
Summarized using gpt-4o-mini
Append: [基于xLSTM的大型重复动作模型研究](https://arxiv.org/abs/2410.22391)
append_entries: 2
Finish: 2024-10-31 09:01:03.424209
------------------------------------------------------
Started: 2024-10-31 12:12:57.569246
Existing_entries: 295
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
error when rendering xml, skip docs/Huggingface-Daliy-Papers
------------------------------------------------------
Started: 2024-10-31 15:00:47.509629
Existing_entries: 295
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1473
Summarized using gpt-4o-mini
Append: [TokenFormer：一种可扩展的变换器架构解决方案](https://arxiv.org/abs/2410.23168)
append_entries: 1
Finish: 2024-10-31 15:00:54.334670
------------------------------------------------------
Started: 2024-10-31 18:00:45.210244
Existing_entries: 296
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1482
Summarized using gpt-4o-mini
Append: [开放数据的有毒内容过滤新方法](https://arxiv.org/abs/2410.22587)
append_entries: 1
Finish: 2024-10-31 18:00:50.980023
------------------------------------------------------
Started: 2024-10-31 21:01:09.847586
Existing_entries: 297
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1101
Summarized using gpt-4o-mini
Append: [通过眼动模式解码阅读目标的可能性研究](https://arxiv.org/abs/2410.20779)
Token length: 1067
Summarized using gpt-4o-mini
Append: [REM框架：基于自然语言的视频概念分割](https://arxiv.org/abs/2410.23287)
append_entries: 2
Finish: 2024-10-31 21:01:21.717566
------------------------------------------------------
Started: 2024-11-01 00:38:02.166816
Existing_entries: 299
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1863
Summarized using gpt-4o-mini
Append: [SlowFast-VGen：一种新型双速学习系统用于长视频生成](https://arxiv.org/abs/2410.23277)
Token length: 1605
Summarized using gpt-4o-mini
Append: [大语言模型的记忆化与推理能力的复杂性](https://arxiv.org/abs/2410.23123)
append_entries: 2
Finish: 2024-11-01 00:38:11.304877
------------------------------------------------------
Started: 2024-11-01 03:23:22.060873
Existing_entries: 301
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-01 03:23:22.182255
------------------------------------------------------
Started: 2024-11-01 06:10:50.374727
Existing_entries: 301
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1415
Summarized using gpt-4o-mini
Append: [Self-Lengthen：提升大语言模型长文本生成能力的新框架](https://arxiv.org/abs/2410.23933)
Token length: 1339
Summarized using gpt-4o-mini
Append: [基于约束回译的数据生成技术提升复杂指令遵循能力](https://arxiv.org/abs/2410.24175)
Token length: 1545
Summarized using gpt-4o-mini
Append: [BenchX：统一的医学视觉语言预训练基准框架](https://arxiv.org/abs/2410.21969)
Token length: 1253
Summarized using gpt-4o-mini
Append: [从合成视频和自然图像学习有效视频表示](https://arxiv.org/abs/2410.24213)
append_entries: 4
Finish: 2024-11-01 06:11:15.491642
------------------------------------------------------
Started: 2024-11-01 09:00:43.139094
Existing_entries: 305
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1292
Summarized using gpt-4o-mini
Append: [CARE系统：提升大语言模型个性化探索能力](https://arxiv.org/abs/2410.24032)
Json decode failed:
{
  "title": "利用稀疏自编码器解析文本到图像模型的潜在特征",
  "keyword": ["稀疏自编码器", "文本到图像", "生成模型"],
  "short_summary": "研究表明稀疏自编码器可为文本到图像模型提供可解释特征。",
  "summary": "本文探讨了稀疏自编码器（SAEs）在文本到图像扩散模型（如SDXL Turbo）中的应用，旨在提取可解释的特征。通过对SDXL Turbo中去噪U-net的变换器块更新进行训练，我们发现所学习的特征不仅具有可解释性，还能因果地影响生成过程，以及揭示各个块的专业化。在研究中，我们识别出处理图像组合、添加局部细节及负责颜色、照明和风格的不同块。这项研究为更好地理解像SDXL Turbo这样的生成文本到图像模型的内部工作机制开辟了重要的第一步，并展示了SAEs在视觉领域学习特征的潜力。代码可在 https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 268 (char 398). Line: 406.
Append: [Unpacking SDXL Turbo: Interpreting Text-to-Image Models with Sparse Autoencoders](https://arxiv.org/abs/2410.22366)
Token length: 1533
Summarized using gpt-4o-mini
Append: [层级梯度分析：快思维与慢思维对大型语言模型训练的影响](https://arxiv.org/abs/2410.23743)
Json decode failed:
{
  "title": "基于单目视频的高效密集3D运动跟踪方法",
  "keyword": ["3D运动跟踪", "单目视频", "深度表示"],
  "short_summary": "提出了一种新方法实现高效密集3D运动跟踪，速度提升8倍，精确度达到了最新水平。",
  "summary": "本文介绍了一种针对单目视频进行密集3D运动跟踪的新方法\Approach，该方法可以在长序列上实现像素级别的精确跟踪。通过使用联合的全球-局部注意机制进行低分辨率跟踪，并结合基于变换器的上采样器实现高分辨率预测，\Approach的计算效率大幅提升，运行速度比以往方法快8倍，同时保持了最先进的准确性。此外，研究还探讨了深度表示对跟踪性能的影响，并确定对数深度为最佳选择。通过大量实验结果表明，\Approach在多个基准测试中表现优越，为需要在3D空间中进行细粒度长期运动跟踪的应用提供了强有力的解决方案。"
}Summarization failed, append the original article
error: Invalid \escape: line 5 column 42 (char 180). Line: 406.
Append: [DELTA: Dense Efficient Long-range 3D Tracking for any video](https://arxiv.org/abs/2410.24211)
append_entries: 4
Finish: 2024-11-01 09:01:10.566601
------------------------------------------------------
Started: 2024-11-01 12:00:54.018376
Existing_entries: 309
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1664
Summarized using gpt-4o-mini
Append: [BitStack：一种新型训练无关权重压缩方法](https://arxiv.org/abs/2410.23918)
Token length: 1056
Summarized using gpt-4o-mini
Append: [多意图任务导向对话系统的研究与实现](https://arxiv.org/abs/2410.22476)
append_entries: 2
Finish: 2024-11-01 12:01:05.081973
------------------------------------------------------
Started: 2024-11-01 15:01:09.732928
Existing_entries: 311
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1805
Summarized using gpt-4o-mini
Append: [SelfCodeAlign：透明的自我对齐代码语言模型训练管道](https://arxiv.org/abs/2410.24198)
append_entries: 1
Finish: 2024-11-01 15:01:16.445619
------------------------------------------------------
Started: 2024-11-01 18:00:48.877030
Existing_entries: 312
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-01 18:00:49.040266
------------------------------------------------------
Started: 2024-11-01 21:00:46.305646
Existing_entries: 312
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1565
Summarized using gpt-4o-mini
Append: [一种新型带有瓶颈的最小熵耦合压缩框架研究](https://arxiv.org/abs/2410.21666)
Token length: 882
Summarized using gpt-4o-mini
Append: [GlotCC：覆盖1000多种语言的清洁文本语料库](https://arxiv.org/abs/2410.23825)
Token length: 1145
Summarized using gpt-4o-mini
Append: [利用丰富语言输入提升强化学习智能体的学习能力](https://arxiv.org/abs/2410.24218)
append_entries: 3
Finish: 2024-11-01 21:01:00.872009
------------------------------------------------------
Started: 2024-11-02 00:33:33.273827
Existing_entries: 315
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 853
Summarized using gpt-4o-mini
Append: [NeuZip: 一种新型神经网络权重压缩方案](https://arxiv.org/abs/2410.20650)
Token length: 1371
Summarized using gpt-4o-mini
Append: [AAAR-1.0: 评估大语言模型在科研任务中的表现](https://arxiv.org/abs/2410.22394)
append_entries: 2
Finish: 2024-11-02 00:33:51.005140
------------------------------------------------------
Started: 2024-11-02 03:12:32.937913
Existing_entries: 317
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-02 03:12:33.021613
------------------------------------------------------
Started: 2024-11-02 06:08:58.019039
Existing_entries: 317
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-02 06:08:58.159857
------------------------------------------------------
Started: 2024-11-02 09:00:55.020260
Existing_entries: 317
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-02 09:00:55.103870
------------------------------------------------------
Started: 2024-11-02 12:00:58.832351
Existing_entries: 317
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-02 12:00:58.996827
------------------------------------------------------
Started: 2024-11-02 15:00:53.920157
Existing_entries: 317
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-02 15:00:53.981649
------------------------------------------------------
Started: 2024-11-02 18:00:46.541487
Existing_entries: 317
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-02 18:00:46.650186
------------------------------------------------------
Started: 2024-11-02 21:01:02.928188
Existing_entries: 317
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-02 21:01:03.042401
------------------------------------------------------
Started: 2024-11-03 00:37:29.054479
Existing_entries: 317
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-03 00:37:29.179877
------------------------------------------------------
Started: 2024-11-03 03:18:22.791792
Existing_entries: 317
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-03 03:18:22.880421
------------------------------------------------------
Started: 2024-11-03 06:01:09.861696
Existing_entries: 317
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-03 06:01:09.982638
------------------------------------------------------
Started: 2024-11-03 09:00:50.413159
Existing_entries: 317
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-03 09:00:50.579769
------------------------------------------------------
Started: 2024-11-03 12:00:25.932679
Existing_entries: 317
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-03 12:00:25.986016
------------------------------------------------------
Started: 2024-11-03 15:00:45.096176
Existing_entries: 317
Fetching from https://rsshub.app/huggingface/daily-papers
Fetch error: HTTPSConnectionPool(host='rsshub.app', port=443): Read timed out. (read timeout=30)
Fetch failed from https://rsshub.app/huggingface/daily-papers
append_entries: 0
error when rendering xml, skip docs/Huggingface-Daliy-Papers
------------------------------------------------------
Started: 2024-11-03 18:01:00.435880
Existing_entries: 317
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-03 18:01:00.693604
------------------------------------------------------
Started: 2024-11-03 21:00:36.521385
Existing_entries: 317
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-03 21:00:36.597407
------------------------------------------------------
Started: 2024-11-04 00:36:38.093529
Existing_entries: 317
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-04 00:36:38.205438
------------------------------------------------------
Started: 2024-11-04 03:18:24.255552
Existing_entries: 317
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-04 03:18:24.406676
------------------------------------------------------
Started: 2024-11-04 06:00:57.009539
Existing_entries: 317
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1255
Summarized using gpt-4o-mini
Append: [M2RC-EVAL: 多语言代码补全基准与数据集](https://arxiv.org/abs/2410.21157)
Json decode failed:
{
  "title": "随机自回归建模(RAR)在视觉生成中的新突破",
  "short_summary": "RAR模型在图像生成任务上创新性地达成新标杆表现。",
  "summary": "本文提出了一种随机自回归建模（RAR）方法用于视觉生成，显著提升了图像生成的性能，并与语言建模框架完全兼容。在标准自回归训练过程中，输入序列按概率r随机打乱排列，r从1线性衰减到0。这种退火训练策略使模型能够学习在所有因式分解顺序上最大化期望似然，从而有效提升了模型对双向上下文的建模能力。RAR在保持自回归建模框架完整性的同时，显著改善了图像生成的性能。在ImageNet-256基准测试中，RAR获得了1.48的FID分数，不仅超越了以往的自回归图像生成器，还优于领先的扩散基础和掩蔽变换基础方法。代码和模型将发布于https:
  "keyword": ["自回归建模", "视觉生成", "图像生成"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 281 (char 367). Line: 406.
Append: [Randomized Autoregressive Visual Generation](https://arxiv.org/abs/2411.00776)
Token length: 1581
Summarized using gpt-4o-mini
Append: [利用IC-LoRA优化文本到图像的生成能力](https://arxiv.org/abs/2410.23775)
Token length: 1389
Summarized using gpt-4o-mini
Append: [基于人类问题解决过程的双组件微调方法提升大型语言模型的科学问题解答能力](https://arxiv.org/abs/2411.00412)
append_entries: 4
Finish: 2024-11-04 06:01:15.114991
------------------------------------------------------
Started: 2024-11-04 09:01:10.576945
Existing_entries: 321
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-04 09:01:10.671481
------------------------------------------------------
Started: 2024-11-04 12:13:30.989833
Existing_entries: 321
Fetching from https://rsshub.app/huggingface/daily-papers
Fetch error: HTTPSConnectionPool(host='rsshub.app', port=443): Read timed out. (read timeout=30)
Fetch failed from https://rsshub.app/huggingface/daily-papers
append_entries: 0
error when rendering xml, skip docs/Huggingface-Daliy-Papers
------------------------------------------------------
Started: 2024-11-04 15:00:58.229243
Existing_entries: 321
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1310
Summarized using gpt-4o-mini
Append: [基于词频的embedding空间校正提升任务性能](https://arxiv.org/abs/2411.00680)
Token length: 1338
Summarized using gpt-4o-mini
Append: [引入常加速度流的图像生成新框架](https://arxiv.org/abs/2411.00322)
Token length: 840
Summarized using gpt-4o-mini
Append: [提升WikiNER语料库质量的研究](https://arxiv.org/abs/2411.00030)
Token length: 1444
Summarized using gpt-4o-mini
Append: [推出OS-Atlas：增强开源GUI代理的基础模型](https://arxiv.org/abs/2410.23218)
Token length: 994
Summarized using gpt-4o-mini
Append: [SambaMixer：一种用于锂离子电池健康状态预测的新结构化状态空间模型](https://arxiv.org/abs/2411.00233)
Token length: 995
Summarized using gpt-4o-mini
Append: [人机交互中的生成式AI应用及其用户界面设计](https://arxiv.org/abs/2410.22370)
Token length: 1102
Summarized using gpt-4o-mini
Append: [引入图推理结构的问答数据集GRS-QA](https://arxiv.org/abs/2411.00369)
Token length: 1383
Summarized using gpt-4o-mini
Append: [个性化大语言模型的使用与挑战](https://arxiv.org/abs/2411.00027)
Token length: 774
Summarized using gpt-4o-mini
Append: [高效适配器插入方案提升文本到图像模型性能](https://arxiv.org/abs/2410.22901)
append_entries: 9
Finish: 2024-11-04 15:01:49.938091
------------------------------------------------------
Started: 2024-11-04 18:00:50.259627
Existing_entries: 330
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1399
Summarized using gpt-4o-mini
Append: [CityGaussianV2：大型场景重建的新方法](https://arxiv.org/abs/2411.00771)
Token length: 1016
Summarized using gpt-4o-mini
Append: [基于扩散模型的人脸匿名化技术研究](https://arxiv.org/abs/2411.00762)
Token length: 561
Summarized using gpt-4o-mini
Append: [结合掩蔽语言建模与因果语言建模的混合训练方法](https://arxiv.org/abs/2410.24159)
append_entries: 3
Finish: 2024-11-04 18:01:08.135069
------------------------------------------------------
Started: 2024-11-04 21:01:03.035570
Existing_entries: 333
Fetching from https://rsshub.app/huggingface/daily-papers
Summarization failed, append the original article
error: 'NoneType' object has no attribute 'group'. Line: 406.
Append: [Physics in Next-token Prediction](https://arxiv.org/abs/2411.00660)
Token length: 1719
Summarized using gpt-4o-mini
Append: [TOMATO：评估多模态基础模型在视频理解中的时间推理能力](https://arxiv.org/abs/2410.23266)
append_entries: 2
Finish: 2024-11-04 21:01:17.736778
------------------------------------------------------
Started: 2024-11-05 00:33:45.853665
Existing_entries: 335
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1069
Summarized using gpt-4o-mini
Append: [Fashion-VDM：视频虚拟试穿的新方法](https://arxiv.org/abs/2411.00225)
append_entries: 1
Finish: 2024-11-05 00:33:50.487407
------------------------------------------------------
Started: 2024-11-05 03:11:28.832745
Existing_entries: 336
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1874
Summarized using gpt-4o-mini
Append: [探讨视觉语言模型的数学推理能力及DynaMath基准的开发](https://arxiv.org/abs/2411.00836)
append_entries: 1
Finish: 2024-11-05 03:11:33.566987
------------------------------------------------------
Started: 2024-11-05 06:10:19.443031
Existing_entries: 337
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-05 06:10:19.543680
------------------------------------------------------
Started: 2024-11-05 09:00:44.917981
Existing_entries: 337
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1296
Summarized using gpt-4o-mini
Append: [基于CamVid-30K数据集的3D和4D生成框架GenXD](https://arxiv.org/abs/2411.02319)
Token length: 1272
Summarized using gpt-4o-mini
Append: [Hunyuan-Large：最强大的开源Transformer专家模型](https://arxiv.org/abs/2411.02265)
Token length: 1895
Summarized using gpt-4o-mini
Append: [解码器Transformer基模型中激活稀疏性的量化研究](https://arxiv.org/abs/2411.02335)
Json decode failed:
{
  "title": "AndroidLab：系统化的安卓智能体框架",
  "keyword": ["安卓智能体", "系统框架", "开放源代码"],
  "short_summary": "AndroidLab提供了一种系统化的安卓智能体训练与评估框架。",
  "summary": "随着自主智能体在现实世界中互动的重要性日益增加，安卓智能体作为一种新兴的交互方式逐渐受到关注。现有的研究在训练和评估安卓智能体方面缺乏系统性的研究。本文提出了AndroidLab，一个系统化的安卓智能体框架，包含不同模态和动作空间的操作环境，以及一个可复现的基准。AndroidLab支持大型语言模型（LLMs）和多模态模型（LMMs）在同一动作空间中工作，基准测试涵盖了预定义的安卓虚拟设备和九个应用中的138个任务。通过使用AndroidLab环境，我们开发了安卓指令数据集并训练了六个开源的LLMs和LMMs，成功率分别从4.59%提高到21.50%（LLMs）和从1.93%提高到13.28%（LMMs）。AndroidLab已开源并可在https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 344 (char 478). Line: 406.
Append: [AndroidLab: Training and Systematic Benchmarking of Android Autonomous Agents](https://arxiv.org/abs/2410.24024)
Token length: 1457
Summarized using gpt-4o-mini
Append: [WebRL：开放LLM的在线强化学习框架](https://arxiv.org/abs/2411.02337)
Token length: 1234
Summarized using gpt-4o-mini
Append: [AdaCache：加速视频生成的自适应缓存方法](https://arxiv.org/abs/2411.02397)
Token length: 1195
Summarized using gpt-4o-mini
Append: [专用稀疏自编码器：揭示基础模型中的关键概念](https://arxiv.org/abs/2411.00743)
Token length: 1752
Summarized using gpt-4o-mini
Append: [视频生成模型对物理规律的学习与评估](https://arxiv.org/abs/2411.02385)
Token length: 1164
Summarized using gpt-4o-mini
Append: [LibMoE: 提升混合专家算法在大语言模型中的可访问性](https://arxiv.org/abs/2411.00918)
append_entries: 9
Finish: 2024-11-05 09:01:32.171287
------------------------------------------------------
Started: 2024-11-05 12:13:32.384658
Existing_entries: 346
Fetching from https://rsshub.app/huggingface/daily-papers
Summarization failed, append the original article
error: 'NoneType' object has no attribute 'group'. Line: 406.
Append: [Survey of Cultural Awareness in Language Models: Text and Beyond](https://arxiv.org/abs/2411.00860)
Summarization failed, append the original article
error: 'NoneType' object has no attribute 'group'. Line: 406.
Append: [DynaSaur: Large Language Agents Beyond Predefined Actions](https://arxiv.org/abs/2411.01747)
Summarization failed, append the original article
error: 'NoneType' object has no attribute 'group'. Line: 406.
Append: [Training-free Regional Prompting for Diffusion Transformers](https://arxiv.org/abs/2411.02395)
append_entries: 3
Finish: 2024-11-05 12:13:56.297370
------------------------------------------------------
Started: 2024-11-05 15:00:49.763018
Existing_entries: 349
Fetching from https://rsshub.app/huggingface/daily-papers
Summarization failed, append the original article
error: 'NoneType' object has no attribute 'group'. Line: 406.
Append: [Swan and ArabicMTEB: Dialect-Aware, Arabic-Centric, Cross-Lingual, and Cross-Cultural Embedding Models and Benchmarks](https://arxiv.org/abs/2411.01192)
append_entries: 1
Finish: 2024-11-05 15:00:59.310920
------------------------------------------------------
Started: 2024-11-05 18:00:44.213959
Existing_entries: 350
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1768
Summarized using gpt-4o-mini
Append: [MVPaint：一种新型的3D纹理生成与优化框架](https://arxiv.org/abs/2411.02336)
Token length: 1625
Summarized using gpt-4o-mini
Append: [PPLLaVA：一种适用于长短视频理解的新型模型](https://arxiv.org/abs/2411.02327)
Token length: 1719
Summarized using gpt-4o-mini
Append: [量化大语言模型的准确性与性能权衡研究](https://arxiv.org/abs/2411.02355)
append_entries: 3
Finish: 2024-11-05 18:00:59.495142
------------------------------------------------------
Started: 2024-11-05 21:00:57.927591
Existing_entries: 353
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-05 21:00:58.065325
------------------------------------------------------
Started: 2024-11-06 00:33:18.656904
Existing_entries: 353
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1676
Summarized using gpt-4o-mini
Append: [SALSA：改进大语言模型的强化学习人类反馈方法](https://arxiv.org/abs/2411.01798)
Token length: 951
Summarized using gpt-4o-mini
Append: [AutoVFX：基于自然语言的自动化视觉特效生成框架](https://arxiv.org/abs/2411.02394)
Token length: 884
Summarized using gpt-4o-mini
Append: [基于预训练扩散模型的高效噪声线性逆问题求解算法](https://arxiv.org/abs/2411.00359)
Token length: 1281
Summarized using gpt-4o-mini
Append: [图像目标表征 (IGOR)：跨人机学习的统一动作空间](https://arxiv.org/abs/2411.00785)
Token length: 989
Summarized using gpt-4o-mini
Append: [LoCAL：增强大型多模态模型的长文档理解能力](https://arxiv.org/abs/2411.01106)
Token length: 1065
Summarized using gpt-4o-mini
Append: [多专家提示：提升大语言模型生成效果的新方法](https://arxiv.org/abs/2411.00492)
append_entries: 6
Finish: 2024-11-06 00:33:52.279773
------------------------------------------------------
Started: 2024-11-06 03:10:46.791483
Existing_entries: 359
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-06 03:10:47.077501
------------------------------------------------------
Started: 2024-11-06 06:00:38.567518
Existing_entries: 359
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1840
Summarized using gpt-4o-mini
Append: [Zebra-Llama：针对罕见疾病的专业语言模型](https://arxiv.org/abs/2411.02657)
Token length: 1236
Summarized using gpt-4o-mini
Append: [LLaMo：基于大语言模型的分子图助手](https://arxiv.org/abs/2411.00871)
Token length: 1721
Summarized using gpt-4o-mini
Append: [动态早期退出框架：提高机器人视觉语言动作模型的效率](https://arxiv.org/abs/2411.02359)
Token length: 1559
Summarized using gpt-4o-mini
Append: [HtmlRAG：提升RAG系统知识能力的HTML利用方法](https://arxiv.org/abs/2411.02959)
append_entries: 4
Finish: 2024-11-06 06:00:57.313217
------------------------------------------------------
Started: 2024-11-06 09:00:57.023875
Existing_entries: 363
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "We study methods for efficiently aligning large language models (LLMs) with human preferences given budgeted online feedback. We first formulate the LLM alignment problem in the frame of contextual dueling bandits. This formulation, subsuming recent paradigms such as online RLHF and online DPO, inherently quests for sample-efficient algorithms that incorporate online active exploration. Leveraging insights from bandit theory, we introduce a unified algorithm based on Thompson sampling and highlight its applications in two distinct LLM alignment scenarios. The practical agent that efficiently implements this algorithm, named SEA (Sample-Efficient Alignment), is empirically validated through extensive experiments across three model scales (1B, 2.8B, 6.9B) and three preference learning algorithms (DPO, IPO, SLiC). The results demonstrate that SEA achieves highly sample-efficient alignment with oracle's preferences, outperforming recent active exploration methods for LLMs. Additionally, we release the implementation of SEA together with an efficient codebase designed for online alignment of LLMs, aiming to accelerate future research in this field."}]}]Summarization failed, append the original article
error: Error code: 503 - {'error': {'code': 503, 'message': 'Service Unavailable.', 'param': None, 'type': 'cf_service_unavailable'}}. Line: 406.
Append: [Sample-Efficient Alignment for LLMs](https://arxiv.org/abs/2411.01493)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We introduce DreamPolish, a text-to-3D generation model that excels in producing refined geometry and high-quality textures. In the geometry construction phase, our approach leverages multiple neural representations to enhance the stability of the synthesis process. Instead of relying solely on a view-conditioned diffusion prior in the novel sampled views, which often leads to undesired artifacts in the geometric surface, we incorporate an additional normal estimator to polish the geometry details, conditioned on viewpoints with varying field-of-views. We propose to add a surface polishing stage with only a few training steps, which can effectively refine the artifacts attributed to limited guidance from previous stages and produce 3D objects with more desirable geometry. The key topic of texture generation using pretrained text-to-image models is to find a suitable domain in the vast latent distribution of these models that contains photorealistic and consistent renderings. In the texture generation phase, we introduce a novel score distillation objective, namely domain score distillation (DSD), to guide neural representations toward such a domain. We draw inspiration from the classifier-free guidance (CFG) in textconditioned image generation tasks and show that CFG and variational distribution guidance represent distinct aspects in gradient guidance and are both imperative domains for the enhancement of texture quality. Extensive experiments show our proposed model can produce 3D assets with polished surfaces and photorealistic textures, outperforming existing state-of-the-art methods.'}]}]Summarization failed, append the original article
error: Error code: 503 - {'error': {'code': 503, 'message': 'Service Unavailable.', 'param': None, 'type': 'cf_service_unavailable'}}. Line: 406.
Append: [DreamPolish: Domain Score Distillation With Progressive Geometry Generation](https://arxiv.org/abs/2411.01602)
append_entries: 2
Finish: 2024-11-06 09:01:00.713728
------------------------------------------------------
Started: 2024-11-06 12:00:58.780826
Existing_entries: 365
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-06 12:00:58.862477
------------------------------------------------------
Started: 2024-11-06 15:00:45.808819
Existing_entries: 365
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1281
Summarized using gpt-4o-mini
Append: [视觉显著性与物体检测准确性的关系研究](https://arxiv.org/abs/2411.02844)
Token length: 1124
Summarized using gpt-4o-mini
Append: [基于激活传输的模型生成控制框架](https://arxiv.org/abs/2410.23054)
append_entries: 2
Finish: 2024-11-06 15:00:54.158947
------------------------------------------------------
Started: 2024-11-06 18:01:00.409874
Existing_entries: 367
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1863
Summarized using gpt-4o-mini
Append: [GarVerseLOD：高保真3D服装重建的新数据集与框架](https://arxiv.org/abs/2411.03047)
append_entries: 1
Finish: 2024-11-06 18:01:05.976195
------------------------------------------------------
Started: 2024-11-06 21:00:53.687388
Existing_entries: 368
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1136
Summarized using gpt-4o-mini
Append: [基于可变长度表示的2D图像编码解码方法](https://arxiv.org/abs/2411.02393)
Token length: 1622
Summarized using gpt-4o-mini
Append: [视觉语言模型中的输入令牌压缩与推理优化](https://arxiv.org/abs/2411.03312)
append_entries: 2
Finish: 2024-11-06 21:01:00.701184
------------------------------------------------------
Started: 2024-11-07 00:33:33.412317
Existing_entries: 370
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-07 00:33:33.542054
------------------------------------------------------
Started: 2024-11-07 03:14:16.600585
Existing_entries: 370
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-07 03:14:16.721820
------------------------------------------------------
Started: 2024-11-07 06:10:12.354644
Existing_entries: 370
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-07 06:10:12.491785
------------------------------------------------------
Started: 2024-11-07 09:00:40.179665
Existing_entries: 370
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-07 09:00:40.313950
------------------------------------------------------
Started: 2024-11-07 12:12:09.487222
Existing_entries: 370
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-07 12:12:09.607116
------------------------------------------------------
Started: 2024-11-07 15:00:59.709606
Existing_entries: 370
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1907
Summarized using gpt-4o-mini
Append: [Agent K v1.0：全自动数据科学代理的创新与应用](https://arxiv.org/abs/2411.03562)
Token length: 1015
Summarized using gpt-4o-mini
Append: [MM-Detect: 一种针对多模态大语言模型的数据污染检测框架](https://arxiv.org/abs/2411.03823)
append_entries: 2
Finish: 2024-11-07 15:01:11.144112
------------------------------------------------------
Started: 2024-11-07 18:09:06.833393
Existing_entries: 372
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "PolyCom: 新型多项式复合激活函数提升Transformer表现",
  "keyword": ["Transformer", "PolyCom", "激活函数"],
  "short_summary": "PolyCom激活函数优化Transformer性能，显著提升模型表现。",
  "summary": "本论文提出了一种新颖的多项式复合激活函数（PolyCom），旨在优化Transformer网络的动态特性。通过全面的数学分析，论文强调了PolyCom相较于其他激活函数的优越表现和提升的表达能力。实验结果表明，采用PolyCom的网络能够以最小参数近似Sobolev空间中的光滑函数，且在大型语言模型的预训练配置上展现出更高的准确性和收敛速度。此外，实验还显示了PolyCom在捕捉高阶数据交互方面的优势，相较于传统激活函数，PolyCom显著提高了性能指标。研究成果及代码可访问https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 261 (char 420). Line: 406.
Append: [Polynomial Composition Activations: Unleashing the Dynamics of Large Language Models](https://arxiv.org/abs/2411.03884)
Token length: 1083
Summarized using gpt-4o-mini
Append: [自我一致性偏好优化：提升模型推理能力的新方法](https://arxiv.org/abs/2411.04109)
append_entries: 2
Finish: 2024-11-07 18:09:21.083876
------------------------------------------------------
Started: 2024-11-07 21:00:55.372600
Existing_entries: 374
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1884
Summarized using gpt-4o-mini
Append: [探索o1-preview模型在医学挑战基准上的表现](https://arxiv.org/abs/2411.03590)
append_entries: 1
Finish: 2024-11-07 21:00:59.370382
------------------------------------------------------
Started: 2024-11-08 00:33:27.495793
Existing_entries: 375
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-08 00:33:27.600549
------------------------------------------------------
Started: 2024-11-08 03:11:30.043745
Existing_entries: 375
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1511
Summarized using gpt-4o-mini
Append: [推出TIP-I2V：首个大规模图像到视频生成用户提示数据集](https://arxiv.org/abs/2411.04709)
Token length: 956
Summarized using gpt-4o-mini
Append: [ReCapture：基于用户视频生成新视角视频的方法](https://arxiv.org/abs/2411.05003)
append_entries: 2
Finish: 2024-11-08 03:11:39.694871
------------------------------------------------------
Started: 2024-11-08 06:10:20.498646
Existing_entries: 377
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1920
Summarized using gpt-4o-mini
Append: [GazeGen: 基于视线控制的视觉内容生成系统](https://arxiv.org/abs/2411.04335)
Token length: 1351
Summarized using gpt-4o-mini
Append: [多面化心智技能对话数据集及其在大语言模型中的应用](https://arxiv.org/abs/2411.04496)
Token length: 1334
Summarized using gpt-4o-mini
Append: [多语言环境中代码混合对信息提取的挑战与解决方案](https://arxiv.org/abs/2411.04752)
Token length: 1421
Summarized using gpt-4o-mini
Append: [DimensionX框架：从单张图像生成真实感3D和4D场景](https://arxiv.org/abs/2411.04928)
Token length: 1612
Summarized using gpt-4o-mini
Append: [OpenCoder：独特的高质量代码语言模型及其开放研究价值](https://arxiv.org/abs/2411.04905)
Token length: 1571
Summarized using gpt-4o-mini
Append: [Mixture-of-Transformers：高效的多模态大语言模型架构](https://arxiv.org/abs/2411.04996)
Token length: 1046
Summarized using gpt-4o-mini
Append: [SG-I2V：一种自我引导的可控图像到视频生成框架](https://arxiv.org/abs/2411.04989)
Token length: 1383
Summarized using gpt-4o-mini
Append: [DynaMem：动态空间语义记忆驱动的开放词汇移动操控](https://arxiv.org/abs/2411.04999)
append_entries: 8
Finish: 2024-11-08 06:11:07.632627
------------------------------------------------------
Started: 2024-11-08 09:00:41.514318
Existing_entries: 385
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 958
Summarized using gpt-4o-mini
Append: [BitNet a4.8: 高效的4-bit激活的大型语言模型](https://arxiv.org/abs/2411.04965)
Token length: 1890
Summarized using gpt-4o-mini
Append: [SVDQuant：提升扩散模型的4位量化效率](https://arxiv.org/abs/2411.05007)
append_entries: 2
Finish: 2024-11-08 09:00:57.853113
------------------------------------------------------
Started: 2024-11-08 12:00:56.282384
Existing_entries: 387
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1412
Summarized using gpt-4o-mini
Append: [长文本语言模型的上下文处理能力评估](https://arxiv.org/abs/2411.05000)
Token length: 1343
Summarized using gpt-4o-mini
Append: [VideoGLaMM：实现视频与文本的细粒度对齐](https://arxiv.org/abs/2411.04923)
append_entries: 2
Finish: 2024-11-08 12:01:03.668071
------------------------------------------------------
Started: 2024-11-08 15:00:47.826454
Existing_entries: 389
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-08 15:00:47.978854
------------------------------------------------------
Started: 2024-11-08 18:00:50.336037
Existing_entries: 389
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-08 18:00:50.501034
------------------------------------------------------
Started: 2024-11-08 21:00:58.137442
Existing_entries: 389
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1209
Summarized using gpt-4o-mini
Append: [M3SciQA: 多模态多文档科学问答基准的提出与评估](https://arxiv.org/abs/2411.04075)
Token length: 1833
Summarized using gpt-4o-mini
Append: [引入M3DocRAG框架提升文档视觉问答能力](https://arxiv.org/abs/2411.04952)
Token length: 1255
Summarized using gpt-4o-mini
Append: [Diff-2-in-1：统一的扩散模型框架用于多模态生成与视觉感知](https://arxiv.org/abs/2411.05005)
append_entries: 3
Finish: 2024-11-08 21:01:08.332085
------------------------------------------------------
Started: 2024-11-09 00:32:39.628836
Existing_entries: 392
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1507
Summarized using gpt-4o-mini
Append: [分析视觉语言的统计特性与自然语言的对比](https://arxiv.org/abs/2411.05001)
append_entries: 1
Finish: 2024-11-09 00:32:42.947922
------------------------------------------------------
Started: 2024-11-09 03:10:27.808449
Existing_entries: 393
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-09 03:10:27.906316
------------------------------------------------------
Started: 2024-11-09 06:00:39.105868
Existing_entries: 393
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-09 06:00:39.267658
------------------------------------------------------
Started: 2024-11-09 09:00:36.651014
Existing_entries: 393
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-09 09:00:36.756563
------------------------------------------------------
Started: 2024-11-09 12:00:49.293744
Existing_entries: 393
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-09 12:00:49.447056
------------------------------------------------------
Started: 2024-11-09 15:01:03.494284
Existing_entries: 393
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-09 15:01:03.645144
------------------------------------------------------
Started: 2024-11-09 18:00:41.126500
Existing_entries: 393
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-09 18:00:41.291889
------------------------------------------------------
Started: 2024-11-09 21:01:03.565610
Existing_entries: 393
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-09 21:01:03.723186
------------------------------------------------------
Started: 2024-11-10 00:36:21.938087
Existing_entries: 393
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-10 00:36:22.038221
------------------------------------------------------
Started: 2024-11-10 03:13:14.247859
Existing_entries: 393
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-10 03:13:14.397292
------------------------------------------------------
Started: 2024-11-10 06:00:40.554827
Existing_entries: 393
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-10 06:00:40.727222
------------------------------------------------------
Started: 2024-11-10 09:00:58.612947
Existing_entries: 393
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-10 09:00:58.798388
------------------------------------------------------
Started: 2024-11-10 12:10:51.162052
Existing_entries: 393
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-10 12:10:51.296592
------------------------------------------------------
Started: 2024-11-10 15:00:46.764776
Existing_entries: 393
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-10 15:00:47.001235
------------------------------------------------------
Started: 2024-11-10 18:00:59.130885
Existing_entries: 393
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-10 18:00:59.246836
------------------------------------------------------
Started: 2024-11-10 21:00:48.424978
Existing_entries: 393
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-10 21:00:48.528694
------------------------------------------------------
Started: 2024-11-11 00:34:59.742890
Existing_entries: 393
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-11 00:34:59.896504
------------------------------------------------------
Started: 2024-11-11 03:13:27.425704
Existing_entries: 393
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-11 03:13:27.547536
------------------------------------------------------
Started: 2024-11-11 06:00:42.801546
Existing_entries: 393
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1490
Summarized using gpt-4o-mini
Append: [大语言模型单元测试生成的参数高效微调研究](https://arxiv.org/abs/2411.02462)
Token length: 1504
Summarized using gpt-4o-mini
Append: [StdGEN：从单幅图像生成高质量3D角色的创新管道](https://arxiv.org/abs/2411.05738)
append_entries: 2
Finish: 2024-11-11 06:00:50.158946
------------------------------------------------------
Started: 2024-11-11 09:00:52.961159
Existing_entries: 395
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-11 09:00:53.051939
------------------------------------------------------
Started: 2024-11-11 12:13:07.362918
Existing_entries: 395
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1742
Summarized using gpt-4o-mini
Append: [利用代码注释识别技术债务的首个数据集构建与实证分析](https://arxiv.org/abs/2411.05457)
Token length: 1402
Summarized using gpt-4o-mini
Append: [DELIFT：提高大语言模型微调效率的创新算法](https://arxiv.org/abs/2411.04425)
Token length: 1457
Summarized using gpt-4o-mini
Append: [通过词汇并行与管道调度优化大语言模型训练](https://arxiv.org/abs/2411.05288)
append_entries: 3
Finish: 2024-11-11 12:13:20.724797
------------------------------------------------------
Started: 2024-11-11 15:00:45.833235
Existing_entries: 398
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-11 15:00:45.941805
------------------------------------------------------
Started: 2024-11-11 18:00:34.918432
Existing_entries: 398
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1762
Summarized using gpt-4o-mini
Append: [LLM2CLIP：利用大型语言模型提升CLIP的多模态表示学习](https://arxiv.org/abs/2411.04997)
append_entries: 1
Finish: 2024-11-11 18:00:38.866854
------------------------------------------------------
Started: 2024-11-11 21:01:00.624624
Existing_entries: 399
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1353
Summarized using gpt-4o-mini
Append: [现代语言模型的语义枢纽假设](https://arxiv.org/abs/2411.04986)
append_entries: 1
Finish: 2024-11-11 21:01:05.445445
------------------------------------------------------
Started: 2024-11-12 00:33:01.191000
Existing_entries: 400
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1420
Summarized using gpt-4o-mini
Append: [RaVL：基于局部特征的视觉语言模型鲁棒性提升方法](https://arxiv.org/abs/2411.04097)
append_entries: 1
Finish: 2024-11-12 00:33:04.637206
------------------------------------------------------
Started: 2024-11-12 03:09:56.123355
Existing_entries: 401
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1559
Summarized using gpt-4o-mini
Append: [CAD-MLLM：基于多模态输入的统一计算机辅助设计生成系统](https://arxiv.org/abs/2411.04954)
Token length: 1214
Summarized using gpt-4o-mini
Append: [LaTent Reasoning Optimization：提升大语言模型推理能力的框架](https://arxiv.org/abs/2411.04282)
append_entries: 2
Finish: 2024-11-12 03:10:02.964887
------------------------------------------------------
Started: 2024-11-12 06:01:08.475557
Existing_entries: 403
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-12 06:01:08.620926
------------------------------------------------------
Started: 2024-11-12 09:00:48.156448
Existing_entries: 403
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 512
Summarized using gpt-4o-mini
Append: [Edify Image：新一代图像生成扩散模型](https://arxiv.org/abs/2411.07126)
Token length: 1134
Summarized using gpt-4o-mini
Append: [TRACE基准与IOPO方法：提升大型语言模型复杂指令跟随能力](https://arxiv.org/abs/2411.06208)
Token length: 1383
Summarized using gpt-4o-mini
Append: [基于反事实推理的语言模型干预机制研究](https://arxiv.org/abs/2411.07180)
Token length: 1365
Summarized using gpt-4o-mini
Append: [M-LongDoc：多模态长文档问答的新基准和框架](https://arxiv.org/abs/2411.06176)
Token length: 1697
Summarized using gpt-4o-mini
Append: [金色基准：评估金融领域大型语言模型的首个综合双语基准](https://arxiv.org/abs/2411.06272)
append_entries: 5
Finish: 2024-11-12 09:01:07.620972
------------------------------------------------------
Started: 2024-11-12 12:01:04.917591
Existing_entries: 408
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1147
Summarized using gpt-4o-mini
Append: [Add-it：无须训练的语义图像编辑新方法](https://arxiv.org/abs/2411.07232)
Token length: 1828
Summarized using gpt-4o-mini
Append: [大型语言模型在博弈理论中的理性决策能力研究](https://arxiv.org/abs/2411.05990)
Token length: 1100
Summarized using gpt-4o-mini
Append: [发布中文SimpleQA基准，评估大型语言模型的 factuality 能力](https://arxiv.org/abs/2411.07140)
Token length: 1748
Summarized using gpt-4o-mini
Append: [OmniEdit：一种通用图像编辑模型](https://arxiv.org/abs/2411.07199)
append_entries: 4
Finish: 2024-11-12 12:01:23.907734
------------------------------------------------------
Started: 2024-11-12 15:01:03.186268
Existing_entries: 412
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1154
Summarized using gpt-4o-mini
Append: [深度学习水印模型WAM实现局部图像水印嵌入](https://arxiv.org/abs/2411.07231)
Token length: 1068
Summarized using gpt-4o-mini
Append: [直接偏好优化在语言模型毒性降低中的作用机制探讨](https://arxiv.org/abs/2411.06424)
Token length: 1469
Summarized using gpt-4o-mini
Append: [针对人类动作生成的新型KMM架构研究](https://arxiv.org/abs/2411.06481)
append_entries: 3
Finish: 2024-11-12 15:01:19.147786
------------------------------------------------------
Started: 2024-11-12 18:09:02.248240
Existing_entries: 415
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1526
Summarized using gpt-4o-mini
Append: [GitChameleon: 适应版本变化的Python代码生成基准](https://arxiv.org/abs/2411.05830)
Token length: 1200
Summarized using gpt-4o-mini
Append: [混合专家模型在多任务纠错中的应用与性能提升](https://arxiv.org/abs/2411.05945)
append_entries: 2
Finish: 2024-11-12 18:09:10.332686
------------------------------------------------------
Started: 2024-11-12 21:01:07.769458
Existing_entries: 417
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-12 21:01:07.910702
------------------------------------------------------
Started: 2024-11-13 00:33:52.906990
Existing_entries: 417
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1848
Summarized using gpt-4o-mini
Append: [小型蛋白语言模型的开发与性能评估](https://arxiv.org/abs/2411.05966)
Token length: 1760
Summarized using gpt-4o-mini
Append: [自回归模型在计算机视觉中的应用与挑战](https://arxiv.org/abs/2411.05902)
append_entries: 2
Finish: 2024-11-13 00:33:59.679770
------------------------------------------------------
Started: 2024-11-13 03:12:44.624970
Existing_entries: 419
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-13 03:12:44.806006
------------------------------------------------------
Started: 2024-11-13 06:00:54.361811
Existing_entries: 419
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-13 06:00:54.459495
------------------------------------------------------
Started: 2024-11-13 09:00:44.109472
Existing_entries: 419
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1710
Summarized using gpt-4o-mini
Append: [SAMPart3D：无文本提示的可扩展零-shot 3D 部件分割框架](https://arxiv.org/abs/2411.07184)
append_entries: 1
Finish: 2024-11-13 09:00:50.000369
------------------------------------------------------
Started: 2024-11-13 12:12:32.951513
Existing_entries: 420
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1300
Summarized using gpt-4o-mini
Append: [挑战传统观念：大型语言模型教学效能的新发现](https://arxiv.org/abs/2411.07133)
Token length: 985
Summarized using gpt-4o-mini
Append: [JanusFlow：统一图像理解与生成的强大框架](https://arxiv.org/abs/2411.07975)
append_entries: 2
Finish: 2024-11-13 12:12:44.350314
------------------------------------------------------
Started: 2024-11-13 15:00:52.705071
Existing_entries: 422
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1728
Summarized using gpt-4o-mini
Append: [硬件与软件平台推理方法的提出与验证](https://arxiv.org/abs/2411.05197)
Token length: 1394
Summarized using gpt-4o-mini
Append: [Wavelet潜在扩散：一种高效的3D生成模型方法](https://arxiv.org/abs/2411.08017)
append_entries: 2
Finish: 2024-11-13 15:01:07.164626
------------------------------------------------------
Started: 2024-11-13 18:01:13.981481
Existing_entries: 424
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "BLIP3-KALE数据集：结合合成描述性字幕与真实网络文本的图像-文本对",
  "keyword": ["数据集", "图像-文本", "多模态模型"],
  "short_summary": "BLIP3-KALE是一个包含2.18亿图像-文本对的数据集，提升了多模态模型的表现。",
  "summary": "BLIP3-KALE是一个包含2.18亿图像-文本对的新数据集，旨在弥合合成描述性字幕与真实网络替代文本之间的差距。KALE通过结合网络规模的替代文本来增强合成的密集图像字幕，从而生成基础于事实的图像字幕。该数据集的构建采取了两阶段的方法，利用大型视觉语言模型和语言模型创建知识增强的字幕，然后用以训练专门的视觉语言模型，从而扩展数据集规模。我们的实验显示，KALE的数据集在视觉语言任务中表现出显著的改进，有助于训练更加高效且富有知识的多模态模型。KALE数据集的详细信息可在https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 260 (char 419). Line: 406.
Append: [BLIP3-KALE: Knowledge Augmented Large-Scale Dense Captions](https://arxiv.org/abs/2411.07461)
append_entries: 1
Finish: 2024-11-13 18:01:19.975600
------------------------------------------------------
Started: 2024-11-13 21:00:49.342812
Existing_entries: 425
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 731
Summarized using gpt-4o-mini
Append: [扩散模型在视觉感知任务中的迭代计算应用](https://arxiv.org/abs/2411.08034)
Json decode failed:
{
  "title": "声学体积渲染：虚拟现实中的冲激响应合成新方法",
  "keyword": ["声学渲染", "冲激响应", "虚拟现实"],
  "short_summary": "本研究提出声学体积渲染方法，以合成虚拟现实中的精确冲激响应。",
  "summary": "本文提出了一种新的声学体积渲染（AVR）方法，旨在破解虚拟现实和增强现实中的音频合成难题。通过估算冲激响应（IR），AVR能在不同位置模拟音频传播特性并高效合成声音。本研究采用频域体积渲染与球面积分来处理时间序列信号，构建一个固有编码声波传播原则的冲激响应场。实验证明，AVR在合成新姿态的冲激响应方面，其性能显著优于现有主流方法。此外，我们还开发了AcoustiX音频模拟平台，该平台提供比现有模拟器更为准确和真实的冲激响应模拟。相关代码可在 https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 244 (char 374). Line: 406.
Append: [Acoustic Volume Rendering for Neural Impulse Response Fields](https://arxiv.org/abs/2411.06307)
append_entries: 2
Finish: 2024-11-13 21:01:00.635576
------------------------------------------------------
Started: 2024-11-14 00:33:59.075479
Existing_entries: 427
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-14 00:33:59.157126
------------------------------------------------------
Started: 2024-11-14 03:13:24.692964
Existing_entries: 427
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-14 03:13:24.831562
------------------------------------------------------
Started: 2024-11-14 06:00:43.405259
Existing_entries: 427
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-14 06:00:43.541249
------------------------------------------------------
Started: 2024-11-14 09:00:52.265992
Existing_entries: 427
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1472
Summarized using gpt-4o-mini
Append: [EgoVid-5M：用于自我中心视频生成的高质量数据集](https://arxiv.org/abs/2411.08380)
Token length: 1102
Summarized using gpt-4o-mini
Append: [特征级约束偏好优化：提升大语言模型的效率与稳定性](https://arxiv.org/abs/2411.07618)
append_entries: 2
Finish: 2024-11-14 09:00:59.676651
------------------------------------------------------
Started: 2024-11-14 12:01:00.084328
Existing_entries: 429
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 792
Summarized using gpt-4o-mini
Append: [深入探讨稀疏自编码器在控制大语言模型中的作用](https://arxiv.org/abs/2411.08790)
Token length: 1494
Summarized using gpt-4o-mini
Append: [CamemBERT新版本应对语言模型时间概念漂移](https://arxiv.org/abs/2411.08868)
Json decode failed:
{
  "title": "自我改进长文本推理的语言模型新方法",
  "keyword": ["长文本推理", "语言模型", "自我改进"],
  "short_summary": "提出一种新方法，实现语言模型在长文本推理上的自我改进。",
  "summary": "本文探讨了大型语言模型（LLMs）在长文本推理中的自我改进潜力，提出了一种新方法\ours，专门针对这一问题。该方法通过为每个问题生成多个输出，并利用最小贝叶斯风险进行评分，从而进行监督精调或偏好优化。实验结果表明，在多个领先的LLMs上，\ours方法表现出显著的有效性，Llama-3.1-8B-Instruct模型的绝对提升达4.2分。此外，\ours相比于依赖人类专家或高级模型生成的数据的先前方法，展现出了更优越的性能。这项工作预计将为长文本场景中的自我改进技术开辟新的研究方向，从而推动大型语言模型的持续进步。"
}Summarization failed, append the original article
error: Invalid \escape: line 5 column 55 (char 178). Line: 406.
Append: [Large Language Models Can Self-Improve in Long-context Reasoning](https://arxiv.org/abs/2411.08147)
append_entries: 3
Finish: 2024-11-14 12:01:12.004213
------------------------------------------------------
Started: 2024-11-14 15:00:57.972741
Existing_entries: 432
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-14 15:00:58.131730
------------------------------------------------------
Started: 2024-11-14 18:00:42.712145
Existing_entries: 432
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-14 18:00:42.868456
------------------------------------------------------
Started: 2024-11-14 21:01:07.189216
Existing_entries: 432
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1000
Summarized using gpt-4o-mini
Append: [PerceiverS架构：提升符号音乐生成的长结构与表现力](https://arxiv.org/abs/2411.08307)
Token length: 1372
Summarized using gpt-4o-mini
Append: [MVideo：提升文本到视频生成的动态动作表现](https://arxiv.org/abs/2411.08328)
append_entries: 2
Finish: 2024-11-14 21:01:13.144308
------------------------------------------------------
Started: 2024-11-15 00:36:21.639963
Existing_entries: 434
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-15 00:36:21.733307
------------------------------------------------------
Started: 2024-11-15 03:21:04.576062
Existing_entries: 434
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-15 03:21:04.697127
------------------------------------------------------
Started: 2024-11-15 06:00:49.526597
Existing_entries: 434
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1266
Summarized using gpt-4o-mini
Append: [大语言模型在临床预测中的表现：对传统机器学习模型的比较](https://arxiv.org/abs/2411.06469)
Token length: 930
Summarized using gpt-4o-mini
Append: [MagicQuill：高效的集成图像编辑系统](https://arxiv.org/abs/2411.09703)
append_entries: 2
Finish: 2024-11-15 06:00:58.180521
------------------------------------------------------
Started: 2024-11-15 09:00:56.456919
Existing_entries: 436
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1497
Summarized using gpt-4o-mini
Append: [Cut Cross-Entropy：优化大型语言模型的内存使用](https://arxiv.org/abs/2411.09009)
Token length: 1246
Summarized using gpt-4o-mini
Append: [LLaMA-Mesh：整合文本与3D网格生成的统一模型](https://arxiv.org/abs/2411.09595)
append_entries: 2
Finish: 2024-11-15 09:01:06.235488
------------------------------------------------------
Started: 2024-11-15 12:13:00.635927
Existing_entries: 438
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1290
Summarized using gpt-4o-mini
Append: [基于视觉-语言模型的用户动作提取方法研究](https://arxiv.org/abs/2411.08768)
append_entries: 1
Finish: 2024-11-15 12:13:03.816167
------------------------------------------------------
Started: 2024-11-15 15:01:07.719295
Existing_entries: 439
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1198
Summarized using gpt-4o-mini
Append: [Hermes：推动网络智能与自主运营的创新方案](https://arxiv.org/abs/2411.06490)
append_entries: 1
Finish: 2024-11-15 15:01:12.054487
------------------------------------------------------
Started: 2024-11-15 18:01:11.357159
Existing_entries: 440
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-15 18:01:11.520833
------------------------------------------------------
Started: 2024-11-15 21:00:44.097879
Existing_entries: 440
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-15 21:00:44.179278
------------------------------------------------------
Started: 2024-11-16 00:35:16.395696
Existing_entries: 440
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1108
Summarized using gpt-4o-mini
Append: [一致性模型的有效性分析与直接一致性模型的比较](https://arxiv.org/abs/2411.08954)
append_entries: 1
Finish: 2024-11-16 00:35:19.841352
------------------------------------------------------
Started: 2024-11-16 03:18:38.923601
Existing_entries: 441
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-16 03:18:39.009889
------------------------------------------------------
Started: 2024-11-16 06:01:13.259642
Existing_entries: 441
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-16 06:01:13.416140
------------------------------------------------------
Started: 2024-11-16 09:00:43.253459
Existing_entries: 441
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-16 09:00:43.358841
------------------------------------------------------
Started: 2024-11-16 12:11:37.044868
Existing_entries: 441
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-16 12:11:37.164562
------------------------------------------------------
Started: 2024-11-16 15:00:43.407630
Existing_entries: 441
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-16 15:00:43.521103
------------------------------------------------------
Started: 2024-11-16 18:00:48.653034
Existing_entries: 441
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-16 18:00:48.892321
------------------------------------------------------
Started: 2024-11-16 21:00:46.032758
Existing_entries: 441
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-16 21:00:46.190948
------------------------------------------------------
Started: 2024-11-17 00:38:40.426173
Existing_entries: 441
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-17 00:38:40.519795
------------------------------------------------------
Started: 2024-11-17 03:23:23.936577
Existing_entries: 441
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-17 03:23:24.048350
------------------------------------------------------
Started: 2024-11-17 06:01:09.398513
Existing_entries: 441
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-17 06:01:09.491505
------------------------------------------------------
Started: 2024-11-17 09:01:01.451542
Existing_entries: 441
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-17 09:01:01.602905
------------------------------------------------------
Started: 2024-11-17 12:11:38.900507
Existing_entries: 441
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-17 12:11:39.063068
------------------------------------------------------
Started: 2024-11-17 15:01:01.601708
Existing_entries: 441
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-17 15:01:01.759773
------------------------------------------------------
Started: 2024-11-17 18:00:45.353393
Existing_entries: 441
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-17 18:00:45.678800
------------------------------------------------------
Started: 2024-11-17 21:00:42.999523
Existing_entries: 441
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-17 21:00:55.160194
------------------------------------------------------
Started: 2024-11-18 00:37:43.354081
Existing_entries: 441
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-18 00:37:43.515639
------------------------------------------------------
Started: 2024-11-18 03:23:48.397694
Existing_entries: 441
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-18 03:23:48.547851
------------------------------------------------------
Started: 2024-11-18 06:00:53.509312
Existing_entries: 441
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1092
Summarized using gpt-4o-mini
Append: [基于点云结构的3D生成框架GaussianAnything](https://arxiv.org/abs/2411.08033)
Token length: 1396
Summarized using gpt-4o-mini
Append: [LLaVA-o1: 一个针对视觉语言模型的多阶段推理框架](https://arxiv.org/abs/2411.10440)
append_entries: 2
Finish: 2024-11-18 06:01:02.365556
------------------------------------------------------
Started: 2024-11-18 09:01:16.782563
Existing_entries: 443
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "NumPro: 提升视频时间定位的创新方法",
  "keyword": ["视频语言模型", "时间定位", "NumPro"],
  "short_summary": "NumPro方法有效提升了视频语言模型在时间定位任务中的表现。",
  "summary": "视频大型语言模型（Vid-LLMs）在视频内容理解和问答对话中取得了显著进展，但在需要精确时间定位的任务（视频时间定位VTG）中仍存在不足。为了解决这一问题，本文提出了一种新方法NumPro，它通过为每帧视频添加唯一数字标识，帮助Vid-LLMs将视觉理解与时间定位结合，类似于翻阅漫画面板，使得对事件时间线的"阅读"更加直观。实验结果表明，NumPro显著提升了顶级Vid-LLMs在VTG任务上的表现，而无需额外的计算成本。此外，通过在NumPro增强数据集上的微调，使VTG性能达到新的最先进水平，在时刻检索中提高了6.9%的mIoU，并在亮点检测中提高了8.5%的mAP。"
}Summarization failed, append the original article
error: Expecting ',' delimiter: line 5 column 171 (char 305). Line: 406.
Append: [Number it: Temporal Grounding Videos like Flipping Manga](https://arxiv.org/abs/2411.10332)
Token length: 1152
Summarized using gpt-4o-mini
Append: [Claude 3.5计算机使用模型的案例研究](https://arxiv.org/abs/2411.10323)
append_entries: 2
Finish: 2024-11-18 09:01:25.531375
------------------------------------------------------
Started: 2024-11-18 12:14:00.623712
Existing_entries: 445
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-18 12:14:00.732718
------------------------------------------------------
Started: 2024-11-18 15:00:51.400557
Existing_entries: 445
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-18 15:00:51.558569
------------------------------------------------------
Started: 2024-11-18 18:00:51.796206
Existing_entries: 445
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1451
Summarized using gpt-4o-mini
Append: [RAG：基于区域描述的文本到图像生成方法](https://arxiv.org/abs/2411.06558)
Token length: 880
Summarized using gpt-4o-mini
Append: [Xmodel-1.5: 一种新型多语种大模型的推出及其性能评估](https://arxiv.org/abs/2411.10083)
append_entries: 2
Finish: 2024-11-18 18:01:01.379787
------------------------------------------------------
Started: 2024-11-18 21:00:49.299707
Existing_entries: 447
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-18 21:00:49.451206
------------------------------------------------------
Started: 2024-11-19 00:36:26.274325
Existing_entries: 447
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1204
Summarized using gpt-4o-mini
Append: [MARS: 一种高效的大模型优化框架](https://arxiv.org/abs/2411.10438)
append_entries: 1
Finish: 2024-11-19 00:36:32.432990
------------------------------------------------------
Started: 2024-11-19 03:21:09.927281
Existing_entries: 448
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-19 03:21:10.013879
------------------------------------------------------
Started: 2024-11-19 06:00:54.951190
Existing_entries: 448
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 726
Summarized using gpt-4o-mini
Append: [重评估重排器在信息检索中的有效性](https://arxiv.org/abs/2411.11767)
Token length: 1081
Summarized using gpt-4o-mini
Append: [top-nsigma：一种新型的抽样方法提升推理任务表现](https://arxiv.org/abs/2411.07641)
append_entries: 2
Finish: 2024-11-19 06:01:07.287214
------------------------------------------------------
Started: 2024-11-19 09:01:02.192524
Existing_entries: 450
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1277
Summarized using gpt-4o-mini
Append: [Generative World Explorer: 基于想象的世界探索框架](https://arxiv.org/abs/2411.11844)
Token length: 1354
Summarized using gpt-4o-mini
Append: [医学领域的检索增强生成 (RAG) 系统评估框架](https://arxiv.org/abs/2411.09213)
Token length: 1228
Summarized using gpt-4o-mini
Append: [SlimLM：优化移动设备的高效小型语言模型](https://arxiv.org/abs/2411.09944)
Token length: 960
Summarized using gpt-4o-mini
Append: [统一可控视频生成方法AnimateAnything](https://arxiv.org/abs/2411.10836)
Token length: 1049
Summarized using gpt-4o-mini
Append: [验证工程：基础模型时代的新监督信号](https://arxiv.org/abs/2411.11504)
Token length: 1042
Summarized using gpt-4o-mini
Append: [Awaker2.5-VL: 为多模态大型语言模型设计的混合专家架构](https://arxiv.org/abs/2411.10669)
Token length: 1067
Summarized using gpt-4o-mini
Append: [SmoothCache: 加速Diffusion Transformers推理的模型无关技术](https://arxiv.org/abs/2411.10510)
Token length: 1556
Summarized using gpt-4o-mini
Append: [FitDiT：高保真虚拟试衣的新方法](https://arxiv.org/abs/2411.10499)
Token length: 1543
Summarized using gpt-4o-mini
Append: [BlueLM-V-3B：高效部署多模态大语言模型于移动平台的创新方案](https://arxiv.org/abs/2411.10640)
append_entries: 9
Finish: 2024-11-19 09:02:06.116633
------------------------------------------------------
Started: 2024-11-19 12:00:52.087399
Existing_entries: 459
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1213
Summarized using gpt-4o-mini
Append: [基于形状一致性的视频编辑方法StableV2V的研究](https://arxiv.org/abs/2411.11045)
Token length: 961
Summarized using gpt-4o-mini
Append: [LLäMmlein德语解码模型的创建与评估](https://arxiv.org/abs/2411.11171)
append_entries: 2
Finish: 2024-11-19 12:01:04.489983
------------------------------------------------------
Started: 2024-11-19 15:00:52.260485
Existing_entries: 461
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1347
Summarized using gpt-4o-mini
Append: [VeGaS：用于视频数据的高效编辑和重建的算法](https://arxiv.org/abs/2411.11024)
Json decode failed:
{
  "title": "大型语言模型的反馈质量与写作指南的影响研究",
  "keyword": ["大型语言模型", "反馈质量", "写作指南"],
  "short_summary": "研究显示详细的指导能提升AI反馈质量，但对信息获取能力的效果有限。",
  "summary": "随着大型语言模型（LLMs）的能力提升，它们被用作人类反馈的替代品来训练和评估其他模型。本文探讨了选择不同写作指南（"宪法"）对反馈质量的影响，使用四种不同的宪法来改善医疗访谈中的以病人为中心的沟通。通过215名人类评审者进行的配对比较研究发现，详尽的宪法在情感质量方面的效果更佳。然而，所有宪法在帮助学习更具实用性的技能（如信息收集和提供）方面均未超过基准。这些结果表明，尽管应优先考虑使用详细的宪法，但AI反馈作为奖励信号在某些领域的有效性可能存在局限性。"
}Summarization failed, append the original article
error: Expecting ',' delimiter: line 5 column 74 (char 208). Line: 406.
Append: [Evaluating the role of `Constitutions' for learning from AI feedback](https://arxiv.org/abs/2411.10168)
Token length: 908
Summarized using gpt-4o-mini
Append: [动态温度采样优化：自适应解码方法研究](https://arxiv.org/abs/2411.09661)
append_entries: 3
Finish: 2024-11-19 15:01:19.523551
------------------------------------------------------
Started: 2024-11-19 18:10:09.838180
Existing_entries: 464
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-19 18:10:10.004269
------------------------------------------------------
Started: 2024-11-19 21:00:50.824201
Existing_entries: 464
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-19 21:00:51.076804
------------------------------------------------------
Started: 2024-11-20 00:35:46.945677
Existing_entries: 464
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-20 00:35:47.096225
------------------------------------------------------
Started: 2024-11-20 03:20:10.770227
Existing_entries: 464
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-20 03:20:10.923880
------------------------------------------------------
Started: 2024-11-20 06:11:09.016534
Existing_entries: 464
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1236
Summarized using gpt-4o-mini
Append: [多语言大型语言模型的分词效率评估](https://arxiv.org/abs/2411.12240)
Token length: 1411
Summarized using gpt-4o-mini
Append: [连续值自回归图像生成模型的推测解码优化](https://arxiv.org/abs/2411.11925)
append_entries: 2
Finish: 2024-11-20 06:11:20.226126
------------------------------------------------------
Started: 2024-11-20 09:01:13.711465
Existing_entries: 466
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-20 09:01:13.775512
------------------------------------------------------
Started: 2024-11-20 12:13:14.193562
Existing_entries: 466
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1826
Summarized using gpt-4o-mini
Append: [RedPajama数据集：推动开放源语言模型的发展](https://arxiv.org/abs/2411.12372)
Token length: 798
Summarized using gpt-4o-mini
Append: [AI模型安全与风险管理研究](https://arxiv.org/abs/2411.12275)
Token length: 1377
Summarized using gpt-4o-mini
Append: [SWIFT: 一种用于动态任务学习的软体机器人手](https://arxiv.org/abs/2411.12734)
append_entries: 3
Finish: 2024-11-20 12:13:27.915540
------------------------------------------------------
Started: 2024-11-20 15:01:09.316215
Existing_entries: 469
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1406
Summarized using gpt-4o-mini
Append: [基于SEAGULL的区域质量评估方法研究](https://arxiv.org/abs/2411.10161)
Token length: 1143
Summarized using gpt-4o-mini
Append: [通过新模块提升CLIP在开集语义分割中的性能](https://arxiv.org/abs/2411.12044)
append_entries: 2
Finish: 2024-11-20 15:01:21.501512
------------------------------------------------------
Started: 2024-11-20 18:01:15.887006
Existing_entries: 471
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1231
Summarized using gpt-4o-mini
Append: [FlipSketch：简化素描动画创作的创新系统](https://arxiv.org/abs/2411.10818)
append_entries: 1
Finish: 2024-11-20 18:01:20.817809
------------------------------------------------------
Started: 2024-11-20 21:01:05.926338
Existing_entries: 472
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-20 21:01:06.036130
------------------------------------------------------
Started: 2024-11-21 00:35:42.532121
Existing_entries: 472
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-21 00:35:42.712945
------------------------------------------------------
Started: 2024-11-21 03:20:03.370718
Existing_entries: 472
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1330
Summarized using gpt-4o-mini
Append: [提高大规模多模态模型的学习能力：符号演示直接偏好优化方法](https://arxiv.org/abs/2411.11909)
append_entries: 1
Finish: 2024-11-21 03:20:07.940228
------------------------------------------------------
Started: 2024-11-21 06:00:59.650822
Existing_entries: 473
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1675
Summarized using gpt-4o-mini
Append: [WebDreamer: 利用语言模型优化网络代理的模型驱动规划](https://arxiv.org/abs/2411.06559)
Token length: 1399
Summarized using gpt-4o-mini
Append: [SageAttention2: 通过低精度矩阵乘法加速注意力计算](https://arxiv.org/abs/2411.10958)
Token length: 1451
Summarized using gpt-4o-mini
Append: [SAMURAI：面向视觉目标跟踪的SAM 2增强模型](https://arxiv.org/abs/2411.11922)
append_entries: 3
Finish: 2024-11-21 06:01:14.144063
------------------------------------------------------
Started: 2024-11-21 09:00:52.697377
Existing_entries: 476
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-21 09:00:52.779122
------------------------------------------------------
Started: 2024-11-21 12:13:27.114291
Existing_entries: 476
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1432
Summarized using gpt-4o-mini
Append: [AnchorAttention：提升长序列处理能力的解决方案](https://arxiv.org/abs/2411.13476)
Token length: 1322
Summarized using gpt-4o-mini
Append: [基于器官区域信息的放射学报告生成框架研究](https://arxiv.org/abs/2411.13025)
Token length: 1915
Summarized using gpt-4o-mini
Append: [VideoAutoArena：一种自动评估视频分析能力的新基准](https://arxiv.org/abs/2411.13281)
Token length: 1854
Summarized using gpt-4o-mini
Append: [VBench: 视频生成模型评估的综合基准](https://arxiv.org/abs/2411.13503)
append_entries: 4
Finish: 2024-11-21 12:13:48.006060
------------------------------------------------------
Started: 2024-11-21 15:01:08.136547
Existing_entries: 480
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 929
Summarized using gpt-4o-mini
Append: [StyleCodes: 开源的图像风格编码器架构](https://arxiv.org/abs/2411.12811)
append_entries: 1
Finish: 2024-11-21 15:01:12.638595
------------------------------------------------------
Started: 2024-11-21 18:01:07.612482
Existing_entries: 481
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-21 18:01:07.847590
------------------------------------------------------
Started: 2024-11-21 21:01:09.973140
Existing_entries: 481
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-21 21:01:10.063647
------------------------------------------------------
Started: 2024-11-22 00:36:42.135715
Existing_entries: 481
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1244
Summarized using gpt-4o-mini
Append: [基于 shifted power law 的模型训练损失预测策略](https://arxiv.org/abs/2411.12925)
Token length: 1331
Summarized using gpt-4o-mini
Append: [ViBe：大型文本生成视频模型的幻觉视频基准](https://arxiv.org/abs/2411.10867)
append_entries: 2
Finish: 2024-11-22 00:36:50.163173
------------------------------------------------------
Started: 2024-11-22 03:21:03.901419
Existing_entries: 483
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1028
Summarized using gpt-4o-mini
Append: [自然语言强化学习框架的探索与实现](https://arxiv.org/abs/2411.14251)
append_entries: 1
Finish: 2024-11-22 03:21:07.864879
------------------------------------------------------
Started: 2024-11-22 06:10:53.940800
Existing_entries: 484
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1226
Summarized using gpt-4o-mini
Append: [增强多模态推理能力的混合偏好优化方法](https://arxiv.org/abs/2411.10442)
Token length: 1095
Summarized using gpt-4o-mini
Append: [Hymba: 高效小型语言模型的新架构](https://arxiv.org/abs/2411.13676)
Token length: 909
Summarized using gpt-4o-mini
Append: [UltraMem：一种高效的超稀疏记忆层架构](https://arxiv.org/abs/2411.12364)
Token length: 725
Summarized using gpt-4o-mini
Append: [Marco-o1：扩展大型推理模型的能力](https://arxiv.org/abs/2411.14405)
Token length: 1650
Summarized using gpt-4o-mini
Append: [Insight-V：提升多模态语言模型推理能力的新方法](https://arxiv.org/abs/2411.14432)
Token length: 1297
Summarized using gpt-4o-mini
Append: [OpenScholar：基于文献的自然语言处理助手](https://arxiv.org/abs/2411.14199)
append_entries: 6
Finish: 2024-11-22 06:11:54.400740
------------------------------------------------------
Started: 2024-11-22 09:01:15.729214
Existing_entries: 490
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 962
Summarized using gpt-4o-mini
Append: [AIMV2：一种新型大规模视觉编码器的预训练方法](https://arxiv.org/abs/2411.14402)
Token length: 1193
Summarized using gpt-4o-mini
Append: [基于扩散变换器的图像编辑方法研究](https://arxiv.org/abs/2411.14430)
append_entries: 2
Finish: 2024-11-22 09:01:28.317725
------------------------------------------------------
Started: 2024-11-22 12:00:57.564601
Existing_entries: 492
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 927
Summarized using gpt-4o-mini
Append: [高效收集低资源语言数据的方法](https://arxiv.org/abs/2411.14343)
Token length: 1067
Summarized using gpt-4o-mini
Append: [MagicDriveDiT：一种新型高分辨率视频合成方法](https://arxiv.org/abs/2411.13807)
Token length: 1346
Summarized using gpt-4o-mini
Append: [稀疏自编码器揭示大语言模型中的幻觉机制](https://arxiv.org/abs/2411.14257)
Token length: 975
Summarized using gpt-4o-mini
Append: [改进大型语言模型的推理能力：链式思维方法的应用](https://arxiv.org/abs/2411.13082)
append_entries: 4
Finish: 2024-11-22 12:01:21.296018
------------------------------------------------------
Started: 2024-11-22 15:01:49.004731
Existing_entries: 496
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-22 15:01:49.091608
------------------------------------------------------
Started: 2024-11-22 18:01:13.085521
Existing_entries: 496
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-22 18:01:13.288738
------------------------------------------------------
Started: 2024-11-22 21:00:50.897443
Existing_entries: 496
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1138
Summarized using gpt-4o-mini
Append: [DiffusionGS：一种新型单阶段3D扩散模型](https://arxiv.org/abs/2411.14384)
append_entries: 1
Finish: 2024-11-22 21:00:59.760764
------------------------------------------------------
Started: 2024-11-23 00:35:14.744274
Existing_entries: 497
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1765
Summarized using gpt-4o-mini
Append: [DINO-X：开创性的物体中心视觉模型](https://arxiv.org/abs/2411.14347)
append_entries: 1
Finish: 2024-11-23 00:35:21.796021
------------------------------------------------------
Started: 2024-11-23 03:17:57.022287
Existing_entries: 498
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-23 03:17:57.154445
------------------------------------------------------
Started: 2024-11-23 06:01:22.374237
Existing_entries: 498
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-23 06:01:22.481046
------------------------------------------------------
Started: 2024-11-23 09:01:03.550828
Existing_entries: 498
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-23 09:01:03.668328
------------------------------------------------------
Started: 2024-11-23 12:01:04.725870
Existing_entries: 498
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-23 12:01:04.927868
------------------------------------------------------
Started: 2024-11-23 15:01:43.398573
Existing_entries: 498
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-23 15:01:43.520205
------------------------------------------------------
Started: 2024-11-23 18:01:06.754997
Existing_entries: 498
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-23 18:01:06.918699
------------------------------------------------------
Started: 2024-11-23 21:01:04.193421
Existing_entries: 498
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-23 21:01:04.368371
------------------------------------------------------
Started: 2024-11-24 00:39:09.545266
Existing_entries: 498
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-24 00:39:09.636719
------------------------------------------------------
Started: 2024-11-24 03:25:36.416734
Existing_entries: 498
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-24 03:25:36.569781
------------------------------------------------------
Started: 2024-11-24 06:01:52.088042
Existing_entries: 498
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-24 06:02:03.685949
------------------------------------------------------
Started: 2024-11-24 09:02:02.758639
Existing_entries: 498
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-24 09:02:02.840785
------------------------------------------------------
Started: 2024-11-24 12:00:52.284189
Existing_entries: 498
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-24 12:00:52.375237
------------------------------------------------------
Started: 2024-11-24 15:00:45.547216
Existing_entries: 498
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-24 15:00:45.708524
------------------------------------------------------
Started: 2024-11-24 18:00:46.514909
Existing_entries: 498
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-24 18:00:46.687367
------------------------------------------------------
Started: 2024-11-24 21:00:47.679478
Existing_entries: 498
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-24 21:00:47.845964
------------------------------------------------------
Started: 2024-11-25 00:37:40.361266
Existing_entries: 498
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-25 00:37:40.451270
------------------------------------------------------
Started: 2024-11-25 03:23:53.039366
Existing_entries: 498
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-25 03:23:53.400609
------------------------------------------------------
Started: 2024-11-25 06:00:58.167676
Existing_entries: 498
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1031
Summarized using gpt-4o-mini
Append: [风格友好的信噪比采样器：提升扩散模型的个性化艺术风格生成](https://arxiv.org/abs/2411.14793)
append_entries: 1
Finish: 2024-11-25 06:01:01.862582
------------------------------------------------------
Started: 2024-11-25 09:01:14.004932
Existing_entries: 499
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1664
Summarized using gpt-4o-mini
Append: [T"ULU 3: 开放的现代语言模型后训练技术](https://arxiv.org/abs/2411.15124)
Token length: 1446
Summarized using gpt-4o-mini
Append: [WildLMa：多环境下的四足机器人操作与规划能力研究](https://arxiv.org/abs/2411.15131)
Token length: 1152
Summarized using gpt-4o-mini
Append: [ViewExtrapolator：一种基于SVD的小说视图外推方法](https://arxiv.org/abs/2411.14208)
Token length: 1472
Summarized using gpt-4o-mini
Append: [MyTimeMachine: 结合全球年龄先验与个人照片实现个性化面部老化](https://arxiv.org/abs/2411.14521)
Token length: 1363
Summarized using gpt-4o-mini
Append: [OminiControl：高效的图像条件集成框架](https://arxiv.org/abs/2411.15098)
append_entries: 5
Finish: 2024-11-25 09:01:41.624817
------------------------------------------------------
Started: 2024-11-25 12:14:09.940222
Existing_entries: 504
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1898
Summarized using gpt-4o-mini
Append: [基于大语言模型的机器人行动规划架构研究](https://arxiv.org/abs/2411.15033)
Token length: 1567
Summarized using gpt-4o-mini
Append: [VideoEspresso：提升视频问答能力的新数据集及方法](https://arxiv.org/abs/2411.14794)
Token length: 1209
Summarized using gpt-4o-mini
Append: [无数据灵活开发大语言模型防护机制](https://arxiv.org/abs/2411.12946)
Token length: 1385
Summarized using gpt-4o-mini
Append: [CoordTok：高效视频标记化方法](https://arxiv.org/abs/2411.14762)
append_entries: 4
Finish: 2024-11-25 12:14:27.115392
------------------------------------------------------
Started: 2024-11-25 15:01:08.102704
Existing_entries: 508
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1504
Summarized using gpt-4o-mini
Append: [BALROG：评估大型语言模型与视觉语言模型能力的新基准](https://arxiv.org/abs/2411.13543)
Token length: 1154
Summarized using gpt-4o-mini
Append: [理解大型多模态模型的内部表示](https://arxiv.org/abs/2411.14982)
append_entries: 2
Finish: 2024-11-25 15:01:22.500939
------------------------------------------------------
Started: 2024-11-25 18:00:51.098728
Existing_entries: 510
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "Cloud-Adapter：提升遥感图像云分割精度的自适应方法",
  "short_summary": "本文提出Cloud-Adapter，利用视觉基础模型提高云分割的准确性和鲁棒性。",
  "summary": "云分割在遥感图像解读中是一个关键挑战，其准确性直接影响后续数据处理与分析的有效性。近期，视觉基础模型(VFM)显示出在多种视觉任务上具有强大的泛化能力。本文提出了一种名为Cloud-Adapter的参数高效自适应方法，以提升云分割的准确性和鲁棒性。该方法利用在一般域数据上预训练的VFM，这部分网络保持不变，无需额外训练。Cloud-Adapter结合了一个轻量级的空间感知模块，通过卷积神经网络(ConvNet)提取密集的空间表示，并将这些多尺度特征聚合，作为适应模块的上下文输入，调节VFM中的冻结变换层。实验结果表明，Cloud-Adapter在只使用0.6%的可训练参数的情况下，显著提高了性能，并在多种来自不同卫星源、传感器系列和土地覆盖场景的云分割数据集中实现了最新的SOTA性能。此外，源代码和预训练模型已在https:
  "keyword": ["云分割", "遥感", "视觉基础模型"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 382 (char 492). Line: 406.
Append: [Adapting Vision Foundation Models for Robust Cloud Segmentation in Remote Sensing Images](https://arxiv.org/abs/2411.13127)
Token length: 1415
Summarized using gpt-4o-mini
Append: [VideoRepair：提升文本到视频生成模型对齐度的框架](https://arxiv.org/abs/2411.15115)
append_entries: 2
Finish: 2024-11-25 18:00:59.925327
------------------------------------------------------
Started: 2024-11-25 21:00:57.218953
Existing_entries: 512
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-25 21:00:57.306187
------------------------------------------------------
Started: 2024-11-26 00:36:26.642621
Existing_entries: 512
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-26 00:36:26.745402
------------------------------------------------------
Started: 2024-11-26 03:22:40.107280
Existing_entries: 512
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-26 03:22:40.221340
------------------------------------------------------
Started: 2024-11-26 06:00:57.732899
Existing_entries: 512
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "Cautious Optimizer: 提升变压器预训练效率的新方法",
  "keyword": ["优化器", "AdamW", "深度学习"],
  "short_summary": "本文提出了一种新型的Cautious Optimizer，提升变压器预训练速度与稳定性。",
  "summary": "在深度学习的变压器预训练中，AdamW优化器已成为默认选择，但寻找更快、更稳定的替代方案一直是社区的追求。本文提出了一种简单的单行修改，称为Cautious Optimizer，例如C-AdamW和C-Lion。理论结果表明，该修改保持了Adam的哈密顿功能，并在Lyapunov分析下不破坏收敛保证。此外，这一理论洞察揭示了一整个新家族的优化器，文章选择了最简单的一个进行实证实验，显示了在Llama和MAE预训练中速度提升达1.47倍。相关代码可在https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 247 (char 403). Line: 406.
Append: [Cautious Optimizers: Improving Training with One Line of Code](https://arxiv.org/abs/2411.16085)
Token length: 1737
Summarized using gpt-4o-mini
Append: [DreamRunner：一种创新的故事视频生成方法](https://arxiv.org/abs/2411.16657)
Token length: 1459
Summarized using gpt-4o-mini
Append: [Diptych Prompting：一种新颖的零-shot图像生成方法](https://arxiv.org/abs/2411.15466)
Token length: 1773
Summarized using gpt-4o-mini
Append: [评估语言模型不确定性承认能力的新框架](https://arxiv.org/abs/2411.14486)
Token length: 1034
Summarized using gpt-4o-mini
Append: [Material Anything：自动化生成3D物体物理基础材料的统一扩散框架](https://arxiv.org/abs/2411.15138)
append_entries: 5
Finish: 2024-11-26 06:01:46.410928
------------------------------------------------------
Started: 2024-11-26 09:01:22.699507
Existing_entries: 517
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1287
Summarized using gpt-4o-mini
Append: [OneDiffusion：多任务大规模扩散模型的创新](https://arxiv.org/abs/2411.16318)
Token length: 1080
Summarized using gpt-4o-mini
Append: [VisualLens: 基于用户视觉历史的个性化推荐方法](https://arxiv.org/abs/2411.16034)
Token length: 1564
Summarized using gpt-4o-mini
Append: [引入因子化量化的新型视觉分词器FQGAN](https://arxiv.org/abs/2411.16681)
Token length: 1857
Summarized using gpt-4o-mini
Append: [深入探讨OpenAI O1模型能力复制中的知识蒸馏技术](https://arxiv.org/abs/2411.16489)
Token length: 1491
Summarized using gpt-4o-mini
Append: [SplatFlow：统一的3D生成与编辑框架](https://arxiv.org/abs/2411.16443)
Token length: 1788
Summarized using gpt-4o-mini
Append: [图序列模型GSM及其改进版本GSM++的理论与实验研究](https://arxiv.org/abs/2411.15671)
Token length: 1369
Summarized using gpt-4o-mini
Append: [语言模型的出现能力预测研究](https://arxiv.org/abs/2411.16035)
Token length: 1698
Summarized using gpt-4o-mini
Append: [全身CT预训练模型在医学图像分割中的迁移学习评估](https://arxiv.org/abs/2411.14525)
Token length: 1223
Summarized using gpt-4o-mini
Append: [大语言模型作为评判者的调查与展望](https://arxiv.org/abs/2411.16594)
Token length: 626
Summarized using gpt-4o-mini
Append: [多头混合专家模型的创新实现及其性能提升](https://arxiv.org/abs/2411.16205)
Json decode failed:
{
  "title": "开发GMAI-VL-5.5M数据集与GMAI-VL模型用于医疗视觉语言处理",
  "short_summary": "本文介绍了GMAI-VL-5.5M数据集及其在医疗AI中的应用。",
  "summary": "本文提出了GMAI-VL-5.5M，一个综合多模态医疗数据集，旨在提升医疗领域内一般人工智能（GMAI）模型的效能。通过将数百个专业医学数据集转换为精心构造的图像-文本配对，该数据集涵盖了丰富的任务、多种模态和高质量的数据。基于此数据集，我们还提出了GMAI-VL模型，该模型采用渐进的三阶段训练策略，使其在处理多模态数据和支持准确的诊断与临床决策方面表现出显著提升。实验评估显示，GMAI-VL在多项医疗任务中，如视觉问答和医学图像诊断，均取得了领先的成绩。我们的贡献包括GMAI-VL-5.5M数据集的开发、GMAI-VL模型的引入以及在多个医疗领域建立的新基准。相关代码和数据集将发布在https:
  "keyword": [
    "GMAI-VL-5.5M",
    "多模态医疗数据集",
    "医疗AI"
  ]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 317 (char 425). Line: 406.
Append: [GMAI-VL & GMAI-VL-5.5M: A Large Vision-Language Model and A Comprehensive Multimodal Dataset Towards General Medical AI](https://arxiv.org/abs/2411.14522)
Token length: 1396
Summarized using gpt-4o-mini
Append: [CRT：高效的x86到ARM汇编转译器](https://arxiv.org/abs/2411.16341)
append_entries: 12
Finish: 2024-11-26 09:04:26.307777
------------------------------------------------------
Started: 2024-11-26 12:14:11.814009
Existing_entries: 529
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1189
Summarized using gpt-4o-mini
Append: [基于文本描述的知识转移方法](https://arxiv.org/abs/2411.15611)
append_entries: 1
Finish: 2024-11-26 12:14:16.855475
------------------------------------------------------
Started: 2024-11-26 15:01:00.463892
Existing_entries: 530
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-26 15:01:00.637214
------------------------------------------------------
Started: 2024-11-26 18:10:30.789157
Existing_entries: 530
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1503
Summarized using gpt-4o-mini
Append: [IMed-361M: 新型医疗图像分割基准数据集](https://arxiv.org/abs/2411.12814)
Token length: 998
Summarized using gpt-4o-mini
Append: [隐式推理与显式推理的比较研究](https://arxiv.org/abs/2411.15862)
append_entries: 2
Finish: 2024-11-26 18:12:48.768820
------------------------------------------------------
Started: 2024-11-26 21:00:56.742594
Existing_entries: 532
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1064
Summarized using gpt-4o-mini
Append: [Find3D：一种开源世界三维零-shot部件分割模型](https://arxiv.org/abs/2411.13550)
Token length: 1154
Summarized using gpt-4o-mini
Append: [EdgeCape: 提升无类别姿态估计的关键点定位精度](https://arxiv.org/abs/2411.16665)
append_entries: 2
Finish: 2024-11-26 21:03:26.449934
------------------------------------------------------
Started: 2024-11-27 00:36:38.640270
Existing_entries: 534
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1679
Summarized using gpt-4o-mini
Append: [全语言重要基准：评估大型多模态模型的文化与语言理解能力](https://arxiv.org/abs/2411.16508)
Token length: 1432
Summarized using gpt-4o-mini
Append: [第二届大语言模型黑客松在材料科学与化学应用中的成果](https://arxiv.org/abs/2411.15221)
append_entries: 2
Finish: 2024-11-27 00:36:48.415101
------------------------------------------------------
Started: 2024-11-27 03:24:42.946169
Existing_entries: 536
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-27 03:24:43.099131
------------------------------------------------------
Started: 2024-11-27 06:00:50.865153
Existing_entries: 536
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1695
Summarized using gpt-4o-mini
Append: [ShowUI：革新图形用户界面的视觉语言模型](https://arxiv.org/abs/2411.17465)
Token length: 1410
Summarized using gpt-4o-mini
Append: [AnchorCrafter：基于扩散模型的人物与物体交互视频生成](https://arxiv.org/abs/2411.17383)
Token length: 1541
Summarized using gpt-4o-mini
Append: [FINECAPTION：提升视觉语言模型的区域构图能力](https://arxiv.org/abs/2411.15411)
Token length: 1013
Summarized using gpt-4o-mini
Append: [自监督学习在无标签3D点云中提取可转移表示的研究](https://arxiv.org/abs/2411.17467)
Token length: 1144
Summarized using gpt-4o-mini
Append: [基于扩散模型的高分辨率UV纹理生成研究](https://arxiv.org/abs/2411.14740)
Token length: 1229
Summarized using gpt-4o-mini
Append: [DreamMix：一种基于扩散模型的目标插入与属性编辑方法](https://arxiv.org/abs/2411.17223)
Token length: 780
Summarized using gpt-4o-mini
Append: [Star Attention: 提升长序列推理效率的块稀疏近似](https://arxiv.org/abs/2411.17116)
append_entries: 7
Finish: 2024-11-27 06:01:27.991748
------------------------------------------------------
Started: 2024-11-27 09:01:08.289697
Existing_entries: 543
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1731
Summarized using gpt-4o-mini
Append: [AI图像生成技术的检测挑战与新 Benchmark 的提出](https://arxiv.org/abs/2411.16754)
Token length: 1535
Summarized using gpt-4o-mini
Append: [SALOVA：增强长视频理解的段落增强视频助手](https://arxiv.org/abs/2411.16173)
Token length: 1147
Summarized using gpt-4o-mini
Append: [新型过滤-关联-压缩范式加速多模态大语言模型推理](https://arxiv.org/abs/2411.17686)
Token length: 1160
Summarized using gpt-4o-mini
Append: [SAR3D：提升3D对象生成与理解的新框架](https://arxiv.org/abs/2411.16856)
Token length: 1419
Summarized using gpt-4o-mini
Append: [多模态大语言模型的评估综述](https://arxiv.org/abs/2411.15296)
Json decode failed:
{
  "title": "低比特量化对大型语言模型的影响研究",
  "keyword": ["低比特量化", "大型语言模型", "量化性能"],
  "short_summary": "研究显示低比特量化在不同训练水平的LLM中表现差异显著。",
  "summary": "本研究揭示低比特量化对大型语言模型（LLM）的影响，发现较大规模或训练样本较少的模型在应用低比特量化时，其量化性能下降较小，而小模型则受损严重。通过研究超过1500个不同规模和训练水平的量化LLM检查点，得出了量化性能下降（QiD）与训练样本数量、模型大小及比特宽度之间的关系规律。研究提出了使用QiD测量LLM训练水平的新视角，并确定了不同规模模型完全训练所需的训练样本数量。我们的预测表明，未来预期训练超过100万亿样本的模型，在低比特量化性能上可能不尽如人意。这为低比特量化领域带来潜在挑战，强调评估量化性能时需关注模型训练水平。为推动未来研究，本文公开了使用的1500多个量化检查点，网址为 https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 321 (char 447). Line: 406.
Append: [Low-Bit Quantization Favors Undertrained LLMs: Scaling Laws for Quantized LLMs with 100T Training Tokens](https://arxiv.org/abs/2411.17691)
Token length: 1265
Summarized using gpt-4o-mini
Append: [SketchAgent：语言驱动的动态素描生成方法](https://arxiv.org/abs/2411.17673)
append_entries: 7
Finish: 2024-11-27 09:01:47.282230
------------------------------------------------------
Started: 2024-11-27 12:13:52.742274
Existing_entries: 550
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1823
Summarized using gpt-4o-mini
Append: [MolReFlect: 基于教师-学生框架的分子与描述文本对齐方法](https://arxiv.org/abs/2411.14721)
Token length: 1003
Summarized using gpt-4o-mini
Append: [利用图像到视频模型提升图像编辑精度](https://arxiv.org/abs/2411.16819)
append_entries: 2
Finish: 2024-11-27 12:14:08.230273
------------------------------------------------------
Started: 2024-11-27 15:00:47.966412
Existing_entries: 552
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1352
Summarized using gpt-4o-mini
Append: [BootComp：基于扩散模型的人像生成框架](https://arxiv.org/abs/2411.16801)
Json decode failed:
{
  "title": "VL-RewardBench：针对视觉-语言生成奖励模型的评估基准",
  "keyword": ["VL-GenRMs", "评估基准", "多模态AI"],
  "short_summary": "VL-RewardBench基准为视觉-语言生成奖励模型的评估提供了新方法。",
  "summary": "本文介绍了VL-RewardBench，一个针对视觉-语言生成奖励模型（VL-GenRMs）评估的新基准。当前的评估方法主要依赖于传统VL任务中的AI标注偏好标签，这可能导致偏见，且难以有效挑战最先进的模型。VL-RewardBench涵盖了广泛的多模态查询、视觉幻觉检测和复杂推理任务，并结合AI辅助注释流程与人工验证，精心策划了1250个高质量示例，以探测模型局限性。在对16个领先的大型视觉-语言模型进行的全面评估中，发现VL-RewardBench作为具有挑战性的试验平台，其有效性得到了验证，甚至GPT-4o的准确率仅为65.4%，而最先进的开源模型如Qwen2-VL-72B的表现也难以超过随机猜测。研究表明，VL-RewardBench的表现与MMMU-Pro准确率高度相关（Pearson"s r > 0.9），为推动VL-GenRMs的发展提供了重要参考。"
}Summarization failed, append the original article
error: Expecting ',' delimiter: line 5 column 368 (char 523). Line: 406.
Append: [VLRewardBench: A Challenging Benchmark for Vision-Language Generative Reward Models](https://arxiv.org/abs/2411.17451)
append_entries: 2
Finish: 2024-11-27 15:00:57.078198
------------------------------------------------------
Started: 2024-11-27 18:10:11.205520
Existing_entries: 554
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-27 18:10:11.387864
------------------------------------------------------
Started: 2024-11-27 21:01:05.698399
Existing_entries: 554
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-27 21:01:05.855861
------------------------------------------------------
Started: 2024-11-28 00:36:50.352834
Existing_entries: 554
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-28 00:36:50.543307
------------------------------------------------------
Started: 2024-11-28 03:24:37.559841
Existing_entries: 554
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1430
Summarized using gpt-4o-mini
Append: [Efficient Vision Mamba: 提升资源受限环境下的视觉模型性能](https://arxiv.org/abs/2411.15241)
append_entries: 1
Finish: 2024-11-28 03:24:43.629899
------------------------------------------------------
Started: 2024-11-28 06:11:18.691258
Existing_entries: 555
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1483
Summarized using gpt-4o-mini
Append: [DiffusionDrive：一种实时多模态驾驶策略生成的新模型](https://arxiv.org/abs/2411.15139)
Token length: 1112
Summarized using gpt-4o-mini
Append: [SVIP：提高推测解码效率的动态草稿长度策略](https://arxiv.org/abs/2411.18462)
Token length: 1626
Summarized using gpt-4o-mini
Append: [Collaborative Decoding：提升视觉自回归图像生成效率的新策略](https://arxiv.org/abs/2411.17787)
Token length: 1658
Summarized using gpt-4o-mini
Append: [ISG：文本与图像交叉生成的综合评估框架](https://arxiv.org/abs/2411.17188)
Token length: 1438
Summarized using gpt-4o-mini
Append: [提升扩散模型的区域实例控制：ROICtrl的提出与应用](https://arxiv.org/abs/2411.17949)
Token length: 1865
Summarized using gpt-4o-mini
Append: [ConsisID：基于频率的身份保留文本到视频生成模型](https://arxiv.org/abs/2411.17440)
Token length: 1282
Summarized using gpt-4o-mini
Append: [MARVEL-40M+: 提升文本驱动3D内容生成的全新数据集](https://arxiv.org/abs/2411.17945)
append_entries: 7
Finish: 2024-11-28 06:12:00.926994
------------------------------------------------------
Started: 2024-11-28 09:01:17.833968
Existing_entries: 562
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1109
Summarized using gpt-4o-mini
Append: [Omegance: 通过单一参数控制扩散合成的细节粒度](https://arxiv.org/abs/2411.17769)
Token length: 1485
Summarized using gpt-4o-mini
Append: [提升计算机视觉中的感知与理解能力：ChatRex模型与Rexverse-2M数据集](https://arxiv.org/abs/2411.18363)
Token length: 1909
Summarized using gpt-4o-mini
Append: [LLM驱动的GUI代理：现状与未来发展路径](https://arxiv.org/abs/2411.18279)
Token length: 1239
Summarized using gpt-4o-mini
Append: [UniPose：多模态人类姿态理解与生成框架](https://arxiv.org/abs/2411.16781)
Token length: 1579
Summarized using gpt-4o-mini
Append: [基于MedNeXt的脑肿瘤分割方法在BraTS-2024挑战中的应用](https://arxiv.org/abs/2411.15872)
Token length: 1626
Summarized using gpt-4o-mini
Append: [TemplateMath: 利用模板生成数学问题以提升大语言模型推理能力](https://arxiv.org/abs/2411.18104)
Token length: 745
Summarized using gpt-4o-mini
Append: [CAT4D：从单目视频生成动态三维场景的新方法](https://arxiv.org/abs/2411.18613)
append_entries: 7
Finish: 2024-11-28 09:01:56.095158
------------------------------------------------------
Started: 2024-11-28 12:13:55.229360
Existing_entries: 569
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1419
Summarized using gpt-4o-mini
Append: [自适应盲式图像恢复模型ABAIR的设计与应用](https://arxiv.org/abs/2411.18412)
Token length: 914
Summarized using gpt-4o-mini
Append: [DreamCache：高效个性化图像生成的新方法](https://arxiv.org/abs/2411.17786)
Token length: 1365
Summarized using gpt-4o-mini
Append: [Make-It-Animatable: 快速将任何3D人形模型变为可动画角色](https://arxiv.org/abs/2411.18197)
append_entries: 3
Finish: 2024-11-28 12:14:10.308346
------------------------------------------------------
Started: 2024-11-28 15:00:51.805250
Existing_entries: 572
Fetching from https://rsshub.app/huggingface/daily-papers
Summarization failed, append the original article
error: __init__() got an unexpected keyword argument 'proxies'. Line: 406.
Append: [3D Convex Splatting: Radiance Field Rendering with 3D Smooth Convexes](https://arxiv.org/abs/2411.14974)
Summarization failed, append the original article
error: __init__() got an unexpected keyword argument 'proxies'. Line: 406.
Append: [VideoLLM Knows When to Speak: Enhancing Time-Sensitive Video Comprehension with Video-Text Duet Interaction Format](https://arxiv.org/abs/2411.17991)
append_entries: 2
Finish: 2024-11-28 15:00:51.897535
------------------------------------------------------
Started: 2024-11-28 18:00:52.239276
Existing_entries: 574
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-28 18:00:52.325537
------------------------------------------------------
Started: 2024-11-28 21:00:42.987284
Existing_entries: 574
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1183
Summarized using gpt-4o-mini
Append: [MultiFoley：视频指导的多模态声音生成模型](https://arxiv.org/abs/2411.17698)
append_entries: 1
Finish: 2024-11-28 21:00:48.628617
------------------------------------------------------
Started: 2024-11-29 00:36:30.682446
Existing_entries: 575
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1174
Summarized using gpt-4o-mini
Append: [扩散自蒸馏：提升文本条件图像生成的控制能力](https://arxiv.org/abs/2411.18616)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Recent advancements in diffusion models have made generative image editing more accessible, enabling creative edits but raising ethical concerns, particularly regarding malicious edits to human portraits that threaten privacy and identity security. Existing protection methods primarily rely on adversarial perturbations to nullify edits but often fail against diverse editing requests. We propose FaceLock, a novel approach to portrait protection that optimizes adversarial perturbations to destroy or significantly alter biometric information, rendering edited outputs biometrically unrecognizable. FaceLock integrates facial recognition and visual perception into perturbation optimization to provide robust protection against various editing attempts. We also highlight flaws in commonly used evaluation metrics and reveal how they can be manipulated, emphasizing the need for reliable assessments of protection. Experiments show FaceLock outperforms baselines in defending against malicious edits and is robust against purification techniques. Ablation studies confirm its stability and broad applicability across diffusion-based editing algorithms. Our work advances biometric defense and sets the foundation for privacy-preserving practices in image editing. The code is available at: https://github.com/taco-group/FaceLock.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Edit Away and My Face Will not Stay: Personal Biometric Defense against Malicious Generative Editing](https://arxiv.org/abs/2411.16832)
append_entries: 2
Finish: 2024-11-29 00:36:36.537334
------------------------------------------------------
Started: 2024-11-29 03:24:03.240854
Existing_entries: 577
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-29 03:24:03.342376
------------------------------------------------------
Started: 2024-11-29 06:00:45.134477
Existing_entries: 577
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-29 06:00:45.257050
------------------------------------------------------
Started: 2024-11-29 09:01:01.635953
Existing_entries: 577
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1187
Summarized using gpt-4o-mini
Append: [Morph：一种无运动数据的物理优化框架](https://arxiv.org/abs/2411.14951)
append_entries: 1
Finish: 2024-11-29 09:01:08.828020
------------------------------------------------------
Started: 2024-11-29 12:13:17.051923
Existing_entries: 578
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1881
Summarized using gpt-4o-mini
Append: [Critic-V: 提升视觉语言模型多模态推理能力的新框架](https://arxiv.org/abs/2411.18203)
append_entries: 1
Finish: 2024-11-29 12:13:23.187735
------------------------------------------------------
Started: 2024-11-29 15:00:51.605927
Existing_entries: 579
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1268
Summarized using gpt-4o-mini
Append: [Free^2Guide: 一种无梯度框架用于文本与视频生成对齐](https://arxiv.org/abs/2411.17041)
Token length: 994
Summarized using gpt-4o-mini
Append: [LongKey：针对长文档的自动关键短语提取框架](https://arxiv.org/abs/2411.17863)
Token length: 1251
Summarized using gpt-4o-mini
Append: [VTOFF: 基于单一图像生成标准化服装图像](https://arxiv.org/abs/2411.18350)
Token length: 1338
Summarized using gpt-4o-mini
Append: [自动文本到图像生成的研究与进展](https://arxiv.org/abs/2411.17176)
append_entries: 4
Finish: 2024-11-29 15:01:17.356497
------------------------------------------------------
Started: 2024-11-29 18:00:39.285273
Existing_entries: 583
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-29 18:00:39.376720
------------------------------------------------------
Started: 2024-11-29 21:00:40.454719
Existing_entries: 583
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-29 21:00:40.768090
------------------------------------------------------
Started: 2024-11-30 00:35:35.373526
Existing_entries: 583
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-30 00:35:35.498553
------------------------------------------------------
Started: 2024-11-30 03:19:37.658166
Existing_entries: 583
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1270
Summarized using gpt-4o-mini
Append: [AfriMed-QA：首个泛非英语言医疗问题回答数据集及其在医学多选题中的表现评估](https://arxiv.org/abs/2411.15640)
append_entries: 1
Finish: 2024-11-30 03:19:44.538488
------------------------------------------------------
Started: 2024-11-30 06:00:53.575807
Existing_entries: 584
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1363
Summarized using gpt-4o-mini
Append: [SelfSplat：无姿态与无三维先验的通用三维重建模型](https://arxiv.org/abs/2411.17190)
append_entries: 1
Finish: 2024-11-30 06:01:02.314380
------------------------------------------------------
Started: 2024-11-30 09:00:36.495458
Existing_entries: 585
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-30 09:00:36.703351
------------------------------------------------------
Started: 2024-11-30 12:11:42.115692
Existing_entries: 585
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-30 12:11:42.271270
------------------------------------------------------
Started: 2024-11-30 15:00:40.085137
Existing_entries: 585
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-30 15:00:40.192919
------------------------------------------------------
Started: 2024-11-30 18:00:58.830268
Existing_entries: 585
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-30 18:00:58.996661
------------------------------------------------------
Started: 2024-11-30 21:00:27.248560
Existing_entries: 585
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-11-30 21:00:27.376045
------------------------------------------------------
Started: 2024-12-01 00:44:18.829290
Existing_entries: 585
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-01 00:44:18.992107
------------------------------------------------------
Started: 2024-12-01 03:36:14.086802
Existing_entries: 585
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-01 03:36:14.226372
------------------------------------------------------
Started: 2024-12-01 06:00:46.302442
Existing_entries: 585
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-01 06:00:46.465911
------------------------------------------------------
Started: 2024-12-01 09:00:33.938831
Existing_entries: 585
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-01 09:00:34.150329
------------------------------------------------------
Started: 2024-12-01 12:12:21.373134
Existing_entries: 585
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-01 12:12:21.452731
------------------------------------------------------
Started: 2024-12-01 15:00:48.611729
Existing_entries: 585
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-01 15:00:48.742681
------------------------------------------------------
Started: 2024-12-01 18:00:39.023477
Existing_entries: 585
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-01 18:00:39.135975
------------------------------------------------------
Started: 2024-12-01 21:00:42.491329
Existing_entries: 585
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-01 21:00:42.611059
------------------------------------------------------
Started: 2024-12-02 00:38:52.642597
Existing_entries: 585
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-02 00:38:52.775718
------------------------------------------------------
Started: 2024-12-02 03:29:05.591473
Existing_entries: 585
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-02 03:29:05.693475
------------------------------------------------------
Started: 2024-12-02 06:11:45.210150
Existing_entries: 585
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-02 06:11:45.308380
------------------------------------------------------
Started: 2024-12-02 09:01:10.349692
Existing_entries: 585
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1854
Summarized using gpt-4o-mini
Append: [Puzzle框架：提升大型语言模型推理效率](https://arxiv.org/abs/2411.19146)
Token length: 1309
Summarized using gpt-4o-mini
Append: [Video-Ma^2mba: 线性扩展的视频处理架构](https://arxiv.org/abs/2411.19460)
Token length: 1327
Summarized using gpt-4o-mini
Append: [TeaCache：基于时间步嵌入的高效视频生成缓存方法](https://arxiv.org/abs/2411.19108)
Token length: 1566
Summarized using gpt-4o-mini
Append: [AC3D架构：先进的3D相机控制模型](https://arxiv.org/abs/2411.18673)
Token length: 1349
Summarized using gpt-4o-mini
Append: [领域适应性提升：后训练与数据合成在多模态大语言模型中的应用](https://arxiv.org/abs/2411.19930)
Token length: 1345
Summarized using gpt-4o-mini
Append: [基于轨迹注意力的视频生成方法研究](https://arxiv.org/abs/2411.19324)
append_entries: 6
Finish: 2024-12-02 09:01:39.497978
------------------------------------------------------
Started: 2024-12-02 12:14:18.051405
Existing_entries: 591
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1332
Summarized using gpt-4o-mini
Append: [DisCoRD：通过修正流解码实现离散与连续运动的优雅结合](https://arxiv.org/abs/2411.19527)
Token length: 1173
Summarized using gpt-4o-mini
Append: [HiAR-ICL：一种高水平自动推理的新范式](https://arxiv.org/abs/2411.18478)
Token length: 1543
Summarized using gpt-4o-mini
Append: [RollingDepth：基于单幅图像的高效视频深度估计模型](https://arxiv.org/abs/2411.19189)
Token length: 1643
Summarized using gpt-4o-mini
Append: [基于大语言模型的多语言新闻分类框架](https://arxiv.org/abs/2411.19638)
Token length: 1241
Summarized using gpt-4o-mini
Append: [AlphaTablets：一种新型三维平面表示方法及其应用](https://arxiv.org/abs/2411.19950)
append_entries: 5
Finish: 2024-12-02 12:14:46.071729
------------------------------------------------------
Started: 2024-12-02 15:00:50.513391
Existing_entries: 596
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-02 15:00:57.328424
------------------------------------------------------
Started: 2024-12-02 18:10:21.085865
Existing_entries: 596
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1535
Summarized using gpt-4o-mini
Append: [逆向思维在大型语言模型中的应用与改进](https://arxiv.org/abs/2411.19865)
Token length: 1321
Summarized using gpt-4o-mini
Append: [Fam扩散模型：灵活调整高质量图像生成](https://arxiv.org/abs/2411.18552)
append_entries: 2
Finish: 2024-12-02 18:10:34.034203
------------------------------------------------------
Started: 2024-12-02 21:00:44.645389
Existing_entries: 598
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-02 21:00:44.821409
------------------------------------------------------
Started: 2024-12-03 00:38:08.362439
Existing_entries: 598
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 509
Summarized using gpt-4o-mini
Append: [视觉变换器的训练噪声令牌修剪方法](https://arxiv.org/abs/2411.18092)
Token length: 1283
Summarized using gpt-4o-mini
Append: [SpotLight：基于扩散模型的可控虚拟物体重光方法](https://arxiv.org/abs/2411.18665)
Token length: 719
Summarized using gpt-4o-mini
Append: [大型参数变换器在语音编码中的应用](https://arxiv.org/abs/2411.19842)
Token length: 1200
Summarized using gpt-4o-mini
Append: [引入时空跳跃引导法以提升视频扩散模型的生成质量](https://arxiv.org/abs/2411.18664)
append_entries: 4
Finish: 2024-12-03 00:38:35.325388
------------------------------------------------------
Started: 2024-12-03 03:28:18.345252
Existing_entries: 602
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 959
Summarized using gpt-4o-mini
Append: [MATATA：一种高效训练小型语言模型处理表格数据的方法](https://arxiv.org/abs/2411.18915)
Token length: 1718
Summarized using gpt-4o-mini
Append: [GRAPE：通过偏好对齐实现机器人政策的普适性提升](https://arxiv.org/abs/2411.19309)
append_entries: 2
Finish: 2024-12-03 03:28:28.318702
------------------------------------------------------
Started: 2024-12-03 06:00:45.319690
Existing_entries: 604
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1569
Summarized using gpt-4o-mini
Append: [VisOnlyQA: 评估大型视觉语言模型的视觉感知能力](https://arxiv.org/abs/2412.00947)
Token length: 1208
Summarized using gpt-4o-mini
Append: [Presto: 一种新型的视频扩散模型实现15秒长视频生成](https://arxiv.org/abs/2412.01316)
Token length: 1365
Summarized using gpt-4o-mini
Append: [TAPTRv3：增强长期视频跟踪的鲁棒性](https://arxiv.org/abs/2411.18671)
Token length: 1375
Summarized using gpt-4o-mini
Append: [Wavelet Flow VAE：高效视频编码的新方法](https://arxiv.org/abs/2411.17459)
append_entries: 4
Finish: 2024-12-03 06:01:05.865066
------------------------------------------------------
Started: 2024-12-03 09:00:43.331780
Existing_entries: 608
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-03 09:00:43.519522
------------------------------------------------------
Started: 2024-12-03 12:13:41.800892
Existing_entries: 608
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1032
Summarized using gpt-4o-mini
Append: [推动多语言大模型性能的本地评估基准建设](https://arxiv.org/abs/2411.19799)
Token length: 1232
Summarized using gpt-4o-mini
Append: [SOLAMI: 3D自主角色的社交智能建模框架](https://arxiv.org/abs/2412.00174)
Json decode failed:
{
  "title": "GATE OpenING：推动多模态生成模型的评估与发展",
  "keyword": ["多模态", "生成模型", "基准测试"],
  "short_summary": "GATE OpenING提供了新的基准测试以推动多模态生成方法的发展与评估。",
  "summary": "多模态大语言模型（MLLMs）在视觉理解和生成任务上取得了显著进展，但生成交错的图文内容依然是一大挑战。为了解决现有基准测试数据不足的问题，我们提出了GATE OpenING（OpenING），这是一个包含5400个高质量人类注释实例的新基准，覆盖56个现实世界任务，涉及日常场景如旅行指南、设计和头脑风暴。此外，我们还提出了IntJudge，一个用于评估开放式多模态生成方法的模型，该模型通过创新的数据处理流程进行训练，与人类判断的协议率高达82.42%，并超过了基于GPT的评估器11.34%。通过在OpenING上的广泛实验，发现当前的交错生成方法仍有很大的改善空间，为下一代模型的发展提供了关键指导。OpenING已在https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 334 (char 477). Line: 406.
Append: [GATE OpenING: A Comprehensive Benchmark for Judging Open-ended Interleaved Image-Text Generation](https://arxiv.org/abs/2411.18499)
Token length: 979
Summarized using gpt-4o-mini
Append: [FLOAT：基于流匹配生成模型的音频驱动人像视频生成方法](https://arxiv.org/abs/2412.01064)
Token length: 1332
Summarized using gpt-4o-mini
Append: [一种基于两阶段算法的大型语言模型测试时间计算的方法](https://arxiv.org/abs/2411.19477)
Token length: 1268
Summarized using gpt-4o-mini
Append: [VISTA: 视频时空增强框架提升长时长高分辨率视频理解](https://arxiv.org/abs/2412.00927)
Json decode failed:
{
  "title": "O1-CODER: 基于强化学习的编码任务模型",
  "keyword": ["O1-CODER", "强化学习", "编码"],
  "short_summary": "O1-CODER模型旨在通过RL和MCTS提升编码任务的系统思维能力。",
  "summary": "技术报告介绍了O1-CODER，一个旨在复制OpenAI o1模型的项目，专注于编码任务。该模型结合了强化学习（RL）和蒙特卡洛树搜索（MCTS），增强其系统-2思维能力。框架中包括训练测试用例生成器（TCG），用于标准化代码测试，应用MCTS生成带有推理过程的代码数据，并反复微调策略模型以首先生成伪代码，随后生成完整代码。报告还讨论了在实际应用中部署类似o1模型的机遇与挑战，建议向系统-2范式转型，并强调环境状态更新的重要性。后续版本将报告模型进展和实验结果，所有源代码、策划的数据集以及衍生模型会在 https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 275 (char 413). Line: 406.
Append: [o1-Coder: an o1 Replication for Coding](https://arxiv.org/abs/2412.00154)
Token length: 1873
Summarized using gpt-4o-mini
Append: [EfficientTAMs：轻量级视频对象分割模型的创新](https://arxiv.org/abs/2411.18933)
Token length: 1434
Summarized using gpt-4o-mini
Append: [TinyFusion：高效的扩散变换器深度剪枝方法](https://arxiv.org/abs/2412.01199)
Token length: 1266
Summarized using gpt-4o-mini
Append: [X-Prompt：提升视觉语言模型的图像生成能力](https://arxiv.org/abs/2412.01824)
Token length: 1425
Summarized using gpt-4o-mini
Append: [FlowChef：高效的受控图像生成框架](https://arxiv.org/abs/2412.00100)
Json decode failed:
{
  "title": "Open-Sora Plan：开放源代码的视频生成项目",
  "keywords": ["视频生成", "开放源代码", "高分辨率"],
  "short_summary": "Open-Sora Plan旨在通过用户输入生成高分辨率长视频。",
  "summary": "Open-Sora Plan是一个开源项目，旨在基于用户输入生成高分辨率的长时间视频。该项目包含了视频生成过程中的多个组件，如Wavelet-Flow变分自编码器、联合图像-视频去噪器和多种条件控制器。同时，我们设计了多种辅助策略以提高训练和推理的效率，并提出了一个多维数据策划管道，以获取所需的高质量数据。得益于这些高效的策略，Open-Sora Plan在定性和定量评估中都取得了令人瞩目的视频生成效果。我们希望我们的精心设计和实践经验能够激励视频生成研究社区。所有代码和模型权重已公开分享在https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 269 (char 408). Line: 406.
Append: [Open-Sora Plan: Open-Source Large Video Generation Model](https://arxiv.org/abs/2412.00131)
append_entries: 12
Finish: 2024-12-03 12:15:01.993394
------------------------------------------------------
Started: 2024-12-03 15:00:51.615338
Existing_entries: 620
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 996
Summarized using gpt-4o-mini
Append: [利用预训练音频表示进行低资源语言的在线辱骂内容检测](https://arxiv.org/abs/2412.01408)
Token length: 1696
Summarized using gpt-4o-mini
Append: [PhysGame：评估视频语言模型中的物理常识理解](https://arxiv.org/abs/2412.01800)
Token length: 1252
Summarized using gpt-4o-mini
Append: [VLsI：高效的视觉语言模型与层级蒸馏方法](https://arxiv.org/abs/2412.01822)
Token length: 1354
Summarized using gpt-4o-mini
Append: [协作实例导航任务及其动态人机交互方法](https://arxiv.org/abs/2412.01250)
Token length: 1114
Summarized using gpt-4o-mini
Append: [Switti: 高效的文本到图像生成规模化变压器](https://arxiv.org/abs/2412.01819)
Token length: 1431
Summarized using gpt-4o-mini
Append: [多模态大型语言模型的安全性问题研究与VLSBench基准构建](https://arxiv.org/abs/2411.19939)
append_entries: 6
Finish: 2024-12-03 15:01:23.409960
------------------------------------------------------
Started: 2024-12-03 18:00:50.332205
Existing_entries: 626
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "引入大型数据集促进机器学习代理模型发展",
  "keyword": ["机器学习", "数据集", "物理模拟"],
  "short_summary": "文章介绍了一个大型数据集，以促进机器学习代理模型在物理模拟中的应用。",
  "summary": "本文介绍了一个名为Well的大型数据集，旨在为机器学习代理模型提供丰富的数据支持。Well包含15TB的数值模拟数据，涵盖生物系统、流体动力学、声散射以及星际流体和超新星爆炸的磁流体动力学等多个领域，共计16个数据集。这些数据集为研究者提供了多样化的物理行为表现，能够单独使用，也可以组成更广泛的基准套件。为便于使用，本文还提供了一个统一的PyTorch接口，用于训练和评估模型。通过示例基线，展示了Well带来的新挑战和复杂动态。相关代码和数据可在GitHub上获取，网址为https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 259 (char 389). Line: 406.
Append: [The Well: a Large-Scale Collection of Diverse Physics Simulations for Machine Learning](https://arxiv.org/abs/2412.00568)
Token length: 1129
Summarized using gpt-4o-mini
Append: [通过XYZ图像实现3D一致性的视频扩散模型](https://arxiv.org/abs/2412.01821)
Token length: 645
Summarized using gpt-4o-mini
Append: [探索艺术创作中先前艺术知识的需求](https://arxiv.org/abs/2412.00176)
append_entries: 3
Finish: 2024-12-03 18:01:01.865398
------------------------------------------------------
Started: 2024-12-03 21:00:40.976670
Existing_entries: 629
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-03 21:00:41.163799
------------------------------------------------------
Started: 2024-12-04 00:37:44.288792
Existing_entries: 629
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1354
Summarized using gpt-4o-mini
Append: [基于CycleGAN的说话人验证系统情感语音数据增强方法](https://arxiv.org/abs/2412.00319)
Token length: 1138
Summarized using gpt-4o-mini
Append: [利用知识增强的提示评估大型语言模型在比例类比完成中的表现](https://arxiv.org/abs/2412.00869)
append_entries: 2
Finish: 2024-12-04 00:37:53.042181
------------------------------------------------------
Started: 2024-12-04 03:26:45.420793
Existing_entries: 631
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1399
Summarized using gpt-4o-mini
Append: [HUGSIM：高保真闭环模拟器提升自主驾驶算法评估](https://arxiv.org/abs/2412.01718)
Token length: 1399
Summarized using gpt-4o-mini
Append: [无训练方法提升文本生成图像的精确度](https://arxiv.org/abs/2411.19415)
append_entries: 2
Finish: 2024-12-04 03:27:01.244721
------------------------------------------------------
Started: 2024-12-04 06:00:52.112231
Existing_entries: 633
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1332
Summarized using gpt-4o-mini
Append: [基于掩码的引导图像分割方法研究](https://arxiv.org/abs/2411.19067)
Token length: 1893
Summarized using gpt-4o-mini
Append: [隐式过程奖励模型的训练方法及其效率提升](https://arxiv.org/abs/2412.01981)
Token length: 1302
Summarized using gpt-4o-mini
Append: [评估多模态大型语言模型的音频视觉理解能力](https://arxiv.org/abs/2412.02611)
Token length: 1267
Summarized using gpt-4o-mini
Append: [基于GSQ的视觉标记器：提高重建质量与可扩展性](https://arxiv.org/abs/2412.02632)
Token length: 1666
Summarized using gpt-4o-mini
Append: [LSceneLLM：提升3D视觉语言模型在大型场景理解中的表现](https://arxiv.org/abs/2412.01292)
Token length: 1894
Summarized using gpt-4o-mini
Append: [VGoT：面向多镜头视频生成的新架构](https://arxiv.org/abs/2412.02259)
Token length: 1676
Summarized using gpt-4o-mini
Append: [识别与奖励关键令牌的对比估计方法cDPO：提升大型语言模型推理表现](https://arxiv.org/abs/2411.19943)
append_entries: 7
Finish: 2024-12-04 06:01:27.934973
------------------------------------------------------
Started: 2024-12-04 09:00:59.818421
Existing_entries: 640
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1566
Summarized using gpt-4o-mini
Append: [OHRBench：评估OCR对RAG系统的影响](https://arxiv.org/abs/2412.02592)
Token length: 608
Summarized using gpt-4o-mini
Append: [动态并行方法提升混合CPU的AI推理性能](https://arxiv.org/abs/2411.19542)
Token length: 1488
Summarized using gpt-4o-mini
Append: [VideoLights: 一种新的视频高亮检测和时刻检索框架](https://arxiv.org/abs/2412.01558)
append_entries: 3
Finish: 2024-12-04 09:01:13.988626
------------------------------------------------------
Started: 2024-12-04 12:01:05.630676
Existing_entries: 643
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-04 12:01:05.723580
------------------------------------------------------
Started: 2024-12-04 15:00:52.604203
Existing_entries: 643
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1538
Summarized using gpt-4o-mini
Append: [多智能体大规模语言模型训练的初步探索](https://arxiv.org/abs/2412.01928)
Token length: 1384
Summarized using gpt-4o-mini
Append: [OmniCreator：统一的图像与视频生成及编辑框架](https://arxiv.org/abs/2412.02114)
append_entries: 2
Finish: 2024-12-04 15:01:10.635103
------------------------------------------------------
Started: 2024-12-04 18:10:36.794053
Existing_entries: 645
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1494
Summarized using gpt-4o-mini
Append: [GenAI系统设计模式与工业应用的探索](https://arxiv.org/abs/2412.00239)
Token length: 1372
Summarized using gpt-4o-mini
Append: [基于运动提示的视频生成模型研究](https://arxiv.org/abs/2412.02700)
Token length: 1526
Summarized using gpt-4o-mini
Append: [LLM-Oasis：评估大型语言模型事实性的创新资源](https://arxiv.org/abs/2411.19655)
append_entries: 3
Finish: 2024-12-04 18:11:13.165210
------------------------------------------------------
Started: 2024-12-04 21:00:45.315453
Existing_entries: 648
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-04 21:00:45.499398
------------------------------------------------------
Started: 2024-12-07 03:52:18.615198
Existing_entries: 648
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1295
Summarized using gpt-4o-mini
Append: [预训练语言模型任务性能的缩放规律与模型阶梯预测](https://arxiv.org/abs/2412.04403)
Token length: 1039
Summarized using gpt-4o-mini
Append: [NVILA：一款高效的视觉语言模型](https://arxiv.org/abs/2412.04468)
Token length: 892
Summarized using gpt-4o-mini
Append: [4Real-Video：新型4D视频生成框架](https://arxiv.org/abs/2412.04462)
Token length: 1471
Summarized using gpt-4o-mini
Append: [基于混合深度机制的高效多模态大语言模型](https://arxiv.org/abs/2412.04449)
Token length: 1355
Summarized using gpt-4o-mini
Append: [SynFinTabs：合成金融表格的标签数据集和模型测试](https://arxiv.org/abs/2412.04262)
Token length: 1369
Summarized using gpt-4o-mini
Append: [Vision Value Model (VisVM) 提升视觉语言模型响应质量](https://arxiv.org/abs/2412.03704)
Token length: 1341
Summarized using gpt-4o-mini
Append: [MEMO：基于记忆的情感驱动视频生成模型](https://arxiv.org/abs/2412.04448)
Token length: 865
Summarized using gpt-4o-mini
Append: [提高开放平台人类注释质量的挑战与对策](https://arxiv.org/abs/2412.04363)
Token length: 1498
Summarized using gpt-4o-mini
Append: [提升视觉语言模型理解能力的新方法](https://arxiv.org/abs/2412.04378)
Token length: 1780
Summarized using gpt-4o-mini
Append: [任何服装虚拟穿搭方法AnyDressing的创新研究](https://arxiv.org/abs/2412.04146)
Token length: 1781
Summarized using gpt-4o-mini
Append: [多语言数据集中的文化偏见及其对模型评估的影响](https://arxiv.org/abs/2412.03304)
Token length: 864
Summarized using gpt-4o-mini
Append: [改进的注意力机制：KV位移注意力提升语言模型的学习能力](https://arxiv.org/abs/2411.19574)
Json decode failed:
{
  "title": "无引导噪声精炼模型在高质量图像生成中的应用",
  "short_summary": "研究表明，精炼初始噪声可在无引导下生成高质量图像。",
  "summary": "本文探讨了在无引导方法的情况下，扩散模型生成高质量图像的可能性。研究发现，通过对扩散反演中获得的噪声进行转换，可以有效地重构高质量图像。我们聚焦于去噪流程中的初始噪声，通过将高斯噪声映射到“无引导噪声”，揭示了小幅低频成分在去噪过程中的重要性，从而消除了对引导的需求。同时，我们提出了一种新方法\ours，采用单次初始噪声精炼来替代传统引导方法。在相同的扩散管道中，该精炼噪声能够实现高质量的图像生成。我们的噪声精炼模型利用高效的噪声空间学习，实现了快速收敛，并且在仅使用50K的文本-图像配对下，展现了强大的性能。通过多种指标验证了其有效性，并分析了精炼噪声如何消除对引导的需求。",
  "keyword": [
    "扩散模型",
    "噪声精炼",
    "高质量图像生成"
  ]
}Summarization failed, append the original article
error: Invalid \escape: line 4 column 162 (char 247). Line: 406.
Append: [A Noise is Worth Diffusion Guidance](https://arxiv.org/abs/2412.03895)
Token length: 1441
Summarized using gpt-4o-mini
Append: [Marco-LLM：跨语言增强的多语言大语言模型](https://arxiv.org/abs/2412.04003)
Token length: 1170
Summarized using gpt-4o-mini
Append: [个性化多模态大语言模型概述](https://arxiv.org/abs/2412.02142)
Json decode failed:
{
  "title": "通过单义专家混合架构提升大语言模型的可解释性",
  "keyword": ["大语言模型", "稀疏自编码器", "专家架构"],
  "short_summary": "本文介绍了一种新架构，通过稀疏字典学习提升大语言模型的可解释性。",
  "summary": "理解大型语言模型（LLMs）的内部计算对于使其与人类价值观对齐至关重要，但多义性问题使得机械可解释性受到阻碍。传统的稀疏自编码器虽然试图通过稀疏字典学习解耦特征，但因依赖后期重构损失而影响了LLM的性能。为解决此问题，本文提出了"单义专家混合"（Monet）架构，直接在端到端的专家预训练中整合稀疏字典学习。该方法允许每层专家数量达到262,144，且总参数量与专家数量的平方根成正比。我们的分析表明，专家之间知识的互斥性，以及各个专家内封装的参数知识。此外，Monet架构能够在不降低整体性能的情况下，对领域、语言和有毒内容进行知识操控。我们追求透明的LLM揭示了提升专家数量对增强机械可解释性的潜力，及其本质上调整模型行为的能力。"
}Summarization failed, append the original article
error: Expecting ',' delimiter: line 5 column 130 (char 265). Line: 406.
Append: [Monet: Mixture of Monosemantic Experts for Transformers](https://arxiv.org/abs/2412.04139)
Json decode failed:
{
  "title": "基于视觉特征的对抗性引导方法NegToMe",
  "short_summary": "NegToMe通过视觉特征改善生成图像的多样性与质量。",
  "summary": "本文首次探讨了通过参考图像的视觉特征进行对抗性引导，提出了一种简单有效的无训练方法NegToMe。在逆扩散过程中，NegToMe通过选择性地分离生成图像与参考图像之间的匹配语义特征，实现对抗性引导。实验结果表明，NegToMe在保持输出图像质量的同时，显著提高了输出的多样性（种族、性别、视觉）和减少与版权内容的相似度（降低34.57%）。该方法易于实现，仅需几行代码，推理时间仅增加不到4%，且能够推广应用到不同的扩散架构中。代码可在 https:
  "keyword": [
    "对抗性引导",
    "视觉特征",
    "NegToMe"
  ]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 240 (char 327). Line: 406.
Append: [Negative Token Merging: Image-based Adversarial Feature Guidance](https://arxiv.org/abs/2412.01339)
Token length: 1314
Summarized using gpt-4o-mini
Append: [基于视觉语言模型的开放集故障检测与预防方法](https://arxiv.org/abs/2412.04455)
Token length: 1684
Summarized using gpt-4o-mini
Append: [MV-Adapter：适用于多视图图像生成的高效适配器](https://arxiv.org/abs/2412.03632)
Token length: 1666
Summarized using gpt-4o-mini
Append: [大语言模型的容量密度：评估效能与效率的新指标](https://arxiv.org/abs/2412.04315)
Token length: 957
Summarized using gpt-4o-mini
Append: [ZipAR: 一种加速自回归视觉生成的并行解码框架](https://arxiv.org/abs/2412.04062)
Token length: 1601
Summarized using gpt-4o-mini
Append: [Florence-VL：增强视觉表示的多模态大型语言模型](https://arxiv.org/abs/2412.04424)
Token length: 1231
Summarized using gpt-4o-mini
Append: [Infinity：一种高效的文本到图像自回归模型](https://arxiv.org/abs/2412.04431)
Token length: 1558
Summarized using gpt-4o-mini
Append: [Aguvis：一种基于视觉的自主GUI代理框架](https://arxiv.org/abs/2412.04454)
Token length: 1218
Summarized using gpt-4o-mini
Append: [OmniFlow：新型多模态生成模型实现任意生成任务](https://arxiv.org/abs/2412.01169)
Token length: 1069
Summarized using gpt-4o-mini
Append: [基于多模态框架的足球视频理解研究](https://arxiv.org/abs/2412.01820)
Token length: 1304
Summarized using gpt-4o-mini
Append: [评估语言模型数据生成能力的AgoraBench基准](https://arxiv.org/abs/2412.03679)
Token length: 1217
Summarized using gpt-4o-mini
Append: [基于生成模型的医学图像分割新 Paradigm](https://arxiv.org/abs/2412.04106)
Token length: 1390
Summarized using gpt-4o-mini
Append: [VisionZip：提高视觉语言模型效率的新方法](https://arxiv.org/abs/2412.04467)
Token length: 1053
Summarized using gpt-4o-mini
Append: [新型三维生成方法：结构化潜在表示与高质量资产创作](https://arxiv.org/abs/2412.01506)
Append: [HumanEdit: A High-Quality Human-Rewarded Dataset for Instruction-based Image Editing](https://arxiv.org/abs/2412.04280)
append_entries: 31
Finish: 2024-12-07 03:54:09.146827
------------------------------------------------------
Started: 2024-12-07 06:00:39.214472
Existing_entries: 679
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-07 06:00:39.415935
------------------------------------------------------
Started: 2024-12-07 09:00:53.668564
Existing_entries: 679
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-07 09:00:53.893443
------------------------------------------------------
Started: 2024-12-07 12:00:44.683942
Existing_entries: 679
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-07 12:00:44.882806
------------------------------------------------------
Started: 2024-12-07 15:01:33.938124
Existing_entries: 679
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-07 15:01:34.181181
------------------------------------------------------
Started: 2024-12-07 18:01:00.695660
Existing_entries: 679
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-07 18:01:00.921809
------------------------------------------------------
Started: 2024-12-07 21:00:38.799888
Existing_entries: 679
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-07 21:00:39.143532
------------------------------------------------------
Started: 2024-12-08 00:40:46.472246
Existing_entries: 679
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-08 00:40:46.702937
------------------------------------------------------
Started: 2024-12-08 03:29:34.311515
Existing_entries: 679
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-08 03:29:34.567409
------------------------------------------------------
Started: 2024-12-08 06:00:40.875778
Existing_entries: 679
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-08 06:00:41.090856
------------------------------------------------------
Started: 2024-12-08 09:01:08.905732
Existing_entries: 679
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-08 09:01:09.165712
------------------------------------------------------
Started: 2024-12-08 12:00:47.281143
Existing_entries: 679
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-08 12:00:47.483880
------------------------------------------------------
Started: 2024-12-08 15:00:40.870077
Existing_entries: 679
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-08 15:00:41.081521
------------------------------------------------------
Started: 2024-12-08 18:00:48.110267
Existing_entries: 679
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-08 18:00:48.317276
------------------------------------------------------
Started: 2024-12-08 21:00:40.399174
Existing_entries: 679
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-08 21:00:40.640765
------------------------------------------------------
Started: 2024-12-09 00:39:00.403928
Existing_entries: 679
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-09 00:39:00.646575
------------------------------------------------------
Started: 2024-12-09 03:30:03.645159
Existing_entries: 679
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-09 03:30:03.843481
------------------------------------------------------
Started: 2024-12-09 06:01:03.306331
Existing_entries: 679
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1673
Summarized using gpt-4o-mini
Append: [GenMAC：多智能体框架实现复杂文本到视频生成](https://arxiv.org/abs/2412.04440)
append_entries: 1
Finish: 2024-12-09 06:01:07.154241
------------------------------------------------------
Started: 2024-12-09 09:01:11.832887
Existing_entries: 680
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1175
Summarized using gpt-4o-mini
Append: [MinT：一种具有时间控制的多事件视频生成器](https://arxiv.org/abs/2412.05263)
Token length: 1105
Summarized using gpt-4o-mini
Append: [高保真室内场景重建的新方法2DGS-Room](https://arxiv.org/abs/2412.03428)
Token length: 1254
Summarized using gpt-4o-mini
Append: [基于人类反馈的文本生成视频模型对齐方法LiFT](https://arxiv.org/abs/2412.04814)
Token length: 1311
Summarized using gpt-4o-mini
Append: [InternVL 2.5：新一代多模态大语言模型](https://arxiv.org/abs/2412.05271)
Token length: 1874
Summarized using gpt-4o-mini
Append: [APOLLO：面向大规模语言模型优化的记忆高效优化器](https://arxiv.org/abs/2412.05270)
Token length: 1284
Summarized using gpt-4o-mini
Append: [构建大规模多模态指令调优数据集以提升推理能力](https://arxiv.org/abs/2412.05237)
Json decode failed:
{
  "title": "EXAONE 3.5指令调优语言模型介绍",
  "keyword": ["LG AI Research", "EXAONE 3.5", "语言模型"],
  "short_summary": "本文介绍了LG AI Research开发的EXAONE 3.5语言模型及其特点。",
  "summary": "本技术报告介绍了LG AI Research开发的EXAONE 3.5指令调优语言模型，提供了32B、7.8B和2.4B三种配置。这些模型在多个领域展现出色能力，包括在七项基准测试中实现最高的指令跟随能力，在四项基准测试中具备卓越的长文本理解能力，以及在九项通用基准中与同类前沿开放模型的竞争表现。EXAONE 3.5模型开放给任何人用于研究，用户可以从https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 198 (char 353). Line: 406.
Append: [EXAONE 3.5: Series of Large Language Models for Real-world Use Cases](https://arxiv.org/abs/2412.04862)
Token length: 1161
Summarized using gpt-4o-mini
Append: [SwiftEdit：高效的文本引导图像编辑工具](https://arxiv.org/abs/2412.04301)
Token length: 1907
Summarized using gpt-4o-mini
Append: [Moto-GPT：基于视频数据的机器人运动学习新方法](https://arxiv.org/abs/2412.04445)
append_entries: 9
Finish: 2024-12-09 09:01:45.663296
------------------------------------------------------
Started: 2024-12-09 12:14:35.457091
Existing_entries: 689
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1119
Summarized using gpt-4o-mini
Append: [对话元素建模的创新研究与基准DEMO](https://arxiv.org/abs/2412.04905)
append_entries: 1
Finish: 2024-12-09 12:14:40.109910
------------------------------------------------------
Started: 2024-12-09 15:00:47.528327
Existing_entries: 690
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-09 15:00:47.834767
------------------------------------------------------
Started: 2024-12-09 18:00:54.776694
Existing_entries: 690
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-09 18:00:55.006279
------------------------------------------------------
Started: 2024-12-09 21:00:57.733574
Existing_entries: 690
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1481
Summarized using gpt-4o-mini
Append: [提升多模态大型语言模型对复合图像理解的研究](https://arxiv.org/abs/2412.05243)
Token length: 788
Summarized using gpt-4o-mini
Append: [PanoDreamer: 一种单幅图像生成360度3D场景的新方法](https://arxiv.org/abs/2412.04827)
Token length: 1531
Summarized using gpt-4o-mini
Append: [Momentum-GS：提升3D重建一致性与准确性的动量自蒸馏方法](https://arxiv.org/abs/2412.04887)
append_entries: 3
Finish: 2024-12-09 21:01:10.090316
------------------------------------------------------
Started: 2024-12-10 00:38:06.785285
Existing_entries: 693
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1634
Summarized using gpt-4o-mini
Append: [BigDocs-7.5M：推动多模态AI在文档理解中的应用](https://arxiv.org/abs/2412.04626)
append_entries: 1
Finish: 2024-12-10 00:38:14.522977
------------------------------------------------------
Started: 2024-12-10 03:28:38.782574
Existing_entries: 694
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-10 03:28:38.953171
------------------------------------------------------
Started: 2024-12-10 06:00:55.652495
Existing_entries: 694
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1609
Summarized using gpt-4o-mini
Append: [无监督增强学习：RLZero方法实现零-shot语言到行为生成](https://arxiv.org/abs/2412.05718)
append_entries: 1
Finish: 2024-12-10 06:01:02.715447
------------------------------------------------------
Started: 2024-12-10 09:00:55.817728
Existing_entries: 695
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-10 09:00:55.974307
------------------------------------------------------
Started: 2024-12-10 12:14:10.656182
Existing_entries: 695
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1348
Summarized using gpt-4o-mini
Append: [多模态多粒度概念注释数据集 MMGiC 的构建与应用](https://arxiv.org/abs/2412.05939)
Token length: 1792
Summarized using gpt-4o-mini
Append: [See3D：基于大规模视频的视觉条件多视角扩散模型](https://arxiv.org/abs/2412.06699)
Token length: 1003
Summarized using gpt-4o-mini
Append: [基于大语言模型的隐蔽多比特文本水印嵌入方法](https://arxiv.org/abs/2412.03123)
Token length: 1495
Summarized using gpt-4o-mini
Append: [ProcessBench：数学推理错误识别能力的评估工具](https://arxiv.org/abs/2412.06559)
Token length: 1570
Summarized using gpt-4o-mini
Append: [Coconut：超越语言空间的连续思维推理范式](https://arxiv.org/abs/2412.06769)
Token length: 1465
Summarized using gpt-4o-mini
Append: [CARP：高效的粗到细自回归策略用于机器人视觉运动学习](https://arxiv.org/abs/2412.06782)
append_entries: 6
Finish: 2024-12-10 12:14:38.997915
------------------------------------------------------
Started: 2024-12-10 15:00:53.659830
Existing_entries: 701
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1589
Summarized using gpt-4o-mini
Append: [Divot: 一种基于扩散过程的视频标记器及其在视频生成中的应用](https://arxiv.org/abs/2412.04432)
append_entries: 1
Finish: 2024-12-10 15:01:04.558083
------------------------------------------------------
Started: 2024-12-10 18:01:01.173090
Existing_entries: 702
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1012
Summarized using gpt-4o-mini
Append: [基于扩散与黎曼流匹配的概率视觉地理定位方法](https://arxiv.org/abs/2412.06781)
Token length: 1087
Summarized using gpt-4o-mini
Append: [基于混合得分指导的扩散变换器运动迁移方法](https://arxiv.org/abs/2412.05355)
Token length: 934
Summarized using gpt-4o-mini
Append: [利用深度学习生成地球观测数据的特征表示](https://arxiv.org/abs/2412.05600)
Token length: 1234
Summarized using gpt-4o-mini
Append: [强化学习中智能体记忆概念的标准化与评估方法](https://arxiv.org/abs/2412.06531)
append_entries: 4
Finish: 2024-12-10 18:01:21.696000
------------------------------------------------------
Started: 2024-12-10 21:00:48.468858
Existing_entries: 706
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1378
Summarized using gpt-4o-mini
Append: [MAtCha: 高质量3D表面重建与光照片真实感视图合成的新模型](https://arxiv.org/abs/2412.06767)
Token length: 1174
Summarized using gpt-4o-mini
Append: [通过合并子优化模型提升通用大模型性能](https://arxiv.org/abs/2412.04144)
append_entries: 2
Finish: 2024-12-10 21:01:01.671351
------------------------------------------------------
Started: 2024-12-11 00:37:38.449753
Existing_entries: 708
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 828
Summarized using gpt-4o-mini
Append: [Turbo3D：超快速文本转3D系统](https://arxiv.org/abs/2412.04470)
append_entries: 1
Finish: 2024-12-11 00:37:44.594826
------------------------------------------------------
Started: 2024-12-11 03:25:58.500124
Existing_entries: 709
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-11 03:25:58.665966
------------------------------------------------------
Started: 2024-12-11 06:11:30.569419
Existing_entries: 709
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 987
Summarized using gpt-4o-mini
Append: [UniReal：统一的图像生成与编辑框架](https://arxiv.org/abs/2412.07774)
Token length: 1109
Summarized using gpt-4o-mini
Append: [推介Granite Guardian模型：提高大型语言模型的风险检测能力](https://arxiv.org/abs/2412.07724)
Token length: 1696
Summarized using gpt-4o-mini
Append: [Moxin 7B：开放源代码的大型语言模型新纪元](https://arxiv.org/abs/2412.06845)
Token length: 1418
Summarized using gpt-4o-mini
Append: [ILLUME：统一的多模态大语言模型研究](https://arxiv.org/abs/2412.06673)
append_entries: 4
Finish: 2024-12-11 06:11:56.209429
------------------------------------------------------
Started: 2024-12-11 09:00:47.103843
Existing_entries: 713
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 789
Summarized using gpt-4o-mini
Append: [DiTFlow：基于扩散转换器的视频运动传递方法](https://arxiv.org/abs/2412.07776)
Token length: 1620
Summarized using gpt-4o-mini
Append: [细粒度视觉属性适应框架的研究进展](https://arxiv.org/abs/2412.07674)
Token length: 1445
Summarized using gpt-4o-mini
Append: [一种新型的隐私保护联邦学习框架：HyperFL](https://arxiv.org/abs/2412.07187)
Token length: 1545
Summarized using gpt-4o-mini
Append: [STIV: 一种简单可扩展的视频生成框架](https://arxiv.org/abs/2412.07730)
Token length: 1466
Summarized using gpt-4o-mini
Append: [DiffSensei: 动态多角色控制的动漫生成框架](https://arxiv.org/abs/2412.07589)
Token length: 1760
Summarized using gpt-4o-mini
Append: [轻量级模型设计：提升5M规模模型性能的创新](https://arxiv.org/abs/2412.06674)
Token length: 1452
Summarized using gpt-4o-mini
Append: [基于3D轨迹的图像到视频生成物体控制方案](https://arxiv.org/abs/2412.07721)
Token length: 1659
Summarized using gpt-4o-mini
Append: [AURORA：增强多模态语言模型的视觉推理能力](https://arxiv.org/abs/2412.03548)
Token length: 1610
Summarized using gpt-4o-mini
Append: [CodeArena：一种评估代码生成模型人类偏好对齐的新基准](https://arxiv.org/abs/2412.05210)
Token length: 1304
Summarized using gpt-4o-mini
Append: [基于扩散模型的抗篡改图像水印方法研究](https://arxiv.org/abs/2412.04653)
append_entries: 10
Finish: 2024-12-11 09:01:44.205910
------------------------------------------------------
Started: 2024-12-11 12:14:01.858617
Existing_entries: 723
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1427
Summarized using gpt-4o-mini
Append: [OmniDocBench：提升文档内容提取的多源基准](https://arxiv.org/abs/2412.07626)
Token length: 1487
Summarized using gpt-4o-mini
Append: [3DTrajMaster：控制多实体3D运动的视频生成方法](https://arxiv.org/abs/2412.07759)
Token length: 1611
Summarized using gpt-4o-mini
Append: [RAPL：一种新的基于偏好的视觉奖励学习方法](https://arxiv.org/abs/2412.04835)
Token length: 1386
Summarized using gpt-4o-mini
Append: [Chimera：提升大规模多模态模型的领域特定能力](https://arxiv.org/abs/2412.05983)
Token length: 1302
Summarized using gpt-4o-mini
Append: [框架表示假说：解读与控制大型语言模型的理论框架](https://arxiv.org/abs/2412.07334)
append_entries: 5
Finish: 2024-12-11 12:14:37.704293
------------------------------------------------------
Started: 2024-12-11 15:01:00.329419
Existing_entries: 728
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-11 15:01:00.530348
------------------------------------------------------
Started: 2024-12-11 18:01:09.014690
Existing_entries: 728
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1901
Summarized using gpt-4o-mini
Append: [基于模块化方法的文本到图像生成改进](https://arxiv.org/abs/2412.06089)
Token length: 1097
Summarized using gpt-4o-mini
Append: [HARP：提升大语言模型性能的高效推理方法](https://arxiv.org/abs/2412.07282)
Token length: 912
Summarized using gpt-4o-mini
Append: [移动优化视频扩散模型MobileVD的设计与实现](https://arxiv.org/abs/2412.07583)
Token length: 949
Summarized using gpt-4o-mini
Append: [移动视频编辑优化方法研究](https://arxiv.org/abs/2412.06578)
Token length: 1134
Summarized using gpt-4o-mini
Append: [LoRA.rar：高效个性化图像生成的新方法](https://arxiv.org/abs/2412.05148)
Token length: 1431
Summarized using gpt-4o-mini
Append: [个性化AI生成反言论的效果与评估](https://arxiv.org/abs/2412.07338)
append_entries: 6
Finish: 2024-12-11 18:01:34.383024
------------------------------------------------------
Started: 2024-12-11 21:00:47.004121
Existing_entries: 734
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1687
Summarized using gpt-4o-mini
Append: [ACDiT：基于自回归和扩散的可调节多模态模型](https://arxiv.org/abs/2412.07720)
append_entries: 1
Finish: 2024-12-11 21:00:55.563394
------------------------------------------------------
Started: 2024-12-12 00:37:20.718318
Existing_entries: 735
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-12 00:37:20.926041
------------------------------------------------------
Started: 2024-12-12 03:26:46.302278
Existing_entries: 735
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-12 03:26:46.555044
------------------------------------------------------
Started: 2024-12-12 06:00:50.170128
Existing_entries: 735
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1574
Summarized using gpt-4o-mini
Append: [3DSRBench：全面评估3D空间推理能力的基准](https://arxiv.org/abs/2412.07825)
Token length: 1156
Summarized using gpt-4o-mini
Append: [构建LAION-SG数据集以提升文本到图像生成的合成能力](https://arxiv.org/abs/2412.08580)
Token length: 1326
Summarized using gpt-4o-mini
Append: [视频扩散模型在多视角一致性生成中的应用研究](https://arxiv.org/abs/2412.07760)
Token length: 1639
Summarized using gpt-4o-mini
Append: [Mogo：一种高效生成连续3D人类运动的新架构](https://arxiv.org/abs/2412.07797)
append_entries: 4
Finish: 2024-12-12 06:01:27.395995
------------------------------------------------------
Started: 2024-12-12 09:00:44.433808
Existing_entries: 739
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-12 09:00:44.624078
------------------------------------------------------
Started: 2024-12-12 12:14:09.090939
Existing_entries: 739
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 931
Summarized using gpt-4o-mini
Append: [FlowEdit：一种无反演的文本驱动图像编辑方法](https://arxiv.org/abs/2412.08629)
Token length: 1176
Summarized using gpt-4o-mini
Append: [MIT-10M: 大规模多语言图像翻译平行语料库](https://arxiv.org/abs/2412.07147)
Token length: 1089
Summarized using gpt-4o-mini
Append: [基于流场注意力机制的可控人像生成](https://arxiv.org/abs/2412.08486)
Token length: 1249
Summarized using gpt-4o-mini
Append: [StreamChat：提升大规模多模态模型对流媒体内容的交互能力](https://arxiv.org/abs/2412.08646)
Token length: 1445
Summarized using gpt-4o-mini
Append: [StyleMaster：高质量视频风格迁移方法](https://arxiv.org/abs/2412.07744)
Token length: 1506
Summarized using gpt-4o-mini
Append: [POINTS1.5：新一代视觉语言模型的创新与应用](https://arxiv.org/abs/2412.08443)
Token length: 1190
Summarized using gpt-4o-mini
Append: [通用密化方法提升高频细节的3D重建](https://arxiv.org/abs/2412.06234)
append_entries: 7
Finish: 2024-12-12 12:14:39.353901
------------------------------------------------------
Started: 2024-12-12 15:00:43.009068
Existing_entries: 746
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1614
Summarized using gpt-4o-mini
Append: [自我完善的数据飞轮：提升语言指导导航性能](https://arxiv.org/abs/2412.08467)
Token length: 1403
Summarized using gpt-4o-mini
Append: [知识感知奇异值适应方法KaSA在大语言模型调优中的应用](https://arxiv.org/abs/2412.06071)
Token length: 1113
Summarized using gpt-4o-mini
Append: [融合文本驱动的风格迁移新策略](https://arxiv.org/abs/2412.08503)
append_entries: 3
Finish: 2024-12-12 15:01:01.433441
------------------------------------------------------
Started: 2024-12-12 18:00:55.558618
Existing_entries: 749
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-12 18:00:55.757056
------------------------------------------------------
Started: 2024-12-12 21:00:49.518338
Existing_entries: 749
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1060
Summarized using gpt-4o-mini
Append: [Track4Gen：一种提高视频生成一致性的空间感知模型](https://arxiv.org/abs/2412.06016)
Token length: 1782
Summarized using gpt-4o-mini
Append: [BrowserGym生态系统：提升Web代理评估与基准测试的统一平台](https://arxiv.org/abs/2412.05467)
Token length: 1078
Summarized using gpt-4o-mini
Append: [一种新型的校准方法减少大型语言模型的幻觉现象](https://arxiv.org/abs/2412.06676)
append_entries: 3
Finish: 2024-12-12 21:01:05.463518
------------------------------------------------------
Started: 2024-12-13 00:37:54.994371
Existing_entries: 752
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-13 00:37:55.160953
------------------------------------------------------
Started: 2024-12-13 03:27:53.319070
Existing_entries: 752
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-13 03:27:53.500060
------------------------------------------------------
Started: 2024-12-13 06:11:32.035082
Existing_entries: 752
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 864
Summarized using gpt-4o-mini
Append: [phi-4语言模型：以数据质量为核心的创新](https://arxiv.org/abs/2412.08905)
Token length: 1831
Summarized using gpt-4o-mini
Append: [WaLLoC：高效的压缩领域学习神经编解码器](https://arxiv.org/abs/2412.09405)
Token length: 1697
Summarized using gpt-4o-mini
Append: [EasyRef: 一种用于扩散模型的多参考图像自适应方法](https://arxiv.org/abs/2412.09618)
Token length: 1489
Summarized using gpt-4o-mini
Append: [提升多模态大语言模型在几何感知中的表现](https://arxiv.org/abs/2412.08737)
Token length: 1156
Summarized using gpt-4o-mini
Append: [构建高质量多语种平行语料库以提升印地语言NMT模型性能](https://arxiv.org/abs/2412.09025)
Token length: 1037
Summarized using gpt-4o-mini
Append: [基于DINOv2的Gaze-LLE框架推广人眼注视目标估计](https://arxiv.org/abs/2412.09586)
Token length: 1408
Summarized using gpt-4o-mini
Append: [Latent语言建模：统一的多模态生成模型](https://arxiv.org/abs/2412.08635)
Token length: 1789
Summarized using gpt-4o-mini
Append: [基于流式感知和推理机制的多模态语言模型框架](https://arxiv.org/abs/2412.09596)
Token length: 1471
Summarized using gpt-4o-mini
Append: [OLA-VLM：优化多模态大语言模型的视觉理解能力](https://arxiv.org/abs/2412.09585)
Token length: 1269
Summarized using gpt-4o-mini
Append: [FreeSplatter：高效的稀疏视图重建框架](https://arxiv.org/abs/2412.09573)
Token length: 1079
Summarized using gpt-4o-mini
Append: [Neural LightRig：基于多重照明条件的物体几何与材料恢复](https://arxiv.org/abs/2412.09593)
Token length: 1141
Summarized using gpt-4o-mini
Append: [基于语言指导的视觉导航任务统一框架研究](https://arxiv.org/abs/2412.05552)
append_entries: 12
Finish: 2024-12-13 06:12:43.402963
------------------------------------------------------
Started: 2024-12-13 09:00:45.632020
Existing_entries: 764
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1042
Summarized using gpt-4o-mini
Append: [基于扩散逆向的新图像超分辨率技术](https://arxiv.org/abs/2412.09013)
Token length: 1061
Summarized using gpt-4o-mini
Append: [LoRACLR：一种高效的多概念图像生成方法](https://arxiv.org/abs/2412.09622)
Token length: 1351
Summarized using gpt-4o-mini
Append: [AgentTrek：基于网络教程的GUI代理高效数据合成方法](https://arxiv.org/abs/2412.09605)
Token length: 1323
Summarized using gpt-4o-mini
Append: [开发高效小型文本生成图像模型SnapGen](https://arxiv.org/abs/2412.09619)
Token length: 1330
Summarized using gpt-4o-mini
Append: [Lyra：提升多模态大语言模型的长语音理解能力](https://arxiv.org/abs/2412.09501)
Token length: 1776
Summarized using gpt-4o-mini
Append: [基于物理信息高斯函数的偏微分方程近似方法](https://arxiv.org/abs/2412.05994)
Token length: 1274
Summarized using gpt-4o-mini
Append: [RuleArena：评估大型语言模型规则推理能力的新基准](https://arxiv.org/abs/2412.08972)
Token length: 1272
Summarized using gpt-4o-mini
Append: [词义消歧的新任务：词义连接](https://arxiv.org/abs/2412.09370)
append_entries: 8
Finish: 2024-12-13 09:01:40.930970
------------------------------------------------------
Started: 2024-12-13 12:00:43.624907
Existing_entries: 772
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-13 12:00:43.878736
------------------------------------------------------
Started: 2024-12-13 15:00:56.758829
Existing_entries: 772
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 610
Summarized using gpt-4o-mini
Append: [评估版权材料对挪威语言模型性能的影响](https://arxiv.org/abs/2412.09460)
Token length: 1145
Summarized using gpt-4o-mini
Append: [系统评价中的LLM评估者：基于生成AI的新方法](https://arxiv.org/abs/2412.09569)
Token length: 1532
Summarized using gpt-4o-mini
Append: [DisPose: 基于稀疏信号的人物图像动画控制](https://arxiv.org/abs/2412.09349)
append_entries: 3
Finish: 2024-12-13 15:01:15.768214
------------------------------------------------------
Started: 2024-12-13 18:10:10.270872
Existing_entries: 775
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-13 18:10:10.520889
------------------------------------------------------
Started: 2024-12-13 21:00:54.221497
Existing_entries: 775
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1915
Summarized using gpt-4o-mini
Append: [ONEBench：开放式基准评估新范式](https://arxiv.org/abs/2412.06745)
append_entries: 1
Finish: 2024-12-13 21:00:59.425196
------------------------------------------------------
Started: 2024-12-14 00:36:15.965039
Existing_entries: 776
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1336
Summarized using gpt-4o-mini
Append: [TarFlow：一种新型的归一化流模型](https://arxiv.org/abs/2412.06329)
Token length: 1310
Summarized using gpt-4o-mini
Append: [VisionArena: 真实用户与视觉语言模型交互的数据集](https://arxiv.org/abs/2412.08687)
append_entries: 2
Finish: 2024-12-14 00:36:28.640332
------------------------------------------------------
Started: 2024-12-14 03:22:04.707442
Existing_entries: 778
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-14 03:22:04.935966
------------------------------------------------------
Started: 2024-12-14 06:00:56.744316
Existing_entries: 778
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-14 06:00:56.928528
------------------------------------------------------
Started: 2024-12-14 09:00:55.336098
Existing_entries: 778
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-14 09:00:55.506478
------------------------------------------------------
Started: 2024-12-14 12:11:49.420881
Existing_entries: 778
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-14 12:11:49.674187
------------------------------------------------------
Started: 2024-12-14 15:00:57.418810
Existing_entries: 778
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-14 15:00:57.626322
------------------------------------------------------
Started: 2024-12-14 18:01:07.306085
Existing_entries: 778
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-14 18:01:07.505154
------------------------------------------------------
Started: 2024-12-14 21:01:06.149331
Existing_entries: 778
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-14 21:01:06.403896
------------------------------------------------------
Started: 2024-12-15 00:41:10.231669
Existing_entries: 778
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-15 00:41:10.401848
------------------------------------------------------
Started: 2024-12-15 03:30:14.045969
Existing_entries: 778
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-15 03:30:14.227134
------------------------------------------------------
Started: 2024-12-15 06:00:44.199907
Existing_entries: 778
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-15 06:00:44.427813
------------------------------------------------------
Started: 2024-12-15 09:01:00.803565
Existing_entries: 778
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-15 09:01:00.976166
------------------------------------------------------
Started: 2024-12-15 12:00:52.090761
Existing_entries: 778
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-15 12:00:52.269728
------------------------------------------------------
Started: 2024-12-15 15:00:51.742928
Existing_entries: 778
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-15 15:00:51.987418
------------------------------------------------------
Started: 2024-12-15 18:00:47.653002
Existing_entries: 778
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-15 18:00:47.840350
------------------------------------------------------
Started: 2024-12-15 21:00:42.911041
Existing_entries: 778
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-15 21:00:43.163866
------------------------------------------------------
Started: 2024-12-16 00:39:32.992534
Existing_entries: 778
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-16 00:39:33.152658
------------------------------------------------------
Started: 2024-12-16 03:30:03.914854
Existing_entries: 778
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1909
Summarized using gpt-4o-mini
Append: [SCBench：针对长上下文的KV缓存优化基准评估](https://arxiv.org/abs/2412.10319)
Token length: 1004
Summarized using gpt-4o-mini
Append: [FireFlow：一种高效的图像反演与编辑方法](https://arxiv.org/abs/2412.07517)
append_entries: 2
Finish: 2024-12-16 03:30:15.004150
------------------------------------------------------
Started: 2024-12-16 06:11:56.946821
Existing_entries: 780
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-16 06:11:57.166836
------------------------------------------------------
Started: 2024-12-16 09:00:47.295536
Existing_entries: 780
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1594
Summarized using gpt-4o-mini
Append: [深入探究大规模多模态模型的视频理解机制](https://arxiv.org/abs/2412.10360)
Token length: 1168
Summarized using gpt-4o-mini
Append: [InstanceCap：基于实例的结构化视频字幕生成框架](https://arxiv.org/abs/2412.09283)
Token length: 1758
Summarized using gpt-4o-mini
Append: [从语言模型到行动模型：人工智能发展的新阶段](https://arxiv.org/abs/2412.10047)
Token length: 1570
Summarized using gpt-4o-mini
Append: [GenEx：基于生成想象的复杂三维世界探索系统](https://arxiv.org/abs/2412.09624)
Token length: 1347
Summarized using gpt-4o-mini
Append: [FreeScale：基于尺度融合的高分辨率视觉生成新范式](https://arxiv.org/abs/2412.09626)
append_entries: 5
Finish: 2024-12-16 09:01:15.077924
------------------------------------------------------
Started: 2024-12-16 12:14:41.189836
Existing_entries: 785
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1244
Summarized using gpt-4o-mini
Append: [SmolTulu-1.7b-Instruct模型的优化与性能分析](https://arxiv.org/abs/2412.08347)
Token length: 1857
Summarized using gpt-4o-mini
Append: [基于语言引导的对抗攻击方法Prompt2Perturb在乳腺癌影像中的应用](https://arxiv.org/abs/2412.09910)
Token length: 1440
Summarized using gpt-4o-mini
Append: [BiMediX2：先进的双语医学大模型](https://arxiv.org/abs/2412.07769)
Token length: 1430
Summarized using gpt-4o-mini
Append: [视觉音乐桥：一种新的多模态音乐生成方法](https://arxiv.org/abs/2412.09428)
append_entries: 4
Finish: 2024-12-16 12:15:04.465456
------------------------------------------------------
Started: 2024-12-16 15:00:45.802799
Existing_entries: 789
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1018
Summarized using gpt-4o-mini
Append: [FluxSpace：基于修正流模型的图像语义编辑方法](https://arxiv.org/abs/2412.09611)
Token length: 1280
Summarized using gpt-4o-mini
Append: [SynerGen-VL：一种简单高效的无编码多模态大型语言模型](https://arxiv.org/abs/2412.09604)
Token length: 1381
Summarized using gpt-4o-mini
Append: [无调优对象插入与主题驱动生成的新方法](https://arxiv.org/abs/2412.08645)
append_entries: 3
Finish: 2024-12-16 15:01:02.272308
------------------------------------------------------
Started: 2024-12-16 18:00:52.198717
Existing_entries: 792
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-16 18:00:52.391472
------------------------------------------------------
Started: 2024-12-16 21:05:37.539145
Existing_entries: 792
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-16 21:05:37.726045
------------------------------------------------------
Started: 2024-12-17 00:37:33.515342
Existing_entries: 792
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1770
Summarized using gpt-4o-mini
Append: [GReaTer：基于梯度的轻量级提示优化技术](https://arxiv.org/abs/2412.09722)
Token length: 1854
Summarized using gpt-4o-mini
Append: [LinGen框架：线性复杂度文本到视频生成的突破](https://arxiv.org/abs/2412.09856)
Token length: 1228
Summarized using gpt-4o-mini
Append: [视觉轨迹提示提升机器人操作的空间-时间意识](https://arxiv.org/abs/2412.10345)
append_entries: 3
Finish: 2024-12-17 00:37:47.672254
------------------------------------------------------
Started: 2024-12-17 03:25:41.773641
Existing_entries: 795
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-17 03:25:42.011845
------------------------------------------------------
Started: 2024-12-17 06:01:11.709900
Existing_entries: 795
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-17 06:01:11.873933
------------------------------------------------------
Started: 2024-12-17 09:00:34.540371
Existing_entries: 795
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1305
Summarized using gpt-4o-mini
Append: [RetroLLM：整合检索与生成的统一框架](https://arxiv.org/abs/2412.11919)
Token length: 1555
Summarized using gpt-4o-mini
Append: [GaussianProperty：无训练框架下的物理性质估计](https://arxiv.org/abs/2412.11258)
append_entries: 2
Finish: 2024-12-17 09:00:45.894296
------------------------------------------------------
Started: 2024-12-17 12:13:58.214136
Existing_entries: 797
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1052
Summarized using gpt-4o-mini
Append: [Byte Latent Transformer：新型字节级LLM架构提升推理效率](https://arxiv.org/abs/2412.09871)
Token length: 1281
Summarized using gpt-4o-mini
Append: [BrushEdit: 基于指令的自由形式图像编辑新方法](https://arxiv.org/abs/2412.10316)
Token length: 1302
Summarized using gpt-4o-mini
Append: [高效动态评估框架提升视觉生成模型评估效率](https://arxiv.org/abs/2412.09645)
Token length: 1374
Summarized using gpt-4o-mini
Append: [基于视频扩散模型的单幅图像高效3D场景重建方法](https://arxiv.org/abs/2412.12091)
Token length: 1493
Summarized using gpt-4o-mini
Append: [ColorFlow：基于扩散模型的图像序列自动上色框架](https://arxiv.org/abs/2412.11815)
Token length: 1182
Summarized using gpt-4o-mini
Append: [引入因果扩散模型：CausalFusion的创新方法](https://arxiv.org/abs/2412.12095)
Token length: 1182
Summarized using gpt-4o-mini
Append: [结合序列变换与状态变换提升基础模型效率](https://arxiv.org/abs/2412.11834)
Token length: 1497
Summarized using gpt-4o-mini
Append: [SPaR：提升语言模型指令遵循能力的新框架](https://arxiv.org/abs/2412.11605)
Token length: 983
Summarized using gpt-4o-mini
Append: [StrandHead：基于文本生成可拆卸3D头发模型的新方法](https://arxiv.org/abs/2412.11586)
Token length: 1421
Summarized using gpt-4o-mini
Append: [小型语言模型在指令演变中的潜力研究](https://arxiv.org/abs/2412.11231)
Token length: 1492
Summarized using gpt-4o-mini
Append: [基于扩散模型的多视角内在分解方法IDArb](https://arxiv.org/abs/2412.12083)
Token length: 1728
Summarized using gpt-4o-mini
Append: [MOVIS：增强多对象新视角合成的结构感知扩散模型](https://arxiv.org/abs/2412.11457)
append_entries: 12
Finish: 2024-12-17 12:15:05.310362
------------------------------------------------------
Started: 2024-12-17 15:00:58.991766
Existing_entries: 809
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-17 15:00:59.161792
------------------------------------------------------
Started: 2024-12-17 18:01:16.670848
Existing_entries: 809
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1369
Summarized using gpt-4o-mini
Append: [SepLLM：一种加速推理的大型语言模型框架](https://arxiv.org/abs/2412.12094)
Token length: 1126
Summarized using gpt-4o-mini
Append: [WHISPER-GPT：融合连续音频表示与离散音频令牌的生成大语言模型](https://arxiv.org/abs/2412.11449)
Token length: 1060
Summarized using gpt-4o-mini
Append: [基于模仿学习的灵活移动操控机器人设计](https://arxiv.org/abs/2412.10447)
Token length: 761
Summarized using gpt-4o-mini
Append: [提升垂直联邦学习中输入数据保护的模型架构转变研究](https://arxiv.org/abs/2412.11689)
append_entries: 4
Finish: 2024-12-17 18:01:31.839562
------------------------------------------------------
Started: 2024-12-17 21:00:58.719518
Existing_entries: 813
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1219
Summarized using gpt-4o-mini
Append: [Emma-X：基于视觉语言模型的机器人控制新方法](https://arxiv.org/abs/2412.11974)
Token length: 1416
Summarized using gpt-4o-mini
Append: [DynamicScaler：高质量全景动态场景视频生成](https://arxiv.org/abs/2412.11100)
Token length: 1862
Summarized using gpt-4o-mini
Append: [大语言模型的发展：开放源代码与闭源模型的较量](https://arxiv.org/abs/2412.12004)
Token length: 495
Summarized using gpt-4o-mini
Append: [Evalica：现代NLP模型评估工具包的介绍与应用](https://arxiv.org/abs/2412.11314)
append_entries: 4
Finish: 2024-12-17 21:01:25.626556
------------------------------------------------------
Started: 2024-12-18 00:36:07.373683
Existing_entries: 817
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1250
Summarized using gpt-4o-mini
Append: [MaxInfoRL：通过最大化信息增益平衡内在与外在探索](https://arxiv.org/abs/2412.12098)
Token length: 1623
Summarized using gpt-4o-mini
Append: [基于扩散模型的视频换脸新框架](https://arxiv.org/abs/2412.11279)
append_entries: 2
Finish: 2024-12-18 00:36:16.875748
------------------------------------------------------
Started: 2024-12-18 03:20:08.836276
Existing_entries: 819
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 844
Summarized using gpt-4o-mini
Append: [通过扰动预训练提高图像生成的保护效果](https://arxiv.org/abs/2412.11423)
Token length: 1316
Summarized using gpt-4o-mini
Append: [强化学习提炼通用策略：提升机器人精确操作能力](https://arxiv.org/abs/2412.09858)
append_entries: 2
Finish: 2024-12-18 03:20:16.300566
------------------------------------------------------
Started: 2024-12-18 06:00:53.833072
Existing_entries: 821
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-18 06:00:54.016706
------------------------------------------------------
Started: 2024-12-18 09:00:44.070292
Existing_entries: 821
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "多维洞察基准：评估大型多模态模型的现实人类需求",
  "keyword": ["大型多模态模型", "人类需求", "多维洞察基准"],
  "short_summary": "提出MDI基准，评估LMM在现实场景中的人类需求适应性。",
  "summary": "大型多模态模型（LMMs）迅速发展，但现有基准未能全面准确评估其在现实场景中满足人类多样需求的能力。为此，提出了多维洞察（MDI）基准，涵盖超过500张图像，涉及六种常见人类生活场景。MDI基准具有两大优势：首先，每张图像配有两类问题——简单问题评估模型对图像的理解，复杂问题考察其分析推理能力。其次，考虑到不同年龄群体在相同场景中的需求和视角差异，基准根据年轻人、中年人和老年人三类人群对问题进行分层设计。这一设计使得能够更细致地评估LMM在满足不同年龄群体偏好和需求方面的能力。MDI基准的数据和评估代码可在https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 277 (char 411). Line: 406.
Append: [Multi-Dimensional Insights: Benchmarking Real-World Personalization in Large Multimodal Models](https://arxiv.org/abs/2412.12606)
Token length: 1342
Summarized using gpt-4o-mini
Append: [新评估指标与动态基准提升大型语言模型推理能力](https://arxiv.org/abs/2412.13147)
append_entries: 2
Finish: 2024-12-18 09:00:54.507890
------------------------------------------------------
Started: 2024-12-18 12:13:31.174980
Existing_entries: 823
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1233
Summarized using gpt-4o-mini
Append: [基于概念编码解码机制的自回归变换器的学习能力研究](https://arxiv.org/abs/2412.12276)
Token length: 1593
Summarized using gpt-4o-mini
Append: [OmniEval：金融领域的自动化检索增强生成基准](https://arxiv.org/abs/2412.13018)
append_entries: 2
Finish: 2024-12-18 12:13:42.954501
------------------------------------------------------
Started: 2024-12-18 15:00:52.887101
Existing_entries: 825
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1459
Summarized using gpt-4o-mini
Append: [MIVE：新一代零-shot多实例视频编辑框架](https://arxiv.org/abs/2412.12877)
append_entries: 1
Finish: 2024-12-18 15:00:57.916341
------------------------------------------------------
Started: 2024-12-18 18:07:47.051264
Existing_entries: 826
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1040
Summarized using gpt-4o-mini
Append: [压缩链式思维框架（CCoT）提升语言模型推理性能](https://arxiv.org/abs/2412.13171)
Token length: 1356
Summarized using gpt-4o-mini
Append: [利用大型语言模型改善软件开发中的异常处理](https://arxiv.org/abs/2412.11713)
Token length: 1543
Summarized using gpt-4o-mini
Append: [提升视觉语言模型加速性能的新策略FEATHER](https://arxiv.org/abs/2412.13180)
Json decode failed:
{
  "title": "通过PAE系统实现自我学习的多能智能代理",
  "short_summary": "本文提出了一种自我发现技能的智能代理学习系统PAE。",
  "summary": "随着基础模型的广泛应用，智能代理的视觉和任务导向能力迅速提高。为了解决技能指定的局限性，本文提出了Proposer-Agent-Evaluator（PAE）系统，使得基础模型能够自主发现和实践技能。PAE依赖于一个上下文感知的任务提议者，利用环境信息（如用户演示或网站名称）提出任务，代理通过具体的操作尝试这些任务，真实世界的执行结果通过基于视觉语言模型的成功评估者进行评估，这一评估结果作为奖励信号，促进代理策略的优化。我们在视觉网页导航任务中验证了该系统的有效性，显示出在真实和自托管网站上的优越性能。此研究首次实现了自主任务提议与强化学习相结合的学习系统，达到最先进的表现，其开源代码可以在网址https:
  "keyword": ["智能代理", "自我学习", "技能发现"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 321 (char 406). Line: 406.
Append: [Proposer-Agent-Evaluator(PAE): Autonomous Skill Discovery For Foundation Model Internet Agents](https://arxiv.org/abs/2412.13194)
Token length: 1433
Summarized using gpt-4o-mini
Append: [VisDoMBench：多文档多模态问答系统的新基准与方法](https://arxiv.org/abs/2412.10704)
Token length: 1320
Summarized using gpt-4o-mini
Append: [对比解码与放弃法：提升大语言模型的可靠性与用户信任](https://arxiv.org/abs/2412.12527)
append_entries: 6
Finish: 2024-12-18 18:08:19.479669
------------------------------------------------------
Started: 2024-12-18 21:00:47.417375
Existing_entries: 832
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-18 21:00:47.599558
------------------------------------------------------
Started: 2024-12-19 00:38:12.674273
Existing_entries: 832
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-19 00:38:12.916546
------------------------------------------------------
Started: 2024-12-19 03:20:58.993482
Existing_entries: 832
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-19 03:20:59.220122
------------------------------------------------------
Started: 2024-12-19 06:00:54.489486
Existing_entries: 832
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-19 06:00:54.707493
------------------------------------------------------
Started: 2024-12-19 09:01:13.804379
Existing_entries: 832
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1000
Summarized using gpt-4o-mini
Append: [基于生成AI的2D动画制作流程优化](https://arxiv.org/abs/2412.14173)
Token length: 1252
Summarized using gpt-4o-mini
Append: [FashionComposer：灵活的服装图像生成框架](https://arxiv.org/abs/2412.14168)
Token length: 958
Summarized using gpt-4o-mini
Append: [基于提示的深度估计新范式：Prompt Depth Anything](https://arxiv.org/abs/2412.14015)
Token length: 1884
Summarized using gpt-4o-mini
Append: [ChatDiT：无调优的交互式视觉生成框架](https://arxiv.org/abs/2412.12571)
Token length: 1422
Summarized using gpt-4o-mini
Append: [RAG-RewardBench：评估检索增强语言模型奖励模型的新基准](https://arxiv.org/abs/2412.13746)
Token length: 962
Summarized using gpt-4o-mini
Append: [图形用户界面代理的综述与未来发展](https://arxiv.org/abs/2412.13501)
Token length: 1179
Summarized using gpt-4o-mini
Append: [VidTok：高性能视频Tokenizer的创新与应用](https://arxiv.org/abs/2412.13061)
Token length: 1706
Summarized using gpt-4o-mini
Append: [AI代理在职场任务自动化中的表现评估](https://arxiv.org/abs/2412.14161)
append_entries: 8
Finish: 2024-12-19 09:01:46.763149
------------------------------------------------------
Started: 2024-12-19 12:01:39.190601
Existing_entries: 840
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1360
Summarized using gpt-4o-mini
Append: [基于CAD-Recode的3D CAD逆向工程方法研究](https://arxiv.org/abs/2412.14042)
Token length: 1050
Summarized using gpt-4o-mini
Append: [AntiLeak-Bench：一种自动化的防泄漏基准框架](https://arxiv.org/abs/2412.13670)
Token length: 1822
Summarized using gpt-4o-mini
Append: [Mix-LN: 一种改进的层归一化技术提升大语言模型训练效果](https://arxiv.org/abs/2412.13795)
Token length: 1048
Summarized using gpt-4o-mini
Append: [AnySat：适应多样化地球观测数据的多模态模型](https://arxiv.org/abs/2412.14123)
Token length: 1319
Summarized using gpt-4o-mini
Append: [Humanoid-X: 大规模人形机器人数据集促进可扩展学习](https://arxiv.org/abs/2412.14172)
Token length: 1647
Summarized using gpt-4o-mini
Append: [Mixture-of-Denoising Experts: 提升模仿学习中的扩散策略](https://arxiv.org/abs/2412.12953)
append_entries: 6
Finish: 2024-12-19 12:02:34.465777
------------------------------------------------------
Started: 2024-12-19 15:00:55.254925
Existing_entries: 846
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-19 15:00:55.454345
------------------------------------------------------
Started: 2024-12-19 18:01:00.888000
Existing_entries: 846
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1319
Summarized using gpt-4o-mini
Append: [LLaVA-UHD v2: 一种提升多模态大语言模型视觉编码的新方法](https://arxiv.org/abs/2412.13871)
append_entries: 1
Finish: 2024-12-19 18:01:10.921420
------------------------------------------------------
Started: 2024-12-19 21:01:12.960701
Existing_entries: 847
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1629
Summarized using gpt-4o-mini
Append: [FastVLM: 高效视觉语言模型优化图像分辨率处理](https://arxiv.org/abs/2412.13303)
Token length: 981
Summarized using gpt-4o-mini
Append: [多模态大型语言模型的视觉空间智能研究](https://arxiv.org/abs/2412.14171)
Token length: 1918
Summarized using gpt-4o-mini
Append: [大型语言模型中的对齐伪装现象研究](https://arxiv.org/abs/2412.14093)
append_entries: 3
Finish: 2024-12-19 21:01:34.214630
------------------------------------------------------
Started: 2024-12-20 00:34:38.509257
Existing_entries: 850
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1466
Summarized using gpt-4o-mini
Append: [SGD-SaI: 一种有效的随机梯度下降方法提升深度学习训练效率](https://arxiv.org/abs/2412.11768)
Token length: 890
Summarized using gpt-4o-mini
Append: [ModernBERT: 优化后的高效编码器模型](https://arxiv.org/abs/2412.13663)
Token length: 1271
Summarized using gpt-4o-mini
Append: [高效自回归视频生成的新方法NOVA](https://arxiv.org/abs/2412.14169)
append_entries: 3
Finish: 2024-12-20 00:34:53.645898
------------------------------------------------------
Started: 2024-12-20 03:13:55.025663
Existing_entries: 853
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-20 03:13:55.261704
------------------------------------------------------
Started: 2024-12-20 06:10:24.987563
Existing_entries: 853
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-20 06:10:25.151681
------------------------------------------------------
Started: 2024-12-20 09:00:48.922363
Existing_entries: 853
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1162
Summarized using gpt-4o-mini
Append: [LeviTor：增强深度维度的图像到视频合成轨迹控制方法](https://arxiv.org/abs/2412.15214)
Token length: 1300
Summarized using gpt-4o-mini
Append: [AceMath：前沿数学模型与奖励模型的创新](https://arxiv.org/abs/2412.15084)
Token length: 1103
Summarized using gpt-4o-mini
Append: [基于视觉专家的图像描述增强方法DCE](https://arxiv.org/abs/2412.14233)
Token length: 1292
Summarized using gpt-4o-mini
Append: [DI-PCG：高效逆向程序内容生成的新方法](https://arxiv.org/abs/2412.15200)
Token length: 1326
Summarized using gpt-4o-mini
Append: [合成数据对语言模型训练的影响及解决方案](https://arxiv.org/abs/2412.14689)
Token length: 1267
Summarized using gpt-4o-mini
Append: [基于可供性概念的图像合成研究](https://arxiv.org/abs/2412.14462)
Token length: 1197
Summarized using gpt-4o-mini
Append: [无监督指令基础图像编辑模型的创新研究](https://arxiv.org/abs/2412.15216)
Token length: 1114
Summarized using gpt-4o-mini
Append: [文本驱动的开放分子生成基准（TOMG-Bench）研究](https://arxiv.org/abs/2412.14642)
Token length: 1797
Summarized using gpt-4o-mini
Append: [CrossFlow: 一种新型跨模态流匹配模型](https://arxiv.org/abs/2412.15213)
Token length: 1910
Summarized using gpt-4o-mini
Append: [Qwen2.5：全面升级的大型语言模型系列](https://arxiv.org/abs/2412.15115)
Token length: 1303
Summarized using gpt-4o-mini
Append: [MegaPairs: 一种新颖的数据合成方法提升多模态检索性能](https://arxiv.org/abs/2412.14475)
Token length: 1298
Summarized using gpt-4o-mini
Append: [LongBench v2：评估大语言模型处理长上下文问题的基准](https://arxiv.org/abs/2412.15204)
Token length: 1443
Summarized using gpt-4o-mini
Append: [AR-MCTS框架：提升多模态大语言模型的推理能力](https://arxiv.org/abs/2412.14835)
append_entries: 13
Finish: 2024-12-20 09:02:05.540692
------------------------------------------------------
Started: 2024-12-20 12:01:01.113344
Existing_entries: 866
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-20 12:01:01.343739
------------------------------------------------------
Started: 2024-12-20 15:01:09.277081
Existing_entries: 866
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "DateLogicQA: 时间推理的基准与评估",
  "short_summary": "本文介绍了DateLogicQA基准，评估大型语言模型在时间推理中的表现。",
  "summary": "本文介绍了DateLogicQA，这是一个包含190个问题的基准，涵盖多种日期格式、时间上下文和推理类型。我们提出了语义完整性指标，以评估词法分析的质量，并分析了两种偏差：影响嵌入的表示层偏差和影响推理输出的逻辑层偏差。研究结果对大型语言模型在时间推理中的能力和局限性进行了全面评估，并突出了准确处理时间数据中的关键挑战。此外，我们的工作相关的GitHub存储库可用，链接为 https:
  "keyword": [
    "时间推理",
    "基准",
    "大型语言模型"
  ]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 209 (char 308). Line: 406.
Append: [DateLogicQA: Benchmarking Temporal Biases in Large Language Models](https://arxiv.org/abs/2412.13377)
Token length: 1043
Summarized using gpt-4o-mini
Append: [Move-in-2D：基于场景图像生成多样化人类动作序列](https://arxiv.org/abs/2412.13185)
append_entries: 2
Finish: 2024-12-20 15:01:17.664291
------------------------------------------------------
Started: 2024-12-20 18:00:58.383215
Existing_entries: 868
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1512
Summarized using gpt-4o-mini
Append: [PixelMan：无反演、高效的一致性对象编辑方法](https://arxiv.org/abs/2412.14283)
append_entries: 1
Finish: 2024-12-20 18:01:02.958207
------------------------------------------------------
Started: 2024-12-20 21:00:46.300681
Existing_entries: 869
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-20 21:00:46.510642
------------------------------------------------------
Started: 2024-12-21 00:33:48.158115
Existing_entries: 869
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-21 00:33:48.322907
------------------------------------------------------
Started: 2024-12-21 03:10:21.994927
Existing_entries: 869
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 956
Summarized using gpt-4o-mini
Append: [AV-Link: 视频与音频生成的统一框架](https://arxiv.org/abs/2412.15191)
append_entries: 1
Finish: 2024-12-21 03:10:27.036106
------------------------------------------------------
Started: 2024-12-21 06:00:55.927144
Existing_entries: 870
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-21 06:00:56.090466
------------------------------------------------------
Started: 2024-12-21 09:00:42.282442
Existing_entries: 870
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-21 09:00:42.473674
------------------------------------------------------
Started: 2024-12-21 12:00:48.726467
Existing_entries: 870
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-21 12:00:48.915818
------------------------------------------------------
Started: 2024-12-21 15:00:49.706432
Existing_entries: 870
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-21 15:00:49.899990
------------------------------------------------------
Started: 2024-12-21 18:00:54.211386
Existing_entries: 870
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-21 18:00:54.402890
------------------------------------------------------
Started: 2024-12-21 21:00:58.825189
Existing_entries: 870
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-21 21:00:59.017181
------------------------------------------------------
Started: 2024-12-22 00:37:52.984522
Existing_entries: 870
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-22 00:37:53.226525
------------------------------------------------------
Started: 2024-12-22 03:16:20.988097
Existing_entries: 870
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-22 03:16:21.240245
------------------------------------------------------
Started: 2024-12-22 06:00:41.584147
Existing_entries: 870
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-22 06:00:41.765935
------------------------------------------------------
Started: 2024-12-22 09:00:50.552423
Existing_entries: 870
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-22 09:00:50.702470
------------------------------------------------------
Started: 2024-12-22 12:01:01.250272
Existing_entries: 870
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-22 12:01:01.470336
------------------------------------------------------
Started: 2024-12-22 15:00:43.386875
Existing_entries: 870
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-22 15:00:43.545662
------------------------------------------------------
Started: 2024-12-22 18:01:04.745554
Existing_entries: 870
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-22 18:01:05.133143
------------------------------------------------------
Started: 2024-12-22 21:00:52.680251
Existing_entries: 870
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-22 21:00:52.920293
------------------------------------------------------
Started: 2024-12-23 00:36:06.207801
Existing_entries: 870
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-23 00:36:06.413081
------------------------------------------------------
Started: 2024-12-23 03:14:28.025599
Existing_entries: 870
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-23 03:14:28.212528
------------------------------------------------------
Started: 2024-12-23 06:11:21.664996
Existing_entries: 870
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1067
Summarized using gpt-4o-mini
Append: [MMAudio：高质量音频合成的新方法](https://arxiv.org/abs/2412.15322)
Token length: 1177
Summarized using gpt-4o-mini
Append: [SCOPE框架：优化长输出生成中的KV缓存](https://arxiv.org/abs/2412.13649)
append_entries: 2
Finish: 2024-12-23 06:11:28.901407
------------------------------------------------------
Started: 2024-12-23 09:01:08.313033
Existing_entries: 872
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1438
Summarized using gpt-4o-mini
Append: [通过离线强化学习提升大型语言模型的多步推理能力](https://arxiv.org/abs/2412.16145)
Token length: 1615
Summarized using gpt-4o-mini
Append: [MixLLM：一种新型混合精度量化方法提升大语言模型性能](https://arxiv.org/abs/2412.14590)
Token length: 1580
Summarized using gpt-4o-mini
Append: [基于清晰局部注意力机制的高效图像生成模型](https://arxiv.org/abs/2412.16112)
Token length: 1377
Summarized using gpt-4o-mini
Append: [提高自回归视觉生成效率的并行化方法](https://arxiv.org/abs/2412.15119)
append_entries: 4
Finish: 2024-12-23 09:01:40.452497
------------------------------------------------------
Started: 2024-12-23 12:13:07.807092
Existing_entries: 876
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1267
Summarized using gpt-4o-mini
Append: [Fietje：面向荷兰语的小型语言模型家族](https://arxiv.org/abs/2412.15450)
append_entries: 1
Finish: 2024-12-23 12:13:13.838785
------------------------------------------------------
Started: 2024-12-23 15:00:57.685434
Existing_entries: 877
Fetching from https://rsshub.app/huggingface/daily-papers
Summarization failed, append the original article
error: 'NoneType' object has no attribute 'group'. Line: 406.
Append: [LLMs Lost in Translation: M-ALERT uncovers Cross-Linguistic Safety Gaps](https://arxiv.org/abs/2412.15035)
Summarization failed, append the original article
error: 'NoneType' object has no attribute 'group'. Line: 406.
Append: [Sequence Matters: Harnessing Video Models in 3D Super-Resolution](https://arxiv.org/abs/2412.11525)
append_entries: 2
Finish: 2024-12-23 15:01:14.169790
------------------------------------------------------
Started: 2024-12-23 18:01:03.273868
Existing_entries: 879
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1361
Summarized using gpt-4o-mini
Append: [基于单幅图像生成高保真3D全身头像的创新研究](https://arxiv.org/abs/2412.14963)
append_entries: 1
Finish: 2024-12-23 18:01:08.986192
------------------------------------------------------
Started: 2024-12-23 21:00:51.725861
Existing_entries: 880
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 980
Summarized using gpt-4o-mini
Append: [多LLM摘要框架的研究与应用](https://arxiv.org/abs/2412.15487)
append_entries: 1
Finish: 2024-12-23 21:00:55.285386
------------------------------------------------------
Started: 2024-12-24 00:34:22.052618
Existing_entries: 881
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 752
Summarized using gpt-4o-mini
Append: [TRecViT：一种新型视频建模架构](https://arxiv.org/abs/2412.14294)
append_entries: 1
Finish: 2024-12-24 00:34:28.599581
------------------------------------------------------
Started: 2024-12-24 03:13:10.864391
Existing_entries: 882
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-24 03:13:11.049792
------------------------------------------------------
Started: 2024-12-24 06:00:57.878882
Existing_entries: 882
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1805
Summarized using gpt-4o-mini
Append: [自我演化训练在多模态推理中的应用与优化](https://arxiv.org/abs/2412.17451)
Token length: 1643
Summarized using gpt-4o-mini
Append: [自我改善框架B-STaR在复杂推理任务中的应用](https://arxiv.org/abs/2412.17256)
Token length: 1218
Summarized using gpt-4o-mini
Append: [RobustFT：一种增强大规模语言模型鲁棒性的新型监督微调框架](https://arxiv.org/abs/2412.14922)
Token length: 1363
Summarized using gpt-4o-mini
Append: [长上下文语言模型中示例选择对ICL性能的影响](https://arxiv.org/abs/2412.16926)
append_entries: 4
Finish: 2024-12-24 06:01:16.190581
------------------------------------------------------
Started: 2024-12-24 09:00:47.969610
Existing_entries: 886
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1316
Summarized using gpt-4o-mini
Append: [基于结果精炼的过程监督：解决复杂编程任务的新方法](https://arxiv.org/abs/2412.15118)
Token length: 1479
Summarized using gpt-4o-mini
Append: [提升大型语言模型推理能力的缓存增强方法](https://arxiv.org/abs/2412.17747)
Token length: 1902
Summarized using gpt-4o-mini
Append: [基于蒸馏解码的自回归模型一键生成方法](https://arxiv.org/abs/2412.17153)
Token length: 1293
Summarized using gpt-4o-mini
Append: [NILE框架：提升LLMs与人类意图对齐的内部一致性优化](https://arxiv.org/abs/2412.16686)
append_entries: 4
Finish: 2024-12-24 09:01:08.135937
------------------------------------------------------
Started: 2024-12-24 12:00:55.779494
Existing_entries: 890
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "Agent-SafetyBench：评估大型语言模型代理安全性的新基准",
  "short_summary": "提出Agent-SafetyBench基准，评估大型语言模型代理的安全性。",
  "summary": "本文介绍了Agent-SafetyBench，这是一种旨在评估大型语言模型(LLM)代理安全性的综合基准。该基准包含349个交互环境和2000个测试案例，针对8类安全风险进行评估，并涵盖10种常见的失败模式。我们对16个流行的LLM代理进行了评估，结果显示没有一个代理的安全评分超过60%，凸显了LLM代理在安全性方面面临的重大挑战。通过量化分析，我们识别出关键失败模式，并总结出现有LLM代理中的两个基本安全缺陷：缺乏稳健性和风险意识。此外，研究发现单靠防御性提示不足以解决这些安全问题，强调了需要更先进、稳健的策略以提升安全性。我们将Agent-SafetyBench发布在https:
  "keyword": [
    "语言模型",
    "安全性评估",
    "代理"
  ]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 310 (char 421). Line: 406.
Append: [Agent-SafetyBench: Evaluating the Safety of LLM Agents](https://arxiv.org/abs/2412.14470)
Token length: 1599
Summarized using gpt-4o-mini
Append: [Friends-MMC：多模态多方会话数据集及关键任务研究](https://arxiv.org/abs/2412.17295)
Token length: 1260
Summarized using gpt-4o-mini
Append: [解析生成式AI在教育中的教学行为注入](https://arxiv.org/abs/2412.16429)
Token length: 1761
Summarized using gpt-4o-mini
Append: [引入DRT-o1：长链思维在神经机器翻译中的应用](https://arxiv.org/abs/2412.17498)
Token length: 1097
Summarized using gpt-4o-mini
Append: [OpenAI o1模型系列的安全性与健壮性研究](https://arxiv.org/abs/2412.16720)
Token length: 1623
Summarized using gpt-4o-mini
Append: [高保真视频变分自编码器的创新与应用](https://arxiv.org/abs/2412.17805)
append_entries: 6
Finish: 2024-12-24 12:01:35.287148
------------------------------------------------------
Started: 2024-12-24 15:00:35.858122
Existing_entries: 896
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 902
Summarized using gpt-4o-mini
Append: [OpenAI的强化微调技术报告：OpenRFT的应用与挑战](https://arxiv.org/abs/2412.16849)
Token length: 1856
Summarized using gpt-4o-mini
Append: [PC Agent：通过人类认知转移提升AI工作能力](https://arxiv.org/abs/2412.17589)
append_entries: 2
Finish: 2024-12-24 15:00:49.977474
------------------------------------------------------
Started: 2024-12-24 18:01:07.972396
Existing_entries: 898
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1518
Summarized using gpt-4o-mini
Append: [ResearchTown: 基于大语言模型的科研社区仿真框架](https://arxiv.org/abs/2412.17767)
append_entries: 1
Finish: 2024-12-24 18:01:14.879207
------------------------------------------------------
Started: 2024-12-24 21:00:47.699650
Existing_entries: 899
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-24 21:00:47.880364
------------------------------------------------------
Started: 2024-12-25 00:33:48.864330
Existing_entries: 899
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-25 00:33:49.122584
------------------------------------------------------
Started: 2024-12-25 03:11:18.960431
Existing_entries: 899
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-25 03:11:19.208556
------------------------------------------------------
Started: 2024-12-25 06:00:48.322790
Existing_entries: 899
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1365
Summarized using gpt-4o-mini
Append: [SKETCH：一种增强检索-生成系统的新方法](https://arxiv.org/abs/2412.15443)
append_entries: 1
Finish: 2024-12-25 06:00:53.188353
------------------------------------------------------
Started: 2024-12-25 09:01:04.115297
Existing_entries: 900
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1582
Summarized using gpt-4o-mini
Append: [DiTCtrl：基于MM-DiT架构的无训练多提示视频生成方法](https://arxiv.org/abs/2412.18597)
Token length: 1364
Summarized using gpt-4o-mini
Append: [基于傅里叶位置嵌入的语言模型上下文长度扩展方法](https://arxiv.org/abs/2412.17739)
Token length: 1113
Summarized using gpt-4o-mini
Append: [ReMoE：可微分的混合专家模型架构](https://arxiv.org/abs/2412.14711)
Token length: 978
Summarized using gpt-4o-mini
Append: [DepthLab：基于图像扩散的深度数据填补模型](https://arxiv.org/abs/2412.18153)
append_entries: 4
Finish: 2024-12-25 09:01:38.679236
------------------------------------------------------
Started: 2024-12-25 12:12:07.576407
Existing_entries: 904
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 790
Summarized using gpt-4o-mini
Append: [评估策略影响LLM挑战难度的研究](https://arxiv.org/abs/2412.17758)
Token length: 1368
Summarized using gpt-4o-mini
Append: [3DGraphLLM：基于3D场景图的语言模型增强方法](https://arxiv.org/abs/2412.18450)
Token length: 1488
Summarized using gpt-4o-mini
Append: [PartGen：基于多视图扩散模型的3D对象分部生成方法](https://arxiv.org/abs/2412.18608)
append_entries: 3
Finish: 2024-12-25 12:12:26.301472
------------------------------------------------------
Started: 2024-12-25 15:00:54.756842
Existing_entries: 907
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-25 15:00:54.985527
------------------------------------------------------
Started: 2024-12-25 18:01:03.864248
Existing_entries: 907
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1244
Summarized using gpt-4o-mini
Append: [LE-MCTS：一种基于蒙特卡洛树搜索的语言模型集成框架](https://arxiv.org/abs/2412.15797)
append_entries: 1
Finish: 2024-12-25 18:01:09.263414
------------------------------------------------------
Started: 2024-12-25 21:00:45.494234
Existing_entries: 908
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1268
Summarized using gpt-4o-mini
Append: [MotiF：提升文本引导图像动画的视频生成方法](https://arxiv.org/abs/2412.16153)
append_entries: 1
Finish: 2024-12-25 21:00:49.701263
------------------------------------------------------
Started: 2024-12-26 00:33:54.395077
Existing_entries: 909
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1762
Summarized using gpt-4o-mini
Append: [多模态数据集审计：训练数据的规模、来源与限制](https://arxiv.org/abs/2412.17847)
append_entries: 1
Finish: 2024-12-26 00:34:00.794089
------------------------------------------------------
Started: 2024-12-26 03:12:54.658896
Existing_entries: 910
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-26 03:12:54.866790
------------------------------------------------------
Started: 2024-12-26 06:10:24.204342
Existing_entries: 910
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1017
Summarized using gpt-4o-mini
Append: [基于令牌预算的语言模型推理框架](https://arxiv.org/abs/2412.18547)
append_entries: 1
Finish: 2024-12-26 06:10:27.579516
------------------------------------------------------
Started: 2024-12-26 09:00:34.829259
Existing_entries: 911
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-26 09:00:35.053692
------------------------------------------------------
Started: 2024-12-26 12:00:51.843262
Existing_entries: 911
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-26 12:00:55.502814
------------------------------------------------------
Started: 2024-12-26 15:00:37.604934
Existing_entries: 911
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-26 15:00:37.827191
------------------------------------------------------
Started: 2024-12-26 18:00:58.132306
Existing_entries: 911
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1919
Summarized using gpt-4o-mini
Append: [PepTune: 多目标离散扩散模型在治疗肽优化中的应用](https://arxiv.org/abs/2412.17780)
append_entries: 1
Finish: 2024-12-26 18:01:05.119260
------------------------------------------------------
Started: 2024-12-26 21:00:47.107117
Existing_entries: 912
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1175
Summarized using gpt-4o-mini
Append: [WavePulse：实时分析电台直播内容的框架](https://arxiv.org/abs/2412.17998)
Token length: 1531
Summarized using gpt-4o-mini
Append: [高效无编码器视频语言理解方法的提出](https://arxiv.org/abs/2412.18609)
Token length: 1184
Summarized using gpt-4o-mini
Append: [集体蒙特卡罗树搜索：一种多模态学习模型的推理与学习方法](https://arxiv.org/abs/2412.18319)
append_entries: 3
Finish: 2024-12-26 21:01:09.326479
------------------------------------------------------
Started: 2024-12-27 00:34:05.767028
Existing_entries: 915
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1139
Summarized using gpt-4o-mini
Append: [强化同步语音转文字翻译研究的必要性与未来方向](https://arxiv.org/abs/2412.18495)
append_entries: 1
Finish: 2024-12-27 00:34:12.232292
------------------------------------------------------
Started: 2024-12-27 03:12:27.918880
Existing_entries: 916
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-27 03:12:28.130945
------------------------------------------------------
Started: 2024-12-27 06:00:51.086544
Existing_entries: 916
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1267
Summarized using gpt-4o-mini
Append: [VidTwin：高效视频自动编码器的新方法](https://arxiv.org/abs/2412.17726)
append_entries: 1
Finish: 2024-12-27 06:00:56.214619
------------------------------------------------------
Started: 2024-12-27 09:00:56.580608
Existing_entries: 917
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1059
Summarized using gpt-4o-mini
Append: [YuLan-Mini：高效预训练的大型语言模型](https://arxiv.org/abs/2412.17743)
append_entries: 1
Finish: 2024-12-27 09:01:00.881753
------------------------------------------------------
Started: 2024-12-27 12:00:53.165466
Existing_entries: 918
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1086
Summarized using gpt-4o-mini
Append: [基于要旨的上下文压缩方法在长文本处理中的应用研究](https://arxiv.org/abs/2412.17483)
append_entries: 1
Finish: 2024-12-27 12:01:00.325040
------------------------------------------------------
Started: 2024-12-27 15:00:42.123425
Existing_entries: 919
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1607
Summarized using gpt-4o-mini
Append: [Molar: 多模态大语言模型在序列推荐中的应用](https://arxiv.org/abs/2412.18176)
Token length: 1895
Summarized using gpt-4o-mini
Append: [MMFactory：面向复杂视觉任务的通用解决方案框架](https://arxiv.org/abs/2412.18072)
append_entries: 2
Finish: 2024-12-27 15:00:52.606311
------------------------------------------------------
Started: 2024-12-27 18:01:13.644065
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-27 18:01:13.817051
------------------------------------------------------
Started: 2024-12-27 21:00:37.374899
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-27 21:00:37.533634
------------------------------------------------------
Started: 2024-12-28 00:33:23.279065
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-28 00:33:23.515976
------------------------------------------------------
Started: 2024-12-28 03:10:11.876451
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-28 03:10:12.060821
------------------------------------------------------
Started: 2024-12-28 06:00:45.296717
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-28 06:00:45.527706
------------------------------------------------------
Started: 2024-12-28 09:01:04.226325
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-28 09:01:04.392593
------------------------------------------------------
Started: 2024-12-28 12:01:01.820971
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-28 12:01:02.029603
------------------------------------------------------
Started: 2024-12-28 15:00:43.407123
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-28 15:00:43.554734
------------------------------------------------------
Started: 2024-12-28 18:00:38.361326
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-28 18:00:38.533347
------------------------------------------------------
Started: 2024-12-28 21:00:45.656835
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-28 21:00:45.837211
------------------------------------------------------
Started: 2024-12-29 00:38:04.995478
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-29 00:38:05.187360
------------------------------------------------------
Started: 2024-12-29 03:17:59.061021
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-29 03:17:59.250417
------------------------------------------------------
Started: 2024-12-29 06:01:01.050339
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-29 06:01:01.271852
------------------------------------------------------
Started: 2024-12-29 09:00:48.932807
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-29 09:00:49.094302
------------------------------------------------------
Started: 2024-12-29 12:10:54.229806
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-29 12:10:54.452985
------------------------------------------------------
Started: 2024-12-29 15:00:42.852055
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-29 15:00:43.015273
------------------------------------------------------
Started: 2024-12-29 18:01:11.787924
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-29 18:01:12.092299
------------------------------------------------------
Started: 2024-12-29 21:00:39.367014
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-29 21:00:39.577131
------------------------------------------------------
Started: 2024-12-30 00:36:06.281385
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-30 00:36:06.515705
------------------------------------------------------
Started: 2024-12-30 03:15:10.866525
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-30 03:15:11.075331
------------------------------------------------------
Started: 2024-12-30 06:00:44.805579
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-30 06:00:44.937402
------------------------------------------------------
Started: 2024-12-30 09:01:07.108654
Existing_entries: 921
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1587
Summarized using gpt-4o-mini
Append: [SuperDiff: 高效组合预训练扩散模型的新方法](https://arxiv.org/abs/2412.17762)
Token length: 1097
Summarized using gpt-4o-mini
Append: [SBSFigures：一种用于图形问答的逐步合成数据集](https://arxiv.org/abs/2412.17606)
Token length: 1359
Summarized using gpt-4o-mini
Append: [基于视频扩散模型的零-shot 定制视频生成框架](https://arxiv.org/abs/2412.19645)
Token length: 1417
Summarized using gpt-4o-mini
Append: [任务偏好优化：提升多模态大语言模型的视觉理解能力](https://arxiv.org/abs/2412.19326)
Token length: 1491
Summarized using gpt-4o-mini
Append: [基于层次设计原则的自动图形设计组合方法LaDeCo](https://arxiv.org/abs/2412.19712)
Token length: 1235
Summarized using gpt-4o-mini
Append: [HuatuoGPT-o1：用于复杂推理的医学大语言模型](https://arxiv.org/abs/2412.18925)
Token length: 1236
Summarized using gpt-4o-mini
Append: [Orient Anything：单图像物体方向估计的创新模型](https://arxiv.org/abs/2412.18605)
append_entries: 7
Finish: 2024-12-30 09:01:49.992582
------------------------------------------------------
Started: 2024-12-30 12:12:44.979612
Existing_entries: 928
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 913
Summarized using gpt-4o-mini
Append: [提升大型语言模型下游任务表现的安全方法](https://arxiv.org/abs/2412.19512)
append_entries: 1
Finish: 2024-12-30 12:12:49.535057
------------------------------------------------------
Started: 2024-12-30 15:00:55.349327
Existing_entries: 929
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1148
Summarized using gpt-4o-mini
Append: [多模态学习中的下一个令牌预测框架综述](https://arxiv.org/abs/2412.18619)
append_entries: 1
Finish: 2024-12-30 15:01:00.593695
------------------------------------------------------
Started: 2024-12-30 18:00:57.974743
Existing_entries: 930
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 791
Summarized using gpt-4o-mini
Append: [1.58-bit FLUX：高效的文本到图像生成模型量化方法](https://arxiv.org/abs/2412.18653)
append_entries: 1
Finish: 2024-12-30 18:01:04.147482
------------------------------------------------------
Started: 2024-12-30 21:01:03.343695
Existing_entries: 931
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1307
Summarized using gpt-4o-mini
Append: [提高大型语言模型检索效率的属性图视图研究](https://arxiv.org/abs/2412.18702)
append_entries: 1
Finish: 2024-12-30 21:01:09.787035
------------------------------------------------------
Started: 2024-12-31 00:34:05.488050
Existing_entries: 932
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-31 00:34:05.671017
------------------------------------------------------
Started: 2024-12-31 03:11:37.410525
Existing_entries: 932
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-31 03:11:37.569921
------------------------------------------------------
Started: 2024-12-31 06:00:46.049188
Existing_entries: 932
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-31 06:00:46.236989
------------------------------------------------------
Started: 2024-12-31 09:00:37.637147
Existing_entries: 932
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1409
Summarized using gpt-4o-mini
Append: [自调用代码生成评估新任务与基准的发展](https://arxiv.org/abs/2412.21199)
Token length: 1351
Summarized using gpt-4o-mini
Append: [基于文本提示的4D生成与3D对象动画方法](https://arxiv.org/abs/2412.20422)
Token length: 832
Summarized using gpt-4o-mini
Append: [SWE-Gym: 软件工程代理训练环境的首次发布](https://arxiv.org/abs/2412.21139)
Token length: 1359
Summarized using gpt-4o-mini
Append: [通过解释性指令促进计算机视觉中的零-shot任务泛化](https://arxiv.org/abs/2412.18525)
Token length: 1279
Summarized using gpt-4o-mini
Append: [Dynasor：优化大型语言模型推理查询的动态计算系统](https://arxiv.org/abs/2412.20993)
Token length: 890
Summarized using gpt-4o-mini
Append: [TangoFlux：高效的文本到音频生成模型](https://arxiv.org/abs/2412.21037)
Json decode failed:
{
  "title": "OneKE：基于架构的知识提取系统",
  "keyword": ["知识提取", "多领域", "架构设计"],
  "short_summary": "OneKE是一个能够从网络和PDF书籍提取知识的系统。",
  "summary": "OneKE是一种经过容器化的架构引导知识提取系统，能够从网络和原始PDF书籍中提取知识，支持多个领域（如科学、新闻等）。本系统设计了多个代理和可配置知识库，帮助优化不同的提取场景。代理各自承担不同角色，而可配置知识库则优化架构配置、错误案例调试与修正，显著提高系统性能。通过在基准数据集上的实证评估，OneKE展示了其有效性，并通过案例研究展示了其在多领域任务中的适应能力，显示其广泛应用的潜力。此外，相关代码已经开源，访问链接为：https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 237 (char 358). Line: 406.
Append: [OneKE: A Dockerized Schema-Guided LLM Agent-based Knowledge Extraction System](https://arxiv.org/abs/2412.20005)
Json decode failed:
{
  "title": "多模态大型语言模型在医疗图像理解中的应用研究",
  "keyword": ["多模态语言模型", "医疗图像", "组合泛化"],
  "short_summary": "探讨多模态大型语言模型在医疗领域的组合泛化能力及数据集选择。",
  "summary": "多模态大型语言模型（MLLMs）在医疗领域展现出巨大的潜力，但在某些医疗领域的数据不足限制了其能力。本文研究了MLLMs如何通过组合泛化（CG）来理解新颖的医学图像，以指导数据集选择和多任务训练的优化。通过组建106个医学数据集形成Med-MAT，实验结果表明MLLMs能够利用CG理解未见过的医学图像，并且CG是多任务训练中观察到的一项主要泛化驱动因素。此外，研究还表明CG可以有效支持数据有限的数据集，并在不同基础架构上提供一致的表现，展现了其灵活性和广泛适用性。Med-MAT已公开供研究使用，网址为 https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 275 (char 408). Line: 406.
Append: [On the Compositional Generalization of Multimodal LLMs for Medical Imaging](https://arxiv.org/abs/2412.20070)
Token length: 915
Summarized using gpt-4o-mini
Append: [Edicho：基于扩散模型的无训练一致性图片编辑](https://arxiv.org/abs/2412.21079)
append_entries: 9
Finish: 2024-12-31 09:01:22.518143
------------------------------------------------------
Started: 2024-12-31 12:12:29.598978
Existing_entries: 941
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1793
Summarized using gpt-4o-mini
Append: [高效的语言适应：学习嵌入传播（LEP）方法的提出](https://arxiv.org/abs/2412.21140)
append_entries: 1
Finish: 2024-12-31 12:12:34.662149
------------------------------------------------------
Started: 2024-12-31 15:00:54.600302
Existing_entries: 942
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1128
Summarized using gpt-4o-mini
Append: [提升模型效率：应对推理中的过度思考问题](https://arxiv.org/abs/2412.21187)
Token length: 1418
Summarized using gpt-4o-mini
Append: [慢感知：提升视觉推理能力的新方法](https://arxiv.org/abs/2412.20631)
Token length: 1198
Summarized using gpt-4o-mini
Append: [PERSE：个性化可动画生成头像的方法](https://arxiv.org/abs/2412.21206)
append_entries: 3
Finish: 2024-12-31 15:01:17.550967
------------------------------------------------------
Started: 2024-12-31 18:00:46.800232
Existing_entries: 945
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-31 18:00:47.022551
------------------------------------------------------
Started: 2024-12-31 21:00:59.394590
Existing_entries: 945
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2024-12-31 21:00:59.570153
------------------------------------------------------
Started: 2025-01-01 00:38:30.952403
Existing_entries: 945
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-01 00:38:31.129036
------------------------------------------------------
Started: 2025-01-01 03:19:56.622511
Existing_entries: 945
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-01 03:19:56.864011
------------------------------------------------------
Started: 2025-01-01 06:00:52.290615
Existing_entries: 945
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-01 06:00:52.452764
------------------------------------------------------
Started: 2025-01-01 09:01:00.840982
Existing_entries: 945
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-01 09:01:01.076576
------------------------------------------------------
Started: 2025-01-01 12:00:45.759860
Existing_entries: 945
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-01 12:00:45.956974
------------------------------------------------------
Started: 2025-01-01 15:00:47.810119
Existing_entries: 945
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-01 15:00:47.979995
------------------------------------------------------
Started: 2025-01-01 18:00:43.221133
Existing_entries: 945
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-01 18:00:43.465241
------------------------------------------------------
Started: 2025-01-01 21:00:43.241458
Existing_entries: 945
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-01 21:00:43.429824
------------------------------------------------------
Started: 2025-01-02 00:33:51.681362
Existing_entries: 945
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-02 00:33:51.898179
------------------------------------------------------
Started: 2025-01-02 03:11:33.844186
Existing_entries: 945
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-02 03:11:34.074443
------------------------------------------------------
Started: 2025-01-02 06:00:47.782217
Existing_entries: 945
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-02 06:00:48.055811
------------------------------------------------------
Started: 2025-01-02 09:00:37.336341
Existing_entries: 945
Fetching from https://rsshub.app/huggingface/daily-papers
Summarization failed, append the original article
error: 'NoneType' object has no attribute 'group'. Line: 406.
Append: [OS-Genesis: Automating GUI Agent Trajectory Construction via Reverse Task Synthesis](https://arxiv.org/abs/2412.19723)
Summarization failed, append the original article
error: 'NoneType' object has no attribute 'group'. Line: 406.
Append: [Xmodel-2 Technical Report](https://arxiv.org/abs/2412.19638)
append_entries: 2
Finish: 2025-01-02 09:00:47.031126
------------------------------------------------------
Started: 2025-01-02 12:00:42.383428
Existing_entries: 947
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-02 12:00:42.595072
------------------------------------------------------
Started: 2025-01-02 15:00:40.720333
Existing_entries: 947
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-02 15:00:40.877897
------------------------------------------------------
Started: 2025-01-02 18:01:04.684159
Existing_entries: 947
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 876
Summarized using gpt-4o-mini
Append: [HunyuanProver：基于Hunyuan 7B的交互式定理证明模型](https://arxiv.org/abs/2412.20735)
append_entries: 1
Finish: 2025-01-02 18:01:11.407019
------------------------------------------------------
Started: 2025-01-02 21:00:36.318929
Existing_entries: 948
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-02 21:00:36.461348
------------------------------------------------------
Started: 2025-01-03 00:34:37.810327
Existing_entries: 948
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-03 00:34:38.099809
------------------------------------------------------
Started: 2025-01-03 03:12:55.476422
Existing_entries: 948
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1165
Summarized using gpt-4o-mini
Append: [多视觉传感器感知与推理基准的创新研究](https://arxiv.org/abs/2412.20750)
Token length: 1467
Summarized using gpt-4o-mini
Append: [基于VMix适配器的扩散模型美学提升研究](https://arxiv.org/abs/2412.20800)
append_entries: 2
Finish: 2025-01-03 03:13:05.447857
------------------------------------------------------
Started: 2025-01-03 06:00:58.658716
Existing_entries: 950
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1704
Summarized using gpt-4o-mini
Append: [基于半监督学习的细粒度动作识别方法SeFAR](https://arxiv.org/abs/2501.01245)
Token length: 1569
Summarized using gpt-4o-mini
Append: [提升视觉语言模型预训练效果的多模态教材语料库](https://arxiv.org/abs/2501.00958)
Token length: 1793
Summarized using gpt-4o-mini
Append: [CodeElo：一种新颖的代码生成基准测试评估LLMs能力](https://arxiv.org/abs/2501.01257)
Summarization failed, append the original article
error: 'NoneType' object has no attribute 'group'. Line: 406.
Append: [VideoRefer Suite: Advancing Spatial-Temporal Object Understanding with Video LLM](https://arxiv.org/abs/2501.00599)
Token length: 1362
Summarized using gpt-4o-mini
Append: [通过增强单元测试提升语言模型在代码生成中的表现](https://arxiv.org/abs/2501.01054)
Token length: 1385
Summarized using gpt-4o-mini
Append: [VideoAnydoor：高保真视频对象插入框架](https://arxiv.org/abs/2501.01427)
Token length: 1288
Summarized using gpt-4o-mini
Append: [推出 Android Agent Arena：评估移动 GUI 代理的新平台](https://arxiv.org/abs/2501.01149)
Token length: 1835
Summarized using gpt-4o-mini
Append: [基于多模态大语言模型的零样本图像安全判断研究](https://arxiv.org/abs/2501.00192)
Token length: 1670
Summarized using gpt-4o-mini
Append: [利用VA-VAE提升潜在扩散模型的生成效率和图像质量](https://arxiv.org/abs/2501.01423)
Token length: 1016
Summarized using gpt-4o-mini
Append: [Program-driven Self-Correction for Large Language Models](https://arxiv.org/abs/2501.01264)
append_entries: 10
Finish: 2025-01-03 06:03:25.076176
------------------------------------------------------
Started: 2025-01-03 09:00:44.287998
Existing_entries: 960
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1110
Summarized using gpt-4o-mini
Append: [SeedVR：一种新型扩散变换器用于视频恢复](https://arxiv.org/abs/2501.01320)
Token length: 1910
Summarized using gpt-4o-mini
Append: [MapEval：评估基础模型在地图推理中的能力](https://arxiv.org/abs/2501.00316)
Token length: 1435
Summarized using gpt-4o-mini
Append: [MapQaTor：提升地图问答数据集创建的便捷性](https://arxiv.org/abs/2412.21015)
Json decode failed:
{
  "title": "结构状态空间模型的局限性与偏极化解决方案",
  "keyword": ["状态空间模型", "偏见", "记忆"],
  "short_summary": "本文探讨了状态空间模型的偏见及其解决方案。",
  "summary": "结构状态空间模型（SSMs）作为变换器的替代方案，尽管在捕捉长序列依赖性方面表现出色，但其固有的较强近期偏见限制了模型对远程信息的回忆能力并引发鲁棒性问题。通过实证研究发现，更深的SSMs结构能够促进对长上下文的学习，但理论分析表明，随着深度增加，模型表现出不可避免的过平滑趋势。为解决近期偏见与过平滑之间的基本困境，本文提出对状态转换矩阵的两个通道进行极化，分别设置为零和一。实验表明，该极化技术可有效提升长距离标记的回忆准确率，并使SSMs能够更好地利用深层架构。所有源代码已在https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 262 (char 379). Line: 406.
Append: [Understanding and Mitigating Bottlenecks of State Space Models through the Lens of Recency and Over-smoothing](https://arxiv.org/abs/2501.00658)
append_entries: 4
Finish: 2025-01-03 09:01:08.701990
------------------------------------------------------
Started: 2025-01-03 12:00:51.727184
Existing_entries: 964
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-03 12:00:51.973998
------------------------------------------------------
Started: 2025-01-03 15:01:08.898579
Existing_entries: 964
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1296
Summarized using gpt-4o-mini
Append: [TAPE：一种改进的动态位置编码框架](https://arxiv.org/abs/2501.00712)
Token length: 1683
Summarized using gpt-4o-mini
Append: [LTX-Video：高效的变压器基础视频生成模型](https://arxiv.org/abs/2501.00103)
append_entries: 2
Finish: 2025-01-03 15:01:16.194917
------------------------------------------------------
Started: 2025-01-03 18:00:42.671255
Existing_entries: 966
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1193
Summarized using gpt-4o-mini
Append: [Nested Attention机制在个性化文本到图像生成中的应用](https://arxiv.org/abs/2501.01407)
Token length: 1667
Summarized using gpt-4o-mini
Append: [基于人口特征的时间序列生成模型PaD-TS](https://arxiv.org/abs/2501.00910)
append_entries: 2
Finish: 2025-01-03 18:00:49.905324
------------------------------------------------------
Started: 2025-01-03 21:00:44.463372
Existing_entries: 968
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1423
Summarized using gpt-4o-mini
Append: [MERV：多编码器视频表示方法提升视频理解能力](https://arxiv.org/abs/2501.01426)
append_entries: 1
Finish: 2025-01-03 21:00:50.252341
------------------------------------------------------
Started: 2025-01-04 00:33:41.271432
Existing_entries: 969
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-04 00:33:41.537820
------------------------------------------------------
Started: 2025-01-04 03:10:34.875959
Existing_entries: 969
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-04 03:10:35.086338
------------------------------------------------------
Started: 2025-01-04 06:01:01.490747
Existing_entries: 969
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-04 06:01:01.699245
------------------------------------------------------
Started: 2025-01-04 09:00:31.484020
Existing_entries: 969
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-04 09:00:31.755006
------------------------------------------------------
Started: 2025-01-04 12:01:00.805660
Existing_entries: 969
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-04 12:01:00.967114
------------------------------------------------------
Started: 2025-01-04 15:00:50.051193
Existing_entries: 969
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-04 15:00:50.241720
------------------------------------------------------
Started: 2025-01-04 18:00:46.356332
Existing_entries: 969
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-04 18:00:46.581572
------------------------------------------------------
Started: 2025-01-04 21:01:02.031167
Existing_entries: 969
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-04 21:01:02.285620
------------------------------------------------------
Started: 2025-01-05 00:38:01.206930
Existing_entries: 969
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-05 00:38:01.410041
------------------------------------------------------
Started: 2025-01-05 03:16:38.148679
Existing_entries: 969
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-05 03:16:38.478480
------------------------------------------------------
Started: 2025-01-05 06:01:06.104953
Existing_entries: 969
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-05 06:01:06.302995
------------------------------------------------------
Started: 2025-01-05 09:00:38.883131
Existing_entries: 969
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-05 09:00:39.124160
------------------------------------------------------
Started: 2025-01-05 12:00:50.462123
Existing_entries: 969
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-05 12:00:50.706316
------------------------------------------------------
Started: 2025-01-05 15:00:57.108235
Existing_entries: 969
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-05 15:00:57.276454
------------------------------------------------------
Started: 2025-01-05 18:01:00.483308
Existing_entries: 969
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-05 18:01:00.732957
------------------------------------------------------
Started: 2025-01-05 21:00:45.524740
Existing_entries: 969
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-05 21:00:45.853785
------------------------------------------------------
Started: 2025-01-06 00:36:37.720604
Existing_entries: 969
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-06 00:36:37.939975
------------------------------------------------------
Started: 2025-01-06 03:16:49.413001
Existing_entries: 969
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-06 03:16:49.623096
------------------------------------------------------
Started: 2025-01-06 06:00:45.757944
Existing_entries: 969
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-06 06:00:45.954189
------------------------------------------------------
Started: 2025-01-06 09:00:36.578391
Existing_entries: 969
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1017
Summarized using gpt-4o-mini
Append: [基于人类偏好的视觉生成模型对齐策略](https://arxiv.org/abs/2412.21059)
Token length: 1920
Summarized using gpt-4o-mini
Append: [BoxingGym：评估LLM科学代理的实验设计与模型发现能力的基准](https://arxiv.org/abs/2501.01540)
Token length: 1157
Summarized using gpt-4o-mini
Append: [基于序列表示的图生成预训练变换器模型G2PT研究](https://arxiv.org/abs/2501.01073)
Token length: 1353
Summarized using gpt-4o-mini
Append: [LUSIFER：一种无监督的多语言嵌入模型](https://arxiv.org/abs/2501.00874)
Token length: 1591
Summarized using gpt-4o-mini
Append: [EnerVerse：未来空间生成的综合框架](https://arxiv.org/abs/2501.01895)
Token length: 1114
Summarized using gpt-4o-mini
Append: [提升多模态对话系统的视觉与语音交互能力](https://arxiv.org/abs/2501.01957)
Token length: 1332
Summarized using gpt-4o-mini
Append: [Virgo：多模态大语言模型的慢思维推理系统](https://arxiv.org/abs/2501.01904)
append_entries: 7
Finish: 2025-01-06 09:01:15.815864
------------------------------------------------------
Started: 2025-01-06 12:13:15.665464
Existing_entries: 976
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-06 12:13:15.897534
------------------------------------------------------
Started: 2025-01-06 15:00:59.105596
Existing_entries: 976
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1149
Summarized using gpt-4o-mini
Append: [基于段落级直接偏好优化的多轮社交智能提升](https://arxiv.org/abs/2501.01821)
append_entries: 1
Finish: 2025-01-06 15:01:05.186585
------------------------------------------------------
Started: 2025-01-06 18:09:46.340250
Existing_entries: 977
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-06 18:09:46.587991
------------------------------------------------------
Started: 2025-01-06 21:00:42.436395
Existing_entries: 977
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-06 21:00:42.589944
------------------------------------------------------
Started: 2025-01-07 00:34:56.344799
Existing_entries: 977
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-07 00:34:56.555358
------------------------------------------------------
Started: 2025-01-07 03:14:56.921091
Existing_entries: 977
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1118
Summarized using gpt-4o-mini
Append: [TransPixar：一种用于生成RGBA视频的新方法](https://arxiv.org/abs/2501.03006)
append_entries: 1
Finish: 2025-01-07 03:15:02.661638
------------------------------------------------------
Started: 2025-01-07 06:10:35.060139
Existing_entries: 978
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-07 06:10:35.279849
------------------------------------------------------
Started: 2025-01-07 09:00:52.102528
Existing_entries: 978
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1552
Summarized using gpt-4o-mini
Append: [BoostStep：提升大型语言模型数学推理质量的新方法](https://arxiv.org/abs/2501.03226)
Token length: 1799
Summarized using gpt-4o-mini
Append: [Dispider：实时视频LLM交互的新范式](https://arxiv.org/abs/2501.03218)
Token length: 1712
Summarized using gpt-4o-mini
Append: [基于文本描述的静态图像到视频生成新框架](https://arxiv.org/abs/2501.03059)
Token length: 1770
Summarized using gpt-4o-mini
Append: [GS-DiT：提升4D视频生成的新框架](https://arxiv.org/abs/2501.02690)
Token length: 1760
Summarized using gpt-4o-mini
Append: [Samba ASR：基于Mamba架构的先进自动语音识别模型](https://arxiv.org/abs/2501.02832)
Token length: 1211
Summarized using gpt-4o-mini
Append: [Auto-RT: 强化学习框架提升大型语言模型安全漏洞探测能力](https://arxiv.org/abs/2501.01830)
Token length: 1207
Summarized using gpt-4o-mini
Append: [ToolHop: 评估多跳工具使用的新数据集](https://arxiv.org/abs/2501.02506)
Token length: 986
Summarized using gpt-4o-mini
Append: [测试时计算扩展的潜力与系统思维转变](https://arxiv.org/abs/2501.02497)
Token length: 1167
Summarized using gpt-4o-mini
Append: [基于变换器的视频生成自定义框架研究](https://arxiv.org/abs/2501.01790)
Token length: 1558
Summarized using gpt-4o-mini
Append: [METAGENE-1：用于疾病监测的元基因组基础模型](https://arxiv.org/abs/2501.02045)
Token length: 1394
Summarized using gpt-4o-mini
Append: [基于文本到视频模型的真实世界视频超分辨率方法](https://arxiv.org/abs/2501.02976)
Token length: 1186
Summarized using gpt-4o-mini
Append: [PGraphRAG：基于用户知识图谱的个性化文本生成框架](https://arxiv.org/abs/2501.02157)
append_entries: 12
Finish: 2025-01-07 09:01:59.481421
------------------------------------------------------
Started: 2025-01-07 12:12:58.685642
Existing_entries: 990
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-07 12:12:58.940885
------------------------------------------------------
Started: 2025-01-07 15:54:25.820386
Existing_entries: 990
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1511
Summarized using gpt-4o-mini
Append: [浮点量化训练对大规模语言模型性能的影响研究](https://arxiv.org/abs/2501.02423)
Token length: 1554
Summarized using gpt-4o-mini
Append: [DepthMaster：基于扩散模型的单步深度估计](https://arxiv.org/abs/2501.02576)
append_entries: 2
Finish: 2025-01-07 15:54:37.106251
------------------------------------------------------
Started: 2025-01-07 18:01:04.398787
Existing_entries: 992
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1351
Summarized using gpt-4o-mini
Append: [自动化幻灯片生成的SlidesBench基准与AutoPresent模型](https://arxiv.org/abs/2501.00912)
append_entries: 1
Finish: 2025-01-07 18:01:09.591118
------------------------------------------------------
Started: 2025-01-07 21:01:00.419052
Existing_entries: 993
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1061
Summarized using gpt-4o-mini
Append: [AutoConverter：提升视觉语言模型评估的自动化框架](https://arxiv.org/abs/2501.03225)
append_entries: 1
Finish: 2025-01-07 21:01:06.394742
------------------------------------------------------
Started: 2025-01-08 00:34:45.888523
Existing_entries: 994
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-08 00:34:46.144572
------------------------------------------------------
Started: 2025-01-08 03:12:32.935352
Existing_entries: 994
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-08 03:12:33.179644
------------------------------------------------------
Started: 2025-01-08 06:10:19.206285
Existing_entries: 994
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1409
Summarized using gpt-4o-mini
Append: [Diffusion as Shader：多任务视频生成的新方法](https://arxiv.org/abs/2501.03847)
Token length: 833
Summarized using gpt-4o-mini
Append: [Cosmos世界基础模型平台：为物理AI定制世界模型](https://arxiv.org/abs/2501.03575)
Token length: 1360
Summarized using gpt-4o-mini
Append: [MotionBench: 评估视频理解模型的细粒度运动理解能力](https://arxiv.org/abs/2501.02955)
Token length: 1175
Summarized using gpt-4o-mini
Append: [基于自注意力机制的面部表情编辑模型MagicFace](https://arxiv.org/abs/2501.02260)
Token length: 1149
Summarized using gpt-4o-mini
Append: [Magic Mirror：高质量动态身份保留视频生成框架](https://arxiv.org/abs/2501.03931)
Token length: 1711
Summarized using gpt-4o-mini
Append: [LLaVA-Mini：高效的多模态模型通过极大压缩视觉令牌](https://arxiv.org/abs/2501.03895)
append_entries: 6
Finish: 2025-01-08 06:10:55.245803
------------------------------------------------------
Started: 2025-01-08 09:00:52.460916
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-08 09:00:52.716119
------------------------------------------------------
Started: 2025-01-08 12:12:53.598229
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1436
Summarized using gpt-4o-mini
Append: [Dolphin：首个闭环开放式自动科研框架的研究](https://arxiv.org/abs/2501.03916)
Token length: 1220
Summarized using gpt-4o-mini
Append: [Sa2VA：首个统一的图像与视频密集基础理解模型](https://arxiv.org/abs/2501.04001)
Json decode failed:
{
  "title": "REINFORCE++: 一种改进的强化学习算法从人类反馈中优化大语言模型",
  "short_summary": "本文介绍了REINFORCE++，一种新型的人类反馈强化学习算法。",
  "summary": "强化学习从人类反馈（RLHF）成为对齐大语言模型与人类偏好的关键方法。本文提出了一种改进版的REINFORCE算法，称为REINFORCE++，该算法结合了近端策略优化（PPO）的优化技术，且不再需要评论网络。REINFORCE++具有三个主要目标：简单性、增强的训练稳定性和降低的计算开销。通过广泛的实证评估，研究表明，REINFORCE++在稳定性上优于组相对策略优化（GRPO），同时在计算效率上超过PPO，且保持相当的性能。该算法的实现代码可在https:
  "keyword": [
    "强化学习",
    "人类反馈",
    "算法优化"
  ]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 247 (char 356). Line: 406.
Append: [REINFORCE++: A Simple and Efficient Approach for Aligning Large Language Models](https://arxiv.org/abs/2501.03262)
append_entries: 3
Finish: 2025-01-08 12:13:15.898192
------------------------------------------------------
Started: 2025-01-08 15:00:47.792190
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1159
Summarized using gpt-4o-mini
Append: [PPTAgent：提升自动生成演示文稿的质量与一致性](https://arxiv.org/abs/2501.03936)
Token length: 1619
Summarized using gpt-4o-mini
Append: [MoDecGS：高效动态场景重建的3D高斯分裂框架](https://arxiv.org/abs/2501.03714)
append_entries: 2
Finish: 2025-01-08 15:01:04.601756
------------------------------------------------------
Started: 2025-01-08 18:01:08.619767
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1919
Summarized using gpt-4o-mini
Append: [将图感知关系推理融入Transformer架构](https://arxiv.org/abs/2501.02393)
Token length: 1202
Summarized using gpt-4o-mini
Append: [基于段落奖励模型的强化学习优化语言模型评估](https://arxiv.org/abs/2501.02790)
append_entries: 2
Finish: 2025-01-08 18:01:21.965759
------------------------------------------------------
Started: 2025-01-08 21:00:48.214047
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-08 21:00:48.387461
------------------------------------------------------
Started: 2025-01-09 00:34:36.140075
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-09 00:34:36.334239
------------------------------------------------------
Started: 2025-01-09 03:29:47.628176
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-09 03:29:47.798727
------------------------------------------------------
Started: 2025-01-09 06:00:40.212888
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1070
Summarized using gpt-4o-mini
Append: [openomni: 开放式全模态学习与实时情感语音生成的新方法](https://arxiv.org/abs/2501.04561)
Token length: 1770
Summarized using gpt-4o-mini
Append: [文本引导图像生成模型的源头识别任务及其解决方案](https://arxiv.org/abs/2501.02376)
append_entries: 2
Finish: 2025-01-09 06:00:48.408906
------------------------------------------------------
Started: 2025-01-09 09:00:43.637221
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 928
Summarized using gpt-4o-mini
Append: [InfiGUIAgent：提升图形用户界面自动化的多模态语言模型代理](https://arxiv.org/abs/2501.04575)
Token length: 937
Summarized using gpt-4o-mini
Append: [Meta链式思维框架：提升人工智能推理能力](https://arxiv.org/abs/2501.04682)
Token length: 1553
Summarized using gpt-4o-mini
Append: [Agent Laboratory：加速科学发现的自主研究框架](https://arxiv.org/abs/2501.04227)
Token length: 1488
Summarized using gpt-4o-mini
Append: [rStar-Math：小型语言模型在数学推理能力上的突破](https://arxiv.org/abs/2501.04519)
Token length: 1445
Summarized using gpt-4o-mini
Append: [Generation Augmented Retrieval (GeAR)方法在文档检索中的应用](https://arxiv.org/abs/2501.02772)
append_entries: 5
Finish: 2025-01-09 09:01:10.806843
------------------------------------------------------
Started: 2025-01-09 12:12:47.624741
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1652
Summarized using gpt-4o-mini
Append: [基于特征树的代码生成框架提升LLM性能](https://arxiv.org/abs/2501.04694)
Token length: 833
Summarized using gpt-4o-mini
Append: [突破细粒度3D生成的创新系统](https://arxiv.org/abs/2501.04144)
Token length: 1241
Summarized using gpt-4o-mini
Append: [SPAR3D: 高效的单图像三维物体重建方法](https://arxiv.org/abs/2501.04689)
Token length: 961
Summarized using gpt-4o-mini
Append: [大型语言模型在科学研究中的变革性应用](https://arxiv.org/abs/2501.04306)
Token length: 1220
Summarized using gpt-4o-mini
Append: [DPO-Kernels：提升大语言模型对齐的创新方法](https://arxiv.org/abs/2501.03271)
Token length: 1568
Summarized using gpt-4o-mini
Append: [提升多模态数学推理的高质量CoT训练数据](https://arxiv.org/abs/2501.04686)
append_entries: 6
Finish: 2025-01-09 12:13:29.741591
------------------------------------------------------
Started: 2025-01-09 15:01:01.531350
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-09 15:01:01.713080
------------------------------------------------------
Started: 2025-01-09 18:01:13.478447
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1061
Summarized using gpt-4o-mini
Append: [提升检索增强生成应用的通用性与效率](https://arxiv.org/abs/2501.04652)
append_entries: 1
Finish: 2025-01-09 18:01:18.541020
------------------------------------------------------
Started: 2025-01-09 21:00:43.497015
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-09 21:00:43.640783
------------------------------------------------------
Started: 2025-01-10 00:35:28.171752
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-10 00:35:28.368855
------------------------------------------------------
Started: 2025-01-10 03:15:31.676994
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-10 03:15:31.874547
------------------------------------------------------
Started: 2025-01-10 06:10:27.480055
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1350
Summarized using gpt-4o-mini
Append: [Search-o1: 提升大型推理模型的知识检索与生成能力](https://arxiv.org/abs/2501.05366)
append_entries: 1
Finish: 2025-01-10 06:10:33.396129
------------------------------------------------------
Started: 2025-01-10 09:01:03.046820
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1269
Summarized using gpt-4o-mini
Append: [VAR模型的计算效率研究与低秩近似优化](https://arxiv.org/abs/2501.04377)
Token length: 1781
Summarized using gpt-4o-mini
Append: [优化私有推理的非线性解码器架构](https://arxiv.org/abs/2501.03489)
Token length: 956
Summarized using gpt-4o-mini
Append: [基于视频的自回归预训练研究：Toto模型的探索](https://arxiv.org/abs/2501.05453)
Token length: 1016
Summarized using gpt-4o-mini
Append: [简化现代GAN训练：R3GAN的提出与优势](https://arxiv.org/abs/2501.05441)
append_entries: 4
Finish: 2025-01-10 09:01:22.915382
------------------------------------------------------
Started: 2025-01-10 12:12:43.271845
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1618
Summarized using gpt-4o-mini
Append: [DriveBench：评估视觉语言模型在自动驾驶中的可靠性](https://arxiv.org/abs/2501.04003)
append_entries: 1
Finish: 2025-01-10 12:12:47.919317
------------------------------------------------------
Started: 2025-01-10 15:00:42.469614
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1594
Summarized using gpt-4o-mini
Append: [多语言视觉语言模型的训练策略研究](https://arxiv.org/abs/2501.05122)
Json decode failed:
{
  "title": "历史土耳其语自然语言处理基础资源与模型的介绍",
  "keyword": ["历史土耳其语", "命名实体识别", "数据集"],
  "short_summary": "本文介绍历史土耳其语的NLP基础资源和模型，包括数据集和实验结果。",
  "summary": "本文介绍了历史土耳其语自然语言处理（NLP）的基础资源和模型，填补了该领域在计算语言学中的空白。我们推出了首个命名实体识别（NER）数据集HisTR和第一个通用依赖树库OTA-BOUN，适用于历史土耳其语，并使用这些数据集训练了基于变换器的模型，以完成命名实体识别、依赖分析和词性标注任务。此外，我们还推出了奥斯曼文本语料库（OTC），这是一个涵盖多个历史时期的转写历史土耳其语文本的清晰语料库。实验结果表明，在历史土耳其语的计算分析中取得了显著的改进，在理解历史语言结构的任务中表现出良好的效果，同时也突显了诸如领域适应和语言时间变化等现存挑战。我们提供的所有资源和模型均可在 https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 311 (char 447). Line: 406.
Append: [Building Foundations for Natural Language Processing of Historical Turkish: Resources and Models](https://arxiv.org/abs/2501.04828)
append_entries: 2
Finish: 2025-01-10 15:00:50.342963
------------------------------------------------------
Started: 2025-01-10 18:01:09.390462
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-10 18:01:09.545808
------------------------------------------------------
Started: 2025-01-10 21:01:05.448606
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 694
Summarized using gpt-4o-mini
Append: [提升大型语言模型的人性化进展研究](https://arxiv.org/abs/2501.05032)
Token length: 1583
Summarized using gpt-4o-mini
Append: [SWE-Fixer: 开源大型语言模型解决GitHub软件工程问题](https://arxiv.org/abs/2501.05040)
append_entries: 2
Finish: 2025-01-10 21:01:13.802237
------------------------------------------------------
Started: 2025-01-11 00:34:33.305114
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-11 00:34:33.456961
------------------------------------------------------
Started: 2025-01-11 03:13:09.461064
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-11 03:13:09.699125
------------------------------------------------------
Started: 2025-01-11 06:00:56.311719
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-11 06:00:56.560930
------------------------------------------------------
Started: 2025-01-11 09:00:39.005390
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-11 09:00:39.197955
------------------------------------------------------
Started: 2025-01-11 12:11:06.279441
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-11 12:11:06.568559
------------------------------------------------------
Started: 2025-01-11 15:00:43.362386
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-11 15:00:43.497603
------------------------------------------------------
Started: 2025-01-11 18:00:45.917417
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-11 18:00:46.135465
------------------------------------------------------
Started: 2025-01-11 21:00:43.330741
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-11 21:00:43.615400
------------------------------------------------------
Started: 2025-01-12 00:38:28.500623
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-12 00:38:28.675058
------------------------------------------------------
Started: 2025-01-12 03:19:04.508058
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-12 03:19:04.751835
------------------------------------------------------
Started: 2025-01-12 06:00:50.296404
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-12 06:00:50.453462
------------------------------------------------------
Started: 2025-01-12 09:00:51.986255
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-12 09:00:52.224278
------------------------------------------------------
Started: 2025-01-12 12:11:03.816052
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-12 12:11:04.000575
------------------------------------------------------
Started: 2025-01-12 15:00:37.103823
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-12 15:00:37.256289
------------------------------------------------------
Started: 2025-01-12 18:00:42.428187
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-12 18:00:42.585269
------------------------------------------------------
Started: 2025-01-12 21:00:35.295842
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-12 21:00:35.533119
------------------------------------------------------
Started: 2025-01-13 00:37:29.962664
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-13 00:37:30.155305
------------------------------------------------------
Started: 2025-01-13 03:17:47.671293
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-13 03:17:47.923197
------------------------------------------------------
Started: 2025-01-13 06:11:16.269881
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-13 06:11:16.503642
------------------------------------------------------
Started: 2025-01-13 09:00:45.253607
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1089
Summarized using gpt-4o-mini
Append: [基于JPEG图像的视觉大型语言模型安全性测试新方法](https://arxiv.org/abs/2501.05542)
Token length: 1166
Summarized using gpt-4o-mini
Append: [多智能体语言模型的自我改进与专业化研究](https://arxiv.org/abs/2501.05707)
Token length: 1536
Summarized using gpt-4o-mini
Append: [面向机器人操控的新型对象中心表征方法](https://arxiv.org/abs/2501.03841)
Token length: 1916
Summarized using gpt-4o-mini
Append: [推动视觉推理：一个新的多步骤框架与基准](https://arxiv.org/abs/2501.06186)
Token length: 1473
Summarized using gpt-4o-mini
Append: [VideoRAG：动态视频检索与生成的创新框架](https://arxiv.org/abs/2501.05874)
Token length: 1202
Summarized using gpt-4o-mini
Append: [SCRIT：自我进化的语言模型批评框架](https://arxiv.org/abs/2501.05727)
append_entries: 6
Finish: 2025-01-13 09:01:24.952873
------------------------------------------------------
Started: 2025-01-13 12:13:53.713437
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1700
Summarized using gpt-4o-mini
Append: [ConceptMaster：多概念视频定制中的身份解耦框架](https://arxiv.org/abs/2501.04698)
Token length: 1544
Summarized using gpt-4o-mini
Append: [Video Alchemist：多主体开放集视频个性化合成的新方法](https://arxiv.org/abs/2501.06187)
Token length: 1893
Summarized using gpt-4o-mini
Append: [OVO-Bench: 进阶在线视频理解能力评估基准](https://arxiv.org/abs/2501.05510)
Token length: 1512
Summarized using gpt-4o-mini
Append: [ReFocus：提升多模态大语言模型的结构化图像理解能力](https://arxiv.org/abs/2501.05452)
append_entries: 4
Finish: 2025-01-13 12:14:16.969342
------------------------------------------------------
Started: 2025-01-13 15:00:48.479674
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-13 15:00:48.774410
------------------------------------------------------
Started: 2025-01-13 18:00:54.703473
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-13 18:00:54.905239
------------------------------------------------------
Started: 2025-01-13 21:00:41.223238
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-13 21:00:41.386532
------------------------------------------------------
Started: 2025-01-14 00:33:03.292109
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1338
Summarized using gpt-4o-mini
Append: [FINDAP：金融领域的大型语言模型领域适应后训练](https://arxiv.org/abs/2501.04961)
append_entries: 1
Finish: 2025-01-14 00:33:16.951600
------------------------------------------------------
Started: 2025-01-14 03:00:40.229037
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-14 03:00:40.463288
------------------------------------------------------
Started: 2025-01-14 06:00:52.086817
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1357
Summarized using gpt-4o-mini
Append: [Migician：首个多图像精准定位模型及评估基准](https://arxiv.org/abs/2501.05767)
Token length: 1363
Summarized using gpt-4o-mini
Append: [生成式人工智能在传统动画制作中的变革](https://arxiv.org/abs/2501.06250)
append_entries: 2
Finish: 2025-01-14 06:01:06.794737
------------------------------------------------------
Started: 2025-01-14 09:01:05.794157
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1113
Summarized using gpt-4o-mini
Append: [长时序叙事生成的烹饪视频数据集与改进方法](https://arxiv.org/abs/2501.06173)
Token length: 828
Summarized using gpt-4o-mini
Append: [WebWalkerQA: 一种评估LLM网络遍历能力的新基准](https://arxiv.org/abs/2501.07572)
Token length: 1433
Summarized using gpt-4o-mini
Append: [ChemAgent：提升大语言模型在化学推理中的表现](https://arxiv.org/abs/2501.06590)
Token length: 1891
Summarized using gpt-4o-mini
Append: [MinMo: 多模态大型语言模型实现无缝语音交互](https://arxiv.org/abs/2501.06282)
Json decode failed:
{
  "title": "自适应大型语言模型的新框架",
  "short_summary": "提出一种新框架，实现大型语言模型的实时自适应。",
  "summary": "本文介绍了一种新颖的自适应框架\implname，旨在解决传统微调方法的计算密集性和适应性不足的问题。该框架通过实时选择性调整权重矩阵的单一组件，能够高效适应未见任务。\implname在推理过程中使用双通机制：首先，调度系统识别任务属性，然后结合通过强化学习训练的任务特定“专家”向量，以实现针对性行为。实验证明，\implname在参数更少和效率更高的情况下，优于当前广泛使用的方法，如LoRA。该框架在不同的LLM架构和模态中展示了其多样性，特别是在视觉语言任务中。总体而言，\implname代表了一个重要的进步，为增强LLM的适应性和任务特定性能提供了可扩展、高效的解决方案，推动了真正动态的自组织AI系统的发展。",
  "keyword": ["自适应", "大型语言模型", "强化学习"]
}Summarization failed, append the original article
error: Invalid \escape: line 4 column 30 (char 105). Line: 406.
Append: [$\text{Transformer}^2$: Self-adaptive LLMs](https://arxiv.org/abs/2501.06252)
Token length: 1906
Summarized using gpt-4o-mini
Append: [提升大型语言模型推理流程监控的过程奖励模型研究](https://arxiv.org/abs/2501.07301)
Token length: 1284
Summarized using gpt-4o-mini
Append: [推理时间扩展对大型语言模型医学推理能力的影响](https://arxiv.org/abs/2501.06458)
Token length: 1241
Summarized using gpt-4o-mini
Append: [Tensor Product Attention：提高语言模型输入序列处理效率的新机制](https://arxiv.org/abs/2501.06425)
Token length: 857
Summarized using gpt-4o-mini
Append: [uCO3D：新型3D深度学习和生成AI对象数据集](https://arxiv.org/abs/2501.07574)
append_entries: 9
Finish: 2025-01-14 09:01:50.916172
------------------------------------------------------
Started: 2025-01-14 12:00:56.234618
Existing_entries: 1009
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-14 12:00:56.457197
------------------------------------------------------
Started: 2025-01-14 15:00:44.349033
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1807
Summarized using gpt-4o-mini
Append: [针对大语言模型训练的梯度尖峰问题及其优化策略](https://arxiv.org/abs/2501.06842)
Token length: 1553
Summarized using gpt-4o-mini
Append: [构建开放的生物医学视觉语言模型数据集BIOMEDICA](https://arxiv.org/abs/2501.07171)
append_entries: 2
Finish: 2025-01-14 15:00:56.610873
------------------------------------------------------
Started: 2025-01-14 18:00:51.145426
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1240
Summarized using gpt-4o-mini
Append: [基于Mimic Score的数据选择框架提升模型训练效果](https://arxiv.org/abs/2501.06708)
append_entries: 1
Finish: 2025-01-14 18:00:56.885364
------------------------------------------------------
Started: 2025-01-14 21:00:58.420170
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-14 21:00:58.620520
------------------------------------------------------
Started: 2025-01-15 00:34:01.494422
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-15 00:34:01.691146
------------------------------------------------------
Started: 2025-01-15 03:08:47.923217
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-15 03:08:48.167347
------------------------------------------------------
Started: 2025-01-15 06:00:56.634886
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1658
Summarized using gpt-4o-mini
Append: [FramePainter: 高效的图像到视频生成用于交互式图像编辑](https://arxiv.org/abs/2501.08225)
Token length: 751
Summarized using gpt-4o-mini
Append: [MangaNinjia：基于扩散模型的参考引导线艺术上色](https://arxiv.org/abs/2501.08332)
Token length: 955
Summarized using gpt-4o-mini
Append: [基于对抗后训练的实时视频生成模型Seaweed-APT](https://arxiv.org/abs/2501.08316)
Token length: 1509
Summarized using gpt-4o-mini
Append: [InstructCell：提高单细胞RNA测序分析的智能助手](https://arxiv.org/abs/2501.08187)
Json decode failed:
{
  "title": "推出MiniMax-01系列：超长上下文处理的前沿模型",
  "keyword": ["MiniMax-01", "长上下文", "模型性能"],
  "short_summary": "MiniMax-01系列模型在处理长上下文方面表现突出，并提供卓越的性能。",
  "summary": "MiniMax-01系列包括MiniMax-Text-01和MiniMax-VL-01，具有与顶尖模型相媲美乃至更强的长上下文处理能力。核心技术为闪电注意力和高效的扩展性，结合了混合专家(MoE)架构，形成一个拥有32个专家和4560亿总参数的模型，在每个token上激活459亿参数。我们开发了优化的并行策略及高效的计算-通信重叠技术，确保在训练和推理中的高效性，能够处理数亿token的上下文。MiniMax-Text-01的上下文窗口在训练时可达100万token，推理时可外推至400万token，且成本可控。MiniMax-VL-01则通过5120亿视觉-语言token的持续训练建立，实验结果表明我们的模型在标准和内部基准测试上，与最高性能的GPT-4o和Claude-3.5-Sonnet表现相当，同时能够支持20-32倍更长的上下文窗口。MiniMax-01系列现已公开发布，详情见https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 420 (char 568). Line: 406.
Append: [MiniMax-01: Scaling Foundation Models with Lightning Attention](https://arxiv.org/abs/2501.08313)
append_entries: 5
Finish: 2025-01-15 06:01:16.607957
------------------------------------------------------
Started: 2025-01-15 09:00:47.997691
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1275
Summarized using gpt-4o-mini
Append: [OpenCSG中文语料库：提升中文LLM性能的高质量数据集](https://arxiv.org/abs/2501.08197)
Json decode failed:
{
  "title": "评估大语言模型在文本总结中的有效性与可靠性",
  "short_summary": "研究探讨大语言模型在解读文本数据中的可靠性，强调人类评估的重要性。",
  "summary": "随着大语言模型（LLMs）技术的快速发展，它们在处理和总结非结构化文本数据方面展现出卓越的能力。本研究探讨了LLMs是否能够准确代表开放式数据集（如调查反馈）中的观点。尽管LLMs能生成类似人类的总结，但输出可能与原始内容存在偏差，从而影响决策的有效性。本研究利用Anthropic的Claude模型生成主题总结，并采用Amazon的Titan Express、Nova Pro和Meta的Llama作为评判模型，同时与人类评估进行比较。通过使用Cohen"s kappa、Spearman"s rho和Krippendorff"s alpha等方法验证了LLMs作为评估模型的有效性，发现其在可扩展性上与人类评估可比，然而人类在捕捉细微、特定背景的差异上仍具优势。本研究不仅丰富了AI辅助文本分析的知识体系，且讨论了限制和未来研究的建议，强调在不同背景和用例中推广LLM评判模型时需要谨慎考虑。",
  "keyword": ["大语言模型", "文本总结", "评估"]
}Summarization failed, append the original article
error: Expecting ',' delimiter: line 4 column 244 (char 337). Line: 406.
Append: [Potential and Perils of Large Language Models as Judges of Unstructured Textual Data](https://arxiv.org/abs/2501.08167)
Token length: 1261
Summarized using gpt-4o-mini
Append: [Tarsier2: 新一代视频语言模型的突破性进展](https://arxiv.org/abs/2501.07888)
Token length: 1675
Summarized using gpt-4o-mini
Append: [PokerBench：评估大型语言模型扑克能力的新基准](https://arxiv.org/abs/2501.08328)
Token length: 1278
Summarized using gpt-4o-mini
Append: [TA-TiTok：高效的文本感知一维图像标记器](https://arxiv.org/abs/2501.07730)
Token length: 1438
Summarized using gpt-4o-mini
Append: [HALoGEN：生成模型幻觉评估基准](https://arxiv.org/abs/2501.08292)
append_entries: 6
Finish: 2025-01-15 09:01:13.614474
------------------------------------------------------
Started: 2025-01-15 12:00:50.094121
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-15 12:00:50.325405
------------------------------------------------------
Started: 2025-01-15 15:00:52.399489
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1079
Summarized using gpt-4o-mini
Append: [Omni-RGPT: 跨区域理解的多模态大语言模型](https://arxiv.org/abs/2501.08326)
Token length: 1201
Summarized using gpt-4o-mini
Append: [分析填充标记在图像生成中的影响](https://arxiv.org/abs/2501.06751)
Token length: 1340
Summarized using gpt-4o-mini
Append: [优化大型语言模型特征描述的自动化方法](https://arxiv.org/abs/2501.08319)
Json decode failed:
{
  "title": "AfriHate：15种非洲语言的仇恨言论与滥用语言数据集",
  "keyword": ["仇恨言论", "数据集", "非洲语言"],
  "short_summary": "AfriHate项目提供15种非洲语言的仇恨言论数据集，旨在改善言论监控。",
  "summary": "AfriHate是一个包括15种非洲语言的多语言仇恨言论和滥用语言数据集的项目，旨在促进对仇恨言论的理解、识别和管理。该项目揭示了全球南方地区在言论监管中面临的挑战，特别是由于缺乏高质量的本地语言数据和当地社区参与的缺失而导致的监管不足与审查。数据集中每一实例均由熟悉当地文化的母语者注释，以提高注释质量。同时，文章展示了构建这些数据集所面临的挑战，并提供了不同分类基准结果，包括使用与不使用大型语言模型的比较。此数据集及其注释和相关词汇在 https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 242 (char 385). Line: 406.
Append: [AfriHate: A Multilingual Collection of Hate Speech and Abusive Language Datasets for African Languages](https://arxiv.org/abs/2501.08284)
append_entries: 4
Finish: 2025-01-15 15:01:15.898648
------------------------------------------------------
Started: 2025-01-15 18:01:20.875660
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1769
Summarized using gpt-4o-mini
Append: [基于FLUX的深度驱动解耦实例合成方法3DIS-FLUX](https://arxiv.org/abs/2501.05131)
Json decode failed:
{
  "title": "图基偏好递归语言模型的探索性优化及其在科学发现中的应用",
  "keyword": ["图推理", "符号抽象", "知识图谱"],
  "short_summary": "介绍了Graph-PReFLexOR框架，实现图推理与动态领域知识扩展。",
  "summary": "本文介绍了Graph-PReFLexOR（图基偏好递归语言模型）的框架，结合图推理和符号抽象，以动态扩展领域知识。该框架从强化学习中获得灵感，将推理定义为结构化映射，任务生成知识图谱和抽象模式，最终得出成果。核心思想借鉴范畴理论，通过节点编码概念，边描述关系，从而支持层次推理和自适应学习。此外，提出的"知识花园生长"策略促进跨领域的洞察整合，实现了学科间的联结。3亿参数的Graph-PReFLexOR模型展示了其在推理深度和适应性方面的优越表现，展现了透明且多学科的AI驱动发现的潜力，为普遍自主推理解决方案奠定了基础。"
}Summarization failed, append the original article
error: Expecting ',' delimiter: line 5 column 167 (char 307). Line: 406.
Append: [In-situ graph reasoning and knowledge expansion using Graph-PReFLexOR](https://arxiv.org/abs/2501.08120)
append_entries: 2
Finish: 2025-01-15 18:01:33.493795
------------------------------------------------------
Started: 2025-01-15 21:00:42.362135
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-15 21:00:42.586056
------------------------------------------------------
Started: 2025-01-16 00:33:48.430985
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1631
Summarized using gpt-4o-mini
Append: [基于合成训练信号的跨模态图像匹配框架](https://arxiv.org/abs/2501.07556)
append_entries: 1
Finish: 2025-01-16 00:34:12.996014
------------------------------------------------------
Started: 2025-01-16 03:08:51.712036
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-16 03:08:51.976717
------------------------------------------------------
Started: 2025-01-16 06:00:51.087864
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-16 06:00:51.329451
------------------------------------------------------
Started: 2025-01-16 09:00:52.461454
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 919
Summarized using gpt-4o-mini
Append: [多模态大语言模型在艺术美学评估中的推理能力研究](https://arxiv.org/abs/2501.09012)
Token length: 1830
Summarized using gpt-4o-mini
Append: [CityDreamer4D：生成真实感4D城市的创新模型](https://arxiv.org/abs/2501.08983)
Token length: 1505
Summarized using gpt-4o-mini
Append: [MMDocIR: 新多模态文档检索基准的建立与分析](https://arxiv.org/abs/2501.08828)
Token length: 1443
Summarized using gpt-4o-mini
Append: [RepVideo：增强文本到视频扩散模型的表示框架](https://arxiv.org/abs/2501.08994)
Token length: 1578
Summarized using gpt-4o-mini
Append: [Ouroboros-Diffusion：一种增强视频一致性的去噪框架](https://arxiv.org/abs/2501.09019)
Token length: 1696
Summarized using gpt-4o-mini
Append: [XMusic：一种通用的情感可控符号音乐生成框架](https://arxiv.org/abs/2501.08809)
append_entries: 6
Finish: 2025-01-16 09:01:37.008158
------------------------------------------------------
Started: 2025-01-16 12:12:18.916043
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1698
Summarized using gpt-4o-mini
Append: [AI大语言模型训练的版权争议及其影响](https://arxiv.org/abs/2501.08365)
Token length: 1479
Summarized using gpt-4o-mini
Append: [利用可信的机器学习模型实现安全计算](https://arxiv.org/abs/2501.08970)
Token length: 1609
Summarized using gpt-4o-mini
Append: [参数反转图像金字塔网络（PIIP）：高效多尺度视觉感知方法](https://arxiv.org/abs/2501.07783)
append_entries: 3
Finish: 2025-01-16 12:12:36.189944
------------------------------------------------------
Started: 2025-01-16 15:00:55.420672
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-16 15:00:55.801116
------------------------------------------------------
Started: 2025-01-16 18:00:50.560495
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-16 18:00:50.803503
------------------------------------------------------
Started: 2025-01-16 21:00:47.211084
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1525
Summarized using gpt-4o-mini
Append: [FuSe：多模态传感器的机器人操作新方法](https://arxiv.org/abs/2501.04693)
Token length: 1555
Summarized using gpt-4o-mini
Append: [MINIMA：多模态图像匹配统一框架](https://arxiv.org/abs/2412.19412)
append_entries: 2
Finish: 2025-01-16 21:01:02.212588
------------------------------------------------------
Started: 2025-01-17 00:33:21.597464
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-17 00:33:21.829291
------------------------------------------------------
Started: 2025-01-17 03:09:44.255920
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-17 03:09:44.520667
------------------------------------------------------
Started: 2025-01-17 06:00:52.825917
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-17 06:00:53.075916
------------------------------------------------------
Started: 2025-01-17 09:00:51.276653
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1072
Summarized using gpt-4o-mini
Append: [OmniThink：提高机器写作知识密度的框架](https://arxiv.org/abs/2501.09751)
Token length: 1905
Summarized using gpt-4o-mini
Append: [探索在线医疗咨询中询问与诊断的关系](https://arxiv.org/abs/2501.09484)
Token length: 1195
Summarized using gpt-4o-mini
Append: [SynthLight：基于扩散模型的人物肖像重照明](https://arxiv.org/abs/2501.09756)
Token length: 1401
Summarized using gpt-4o-mini
Append: [基于频率空间的机器人动作序列标记化方法](https://arxiv.org/abs/2501.09747)
Json decode failed:
{
  "title": "AnyStory：个性化多主体图像生成的统一方法",
  "short_summary": "AnyStory提出了一种高保真个性化多主体图像生成的新方法。",
  "summary": "近年来，大规模生成模型在文本到图像生成方面表现出色，但在生成高保真个性化图像，尤其是涉及多个主体时仍面临挑战。本文提出的AnyStory通过‘编码-路由’的方式统一解决个性化主体生成问题。具体而言，AnyStory在编码阶段利用强大的图像编码器ReferenceNet结合CLIP视觉编码器，实现高保真的主体特征编码。在路由阶段，AnyStory采用一种解耦的实例感知主体路由器，准确预测潜在主体在潜空间中的位置，引导主体条件的注入。实验结果表明，该方法在保留主体细节、对齐文本描述和实现多主体个性化生成方面表现优异。更多信息可见项目主页： https:
  "keyword": [
    "个性化生成",
    "图像编码",
    "多主体"
  ]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 292 (char 386). Line: 406.
Append: [AnyStory: Towards Unified Single and Multiple Subject Personalization in Text-to-Image Generation](https://arxiv.org/abs/2501.09503)
Token length: 1396
Summarized using gpt-4o-mini
Append: [高保真3D资产生成的CaPa框架研究](https://arxiv.org/abs/2501.09433)
Token length: 1888
Summarized using gpt-4o-mini
Append: [自编码器设计在图像与视频生成模型中的作用研究](https://arxiv.org/abs/2501.09755)
Token length: 1517
Summarized using gpt-4o-mini
Append: [扩展扩散模型的推理时间计算行为研究](https://arxiv.org/abs/2501.09732)
Token length: 1791
Summarized using gpt-4o-mini
Append: [大规模语言模型的推理能力研究进展](https://arxiv.org/abs/2501.09686)
Token length: 1892
Summarized using gpt-4o-mini
Append: [基于事后模拟的强化学习：提升生成型AI的对齐性](https://arxiv.org/abs/2501.08617)
append_entries: 10
Finish: 2025-01-17 09:01:45.048512
------------------------------------------------------
Started: 2025-01-17 12:12:01.333434
Existing_entries: 1010
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1258
Summarized using gpt-4o-mini
Append: [AI视频生成与物理理解的界限](https://arxiv.org/abs/2501.09038)
append_entries: 1
Finish: 2025-01-17 12:12:07.239299
------------------------------------------------------
Started: 2025-01-17 15:00:43.551851
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-17 15:00:43.744242
------------------------------------------------------
Started: 2025-01-17 18:01:11.034698
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 631
Summarized using gpt-4o-mini
Append: [推出全新多语言编程数据集The Heap](https://arxiv.org/abs/2501.09653)
append_entries: 1
Finish: 2025-01-17 18:01:15.389186
------------------------------------------------------
Started: 2025-01-17 21:00:47.801336
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-17 21:00:47.987472
------------------------------------------------------
Started: 2025-01-18 00:32:05.654248
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-18 00:32:05.897486
------------------------------------------------------
Started: 2025-01-18 03:00:45.995948
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-18 03:00:46.262946
------------------------------------------------------
Started: 2025-01-18 06:00:36.515329
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-18 06:00:36.759255
------------------------------------------------------
Started: 2025-01-18 09:00:50.016424
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-18 09:00:50.227706
------------------------------------------------------
Started: 2025-01-18 12:10:35.341613
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-18 12:10:35.555895
------------------------------------------------------
Started: 2025-01-18 15:00:39.634095
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-18 15:00:39.845844
------------------------------------------------------
Started: 2025-01-18 18:00:59.890604
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-18 18:01:18.868886
------------------------------------------------------
Started: 2025-01-18 21:00:49.267492
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-18 21:00:49.480948
------------------------------------------------------
Started: 2025-01-19 00:36:39.073099
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-19 00:36:39.385471
------------------------------------------------------
Started: 2025-01-19 03:11:57.291450
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-19 03:11:57.474378
------------------------------------------------------
Started: 2025-01-19 06:00:41.733122
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-19 06:00:42.028104
------------------------------------------------------
Started: 2025-01-19 09:00:35.887144
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-19 09:00:36.125540
------------------------------------------------------
Started: 2025-01-19 12:00:49.325110
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-19 12:00:49.495147
------------------------------------------------------
Started: 2025-01-19 15:00:52.714444
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-19 15:00:53.017251
------------------------------------------------------
Started: 2025-01-19 18:00:59.088728
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-19 18:00:59.250868
------------------------------------------------------
Started: 2025-01-19 21:00:54.956234
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-19 21:00:55.113955
------------------------------------------------------
Started: 2025-01-20 00:34:44.622930
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-20 00:34:44.904764
------------------------------------------------------
Started: 2025-01-20 03:10:30.073429
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-20 03:10:30.293010
------------------------------------------------------
Started: 2025-01-20 06:00:56.036101
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1281
Summarized using gpt-4o-mini
Append: [GaussianAvatar-Editor：文本驱动的可动画高斯头像编辑框架](https://arxiv.org/abs/2501.09978)
Token length: 706
Summarized using gpt-4o-mini
Append: [Mind Evolution：提升大型语言模型推理效率的进化搜索策略](https://arxiv.org/abs/2501.09891)
Token length: 1231
Summarized using gpt-4o-mini
Append: [PaSa：基于大语言模型的学术论文搜索代理](https://arxiv.org/abs/2501.10120)
Json decode failed:
{
  "title": "ComplexFuncBench: 复杂函数调用的基准与评估框架",
  "keyword": ["大型语言模型", "函数调用", "基准评估"],
  "short_summary": "文章介绍了ComplexFuncBench基准及其在复杂函数调用评估中的应用。",
  "summary": "本文提出了ComplexFuncBench，这是一个针对复杂函数调用的新基准，旨在评估大型语言模型（LLMs）在五个现实场景下的函数调用能力。与现有基准相比，ComplexFuncBench 涉及多步骤和受限的函数调用，要求长参数填充和参数值推理，使用了128k的长上下文。我们还提出了自动化框架ComplexEval，用于定量评估复杂的函数调用任务。通过全面的实验，我们揭示了当前最先进的 LLMs 在函数调用方面的缺陷，并建议未来优化这些能力的方向。数据和代码可在 https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 256 (char 407). Line: 406.
Append: [ComplexFuncBench: Exploring Multi-Step and Constrained Function Calling under Long-Context Scenario](https://arxiv.org/abs/2501.10132)
append_entries: 4
Finish: 2025-01-20 06:01:16.714102
------------------------------------------------------
Started: 2025-01-20 09:00:41.558533
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-20 09:00:41.732147
------------------------------------------------------
Started: 2025-01-20 12:12:44.675742
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1365
Summarized using gpt-4o-mini
Append: [X-Dyna：基于扩散的零-shot人类图像动画生成方法](https://arxiv.org/abs/2501.10021)
Token length: 1507
Summarized using gpt-4o-mini
Append: [HiFi-SR：基于GAN的高保真语音超分辨率方法](https://arxiv.org/abs/2501.10045)
Json decode failed:
{
  "title": "Textoon：基于文本描述生成多样化2D卡通角色的创新方法",
  "short_summary": "Textoon利用文本生成不同的Live2D 2D卡通角色。",
  "summary": "Textoon是一种基于文本描述生成多样化2D卡通角色的创新方法，采用Live2D格式，具有高效率和互动性。与资源密集的3D角色构建不同，Textoon能够通过现代语言与视觉模型快速解读文本意图，并在短时间内生成多种风格的2D角色。这一方法使用轻量级HTML5渲染，提高了可访问性和响应速度。该技术特别适合年轻受众，满足了对2D卡通风格角色的需求，同时展现出与3D角色动画相似的运动表现。项目主页为：https:
  "keyword": ["2D卡通", "Live2D", "字符生成"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 221 (char 320). Line: 406.
Append: [Textoon: Generating Vivid 2D Cartoon Characters from Text Descriptions](https://arxiv.org/abs/2501.10020)
append_entries: 3
Finish: 2025-01-20 12:13:07.829089
------------------------------------------------------
Started: 2025-01-20 15:00:43.594948
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1631
Summarized using gpt-4o-mini
Append: [语言模型自信度与推理顺序的关系研究](https://arxiv.org/abs/2501.09775)
append_entries: 1
Finish: 2025-01-20 15:00:51.090057
------------------------------------------------------
Started: 2025-01-20 18:00:41.207098
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 982
Summarized using gpt-4o-mini
Append: [多语言医疗知识大语言模型的挑战与发展](https://arxiv.org/abs/2501.09825)
append_entries: 1
Finish: 2025-01-20 18:00:46.579643
------------------------------------------------------
Started: 2025-01-20 21:00:47.772181
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-20 21:00:47.967488
------------------------------------------------------
Started: 2025-01-21 00:33:17.192173
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-21 00:33:17.374907
------------------------------------------------------
Started: 2025-01-21 03:08:49.315213
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-21 03:08:49.473899
------------------------------------------------------
Started: 2025-01-21 06:00:58.467387
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-21 06:00:58.654012
------------------------------------------------------
Started: 2025-01-21 09:00:56.491521
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1465
Summarized using gpt-4o-mini
Append: [GameFactory：游戏视频生成中的场景泛化框架](https://arxiv.org/abs/2501.08325)
append_entries: 1
Finish: 2025-01-21 09:01:05.018183
------------------------------------------------------
Started: 2025-01-21 12:12:32.581771
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-21 12:12:32.762734
------------------------------------------------------
Started: 2025-01-21 15:00:53.819737
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1313
Summarized using gpt-4o-mini
Append: [基于视觉输入的深度生成模型研究：VideoWorld的应用与发现](https://arxiv.org/abs/2501.09781)
append_entries: 1
Finish: 2025-01-21 15:01:02.314231
------------------------------------------------------
Started: 2025-01-21 18:00:49.073629
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1004
Summarized using gpt-4o-mini
Append: [SEAL：保护LoRA权重的安全水印技术](https://arxiv.org/abs/2501.09284)
append_entries: 1
Finish: 2025-01-21 18:01:03.363308
------------------------------------------------------
Started: 2025-01-21 21:00:46.519757
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-21 21:00:46.703675
------------------------------------------------------
Started: 2025-01-22 00:34:09.250479
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-22 00:34:09.420114
------------------------------------------------------
Started: 2025-01-22 03:10:57.593070
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-22 03:10:57.757189
------------------------------------------------------
Started: 2025-01-22 06:01:09.160192
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-22 06:01:09.439022
------------------------------------------------------
Started: 2025-01-22 09:00:38.882993
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1919
Summarized using gpt-4o-mini
Append: [Agent-R：迭代自我训练框架提升语言模型错误纠正能力](https://arxiv.org/abs/2501.11425)
Token length: 1914
Summarized using gpt-4o-mini
Append: [Mobile-Agent-E：新一代自我进化移动代理框架](https://arxiv.org/abs/2501.11733)
Token length: 1719
Summarized using gpt-4o-mini
Append: [Learn-by-interact: 提升大语言模型自主代理的数据合成方法](https://arxiv.org/abs/2501.10893)
Token length: 1849
Summarized using gpt-4o-mini
Append: [UI-TARS：一种全新的GUI代理模型](https://arxiv.org/abs/2501.12326)
Token length: 1818
Summarized using gpt-4o-mini
Append: [解构推理语言模型的模块化框架](https://arxiv.org/abs/2501.11223)
Token length: 822
Summarized using gpt-4o-mini
Append: [基于GPS标签的图像生成模型研究](https://arxiv.org/abs/2501.12390)
Token length: 1628
Summarized using gpt-4o-mini
Append: [改进Mixture-of-Experts模型训练中的负载均衡损失方法](https://arxiv.org/abs/2501.11873)
Token length: 1341
Summarized using gpt-4o-mini
Append: [MMVU：视频理解基础模型的专家级多学科基准评估](https://arxiv.org/abs/2501.12380)
Token length: 1077
Summarized using gpt-4o-mini
Append: [Condor：提高大模型会话能力的合成数据生成框架](https://arxiv.org/abs/2501.12273)
append_entries: 9
Finish: 2025-01-22 09:01:22.782931
------------------------------------------------------
Started: 2025-01-22 12:12:35.792377
Existing_entries: 1009
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1533
Summarized using gpt-4o-mini
Append: [基于结构化噪声采样的视频扩散模型运动控制](https://arxiv.org/abs/2501.08331)
Token length: 1554
Summarized using gpt-4o-mini
Append: [Video Depth Anything: 提高超长视频的深度估计一致性](https://arxiv.org/abs/2501.12375)
Token length: 1159
Summarized using gpt-4o-mini
Append: [音频驱动的自然对话生成方法研究](https://arxiv.org/abs/2501.10687)
Token length: 1402
Summarized using gpt-4o-mini
Append: [Hunyuan3D 2.0：先进的大规模3D合成系统](https://arxiv.org/abs/2501.12202)
append_entries: 4
Finish: 2025-01-22 12:13:28.676888
------------------------------------------------------
Started: 2025-01-22 15:00:49.189662
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1199
Summarized using gpt-4o-mini
Append: [引入多模态安全测试套件评估视觉语言模型的安全性](https://arxiv.org/abs/2501.10057)
append_entries: 1
Finish: 2025-01-22 15:00:57.083549
------------------------------------------------------
Started: 2025-01-22 18:00:59.099772
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 930
Summarized using gpt-4o-mini
Append: [剖析变换器模型中令牌嵌入几何与下一令牌预测的关系](https://arxiv.org/abs/2501.10573)
Token length: 981
Summarized using gpt-4o-mini
Append: [基于风格与内容的个性化新闻标题生成框架SCAPE](https://arxiv.org/abs/2501.11900)
Token length: 1712
Summarized using gpt-4o-mini
Append: [提升大视觉语言模型的生成质量：InternLM-XComposer2.5-Reward的应用](https://arxiv.org/abs/2501.12368)
Token length: 1293
Summarized using gpt-4o-mini
Append: [TokenVerse：多概念个性化生成的新方法](https://arxiv.org/abs/2501.12224)
append_entries: 4
Finish: 2025-01-22 18:01:18.951460
------------------------------------------------------
Started: 2025-01-22 21:00:45.433953
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-22 21:00:45.622405
------------------------------------------------------
Started: 2025-01-23 00:33:57.322848
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1532
Summarized using gpt-4o-mini
Append: [通过注意力机制优化减少大型视觉语言模型中的幻觉现象](https://arxiv.org/abs/2501.12206)
append_entries: 1
Finish: 2025-01-23 00:34:01.254802
------------------------------------------------------
Started: 2025-01-23 03:09:15.035814
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 899
Summarized using gpt-4o-mini
Append: [MAGI：创新的混合视频生成框架](https://arxiv.org/abs/2501.12389)
append_entries: 1
Finish: 2025-01-23 03:09:20.006047
------------------------------------------------------
Started: 2025-01-23 06:00:47.751230
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-23 06:00:47.937363
------------------------------------------------------
Started: 2025-01-23 09:00:59.659809
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1247
Summarized using gpt-4o-mini
Append: [测试时间偏好优化框架：实时调整大型语言模型输出](https://arxiv.org/abs/2501.12895)
Token length: 1705
Summarized using gpt-4o-mini
Append: [VideoLLaMA3：图像与视频理解的先进多模态基础模型](https://arxiv.org/abs/2501.13106)
Token length: 1911
Summarized using gpt-4o-mini
Append: [IntellAgent：评估对话式人工智能的新框架](https://arxiv.org/abs/2501.11067)
Token length: 1250
Summarized using gpt-4o-mini
Append: [自主专家选择的Mixture-of-Experts新范式](https://arxiv.org/abs/2501.13074)
Token length: 888
Summarized using gpt-4o-mini
Append: [发布首代推理模型DeepSeek-R1-Zero和DeepSeek-R1](https://arxiv.org/abs/2501.12948)
Token length: 1502
Summarized using gpt-4o-mini
Append: [FilmAgent：基于大型语言模型的虚拟电影制作自动化框架](https://arxiv.org/abs/2501.12909)
Token length: 1495
Summarized using gpt-4o-mini
Append: [Kimi k1.5：基于强化学习的多模态大语言模型训练](https://arxiv.org/abs/2501.12599)
Token length: 1403
Summarized using gpt-4o-mini
Append: [O1-Pruner：降低长思考推理模型推理时间的新方法](https://arxiv.org/abs/2501.12570)
append_entries: 8
Finish: 2025-01-23 09:01:53.889378
------------------------------------------------------
Started: 2025-01-23 12:12:55.236092
Existing_entries: 1008
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "基于对比奖励模型的Best-of-N采样优化",
  "keyword": ["对比奖励模型", "Best-of-N采样", "大语言模型"],
  "short_summary": "提出对比奖励模型，优化Large Language Models的Best-of-N采样策略。",
  "summary": "本文提出了Pairwise Reward Model（对比奖励模型，Pairwise RM），旨在优化Large Language Models（LLMs）在测试时采用的Best-of-N（BoN）采样策略。与传统的绝对分数评分方法不同，Pairwise RM通过同时评估两个候选解的正确性，从而消除了任意评分的需求。该模型通过迭代的淘汰赛方式，在多个候选解之间进行对比，从而逐步筛除不正确的解。为训练Pairwise RM，研究团队构建了一个名为\ourdataset的大规模数据集，其中包含443K对比实例，并通过监督微调技术进行训练。实验结果表明，Pairwise RM在MATH-500和奥林匹克基准测试中的表现显著优于传统的判别奖励模型，尤其在困难问题的前50%上实现了40%到60%的相对提升。"
}Summarization failed, append the original article
error: Invalid \escape: line 5 column 239 (char 396). Line: 406.
Append: [Pairwise RM: Perform Best-of-N Sampling with Knockout Tournament](https://arxiv.org/abs/2501.13007)
append_entries: 1
Finish: 2025-01-23 12:12:58.821600
------------------------------------------------------
Started: 2025-01-23 15:00:46.684136
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-23 15:00:46.870812
------------------------------------------------------
Started: 2025-01-23 18:00:38.938801
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-23 18:00:39.140948
------------------------------------------------------
Started: 2025-01-23 21:00:48.589095
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-23 21:00:48.780888
------------------------------------------------------
Started: 2025-01-24 00:33:49.107421
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-24 00:33:49.348681
------------------------------------------------------
Started: 2025-01-24 03:09:29.646337
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-24 03:09:29.852165
------------------------------------------------------
Started: 2025-01-24 06:01:07.869631
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1685
Summarized using gpt-4o-mini
Append: [增强人类监督提升强模型对齐能力的研究](https://arxiv.org/abs/2501.13124)
Token length: 1392
Summarized using gpt-4o-mini
Append: [提升长视频理解的时间定位能力：时间偏好优化框架](https://arxiv.org/abs/2501.13919)
Token length: 1745
Summarized using gpt-4o-mini
Append: [文本到图像模型的评估与未来展望](https://arxiv.org/abs/2501.13920)
Token length: 1557
Summarized using gpt-4o-mini
Append: [Sigma：高效的系统领域大语言模型及其DiffQKV关注机制](https://arxiv.org/abs/2501.13629)
Token length: 1173
Summarized using gpt-4o-mini
Append: [Step-KTO：提升大型语言模型的数学推理可信度](https://arxiv.org/abs/2501.10799)
Token length: 1601
Summarized using gpt-4o-mini
Append: [链式思维推理在自回归图像生成中的应用研究](https://arxiv.org/abs/2501.13926)
append_entries: 6
Finish: 2025-01-24 06:01:34.418349
------------------------------------------------------
Started: 2025-01-24 09:01:06.141489
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-24 09:01:06.397700
------------------------------------------------------
Started: 2025-01-24 12:12:32.423891
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1309
Summarized using gpt-4o-mini
Append: [GSTAR：动态场景中的高效3D跟踪与重建](https://arxiv.org/abs/2501.10283)
Token length: 1366
Summarized using gpt-4o-mini
Append: [基于扩散模型的高效视频修复方法DiffuEraser](https://arxiv.org/abs/2501.10018)
Token length: 1402
Summarized using gpt-4o-mini
Append: [EchoVideo：一种提升身份保护视频生成的有效方法](https://arxiv.org/abs/2501.13452)
Token length: 1396
Summarized using gpt-4o-mini
Append: [共享递归记忆变压器在多智能体强化学习中的应用](https://arxiv.org/abs/2501.13200)
Token length: 1869
Summarized using gpt-4o-mini
Append: [机器学习中的盲点：对未知未来的鲁棒性](https://arxiv.org/abs/2501.13075)
append_entries: 5
Finish: 2025-01-24 12:13:01.954771
------------------------------------------------------
Started: 2025-01-24 15:01:00.045184
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1510
Summarized using gpt-4o-mini
Append: [基于人类反馈的视频生成优化模型](https://arxiv.org/abs/2501.13918)
Json decode failed:
{
  "title": "Video-MMMU：评估多模态模型的视频知识获取能力的基准",
  "keyword": ["知识获取", "多模态模型", "视频学习"],
  "short_summary": "本文介绍了Video-MMMU基准，以评估多模态模型从视频中获取知识的能力。",
  "summary": "人类通过感知信息、理解知识以及将知识应用于解决新问题的三个认知阶段来获取知识。视频作为学习过程中有效的媒介，促进了这些认知阶段的进展。然而，现有的视频基准未能系统地评估大型多模态模型（LMMs）的知识获取能力。为此，本文提出了Video-MMMU，一个多模态、多学科的基准，旨在评估LMMs从视频中获取和利用知识的能力。Video-MMMU包括300个专业级视频和900个人工标注的问题，涵盖六个学科，通过阶段对齐的问题-答案对（感知、理解和适应）评估知识获取。我们提出的知识增益度量{\Delta}knowledge量化了观看视频后的性能提升。LMMs的评估显示，随着认知需求的增加，性能呈现显著下降，并突显了人类与模型知识获取之间的重要差距，强调了提升LMMs从视频中学习和适应能力的方法的必要性。"
}Summarization failed, append the original article
error: Invalid \escape: line 5 column 258 (char 405). Line: 406.
Append: [Video-MMMU: Evaluating Knowledge Acquisition from Multi-Discipline Professional Videos](https://arxiv.org/abs/2501.13826)
append_entries: 2
Finish: 2025-01-24 15:01:13.274397
------------------------------------------------------
Started: 2025-01-24 18:01:06.880728
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1173
Summarized using gpt-4o-mini
Append: [幻觉在药物发现中的应用潜力：大型语言模型的研究](https://arxiv.org/abs/2501.13824)
Token length: 1414
Summarized using gpt-4o-mini
Append: [一种无训练的文本到图像生成方法：One-Prompt-One-Story](https://arxiv.org/abs/2501.13554)
append_entries: 2
Finish: 2025-01-24 18:01:32.067502
------------------------------------------------------
Started: 2025-01-24 21:01:01.828009
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-24 21:01:01.992657
------------------------------------------------------
Started: 2025-01-25 00:32:48.811189
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1625
Summarized using gpt-4o-mini
Append: [Control LLM: 一种有效应对灾难性遗忘的方法](https://arxiv.org/abs/2501.10979)
append_entries: 1
Finish: 2025-01-25 00:32:54.932492
------------------------------------------------------
Started: 2025-01-25 03:00:44.469286
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-25 03:00:44.740398
------------------------------------------------------
Started: 2025-01-25 06:05:25.276332
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1430
Summarized using gpt-4o-mini
Append: [EmbodiedEval：多模态大语言模型的交互式评估基准](https://arxiv.org/abs/2501.11858)
append_entries: 1
Finish: 2025-01-25 06:05:31.365356
------------------------------------------------------
Started: 2025-01-25 09:01:00.820213
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-25 09:01:01.261498
------------------------------------------------------
Started: 2025-01-25 12:01:00.498445
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-25 12:01:00.644605
------------------------------------------------------
Started: 2025-01-25 15:00:39.734670
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-25 15:00:39.981978
------------------------------------------------------
Started: 2025-01-25 18:00:41.686130
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-25 18:00:41.892302
------------------------------------------------------
Started: 2025-01-25 21:00:37.419868
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-25 21:00:37.574330
------------------------------------------------------
Started: 2025-01-26 00:34:35.318645
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-26 00:34:35.516247
------------------------------------------------------
Started: 2025-01-26 03:09:42.442386
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-26 03:09:42.605992
------------------------------------------------------
Started: 2025-01-26 06:00:48.761904
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-26 06:00:53.177868
------------------------------------------------------
Started: 2025-01-26 09:00:40.221531
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-26 09:00:40.471485
------------------------------------------------------
Started: 2025-01-26 12:10:39.921914
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-26 12:10:40.082467
------------------------------------------------------
Started: 2025-01-26 15:00:58.120382
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-26 15:00:58.275186
------------------------------------------------------
Started: 2025-01-26 18:01:05.567967
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-26 18:01:05.776936
------------------------------------------------------
Started: 2025-01-26 21:00:51.242428
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-26 21:00:51.418548
------------------------------------------------------
Started: 2025-01-27 00:35:01.934080
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-27 00:35:02.194283
------------------------------------------------------
Started: 2025-01-27 03:10:16.340593
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-27 03:10:16.553450
------------------------------------------------------
Started: 2025-01-27 06:10:47.359244
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1452
Summarized using gpt-4o-mini
Append: [评估大型语言模型批评能力的新基准](https://arxiv.org/abs/2501.14492)
Token length: 1428
Summarized using gpt-4o-mini
Append: [CoRAG：链式检索增强生成模型的训练方法](https://arxiv.org/abs/2501.14342)
append_entries: 2
Finish: 2025-01-27 06:10:55.704855
------------------------------------------------------
Started: 2025-01-27 09:00:46.395668
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1656
Summarized using gpt-4o-mini
Append: [可重光照全身高斯编码虚拟形象建模方法](https://arxiv.org/abs/2501.14726)
Token length: 1246
Summarized using gpt-4o-mini
Append: [推出人类最后考试：评估大型语言模型的新基准工具](https://arxiv.org/abs/2501.14249)
append_entries: 2
Finish: 2025-01-27 09:00:55.413707
------------------------------------------------------
Started: 2025-01-27 12:01:04.660512
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1009
Summarized using gpt-4o-mini
Append: [评估多模态大语言模型基准的冗余性与优化策略](https://arxiv.org/abs/2501.13953)
append_entries: 1
Finish: 2025-01-27 12:01:08.119163
------------------------------------------------------
Started: 2025-01-27 15:01:15.943517
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-27 15:01:16.102978
------------------------------------------------------
Started: 2025-01-27 18:01:03.768525
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 973
Summarized using gpt-4o-mini
Append: [增强学习与元学习结合的变换器模型研究](https://arxiv.org/abs/2501.14176)
Token length: 1917
Summarized using gpt-4o-mini
Append: [基于频率挖掘的自适应全能图像恢复网络](https://arxiv.org/abs/2403.14614)
Token length: 1647
Summarized using gpt-4o-mini
Append: [基于扩散模型的图像恢复领域适应方法](https://arxiv.org/abs/2406.18516)
Token length: 1171
Summarized using gpt-4o-mini
Append: [提升视觉模型的3D意识：基于ViT的研究与优化](https://arxiv.org/abs/2411.19458)
Token length: 1560
Summarized using gpt-4o-mini
Append: [GeoPixel: 一种高分辨率遥感图像的像素级基础大模型](https://arxiv.org/abs/2501.13925)
append_entries: 5
Finish: 2025-01-27 18:01:35.163972
------------------------------------------------------
Started: 2025-01-27 21:01:06.406743
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1307
Summarized using gpt-4o-mini
Append: [CatV2TON：一种高效的图像与视频虚拟试穿方法](https://arxiv.org/abs/2501.11325)
Token length: 1399
Summarized using gpt-4o-mini
Append: [利用大型语言模型实现电子健康记录的语义问答](https://arxiv.org/abs/2501.13687)
append_entries: 2
Finish: 2025-01-27 21:01:15.753048
------------------------------------------------------
Started: 2025-01-28 00:34:04.630780
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-28 00:34:04.844688
------------------------------------------------------
Started: 2025-01-28 03:08:38.000238
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-28 03:08:38.187355
------------------------------------------------------
Started: 2025-01-28 06:02:56.662224
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-28 06:02:56.821880
------------------------------------------------------
Started: 2025-01-28 09:01:09.403396
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1233
Summarized using gpt-4o-mini
Append: [iFormer：一种优化移动应用延迟与准确性的混合视觉网络](https://arxiv.org/abs/2501.15369)
Token length: 1148
Summarized using gpt-4o-mini
Append: [可行学习：重塑机器学习的样本中心训练范式](https://arxiv.org/abs/2501.14912)
Token length: 1817
Summarized using gpt-4o-mini
Append: [Mixture-of-Mamba：一种新型的状态空间模型架构用于多模态预训练](https://arxiv.org/abs/2501.16295)
Token length: 1103
Summarized using gpt-4o-mini
Append: [统一的无模型深度强化学习算法MR.Q的探索及其性能评估](https://arxiv.org/abs/2501.16142)
Token length: 1915
Summarized using gpt-4o-mini
Append: [Qwen2.5-1M模型：实现百万级上下文处理](https://arxiv.org/abs/2501.15383)
Token length: 1135
Summarized using gpt-4o-mini
Append: [Baichuan-Omni-1.5：全新的多模态理解与音频生成模型](https://arxiv.org/abs/2501.15368)
append_entries: 6
Finish: 2025-01-28 09:01:41.988606
------------------------------------------------------
Started: 2025-01-28 12:00:48.277212
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1261
Summarized using gpt-4o-mini
Append: [基于RWKV的高效混合注意力模型研究](https://arxiv.org/abs/2501.15570)
append_entries: 1
Finish: 2025-01-28 12:00:52.839843
------------------------------------------------------
Started: 2025-01-28 15:00:58.071071
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1186
Summarized using gpt-4o-mini
Append: [稀疏专家混合模型中的参数稀疏性对性能的影响研究](https://arxiv.org/abs/2501.12370)
Token length: 1421
Summarized using gpt-4o-mini
Append: [Emilia-Pipe：构建多语言自发语音生成数据集的开源管道](https://arxiv.org/abs/2501.15907)
append_entries: 2
Finish: 2025-01-28 15:01:10.626427
------------------------------------------------------
Started: 2025-01-28 18:01:03.857496
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-28 18:01:04.052870
------------------------------------------------------
Started: 2025-01-28 21:00:47.118077
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 984
Summarized using gpt-4o-mini
Append: [大语言模型中的角色定制化与合成数据研究](https://arxiv.org/abs/2501.15427)
Token length: 1578
Summarized using gpt-4o-mini
Append: [小型语言模型中的编码器-解码器架构优势分析](https://arxiv.org/abs/2501.16273)
append_entries: 2
Finish: 2025-01-28 21:01:01.526275
------------------------------------------------------
Started: 2025-01-29 00:34:02.670663
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1603
Summarized using gpt-4o-mini
Append: [CodeMonkeys：基于多轮迭代编辑的代码问题解决系统](https://arxiv.org/abs/2501.14723)
Json decode failed:
{
  "title": "引导无关训练（GFT）：提升视觉生成模型的效率",
  "short_summary": "GFT算法实现视觉模型引导无关采样，降低计算成本，性能优于CFG。",
  "summary": "引导自由训练（GFT）是一种新型视觉生成模型训练方法，旨在消除现有技术中需要进行条件和无条件模型推理的复杂性。与经典的分类无关引导（CFG）方法相比，GFT能够在单一模型下进行采样，成本减半。GFT不依赖于预训练的CFG网络，而是允许从零开始的直接训练。该方法在最大似然目标上与CFG保持一致，仅在条件模型的参数化上有所不同，实现起来也非常简单，只需对现有代码库进行最小修改。通过对五种不同视觉模型的广泛实验，GFT表现出优越性与多样性，能够在扩散、自回归及遮挡预测建模领域中实现与CFG相当或更低的FID分数，表现出相似的多样性与保真度权衡，且完全不依赖于引导机制。代码将公开于https:
  "keyword": [
    "引导自由训练",
    "视觉生成模型",
    "计算效率"
  ]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 311 (char 406). Line: 406.
Append: [Visual Generation Without Guidance](https://arxiv.org/abs/2501.15420)
Token length: 1391
Summarized using gpt-4o-mini
Append: [视觉语言模型中的视觉偏差研究](https://arxiv.org/abs/2403.09193)
append_entries: 3
Finish: 2025-01-29 00:34:19.661539
------------------------------------------------------
Started: 2025-01-29 03:08:52.613867
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-29 03:08:52.776705
------------------------------------------------------
Started: 2025-01-29 06:00:50.844742
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "低秩适配器与神经架构搜索结合下的大语言模型优化",
  "short_summary": "文章探讨低秩适配器与神经架构搜索结合对大语言模型的优化方法。",
  "summary": "随着大语言模型（LLMs）的快速扩展，模型的微调和部署面临着显著的计算资源挑战。本文回顾了低秩适配器在参数高效微调（PEFT）中的有效性，并详细探讨了将低秩表示与神经架构搜索（NAS）技术相结合的创新方法，特别是权重共享超网络。通过整合这些方法，开发出了有效的解决方案以压缩和微调大型预训练模型。分析结果显示，这些组合策略有潜力使大语言模型的使用更加民主化，提高其在资源有限环境下的可接入性。所生成的模型在内存占用和推理速度上均有所改善，推动了大语言模型在实际应用中的可扩展性和实用性。相关模型和代码可在https:
  "keyword": ["大语言模型", "低秩适配器", "神经架构搜索"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 273 (char 365). Line: 406.
Append: [Low-Rank Adapters Meet Neural Architecture Search for LLM Compression](https://arxiv.org/abs/2501.16372)
Token length: 1246
Summarized using gpt-4o-mini
Append: [IndicMMLU-Pro：评估印地语言大型语言模型的新基准](https://arxiv.org/abs/2501.15747)
append_entries: 2
Finish: 2025-01-29 06:01:05.830486
------------------------------------------------------
Started: 2025-01-29 09:00:46.737857
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1171
Summarized using gpt-4o-mini
Append: [DiffSplat：基于文本和图像的3D生成功能框架](https://arxiv.org/abs/2501.16764)
Token length: 1308
Summarized using gpt-4o-mini
Append: [强化学习与有监督微调在模型泛化能力中的区别研究](https://arxiv.org/abs/2501.17161)
Token length: 1103
Summarized using gpt-4o-mini
Append: [FP4训练框架：应对大语言模型低比特算力挑战](https://arxiv.org/abs/2501.17116)
Token length: 915
Summarized using gpt-4o-mini
Append: [超标记化变换器：提升大型语言模型性能的新框架](https://arxiv.org/abs/2501.16975)
Token length: 960
Summarized using gpt-4o-mini
Append: [机械解释性领域的现状与挑战](https://arxiv.org/abs/2501.16496)
append_entries: 5
Finish: 2025-01-29 09:01:16.132672
------------------------------------------------------
Started: 2025-01-29 12:12:38.228379
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1388
Summarized using gpt-4o-mini
Append: [构建与人类价值观一致的法语数据集](https://arxiv.org/abs/2501.17117)
append_entries: 1
Finish: 2025-01-29 12:13:06.156666
------------------------------------------------------
Started: 2025-01-29 15:00:52.173253
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-29 15:00:52.366731
------------------------------------------------------
Started: 2025-01-29 18:00:54.687926
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-29 18:00:54.970072
------------------------------------------------------
Started: 2025-01-29 21:00:55.485575
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-29 21:00:55.691663
------------------------------------------------------
Started: 2025-01-30 00:33:11.405148
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-30 00:33:11.653974
------------------------------------------------------
Started: 2025-01-30 03:01:09.801796
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-30 03:01:10.042432
------------------------------------------------------
Started: 2025-01-30 06:00:40.813907
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1380
Summarized using gpt-4o-mini
Append: [批评微调：一种增强语言模型推理的新策略](https://arxiv.org/abs/2501.17703)
Token length: 1281
Summarized using gpt-4o-mini
Append: [Atla Selene Mini：新一代小型评估模型](https://arxiv.org/abs/2501.17195)
Token length: 1280
Summarized using gpt-4o-mini
Append: [大型语言模型安全性测试研究](https://arxiv.org/abs/2501.17749)
append_entries: 3
Finish: 2025-01-30 06:00:55.234822
------------------------------------------------------
Started: 2025-01-30 09:00:43.683743
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1061
Summarized using gpt-4o-mini
Append: [大型语言模型的安全性与有害微调攻击风险](https://arxiv.org/abs/2501.17433)
append_entries: 1
Finish: 2025-01-30 09:00:51.551842
------------------------------------------------------
Started: 2025-01-30 12:00:56.180109
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1592
Summarized using gpt-4o-mini
Append: [人工智能环境影响评估与净零目标的协调策略](https://arxiv.org/abs/2501.14334)
append_entries: 1
Finish: 2025-01-30 12:01:05.472942
------------------------------------------------------
Started: 2025-01-30 15:00:40.920846
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-30 15:00:41.073944
------------------------------------------------------
Started: 2025-01-30 18:01:05.456118
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1134
Summarized using gpt-4o-mini
Append: [人类对AI生成文本的检测能力研究](https://arxiv.org/abs/2501.15654)
append_entries: 1
Finish: 2025-01-30 18:01:20.970802
------------------------------------------------------
Started: 2025-01-30 21:00:35.867710
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-30 21:00:36.019143
------------------------------------------------------
Started: 2025-01-31 00:33:52.072172
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-31 00:33:52.248170
------------------------------------------------------
Started: 2025-01-31 03:08:40.044889
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-31 03:08:40.189691
------------------------------------------------------
Started: 2025-01-31 06:00:42.121203
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1700
Summarized using gpt-4o-mini
Append: [提升视觉语言模型在物理世界理解上的能力](https://arxiv.org/abs/2501.16411)
Token length: 985
Summarized using gpt-4o-mini
Append: [GuardReasoner：提升大语言模型安全性的新方法](https://arxiv.org/abs/2501.18492)
append_entries: 2
Finish: 2025-01-31 06:00:53.704023
------------------------------------------------------
Started: 2025-01-31 09:00:46.020338
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1348
Summarized using gpt-4o-mini
Append: [应对大语言模型中的思维不足现象](https://arxiv.org/abs/2501.18585)
Token length: 1224
Summarized using gpt-4o-mini
Append: [大型语言模型在开放任务中的探索能力研究](https://arxiv.org/abs/2501.18009)
append_entries: 2
Finish: 2025-01-31 09:01:09.685277
------------------------------------------------------
Started: 2025-01-31 12:01:01.779784
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1491
Summarized using gpt-4o-mini
Append: [改进的分布式训练算法DiLoCo：降低带宽需求的突破](https://arxiv.org/abs/2501.18512)
Token length: 1259
Summarized using gpt-4o-mini
Append: [MedXpertQA: 全面评价医学专家知识的基准测试](https://arxiv.org/abs/2501.18362)
Token length: 914
Summarized using gpt-4o-mini
Append: [WILDCHAT-50M：扩展的公共聊天数据集及其性能分析](https://arxiv.org/abs/2501.18511)
Token length: 1256
Summarized using gpt-4o-mini
Append: [DeepSeek-R1与OpenAI o3-mini安全性评估对比](https://arxiv.org/abs/2501.18438)
append_entries: 4
Finish: 2025-01-31 12:01:36.063101
------------------------------------------------------
Started: 2025-01-31 15:00:52.216844
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-31 15:00:52.400210
------------------------------------------------------
Started: 2025-01-31 18:00:48.808824
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-01-31 18:00:49.000713
------------------------------------------------------
Started: 2025-01-31 21:00:42.237908
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1379
Summarized using gpt-4o-mini
Append: [CowPilot：人机协作的网页导航框架](https://arxiv.org/abs/2501.16609)
append_entries: 1
Finish: 2025-01-31 21:00:46.591477
------------------------------------------------------
Started: 2025-02-01 00:36:40.766792
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-01 00:36:40.968877
------------------------------------------------------
Started: 2025-02-01 03:12:42.214891
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-01 03:12:42.384032
------------------------------------------------------
Started: 2025-02-01 06:00:41.260317
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-01 06:00:41.492480
------------------------------------------------------
Started: 2025-02-01 09:00:48.444131
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1066
Summarized using gpt-4o-mini
Append: [SANA-1.5：文本到图像生成中的高效线性扩展变换器](https://arxiv.org/abs/2501.18427)
append_entries: 1
Finish: 2025-02-01 09:00:54.242705
------------------------------------------------------
Started: 2025-02-01 12:00:40.587395
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-01 12:00:40.772194
------------------------------------------------------
Started: 2025-02-01 15:01:02.097475
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-01 15:01:02.329273
------------------------------------------------------
Started: 2025-02-01 18:00:53.010783
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-01 18:00:53.256040
------------------------------------------------------
Started: 2025-02-01 21:00:54.284231
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-01 21:00:54.515753
------------------------------------------------------
Started: 2025-02-02 00:36:23.975721
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-02 00:36:24.165636
------------------------------------------------------
Started: 2025-02-02 03:10:25.090090
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-02 03:10:25.324920
------------------------------------------------------
Started: 2025-02-03 05:01:33.134254
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We introduce Reward-Guided Speculative Decoding (RSD), a novel framework aimed at improving the efficiency of inference in large language models (LLMs). RSD synergistically combines a lightweight draft model with a more powerful target model, incorporating a controlled bias to prioritize high-reward outputs, in contrast to existing speculative decoding methods that enforce strict unbiasedness. RSD employs a process reward model to evaluate intermediate decoding steps and dynamically decide whether to invoke the target model, optimizing the trade-off between computational cost and output quality. We theoretically demonstrate that a threshold-based mixture strategy achieves an optimal balance between resource utilization and performance. Extensive evaluations on challenging reasoning benchmarks, including Olympiad-level tasks, show that RSD delivers significant efficiency gains against decoding with the target model only (up to 4.4x fewer FLOPs), while achieving significant better accuracy than parallel decoding method on average (up to +3.5). These results highlight RSD as a robust and cost-effective approach for deploying LLMs in resource-intensive scenarios.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Reward-Guided Speculative Decoding for Efficient LLM Reasoning](https://arxiv.org/abs/2501.19324)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Test-time scaling is a promising new approach to language modeling that uses extra test-time compute to improve performance. Recently, OpenAI\'s o1 model showed this capability but did not publicly share its methodology, leading to many replication efforts. We seek the simplest approach to achieve test-time scaling and strong reasoning performance. First, we curate a small dataset s1K of 1,000 questions paired with reasoning traces relying on three criteria we validate through ablations: difficulty, diversity, and quality. Second, we develop budget forcing to control test-time compute by forcefully terminating the model\'s thinking process or lengthening it by appending "Wait" multiple times to the model\'s generation when it tries to end. This can lead the model to double-check its answer, often fixing incorrect reasoning steps. After supervised finetuning the Qwen2.5-32B-Instruct language model on s1K and equipping it with budget forcing, our model s1 exceeds o1-preview on competition math questions by up to 27% (MATH and AIME24). Further, scaling s1 with budget forcing allows extrapolating beyond its performance without test-time intervention: from 50% to 57% on AIME24. Our model, data, and code are open-source at https://github.com/simplescaling/s1.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [s1: Simple test-time scaling](https://arxiv.org/abs/2501.19393)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We conduct experiments on the impact of increasing inference-time compute in reasoning models (specifically OpenAI o1-preview and o1-mini) on their robustness to adversarial attacks. We find that across a variety of attacks, increased inference-time compute leads to improved robustness. In many cases (with important exceptions), the fraction of model samples where the attack succeeds tends to zero as the amount of test-time compute grows. We perform no adversarial training for the tasks we study, and we increase inference-time compute by simply allowing the models to spend more compute on reasoning, independently of the form of attack. Our results suggest that inference-time compute has the potential to improve adversarial robustness for Large Language Models. We also explore new attacks directed at reasoning models, as well as settings where inference-time compute does not improve reliability, and speculate on the reasons for these as well as ways to address them.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Trading Inference-Time Compute for Adversarial Robustness](https://arxiv.org/abs/2501.18841)
append_entries: 3
Finish: 2025-02-03 05:01:35.097640
------------------------------------------------------
Started: 2025-02-03 06:00:37.378172
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-03 06:00:37.682922
------------------------------------------------------
Started: 2025-02-03 09:00:57.174278
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1135
Summarized using gpt-4o-mini
Append: [应对大语言模型的普遍越狱攻击：宪法分类器的应用与效果](https://arxiv.org/abs/2501.18837)
append_entries: 1
Finish: 2025-02-03 09:01:13.953024
------------------------------------------------------
Started: 2025-02-03 12:12:41.230062
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1560
Summarized using gpt-4o-mini
Append: [基于多语言模型的新闻摘要性能评估](https://arxiv.org/abs/2501.18128)
Token length: 1459
Summarized using gpt-4o-mini
Append: [TracksTo4D：从动态视频重建3D结构的新方法](https://arxiv.org/abs/2404.07097)
Token length: 1688
Summarized using gpt-4o-mini
Append: [DINO世界模型：无需重建视觉世界的视觉动态建模](https://arxiv.org/abs/2411.04983)
append_entries: 3
Finish: 2025-02-03 12:12:58.973533
------------------------------------------------------
Started: 2025-02-03 15:00:44.556969
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1124
Summarized using gpt-4o-mini
Append: [将知识图谱与大语言模型无缝集成的量化表示方法](https://arxiv.org/abs/2501.18119)
Token length: 1324
Summarized using gpt-4o-mini
Append: [针对任务通用提示的实例特定负样本挖掘方法](https://arxiv.org/abs/2501.18753)
append_entries: 2
Finish: 2025-02-03 15:01:01.093051
------------------------------------------------------
Started: 2025-02-03 18:01:09.061213
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 702
Summarized using gpt-4o-mini
Append: [学习率调度在大模型训练中的优化理论应用](https://arxiv.org/abs/2501.18965)
Token length: 1521
Summarized using gpt-4o-mini
Append: [统一视觉与文本输入的像素感知框架研究](https://arxiv.org/abs/2501.19339)
append_entries: 2
Finish: 2025-02-03 18:01:20.408966
------------------------------------------------------
Started: 2025-02-03 21:01:05.151565
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-03 21:01:05.422277
------------------------------------------------------
Started: 2025-02-04 00:34:00.422193
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1318
Summarized using gpt-4o-mini
Append: [SAeUron：通过稀疏自编码器优化扩散模型中的不当内容去除](https://arxiv.org/abs/2501.18052)
Token length: 1331
Summarized using gpt-4o-mini
Append: [基于扩散模型的多视点图像和深度图生成方法](https://arxiv.org/abs/2501.18804)
Token length: 967
Summarized using gpt-4o-mini
Append: [MatAnyone: 一种针对特定目标的视频抠图框架](https://arxiv.org/abs/2501.14677)
Token length: 1262
Summarized using gpt-4o-mini
Append: [SSMax：一种提升Transformer模型长文本处理能力的可扩展Softmax方法](https://arxiv.org/abs/2501.19399)
append_entries: 4
Finish: 2025-02-04 00:34:33.504199
------------------------------------------------------
Started: 2025-02-04 03:09:34.242814
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-04 03:09:34.509592
------------------------------------------------------
Started: 2025-02-04 06:10:56.646912
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1460
Summarized using gpt-4o-mini
Append: [提高潜在一致性模型质量的研究与方法](https://arxiv.org/abs/2502.01441)
Token length: 1387
Summarized using gpt-4o-mini
Append: [AIN：开创阿拉伯语多模态模型的新纪元](https://arxiv.org/abs/2502.00094)
append_entries: 2
Finish: 2025-02-04 06:11:08.227123
------------------------------------------------------
Started: 2025-02-04 09:00:52.097677
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1303
Summarized using gpt-4o-mini
Append: [偏好泄漏：LLM作为评判者的数据注释问题探讨](https://arxiv.org/abs/2502.01534)
Token length: 1307
Summarized using gpt-4o-mini
Append: [ENCORE：提升知识编辑的模型性能与速度](https://arxiv.org/abs/2502.01636)
Token length: 1347
Summarized using gpt-4o-mini
Append: [FastKV：提升长上下文序列的KV缓存压缩与延迟性能](https://arxiv.org/abs/2502.01068)
Token length: 1322
Summarized using gpt-4o-mini
Append: [OmniHuman：基于扩散转化器的高真实感人类视频生成框架](https://arxiv.org/abs/2502.01061)
Token length: 1324
Summarized using gpt-4o-mini
Append: [ZebraLogic：评估大型语言模型逻辑推理能力的框架](https://arxiv.org/abs/2502.01100)
Token length: 1452
Summarized using gpt-4o-mini
Append: [OpenAI o1与o3模型在多模态推理能力上的演变与挑战](https://arxiv.org/abs/2502.01081)
Token length: 902
Summarized using gpt-4o-mini
Append: [SCONE: 可扩展上下文化n-gram嵌入方法提升语言模型性能](https://arxiv.org/abs/2502.01637)
Token length: 1095
Summarized using gpt-4o-mini
Append: [基于模型的强化学习在Craftax经典基准上的突破性应用](https://arxiv.org/abs/2502.01591)
Token length: 1497
Summarized using gpt-4o-mini
Append: [PRIME：通过隐式过程奖励优化大语言模型的训练](https://arxiv.org/abs/2502.01456)
append_entries: 9
Finish: 2025-02-04 09:01:53.941335
------------------------------------------------------
Started: 2025-02-04 12:01:02.650519
Existing_entries: 1009
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1051
Summarized using gpt-4o-mini
Append: [基于马尔可夫决策过程的语言模型安全生成方法](https://arxiv.org/abs/2502.01208)
Token length: 1185
Summarized using gpt-4o-mini
Append: [基于普通知识的推理模型基准测试](https://arxiv.org/abs/2502.01584)
Token length: 1697
Summarized using gpt-4o-mini
Append: [病理基础模型的鲁棒性评估及临床应用前景](https://arxiv.org/abs/2501.18055)
Token length: 913
Summarized using gpt-4o-mini
Append: [DeepRAG：优化检索增强推理的新框架](https://arxiv.org/abs/2502.01142)
Token length: 1022
Summarized using gpt-4o-mini
Append: [利用ViLU-Net提高腹膜后肿瘤的自动分割效率](https://arxiv.org/abs/2502.00314)
Token length: 1153
Summarized using gpt-4o-mini
Append: [SafeRAG：评估检索增强生成模型的安全性](https://arxiv.org/abs/2501.18636)
Token length: 1193
Summarized using gpt-4o-mini
Append: [直接对齐算法在模型对齐中的应用与改进](https://arxiv.org/abs/2502.01237)
append_entries: 7
Finish: 2025-02-04 12:01:43.425580
------------------------------------------------------
Started: 2025-02-04 15:00:54.840016
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1097
Summarized using gpt-4o-mini
Append: [提出MM-IQ：多模态系统认知能力评估框架](https://arxiv.org/abs/2502.00698)
Token length: 1172
Summarized using gpt-4o-mini
Append: [SliderSpace: 一种可控的扩散模型视觉能力自动分解框架](https://arxiv.org/abs/2502.01639)
append_entries: 2
Finish: 2025-02-04 15:01:07.931795
------------------------------------------------------
Started: 2025-02-04 18:00:58.678034
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-04 18:00:58.919135
------------------------------------------------------
Started: 2025-02-04 21:01:19.362943
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1153
Summarized using gpt-4o-mini
Append: [AlignVLM: 视觉文本对齐的新方法](https://arxiv.org/abs/2502.01341)
append_entries: 1
Finish: 2025-02-04 21:01:26.066975
------------------------------------------------------
Started: 2025-02-05 00:34:22.899420
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-05 00:34:23.083590
------------------------------------------------------
Started: 2025-02-05 03:11:24.108910
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1114
Summarized using gpt-4o-mini
Append: [通过过程监督提升长文生成质量](https://arxiv.org/abs/2502.02095)
Token length: 1302
Summarized using gpt-4o-mini
Append: [MakeAnything：针对多域程序生成的创新框架](https://arxiv.org/abs/2502.01572)
Token length: 1540
Summarized using gpt-4o-mini
Append: [RandLoRA：克服低秩适应的局限性并提高模型性能](https://arxiv.org/abs/2502.00987)
Token length: 1414
Summarized using gpt-4o-mini
Append: [UTGen: 提高单位测试生成与调试的有效性](https://arxiv.org/abs/2502.01619)
Token length: 1695
Summarized using gpt-4o-mini
Append: [相对信心估计在语言模型中的应用研究](https://arxiv.org/abs/2502.01126)
append_entries: 5
Finish: 2025-02-05 03:11:49.646476
------------------------------------------------------
Started: 2025-02-05 06:01:06.323385
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-05 06:01:06.573316
------------------------------------------------------
Started: 2025-02-05 09:00:54.263039
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1097
Summarized using gpt-4o-mini
Append: [加速扩散桥接模型的推理效果](https://arxiv.org/abs/2502.01362)
Token length: 1108
Summarized using gpt-4o-mini
Append: [改进的文本到图像模型定制方法](https://arxiv.org/abs/2502.01720)
Token length: 1481
Summarized using gpt-4o-mini
Append: [VideoJAM：提升视频生成模型运动一致性的框架](https://arxiv.org/abs/2502.02492)
Token length: 1370
Summarized using gpt-4o-mini
Append: [KV缓存压缩方法对大型语言模型能力的影响研究](https://arxiv.org/abs/2502.01941)
Token length: 1330
Summarized using gpt-4o-mini
Append: [利用强化学习提升编程模型的训练效果](https://arxiv.org/abs/2502.01718)
Token length: 1363
Summarized using gpt-4o-mini
Append: [QLASS：增强语言代理的步进搜索策略](https://arxiv.org/abs/2502.02584)
Token length: 1407
Summarized using gpt-4o-mini
Append: [Satori：通过链式行动思维提升大语言模型的推理能力](https://arxiv.org/abs/2502.02508)
append_entries: 7
Finish: 2025-02-05 09:01:49.174633
------------------------------------------------------
Started: 2025-02-05 12:12:49.357607
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-05 12:12:49.516033
------------------------------------------------------
Started: 2025-02-05 15:00:59.349108
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-05 15:00:59.533333
------------------------------------------------------
Started: 2025-02-05 18:00:52.296113
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1341
Summarized using gpt-4o-mini
Append: [基于采样的搜索：规模化趋势及自我验证能力的提升](https://arxiv.org/abs/2502.01839)
Token length: 1534
Summarized using gpt-4o-mini
Append: [Self-MoA: 提升大型语言模型性能的新方法](https://arxiv.org/abs/2502.00674)
Token length: 1154
Summarized using gpt-4o-mini
Append: [基于k稀疏自编码器的文本到图像生成模型概念操控框架](https://arxiv.org/abs/2501.19066)
append_entries: 3
Finish: 2025-02-05 18:01:10.607968
------------------------------------------------------
Started: 2025-02-05 21:01:17.509069
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-05 21:01:17.696403
------------------------------------------------------
Started: 2025-02-06 00:34:38.893565
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1109
Summarized using gpt-4o-mini
Append: [COCONut-PanCap数据集：提升全景分割与图像描述的革新](https://arxiv.org/abs/2502.02589)
append_entries: 1
Finish: 2025-02-06 00:34:43.988434
------------------------------------------------------
Started: 2025-02-06 03:11:28.502092
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1211
Summarized using gpt-4o-mini
Append: [大型语言模型激活近似的安全性评估](https://arxiv.org/abs/2502.00840)
Token length: 1336
Summarized using gpt-4o-mini
Append: [FSLoRA: 针对设备异构性的联合微调方法](https://arxiv.org/abs/2501.19389)
append_entries: 2
Finish: 2025-02-06 03:11:41.645864
------------------------------------------------------
Started: 2025-02-06 06:00:51.045741
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1430
Summarized using gpt-4o-mini
Append: [CADFusion：基于大型语言模型的文本到CAD转换框架](https://arxiv.org/abs/2501.19054)
append_entries: 1
Finish: 2025-02-06 06:00:55.714248
------------------------------------------------------
Started: 2025-02-06 09:00:44.182336
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1162
Summarized using gpt-4o-mini
Append: [基于潜在离散令牌的混合推理表示方法](https://arxiv.org/abs/2502.03275)
Token length: 1851
Summarized using gpt-4o-mini
Append: [挑战传统认知：LIMO模型在复杂推理中的突破](https://arxiv.org/abs/2502.03387)
Token length: 1238
Summarized using gpt-4o-mini
Append: [SmolLM2：高效的小型语言模型开发](https://arxiv.org/abs/2502.02737)
Token length: 1542
Summarized using gpt-4o-mini
Append: [基于粒子蒙特卡洛方法的推理时间缩放新方法](https://arxiv.org/abs/2502.01618)
Token length: 1577
Summarized using gpt-4o-mini
Append: [增强大语言模型推理能力的长链思维研究](https://arxiv.org/abs/2502.03373)
Token length: 1345
Summarized using gpt-4o-mini
Append: [AStar：基于蒙特卡洛树搜索的多模态推理新范式](https://arxiv.org/abs/2502.02339)
Token length: 1262
Summarized using gpt-4o-mini
Append: [利用大型语言模型模拟社会经济系统的多智能体框架](https://arxiv.org/abs/2502.01506)
append_entries: 7
Finish: 2025-02-06 09:01:20.554692
------------------------------------------------------
Started: 2025-02-06 12:12:49.346248
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 880
Summarized using gpt-4o-mini
Append: [利用JUMP与DUMP技术对大型语言模型进行越狱与防御](https://arxiv.org/abs/2502.01154)
Token length: 1071
Summarized using gpt-4o-mini
Append: [LayerTracer：认知对齐分层SVG生成框架](https://arxiv.org/abs/2502.01105)
append_entries: 2
Finish: 2025-02-06 12:12:56.351644
------------------------------------------------------
Started: 2025-02-06 15:00:53.904115
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1523
Summarized using gpt-4o-mini
Append: [语言模型知识蒸馏中的教师黑客现象研究](https://arxiv.org/abs/2502.02671)
append_entries: 1
Finish: 2025-02-06 15:01:12.657555
------------------------------------------------------
Started: 2025-02-06 18:01:09.483926
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1049
Summarized using gpt-4o-mini
Append: [PyCapsule：高效的自动代码生成框架](https://arxiv.org/abs/2502.02928)
append_entries: 1
Finish: 2025-02-06 18:01:14.824851
------------------------------------------------------
Started: 2025-02-06 21:01:53.284251
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1206
Summarized using gpt-4o-mini
Append: [针对RAG系统的成员推断攻击：自然文本查询的隐蔽性与有效性](https://arxiv.org/abs/2502.00306)
append_entries: 1
Finish: 2025-02-06 21:02:13.272481
------------------------------------------------------
Started: 2025-02-07 00:34:30.787791
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1088
Summarized using gpt-4o-mini
Append: [大型语言模型在软件开发任务中的一致性评估](https://arxiv.org/abs/2502.00226)
Token length: 1103
Summarized using gpt-4o-mini
Append: [激活信息合并：提升大语言模型性能的创新方法](https://arxiv.org/abs/2502.02421)
append_entries: 2
Finish: 2025-02-07 00:34:40.708120
------------------------------------------------------
Started: 2025-02-07 03:12:18.847841
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-07 03:12:19.060150
------------------------------------------------------
Started: 2025-02-07 06:01:07.003517
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-07 06:01:07.204138
------------------------------------------------------
Started: 2025-02-07 09:00:44.925981
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1268
Summarized using gpt-4o-mini
Append: [MAGA框架：解决大型语言模型预训练数据稀缺问题](https://arxiv.org/abs/2502.04235)
Json decode failed:
{
  "title": "Ola: 开创全模态理解的语言模型",
  "keyword": ["全模态模型", "图像理解", "多模态学习"],
  "short_summary": "Ola是一种竞争力强的全模态语言模型，提升了多种模态的理解能力。",
  "summary": "本文介绍了Ola，一个新型的全模态语言模型，能够在图像、视频和音频理解方面与专门的单模态模型竞争。Ola采用渐进的模态对齐策略，先通过图像和文本的训练建立基础，再加入语音和视频数据以扩展模型技能。该训练管道可以保持跨模态对齐数据相对较小，从而简化现有视觉-语言模型向全模态模型的开发，并降低成本。同时，为了实现类似于GPT-4o的交互体验，Ola还设计了一种逐句解码方案以实现流式语音生成。实验证明，Ola在所有模态方面超越现有的开放全模态语言模型，并在类似规模的专门模型中也表现出高度竞争力。我们希望Ola能成为一个完全开放的全模态理解解决方案，推动这一新兴领域的未来研究。模型权重、代码和数据已在https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 321 (char 450). Line: 406.
Append: [Ola: Pushing the Frontiers of Omni-Modal Language Model with Progressive Modality Alignment](https://arxiv.org/abs/2502.04328)
Token length: 1301
Summarized using gpt-4o-mini
Append: [动态内容增强技术在实景视频中的应用](https://arxiv.org/abs/2502.03621)
Token length: 1125
Summarized using gpt-4o-mini
Append: [基于3D几何的动态视频生成框架](https://arxiv.org/abs/2502.03639)
Token length: 1563
Summarized using gpt-4o-mini
Append: [MotionCanvas: 用户驱动的图像到视频生成镜头设计方法](https://arxiv.org/abs/2502.04299)
Token length: 1685
Summarized using gpt-4o-mini
Append: [全新统一框架MotionLab在人体动作生成与编辑中的应用](https://arxiv.org/abs/2502.02358)
Token length: 1354
Summarized using gpt-4o-mini
Append: [AlphaGeometry2：超越金牌选手的自动几何问题求解系统](https://arxiv.org/abs/2502.03544)
Token length: 1453
Summarized using gpt-4o-mini
Append: [通过单层变换器架构优化语音合成的计算扩展](https://arxiv.org/abs/2502.04128)
Token length: 934
Summarized using gpt-4o-mini
Append: [基于人类反馈的政策插值学习方法](https://arxiv.org/abs/2502.04270)
Token length: 1713
Summarized using gpt-4o-mini
Append: [BOLT：无须知识蒸馏的长链思维能力提升方法](https://arxiv.org/abs/2502.03860)
Token length: 999
Summarized using gpt-4o-mini
Append: [ScoreFlow：基于梯度优化的多智能体系统自动化工作流优化框架](https://arxiv.org/abs/2502.04306)
Token length: 1324
Summarized using gpt-4o-mini
Append: [提升大语言模型指令跟随能力的UltraIF方法](https://arxiv.org/abs/2502.04153)
Json decode failed:
{
  "title": "内容-格式集成提示优化方法研究",
  "keyword": ["大型语言模型", "提示设计", "CFPO"],
  "short_summary": "提出了一种内容与格式联合优化的提示设计方法CFPO，以提升大型语言模型的性能。",
  "summary": "本文介绍了一种新的提示优化方法——内容-格式集成提示优化（CFPO），该方法通过迭代优化过程同时优化提示的内容和格式。尽管近年来研究主要集中在优化提示内容，提示格式这一重要维度却鲜有系统性探讨。CFPO利用自然语言变异探索内容变化，并采用动态格式探索策略系统性评估不同格式选择。我们在多个任务和开源大型语言模型上进行的广泛评估表明，CFPO相对于仅优化内容的方法显示出可测量的性能提升，强调了集成内容与格式优化的重要性，并提供了一种实用的模型不可知性的方法来增强大型语言模型的表现。相关代码将发布在 https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 271 (char 405). Line: 406.
Append: [Beyond Prompt Content: Enhancing LLM Performance via Content-Format Integrated Prompt Optimization](https://arxiv.org/abs/2502.04295)
Token length: 948
Summarized using gpt-4o-mini
Append: [异构masked自回归模型用于机器人学习中的视频动态建模](https://arxiv.org/abs/2502.04296)
append_entries: 14
Finish: 2025-02-07 09:01:58.572239
------------------------------------------------------
Started: 2025-02-07 12:00:48.994089
Existing_entries: 1014
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 985
Summarized using gpt-4o-mini
Append: [ChartCitor：增强大语言模型的图表问答能力](https://arxiv.org/abs/2502.00989)
Token length: 1129
Summarized using gpt-4o-mini
Append: [语言模型监督能力的进展与相似性影响](https://arxiv.org/abs/2502.04313)
Token length: 1271
Summarized using gpt-4o-mini
Append: [大型语言模型的安全脆弱性与恶意攻击研究](https://arxiv.org/abs/2502.04322)
Token length: 946
Summarized using gpt-4o-mini
Append: [基于稀疏自编码器的跨层特征映射与控制方法](https://arxiv.org/abs/2502.03032)
append_entries: 4
Finish: 2025-02-07 12:01:19.241139
------------------------------------------------------
Started: 2025-02-07 15:00:48.960396
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1648
Summarized using gpt-4o-mini
Append: [Weak-to-Strong Diffusion框架实现生成模型性能提升](https://arxiv.org/abs/2502.00473)
Token length: 1421
Summarized using gpt-4o-mini
Append: [PlotGen：自动化科学数据可视化的多智能体框架](https://arxiv.org/abs/2502.00988)
Token length: 1879
Summarized using gpt-4o-mini
Append: [提升大型语言模型在低资源编程语言中的代码生成性能研究](https://arxiv.org/abs/2501.19085)
append_entries: 3
Finish: 2025-02-07 15:01:09.458583
------------------------------------------------------
Started: 2025-02-07 18:00:58.244761
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-07 18:00:58.493534
------------------------------------------------------
Started: 2025-02-07 21:00:36.008527
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1176
Summarized using gpt-4o-mini
Append: [ConceptAttention：增强多模态扩散转换器的可解释性](https://arxiv.org/abs/2502.04320)
append_entries: 1
Finish: 2025-02-07 21:00:41.644283
------------------------------------------------------
Started: 2025-02-08 00:33:15.262506
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-08 00:33:15.484938
------------------------------------------------------
Started: 2025-02-08 03:09:21.209061
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-08 03:09:21.496714
------------------------------------------------------
Started: 2025-02-08 06:00:56.740572
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-08 06:00:57.035193
------------------------------------------------------
Started: 2025-02-08 09:00:43.819376
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-08 09:00:44.001692
------------------------------------------------------
Started: 2025-02-08 12:10:42.303344
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-08 12:10:42.473568
------------------------------------------------------
Started: 2025-02-08 15:00:40.184724
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-08 15:00:40.442052
------------------------------------------------------
Started: 2025-02-08 18:00:38.420332
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-08 18:00:38.606993
------------------------------------------------------
Started: 2025-02-08 21:01:01.109177
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-08 21:01:01.409790
------------------------------------------------------
Started: 2025-02-09 00:37:00.305394
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-09 00:37:00.520479
------------------------------------------------------
Started: 2025-02-09 03:12:30.515724
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-09 03:12:30.802876
------------------------------------------------------
Started: 2025-02-09 06:00:48.654226
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-09 06:00:49.012638
------------------------------------------------------
Started: 2025-02-09 09:01:00.110212
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-09 09:01:00.344273
------------------------------------------------------
Started: 2025-02-09 12:11:05.946135
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-09 12:11:06.233549
------------------------------------------------------
Started: 2025-02-09 15:00:44.283634
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-09 15:00:44.518588
------------------------------------------------------
Started: 2025-02-09 18:01:02.487882
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-09 18:01:02.864906
------------------------------------------------------
Started: 2025-02-09 21:00:56.066203
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-09 21:00:56.343904
------------------------------------------------------
Started: 2025-02-10 00:35:52.830696
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-10 00:35:53.112954
------------------------------------------------------
Started: 2025-02-10 03:13:18.978905
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-10 03:13:19.249563
------------------------------------------------------
Started: 2025-02-10 06:00:46.361293
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-10 06:00:46.559066
------------------------------------------------------
Started: 2025-02-10 09:00:46.787309
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1054
Summarized using gpt-4o-mini
Append: [量化语言-图像预训练方法QLIP的研究](https://arxiv.org/abs/2502.05178)
Token length: 1363
Summarized using gpt-4o-mini
Append: [大语言模型在会议代理中的应用与挑战](https://arxiv.org/abs/2502.04376)
Token length: 1505
Summarized using gpt-4o-mini
Append: [基于强化学习的多语言安全防护模型生成框架](https://arxiv.org/abs/2502.05163)
Token length: 1378
Summarized using gpt-4o-mini
Append: [FlashVideo：一种双阶段框架提升文本到视频生成的效率与质量](https://arxiv.org/abs/2502.05179)
Token length: 1277
Summarized using gpt-4o-mini
Append: [滑动块注意力：提升视频生成效率的新方法](https://arxiv.org/abs/2502.04507)
Token length: 1114
Summarized using gpt-4o-mini
Append: [AuraFusion360：高质量三维场景补全的新方法](https://arxiv.org/abs/2502.05176)
Token length: 857
Summarized using gpt-4o-mini
Append: [Goku模型：图像与视频生成的新标杆](https://arxiv.org/abs/2502.04896)
Token length: 1725
Summarized using gpt-4o-mini
Append: [On-device Sora：基于扩散模型的手机端文本转视频生成](https://arxiv.org/abs/2502.04363)
Token length: 1167
Summarized using gpt-4o-mini
Append: [语言模型中的知识构成线性相关性研究](https://arxiv.org/abs/2502.04520)
Token length: 812
Summarized using gpt-4o-mini
Append: [一种新型语言模型架构的研究](https://arxiv.org/abs/2502.05171)
Token length: 1556
Summarized using gpt-4o-mini
Append: [基于PDDL的高效规划领域生成方法](https://arxiv.org/abs/2502.04728)
Token length: 955
Summarized using gpt-4o-mini
Append: [探索代理性：框架依赖性与强化学习的关系](https://arxiv.org/abs/2502.04403)
Token length: 1253
Summarized using gpt-4o-mini
Append: [新型自回溯机制提升大语言模型推理能力](https://arxiv.org/abs/2502.04404)
Token length: 1334
Summarized using gpt-4o-mini
Append: [VideoRoPE: 高效视频旋转位置嵌入的新方法](https://arxiv.org/abs/2502.05173)
Token length: 1355
Summarized using gpt-4o-mini
Append: [CodeSteer: 提升大型语言模型代码生成与文本推理能力的方法](https://arxiv.org/abs/2502.04350)
append_entries: 15
Finish: 2025-02-10 09:02:19.380972
------------------------------------------------------
Started: 2025-02-10 12:12:59.344861
Existing_entries: 1015
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-10 12:12:59.512920
------------------------------------------------------
Started: 2025-02-10 15:00:55.681890
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1192
Summarized using gpt-4o-mini
Append: [有效的多任务模型合并框架](https://arxiv.org/abs/2502.04959)
Token length: 1186
Summarized using gpt-4o-mini
Append: [CMoE：从稠密模型高效切 carve Mixture-of-Experts](https://arxiv.org/abs/2502.04416)
Token length: 1055
Summarized using gpt-4o-mini
Append: [ARR：提升大语言模型问答能力的新型零-shot提示方法](https://arxiv.org/abs/2502.04689)
Token length: 1667
Summarized using gpt-4o-mini
Append: [QuEST：基于4位权重的量化感知训练方法](https://arxiv.org/abs/2502.05003)
Token length: 1498
Summarized using gpt-4o-mini
Append: [深入探讨视觉Transformer中的patchification信息损失及其影响](https://arxiv.org/abs/2502.03738)
Token length: 1251
Summarized using gpt-4o-mini
Append: [YinYangAlign：提升文本图像系统对齐精准度的基准框架](https://arxiv.org/abs/2502.03512)
append_entries: 6
Finish: 2025-02-10 15:01:51.154751
------------------------------------------------------
Started: 2025-02-10 18:00:47.548719
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1024
Summarized using gpt-4o-mini
Append: [视觉时间理解能力的挑战：对多模态大语言模型的研究](https://arxiv.org/abs/2502.05092)
append_entries: 1
Finish: 2025-02-10 18:00:51.459779
------------------------------------------------------
Started: 2025-02-10 21:00:44.082835
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1325
Summarized using gpt-4o-mini
Append: [机器学习中可预测的深度强化学习方法的规模扩展](https://arxiv.org/abs/2502.04327)
append_entries: 1
Finish: 2025-02-10 21:00:48.056683
------------------------------------------------------
Started: 2025-02-11 00:34:25.171727
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1153
Summarized using gpt-4o-mini
Append: [CUT3R: 持续更新的3D重建框架](https://arxiv.org/abs/2501.12387)
append_entries: 1
Finish: 2025-02-11 00:34:28.719098
------------------------------------------------------
Started: 2025-02-11 03:12:19.586010
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 919
Summarized using gpt-4o-mini
Append: [VectorQ：动态阈值框架提升语义缓存的效率](https://arxiv.org/abs/2502.03771)
Token length: 1327
Summarized using gpt-4o-mini
Append: [SPARC：轻量级持续学习框架用于大语言模型](https://arxiv.org/abs/2502.02909)
Token length: 1834
Summarized using gpt-4o-mini
Append: [自主边缘计算在机器人和智能城市中的应用](https://arxiv.org/abs/2502.02692)
append_entries: 3
Finish: 2025-02-11 03:12:39.732171
------------------------------------------------------
Started: 2025-02-11 06:02:30.333854
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1131
Summarized using gpt-4o-mini
Append: [层次化草拟方法加速大型语言模型推理](https://arxiv.org/abs/2502.05609)
Token length: 1328
Summarized using gpt-4o-mini
Append: [ReasonFlux-32B：通过层次化思维模板优化推理能力](https://arxiv.org/abs/2502.06772)
Token length: 1206
Summarized using gpt-4o-mini
Append: [EVEv2.0：高效的无编码视觉语言模型](https://arxiv.org/abs/2502.06788)
Token length: 1452
Summarized using gpt-4o-mini
Append: [双重标题偏好优化：提升文本到图像扩散模型的图像质量](https://arxiv.org/abs/2502.06023)
Token length: 1407
Summarized using gpt-4o-mini
Append: [自适应并行编码技术提升上下文增强生成的效率](https://arxiv.org/abs/2502.05431)
Json decode failed:
{
  "title": "Steel-LLM：面向中文的开源语言模型开发",
  "short_summary": "Steel-LLM项目致力于开发高质量的中文语言模型。",
  "summary": "Steel-LLM是一个以中文为中心的语言模型，旨在尽管计算资源有限仍能开发出高质量的开源模型。该项目于2024年3月启动，计划训练一个包含10亿参数的模型，使用大规模数据集，强调透明度和实践经验分享，以帮助社区中的其他开发者。训练过程中主要使用中文数据，并少量包含英语数据，旨在填补现有开源LMM的空白，提供更详细的模型构建过程。Steel-LLM在CEVAL和CMMLU等基准测试中表现出色，超越了来自更大机构的早期模型。本文全面总结了项目的关键贡献，包括数据收集、模型设计、训练方法和所遇挑战，成为希望开发自身LMM的研究者和实践者的重要资源。模型检查点和训练脚本可在https:
  "keyword": [
    "中文语言模型",
    "开源项目",
    "Steel-LLM"
  ]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 308 (char 397). Line: 406.
Append: [Steel-LLM:From Scratch to Open Source -- A Personal Journey in Building a Chinese-Centric LLM](https://arxiv.org/abs/2502.06635)
Token length: 1360
Summarized using gpt-4o-mini
Append: [LM2: 一种增强记忆模块的变压器架构](https://arxiv.org/abs/2502.06049)
Token length: 1444
Summarized using gpt-4o-mini
Append: [提升Diffusion Transformers视频生成效率的方法](https://arxiv.org/abs/2502.06155)
Token length: 1563
Summarized using gpt-4o-mini
Append: [VISTA：减轻大规模视觉语言模型的幻觉现象](https://arxiv.org/abs/2502.03628)
append_entries: 9
Finish: 2025-02-11 06:03:29.499332
------------------------------------------------------
Started: 2025-02-11 09:00:50.862125
Existing_entries: 1009
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1347
Summarized using gpt-4o-mini
Append: [Show-o Turbo：提升多模态生成模型的效率](https://arxiv.org/abs/2502.05415)
Token length: 1697
Summarized using gpt-4o-mini
Append: [MetaChain：通过自然语言构建 LLM 代理的全自动框架](https://arxiv.org/abs/2502.05957)
Token length: 1406
Summarized using gpt-4o-mini
Append: [Matryoshka量化：一种创新的多尺度量化技术](https://arxiv.org/abs/2502.06786)
Token length: 1332
Summarized using gpt-4o-mini
Append: [Lumina-Video: 基于Next-DiT的视频生成框架](https://arxiv.org/abs/2502.06782)
Token length: 1267
Summarized using gpt-4o-mini
Append: [基于DFoT的视频扩散生成与历史指导](https://arxiv.org/abs/2502.06764)
Token length: 1536
Summarized using gpt-4o-mini
Append: [CustomVideoX：基于视频扩散变换器的个性化视频生成框架](https://arxiv.org/abs/2502.06527)
Token length: 1524
Summarized using gpt-4o-mini
Append: [测试时间扩展对大型语言模型性能的影响分析](https://arxiv.org/abs/2502.06703)
Token length: 1771
Summarized using gpt-4o-mini
Append: [OREAL：基于结果奖励的数学推理强化学习框架](https://arxiv.org/abs/2502.06781)
append_entries: 8
Finish: 2025-02-11 09:01:35.316151
------------------------------------------------------
Started: 2025-02-11 12:00:46.525574
Existing_entries: 1008
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1506
Summarized using gpt-4o-mini
Append: [深度的诅咒：改善大语言模型训练效能的层归一化缩放](https://arxiv.org/abs/2502.05795)
Token length: 1545
Summarized using gpt-4o-mini
Append: [通过自然语言训练多智能体有效沟通](https://arxiv.org/abs/2502.06060)
Token length: 973
Summarized using gpt-4o-mini
Append: [生成多语种平行文本去毒化数据的新方法](https://arxiv.org/abs/2502.06394)
Token length: 1125
Summarized using gpt-4o-mini
Append: [DreamDPO：基于人类偏好的3D内容生成框架](https://arxiv.org/abs/2502.04370)
append_entries: 4
Finish: 2025-02-11 12:01:14.075525
------------------------------------------------------
Started: 2025-02-11 15:00:46.701935
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-11 15:00:46.873812
------------------------------------------------------
Started: 2025-02-11 18:00:57.908161
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Summarization failed, append the original article
error: 'NoneType' object has no attribute 'group'. Line: 406.
Append: [CODESIM: Multi-Agent Code Generation and Problem Solving through Simulation-Driven Planning and Debugging](https://arxiv.org/abs/2502.05664)
append_entries: 1
Finish: 2025-02-11 18:01:02.690119
------------------------------------------------------
Started: 2025-02-11 21:00:38.086387
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-11 21:00:38.387507
------------------------------------------------------
Started: 2025-02-12 00:34:09.952241
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1433
Summarized using gpt-4o-mini
Append: [无须人工标注的互联网规模导航代理训练方法](https://arxiv.org/abs/2502.06776)
Token length: 1147
Summarized using gpt-4o-mini
Append: [开发新评价方法以提升语言条件机器人模型的安全性与效能](https://arxiv.org/abs/2411.18676)
append_entries: 2
Finish: 2025-02-12 00:34:22.176836
------------------------------------------------------
Started: 2025-02-12 03:11:20.981885
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1266
Summarized using gpt-4o-mini
Append: [Jakiro：提升猜测解码效率与准确性的混合推理策略](https://arxiv.org/abs/2502.06282)
append_entries: 1
Finish: 2025-02-12 03:11:25.331539
------------------------------------------------------
Started: 2025-02-12 06:00:51.339018
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1516
Summarized using gpt-4o-mini
Append: [Magic 1-For-1：高效的视频生成模型](https://arxiv.org/abs/2502.07701)
Token length: 1431
Summarized using gpt-4o-mini
Append: [揭示大语言模型的过拟合：C-BOD基准检测器](https://arxiv.org/abs/2502.07445)
Token length: 1535
Summarized using gpt-4o-mini
Append: [VidCRAFT3: 多视觉元素控件的图像到视频生成框架](https://arxiv.org/abs/2502.07531)
Token length: 1335
Summarized using gpt-4o-mini
Append: [CAD-Editor: 基于文本的计算机辅助设计编辑框架](https://arxiv.org/abs/2502.03997)
Token length: 773
Summarized using gpt-4o-mini
Append: [Enhance-A-Video：一种无训练的视频生成增强方法](https://arxiv.org/abs/2502.07508)
Token length: 1015
Summarized using gpt-4o-mini
Append: [大语言模型中的提示缓存及其隐私泄露风险](https://arxiv.org/abs/2502.07776)
Token length: 1652
Summarized using gpt-4o-mini
Append: [NatureLM：针对科学发现的序列基础模型](https://arxiv.org/abs/2502.07527)
Token length: 1141
Summarized using gpt-4o-mini
Append: [Hephaestus-Forge：提升LLM代理能力的大规模预训练数据集](https://arxiv.org/abs/2502.06589)
Token length: 1016
Summarized using gpt-4o-mini
Append: [百亿规模预训练视觉语言模型的潜力研究](https://arxiv.org/abs/2502.07617)
Token length: 1395
Summarized using gpt-4o-mini
Append: [CodeI/O：提升大语言模型推理能力的新方法](https://arxiv.org/abs/2502.07316)
Token length: 1738
Summarized using gpt-4o-mini
Append: [大规模语言模型在复杂推理中的长链思维训练研究](https://arxiv.org/abs/2502.07374)
Token length: 1330
Summarized using gpt-4o-mini
Append: [强化学习在大型语言模型上的应用及其在编程竞赛中的表现](https://arxiv.org/abs/2502.06807)
append_entries: 12
Finish: 2025-02-12 06:02:14.870733
------------------------------------------------------
Started: 2025-02-12 09:00:59.182078
Existing_entries: 1012
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1227
Summarized using gpt-4o-mini
Append: [FocalCodec：高效低比特率语音编解码器](https://arxiv.org/abs/2502.04465)
Token length: 929
Summarized using gpt-4o-mini
Append: [利用CTRL框架提升大语言模型生成代码的自我评估能力](https://arxiv.org/abs/2502.03492)
append_entries: 2
Finish: 2025-02-12 09:01:06.866491
------------------------------------------------------
Started: 2025-02-12 12:12:54.166263
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1630
Summarized using gpt-4o-mini
Append: [参数化技能扩展与组合框架的研究](https://arxiv.org/abs/2502.05932)
Token length: 1437
Summarized using gpt-4o-mini
Append: [Eclair：一种新型文档层次OCR文本提取工具](https://arxiv.org/abs/2502.04223)
Token length: 1506
Summarized using gpt-4o-mini
Append: [FailSafeQA：评估金融问答系统中LLM的鲁棒性与上下文意识](https://arxiv.org/abs/2502.06329)
append_entries: 3
Finish: 2025-02-12 12:13:13.054070
------------------------------------------------------
Started: 2025-02-12 15:01:05.038718
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1286
Summarized using gpt-4o-mini
Append: [Chain-of-Shot提示框架提升长视频理解能力](https://arxiv.org/abs/2502.06428)
Token length: 1012
Summarized using gpt-4o-mini
Append: [宽范围超参数对比例法则的影响研究](https://arxiv.org/abs/2502.06857)
Token length: 1389
Summarized using gpt-4o-mini
Append: [用于金融时间序列预测的检索增强生成框架](https://arxiv.org/abs/2502.05878)
Token length: 1491
Summarized using gpt-4o-mini
Append: [增强自回归预测的训练范式：掩码增强自回归预测（MEAP）](https://arxiv.org/abs/2502.07490)
append_entries: 4
Finish: 2025-02-12 15:01:35.111028
------------------------------------------------------
Started: 2025-02-12 18:10:06.141864
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1417
Summarized using gpt-4o-mini
Append: [Hypencoder：一种新型学习相关性评分的检索模型](https://arxiv.org/abs/2502.05364)
Token length: 1310
Summarized using gpt-4o-mini
Append: [Goedel-Prover：开源数学自动证明生成的新标杆](https://arxiv.org/abs/2502.07640)
Token length: 1122
Summarized using gpt-4o-mini
Append: [利用稀疏自编码器理解与操控视觉模型](https://arxiv.org/abs/2502.06755)
append_entries: 3
Finish: 2025-02-12 18:10:24.285330
------------------------------------------------------
Started: 2025-02-12 21:00:36.892564
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1146
Summarized using gpt-4o-mini
Append: [Pippo：从单张照片生成高分辨率人类视频的生成模型](https://arxiv.org/abs/2502.07785)
append_entries: 1
Finish: 2025-02-12 21:00:42.663860
------------------------------------------------------
Started: 2025-02-13 00:34:30.546908
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-13 00:34:30.723174
------------------------------------------------------
Started: 2025-02-13 03:11:55.734863
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-13 03:11:55.981399
------------------------------------------------------
Started: 2025-02-13 05:01:27.323809
Existing_entries: 0
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1550
Summarized using gpt-4o-mini
Append: [可学习的合规性放弃：提高大规模语言模型的决策可靠性](https://arxiv.org/abs/2502.06884)
Token length: 1146
Summarized using gpt-4o-mini
Append: [Pippo: 从单张照片生成高分辨率密集视频的多视角扩散模型](https://arxiv.org/abs/2502.07785)
Token length: 1417
Summarized using gpt-4o-mini
Append: [Hypencoder：一种新型请求编码器提升文档检索性能](https://arxiv.org/abs/2502.05364)
Token length: 1310
Summarized using gpt-4o-mini
Append: [Goedel-Prover：开源自动化数学证明生成的最优语言模型](https://arxiv.org/abs/2502.07640)
Token length: 1122
Summarized using gpt-4o-mini
Append: [通过稀疏自编码器理解与控制视觉模型](https://arxiv.org/abs/2502.06755)
Token length: 1286
Summarized using gpt-4o-mini
Append: [基于链式选片的长视频理解优化](https://arxiv.org/abs/2502.06428)
Token length: 1012
Summarized using gpt-4o-mini
Append: [深入探讨模型架构与超参数对缩放法则的影响](https://arxiv.org/abs/2502.06857)
Token length: 1389
Summarized using gpt-4o-mini
Append: [基于检索增强生成的金融时间序列预测框架](https://arxiv.org/abs/2502.05878)
Token length: 1491
Summarized using gpt-4o-mini
Append: [Mask-Enhanced Autoregressive Prediction：提升大型语言模型信息检索能力](https://arxiv.org/abs/2502.07490)
Token length: 1630
Summarized using gpt-4o-mini
Append: [参数化技能扩展与组合框架PSEC的研究](https://arxiv.org/abs/2502.05932)
Token length: 1437
Summarized using gpt-4o-mini
Append: [Eclair: 一种高效的文档级光学字符识别工具](https://arxiv.org/abs/2502.04223)
Token length: 1506
Summarized using gpt-4o-mini
Append: [FailSafeQA：评估金融领域LLM的鲁棒性与上下文意识的新基准](https://arxiv.org/abs/2502.06329)
Token length: 1227
Summarized using gpt-4o-mini
Append: [FocalCodec：一种高效的低比特率语音编解码器](https://arxiv.org/abs/2502.04465)
Token length: 929
Summarized using gpt-4o-mini
Append: [通过强化学习提升大语言模型的代码生成能力](https://arxiv.org/abs/2502.03492)
Json decode failed:
{
  "title": "Magic 1-For-1：高效视频生成模型",
  "keyword": ["视频生成", "模型优化", "扩散步骤蒸馏"],
  "short_summary": "本文介绍了一种高效的视频生成模型Magic 1-For-1，优化了内存消耗和延迟。",
  "summary": "本技术报告介绍了Magic 1-For-1 (Magic141)，一个优化内存占用和推理延迟的视频生成模型。该模型的核心思想是将文本到视频的生成任务分解为两个更简单的任务进行扩散步骤蒸馏：文本到图像生成和图像到视频生成。研究表明，使用相同的优化算法，图像到视频任务的收敛速度确实优于文本到视频任务。报告中还探讨了一系列优化技巧，从模型收敛速度、推理延迟加速和内存成本优化三个方面降低了图像到视频模型的训练计算成本。通过这些技术，我们能够在3秒内生成5秒的视频片段，并在一分钟内生成1分钟的视频，显著提高了视觉质量和动态效果。代码和模型参数可在 https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 293 (char 436). Line: 406.
Append: [Magic 1-For-1: Generating One Minute Video Clips within One Minute](https://arxiv.org/abs/2502.07701)
Token length: 1431
Summarized using gpt-4o-mini
Append: [Chameleon Benchmark Overfit Detector：评估大型语言模型的真实理解能力](https://arxiv.org/abs/2502.07445)
Token length: 1535
Summarized using gpt-4o-mini
Append: [VidCRAFT3: 一种精准控制多视觉元素的图像到视频生成框架](https://arxiv.org/abs/2502.07531)
Token length: 1335
Summarized using gpt-4o-mini
Append: [CAD-Editor: 基于文本的计算机辅助设计编辑框架](https://arxiv.org/abs/2502.03997)
Token length: 773
Summarized using gpt-4o-mini
Append: [Enhance-A-Video: 一种提升DiT生成视频的一体化方法](https://arxiv.org/abs/2502.07508)
Token length: 1015
Summarized using gpt-4o-mini
Append: [大语言模型中的提示缓存引发的隐私泄露风险](https://arxiv.org/abs/2502.07776)
Token length: 1652
Summarized using gpt-4o-mini
Append: [Nature语言模型：跨领域科学发现的基础模型](https://arxiv.org/abs/2502.07527)
Token length: 1141
Summarized using gpt-4o-mini
Append: [Hephaestus-Forge：提升LLM代理的预训练数据集](https://arxiv.org/abs/2502.06589)
Token length: 1016
Summarized using gpt-4o-mini
Append: [超大规模预训练视觉语言模型的实证研究](https://arxiv.org/abs/2502.07617)
Token length: 1395
Summarized using gpt-4o-mini
Append: [CodeI/O：提升大语言模型的推理能力](https://arxiv.org/abs/2502.07316)
Token length: 1738
Summarized using gpt-4o-mini
Append: [大规模语言模型中长链推理的训练与结构探索](https://arxiv.org/abs/2502.07374)
Token length: 1330
Summarized using gpt-4o-mini
Append: [大语言模型强化学习在编码与推理任务中的应用](https://arxiv.org/abs/2502.06807)
append_entries: 26
Finish: 2025-02-13 05:03:42.719102
------------------------------------------------------
Started: 2025-02-13 06:00:33.854743
Existing_entries: 26
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1725
Summarized using gpt-4o-mini
Append: [LASP-2: 提升线性注意力变换器模型的序列并行ism方法](https://arxiv.org/abs/2502.07563)
Token length: 1125
Summarized using gpt-4o-mini
Append: [CoCoMix：结合离散的下一个标记预测与连续概念的预训练框架](https://arxiv.org/abs/2502.08524)
Token length: 905
Summarized using gpt-4o-mini
Append: [基于计算预算的模型蒸馏性能估计研究](https://arxiv.org/abs/2502.08606)
Json decode failed:
{
  "title": "SARChat-2M：首个大规模SAR图像的多模态对话数据集",
  "keyword": ["合成孔径雷达", "视觉语言模型", "多模态数据集"],
  "short_summary": "本文提出SARChat-2M数据集，推动SAR图像的多模态理解与应用。",
  "summary": "本文创新性地提出了首个大规模合成孔径雷达（SAR）图像的多模态对话数据集——SARChat-2M，包含约200万个高质量的图像-文本对，涵盖多种场景和详细的目标注释。此数据集支持视觉理解和目标检测等关键任务，同时为SAR领域的视觉语言模型（VLMs）提供了评估基础，验证了VLM在SAR图像解读中的能力。通过对16个主流VLM进行实验，充分验证了该数据集的有效性，并成功建立了SAR领域的首个多任务对话基准。本项目将发布在https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 232 (char 381). Line: 406.
Append: [SARChat-Bench-2M: A Multi-Task Vision-Language Benchmark for SAR Image Interpretation](https://arxiv.org/abs/2502.08168)
Token length: 1357
Summarized using gpt-4o-mini
Append: [CineMaster：3D感知可控文本到视频生成框架](https://arxiv.org/abs/2502.08639)
Token length: 1414
Summarized using gpt-4o-mini
Append: [基于下一块预测的半自回归视频生成框架](https://arxiv.org/abs/2502.07737)
Token length: 1547
Summarized using gpt-4o-mini
Append: [评估大型语言模型在金融推理中的能力与改进](https://arxiv.org/abs/2502.08127)
Json decode failed:
{
  "title": "解决DPO中选择概率位移的优化方法",
  "keyword": ["Direct Preference Optimization", "选择概率", "人类偏好"],
  "short_summary": "提出一种新方法控制选择概率，优化语言模型对人类偏好的调节。",
  "summary": "本研究针对Direct Preference Optimization (DPO)及其变种在训练过程中出现的选择概率下降现象（即似然位移）提出了一种新的方法\method，旨在可控地转移选择概率分布。我们展示了该方法在提高选择概率与牺牲奖励边际之间存在根本的权衡关系，这一结论通过理论分析和实验验证得到了支持。此外，我们在下游任务，如MT-Bench和设计的胜率实验中，展示了\method优于传统DPO的性能。研究结果表明，通过这一简单且有理论基础的解决方案，可以有效缓解DPO的似然位移问题。"
}Summarization failed, append the original article
error: Invalid \escape: line 5 column 93 (char 243). Line: 406.
Append: [DPO-Shift: Shifting the Distribution of Direct Preference Optimization](https://arxiv.org/abs/2502.07599)
Token length: 1423
Summarized using gpt-4o-mini
Append: [TransMLA：提升语言模型通信效率的新方法](https://arxiv.org/abs/2502.07864)
append_entries: 9
Finish: 2025-02-13 06:01:28.440569
------------------------------------------------------
Started: 2025-02-13 09:01:01.328372
Existing_entries: 35
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-13 09:01:01.460858
------------------------------------------------------
Started: 2025-02-13 12:12:49.218663
Existing_entries: 35
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 771
Summarized using gpt-4o-mini
Append: [通过增强交叉注意机制实现大型模型知识传输至小型模型](https://arxiv.org/abs/2502.08213)
Token length: 964
Summarized using gpt-4o-mini
Append: [改进长效目标优化的语言模型探索方法](https://arxiv.org/abs/2502.06533)
Token length: 1244
Summarized using gpt-4o-mini
Append: [Animate Anyone 2: 结合环境语义的角色动画生成](https://arxiv.org/abs/2502.06145)
Token length: 1172
Summarized using gpt-4o-mini
Append: [BenchMAX：一种多语言评估基准以测量语言模型的高级能力](https://arxiv.org/abs/2502.07346)
Token length: 1232
Summarized using gpt-4o-mini
Append: [优化模型合并提升大语言模型性能](https://arxiv.org/abs/2502.04411)
Token length: 867
Summarized using gpt-4o-mini
Append: [动态安全框架优化语言模型推理安全](https://arxiv.org/abs/2502.07985)
Token length: 1251
Summarized using gpt-4o-mini
Append: [WorldGUI：一种新颖的GUI基准用于真实用户交互评估](https://arxiv.org/abs/2502.08047)
Token length: 1488
Summarized using gpt-4o-mini
Append: [建立值得信赖的检索增强生成（RAG）系统的综合路线图](https://arxiv.org/abs/2502.06872)
Token length: 1379
Summarized using gpt-4o-mini
Append: [NoLiMa基准评估长文本环境下大语言模型的检索能力](https://arxiv.org/abs/2502.05167)
Token length: 1475
Summarized using gpt-4o-mini
Append: [TextAtlas5M：评估长文本条件下的图像生成的新数据集](https://arxiv.org/abs/2502.07870)
Token length: 1473
Summarized using gpt-4o-mini
Append: [Light-A-Video：无训练的视频重光照方法](https://arxiv.org/abs/2502.08590)
append_entries: 11
Finish: 2025-02-13 12:13:45.803273
------------------------------------------------------
Started: 2025-02-13 15:00:44.182122
Existing_entries: 46
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-13 15:00:44.372192
------------------------------------------------------
Started: 2025-02-13 18:00:42.341364
Existing_entries: 46
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1199
Summarized using gpt-4o-mini
Append: [PDE-Controller: 利用大型语言模型控制偏微分方程系统](https://arxiv.org/abs/2502.00963)
append_entries: 1
Finish: 2025-02-13 18:00:48.105916
------------------------------------------------------
Started: 2025-02-13 21:01:06.910239
Existing_entries: 47
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-13 21:01:07.121627
------------------------------------------------------
Started: 2025-02-14 00:34:22.782704
Existing_entries: 47
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1522
Summarized using gpt-4o-mini
Append: [基于GEMINI学习的医疗图像密集对比表示学习](https://arxiv.org/abs/2502.05282)
append_entries: 1
Finish: 2025-02-14 00:34:28.150875
------------------------------------------------------
Started: 2025-02-14 03:11:39.967560
Existing_entries: 48
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-14 03:11:40.191424
------------------------------------------------------
Started: 2025-02-14 06:00:43.199482
Existing_entries: 48
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1546
Summarized using gpt-4o-mini
Append: [高质量合成多模态数据及其在mmE5模型中的应用](https://arxiv.org/abs/2502.08468)
Token length: 1391
Summarized using gpt-4o-mini
Append: [构建评估框架以提升多模态大型语言模型在体感代理中的应用](https://arxiv.org/abs/2502.09560)
Token length: 1273
Summarized using gpt-4o-mini
Append: [Skrr: 提高文本编码器在T2I扩散模型中的内存效率](https://arxiv.org/abs/2502.08690)
Token length: 1276
Summarized using gpt-4o-mini
Append: [InfiniteHiP：高效的长序列推理框架](https://arxiv.org/abs/2502.08910)
Token length: 1896
Summarized using gpt-4o-mini
Append: [TripoSG：高保真3D形状生成的新流行扩散模型](https://arxiv.org/abs/2502.06608)
Token length: 1217
Summarized using gpt-4o-mini
Append: [提升泰语大语言模型推理能力的方法研究](https://arxiv.org/abs/2502.09056)
Token length: 1080
Summarized using gpt-4o-mini
Append: [对大型语言模型理解能力的系统评估](https://arxiv.org/abs/2502.08946)
Token length: 920
Summarized using gpt-4o-mini
Append: [大型语言模型中的逻辑推理能力研究](https://arxiv.org/abs/2502.09100)
Token length: 918
Summarized using gpt-4o-mini
Append: [SelfCite：一种自监督方法生成高质量句子级引用](https://arxiv.org/abs/2502.09604)
append_entries: 9
Finish: 2025-02-14 06:01:31.351791
------------------------------------------------------
Started: 2025-02-14 09:00:52.947726
Existing_entries: 57
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1165
Summarized using gpt-4o-mini
Append: [ProbeLog：提高分类模型检索效率的新方法](https://arxiv.org/abs/2502.09619)
Token length: 1338
Summarized using gpt-4o-mini
Append: [CoSER: 高质量角色扮演语言模型数据集及评估协议](https://arxiv.org/abs/2502.09082)
Json decode failed:
{
  "title": "SQuARE：提升自然语言处理中的推理能力",
  "short_summary": "本文提出SQuARE，一种新型提示方法以改进LLM的推理能力。",
  "summary": "在自然语言处理领域，大型语言模型（LLMs）面临越来越复杂的推理挑战。传统的如链式思维（CoT）提示方法虽然展现出良好效果，但往往无法充分发挥模型的推理能力。本文提出了一种名为SQuARE（顺序问题回答推理引擎）的新型提示技术，旨在通过自我质询范式来改善推理。SQuARE鼓励模型在解决主要问题之前，生成和解决多个辅助问题，以更全面地探讨主题的各个方面。通过对Llama 3和GPT-4o模型进行的多项评估，结果显示SQuARE显著超越了传统的CoT提示方法和现有的重述-回答方法。SQuARE通过系统地分解查询，推动了LLM在推理任务中的能力发展。代码已公开，可在https:
  "keyword": ["自然语言处理", "推理能力", "大型语言模型"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 304 (char 395). Line: 406.
Append: [SQuARE: Sequential Question Answering Reasoning Engine for Enhanced Chain-of-Thought in Large Language Models](https://arxiv.org/abs/2502.09390)
Token length: 1557
Summarized using gpt-4o-mini
Append: [无编码器架构在3D理解中的应用探索](https://arxiv.org/abs/2502.09620)
Token length: 1364
Summarized using gpt-4o-mini
Append: [MME-CoT：评估大型多模态模型的链式思维推理性能](https://arxiv.org/abs/2502.09621)
Token length: 1111
Summarized using gpt-4o-mini
Append: [Typhoon T1：开放的泰语推理模型开发](https://arxiv.org/abs/2502.09042)
Token length: 1487
Summarized using gpt-4o-mini
Append: [CoT-Valve: 动态控制推理链长度的方法](https://arxiv.org/abs/2502.09601)
append_entries: 7
Finish: 2025-02-14 09:01:44.588014
------------------------------------------------------
Started: 2025-02-14 12:00:47.960997
Existing_entries: 64
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1773
Summarized using gpt-4o-mini
Append: [通用神经追踪控制器的开发与应用](https://arxiv.org/abs/2502.09614)
Token length: 1815
Summarized using gpt-4o-mini
Append: [3CAD：用于工业缺陷检测的新型大规模数据集与检测框架](https://arxiv.org/abs/2502.05761)
append_entries: 2
Finish: 2025-02-14 12:00:58.034763
------------------------------------------------------
Started: 2025-02-14 15:00:44.465819
Existing_entries: 66
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1897
Summarized using gpt-4o-mini
Append: [VFX Creator: 基于AI的可控视觉效果生成新范式](https://arxiv.org/abs/2502.05979)
append_entries: 1
Finish: 2025-02-14 15:00:50.658285
------------------------------------------------------
Started: 2025-02-14 18:00:45.710920
Existing_entries: 67
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1358
Summarized using gpt-4o-mini
Append: [GSM-Ranges：评估大语言模型数学推理能力的新方法](https://arxiv.org/abs/2502.08680)
append_entries: 1
Finish: 2025-02-14 18:00:52.280324
------------------------------------------------------
Started: 2025-02-14 21:00:42.643197
Existing_entries: 68
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-14 21:00:42.829261
------------------------------------------------------
Started: 2025-02-15 00:33:43.668780
Existing_entries: 68
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-15 00:33:43.811823
------------------------------------------------------
Started: 2025-02-15 03:09:57.076670
Existing_entries: 68
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-15 03:09:57.252607
------------------------------------------------------
Started: 2025-02-15 06:00:53.212196
Existing_entries: 68
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1195
Summarized using gpt-4o-mini
Append: [新框架提升二维潜在空间的三维重建效果](https://arxiv.org/abs/2502.09613)
append_entries: 1
Finish: 2025-02-15 06:00:58.728035
------------------------------------------------------
Started: 2025-02-15 09:00:38.635508
Existing_entries: 69
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-15 09:00:38.852695
------------------------------------------------------
Started: 2025-02-15 12:10:58.850633
Existing_entries: 69
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-15 12:10:58.995437
------------------------------------------------------
Started: 2025-02-15 15:00:36.073702
Existing_entries: 69
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-15 15:00:36.246422
------------------------------------------------------
Started: 2025-02-15 18:00:37.926630
Existing_entries: 69
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-15 18:00:38.287223
------------------------------------------------------
Started: 2025-02-15 21:00:40.735015
Existing_entries: 69
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-15 21:00:40.906400
------------------------------------------------------
Started: 2025-02-16 00:37:47.736963
Existing_entries: 69
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-16 00:37:47.895472
------------------------------------------------------
Started: 2025-02-16 03:15:08.527039
Existing_entries: 69
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-16 03:15:08.767151
------------------------------------------------------
Started: 2025-02-16 06:00:35.947648
Existing_entries: 69
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-16 06:00:36.078887
------------------------------------------------------
Started: 2025-02-16 09:00:38.719136
Existing_entries: 69
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-16 09:00:38.889019
------------------------------------------------------
Started: 2025-02-16 12:00:41.929584
Existing_entries: 69
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-16 12:00:42.249105
------------------------------------------------------
Started: 2025-02-16 15:00:34.239231
Existing_entries: 69
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-16 15:00:34.423630
------------------------------------------------------
Started: 2025-02-16 18:00:53.149638
Existing_entries: 69
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-16 18:00:53.414377
------------------------------------------------------
Started: 2025-02-16 21:00:57.626840
Existing_entries: 69
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-16 21:00:57.776165
------------------------------------------------------
Started: 2025-02-17 00:36:44.630563
Existing_entries: 69
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-17 00:36:44.794506
------------------------------------------------------
Started: 2025-02-17 03:14:50.934691
Existing_entries: 69
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-17 03:14:51.167046
------------------------------------------------------
Started: 2025-02-17 06:00:55.216649
Existing_entries: 69
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1281
Summarized using gpt-4o-mini
Append: [利用LLM进行反监测的创新方法及其潜在风险](https://arxiv.org/abs/2502.09638)
Token length: 1121
Summarized using gpt-4o-mini
Append: [LLaDA：突破自回归模型的扩散模型探索](https://arxiv.org/abs/2502.09992)
Token length: 1262
Summarized using gpt-4o-mini
Append: [多模型推理方法提升LLM在高级数学和编码任务中的表现](https://arxiv.org/abs/2502.09955)
Token length: 1401
Summarized using gpt-4o-mini
Append: [傅里叶数字嵌入方法及其在大语言模型中的应用](https://arxiv.org/abs/2502.09741)
Token length: 1851
Summarized using gpt-4o-mini
Append: [MM-RLHF: 提升多模态大语言模型对人类偏好的对齐研究](https://arxiv.org/abs/2502.10391)
Token length: 1445
Summarized using gpt-4o-mini
Append: [Step-Video-T2V：先进的文本生成视频预训练模型](https://arxiv.org/abs/2502.10248)
Token length: 1638
Summarized using gpt-4o-mini
Append: [RAS：一种高效的动态采样策略以加速扩散模型](https://arxiv.org/abs/2502.10389)
Token length: 829
Summarized using gpt-4o-mini
Append: [ZeroBench：一项全新的视觉推理基准挑战大型多模态模型](https://arxiv.org/abs/2502.09696)
Token length: 1081
Summarized using gpt-4o-mini
Append: [基于时空记忆的智能代理框架STMA](https://arxiv.org/abs/2502.10177)
append_entries: 9
Finish: 2025-02-17 06:02:03.748844
------------------------------------------------------
Started: 2025-02-17 09:00:52.218288
Existing_entries: 78
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1427
Summarized using gpt-4o-mini
Append: [通过局部化关注层提升扩散模型文本生成能力](https://arxiv.org/abs/2502.09935)
Token length: 1501
Summarized using gpt-4o-mini
Append: [MR采样器：加速可控生成中的扩散模型采样过程](https://arxiv.org/abs/2502.07856)
Token length: 1478
Summarized using gpt-4o-mini
Append: [基于大语言模型的车辆间合作感知与规划研究](https://arxiv.org/abs/2502.09980)
append_entries: 3
Finish: 2025-02-17 09:01:15.523265
------------------------------------------------------
Started: 2025-02-17 12:00:44.269336
Existing_entries: 81
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "利用适配器优化预训练模型在多变量时间序列预测中的应用",
  "keyword": ["预训练模型", "时间序列预测", "适配器"],
  "short_summary": "本研究提出适配器以提升预训练模型在多变量时间序列预测中的表现。",
  "summary": "预训练基础模型在单变量时间序列预测中表现优异，但在处理特征间复杂依赖和预测不确定性方面仍面临挑战。本文通过引入适配器，解决这些限制，适配器通过将多变量输入投影到合适的潜在空间，使预训练的单变量时间序列模型能够独立地应用于每个维度。受表示学习和部分随机贝叶斯神经网络文献的启发，我们提出了一系列适配器及优化和推理策略。通过在合成和真实数据集上的实验，结果表明适配器能够显著提高预测准确性和不确定性量化能力。我们的框架AdaPTS将适配器视为一种模块化、可扩展且有效的解决方案，以提升时间序列模型在多变量中的应用，促进其在实际应用中的更广泛采用。代码已发布在 https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 299 (char 436). Line: 406.
Append: [AdaPTS: Adapting Univariate Foundation Models to Probabilistic Multivariate Time Series Forecasting](https://arxiv.org/abs/2502.10235)
Token length: 1685
Summarized using gpt-4o-mini
Append: [VibeGen：基于生成AI的蛋白质动态设计框架](https://arxiv.org/abs/2502.10173)
Token length: 1218
Summarized using gpt-4o-mini
Append: [通过新词开发理解人工智能的语言](https://arxiv.org/abs/2502.07586)
append_entries: 3
Finish: 2025-02-17 12:01:03.445755
------------------------------------------------------
Started: 2025-02-17 15:00:54.173241
Existing_entries: 84
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1609
Summarized using gpt-4o-mini
Append: [高效多级卷积架构在3D视觉定位中的应用](https://arxiv.org/abs/2502.10392)
Json decode failed:
{
  "title": "基于进化搜索的训练感知结构化剪枝方法",
  "short_summary": "提出一种提高大语言模型剪枝效率的新方法。",
  "summary": "本文提出了一种名为\sysname的训练感知结构化剪枝方法，旨在提高大语言模型的压缩效率，同时保持性能。研究表明，现有模型在剪枝时对不同组件的敏感度不同，因此非均匀模型压缩显得尤为重要。该方法基于进化搜索过程，通过生成多个后代模型并进行选择，进行剪枝，并结合轻量级的多步骤训练，逐步提升训练数据的使用效率。实验结果显示，\sysname在Llama-2-7B、Llama-3.1-8B和Qwen-2.5-14B-Instruct模型上取得了优秀性能，特别是在后期训练中，\sysname的表现优于ShearedLlama，但所需训练数据量减少了五倍。",
  "keyword": ["结构化剪枝", "训练感知", "进化搜索"]
}Summarization failed, append the original article
error: Invalid \escape: line 4 column 24 (char 101). Line: 406.
Append: [DarwinLM: Evolutionary Structured Pruning of Large Language Models](https://arxiv.org/abs/2502.07780)
Token length: 936
Summarized using gpt-4o-mini
Append: [ImageRAG：基于检索增强生成的图像合成方法](https://arxiv.org/abs/2502.09411)
Token length: 1489
Summarized using gpt-4o-mini
Append: [小型多语言模型在低资源语言处理中的适应性研究](https://arxiv.org/abs/2502.10140)
Token length: 755
Summarized using gpt-4o-mini
Append: [CAPI：一种基于聚类的纯MIM框架及其在图像识别中的应用](https://arxiv.org/abs/2502.08769)
append_entries: 5
Finish: 2025-02-17 15:01:21.256927
------------------------------------------------------
Started: 2025-02-17 18:00:45.859648
Existing_entries: 89
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1403
Summarized using gpt-4o-mini
Append: [选择性自我监督微调方法（S3FT）提升大语言模型的泛化能力](https://arxiv.org/abs/2502.08130)
Token length: 1133
Summarized using gpt-4o-mini
Append: [CLaMP 3: 一种跨模态与跨语言音乐信息检索统一框架](https://arxiv.org/abs/2502.10362)
append_entries: 2
Finish: 2025-02-17 18:00:56.803345
------------------------------------------------------
Started: 2025-02-17 21:00:40.920757
Existing_entries: 91
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-17 21:00:41.299330
------------------------------------------------------
Started: 2025-02-18 00:34:07.091199
Existing_entries: 91
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1431
Summarized using gpt-4o-mini
Append: [深度分析大型推理模型中的过度思考现象](https://arxiv.org/abs/2502.08235)
append_entries: 1
Finish: 2025-02-18 00:34:21.708070
------------------------------------------------------
Started: 2025-02-18 03:10:54.573150
Existing_entries: 92
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-18 03:10:54.723316
------------------------------------------------------
Started: 2025-02-18 06:00:43.253222
Existing_entries: 92
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-18 06:00:43.497170
------------------------------------------------------
Started: 2025-02-18 09:00:43.445115
Existing_entries: 92
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1304
Summarized using gpt-4o-mini
Append: [大型语言模型的数学推理能力研究](https://arxiv.org/abs/2502.11574)
Token length: 1266
Summarized using gpt-4o-mini
Append: [大型语言模型在语言复杂性测量任务中的表现研究](https://arxiv.org/abs/2502.11578)
Token length: 1243
Summarized using gpt-4o-mini
Append: [SysGen: 提升语言模型响应的系统消息生成管道](https://arxiv.org/abs/2502.11330)
Token length: 1115
Summarized using gpt-4o-mini
Append: [大型语言模型知识电路演化研究](https://arxiv.org/abs/2502.11196)
Token length: 1387
Summarized using gpt-4o-mini
Append: [探索大型语言模型作为代码执行替代者的能力](https://arxiv.org/abs/2502.11167)
Json decode failed:
{
  "title": "ReLearn：提升大型语言模型非学习效果的方法",
  "keyword": ["大型语言模型", "非学习", "数据增强"],
  "short_summary": "ReLearn提供了一种有效的非学习方法，提升生成质量并保留关键信息。",
  "summary": "当前大型语言模型的非学习方法主要依赖逆优化，虽能降低目标Token的概率，但却破坏了后续token的预测，从而影响了模型的整体性能和语言连贯性。针对这一问题，本文提出ReLearn，一个数据增强及微调的管道，并构建了综合评估框架，提出知识遗忘率（KFR）和知识保留率（KRR）来衡量知识层面的保存，以及语言评分（LS）来评估生成质量。实验结果表明，ReLearn能有效实现目标遗忘，同时保持高质量的输出。通过机制分析还表明，逆优化会干扰连贯文本的生成，而ReLearn则能够保护这一关键能力。代码可在 https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 272 (char 410). Line: 406.
Append: [ReLearn: Unlearning via Learning for Large Language Models](https://arxiv.org/abs/2502.11190)
Token length: 1511
Summarized using gpt-4o-mini
Append: [基于学习框架的人形机器人自动起立控制研究](https://arxiv.org/abs/2502.12152)
Json decode failed:
{
  "title": "SWE-Lancer：开源的自由软件工程任务基准",
  "keyword": ["自由职业", "软件工程", "AI经济影响"],
  "short_summary": "SWE-Lancer是一个包含1400多个自由软件工程任务的基准，旨在推动AI研究。",
  "summary": "SWE-Lancer是一个新的基准项目，涵盖来自Upwork的1400多个自由软件工程任务，真实的总价值达100万美元。该基准包括独立的工程任务，如50个缺陷修复和高达32,000美元的功能实现，以及需要选择技术实现提议的管理任务。独立任务通过由经验丰富的软件工程师三重验证的端到端测试进行评分，而管理决策则与原聘请的工程经理的选择进行比较。评价结果显示，现有的前沿模型仍无法有效解决大多数任务。为了促进未来的研究，项目团队开源了统一的Docker镜像和公共评估集SWE-Lancer Diamond，网址为https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 275 (char 421). Line: 406.
Append: [SWE-Lancer: Can Frontier LLMs Earn $1 Million from Real-World Freelance Software Engineering?](https://arxiv.org/abs/2502.12115)
Token length: 1397
Summarized using gpt-4o-mini
Append: [提升视频理解能力的开源多模态LLM video-SALMONN-o1](https://arxiv.org/abs/2502.11775)
Token length: 1084
Summarized using gpt-4o-mini
Append: [TalkHier：一种新型LLM-MA系统的结构化沟通框架](https://arxiv.org/abs/2502.11098)
Token length: 1424
Summarized using gpt-4o-mini
Append: [通过对例增强数学大语言模型的证明能力研究](https://arxiv.org/abs/2502.10454)
Token length: 1081
Summarized using gpt-4o-mini
Append: [Diffusion-Sharpening：一种优化采样轨迹的微调方法](https://arxiv.org/abs/2502.12146)
Token length: 1264
Summarized using gpt-4o-mini
Append: [HermesFlow：弥合多模态大语言模型理解与生成能力的差距](https://arxiv.org/abs/2502.12148)
Token length: 1091
Summarized using gpt-4o-mini
Append: [SAFE-SQL：自增强上下文学习提升Text-to-SQL性能](https://arxiv.org/abs/2502.11438)
Token length: 1385
Summarized using gpt-4o-mini
Append: [CRANE：一种增强推理能力的约束解码算法](https://arxiv.org/abs/2502.09061)
Token length: 983
Summarized using gpt-4o-mini
Append: [利用高质量LLM数据提升信息提取模型性能](https://arxiv.org/abs/2502.11275)
Token length: 1175
Summarized using gpt-4o-mini
Append: [合成数据增强在项目级证明导向编程中的应用](https://arxiv.org/abs/2502.11901)
append_entries: 17
Finish: 2025-02-18 09:02:04.930775
------------------------------------------------------
Started: 2025-02-18 12:12:53.281593
Existing_entries: 109
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 717
Summarized using gpt-4o-mini
Append: [Dyve：基于动态过程验证的语言模型错误检测增强工具](https://arxiv.org/abs/2502.11157)
Token length: 1392
Summarized using gpt-4o-mini
Append: [NSA：高效的长上下文稀疏注意力机制](https://arxiv.org/abs/2502.11089)
Token length: 502
Summarized using gpt-4o-mini
Append: [改进Adam优化器以缓解大语言模型中嵌入的各向异性问题](https://arxiv.org/abs/2502.08441)
Token length: 1159
Summarized using gpt-4o-mini
Append: [提升自动化事实核查工具的有效性](https://arxiv.org/abs/2502.09083)
Token length: 1459
Summarized using gpt-4o-mini
Append: [MagicArticulate：自动将静态3D模型转化为可动画资产的有效框架](https://arxiv.org/abs/2502.12135)
Token length: 1502
Summarized using gpt-4o-mini
Append: [ThinkDiff：增强图文扩散模型的多模态推理能力](https://arxiv.org/abs/2502.10458)
Token length: 1087
Summarized using gpt-4o-mini
Append: [深度神经网络模型中的直觉物理理解研究](https://arxiv.org/abs/2502.11831)
Token length: 1108
Summarized using gpt-4o-mini
Append: [量子属性预测中的预训练质量优于量](https://arxiv.org/abs/2502.11085)
Token length: 1345
Summarized using gpt-4o-mini
Append: [PhysReason：评估大语言模型物理推理能力的新基准](https://arxiv.org/abs/2502.12054)
append_entries: 9
Finish: 2025-02-18 12:13:37.021932
------------------------------------------------------
Started: 2025-02-18 15:00:56.779716
Existing_entries: 118
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-18 15:00:57.008528
------------------------------------------------------
Started: 2025-02-18 18:01:09.766308
Existing_entries: 118
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1254
Summarized using gpt-4o-mini
Append: [CALM：结合对话与智能能力的统一语言模型](https://arxiv.org/abs/2502.08820)
Token length: 1356
Summarized using gpt-4o-mini
Append: [模型编辑在问答系统中的评估与实践研究](https://arxiv.org/abs/2502.11177)
Token length: 1271
Summarized using gpt-4o-mini
Append: [MIKASA：增强记忆能力的强化学习基准](https://arxiv.org/abs/2502.10550)
append_entries: 3
Finish: 2025-02-18 18:01:38.245760
------------------------------------------------------
Started: 2025-02-18 21:00:41.780674
Existing_entries: 121
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1057
Summarized using gpt-4o-mini
Append: [EQ-VAE：提升潜在生成模型的等变性](https://arxiv.org/abs/2502.09509)
Token length: 1327
Summarized using gpt-4o-mini
Append: [多模态检索增强生成系统综述](https://arxiv.org/abs/2502.08826)
Token length: 1039
Summarized using gpt-4o-mini
Append: [IHEval：评估语言模型指令层级遵循能力的新基准](https://arxiv.org/abs/2502.08745)
Token length: 1401
Summarized using gpt-4o-mini
Append: [高效影响值估计的神经网络方法](https://arxiv.org/abs/2502.09969)
Token length: 1407
Summarized using gpt-4o-mini
Append: [合成多模态网络任务数据集和探索者代理的研究](https://arxiv.org/abs/2502.11357)
Token length: 1417
Summarized using gpt-4o-mini
Append: [ILIAS：用于实例级图像检索的新测试数据集](https://arxiv.org/abs/2502.11748)
append_entries: 6
Finish: 2025-02-18 21:01:17.869566
------------------------------------------------------
Started: 2025-02-19 00:34:36.979112
Existing_entries: 127
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-19 00:34:37.215241
------------------------------------------------------
Started: 2025-02-19 03:13:08.428103
Existing_entries: 127
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1255
Summarized using gpt-4o-mini
Append: [Decomposed Reward Models: 提取人类偏好的新方法](https://arxiv.org/abs/2502.13131)
Token length: 1161
Summarized using gpt-4o-mini
Append: [HEADINFER: 一种高效的长序列推理策略](https://arxiv.org/abs/2502.12574)
Json decode failed:
{
  "title": "Phantom: 一种统一的视频生成框架用于主题一致性",
  "keyword": [
    "视频生成",
    "主题一致性",
    "跨模态对齐"
  ],
  "short_summary": "Phantom框架实现主题一致性的视频生成，注重文本与图像的双模态平衡。",
  "summary": "随着基础模型在视频生成领域的持续发展，主题一致性的视频生成仍处于探索阶段。本文介绍了"主题到视频"的概念，通过提取参考图像中的主题元素，利用文本指令生成主题一致的视频。我们提出了Phantom，一个统一的视频生成框架，支持单一和多主题参考。Phantom重构了现有的文本到视频和图像到视频架构，重新设计了联合文本-图像注入模型，并通过文本-图像-视频三元组数据学习跨模态对齐。特别强调在人生成中的主题一致性，涵盖了现有的ID保持视频生成，同时提供了增强的优势。"
}Summarization failed, append the original article
error: Expecting ',' delimiter: line 9 column 58 (char 217). Line: 406.
Append: [Phantom: Subject-consistent video generation via cross-modal alignment](https://arxiv.org/abs/2502.11079)
Token length: 1261
Summarized using gpt-4o-mini
Append: [基于人群比较评估的LLM自动评价方法的改进](https://arxiv.org/abs/2502.12501)
Token length: 1405
Summarized using gpt-4o-mini
Append: [RealSyn：用于视觉-语言表示学习的真实与合成文本数据集](https://arxiv.org/abs/2502.12513)
Token length: 1483
Summarized using gpt-4o-mini
Append: [利用自然语言定义物体方向以增强机器人操作能力](https://arxiv.org/abs/2502.13143)
append_entries: 6
Finish: 2025-02-19 03:13:41.203954
------------------------------------------------------
Started: 2025-02-19 06:10:29.431538
Existing_entries: 133
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-19 06:10:29.640856
------------------------------------------------------
Started: 2025-02-19 09:00:49.171990
Existing_entries: 133
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 748
Summarized using gpt-4o-mini
Append: [Soundwave: 一种高效的语音到文本大语言模型训练方法](https://arxiv.org/abs/2502.12900)
Token length: 1527
Summarized using gpt-4o-mini
Append: [Magma：多模态AI代理任务的基础模型](https://arxiv.org/abs/2502.13130)
Token length: 1147
Summarized using gpt-4o-mini
Append: [测试时间缩放在大型语言模型中的应用与效果研究](https://arxiv.org/abs/2502.12215)
Token length: 1072
Summarized using gpt-4o-mini
Append: [SafeRoute：高效的安全守卫模型自适应路由方案](https://arxiv.org/abs/2502.12464)
Token length: 1098
Summarized using gpt-4o-mini
Append: [MUDD连接：提升Transformer跨层信息流动的有效方法](https://arxiv.org/abs/2502.12170)
Token length: 914
Summarized using gpt-4o-mini
Append: [XLM-SWCM：低资源语言文本生成的新框架](https://arxiv.org/abs/2502.10852)
Token length: 1365
Summarized using gpt-4o-mini
Append: [基于几何性质的连续扩散模型用于语言建模](https://arxiv.org/abs/2502.11564)
Token length: 876
Summarized using gpt-4o-mini
Append: [HealthGPT：融合医疗视觉的强大语言模型](https://arxiv.org/abs/2502.09838)
Token length: 1503
Summarized using gpt-4o-mini
Append: [mmMamba：一种线性复杂度的多模态状态空间模型框架](https://arxiv.org/abs/2502.13145)
Token length: 953
Summarized using gpt-4o-mini
Append: [FLAG-Trader：一种融合语言处理与强化学习的金融交易模型](https://arxiv.org/abs/2502.11433)
append_entries: 10
Finish: 2025-02-19 09:01:40.388861
------------------------------------------------------
Started: 2025-02-19 12:12:49.492954
Existing_entries: 143
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 980
Summarized using gpt-4o-mini
Append: [提升变换器性能的层集成记忆方法研究](https://arxiv.org/abs/2502.09245)
Token length: 1401
Summarized using gpt-4o-mini
Append: [增强大型语言模型的领域知识方法综述](https://arxiv.org/abs/2502.10708)
Token length: 1204
Summarized using gpt-4o-mini
Append: [增强的钙钛矿太阳能电池知识管理系统](https://arxiv.org/abs/2502.12669)
Token length: 1127
Summarized using gpt-4o-mini
Append: [OctoTools：一个面向多领域复杂推理任务的开放源框架](https://arxiv.org/abs/2502.11271)
Token length: 1209
Summarized using gpt-4o-mini
Append: [ARM4R：基于人类视频数据的自动回归机器人模型](https://arxiv.org/abs/2502.13142)
Token length: 1065
Summarized using gpt-4o-mini
Append: [基于动态提示的无提示微调方法研究](https://arxiv.org/abs/2502.12859)
append_entries: 6
Finish: 2025-02-19 12:13:20.758899
------------------------------------------------------
Started: 2025-02-19 15:00:48.235353
Existing_entries: 149
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1753
Summarized using gpt-4o-mini
Append: [Atom of Thoughts: 通过原子问题提升推理能力的框架](https://arxiv.org/abs/2502.12018)
Token length: 1100
Summarized using gpt-4o-mini
Append: [优化分布式训练的通信与计算重叠技术研究](https://arxiv.org/abs/2502.12996)
Token length: 1597
Summarized using gpt-4o-mini
Append: [金融领域文本嵌入基准测试与模型评估](https://arxiv.org/abs/2502.10990)
Token length: 1322
Summarized using gpt-4o-mini
Append: [序列令牌压缩的极限研究及优化潜力](https://arxiv.org/abs/2502.13063)
append_entries: 4
Finish: 2025-02-19 15:01:12.515856
------------------------------------------------------
Started: 2025-02-19 18:00:55.531712
Existing_entries: 153
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1102
Summarized using gpt-4o-mini
Append: [创新推理方法Flow-of-Options在AutoML中的应用](https://arxiv.org/abs/2502.12929)
Token length: 1229
Summarized using gpt-4o-mini
Append: [Text2World: 基于语言模型的符号世界模型生成新基准](https://arxiv.org/abs/2502.13092)
append_entries: 2
Finish: 2025-02-19 18:01:05.060632
------------------------------------------------------
Started: 2025-02-19 21:01:09.558705
Existing_entries: 155
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1286
Summarized using gpt-4o-mini
Append: [视觉模型在时间序列分析中的优势与未来研究方向](https://arxiv.org/abs/2502.08869)
append_entries: 1
Finish: 2025-02-19 21:01:14.586491
------------------------------------------------------
Started: 2025-02-20 00:34:50.061833
Existing_entries: 156
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1077
Summarized using gpt-4o-mini
Append: [基于注意力机制的YOLOv12框架提升目标检测性能](https://arxiv.org/abs/2502.12524)
append_entries: 1
Finish: 2025-02-20 00:35:01.064796
------------------------------------------------------
Started: 2025-02-20 03:12:53.046477
Existing_entries: 157
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1879
Summarized using gpt-4o-mini
Append: [提升大型语言模型决策能力的自动化奖励模型框架](https://arxiv.org/abs/2502.12130)
append_entries: 1
Finish: 2025-02-20 03:12:57.768387
------------------------------------------------------
Started: 2025-02-20 06:00:42.029363
Existing_entries: 158
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1127
Summarized using gpt-4o-mini
Append: [基于3DGS的闭环强化学习在自动驾驶中的应用](https://arxiv.org/abs/2502.13144)
Token length: 1058
Summarized using gpt-4o-mini
Append: [克服小模型学习差距的混合蒸馏策略](https://arxiv.org/abs/2502.12143)
Token length: 1578
Summarized using gpt-4o-mini
Append: [通过LongPO提升短文档LLM在长文档任务中的表现](https://arxiv.org/abs/2502.13922)
append_entries: 3
Finish: 2025-02-20 06:00:57.425928
------------------------------------------------------
Started: 2025-02-20 09:00:42.964917
Existing_entries: 161
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1062
Summarized using gpt-4o-mini
Append: [名字与身份：大型语言模型的偏见研究](https://arxiv.org/abs/2502.11995)
Token length: 1468
Summarized using gpt-4o-mini
Append: [SongGen：基于文本的可控歌曲生成模型](https://arxiv.org/abs/2502.13128)
Token length: 1130
Summarized using gpt-4o-mini
Append: [大型语言模型的安全对齐漏洞分析](https://arxiv.org/abs/2502.13946)
Token length: 1867
Summarized using gpt-4o-mini
Append: [Qwen2.5-VL：视觉语言系列最新旗舰模型](https://arxiv.org/abs/2502.13923)
Token length: 890
Summarized using gpt-4o-mini
Append: [提高大语言模型推理时效的信心评估](https://arxiv.org/abs/2502.13962)
Token length: 1401
Summarized using gpt-4o-mini
Append: [Thinking Preference Optimization：提升长链推理能力的有效方法](https://arxiv.org/abs/2502.13173)
Json decode failed:
{
  "title": "NExT-Mol：结合3D扩散与1D语言模型的分子生成新方法",
  "short_summary": "提出NExT-Mol，通过结合1D和3D模型，提升分子生成准确性。",
  "summary": "NExT-Mol是一种新型的基础模型，旨在结合1D SELFIES语言模型和3D扩散模型，以提高3D分子的生成性能。该模型首先利用经过广泛预训练的1D分子语言模型生成有效的1D分子，然后通过3D扩散模型预测生成分子的3D构象。通过扩大语言模型规模、改进扩散神经架构及应用1D到3D的迁移学习，NExT-Mol在分布相似度方面显著优于基线模型，同时保持分子的有效性。在GEOM-DRUGS数据集上，相较于以往模型，NExT-Mol在3D分子生成中实现了26%的相对提升，在QM9-2014数据集上则获得了13%的平均相对增益。我们的代码和预训练的检查点可在 https:
  "keyword": ["3D分子生成", "扩散模型", "语言模型"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 299 (char 401). Line: 406.
Append: [NExT-Mol: 3D Diffusion Meets 1D Language Modeling for 3D Molecule Generation](https://arxiv.org/abs/2502.12638)
Token length: 1238
Summarized using gpt-4o-mini
Append: [AdaptiveStep：基于自适应步长的过程奖励模型训练方法](https://arxiv.org/abs/2502.13943)
Token length: 953
Summarized using gpt-4o-mini
Append: [Crawl4LLM：基于优先评分的高效网页爬取方法](https://arxiv.org/abs/2502.13347)
Token length: 1179
Summarized using gpt-4o-mini
Append: [Autellix：优化LLM服务系统的高效调度方法](https://arxiv.org/abs/2502.13965)
Token length: 1005
Summarized using gpt-4o-mini
Append: [SearchRAG：提升医疗问答准确性的实时检索框架](https://arxiv.org/abs/2502.13233)
append_entries: 11
Finish: 2025-02-20 09:01:40.265438
------------------------------------------------------
Started: 2025-02-20 12:12:52.438888
Existing_entries: 172
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1264
Summarized using gpt-4o-mini
Append: [ActionPiece: 通过上下文增强的动作序列标记方法](https://arxiv.org/abs/2502.13581)
Token length: 1538
Summarized using gpt-4o-mini
Append: [Mixture-of-Memories: 提升线性序列建模的新架构](https://arxiv.org/abs/2502.13685)
append_entries: 2
Finish: 2025-02-20 12:13:04.201811
------------------------------------------------------
Started: 2025-02-20 15:00:41.423466
Existing_entries: 174
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-20 15:00:41.597643
------------------------------------------------------
Started: 2025-02-20 18:00:59.356838
Existing_entries: 174
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1071
Summarized using gpt-4o-mini
Append: [REFIND框架：改进大语言模型输出中的幻觉检测](https://arxiv.org/abs/2502.13622)
Token length: 1624
Summarized using gpt-4o-mini
Append: [LoRAM：高效的低秩适应训练方案](https://arxiv.org/abs/2502.13533)
Token length: 1609
Summarized using gpt-4o-mini
Append: [半监督异构领域适应中的可转移知识探讨](https://arxiv.org/abs/2502.13573)
Token length: 1467
Summarized using gpt-4o-mini
Append: [全球文化知识评估：GIMMICK多模态基准研究](https://arxiv.org/abs/2502.13766)
Json decode failed:
{
  "title": "高效小型语言模型的研发及其推理能力提升",
  "short_summary": "本文探讨了开发高效小型语言模型以提升推理能力的创新方法。",
  "summary": "随着大语言模型和多模态大语言模型在推理能力方面取得了显著进展，但仍面临高计算需求和隐私问题。本文专注于开发高效的小型语言模型（SLMs）和多模态小型语言模型（MSLMs），旨在保持竞争的推理能力。我们提出了一种创新的训练管道，以提升推理能力并便于在边缘设备上部署，同时实现了性能达到了最先进水平，并降低了开发成本。"InfR"旨在通过缩小模型规模来促进人工智能系统的进步，改善推理能力，降低采用门槛，并解决隐私问题。",
  "keyword": ["小型语言模型", "推理能力", "边缘设备"]
}Summarization failed, append the original article
error: Expecting ',' delimiter: line 4 column 173 (char 259). Line: 406.
Append: [InfiR : Crafting Effective Small Language Models and Multimodal Small Language Models in Reasoning](https://arxiv.org/abs/2502.11573)
append_entries: 5
Finish: 2025-02-20 18:01:32.109341
------------------------------------------------------
Started: 2025-02-20 21:00:57.175239
Existing_entries: 179
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1634
Summarized using gpt-4o-mini
Append: [推出大规模多语言文本嵌入基准（MMTEB）](https://arxiv.org/abs/2502.13595)
Token length: 1052
Summarized using gpt-4o-mini
Append: [AI驱动探索：优化机器学习工程的创新方法](https://arxiv.org/abs/2502.13138)
Json decode failed:
{
  "title": "MVL-SIB：针对低资源语言的多语言视觉-语言基准",
  "keyword": ["多语言基准", "视觉-语言模型", "低资源语言"],
  "short_summary": "MVL-SIB基准评估205种语言的视觉-语言模型表现，揭示低资源语言的表现不足。",
  "summary": "本文介绍了MVL-SIB，一个覆盖205种语言的多语言视觉-语言基准，解决了现有基准只能评估少数高资源语言的局限性。我们对多种开放权重的视觉-语言模型进行了评估，结果显示，在低资源语言的跨模态话题匹配中，这些模型的表现相较随机选择毫无改善，尤其是语言如N"Koo。此外，分析表明，相较于文本支持，视觉-语言模型在低资源语言的支持显著下降。观察还发现，开放权重的视觉-语言模型在处理多图像任务时，未能有效利用多个图像来表示话题。通过关联MVL-SIB与其他多语言视觉-语言基准的表现，我们强调MVL-SIB是检验视觉-语言模型多语言理解能力的重要工具。"
}Summarization failed, append the original article
error: Expecting ',' delimiter: line 5 column 143 (char 293). Line: 406.
Append: [MVL-SIB: A Massively Multilingual Vision-Language Benchmark for Cross-Modal Topical Matching](https://arxiv.org/abs/2502.12852)
Token length: 1169
Summarized using gpt-4o-mini
Append: [PGMR框架：提升自然语言生成SPARQL查询的准确性](https://arxiv.org/abs/2502.13369)
Token length: 1229
Summarized using gpt-4o-mini
Append: [SplatDiff：基于像素喷溅指导的视频扩散模型](https://arxiv.org/abs/2502.12752)
Token length: 982
Summarized using gpt-4o-mini
Append: [TESS 2：提升指令跟随能力的扩散语言模型](https://arxiv.org/abs/2502.13917)
append_entries: 6
Finish: 2025-02-20 21:01:29.255463
------------------------------------------------------
Started: 2025-02-21 00:35:01.424235
Existing_entries: 185
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1401
Summarized using gpt-4o-mini
Append: [基于真实对话的长效聊天机器人情感智能研究](https://arxiv.org/abs/2502.13270)
Token length: 903
Summarized using gpt-4o-mini
Append: [记忆代码：探索大型语言模型在长期互动中的局限性](https://arxiv.org/abs/2502.13791)
Token length: 1723
Summarized using gpt-4o-mini
Append: [大语言模型在相关性评估中的应用与挑战](https://arxiv.org/abs/2502.13908)
append_entries: 3
Finish: 2025-02-21 00:35:14.838524
------------------------------------------------------
Started: 2025-02-21 03:14:15.545186
Existing_entries: 188
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-21 03:14:15.785289
------------------------------------------------------
Started: 2025-02-21 06:00:39.880409
Existing_entries: 188
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-21 06:00:40.115197
------------------------------------------------------
Started: 2025-02-21 09:00:42.250706
Existing_entries: 188
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1627
Summarized using gpt-4o-mini
Append: [基于强化学习的量子码权重优化方法研究](https://arxiv.org/abs/2502.14372)
Token length: 1036
Summarized using gpt-4o-mini
Append: [语言模型的时间知识处理及其局部特征分析](https://arxiv.org/abs/2502.14258)
Token length: 1339
Summarized using gpt-4o-mini
Append: [Set-and-Sequence：动态概念个性化的视频生成框架](https://arxiv.org/abs/2502.14844)
Token length: 1287
Summarized using gpt-4o-mini
Append: [PC-Agent: 复杂交互环境下的分层代理框架](https://arxiv.org/abs/2502.14282)
Token length: 1238
Summarized using gpt-4o-mini
Append: [LongWriter-V-22k: 提升长文本生成能力的视觉语言模型](https://arxiv.org/abs/2502.14834)
Token length: 1379
Summarized using gpt-4o-mini
Append: [CoSyn框架：自动生成文本丰富的多模态数据](https://arxiv.org/abs/2502.14846)
Token length: 1222
Summarized using gpt-4o-mini
Append: [SigLIP 2：新一代多语言视觉-语言编码器](https://arxiv.org/abs/2502.14786)
Token length: 1640
Summarized using gpt-4o-mini
Append: [RelaCtrl：基于相关性指导的可控生成框架](https://arxiv.org/abs/2502.14377)
Token length: 881
Summarized using gpt-4o-mini
Append: [基于规则的强化学习在大型推理模型中的应用研究](https://arxiv.org/abs/2502.14768)
Token length: 1446
Summarized using gpt-4o-mini
Append: [评估大语言模型在多学科领域的知识和推理能力](https://arxiv.org/abs/2502.14739)
Token length: 1302
Summarized using gpt-4o-mini
Append: [增强语言模型的视觉空间推理能力的两阶段训练框架](https://arxiv.org/abs/2502.14669)
Token length: 1468
Summarized using gpt-4o-mini
Append: [Meta MLGym：评估与开发 LLM 代理的新框架与基准](https://arxiv.org/abs/2502.14499)
Json decode failed:
{
  "title": "S*: 一种新型混合测试时间扩展框架提升代码生成精度",
  "short_summary": "本文提出S*框架，提升代码生成模型的覆盖率与选择准确性。",
  "summary": "本文介绍了S*，一种新颖的混合测试时间扩展框架，旨在提升大型语言模型在代码生成领域的表现。S*结合了并行扩展和顺序扩展，显著提高了生成代码的覆盖率和选择准确性。它采用一种新颖的选择机制，能够适应性地生成对比输入，并结合执行基础的信息来准确识别正确解决方案。实验结果显示，S*在12种大型语言模型和推理模型中均表现出色，实现了：首先，3B模型在S*的辅助下超越GPT-4o-mini；其次，非推理模型在S*的支持下超越推理模型，S*处理的GPT-4o-mini在LiveCodeBench上超出o1-preview 3.7%；最后，S*还进一步提升了先进的推理模型的性能，例如，DeepSeek-R1-Distill-Qwen-32B在S*的支持下在LiveCodeBench上达到85.7%，接近88.5%的o1（高）。相关代码将在 https:
  "keyword": ["测试时间扩展", "代码生成", "大型语言模型"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 388 (char 481). Line: 406.
Append: [S*: Test Time Scaling for Code Generation](https://arxiv.org/abs/2502.14382)
append_entries: 13
Finish: 2025-02-21 09:02:00.808920
------------------------------------------------------
Started: 2025-02-21 12:12:45.608309
Existing_entries: 201
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1353
Summarized using gpt-4o-mini
Append: [改进长文本摘要的无结构证据引用方法](https://arxiv.org/abs/2502.14409)
Token length: 1853
Summarized using gpt-4o-mini
Append: [提升图像地理定位的综合框架与新方法](https://arxiv.org/abs/2502.13759)
append_entries: 2
Finish: 2025-02-21 12:12:53.922346
------------------------------------------------------
Started: 2025-02-21 15:00:39.819957
Existing_entries: 203
Fetching from https://rsshub.app/huggingface/daily-papers
Summarization failed, append the original article
error: 'NoneType' object has no attribute 'group'. Line: 406.
Append: [LLM-based User Profile Management for Recommender System](https://arxiv.org/abs/2502.14541)
Summarization failed, append the original article
error: 'NoneType' object has no attribute 'group'. Line: 406.
Append: [How Much Knowledge Can You Pack into a LoRA Adapter without Harming LLM?](https://arxiv.org/abs/2502.14502)
Summarization failed, append the original article
error: 'NoneType' object has no attribute 'group'. Line: 406.
Append: [How Much Do LLMs Hallucinate across Languages? On Multilingual Estimation of LLM Hallucination in the Wild](https://arxiv.org/abs/2502.12769)
Summarization failed, append the original article
error: 'NoneType' object has no attribute 'group'. Line: 406.
Append: [S$^2$R: Teaching LLMs to Self-verify and Self-correct via Reinforcement Learning](https://arxiv.org/abs/2502.12853)
append_entries: 4
Finish: 2025-02-21 15:01:23.494533
------------------------------------------------------
Started: 2025-02-21 18:00:53.882262
Existing_entries: 207
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-21 18:00:54.034350
------------------------------------------------------
Started: 2025-02-21 21:00:39.203515
Existing_entries: 207
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1432
Summarized using gpt-4o-mini
Append: [LServe：基于混合稀疏注意力的长序列大语言模型高效服务](https://arxiv.org/abs/2502.14866)
Token length: 1201
Summarized using gpt-4o-mini
Append: [提升大型多模态模型的视觉推理与可解释性的框架](https://arxiv.org/abs/2502.14044)
Token length: 873
Summarized using gpt-4o-mini
Append: [NaviClues数据集与Navig框架推动影像地理定位进步](https://arxiv.org/abs/2502.14638)
Token length: 1523
Summarized using gpt-4o-mini
Append: [HippoRAG 2: 近似人类长期记忆的高效检索增强生成框架](https://arxiv.org/abs/2502.14802)
Token length: 1314
Summarized using gpt-4o-mini
Append: [CLIPPER：用于叙述主张验证的合成数据生成方法](https://arxiv.org/abs/2502.14854)
append_entries: 5
Finish: 2025-02-21 21:00:59.723224
------------------------------------------------------
Started: 2025-02-22 00:33:20.879213
Existing_entries: 212
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1439
Summarized using gpt-4o-mini
Append: [S-VCO：提升大规模视觉语言模型对细粒度图像细节的敏感性](https://arxiv.org/abs/2502.13928)
Json decode failed:
{
  "title": "基于活跃学习的有机π功能材料分子设计",
  "keyword": ["分子发现", "增强学习", "活跃学习"],
  "short_summary": "提出了一种结合监督学习与活跃学习的分子设计新方法，生成新型吸收性分子。",
  "summary": "本研究解决了分子发现中生成具有离域特性的新型分子的挑战。虽然监督学习方法能够生成与已有数据集相似的高质量分子，但在推广至离域特性方面表现不足。强化学习虽然能探索新化学空间，但常常出现"奖励黑客"现象，生成不易合成的分子。为此，本研究整合了最先进的监督学习方法STGG+，构建了一个活跃学习循环，命名为STGG+AL。我们将STGG+AL应用于有机π功能材料的设计，特别是在两个挑战性任务上：1）生成具有高振荡强度的高吸收分子，2）设计在近红外（NIR）范围内具有合理振荡强度的吸收分子。通过时变密度泛函理论进行了分子验证与合理化，结果显示与现有的强化学习方法相比，本方法在生成高振荡强度的新分子方面效果显著。此外，我们开源了我们的活跃学习代码及包含290万种π共轭分子的Conjugated-xTB数据集，提供了近似振荡强度和吸收波长的函数（基于sTDA-xTB）。"
}Summarization failed, append the original article
error: Expecting ',' delimiter: line 5 column 107 (char 238). Line: 406.
Append: [Generating $π$-Functional Molecules Using STGG+ with Active Learning](https://arxiv.org/abs/2502.14842)
Token length: 1101
Summarized using gpt-4o-mini
Append: [CHASE框架：无人工参与的挑战性问题生成](https://arxiv.org/abs/2502.14678)
Json decode failed:
{
  "title": "Multimodal RewardBench: 新的多模态奖励模型评估基准",
  "short_summary": "推出Multimodal RewardBench以评估多模态奖励模型的表现。",
  "summary": "本文介绍了Multimodal RewardBench，一个涵盖六个领域的专家注释基准，以评估视觉语言模型（VLMs）中的多模态奖励模型。基准包括一般正确性、偏好、知识、推理、安全性和视觉问答等方面，共计5,211个注释的三元组（提示、选择的响应、拒绝的响应）。在对各种VLM评估器的测试中，甚至表现最好的模型如Gemini 1.5 Pro和Claude 3.5 Sonnet，整体准确率仅为72%。特别是在推理和安全性领域，大多数模型表现不佳。这些发现表明，Multimodal RewardBench为推动多领域奖励模型的发展提供了一个具有挑战性的测试平台，基准数据已发布于 https:
  "keyword": ["多模态", "奖励模型", "基准评估"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 311 (char 425). Line: 406.
Append: [Multimodal RewardBench: Holistic Evaluation of Reward Models for Vision Language Models](https://arxiv.org/abs/2502.14191)
append_entries: 4
Finish: 2025-02-22 00:33:38.140580
------------------------------------------------------
Started: 2025-02-22 03:09:46.562502
Existing_entries: 216
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-22 03:09:46.779509
------------------------------------------------------
Started: 2025-02-22 06:01:03.132360
Existing_entries: 216
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-22 06:01:03.272038
------------------------------------------------------
Started: 2025-02-22 09:00:48.973318
Existing_entries: 216
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1290
Summarized using gpt-4o-mini
Append: [MODis框架：基于多目标优化的数据集发现方法](https://arxiv.org/abs/2502.11262)
append_entries: 1
Finish: 2025-02-22 09:00:56.737014
------------------------------------------------------
Started: 2025-02-22 12:00:52.290972
Existing_entries: 217
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-22 12:00:52.477100
------------------------------------------------------
Started: 2025-02-22 15:00:38.022307
Existing_entries: 217
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-22 15:00:38.199379
------------------------------------------------------
Started: 2025-02-22 18:00:43.386749
Existing_entries: 217
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-22 18:00:43.530852
------------------------------------------------------
Started: 2025-02-22 21:00:54.652184
Existing_entries: 217
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-22 21:00:54.842410
------------------------------------------------------
Started: 2025-02-23 00:37:42.826061
Existing_entries: 217
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-23 00:37:43.118825
------------------------------------------------------
Started: 2025-02-23 03:15:22.753558
Existing_entries: 217
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-23 03:15:22.981921
------------------------------------------------------
Started: 2025-02-23 06:00:42.278556
Existing_entries: 217
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-23 06:00:42.484939
------------------------------------------------------
Started: 2025-02-23 09:00:56.337813
Existing_entries: 217
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-23 09:00:56.486566
------------------------------------------------------
Started: 2025-02-23 12:11:08.341738
Existing_entries: 217
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-23 12:11:08.494100
------------------------------------------------------
Started: 2025-02-23 15:00:36.409644
Existing_entries: 217
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-23 15:00:36.575018
------------------------------------------------------
Started: 2025-02-23 18:00:43.490300
Existing_entries: 217
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-23 18:00:43.720096
------------------------------------------------------
Started: 2025-02-23 21:00:39.199751
Existing_entries: 217
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-23 21:00:39.354177
------------------------------------------------------
Started: 2025-02-24 00:36:27.570921
Existing_entries: 217
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-24 00:36:27.790140
------------------------------------------------------
Started: 2025-02-24 03:16:40.783902
Existing_entries: 217
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-24 03:16:41.030129
------------------------------------------------------
Started: 2025-02-24 06:11:28.612694
Existing_entries: 217
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-24 06:11:28.773050
------------------------------------------------------
Started: 2025-02-24 09:00:52.096454
Existing_entries: 217
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1092
Summarized using gpt-4o-mini
Append: [大型语言模型中的上下文信息存储与量化](https://arxiv.org/abs/2502.15007)
Token length: 1677
Summarized using gpt-4o-mini
Append: [基于视频掩码重建的可泛化驾驶世界模型](https://arxiv.org/abs/2502.11663)
Token length: 1014
Summarized using gpt-4o-mini
Append: [CrossOver：灵活的跨模态三维场景理解框架](https://arxiv.org/abs/2502.15011)
Token length: 1293
Summarized using gpt-4o-mini
Append: [VLM^2-Bench：评估视觉语言模型的匹配线索能力](https://arxiv.org/abs/2502.12084)
Token length: 1306
Summarized using gpt-4o-mini
Append: [LightThinker：动态压缩增强大型语言模型推理效率](https://arxiv.org/abs/2502.15589)
Token length: 1915
Summarized using gpt-4o-mini
Append: [推动非代理性AI的发展以确保安全与创新](https://arxiv.org/abs/2502.15657)
Token length: 1337
Summarized using gpt-4o-mini
Append: [StructFlowBench：一项多轮指令跟随评估基准](https://arxiv.org/abs/2502.14494)
Token length: 1401
Summarized using gpt-4o-mini
Append: [UPCORE：平衡信息删除与模型保持的高效方法](https://arxiv.org/abs/2502.15082)
Token length: 1329
Summarized using gpt-4o-mini
Append: [PhotoDoodle：新型图像编辑框架促进艺术涂鸦](https://arxiv.org/abs/2502.14397)
Token length: 1755
Summarized using gpt-4o-mini
Append: [一种基于f散度最小化的扩散模型快速生成方法](https://arxiv.org/abs/2502.15681)
Token length: 1439
Summarized using gpt-4o-mini
Append: [使用SIFT技术提升大语言模型推理的准确性](https://arxiv.org/abs/2502.14922)
Token length: 1365
Summarized using gpt-4o-mini
Append: [利用深度强化学习提升大语言模型的模式遵循能力](https://arxiv.org/abs/2502.14905)
Token length: 1333
Summarized using gpt-4o-mini
Append: [Mol-LLaMA：跨学科的通用分子语言模型](https://arxiv.org/abs/2502.13449)
Token length: 953
Summarized using gpt-4o-mini
Append: [评估大型多模态模型的交互智能新工具与方法](https://arxiv.org/abs/2502.15027)
Token length: 1384
Summarized using gpt-4o-mini
Append: [大型语言模型在数学推理中的效率与准确性分析](https://arxiv.org/abs/2502.15631)
Token length: 1179
Summarized using gpt-4o-mini
Append: [SurveyX：高效自动化问卷生成系统](https://arxiv.org/abs/2502.14776)
append_entries: 16
Finish: 2025-02-24 09:02:25.979962
------------------------------------------------------
Started: 2025-02-24 12:13:26.234417
Existing_entries: 233
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-24 12:13:26.446329
------------------------------------------------------
Started: 2025-02-24 15:00:52.615343
Existing_entries: 233
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1187
Summarized using gpt-4o-mini
Append: [针对用户特定安全标准的LLM安全性评估新基准](https://arxiv.org/abs/2502.15086)
Token length: 1239
Summarized using gpt-4o-mini
Append: [WHAC框架：精确恢复人类模型与相机轨迹](https://arxiv.org/abs/2403.12959)
Json decode failed:
{
  "title": "韩国国家教育测试基准（KoNET）的设计与评估",
  "short_summary": "本文介绍了用于评估多模态生成AI系统的KoNET基准测试。",
  "summary": "本文提出了韩国国家教育测试基准（KoNET），旨在通过韩国国家教育测试评估多模态生成AI系统。KoNET包含四个考试：韩国小学通用教育发展测试（KoEGED）、中学考试（KoMGED）、高中考试（KoHGED）和大学入学能力测试（KoCSAT），这些考试以其严格的标准和多样化的问题著称，能够全面分析AI在不同教育水平的表现。KoNET专注于韩语，为较少探索的语言中的模型性能提供了深入见解。我们评估了一系列模型，包括开源模型、开放获取的API和封闭API，通过考查难度、学科多样性及人工错误率等方面进行分析。相关代码和数据集建构将完全开源，网址为 https:
  "keyword": [
    "KoNET",
    "多模态生成AI",
    "教育测试"
  ]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 296 (char 387). Line: 406.
Append: [Evaluating Multimodal Generative AI with Korean Educational Standards](https://arxiv.org/abs/2502.15422)
Token length: 1622
Summarized using gpt-4o-mini
Append: [大型语言模型情感边界处理评估框架的开放源代码基准](https://arxiv.org/abs/2502.14975)
Token length: 1560
Summarized using gpt-4o-mini
Append: [KITAB-Bench: 阿拉伯语OCR性能的新基准与挑战](https://arxiv.org/abs/2502.14949)
Token length: 1409
Summarized using gpt-4o-mini
Append: [快速高质量蛋白质骨架生成的ReQFlow方法](https://arxiv.org/abs/2502.14637)
Token length: 1362
Summarized using gpt-4o-mini
Append: [创新的混合块注意力机制提升长上下文任务效率](https://arxiv.org/abs/2502.13189)
Token length: 868
Summarized using gpt-4o-mini
Append: [JL1-CD数据集与多教师知识蒸馏框架在遥感影像变化检测中的应用](https://arxiv.org/abs/2502.13407)
append_entries: 8
Finish: 2025-02-24 15:01:38.707094
------------------------------------------------------
Started: 2025-02-24 18:00:43.106223
Existing_entries: 241
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-24 18:00:43.244496
------------------------------------------------------
Started: 2025-02-24 21:00:49.832365
Existing_entries: 241
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1351
Summarized using gpt-4o-mini
Append: [无调优身份保护文本到视频生成的新框架FantasyID](https://arxiv.org/abs/2502.13995)
Token length: 1270
Summarized using gpt-4o-mini
Append: [MedHallu：检测医疗领域大语言模型幻觉的新基准](https://arxiv.org/abs/2502.14302)
Token length: 812
Summarized using gpt-4o-mini
Append: [多语言风格嵌入模型mStyleDistance的介绍与应用](https://arxiv.org/abs/2502.15168)
Token length: 1104
Summarized using gpt-4o-mini
Append: [EgoSpeak：实时语音启动预测的创新框架](https://arxiv.org/abs/2502.14892)
append_entries: 4
Finish: 2025-02-24 21:01:08.073923
------------------------------------------------------
Started: 2025-02-25 00:35:40.858545
Existing_entries: 245
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1098
Summarized using gpt-4o-mini
Append: [Seq2Exp：精准预测基因表达的序列转表达网络](https://arxiv.org/abs/2502.13991)
Token length: 1479
Summarized using gpt-4o-mini
Append: [RareScale：结合语言模型与专家系统的罕见疾病诊断方法](https://arxiv.org/abs/2502.15069)
Token length: 1237
Summarized using gpt-4o-mini
Append: [利用Tree-of-Debate框架提升科学文献评估的创新性辩论](https://arxiv.org/abs/2502.14767)
Token length: 1501
Summarized using gpt-4o-mini
Append: [大语言模型在联合国决策中的应用研究](https://arxiv.org/abs/2502.14122)
append_entries: 4
Finish: 2025-02-25 00:35:55.270250
------------------------------------------------------
Started: 2025-02-25 03:16:13.964747
Existing_entries: 249
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-25 03:16:14.178845
------------------------------------------------------
Started: 2025-02-25 06:00:41.150834
Existing_entries: 249
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-25 06:00:41.366328
------------------------------------------------------
Started: 2025-02-25 09:00:50.109394
Existing_entries: 249
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1186
Summarized using gpt-4o-mini
Append: [多语种数学基准测试中的测试时间扩展方法研究](https://arxiv.org/abs/2502.17407)
Token length: 852
Summarized using gpt-4o-mini
Append: [开放权重模型影响力演变框架研究](https://arxiv.org/abs/2502.15987)
Token length: 1117
Summarized using gpt-4o-mini
Append: [Audio-FLAN: 统一音频理解与生成的指令调优数据集](https://arxiv.org/abs/2502.16584)
Token length: 779
Summarized using gpt-4o-mini
Append: [Slam：24小时内在单一GPU上训练高质量语言模型的Recipe](https://arxiv.org/abs/2502.15814)
Token length: 822
Summarized using gpt-4o-mini
Append: [CTM基准：评估语言模型的时间推理能力](https://arxiv.org/abs/2502.16922)
Token length: 1301
Summarized using gpt-4o-mini
Append: [DICEPTION：一种高效的通用视觉感知模型](https://arxiv.org/abs/2502.17157)
Token length: 1179
Summarized using gpt-4o-mini
Append: [GOAT：一种提升LoRA性能的新型专家模型框架](https://arxiv.org/abs/2502.16894)
Token length: 1014
Summarized using gpt-4o-mini
Append: [Mobile-Agent-V：基于视频指导的移动自动化框架](https://arxiv.org/abs/2502.17110)
Token length: 1475
Summarized using gpt-4o-mini
Append: [长上下文对大型语言模型的影响与挑战](https://arxiv.org/abs/2502.17129)
Token length: 1305
Summarized using gpt-4o-mini
Append: [CodeCriticBench：全面评估大型语言模型的代码批判能力](https://arxiv.org/abs/2502.16614)
Token length: 1475
Summarized using gpt-4o-mini
Append: [多模态不一致性推理基准的建立与评估](https://arxiv.org/abs/2502.16033)
Token length: 1207
Summarized using gpt-4o-mini
Append: [生成性人工智能系统发布及其接入性分析](https://arxiv.org/abs/2502.16701)
append_entries: 12
Finish: 2025-02-25 09:01:30.057618
------------------------------------------------------
Started: 2025-02-25 12:00:42.511855
Existing_entries: 261
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 999
Summarized using gpt-4o-mini
Append: [基于扩散模型的通用颜色一致性方法GCC](https://arxiv.org/abs/2502.17435)
Token length: 1241
Summarized using gpt-4o-mini
Append: [提升视觉语言模型在复杂机器人操作中的物理推理能力](https://arxiv.org/abs/2502.16707)
Token length: 918
Summarized using gpt-4o-mini
Append: [MONSTER：针对时间序列分类的大型数据集评估库](https://arxiv.org/abs/2502.15122)
Token length: 1666
Summarized using gpt-4o-mini
Append: [X-Dancer：基于音乐驱动的零样本人类舞蹈视频生成新方法](https://arxiv.org/abs/2502.17414)
Token length: 1145
Summarized using gpt-4o-mini
Append: [VideoGrain：实现细粒度视频编辑的零-shot方法](https://arxiv.org/abs/2502.17258)
Token length: 1053
Summarized using gpt-4o-mini
Append: [RIFLEx：高效视频生成的频率成分分析与应用](https://arxiv.org/abs/2502.15894)
append_entries: 6
Finish: 2025-02-25 12:01:10.423777
------------------------------------------------------
Started: 2025-02-25 15:01:02.032506
Existing_entries: 267
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1237
Summarized using gpt-4o-mini
Append: [TAME Agent Framework：构建去中心化层次多智能体系统](https://arxiv.org/abs/2502.15425)
Token length: 1504
Summarized using gpt-4o-mini
Append: [Stable-SPAM: 提高4位训练稳定性的优化器](https://arxiv.org/abs/2502.17055)
Token length: 1123
Summarized using gpt-4o-mini
Append: [社交媒体上信息获取与社区审核的互动研究](https://arxiv.org/abs/2502.14132)
Token length: 709
Summarized using gpt-4o-mini
Append: [布朗球面的连续CVS双射逆过程](https://arxiv.org/abs/2502.13074)
Json decode failed:
{
  "title": "M3-AGIQA：先进的AI生成图像质量评估框架",
  "keyword": ["AI生成图像", "质量评估", "多模态"],
  "short_summary": "提出M3-AGIQA框架，全面评估AI生成图像质量。",
  "summary": "随着AI生成图像模型的快速发展，评估其质量面临多维度的挑战，包括感知质量、提示对应性和真实性。为应对这些挑战，本文提出M3-AGIQA框架，该框架具有多模态、多轮次和多方面的特点，充分利用多模态大型语言模型的优势，对文本和图像进行联合编码。通过低秩适应（LoRA）微调，将先进的在线MLLM字幕能力提取到本地模型中。框架包括结构化的多轮评估机制，通过生成中间图像描述，深入洞察质量、对应性和真实性方面。为了使预测与人类感知判断对齐，框架结合了基于xLSTM的预测器和回归头，处理序列logits并预测平均意见分数（MOSs）。在多个基准数据集上进行的广泛实验表明，M3-AGIQA在捕捉AGI质量的细微差别方面表现出色，并且交叉数据集验证也确认了其强大的泛化能力。代码可在https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 357 (char 486). Line: 406.
Append: [M3-AGIQA: Multimodal, Multi-Round, Multi-Aspect AI-Generated Image Quality Assessment](https://arxiv.org/abs/2502.15167)
append_entries: 5
Finish: 2025-02-25 15:01:22.439884
------------------------------------------------------
Started: 2025-02-25 18:00:42.807889
Existing_entries: 272
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 985
Summarized using gpt-4o-mini
Append: [MegaLoc：多任务图像检索模型的研究](https://arxiv.org/abs/2502.17237)
append_entries: 1
Finish: 2025-02-25 18:00:46.003020
------------------------------------------------------
Started: 2025-02-25 21:00:45.327895
Existing_entries: 273
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1517
Summarized using gpt-4o-mini
Append: [Agentic Long-Context Understanding: 提升LLMs的复杂问题回答能力](https://arxiv.org/abs/2502.15920)
Token length: 1075
Summarized using gpt-4o-mini
Append: [基于大语言模型的房地产市场营销内容自动生成框架](https://arxiv.org/abs/2502.16810)
Token length: 1220
Summarized using gpt-4o-mini
Append: [评估大型语言模型的归纳推理能力：InductionBench基准介绍](https://arxiv.org/abs/2502.15823)
Token length: 1060
Summarized using gpt-4o-mini
Append: [量化技术在大语言模型安全性评估中的应用](https://arxiv.org/abs/2502.15799)
Token length: 933
Summarized using gpt-4o-mini
Append: [利用机器学习分析胸部X光片预测COVID-19病程严重性](https://arxiv.org/abs/2502.16622)
Token length: 1225
Summarized using gpt-4o-mini
Append: [提高机器翻译质量估计效率的模型](https://arxiv.org/abs/2502.14429)
append_entries: 6
Finish: 2025-02-25 21:01:08.584494
------------------------------------------------------
Started: 2025-02-26 00:35:04.473538
Existing_entries: 279
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1434
Summarized using gpt-4o-mini
Append: [多样化输入提示下的高质量3D形状和纹理生成框架](https://arxiv.org/abs/2502.14247)
Token length: 1285
Summarized using gpt-4o-mini
Append: [语音交互中的大音频模型(LAM)评估研究](https://arxiv.org/abs/2502.15919)
append_entries: 2
Finish: 2025-02-26 00:35:11.445981
------------------------------------------------------
Started: 2025-02-26 03:15:39.144691
Existing_entries: 281
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-26 03:15:39.304614
------------------------------------------------------
Started: 2025-02-26 06:10:50.047771
Existing_entries: 281
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1256
Summarized using gpt-4o-mini
Append: [MutaGReP: 基于变异的代码库计划搜索方法](https://arxiv.org/abs/2502.15872)
append_entries: 1
Finish: 2025-02-26 06:10:53.885132
------------------------------------------------------
Started: 2025-02-26 09:01:00.258373
Existing_entries: 282
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1118
Summarized using gpt-4o-mini
Append: [Scale-Distribution Decoupling: 稳定大规模语言模型训练的新方法](https://arxiv.org/abs/2502.15499)
Token length: 1370
Summarized using gpt-4o-mini
Append: [WebGames：评估通用网页浏览AI代理的新基准套件](https://arxiv.org/abs/2502.18356)
Token length: 1442
Summarized using gpt-4o-mini
Append: [兼顾人类听觉选择性的听觉注意驱动大型语言模型研究](https://arxiv.org/abs/2502.16794)
Token length: 1794
Summarized using gpt-4o-mini
Append: [基于难度聚类的下游性能预测框架在大语言模型中的应用](https://arxiv.org/abs/2502.17262)
Token length: 1247
Summarized using gpt-4o-mini
Append: [SpargeAttn：通用稀疏和量化注意力机制的实现](https://arxiv.org/abs/2502.18137)
Token length: 1722
Summarized using gpt-4o-mini
Append: [SWE-RL：通过强化学习提升软件工程领域的大语言模型推理能力](https://arxiv.org/abs/2502.18449)
Json decode failed:
{
  "title": "OmniAlign-V：提升多模态大型语言模型与人类偏好对齐的数据集",
  "keyword": ["多模态语言模型", "人类偏好对齐", "数据集"],
  "short_summary": "本文介绍了OmniAlign-V数据集，以增强多模态语言模型与人类偏好的对齐。", 
  "summary": "随着开源多模态大型语言模型（MLLMs）的最新进展，基础能力的增强仍然存在与人类偏好对齐的重要空白。本文提出了OmniAlign-V，一个包含20万高质量训练样本的数据集，涵盖多样化的图像、复杂问题和不同响应格式，旨在改善MLLMs与人类偏好的对齐情况。同时，我们还推出了MM-AlignBench，这是一项专门设计的人类标注基准，用于评估MLLMs在人类价值观方面的对齐情况。实验结果表明，使用Supervised Fine-Tuning（SFT）或Direct Preference Optimization（DPO）对MLLMs进行微调，结合OmniAlign-V能显著提升人类偏好对齐，同时在标准视觉问答基准上保持或增强其性能，保留其基本能力。我们的数据集、基准、代码和检查点已发布于 https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 368 (char 524). Line: 406.
Append: [OmniAlign-V: Towards Enhanced Alignment of MLLMs with Human Preference](https://arxiv.org/abs/2502.18411)
Token length: 1526
Summarized using gpt-4o-mini
Append: [匿名区域变换器（ART）：革命性的多层透明图像生成技术](https://arxiv.org/abs/2502.18364)
Token length: 1097
Summarized using gpt-4o-mini
Append: [KV-Edit：一种无训练的图像编辑背景一致性方法](https://arxiv.org/abs/2502.17363)
append_entries: 9
Finish: 2025-02-26 09:01:38.621200
------------------------------------------------------
Started: 2025-02-26 12:13:46.323830
Existing_entries: 291
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1585
Summarized using gpt-4o-mini
Append: [引入视觉感知标记提升多模态大语言模型性能](https://arxiv.org/abs/2502.17425)
Token length: 1063
Summarized using gpt-4o-mini
Append: [压缩LLM的最新进展与彩票模型假设](https://arxiv.org/abs/2502.17535)
Token length: 1057
Summarized using gpt-4o-mini
Append: [K-LoRA：一种无训练的内容与风格融合方法](https://arxiv.org/abs/2502.18461)
Token length: 922
Summarized using gpt-4o-mini
Append: [Shakti VLM：高效的视觉语言模型家族](https://arxiv.org/abs/2502.17092)
append_entries: 4
Finish: 2025-02-26 12:14:00.050665
------------------------------------------------------
Started: 2025-02-26 15:01:03.993860
Existing_entries: 295
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-26 15:01:04.205509
------------------------------------------------------
Started: 2025-02-26 18:01:11.250399
Existing_entries: 295
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 883
Summarized using gpt-4o-mini
Append: [LaTIM: 基于Mamba模型的细粒度令牌级可解释性方法](https://arxiv.org/abs/2502.15612)
append_entries: 1
Finish: 2025-02-26 18:01:15.096958
------------------------------------------------------
Started: 2025-02-26 21:00:43.528714
Existing_entries: 296
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1143
Summarized using gpt-4o-mini
Append: [统计学在大型语言模型中的作用与挑战](https://arxiv.org/abs/2502.17814)
Json decode failed:
{
  "title": "WiCkeD: 增强多项选择基准测试复杂性的方法",
  "keyword": ["多项选择", "WiCkeD", "基准测试"],
  "short_summary": "WiCkeD通过引入“无上述选项”来提升多项选择基准测试的难度。",
  "summary": "WiCkeD是一种简单的方法，通过随机将一个选项替换为“无上述选项”来提高现有多项选择基准的复杂性，这种方法通常用于教育测试。我们展示了WiCkeD可自动应用于任何现有基准，从而使其更具挑战性。我们将WiCkeD应用于六个流行的基准，并用其评估了18个开放权重的大型语言模型（LLMs）。相较于原始数据集模型的平均性能下降了12.1个百分点。在应用思维链法（chain-of-thought）于三个MMLU数据集时，WiCkeD变体的表现下降与直接使用LLMs时的观察结果相似，显示出WiCkeD同样对具有增强推理能力的模型具有挑战性。此外，WiCkeD还揭示出某些模型对额外推理的敏感性，提供了与原始基准测试相关的额外信息。我们的代码和数据已在https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 344 (char 480). Line: 406.
Append: [WiCkeD: A Simple Method to Make Multiple Choice Benchmarks More Challenging](https://arxiv.org/abs/2502.18316)
Token length: 1234
Summarized using gpt-4o-mini
Append: [基于提示的语言模型评估方法P2L的提案](https://arxiv.org/abs/2502.14855)
Token length: 1316
Summarized using gpt-4o-mini
Append: [提升大语言模型调优性能的可扩展偏好数据构建策略](https://arxiv.org/abs/2502.16825)
append_entries: 4
Finish: 2025-02-26 21:00:59.068338
------------------------------------------------------
Started: 2025-02-27 00:35:24.591963
Existing_entries: 300
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 976
Summarized using gpt-4o-mini
Append: [通过词汇课程学习提升语言模型的预训练效率](https://arxiv.org/abs/2502.17910)
Token length: 1052
Summarized using gpt-4o-mini
Append: [LDGen：高效的多语言文本到图像生成方法](https://arxiv.org/abs/2502.18302)
Token length: 1429
Summarized using gpt-4o-mini
Append: [多模态大语言模型在视觉识别中的效果与干预研究](https://arxiv.org/abs/2502.17422)
Json decode failed:
{
  "title": "Curie：提升科学实验可靠性的AI框架",
  "short_summary": "Curie框架通过三个模块提升科学实验的可靠性和可解释性。",
  "summary": "科学实验是人类进步的重要基石，但严格的实验自动化仍面临挑战。为此，本文提出Curie，一个AI代理框架，旨在通过三个关键组件提升实验的严谨性：内部严谨模块增强可靠性，外部严谨模块保持方法控制，以及实验知识模块增强可解释性。为评估Curie，设计了一个包含46个问题的新实验基准，覆盖四个计算机科学领域，所有问题均取自重要研究论文和广泛采用的开源项目。与测试的最强基线相比，Curie在正确回答实验问题上取得了3.4倍的提升。Curie的开源链接为：https:
  "keyword": ["AI框架", "科学实验", "自动化"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 245 (char 333). Line: 406.
Append: [Curie: Toward Rigorous and Automated Scientific Experimentation with AI Agents](https://arxiv.org/abs/2502.16069)
append_entries: 4
Finish: 2025-02-27 00:35:38.180751
------------------------------------------------------
Started: 2025-02-27 03:16:28.380092
Existing_entries: 304
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-27 03:16:28.591844
------------------------------------------------------
Started: 2025-02-27 06:00:47.273678
Existing_entries: 304
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-27 06:00:47.510977
------------------------------------------------------
Started: 2025-02-27 09:01:16.825232
Existing_entries: 304
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1514
Summarized using gpt-4o-mini
Append: [推出BIG-Bench Extra Hard：评估大型语言模型推理能力的新基准](https://arxiv.org/abs/2502.19187)
Token length: 1436
Summarized using gpt-4o-mini
Append: [提升语言模型反驳能力以加速科学发现](https://arxiv.org/abs/2502.19414)
Token length: 1455
Summarized using gpt-4o-mini
Append: [CritiQ：基于人类偏好的自动数据选择方法](https://arxiv.org/abs/2502.19279)
Token length: 1012
Summarized using gpt-4o-mini
Append: [PosterSum：科学海报总结的前沿基准](https://arxiv.org/abs/2502.17540)
Token length: 1322
Summarized using gpt-4o-mini
Append: [多语言模型的事实知识回忆与跨语言转移研究](https://arxiv.org/abs/2502.17955)
Token length: 1648
Summarized using gpt-4o-mini
Append: [首个希腊金融评估基准与语言模型的推出](https://arxiv.org/abs/2502.18772)
Token length: 1081
Summarized using gpt-4o-mini
Append: [Kanana系列双语语言模型的高效预训练与适应性方法](https://arxiv.org/abs/2502.18934)
Token length: 1121
Summarized using gpt-4o-mini
Append: [DeltaBench：评估o1-like模型在长推理链上的表现](https://arxiv.org/abs/2502.19361)
Token length: 1193
Summarized using gpt-4o-mini
Append: [利用量子力学知识提升3D分子表示的能谱预训练](https://arxiv.org/abs/2502.16284)
Token length: 1901
Summarized using gpt-4o-mini
Append: [AI助力科学发现：多智能体系统在生物医学领域的应用](https://arxiv.org/abs/2502.18864)
Token length: 1099
Summarized using gpt-4o-mini
Append: [AISafetyLab: 统一的AI安全框架与工具包](https://arxiv.org/abs/2502.16776)
Token length: 1087
Summarized using gpt-4o-mini
Append: [跨上下文蒸馏方法提升单目深度估计精度](https://arxiv.org/abs/2502.19204)
Token length: 1250
Summarized using gpt-4o-mini
Append: [基于Manim动画的定理解释视频生成与评估](https://arxiv.org/abs/2502.19400)
Token length: 1215
Summarized using gpt-4o-mini
Append: [一种结合可验证正确性信号的代理奖励建模方法](https://arxiv.org/abs/2502.19328)
Token length: 1360
Summarized using gpt-4o-mini
Append: [基于预训练值环境模型的无环境强化学习框架](https://arxiv.org/abs/2502.18906)
append_entries: 15
Finish: 2025-02-27 09:02:29.288020
------------------------------------------------------
Started: 2025-02-27 12:00:50.013857
Existing_entries: 319
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-27 12:00:50.168462
------------------------------------------------------
Started: 2025-02-27 15:00:41.996318
Existing_entries: 319
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1372
Summarized using gpt-4o-mini
Append: [知识单位：破解科学知识传播的版权壁垒](https://arxiv.org/abs/2502.19413)
Json decode failed:
{
  "title": "GHOST 2.0：一种用于头部交换的先进模型",
  "short_summary": "本文介绍了GHOST 2.0，一个用于高效头部交换的模型，克服了传统方法的局限。",
  "summary": "本文提出了GHOST 2.0，旨在解决人脸交换领域尚未深入研究的头部交换问题。头部交换在进行皮肤颜色转换的同时，还面临如何在合成过程中保持头部整体结构的信息以及如何填补交换头部与背景之间的空白等额外挑战。GHOST 2.0由两个特定模块组成：首先，增强的对齐模型用于头部重演，该模型在多个尺度上保留身份信息，对极端姿态变化具有良好的鲁棒性；其次，Blender模块将重演后的头部无缝融入目标背景，转移皮肤颜色并修补不匹配区域。实验结果表明，这两个模块在各自任务上都优于基线方法，实现了头部交换的最新技术水平。此外，本文还处理了源头与目标间发型差异较大的复杂情况。代码可在https:
  "keyword": ["头部交换", "模型", "计算机视觉"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 306 (char 408). Line: 406.
Append: [GHOST 2.0: generative high-fidelity one shot transfer of heads](https://arxiv.org/abs/2502.18417)
append_entries: 2
Finish: 2025-02-27 15:00:50.619416
------------------------------------------------------
Started: 2025-02-27 18:00:51.330735
Existing_entries: 321
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1009
Summarized using gpt-4o-mini
Append: [Rank1：基于测试时间计算的新型重排序模型](https://arxiv.org/abs/2502.18418)
Token length: 1589
Summarized using gpt-4o-mini
Append: [双重优化嵌入信息的方法提升弱监督语义分割性能](https://arxiv.org/abs/2502.15885)
append_entries: 2
Finish: 2025-02-27 18:01:01.365623
------------------------------------------------------
Started: 2025-02-27 21:00:47.361552
Existing_entries: 323
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1396
Summarized using gpt-4o-mini
Append: [基于少量偏好的个性化优化框架FSPO研究](https://arxiv.org/abs/2502.19312)
Token length: 1382
Summarized using gpt-4o-mini
Append: [Drop-Upcycling：提升混合专家模型训练效率的新方法](https://arxiv.org/abs/2502.19261)
append_entries: 2
Finish: 2025-02-27 21:01:00.092834
------------------------------------------------------
Started: 2025-02-28 00:35:24.339078
Existing_entries: 325
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1788
Summarized using gpt-4o-mini
Append: [多草稿推测解码的效率优化研究](https://arxiv.org/abs/2502.18779)
append_entries: 1
Finish: 2025-02-28 00:35:28.417349
------------------------------------------------------
Started: 2025-02-28 03:16:46.587594
Existing_entries: 326
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-02-28 03:16:46.859286
------------------------------------------------------
Started: 2025-02-28 06:10:38.689744
Existing_entries: 326
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1278
Summarized using gpt-4o-mini
Append: [提升大型多模态模型性能的新策略：测试时重路由](https://arxiv.org/abs/2502.20395)
Token length: 1239
Summarized using gpt-4o-mini
Append: [LongRoPE2：扩展大语言模型的上下文窗口](https://arxiv.org/abs/2502.20082)
Token length: 1369
Summarized using gpt-4o-mini
Append: [自我奖励推理大型语言模型的研究](https://arxiv.org/abs/2502.19613)
append_entries: 3
Finish: 2025-02-28 06:10:51.303159
------------------------------------------------------
Started: 2025-02-28 09:00:52.489857
Existing_entries: 329
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1239
Summarized using gpt-4o-mini
Append: [FINEREASON: 细粒度评估大语言模型推理能力的逻辑难题基准](https://arxiv.org/abs/2502.20238)
Token length: 1395
Summarized using gpt-4o-mini
Append: [Mobius：无注释文本生成无缝循环视频的新方法](https://arxiv.org/abs/2502.20307)
Token length: 1064
Summarized using gpt-4o-mini
Append: [FlexiDiT：一种动态计算预算的生成变换器](https://arxiv.org/abs/2502.20126)
Token length: 1510
Summarized using gpt-4o-mini
Append: [R1-Translator: 增强推理能力的通用机器翻译框架](https://arxiv.org/abs/2502.19735)
Token length: 1136
Summarized using gpt-4o-mini
Append: [UniTok：统一视觉生成与理解的新型离散标记器](https://arxiv.org/abs/2502.20321)
Token length: 1403
Summarized using gpt-4o-mini
Append: [CODESYNC：适应动态代码演变的语言模型评估基准](https://arxiv.org/abs/2502.16645)
Token length: 1230
Summarized using gpt-4o-mini
Append: [Subtask导向的强化微调（SoRFT）：提升大语言模型的issue解决能力](https://arxiv.org/abs/2502.20127)
append_entries: 7
Finish: 2025-02-28 09:01:31.787096
------------------------------------------------------
Started: 2025-02-28 12:00:47.110226
Existing_entries: 336
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1316
Summarized using gpt-4o-mini
Append: [MedVLM-R1：提升医疗图像分析的透明度与可信度](https://arxiv.org/abs/2502.19634)
Token length: 1469
Summarized using gpt-4o-mini
Append: [Dream Engine：一种高效的文本-图像交错控制生成框架](https://arxiv.org/abs/2502.20172)
Token length: 1281
Summarized using gpt-4o-mini
Append: [NeoBERT：下一代双向编码器的创新与突破](https://arxiv.org/abs/2502.19587)
Token length: 1277
Summarized using gpt-4o-mini
Append: [基于去耦价值策略优化的强化学习框架](https://arxiv.org/abs/2502.16944)
append_entries: 4
Finish: 2025-02-28 12:01:05.244462
------------------------------------------------------
Started: 2025-02-28 15:01:05.665215
Existing_entries: 340
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1342
Summarized using gpt-4o-mini
Append: [高效动态高斯点阵的渲染技术研究](https://arxiv.org/abs/2502.20378)
Token length: 1264
Summarized using gpt-4o-mini
Append: [ArtGS：一种用于多部件关节物体建模的新方法](https://arxiv.org/abs/2502.19459)
append_entries: 2
Finish: 2025-02-28 15:01:16.687267
------------------------------------------------------
Started: 2025-02-28 18:00:47.876595
Existing_entries: 342
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1513
Summarized using gpt-4o-mini
Append: [探讨大语言模型中的关系特定神经元](https://arxiv.org/abs/2502.17355)
Token length: 1828
Summarized using gpt-4o-mini
Append: [提升自主AI代理的安全性：应对攻击与脆弱性](https://arxiv.org/abs/2502.16750)
Json decode failed:
{
  "title": "基于流匹配框架的噪声耦合一致性训练方法",
  "short_summary": "提出了一种新颖的基于流匹配的噪声耦合一致性训练方法，提升图像生成效果。",
  "summary": "一致性训练（CT）作为图像生成任务中的一种新兴方法，尽管具有竞争力，但在非蒸馏一致性训练中常面临高方差和不稳定性的问题。本研究提出了一种基于流匹配框架的新型CT训练方法，主要贡献在于开发了一种受变分自编码器（VAE）架构启发的噪声耦合方案。通过训练一个数据依赖的噪声发射模型，我们的方法能够间接学习噪声到数据映射的几何特征，克服了经典CT中固定的正向过程选择带来的限制。实验证明，在多种图像数据集上，我们的模型显著改善了生成性能，超越了基准模型，并在CIFAR-10上达成了当前最先进的非蒸馏CT FID，在64x64分辨率的2步生成中，FID与ImageNet上的最先进水平相当。我们的代码已发布至https:
  "keyword": ["一致性训练", "噪声耦合", "图像生成"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 321 (char 414). Line: 406.
Append: [Training Consistency Models with Variational Noise Coupling](https://arxiv.org/abs/2502.18197)
append_entries: 3
Finish: 2025-02-28 18:01:01.610494
------------------------------------------------------
Started: 2025-02-28 21:00:50.724025
Existing_entries: 345
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1727
Summarized using gpt-4o-mini
Append: [xAR框架：一种扩展自回归模型的生成方法](https://arxiv.org/abs/2502.20388)
append_entries: 1
Finish: 2025-02-28 21:00:57.569242
------------------------------------------------------
Started: 2025-03-01 00:38:41.762942
Existing_entries: 346
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-01 00:38:42.078759
------------------------------------------------------
Started: 2025-03-01 03:21:56.175681
Existing_entries: 346
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1379
Summarized using gpt-4o-mini
Append: [PlanGEN框架：提升复杂规划问题推理能力的新方法](https://arxiv.org/abs/2502.16111)
append_entries: 1
Finish: 2025-03-01 03:21:59.688263
------------------------------------------------------
Started: 2025-03-01 06:09:34.650023
Existing_entries: 347
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-01 06:09:34.795420
------------------------------------------------------
Started: 2025-03-01 09:00:50.886084
Existing_entries: 347
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-01 09:00:51.051722
------------------------------------------------------
Started: 2025-03-01 12:11:29.965420
Existing_entries: 347
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-01 12:11:30.142426
------------------------------------------------------
Started: 2025-03-01 15:00:44.939306
Existing_entries: 347
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-01 15:00:45.177661
------------------------------------------------------
Started: 2025-03-01 18:01:09.224791
Existing_entries: 347
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-01 18:01:09.420290
------------------------------------------------------
Started: 2025-03-01 21:00:50.637154
Existing_entries: 347
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-01 21:00:50.808835
------------------------------------------------------
Started: 2025-03-02 00:38:18.193149
Existing_entries: 347
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-02 00:38:18.416621
------------------------------------------------------
Started: 2025-03-02 03:18:21.188428
Existing_entries: 347
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-02 03:18:21.364459
------------------------------------------------------
Started: 2025-03-02 06:01:03.702021
Existing_entries: 347
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-02 06:01:03.945753
------------------------------------------------------
Started: 2025-03-02 09:01:07.995570
Existing_entries: 347
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-02 09:01:08.146719
------------------------------------------------------
Started: 2025-03-02 12:11:12.199218
Existing_entries: 347
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-02 12:11:12.436418
------------------------------------------------------
Started: 2025-03-02 15:00:56.905320
Existing_entries: 347
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-02 15:00:57.138933
------------------------------------------------------
Started: 2025-03-02 18:00:59.264785
Existing_entries: 347
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-02 18:00:59.525426
------------------------------------------------------
Started: 2025-03-02 21:00:48.174007
Existing_entries: 347
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-02 21:00:48.354556
------------------------------------------------------
Started: 2025-03-03 00:37:28.123960
Existing_entries: 347
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-03 00:37:28.299938
------------------------------------------------------
Started: 2025-03-03 03:19:05.191647
Existing_entries: 347
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-03 03:19:05.387596
------------------------------------------------------
Started: 2025-03-03 06:11:38.856730
Existing_entries: 347
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1454
Summarized using gpt-4o-mini
Append: [ViDoSeek与ViDoRAG：解决视觉文档中的复杂推理挑战](https://arxiv.org/abs/2502.18017)
Token length: 1299
Summarized using gpt-4o-mini
Append: [应用强化学习提升人形机器人灵巧操作能力](https://arxiv.org/abs/2502.20396)
Token length: 1190
Summarized using gpt-4o-mini
Append: [双阶段数据注释管道在视频理解中的应用](https://arxiv.org/abs/2502.20811)
Token length: 1301
Summarized using gpt-4o-mini
Append: [大语言模型在多变量多项式非负性判断中的应用与研究](https://arxiv.org/abs/2502.20545)
Token length: 1029
Summarized using gpt-4o-mini
Append: [LiteASR：一种低秩压缩的自动语音识别编码器方案](https://arxiv.org/abs/2502.20583)
Token length: 938
Summarized using gpt-4o-mini
Append: [基于SolutionBench的复杂工程解决方案设计评估与SolutionRAG系统](https://arxiv.org/abs/2502.20730)
append_entries: 6
Finish: 2025-03-03 06:12:01.183849
------------------------------------------------------
Started: 2025-03-03 09:09:23.970842
Existing_entries: 353
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-03 09:09:24.133472
------------------------------------------------------
Started: 2025-03-03 12:13:43.780261
Existing_entries: 353
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 955
Summarized using gpt-4o-mini
Append: [ProtoFM：结合视觉基础模型的自解释分类器](https://arxiv.org/abs/2502.19577)
Token length: 776
Summarized using gpt-4o-mini
Append: [链式草稿模型：提升大语言模型推理效率的创新方法](https://arxiv.org/abs/2502.18600)
append_entries: 2
Finish: 2025-03-03 12:13:56.851863
------------------------------------------------------
Started: 2025-03-03 15:00:49.274845
Existing_entries: 355
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1174
Summarized using gpt-4o-mini
Append: [LettuceDetect：克服生成模型幻觉的高效检测框架](https://arxiv.org/abs/2502.17125)
Json decode failed:
{
  "title": "基于Hessian矩阵的Optimal Brain Apoptosis：一种高效的模型剪枝方法",
  "short_summary": "文章提出了一种新颖的剪枝方法，利用Hessian矩阵提高CNN和Transformer的计算效率。",
  "summary": "随着卷积神经网络（CNN）和变换器（Transformers）的复杂性和参数数量增加，计算效率和资源需求成为挑战。本文提出一种新颖的剪枝方法——Optimal Brain Apoptosis（OBA），在参数重要性评估上突破了传统方法，通过直接计算每个参数的Hessian-向量乘积值来提高剪枝效率。我们对Hessian矩阵进行层级分解，并识别层间Hessian子矩阵非零的条件，从而优化了参数的二阶Taylor展开计算。通过在CIFAR10、CIFAR100和Imagenet数据集上实验证实了该方法的有效性，验证了其在CNN和Transformers中的应用，我的代码可在此链接获取：https:
  "keyword": ["卷积神经网络", "变换器", "剪枝方法"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 315 (char 450). Line: 406.
Append: [Optimal Brain Apoptosis](https://arxiv.org/abs/2502.17941)
append_entries: 2
Finish: 2025-03-03 15:01:00.196908
------------------------------------------------------
Started: 2025-03-03 18:00:59.187451
Existing_entries: 357
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1674
Summarized using gpt-4o-mini
Append: [利用大型语言模型提升心理咨询服务的潜力](https://arxiv.org/abs/2502.19731)
Token length: 1460
Summarized using gpt-4o-mini
Append: [EgoNormia: 评估视觉语言模型的规范推理能力](https://arxiv.org/abs/2502.20490)
Token length: 767
Summarized using gpt-4o-mini
Append: [小数据集的战略增强在图像生成中的成功应用](https://arxiv.org/abs/2502.21318)
Token length: 1327
Summarized using gpt-4o-mini
Append: [DexGraspVLA：实现通用灵巧抓取的新框架](https://arxiv.org/abs/2502.20900)
Token length: 1040
Summarized using gpt-4o-mini
Append: [TeleRAG：提升RAG系统推理效率的创新方案](https://arxiv.org/abs/2502.20969)
Token length: 1666
Summarized using gpt-4o-mini
Append: [MIGE：统一的多模态框架促进主题驱动生成与指令编辑](https://arxiv.org/abs/2502.21291)
append_entries: 6
Finish: 2025-03-03 18:01:39.768452
------------------------------------------------------
Started: 2025-03-03 21:01:08.093768
Existing_entries: 363
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-03 21:01:08.357381
------------------------------------------------------
Started: 2025-03-04 00:36:12.468981
Existing_entries: 363
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 994
Summarized using gpt-4o-mini
Append: [基于单步反馈的多轮代码生成方法muCode](https://arxiv.org/abs/2502.20380)
append_entries: 1
Finish: 2025-03-04 00:36:16.046021
------------------------------------------------------
Started: 2025-03-04 03:18:42.368406
Existing_entries: 364
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-04 03:18:42.555409
------------------------------------------------------
Started: 2025-03-04 06:01:02.306063
Existing_entries: 364
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-04 06:01:02.618330
------------------------------------------------------
Started: 2025-03-04 09:00:45.604171
Existing_entries: 364
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1286
Summarized using gpt-4o-mini
Append: [DuoDecoding：提升大语言模型推理速度的新方法](https://arxiv.org/abs/2503.00784)
append_entries: 1
Finish: 2025-03-04 09:00:48.793774
------------------------------------------------------
Started: 2025-03-04 12:13:38.360538
Existing_entries: 365
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1128
Summarized using gpt-4o-mini
Append: [TOKENSWIFT框架：加速超长序列生成的解决方案](https://arxiv.org/abs/2502.18890)
Token length: 1436
Summarized using gpt-4o-mini
Append: [DiffRhythm：高效生成完整歌曲的潜在扩散模型](https://arxiv.org/abs/2503.01183)
Token length: 1484
Summarized using gpt-4o-mini
Append: [基于DUSt3R的多视角房间布局估计新方法](https://arxiv.org/abs/2502.16779)
Token length: 1917
Summarized using gpt-4o-mini
Append: [OneRec: 基于生成模型的推荐系统优化方案](https://arxiv.org/abs/2502.18965)
Token length: 1368
Summarized using gpt-4o-mini
Append: [大型语言模型在机间通信中开发私密声调语言的潜力研究](https://arxiv.org/abs/2503.01063)
Token length: 1634
Summarized using gpt-4o-mini
Append: [Liger：将预训练语言模型线性化为门控递归结构](https://arxiv.org/abs/2503.01496)
Token length: 1434
Summarized using gpt-4o-mini
Append: [封闭循环体态代理（CLEA）架构在动态环境中的任务管理](https://arxiv.org/abs/2503.00729)
Token length: 1242
Summarized using gpt-4o-mini
Append: [SpeQL: 利用大型语言模型加速大数据集查询执行](https://arxiv.org/abs/2503.00714)
Token length: 1194
Summarized using gpt-4o-mini
Append: [CodeArena：重塑大语言模型代码生成评估框架](https://arxiv.org/abs/2503.01295)
Token length: 1847
Summarized using gpt-4o-mini
Append: [Qilin数据集：推动多模态搜索与推荐服务的发展](https://arxiv.org/abs/2503.00501)
Token length: 1323
Summarized using gpt-4o-mini
Append: [Kiss3DGen: 高效的3D生成与编辑框架](https://arxiv.org/abs/2503.01370)
Token length: 1335
Summarized using gpt-4o-mini
Append: [基于单步扩散模型的3D重建与新视角合成增强方法](https://arxiv.org/abs/2503.01774)
Json decode failed:
{
  "title": "VideoUFO: 用户焦点视频数据集的构建与应用",
  "keyword": ["视频生成", "用户焦点", "数据集"],
  "short_summary": "本文提出了VideoUFO数据集，以满足用户的视频生成需求。",
  "summary": "本文介绍了VideoUFO，这是首个专门为满足用户兴趣而构建的视频数据集，应用于文本到视频生成模型。VideoUFO具有与现有数据集重叠度低（仅0.29%）和使用YouTube官方API搜索获得的Creative Commons授权视频等独特特点，能够为未来研究提供更加广泛的训练资源。该数据集包含逾109万段视频剪辑，并为每段剪辑生成简短及详细的描述。通过对大规模的文本到视频提示数据集VidProM进行主题聚类，我们识别出1,291个用户关注的话题并据此获取相关视频。实验结果显示，目前16种文本到视频模型在用户关注的主题上表现不一致，而使用VideoUFO训练的简单模型在表现最差的主题上超过了其他模型。该数据集已在https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 332 (char 464). Line: 406.
Append: [VideoUFO: A Million-Scale User-Focused Dataset for Text-to-Video Generation](https://arxiv.org/abs/2503.01739)
Token length: 1827
Summarized using gpt-4o-mini
Append: [语言模型自我改进的内在机制：推理行为的作用](https://arxiv.org/abs/2503.01307)
Json decode failed:
{
  "title": "数据选择方法在大规模训练中的有效性研究",
  "keyword": [
    "数据选择",
    "指令调整",
    "模型训练"
  ],
  "short_summary": "研究表明，数据选择在模型训练中的效果依赖于数据集规模，复杂方法往往表现不如随机选择。",
  "summary": "本研究系统性地探讨了数据选择方法在大规模指令调优中的效果，选择最多2.5M样本自5.8M样本池中进行评估，涵盖7个不同任务。结果显示，许多新提出的方法在这一环境下的表现不如随机选择，尽管它们使用了更多的计算资源。更令人关注的是，当面对更大数据池时，它们的性能反而下降。相较之下，一种基于表现的加权平均池化（RDS+）变体在所有测试环境中都 consistently 超过更复杂的方法，同时计算效率更高。我们的发现表明，自动选择方法的扩展性特征需要更深入的研究。相关代码、数据和模型已发布在 https:
}Summarization failed, append the original article
error: Invalid control character at: line 9 column 266 (char 421). Line: 406.
Append: [Large-Scale Data Selection for Instruction Tuning](https://arxiv.org/abs/2503.01807)
Token length: 1830
Summarized using gpt-4o-mini
Append: [视觉强化微调（Visual-RFT）：提升大型视觉语言模型的推理能力](https://arxiv.org/abs/2503.01785)
Token length: 1724
Summarized using gpt-4o-mini
Append: [Introducing Phi-4-Mini与Phi-4-Multimodal：紧凑且高效的语言和多模态模型](https://arxiv.org/abs/2503.01743)
append_entries: 17
Finish: 2025-03-04 12:15:25.171551
------------------------------------------------------
Started: 2025-03-04 21:00:48.295920
Existing_entries: 382
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1386
Summarized using gpt-4o-mini
Append: [基于模型置信度的测试时计算效率提升方法](https://arxiv.org/abs/2503.00031)
Token length: 1417
Summarized using gpt-4o-mini
Append: [Web AI代理的安全性与脆弱性分析](https://arxiv.org/abs/2502.20383)
Token length: 1463
Summarized using gpt-4o-mini
Append: [从人工有用智能到人工通用智能的过渡：分离知识与推理](https://arxiv.org/abs/2502.19402)
Token length: 1122
Summarized using gpt-4o-mini
Append: [PodAgent：一种全新的播客音频生成框架](https://arxiv.org/abs/2503.00455)
Token length: 1288
Summarized using gpt-4o-mini
Append: [评估大语言模型不确定性的方法研究](https://arxiv.org/abs/2503.01688)
Token length: 1174
Summarized using gpt-4o-mini
Append: [SampleMix: 一种基于样本特征的数据混合方法](https://arxiv.org/abs/2503.01506)
Token length: 1343
Summarized using gpt-4o-mini
Append: [探索语言模型语义重建中的词形与上下文信息的作用](https://arxiv.org/abs/2503.01714)
Token length: 1480
Summarized using gpt-4o-mini
Append: [Direct Discriminative Optimization：提升视觉生成模型的质量](https://arxiv.org/abs/2503.01103)
append_entries: 8
Finish: 2025-03-04 21:01:54.852133
------------------------------------------------------
Started: 2025-03-05 00:36:06.686739
Existing_entries: 390
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-05 00:36:07.033298
------------------------------------------------------
Started: 2025-03-05 03:17:31.268230
Existing_entries: 390
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-05 03:17:31.587505
------------------------------------------------------
Started: 2025-03-05 06:00:46.158119
Existing_entries: 390
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1068
Summarized using gpt-4o-mini
Append: [Meta Plan Optimization框架提升大型语言模型代理的规划能力](https://arxiv.org/abs/2503.02682)
Token length: 1171
Summarized using gpt-4o-mini
Append: [大语言模型对维基百科影响的深入分析](https://arxiv.org/abs/2503.02879)
Token length: 1789
Summarized using gpt-4o-mini
Append: [基于直接偏好优化的细粒度事实对齐方法Mask-DPO](https://arxiv.org/abs/2503.02846)
Token length: 1232
Summarized using gpt-4o-mini
Append: [ATLaS：提高大型语言模型代理在多任务中的泛化能力](https://arxiv.org/abs/2503.02197)
Token length: 1342
Summarized using gpt-4o-mini
Append: [SPIDER：多器官补丁级别的病理图像数据集及基准模型](https://arxiv.org/abs/2503.02876)
Token length: 799
Summarized using gpt-4o-mini
Append: [自我学习预见法：提高多步推理任务效率的自监督方法](https://arxiv.org/abs/2503.02878)
Json decode failed:
{
  "title": "MultiAgentBench：评估基于大型语言模型的多智能体系统的综合基准",
  "keyword": ["多智能体", "大型语言模型", "基准测试"],
  "short_summary": "本文提出了MultiAgentBench，用于评估多智能体系统的协作和竞争能力。",
  "summary": "本文介绍了MultiAgentBench，这是一个综合性的基准测试，用于评估基于大型语言模型（LLM）的多智能体系统在多样化互动场景中的表现。现有基准多集中于单个智能体任务或狭窄领域，无法反映多智能体协作与竞争的动态。MultiAgentBench不仅测量任务完成情况，还引入里程碑式关键绩效指标来评估协作和竞争质量。研究中评估了多种协调协议（包括星型、链式、树状和图状拓扑）以及组讨论和认知规划等创新策略。结果显示，gpt-4o-mini在任务评分上平均最高，图结构在协调协议中表现最佳，而认知规划使里程碑达成率提高了3%。相关代码和数据集已公开，地址为https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 299 (char 457). Line: 406.
Append: [MultiAgentBench: Evaluating the Collaboration and Competition of LLM agents](https://arxiv.org/abs/2503.01935)
Token length: 1158
Summarized using gpt-4o-mini
Append: [优化管道并行性中的激活内存消耗](https://arxiv.org/abs/2503.01328)
append_entries: 8
Finish: 2025-03-05 06:01:52.962836
------------------------------------------------------
Started: 2025-03-05 09:00:44.605926
Existing_entries: 398
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1363
Summarized using gpt-4o-mini
Append: [基于进化框架的智能GUI代理提升效率与灵活性](https://arxiv.org/abs/2503.02268)
Token length: 1037
Summarized using gpt-4o-mini
Append: [FR-Spec：一种优化的频率排名推测采样框架](https://arxiv.org/abs/2502.14856)
Token length: 963
Summarized using gpt-4o-mini
Append: [SemViQA：提升越南语事实检查的创新框架](https://arxiv.org/abs/2503.00955)
Json decode failed:
{
  "title": "通过开放语言接口统一细粒度视觉感知任务的框架",
  "keyword": ["视觉感知", "统一模型", "细粒度任务"],
  "short_summary": "提出了一种新框架，通过语言接口统一细粒度视觉感知任务。",
  "summary": "本文介绍了一种名为\ours的新框架，该框架旨在通过开放的语言接口统一细粒度视觉感知任务，包括对象检测、像素级分割和图像级视觉语言任务。该方法将所有感知目标转化为语言空间，从而简化了建筑设计和训练策略。同时，引入了一种新颖的嵌入检索方法，仅依赖语言接口来支持分割任务。经过对五个标准视觉感知数据集的多任务训练，\ours在COCO实例分割上超过了之前的通用模型12.3 mAP，在ADE20K语义分割上达到3.3 mIoU的提升。此外，该方法与现有的多模态语言模型（MLLMs）无缝集成，有效结合细粒度感知能力与先进的语言能力，从而支持更复杂的推理分割任务。相关代码和模型将公开可用。"
}Summarization failed, append the original article
error: Invalid \escape: line 5 column 24 (char 152). Line: 406.
Append: [UFO: A Unified Approach to Fine-grained Visual Perception via Open-ended Language Interface](https://arxiv.org/abs/2503.01342)
append_entries: 4
Finish: 2025-03-05 09:01:03.402659
------------------------------------------------------
Started: 2025-03-05 12:00:54.287275
Existing_entries: 402
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1232
Summarized using gpt-4o-mini
Append: [LADDER: 自主驱动的自我学习框架提升语言模型解决问题的能力](https://arxiv.org/abs/2503.00735)
Token length: 1355
Summarized using gpt-4o-mini
Append: [迭代价值函数优化：提升价值引导解码的有效性](https://arxiv.org/abs/2503.02368)
append_entries: 2
Finish: 2025-03-05 12:01:04.778376
------------------------------------------------------
Started: 2025-03-05 15:00:46.389105
Existing_entries: 404
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1271
Summarized using gpt-4o-mini
Append: [平衡回归中的均匀性学习方法](https://arxiv.org/abs/2503.00876)
Token length: 1457
Summarized using gpt-4o-mini
Append: [Q-EVAL-100K：评估文本与视觉内容的综合数据集](https://arxiv.org/abs/2503.02357)
Token length: 1281
Summarized using gpt-4o-mini
Append: [IterPref：提升代码大语言模型的偏好学习框架](https://arxiv.org/abs/2503.02783)
Token length: 1238
Summarized using gpt-4o-mini
Append: [RectifiedHR：一种高效的无训练高分辨率图像生成方法](https://arxiv.org/abs/2503.02537)
append_entries: 4
Finish: 2025-03-05 15:01:08.390251
------------------------------------------------------
Started: 2025-03-05 18:00:52.181667
Existing_entries: 408
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-05 18:00:52.349220
------------------------------------------------------
Started: 2025-03-05 21:00:52.841536
Existing_entries: 408
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1268
Summarized using gpt-4o-mini
Append: [高效的KV缓存压缩方法Q-Filters在自回归语言模型中的应用](https://arxiv.org/abs/2503.02812)
Token length: 1049
Summarized using gpt-4o-mini
Append: [味觉信息与音乐生成模型的关系研究](https://arxiv.org/abs/2503.02823)
Token length: 876
Summarized using gpt-4o-mini
Append: [Tabby: 一种用于合成表格数据的强大Transformer后训练方法](https://arxiv.org/abs/2503.02152)
Token length: 1283
Summarized using gpt-4o-mini
Append: [TokenOCR：一种针对文本图像任务的首个 token 级视觉基础模型](https://arxiv.org/abs/2503.02304)
Token length: 1014
Summarized using gpt-4o-mini
Append: [基于强化学习的离散时间混合自动机学习框架](https://arxiv.org/abs/2503.01842)
append_entries: 5
Finish: 2025-03-05 21:01:18.250390
------------------------------------------------------
Started: 2025-03-06 00:35:57.343912
Existing_entries: 413
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1690
Summarized using gpt-4o-mini
Append: [统一视频与动作模型：提升机器人任务性能的创新框架](https://arxiv.org/abs/2503.00200)
append_entries: 1
Finish: 2025-03-06 00:36:00.946881
------------------------------------------------------
Started: 2025-03-06 03:18:20.805525
Existing_entries: 414
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1273
Summarized using gpt-4o-mini
Append: [大型语言模型对齐的挑战与社会对齐框架的启示](https://arxiv.org/abs/2503.00069)
append_entries: 1
Finish: 2025-03-06 03:18:28.896242
------------------------------------------------------
Started: 2025-03-06 06:10:52.805304
Existing_entries: 415
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1378
Summarized using gpt-4o-mini
Append: [GEN3C：增强的视频生成模型与精确摄像机控制](https://arxiv.org/abs/2503.03751)
Token length: 1270
Summarized using gpt-4o-mini
Append: [Babel：开创多语言大模型的新标准](https://arxiv.org/abs/2503.00865)
Token length: 1473
Summarized using gpt-4o-mini
Append: [自主车辆与人驱动车辆的双向交互框架研究](https://arxiv.org/abs/2503.00502)
Token length: 1368
Summarized using gpt-4o-mini
Append: [ABC: 深度整合视觉与自然语言的多模态嵌入模型](https://arxiv.org/abs/2503.00329)
Token length: 1376
Summarized using gpt-4o-mini
Append: [KodCode：用于编码训练的高质量合成数据集](https://arxiv.org/abs/2503.02951)
append_entries: 5
Finish: 2025-03-06 06:11:17.685409
------------------------------------------------------
Started: 2025-03-06 09:01:11.197444
Existing_entries: 420
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1148
Summarized using gpt-4o-mini
Append: [机器翻译后编辑中单词级质量估计的影响研究](https://arxiv.org/abs/2503.03044)
Token length: 1395
Summarized using gpt-4o-mini
Append: [通过分解医学知识提升视觉语言模型在医学异常检测中的表现](https://arxiv.org/abs/2503.03278)
Token length: 1329
Summarized using gpt-4o-mini
Append: [利用多元信号提升小型模型的指令跟随能力](https://arxiv.org/abs/2503.01836)
Token length: 1142
Summarized using gpt-4o-mini
Append: [提升工具检索性能的ToolRet基准](https://arxiv.org/abs/2503.01763)
Token length: 1117
Summarized using gpt-4o-mini
Append: [FLAME基准：联邦学习在机器人操控中的应用](https://arxiv.org/abs/2503.01729)
Token length: 1820
Summarized using gpt-4o-mini
Append: [大语言模型在软件漏洞检测中的效能研究](https://arxiv.org/abs/2503.01449)
Token length: 1391
Summarized using gpt-4o-mini
Append: [CognitiveDrone：面向复杂无人机任务的视觉-语言-动作模型](https://arxiv.org/abs/2503.01378)
Token length: 1216
Summarized using gpt-4o-mini
Append: [瑞士法律翻译的挑战与SwiLTra-Bench创新解决方案](https://arxiv.org/abs/2503.01372)
append_entries: 8
Finish: 2025-03-06 09:02:05.703179
------------------------------------------------------
Started: 2025-03-06 12:13:44.882199
Existing_entries: 428
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 888
Summarized using gpt-4o-mini
Append: [小型语言模型Shakti在边缘设备上的应用研究](https://arxiv.org/abs/2503.01933)
Token length: 1227
Summarized using gpt-4o-mini
Append: [结构与文本检索的混合模型：MoR框架](https://arxiv.org/abs/2502.20317)
Token length: 1387
Summarized using gpt-4o-mini
Append: [对话助手中的问题重写与融合方法研究](https://arxiv.org/abs/2502.18860)
append_entries: 3
Finish: 2025-03-06 12:14:01.001410
------------------------------------------------------
Started: 2025-03-06 15:00:44.889194
Existing_entries: 431
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-06 15:00:45.118471
------------------------------------------------------
Started: 2025-03-06 18:10:17.868745
Existing_entries: 431
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1066
Summarized using gpt-4o-mini
Append: [基于过程的自奖励方法提升大语言模型数学推理能力](https://arxiv.org/abs/2503.03746)
append_entries: 1
Finish: 2025-03-06 18:10:21.131924
------------------------------------------------------
Started: 2025-03-06 21:00:42.725318
Existing_entries: 432
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1270
Summarized using gpt-4o-mini
Append: [重掩蔽扩散模型：提升离散扩散生成质量的新方法](https://arxiv.org/abs/2503.00307)
append_entries: 1
Finish: 2025-03-06 21:00:50.075301
------------------------------------------------------
Started: 2025-03-07 00:36:27.069621
Existing_entries: 433
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-07 00:36:27.311334
------------------------------------------------------
Started: 2025-03-07 03:19:13.694099
Existing_entries: 433
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1075
Summarized using gpt-4o-mini
Append: [Highlighted Chain-of-Thought Prompting提升大型语言模型的响应准确性](https://arxiv.org/abs/2503.02003)
Token length: 1531
Summarized using gpt-4o-mini
Append: [基于图神经网络变分自编码器的多智能体协调方法](https://arxiv.org/abs/2503.02954)
Token length: 1574
Summarized using gpt-4o-mini
Append: [基于信号时序逻辑的多样化自主决策方法研究](https://arxiv.org/abs/2503.02924)
append_entries: 3
Finish: 2025-03-07 03:19:27.390691
------------------------------------------------------
Started: 2025-03-07 06:00:42.524063
Existing_entries: 436
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1166
Summarized using gpt-4o-mini
Append: [音频理解与推理的先进模型：Audio Flamingo 2](https://arxiv.org/abs/2503.03983)
Token length: 1563
Summarized using gpt-4o-mini
Append: [预测GitHub对话中的毒性与偏离现象的主动调节策略](https://arxiv.org/abs/2503.02191)
Token length: 756
Summarized using gpt-4o-mini
Append: [大语言模型信息扭曲研究：迭代生成的传播影响](https://arxiv.org/abs/2502.20258)
Json decode failed:
{
  "title": "PokéChamp：基于大语言模型的Pokémon对战智能体",
  "keyword": ["Pokémon", "大语言模型", "强化学习"],
  "short_summary": "PokéChamp利用大语言模型优化Pokémon对战智能体，提升游戏表现。",
  "summary": "PokéChamp是一个基于大型语言模型（LLMs）的最小最大智能体，专为Pokémon对战而设计。该框架通过LLMs替代了三个关键模块：玩家动作采样、对手建模和价值函数估计，利用游戏历史和人类知识来降低搜索空间，解决部分可观察性的问题。经过评估，PokéChamp在流行的Gen 9 OU格式中表现优异，使用GPT-4o时对战胜率达到76%，对比现有最佳LLM基础机器人时，胜率为84%；即使是使用开源的8亿参数Llama 3.1模型，也能以64%的胜率超过之前的最佳LLM机器人Pok"éllmon。通过建立超过300万场游戏的真实玩家数据集，我们提出了一系列用于评估特定对战技能的基准和难题，期待此工作能促进Pokémon对战作为基准，将LLM技术与博弈论算法整合于多智能体问题的进一步研究。"
}Summarization failed, append the original article
error: Expecting ',' delimiter: line 5 column 260 (char 410). Line: 406.
Append: [PokéChamp: an Expert-level Minimax Language Agent](https://arxiv.org/abs/2503.04094)
Token length: 1707
Summarized using gpt-4o-mini
Append: [STORM：提升视频理解效率的时空编码新架构](https://arxiv.org/abs/2503.04130)
Token length: 1325
Summarized using gpt-4o-mini
Append: [LanDiff：融合自回归语言模型与扩散模型的文本生成视频新框架](https://arxiv.org/abs/2503.04606)
Token length: 1371
Summarized using gpt-4o-mini
Append: [HybridNorm: 一种新型混合归一化策略提高深度Transformer模型性能](https://arxiv.org/abs/2503.04598)
Token length: 1904
Summarized using gpt-4o-mini
Append: [START：一种集成工具的长链推理模型](https://arxiv.org/abs/2503.04625)
Token length: 1510
Summarized using gpt-4o-mini
Append: [FuseChat-3.0: 整合多种语言模型的高效新模型](https://arxiv.org/abs/2503.04222)
Token length: 1248
Summarized using gpt-4o-mini
Append: [基于反馈和编辑模型的推理时扩展方法](https://arxiv.org/abs/2503.04378)
append_entries: 10
Finish: 2025-03-07 06:01:34.576216
------------------------------------------------------
Started: 2025-03-07 09:00:57.099349
Existing_entries: 446
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 538
Summarized using gpt-4o-mini
Append: [高效采样贝叶斯逆问题的条件流匹配与变压器架构结合](https://arxiv.org/abs/2503.01375)
Token length: 766
Summarized using gpt-4o-mini
Append: [长范围依赖的双重互信息缩放法则及其在语言建模中的应用](https://arxiv.org/abs/2503.04725)
Token length: 1807
Summarized using gpt-4o-mini
Append: [EgoLife：基于AI的自我中心生活助理系统](https://arxiv.org/abs/2503.03803)
append_entries: 3
Finish: 2025-03-07 09:01:18.531409
------------------------------------------------------
Started: 2025-03-07 12:13:09.169605
Existing_entries: 449
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1431
Summarized using gpt-4o-mini
Append: [Union-of-Experts：提升MoE模型的动态路由与计算效率](https://arxiv.org/abs/2503.02495)
Token length: 1244
Summarized using gpt-4o-mini
Append: [优化大型语言模型翻译以克服翻译腔问题](https://arxiv.org/abs/2503.04369)
Token length: 1246
Summarized using gpt-4o-mini
Append: [评估大型语言模型推理能力的新框架：LINGOLY-TOO 的应用](https://arxiv.org/abs/2503.02972)
Token length: 1107
Summarized using gpt-4o-mini
Append: [IFIR：评估专家领域指令跟随信息检索的首个综合基准](https://arxiv.org/abs/2503.04644)
Token length: 1378
Summarized using gpt-4o-mini
Append: [提升LLM后训练量化性能的精确敏感性度量](https://arxiv.org/abs/2503.01901)
append_entries: 5
Finish: 2025-03-07 12:13:43.579403
------------------------------------------------------
Started: 2025-03-07 15:00:51.057303
Existing_entries: 454
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1375
Summarized using gpt-4o-mini
Append: [LLMVoX: 一种轻量级的自回归语音合成系统](https://arxiv.org/abs/2503.04724)
append_entries: 1
Finish: 2025-03-07 15:01:10.191042
------------------------------------------------------
Started: 2025-03-07 18:00:59.257180
Existing_entries: 455
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1080
Summarized using gpt-4o-mini
Append: [双语模型训练对跨语言结构启动的影响研究](https://arxiv.org/abs/2503.03962)
Token length: 1148
Summarized using gpt-4o-mini
Append: [提升大型语言模型可信度的Truthfulness Separator Vector](https://arxiv.org/abs/2503.01917)
append_entries: 2
Finish: 2025-03-07 18:01:10.029326
------------------------------------------------------
Started: 2025-03-07 21:00:40.566078
Existing_entries: 457
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-07 21:00:40.806620
------------------------------------------------------
Started: 2025-03-08 00:28:22.714958
Existing_entries: 457
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-08 00:28:22.949373
------------------------------------------------------
Started: 2025-03-08 03:00:51.873376
Existing_entries: 457
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-08 03:00:52.130201
------------------------------------------------------
Started: 2025-03-08 06:00:57.195373
Existing_entries: 457
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-08 06:00:57.442487
------------------------------------------------------
Started: 2025-03-08 09:00:38.305330
Existing_entries: 457
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-08 09:00:38.501220
------------------------------------------------------
Started: 2025-03-08 12:01:17.830598
Existing_entries: 457
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-08 12:01:17.995167
------------------------------------------------------
Started: 2025-03-08 15:00:45.147113
Existing_entries: 457
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-08 15:00:45.466694
------------------------------------------------------
Started: 2025-03-08 18:00:53.974043
Existing_entries: 457
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-08 18:00:54.336152
------------------------------------------------------
Started: 2025-03-08 21:00:45.062426
Existing_entries: 457
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-08 21:00:45.221210
------------------------------------------------------
Started: 2025-03-09 00:31:52.315848
Existing_entries: 457
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-09 00:31:52.621526
------------------------------------------------------
Started: 2025-03-09 03:01:08.783519
Existing_entries: 457
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-09 03:01:09.012756
------------------------------------------------------
Started: 2025-03-09 06:00:44.369674
Existing_entries: 457
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-09 06:00:44.665804
------------------------------------------------------
Started: 2025-03-09 09:00:57.321305
Existing_entries: 457
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-09 09:00:57.524409
------------------------------------------------------
Started: 2025-03-09 12:00:49.954478
Existing_entries: 457
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-09 12:00:50.123706
------------------------------------------------------
Started: 2025-03-09 15:00:41.953964
Existing_entries: 457
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-09 15:00:42.162480
------------------------------------------------------
Started: 2025-03-09 18:00:45.625419
Existing_entries: 457
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-09 18:00:45.896315
------------------------------------------------------
Started: 2025-03-09 21:01:02.875026
Existing_entries: 457
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-09 21:01:04.094022
------------------------------------------------------
Started: 2025-03-10 00:30:54.626618
Existing_entries: 457
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-10 00:30:54.780085
------------------------------------------------------
Started: 2025-03-10 03:01:06.980008
Existing_entries: 457
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-10 03:01:07.170136
------------------------------------------------------
Started: 2025-03-10 06:01:02.533349
Existing_entries: 457
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1374
Summarized using gpt-4o-mini
Append: [BEHAVIOR机器人套件：应对家庭任务的全面机器人控制框架](https://arxiv.org/abs/2503.05652)
Token length: 1192
Summarized using gpt-4o-mini
Append: [Sketch-of-Thought: 一种高效的语言模型推理框架](https://arxiv.org/abs/2503.05179)
Token length: 1540
Summarized using gpt-4o-mini
Append: [UnifiedReward：提升多模态生成与理解的统一奖励模型](https://arxiv.org/abs/2503.05236)
Token length: 1228
Summarized using gpt-4o-mini
Append: [引入遗忘门的变换器模型](https://arxiv.org/abs/2503.02130)
append_entries: 4
Finish: 2025-03-10 06:01:29.825038
------------------------------------------------------
Started: 2025-03-10 09:00:43.178429
Existing_entries: 461
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1036
Summarized using gpt-4o-mini
Append: [基于低秩适应的代码检索参数高效微调方法](https://arxiv.org/abs/2503.05315)
Token length: 1081
Summarized using gpt-4o-mini
Append: [R1-Searcher：提升大型语言模型推理能力的新方法](https://arxiv.org/abs/2503.05592)
Token length: 917
Summarized using gpt-4o-mini
Append: [基于可验证奖励的强化学习在多模态情感识别中的应用](https://arxiv.org/abs/2503.05379)
Token length: 1256
Summarized using gpt-4o-mini
Append: [DeepSeek R1在多模态推理中的成功应用与挑战](https://arxiv.org/abs/2503.05132)
Token length: 1248
Summarized using gpt-4o-mini
Append: [分支合并蒸馏法：提升大语言模型压缩与性能的创新策略](https://arxiv.org/abs/2503.04872)
Token length: 1299
Summarized using gpt-4o-mini
Append: [多尝试任务提升大型语言模型推理能力的研究](https://arxiv.org/abs/2503.04808)
append_entries: 6
Finish: 2025-03-10 09:01:16.262454
------------------------------------------------------
Started: 2025-03-10 12:00:59.805555
Existing_entries: 467
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1321
Summarized using gpt-4o-mini
Append: [Linear-MoE：集成线性序列建模与专家混合模型的高效系统](https://arxiv.org/abs/2503.05447)
Token length: 1850
Summarized using gpt-4o-mini
Append: [VideoPainter：一种高效的视频修复方法](https://arxiv.org/abs/2503.05639)
Token length: 1259
Summarized using gpt-4o-mini
Append: [可定制化视频异常检测技术及其应用](https://arxiv.org/abs/2503.04504)
Token length: 1029
Summarized using gpt-4o-mini
Append: [EuroBERT: 高性能多语言编码器的开发与应用](https://arxiv.org/abs/2503.05500)
Token length: 1832
Summarized using gpt-4o-mini
Append: [基于语义分割的检索增强生成框架SAGE的研究](https://arxiv.org/abs/2503.01713)
Token length: 879
Summarized using gpt-4o-mini
Append: [TrajectoryCrafter: 精确控制单目视频摄像机轨迹的新方法](https://arxiv.org/abs/2503.05638)
append_entries: 6
Finish: 2025-03-10 12:01:29.636187
------------------------------------------------------
Started: 2025-03-10 15:01:00.652416
Existing_entries: 473
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1034
Summarized using gpt-4o-mini
Append: [改进的流匹配技术在扩散模型中应用](https://arxiv.org/abs/2503.04824)
Token length: 1222
Summarized using gpt-4o-mini
Append: [STILL项目第三技术报告：强化学习模型的发展与工具操作的影响](https://arxiv.org/abs/2503.04548)
append_entries: 2
Finish: 2025-03-10 15:01:16.857896
------------------------------------------------------
Started: 2025-03-10 18:00:52.359594
Existing_entries: 475
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1426
Summarized using gpt-4o-mini
Append: [引入S2S-Arena：评估语音模型的指令跟随能力](https://arxiv.org/abs/2503.05085)
Token length: 1183
Summarized using gpt-4o-mini
Append: [LONGCODEU基准测试：评估长代码理解能力的研究](https://arxiv.org/abs/2503.04359)
Json decode failed:
{
  "title": "EAGLE-3: 一种新型高效的语言模型采样方法",
  "keyword": ["LLM", "EAGLE-3", "特征融合"],
  "short_summary": "EAGLE-3通过直接预测令牌显著提升模型性能和推理速度。",
  "summary": "本文介绍了EAGLE-3，这是一种新型的语言模型采样方法，旨在克服现有LLM在推理过程中的高成本和延迟问题。与EAGLE不同，EAGLE-3放弃了特征预测，转而采用直接令牌预测，并通过一种称为训练时测试的技术，实现多层特征融合。这种改进为模型性能提供了显著提升，使得提高训练数据规模的优势得到充分利用。实验表明，EAGLE-3在五个任务上相比于EAGLE-2实现了约6.5倍的速度提升及1.4倍的性能改善。本论文的代码可在https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 232 (char 365). Line: 406.
Append: [EAGLE-3: Scaling up Inference Acceleration of Large Language Models via Training-Time Test](https://arxiv.org/abs/2503.01840)
Token length: 1156
Summarized using gpt-4o-mini
Append: [俄语临床编码自动化的可行性研究](https://arxiv.org/abs/2502.21263)
Token length: 1396
Summarized using gpt-4o-mini
Append: [基于隐性用户画像的对话系统用户模拟器](https://arxiv.org/abs/2502.18968)
append_entries: 5
Finish: 2025-03-10 18:01:28.534564
------------------------------------------------------
Started: 2025-03-10 21:00:50.378362
Existing_entries: 480
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1227
Summarized using gpt-4o-mini
Append: [SafeArena：评估大型语言模型代理的网络滥用风险](https://arxiv.org/abs/2503.04957)
append_entries: 1
Finish: 2025-03-10 21:00:57.985434
------------------------------------------------------
Started: 2025-03-11 00:36:18.252251
Existing_entries: 481
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-11 00:36:18.421195
------------------------------------------------------
Started: 2025-03-11 03:19:24.608498
Existing_entries: 481
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1003
Summarized using gpt-4o-mini
Append: [稀疏专家激活剪枝：优化大型语言模型推理效率的新方法](https://arxiv.org/abs/2503.07605)
Token length: 885
Summarized using gpt-4o-mini
Append: [大型语言模型带来的假新闻风险与检测系统的挑战](https://arxiv.org/abs/2503.07595)
Token length: 1083
Summarized using gpt-4o-mini
Append: [PE3R：高效的3D重建框架](https://arxiv.org/abs/2503.07507)
Json decode failed:
{
  "title": "MM-Eureka：扩展大规模规则基础强化学习的多模态推理模型",
  "short_summary": "MM-Eureka通过规则基础强化学习提升多模态推理能力。",
  "summary": "MM-Eureka是一个多模态推理模型，它成功地将大规模规则基础强化学习（RL）扩展到多模态推理领域。尽管规则基础RL在文本领域显著提升了大型语言模型（LLMs）的推理能力，但在多模态环境中的应用仍然具有挑战性。我们的研究复现了文本基础RL系统（如DeepSeek-R1）在多模态空间中的关键特征，包括准确奖励和响应长度的稳步增加及反思行为的出现。我们证明，无论是指令调优还是预训练模型，通过规则基础RL都能在无需监督微调的情况下发展出强大的多模态推理能力，相较于其他方法显示出更优秀的数据效率。此外，我们还开源了完整的工作流程，以促进该领域的进一步研究，所有代码、模型和数据均可在https:
  "keyword": ["多模态推理", "规则基础强化学习", "开源研究"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 312 (char 411). Line: 406.
Append: [MM-Eureka: Exploring Visual Aha Moment with Rule-based Large-scale Reinforcement Learning](https://arxiv.org/abs/2503.07365)
Json decode failed:
{
  "title": "MovieAgent: 自动化电影生成框架",
  "keyword": ["自动化", "电影生成", "多智能体"],
  "short_summary": "MovieAgent通过自动化多智能体计划，实现高效的电影生成。",
  "summary": "本文介绍了MovieAgent，一个用于长视频生成的自动化电影生成框架。现有的长视频生成系统依赖手动输入剧本、场景和角色互动，导致成本高昂且效率低下。MovieAgent的主要优势在于首先探索和定义了自动化电影生成的范式，能够根据剧本和角色库生成多场景、多镜头的视频，确保叙事连贯性、角色一致性及字幕同步。其次，MovieAgent引入基于分层链式思维的推理过程，自动构建场景、镜头设置和摄影视觉，显著减少人力投入。实验结果显示，MovieAgent在剧本忠实度、角色一致性和叙事连贯性方面达到了新的最先进水平，为完全自动化电影生成提供了新的见解与方法。所有代码和项目网站可访问：https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 311 (char 441). Line: 406.
Append: [Automated Movie Generation via Multi-Agent CoT Planning](https://arxiv.org/abs/2503.07314)
Token length: 1340
Summarized using gpt-4o-mini
Append: [FedRand框架：提升联邦学习中的数据隐私](https://arxiv.org/abs/2503.07216)
Token length: 1043
Summarized using gpt-4o-mini
Append: [eMIGM：统一的图像生成与扩散模型](https://arxiv.org/abs/2503.07197)
Token length: 1756
Summarized using gpt-4o-mini
Append: [EasyControl: 高效灵活的条件引导扩散变换框架](https://arxiv.org/abs/2503.07027)
Token length: 1305
Summarized using gpt-4o-mini
Append: [MMDiag: 多轮多模态对话数据集及DiagNote模型](https://arxiv.org/abs/2503.07002)
Token length: 1131
Summarized using gpt-4o-mini
Append: [FEA-Bench: 评估大型语言模型在代码库增量开发中的能力](https://arxiv.org/abs/2503.06680)
Token length: 1014
Summarized using gpt-4o-mini
Append: [AutoCoA：提升自主性的大型代理模型框架](https://arxiv.org/abs/2503.06580)
Token length: 1401
Summarized using gpt-4o-mini
Append: [Seg-Zero: 用于分割推理的零-shot 学习框架](https://arxiv.org/abs/2503.06520)
Json decode failed:
{
  "title": "利用RWKV-7模型提升时间序列分析的性能",
  "short_summary": "提出RWKV-7模型，显著提高时间序列分析性能和训练效率。",
  "summary": "时间序列模型在处理大规模复杂数据集时面临显著挑战，尤其在实现与大型语言模型相似的扩展性方面。针对时间序列数据的独特特性和模型扩展的计算需求，研究人员探索了包括Transformers、LSTMs和GRUs等在内的多种架构。本文提出一种新颖的解决方案，使用RWKV-7模型，该模型在状态更新机制中融入了元学习。通过将RWKV-7的时间混合和通道混合组件整合到基于Transformer的时间序列模型Timer中，我们实现了性能显著提升，约为1.13至43.3倍，同时训练时间缩短了4.5倍，所需参数减少至原来的1/23。我们的代码和模型权重可在https:
  "keyword": ["时间序列模型", "RWKV-7", "性能提升"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 292 (char 381). Line: 406.
Append: [BlackGoose Rimer: Harnessing RWKV-7 as a Simple yet Superior Replacement for Transformers in Large-Scale Time Series Modeling](https://arxiv.org/abs/2503.06121)
Token length: 940
Summarized using gpt-4o-mini
Append: [NeuGrasp：应对透明和镜面物体抓取的神经表面重建方法](https://arxiv.org/abs/2503.03511)
Token length: 1040
Summarized using gpt-4o-mini
Append: [基于状态的参数高效微调方法在状态空间模型中的应用](https://arxiv.org/abs/2503.03499)
Token length: 1323
Summarized using gpt-4o-mini
Append: [LLaVE：增强多模态嵌入模型表现的动态框架](https://arxiv.org/abs/2503.04812)
Token length: 1545
Summarized using gpt-4o-mini
Append: [解析视觉语言模型中的文本偏见现象及其影响](https://arxiv.org/abs/2503.02199)
append_entries: 17
Finish: 2025-03-11 03:20:54.388351
------------------------------------------------------
Started: 2025-03-11 06:00:58.401334
Existing_entries: 498
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-11 06:00:58.583399
------------------------------------------------------
Started: 2025-03-11 09:00:55.636184
Existing_entries: 498
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1464
Summarized using gpt-4o-mini
Append: [AlphaDrive：基于强化学习和推理的自动驾驶视觉语言模型框架](https://arxiv.org/abs/2503.07608)
Token length: 1009
Summarized using gpt-4o-mini
Append: [图像与文本结合预训练模型在视语言任务中的表现](https://arxiv.org/abs/2503.07603)
Token length: 1799
Summarized using gpt-4o-mini
Append: [DreamRelation：一种基于示例视频的个性化关系视频定制方法](https://arxiv.org/abs/2503.07602)
Token length: 1514
Summarized using gpt-4o-mini
Append: [MedAgentsBench: 复杂医学问题的新评估基准](https://arxiv.org/abs/2503.07459)
Token length: 964
Summarized using gpt-4o-mini
Append: [DistiLLM-2：通过对比学习提升语言模型蒸馏效果](https://arxiv.org/abs/2503.07067)
Token length: 1025
Summarized using gpt-4o-mini
Append: [ProBench: 新型多模态智能评估基准的构建与实证分析](https://arxiv.org/abs/2503.06885)
Token length: 1615
Summarized using gpt-4o-mini
Append: [Vision-R1：增强多模态推理能力的深度学习模型](https://arxiv.org/abs/2503.06749)
Token length: 1110
Summarized using gpt-4o-mini
Append: [SurveyForge：提升文献综述生成质量的自动化工具](https://arxiv.org/abs/2503.04629)
Token length: 963
Summarized using gpt-4o-mini
Append: [提升人工文本检测的可解释性：稀疏自编码器的应用](https://arxiv.org/abs/2503.03601)
append_entries: 9
Finish: 2025-03-11 09:01:34.848673
------------------------------------------------------
Started: 2025-03-11 12:01:15.048198
Existing_entries: 507
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1822
Summarized using gpt-4o-mini
Append: [YOLOE：高效的开放式检测与分割模型](https://arxiv.org/abs/2503.07465)
Token length: 982
Summarized using gpt-4o-mini
Append: [基于ReLU的偏好优化算法RePO：简化语言模型对齐方法](https://arxiv.org/abs/2503.07426)
Token length: 1503
Summarized using gpt-4o-mini
Append: [Llama-MTSK：一种灵活的音视频识别多模态语言模型](https://arxiv.org/abs/2503.06362)
Token length: 1454
Summarized using gpt-4o-mini
Append: [探索三维编码器与文本特征空间的后期对齐](https://arxiv.org/abs/2503.05283)
Token length: 1178
Summarized using gpt-4o-mini
Append: [WritingBench：提升大语言模型写作能力的综合评估基准](https://arxiv.org/abs/2503.05244)
append_entries: 5
Finish: 2025-03-11 12:01:48.593876
------------------------------------------------------
Started: 2025-03-11 15:00:50.081634
Existing_entries: 512
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1207
Summarized using gpt-4o-mini
Append: [基于多镜头视频的人类动作重建框架](https://arxiv.org/abs/2503.07597)
Token length: 1466
Summarized using gpt-4o-mini
Append: [适配器引导蒸馏：提升条件扩散模型采样效率](https://arxiv.org/abs/2503.07274)
Token length: 1321
Summarized using gpt-4o-mini
Append: [WISE：基于世界知识的文本到图像生成语义评估基准](https://arxiv.org/abs/2503.07265)
Token length: 1356
Summarized using gpt-4o-mini
Append: [新型零样本音视频语音识别框架Zero-AVSR](https://arxiv.org/abs/2503.06273)
Json decode failed:
{
  "title": "一种单参考视角的新颖物体6D姿态估计方法",
  "short_summary": "提出了一种基于单参考视角的6D姿态估计方法SinRef-6D。",
  "summary": "本文提出了一种新颖的6D姿态估计方法SinRef-6D，旨在解决传统方法依赖CAD模型或密集参考视图所带来的困难。该方法通过迭代建立基于状态空间模型的点云对齐，能够有效处理较大的姿态偏差。此外，SinRef-6D引入的RGB和Points状态空间模型能够从单一视角捕获远程依赖关系和空间信息，具备线性复杂度和优越的空间建模能力。在通过合成数据预训练后，SinRef-6D无须重训练或CAD模型即可仅用单个参考视角估计新颖物体的6D姿态。通过在六个流行数据集和现实机器人场景进行广泛实验，我们的结果显示，尽管在更具挑战性的单参考设置下，SinRef-6D的表现与基于CAD和密集参考视图的方法相当。代码将发布于https:
  "keyword": [
    "6D姿态估计",
    "单参考视角",
    "状态空间模型"
  ]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 325 (char 415). Line: 406.
Append: [Novel Object 6D Pose Estimation with a Single Reference View](https://arxiv.org/abs/2503.05578)
Token length: 1248
Summarized using gpt-4o-mini
Append: [Mixture of Large Language Model Agents的安全性与防御机制研究](https://arxiv.org/abs/2503.05856)
Token length: 1102
Summarized using gpt-4o-mini
Append: [任务感知的键值缓存压缩：提升大型语言模型的信息处理效率](https://arxiv.org/abs/2503.04973)
append_entries: 7
Finish: 2025-03-11 15:01:38.440160
------------------------------------------------------
Started: 2025-03-11 18:00:59.771585
Existing_entries: 519
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1797
Summarized using gpt-4o-mini
Append: [REF-VLM：统一视觉解码任务的多模态大型语言模型框架](https://arxiv.org/abs/2503.07413)
Token length: 1760
Summarized using gpt-4o-mini
Append: [TRCE：提高文本生成模型中恶意内容的概念抹除能力](https://arxiv.org/abs/2503.07389)
Token length: 1429
Summarized using gpt-4o-mini
Append: [自回归表示对齐框架（ARRA）在文本到图像生成中的应用](https://arxiv.org/abs/2503.07334)
Token length: 1389
Summarized using gpt-4o-mini
Append: [基于SlotMIM的预训练视觉模型在机器人学习中的优化研究](https://arxiv.org/abs/2503.06960)
Token length: 853
Summarized using gpt-4o-mini
Append: [DiffCLIP：基于差分注意力机制的视觉-语言模型](https://arxiv.org/abs/2503.06626)
Token length: 1918
Summarized using gpt-4o-mini
Append: [Symbolic-MoE：基于技能的专家选择框架提升LLM性能](https://arxiv.org/abs/2503.05641)
append_entries: 6
Finish: 2025-03-11 18:01:38.956639
------------------------------------------------------
Started: 2025-03-11 21:00:53.296461
Existing_entries: 525
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1394
Summarized using gpt-4o-mini
Append: [VACE：全能视频生成与编辑框架](https://arxiv.org/abs/2503.07598)
Token length: 1220
Summarized using gpt-4o-mini
Append: [提升模型领域泛化能力的方法研究](https://arxiv.org/abs/2503.06698)
Json decode failed:
{
  "title": "语言模型在一对多事实查询中的知识回忆机制",
  "keyword": ["语言模型", "知识回忆", "答案抑制"],
  "short_summary": "语言模型通过促进与抑制机制实现一对多事实查询。",
  "summary": "本文探讨了语言模型（LM）在处理一对多事实查询时如何同时进行知识回忆与避免重复答案。我们提出了一种促进-抑制机制：模型首先回忆出所有可能的答案，然后抑制之前生成的答案。具体而言，LM通过主题和先前答案的标记执行知识回忆，注意力机制传播主题信息，而多层感知机（MLP）则促进答案生成。随后，注意力机制针对并抑制先前的答案标记，而MLP增强抑制信号。通过丰富的实验数据支持该机制的有效性，我们还引入了Token Lens方法，分析特定标记的注意力更新，以及击败方法，研究去除特定标记的注意力后MLP输出的变化。这项研究为了解语言模型内部组件如何与不同输入标记交互，从而支持复杂的事实回忆提供了新视角。代码可在 https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 324 (char 445). Line: 406.
Append: [Promote, Suppress, Iterate: How Language Models Answer One-to-Many Factual Queries](https://arxiv.org/abs/2502.20475)
append_entries: 3
Finish: 2025-03-11 21:01:11.642646
------------------------------------------------------
Started: 2025-03-12 00:36:03.594709
Existing_entries: 528
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-12 00:36:03.910660
------------------------------------------------------
Started: 2025-03-12 03:18:26.258108
Existing_entries: 528
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 896
Summarized using gpt-4o-mini
Append: [PhiloBERTA：跨语言的古希腊与拉丁语词汇语义关系测量](https://arxiv.org/abs/2503.05265)
Json decode failed:
{
  "title": "基于费曼-卡克修正的有效取样方法",
  "keyword": ["生成模型", "取样方法", "费曼-卡克"],
  "short_summary": "本文提出了一种基于费曼-卡克修正的有效取样方法。",
  "summary": "本文探讨了在基于评分的生成模型中控制推理行为的新方法。现有的无分类器指导方法依赖简单启发式，将条件和无条件得分混合，无法有效近似中间分布，导致额外的"修正"步骤。我们提出了一种高效且原则性的取样方法，利用来自预训练评分模型的退火、几何平均或乘积分布。通过导出基于费曼-卡克公式的加权仿真方案（Feynman-Kac Correctors, FKC），我们精确考虑适当偏微分方程（PDE）中的各项。为了模拟这些PDE，我们提出了利用推理时间缩放以提升取样质量的序列蒙特卡洛（SMC）重采样算法。通过推理时间温度退火、提升多目标分子生成的表现，以及改善文本到图像生成的无分类器指导，我们实证验证了我们方法的实用性。"
}Summarization failed, append the original article
error: Expecting ',' delimiter: line 5 column 90 (char 209). Line: 406.
Append: [Feynman-Kac Correctors in Diffusion: Annealing, Guidance, and Product of Experts](https://arxiv.org/abs/2503.02819)
append_entries: 2
Finish: 2025-03-12 03:18:37.501434
------------------------------------------------------
Started: 2025-03-12 06:00:53.669010
Existing_entries: 530
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1328
Summarized using gpt-4o-mini
Append: [新型视觉标记化框架的结构化实现](https://arxiv.org/abs/2503.08685)
Token length: 1653
Summarized using gpt-4o-mini
Append: [SynCoS：一种同步耦合采样框架用于长视频生成](https://arxiv.org/abs/2503.08605)
Token length: 1550
Summarized using gpt-4o-mini
Append: [UniF^2ace：用于细粒度面部理解与生成的统一多模态模型](https://arxiv.org/abs/2503.08120)
Token length: 1456
Summarized using gpt-4o-mini
Append: [促进东南亚文化多样性：SEA-VL开放源代码计划](https://arxiv.org/abs/2503.07920)
Token length: 1280
Summarized using gpt-4o-mini
Append: [VidDiff：识别视频中细微动作差异的新任务与基准](https://arxiv.org/abs/2503.07860)
Token length: 1910
Summarized using gpt-4o-mini
Append: [Seedream 2.0：双语图像生成模型的进步](https://arxiv.org/abs/2503.07703)
Token length: 1322
Summarized using gpt-4o-mini
Append: [语言模型的隐式推理能力与多步骤推理的研究](https://arxiv.org/abs/2503.07604)
Token length: 1618
Summarized using gpt-4o-mini
Append: [优化测试时间计算的元强化学习方法](https://arxiv.org/abs/2503.07572)
Json decode failed:
{
  "title": "提升大规模多模态模型中的推理能力",
  "keyword": [
    "多模态推理",
    "强化学习",
    "基础推理增强"
  ],
  "short_summary": "提出一种两阶段框架以增强多模态模型的推理能力。",
  "summary": "本文探讨了在大规模多模态模型中增强推理能力所面临的独特挑战，特别是在3B参数的紧凑架构中，视觉感知与逻辑推理之间的复杂相互作用限制了推理能力和模态对齐。针对基于规则的强化学习在文本领域的优越表现，提出了一种名为\method的两阶段框架，通过基础推理增强（FRE）和多模态泛化训练（MGT）来适应多模态推理需求。FRE阶段利用文本数据强化推理能力，而MGT阶段则将这些能力推广至多模态领域。在Qwen2.5-VL-Instruct-3B上的实验显示，\method在多模态和文本基准上分别比基线平均提高了4.83%和4.5%，在复杂的足球比赛任务中提高了3.63%。这些结果验证了基于文本的推理增强能够有效实现多模态泛化，提供了一种绕过高质量多模态训练数据的成本有效方案。"
}Summarization failed, append the original article
error: Invalid \escape: line 9 column 120 (char 256). Line: 406.
Append: [LMM-R1: Empowering 3B LMMs with Strong Reasoning Abilities Through Two-Stage Rule-Based RL](https://arxiv.org/abs/2503.07536)
Token length: 1460
Summarized using gpt-4o-mini
Append: [MoE-X：一种具备内在可解释性的混合专家语言模型](https://arxiv.org/abs/2503.07639)
append_entries: 10
Finish: 2025-03-12 06:01:55.587084
------------------------------------------------------
Started: 2025-03-12 09:01:07.885419
Existing_entries: 540
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1476
Summarized using gpt-4o-mini
Append: [QuoTA：基于查询重要性评估的视频标记分配模型](https://arxiv.org/abs/2503.08689)
Token length: 1380
Summarized using gpt-4o-mini
Append: [OmniMamba：首个线性架构的多模态生成模型](https://arxiv.org/abs/2503.08686)
Token length: 1452
Summarized using gpt-4o-mini
Append: [YuE：创新的长篇音乐生成模型](https://arxiv.org/abs/2503.08638)
Token length: 1774
Summarized using gpt-4o-mini
Append: [新的人类类掩膜标注任务：提升多模态大语言模型的像素理解能力](https://arxiv.org/abs/2503.08625)
Token length: 1567
Summarized using gpt-4o-mini
Append: [LightGen：一种高效的文本到图像生成方法](https://arxiv.org/abs/2503.08619)
Token length: 1139
Summarized using gpt-4o-mini
Append: [BiasEdit：一种去除语言模型刻板偏见的高效编辑方法](https://arxiv.org/abs/2503.08588)
Token length: 1050
Summarized using gpt-4o-mini
Append: [Gemini Embedding：多语言嵌入模型的突破](https://arxiv.org/abs/2503.07891)
Token length: 920
Summarized using gpt-4o-mini
Append: [RayFlow: 一种提升扩散模型生成效率的新框架](https://arxiv.org/abs/2503.07699)
Token length: 1908
Summarized using gpt-4o-mini
Append: [生存游戏：评估人工智能自主水平的框架](https://arxiv.org/abs/2502.18858)
append_entries: 9
Finish: 2025-03-12 09:02:02.526145
------------------------------------------------------
Started: 2025-03-12 12:13:40.001610
Existing_entries: 549
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1396
Summarized using gpt-4o-mini
Append: [提升计算机视觉中的个体识别能力：RexSeek模型与HumanRef数据集](https://arxiv.org/abs/2503.08507)
Token length: 1162
Summarized using gpt-4o-mini
Append: [一种无训练的人脸匿名化方法](https://arxiv.org/abs/2503.08478)
Token length: 860
Summarized using gpt-4o-mini
Append: [一种新型Transformer架构用于音视频生成的研究](https://arxiv.org/abs/2503.08307)
Token length: 1782
Summarized using gpt-4o-mini
Append: [智能记忆管理系统SECOND ME的创新应用](https://arxiv.org/abs/2503.08102)
Token length: 1201
Summarized using gpt-4o-mini
Append: [结合大语言模型与神经机器翻译的高效模型](https://arxiv.org/abs/2503.06594)
Token length: 1164
Summarized using gpt-4o-mini
Append: [VisualSimpleQA：一项针对大规模视觉语言模型的多模态基准评测](https://arxiv.org/abs/2503.06492)
Token length: 1601
Summarized using gpt-4o-mini
Append: [MagicInfinite：高保真多角色肖像动画的新方法](https://arxiv.org/abs/2503.05978)
Token length: 1585
Summarized using gpt-4o-mini
Append: [AI4SE基准的评估与优化：BenchScout和BenchFrame的应用](https://arxiv.org/abs/2503.05860)
append_entries: 8
Finish: 2025-03-12 12:14:29.406469
------------------------------------------------------
Started: 2025-03-12 15:01:02.049296
Existing_entries: 557
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1348
Summarized using gpt-4o-mini
Append: [源偏差与PLM基础检索模型的因果分析](https://arxiv.org/abs/2503.08684)
Token length: 977
Summarized using gpt-4o-mini
Append: [AnyMoLe：一种无数据集依赖的角色运动插值方法](https://arxiv.org/abs/2503.08417)
append_entries: 2
Finish: 2025-03-12 15:01:21.746205
------------------------------------------------------
Started: 2025-03-12 18:10:28.691344
Existing_entries: 559
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1102
Summarized using gpt-4o-mini
Append: [指令跟随检索器的安全风险研究](https://arxiv.org/abs/2503.08644)
Token length: 1251
Summarized using gpt-4o-mini
Append: [ObjectMover：应对复杂场景的物体移动生成模型](https://arxiv.org/abs/2503.08037)
Token length: 1315
Summarized using gpt-4o-mini
Append: [多模态基础模型在自驾车中人类与机器驾驶反应的比较研究](https://arxiv.org/abs/2503.07587)
Token length: 1187
Summarized using gpt-4o-mini
Append: [CineBrain：首个动态视听刺激下的EEG与fMRI同步记录数据集](https://arxiv.org/abs/2503.06940)
append_entries: 4
Finish: 2025-03-12 18:10:54.422211
------------------------------------------------------
Started: 2025-03-12 21:00:56.441148
Existing_entries: 563
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-12 21:00:56.730850
------------------------------------------------------
Started: 2025-03-13 00:36:50.507439
Existing_entries: 563
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 810
Summarized using gpt-4o-mini
Append: [引导矩匹配模型：快速稳定的生成模型](https://arxiv.org/abs/2503.07565)
Token length: 953
Summarized using gpt-4o-mini
Append: [多模态智能的推理优先视角及生成预训练算法的创新](https://arxiv.org/abs/2503.07154)
Token length: 1281
Summarized using gpt-4o-mini
Append: [通过容量感知推理优化混合专家模型的效率](https://arxiv.org/abs/2503.05066)
Token length: 1225
Summarized using gpt-4o-mini
Append: [深度检索模型中的偏见与鲁棒性研究](https://arxiv.org/abs/2503.05037)
Token length: 1155
Summarized using gpt-4o-mini
Append: [OTTER：一种新的视觉-语言-行动模型实现有效的机器人操作](https://arxiv.org/abs/2503.03734)
append_entries: 5
Finish: 2025-03-13 00:37:16.911314
------------------------------------------------------
Started: 2025-03-13 03:20:06.162343
Existing_entries: 568
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1259
Summarized using gpt-4o-mini
Append: [PlainQAFact框架在医疗领域中的事实性评估](https://arxiv.org/abs/2503.08890)
append_entries: 1
Finish: 2025-03-13 03:20:10.163092
------------------------------------------------------
Started: 2025-03-13 06:10:50.986485
Existing_entries: 569
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1043
Summarized using gpt-4o-mini
Append: [块扩散语言模型：突破生成限制的新方法](https://arxiv.org/abs/2503.09573)
Token length: 1288
Summarized using gpt-4o-mini
Append: [scMMGPT：结合细胞与文本建模的单细胞多模态生成预训练变换器](https://arxiv.org/abs/2503.09427)
append_entries: 2
Finish: 2025-03-13 06:11:03.139515
------------------------------------------------------
Started: 2025-03-13 09:00:52.457469
Existing_entries: 571
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1189
Summarized using gpt-4o-mini
Append: [TPDiff: 高效视频扩散模型的多阶段训练框架](https://arxiv.org/abs/2503.09566)
Token length: 1259
Summarized using gpt-4o-mini
Append: [增强一致性的潜在扩散模型（AF-LDM）](https://arxiv.org/abs/2503.09419)
Token length: 1473
Summarized using gpt-4o-mini
Append: [VLog: 一种基于语言模型的视频理解框架](https://arxiv.org/abs/2503.09402)
Token length: 1178
Summarized using gpt-4o-mini
Append: [Reangle-A-Video：新型同步多视角视频生成框架](https://arxiv.org/abs/2503.09151)
Token length: 1348
Summarized using gpt-4o-mini
Append: [Motion Anything：一种多模态运动生成框架](https://arxiv.org/abs/2503.06955)
append_entries: 5
Finish: 2025-03-13 09:01:31.764941
------------------------------------------------------
Started: 2025-03-13 12:14:03.571500
Existing_entries: 576
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1025
Summarized using gpt-4o-mini
Append: [RewardSDS: 基于对齐评分的采样优化方法](https://arxiv.org/abs/2503.09601)
Token length: 1231
Summarized using gpt-4o-mini
Append: [基于大语言模型的文本块处理优化研究](https://arxiv.org/abs/2503.09600)
Token length: 1348
Summarized using gpt-4o-mini
Append: [优化大语言模型的构建：上下文长度与注意力头的影响](https://arxiv.org/abs/2503.09579)
Token length: 1386
Summarized using gpt-4o-mini
Append: [通过可验证结果奖励强化学习提升视觉语言模型的推理能力](https://arxiv.org/abs/2503.08525)
Token length: 1424
Summarized using gpt-4o-mini
Append: [高效遥感图像的视觉语言理解方法](https://arxiv.org/abs/2503.07588)
Token length: 1830
Summarized using gpt-4o-mini
Append: [优化LLM的量化技术以提高代码生成效率](https://arxiv.org/abs/2503.07103)
Token length: 1087
Summarized using gpt-4o-mini
Append: [WildIFEval: 一个多约束用户指令评估数据集](https://arxiv.org/abs/2503.06573)
Token length: 790
Summarized using gpt-4o-mini
Append: [文档数量对检索增强生成性能的影响研究](https://arxiv.org/abs/2503.04388)
append_entries: 8
Finish: 2025-03-13 12:14:50.892657
------------------------------------------------------
Started: 2025-03-13 15:00:59.407126
Existing_entries: 584
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-13 15:00:59.642450
------------------------------------------------------
Started: 2025-03-13 18:00:43.601778
Existing_entries: 584
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1322
Summarized using gpt-4o-mini
Append: [BIMBA模型：应对长视频的高效视频问答](https://arxiv.org/abs/2503.09590)
Token length: 1201
Summarized using gpt-4o-mini
Append: [一种基于扩散的蒙特卡洛采样方法提升学习型RANSAC的泛化能力](https://arxiv.org/abs/2503.09410)
Token length: 920
Summarized using gpt-4o-mini
Append: [小型语言模型的自我纠错机制研究](https://arxiv.org/abs/2503.08681)
Token length: 957
Summarized using gpt-4o-mini
Append: [基于多代理的智能医疗助手：克服隐私与延迟挑战](https://arxiv.org/abs/2503.05397)
append_entries: 4
Finish: 2025-03-13 18:01:03.697579
------------------------------------------------------
Started: 2025-03-13 21:00:57.451865
Existing_entries: 588
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-13 21:00:57.701716
------------------------------------------------------
Started: 2025-03-14 00:35:49.160356
Existing_entries: 588
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1367
Summarized using gpt-4o-mini
Append: [Search-R1：通过强化学习优化的大型语言模型检索能力](https://arxiv.org/abs/2503.09516)
Token length: 1775
Summarized using gpt-4o-mini
Append: [改进机器学习力场在分布转移中的泛化能力](https://arxiv.org/abs/2503.08674)
Json decode failed:
{
  "title": "生成模型在物理模拟中的应用研究",
  "short_summary": "本文探讨生成模型在物理模拟中的性能与局限性。",
  "summary": "随着生成学习模型在复杂映射估计中的显著进展，本文建议研究其在物理模拟中的潜力。提供了一个包含30万个图像对的数据集及三个不同物理模拟任务的基线评估，旨在探讨两个问题：一是生成模型是否能够从输入输出图像对中学习复杂的物理关系；二是通过替代基于微分方程的模拟能实现多少加速。基线评估显示，尽管当前模型具有潜在的高加速能力，但在物理正确性方面也存在显著限制，这强调了迫切需要新的方法来加强物理正确性。数据、基线模型和评估代码可访问http:
  "keyword": ["生成模型", "物理模拟", "图像对"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 232 (char 308). Line: 406.
Append: [PhysicsGen: Can Generative Models Learn from Images to Predict Complex Physical Relations?](https://arxiv.org/abs/2503.05333)
append_entries: 3
Finish: 2025-03-14 00:36:03.332561
------------------------------------------------------
Started: 2025-03-14 03:19:24.134295
Existing_entries: 591
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-14 03:19:24.320271
------------------------------------------------------
Started: 2025-03-14 06:10:54.165399
Existing_entries: 591
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1469
Summarized using gpt-4o-mini
Append: [Generation Chain-of-Thought: 提升图像生成与编辑的推理驱动框架](https://arxiv.org/abs/2503.10639)
Token length: 1654
Summarized using gpt-4o-mini
Append: [提升蒸馏扩散模型多样性的研究](https://arxiv.org/abs/2503.10637)
Json decode failed:
{
  "title": "改进的条件最优传输方法提升无条件流匹配性能",
  "keyword": ["最优传输", "条件流匹配", "深度学习"],
  "short_summary": "提出条件最优传输C^2OT以改善流匹配中的训练和测试性能差异。",
  "summary": "本研究讨论了在无条件流匹配中使用的小批量最优传输方法，该方法通过简化计算减少了推理时的计算需求。然而，在条件流匹配中，该方法存在不足，因为默认的最优传输映射忽视了条件，导致训练过程中生成的先验分布存在偏斜。在测试时，我们无法使用偏斜的先验，而是从完整的无偏先验中进行采样。这种训练和测试之间的差距导致了性能下降。为了解决这一问题，我们提出了条件最优传输C^2OT，通过在计算最优传输分配时在成本矩阵中添加条件权重项来调整模型。实验表明，该简单修正方法在8gaussians-to-moons、CIFAR-10、ImageNet-32x32和ImageNet-256x256等数据集上均优于现有基线，展示了其在不同函数评估预算下的总体优势。代码可在 https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 345 (char 476). Line: 406.
Append: [The Curse of Conditions: Analyzing and Improving Optimal Transport for Conditional Flow-Based Generation](https://arxiv.org/abs/2503.10636)
Token length: 1571
Summarized using gpt-4o-mini
Append: [通用零样本目标导航的统一框架](https://arxiv.org/abs/2503.10630)
Token length: 1564
Summarized using gpt-4o-mini
Append: [R1-Onevision：跨模态推理模型的创新与评估](https://arxiv.org/abs/2503.10615)
Token length: 1540
Summarized using gpt-4o-mini
Append: [结合LLMs与图搜索的高效多回合图像编辑方法CoSTA*](https://arxiv.org/abs/2503.10613)
Token length: 1222
Summarized using gpt-4o-mini
Append: [GroundingSuite：推动视觉与语言交互的创新数据集](https://arxiv.org/abs/2503.10596)
Token length: 1223
Summarized using gpt-4o-mini
Append: [长上下文调优：提升视频生成一致性的训练方法](https://arxiv.org/abs/2503.10589)
Token length: 1421
Summarized using gpt-4o-mini
Append: [VisualWebInstruct：提升视觉语言模型推理能力的新数据集](https://arxiv.org/abs/2503.10582)
Token length: 1320
Summarized using gpt-4o-mini
Append: [ARPG：一种新型视觉自回归模型的提出](https://arxiv.org/abs/2503.10568)
Token length: 1079
Summarized using gpt-4o-mini
Append: [基于双偏好优化的新框架提升大型视觉语言模型的任务规划能力](https://arxiv.org/abs/2503.10480)
Token length: 1585
Summarized using gpt-4o-mini
Append: [Light-R1系列模型训练与性能提升研究](https://arxiv.org/abs/2503.10460)
Token length: 1877
Summarized using gpt-4o-mini
Append: [4D LangSplat：动态场景中的时间敏感语言查询](https://arxiv.org/abs/2503.10437)
Token length: 1517
Summarized using gpt-4o-mini
Append: [基于多模态大语言模型的多主体视频生成框架CINEMA](https://arxiv.org/abs/2503.10391)
Token length: 1804
Summarized using gpt-4o-mini
Append: [大型推理模型在机器翻译中的变革与挑战](https://arxiv.org/abs/2503.10351)
Token length: 899
Summarized using gpt-4o-mini
Append: [开源软件开发中错误报告讨论的毒性影响](https://arxiv.org/abs/2503.10072)
Token length: 1350
Summarized using gpt-4o-mini
Append: [Whisper模型的性能分析与量化方法研究](https://arxiv.org/abs/2503.09905)
Token length: 1328
Summarized using gpt-4o-mini
Append: [静默品牌攻击：数据中毒对文本生成图像模型的影响](https://arxiv.org/abs/2503.09669)
Token length: 1085
Summarized using gpt-4o-mini
Append: [Open-Sora 2.0：高效的商业级视频生成模型](https://arxiv.org/abs/2503.09642)
Token length: 925
Summarized using gpt-4o-mini
Append: [长输出生成的研究重要性与挑战](https://arxiv.org/abs/2503.04723)
append_entries: 20
Finish: 2025-03-14 06:12:25.197357
------------------------------------------------------
Started: 2025-03-14 09:00:41.330758
Existing_entries: 611
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1029
Summarized using gpt-4o-mini
Append: [探索Hugging Face模型的初步图谱及其潜力](https://arxiv.org/abs/2503.10633)
Token length: 1078
Summarized using gpt-4o-mini
Append: [动态Tanh：非标准化变压器的性能提升](https://arxiv.org/abs/2503.10622)
Token length: 1124
Summarized using gpt-4o-mini
Append: [Diffusion Transformers在文本到图像生成中的应用研究](https://arxiv.org/abs/2503.10618)
Token length: 1543
Summarized using gpt-4o-mini
Append: [SANA-Sprint：高效的文本到图像生成模型](https://arxiv.org/abs/2503.09641)
append_entries: 4
Finish: 2025-03-14 09:01:01.094616
------------------------------------------------------
Started: 2025-03-14 12:00:38.041598
Existing_entries: 615
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-14 12:00:38.297504
------------------------------------------------------
Started: 2025-03-14 15:00:39.898902
Existing_entries: 615
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1081
Summarized using gpt-4o-mini
Append: [文本到图像模型在分类概念生成中的应用研究](https://arxiv.org/abs/2503.10357)
Token length: 1249
Summarized using gpt-4o-mini
Append: [VisualPRM：增强多模态推理能力的过程奖励模型](https://arxiv.org/abs/2503.10291)
Token length: 837
Summarized using gpt-4o-mini
Append: [探究视觉语言模型在图像理解中的不足](https://arxiv.org/abs/2503.09837)
Token length: 1681
Summarized using gpt-4o-mini
Append: [CoRe²: 高效且有效的文本到图像生成模型推理框架](https://arxiv.org/abs/2503.09662)
Json decode failed:
{
  "title": "PerCoV2：一种新型的超低比特率感知图像压缩系统",
  "keyword": ["图像压缩", "感知质量", "低比特率"],
  "short_summary": "PerCoV2是一种新型的超低比特率图像压缩系统，旨在提升图像质量和压缩效率。",
  "summary": "PerCoV2是一种新开发的开源超低比特率感知图像压缩系统，专为带宽和存储受限的应用而设计。该系统在Careil等人之前工作的基础上进行了扩展，整合了Stable Diffusion 3生态系统，通过显式建模离散超潜图像分布，提高了熵编码效率。我们对最新的自回归方法（VAR和MaskGIT）进行了全面比较，并在大规模的MSCOCO-30k基准上评估了我们的方法。与以往的工作相比，PerCoV2在更低的比特率下实现了更高的图像保真度，同时保持了竞争力的感知质量，具有更省比特率的混合生成模式，并且完全基于公共组件构建。相关代码和训练模型将在https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 292 (char 435). Line: 406.
Append: [PerCoV2: Improved Ultra-Low Bit-Rate Perceptual Image Compression with Implicit Hierarchical Masked Image Modeling](https://arxiv.org/abs/2503.09368)
append_entries: 5
Finish: 2025-03-14 15:01:05.044930
------------------------------------------------------
Started: 2025-03-14 18:00:58.052788
Existing_entries: 620
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1315
Summarized using gpt-4o-mini
Append: [ConsisLoRA: 改进的样式转移方法与评估](https://arxiv.org/abs/2503.10614)
Token length: 1590
Summarized using gpt-4o-mini
Append: [应对大规模视觉语言模型中的物体幻觉挑战](https://arxiv.org/abs/2503.10602)
Token length: 1230
Summarized using gpt-4o-mini
Append: [融合视觉成分的生成框架：IP-Prior与基于LoRA的微调策略](https://arxiv.org/abs/2503.10365)
Token length: 965
Summarized using gpt-4o-mini
Append: [儿童与大型语言模型的安全性研究](https://arxiv.org/abs/2503.10242)
Token length: 1160
Summarized using gpt-4o-mini
Append: [DiLoCo在大模型训练中的扩展性研究](https://arxiv.org/abs/2503.09799)
Token length: 1684
Summarized using gpt-4o-mini
Append: [探索视觉Transformer模型中的关键神经元路径](https://arxiv.org/abs/2503.09046)
Token length: 1019
Summarized using gpt-4o-mini
Append: [OmniPaint：一种统一的图像对象去除与插入框架](https://arxiv.org/abs/2503.08677)
append_entries: 7
Finish: 2025-03-14 18:01:37.743478
------------------------------------------------------
Started: 2025-03-14 21:00:47.330299
Existing_entries: 627
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-14 21:00:47.681055
------------------------------------------------------
Started: 2025-03-15 00:35:45.038990
Existing_entries: 627
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1164
Summarized using gpt-4o-mini
Append: [无分类器引导在条件生成中的新视角](https://arxiv.org/abs/2503.10638)
Token length: 1901
Summarized using gpt-4o-mini
Append: [提高黑箱商业视觉语言模型的对抗攻击效果](https://arxiv.org/abs/2503.10635)
append_entries: 2
Finish: 2025-03-15 00:35:54.395312
------------------------------------------------------
Started: 2025-03-15 03:16:04.689202
Existing_entries: 629
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-15 03:16:04.863360
------------------------------------------------------
Started: 2025-03-15 06:09:34.632137
Existing_entries: 629
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 747
Summarized using gpt-4o-mini
Append: [PoseLess: 一种无姿态估计的机器人手控制框架](https://arxiv.org/abs/2503.07111)
append_entries: 1
Finish: 2025-03-15 06:09:38.629323
------------------------------------------------------
Started: 2025-03-15 09:00:57.082849
Existing_entries: 630
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-15 09:00:57.299565
------------------------------------------------------
Started: 2025-03-15 12:11:26.512590
Existing_entries: 630
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-15 12:11:26.717238
------------------------------------------------------
Started: 2025-03-15 15:00:32.792237
Existing_entries: 630
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-15 15:00:32.989741
------------------------------------------------------
Started: 2025-03-15 18:00:59.525518
Existing_entries: 630
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-15 18:00:59.767153
------------------------------------------------------
Started: 2025-03-15 21:00:40.600342
Existing_entries: 630
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-15 21:00:40.881444
------------------------------------------------------
Started: 2025-03-16 00:39:46.629217
Existing_entries: 630
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-16 00:39:46.899850
------------------------------------------------------
Started: 2025-03-16 03:23:06.808028
Existing_entries: 630
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-16 03:23:07.052956
------------------------------------------------------
Started: 2025-03-16 06:00:49.182711
Existing_entries: 630
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-16 06:00:49.353393
------------------------------------------------------
Started: 2025-03-16 09:00:33.015269
Existing_entries: 630
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-16 09:00:33.237482
------------------------------------------------------
Started: 2025-03-16 12:00:50.971612
Existing_entries: 630
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-16 12:00:51.344029
------------------------------------------------------
Started: 2025-03-16 15:00:40.513019
Existing_entries: 630
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-16 15:00:40.747204
------------------------------------------------------
Started: 2025-03-16 18:00:47.744940
Existing_entries: 630
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-16 18:00:47.940273
------------------------------------------------------
Started: 2025-03-16 21:00:38.309709
Existing_entries: 630
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-16 21:00:38.585867
------------------------------------------------------
Started: 2025-03-17 00:38:06.985044
Existing_entries: 630
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-17 00:38:07.229544
------------------------------------------------------
Started: 2025-03-17 03:22:25.646133
Existing_entries: 630
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-17 03:22:25.903122
------------------------------------------------------
Started: 2025-03-17 06:11:21.253047
Existing_entries: 630
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-17 06:11:21.462822
------------------------------------------------------
Started: 2025-03-17 09:00:28.781042
Existing_entries: 630
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1462
Summarized using gpt-4o-mini
Append: [ReCamMaster：一种新的视频重渲染框架实现动态镜头控制](https://arxiv.org/abs/2503.11647)
Token length: 1913
Summarized using gpt-4o-mini
Append: [利用对抗数据收集提高机器人操作的效率与性能](https://arxiv.org/abs/2503.11646)
Token length: 957
Summarized using gpt-4o-mini
Append: [状态空间模型的系统概述与应用](https://arxiv.org/abs/2503.11224)
Token length: 1375
Summarized using gpt-4o-mini
Append: [API与GUI基础大语言模型代理的比较研究](https://arxiv.org/abs/2503.11069)
Token length: 1878
Summarized using gpt-4o-mini
Append: [TxAgent：推动精准药物治疗的多模态自适应AI模型](https://arxiv.org/abs/2503.10970)
Token length: 1423
Summarized using gpt-4o-mini
Append: [FlowTok：高效的文本与图像跨模态生成框架](https://arxiv.org/abs/2503.10772)
Token length: 1613
Summarized using gpt-4o-mini
Append: [基于可学习Kolmogorov-Arnold网络的视觉Transformer架构研究](https://arxiv.org/abs/2503.10632)
Token length: 1619
Summarized using gpt-4o-mini
Append: [联邦学习中的梯度反演攻击分析与防御策略](https://arxiv.org/abs/2503.11514)
Token length: 1279
Summarized using gpt-4o-mini
Append: [提升视频详细描述的模型：Cockatiel](https://arxiv.org/abs/2503.09279)
Token length: 1189
Summarized using gpt-4o-mini
Append: [PLADIS：基于稀疏注意力的高效文本到图像扩散模型优化方法](https://arxiv.org/abs/2503.07677)
Token length: 1897
Summarized using gpt-4o-mini
Append: [基于轨迹分布匹配的少步扩散模型学习](https://arxiv.org/abs/2503.06674)
Token length: 1615
Summarized using gpt-4o-mini
Append: [GoalFlow：高质量多模态轨迹生成的端到端自主驾驶方法](https://arxiv.org/abs/2503.05689)
append_entries: 12
Finish: 2025-03-17 09:01:41.966461
------------------------------------------------------
Started: 2025-03-17 12:13:44.636824
Existing_entries: 642
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1403
Summarized using gpt-4o-mini
Append: [基于密集边界框的视频字幕生成与物体定位新方法](https://arxiv.org/abs/2503.10781)
Token length: 1370
Summarized using gpt-4o-mini
Append: [新型ETC身体拟合方法提升衣着人类的拟合准确性](https://arxiv.org/abs/2503.10624)
Token length: 1627
Summarized using gpt-4o-mini
Append: [邻接自回归建模：一种新的视觉生成框架](https://arxiv.org/abs/2503.10696)
Token length: 1376
Summarized using gpt-4o-mini
Append: [MaRI框架：提升3D资产真实感的材料检索](https://arxiv.org/abs/2503.08111)
Token length: 1522
Summarized using gpt-4o-mini
Append: [ProJudgeBench：多模态大语言模型的过程评估基准](https://arxiv.org/abs/2503.06553)
Token length: 1503
Summarized using gpt-4o-mini
Append: [ARMOR：高效的多模态理解与生成框架](https://arxiv.org/abs/2503.06542)
append_entries: 6
Finish: 2025-03-17 12:14:11.762025
------------------------------------------------------
Started: 2025-03-17 15:00:54.087861
Existing_entries: 648
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 995
Summarized using gpt-4o-mini
Append: [VGGT：高效的3D场景属性推断网络](https://arxiv.org/abs/2503.11651)
Token length: 1216
Summarized using gpt-4o-mini
Append: [TreeMeshGPT：高质量艺术网格生成的新方法](https://arxiv.org/abs/2503.11629)
Token length: 1206
Summarized using gpt-4o-mini
Append: [VAMBA：高效处理长视频的混合变换器模型](https://arxiv.org/abs/2503.11579)
Token length: 1345
Summarized using gpt-4o-mini
Append: [SmolDocling：超紧凑的文档转换视觉语言模型](https://arxiv.org/abs/2503.11576)
Token length: 868
Summarized using gpt-4o-mini
Append: [将多语言大型语言模型扩展至语音模态的研究](https://arxiv.org/abs/2503.10620)
Token length: 1435
Summarized using gpt-4o-mini
Append: [群体鲁棒的机器遗忘：解决非均匀分布遗忘集的问题](https://arxiv.org/abs/2503.09330)
Token length: 1443
Summarized using gpt-4o-mini
Append: [基于自监督学习的视频技能边界检测](https://arxiv.org/abs/2503.10684)
append_entries: 7
Finish: 2025-03-17 15:01:27.920318
------------------------------------------------------
Started: 2025-03-17 18:10:16.765759
Existing_entries: 655
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-17 18:10:16.923095
------------------------------------------------------
Started: 2025-03-17 21:00:47.903413
Existing_entries: 655
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1632
Summarized using gpt-4o-mini
Append: [大规模推理模型在类比推理中的性能评估](https://arxiv.org/abs/2503.11207)
append_entries: 1
Finish: 2025-03-17 21:00:52.388294
------------------------------------------------------
Started: 2025-03-18 00:36:22.088674
Existing_entries: 656
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-18 00:36:22.251125
------------------------------------------------------
Started: 2025-03-18 03:21:45.411777
Existing_entries: 656
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1137
Summarized using gpt-4o-mini
Append: [CHOrD框架：高效生成3D室内场景的创新方法](https://arxiv.org/abs/2503.11958)
append_entries: 1
Finish: 2025-03-18 03:21:49.368334
------------------------------------------------------
Started: 2025-03-18 06:00:47.891377
Existing_entries: 657
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1377
Summarized using gpt-4o-mini
Append: [VideoMind：一个新的视频语言代理用于时间基础的视频理解](https://arxiv.org/abs/2503.13444)
Token length: 1541
Summarized using gpt-4o-mini
Append: [WideRange4D: 一种针对大范围空间运动的4D重建基准与方法](https://arxiv.org/abs/2503.13435)
Token length: 1873
Summarized using gpt-4o-mini
Append: [MicroVQA：生物医学研究中的多模态视觉问答基准](https://arxiv.org/abs/2503.13399)
Token length: 1212
Summarized using gpt-4o-mini
Append: [Edit Transfer: 基于少量示例的非刚性图像编辑技术](https://arxiv.org/abs/2503.13327)
Token length: 1494
Summarized using gpt-4o-mini
Append: [通过奖励增强的生成方法提升文本到图像生成控制能力](https://arxiv.org/abs/2503.13070)
Token length: 1293
Summarized using gpt-4o-mini
Append: [Step-wise Group Relative Policy Optimization提升多语言大型模型的推理能力](https://arxiv.org/abs/2503.12937)
Token length: 1544
Summarized using gpt-4o-mini
Append: [DreamRenderer：增强图像生成的实例控制](https://arxiv.org/abs/2503.12885)
Token length: 1323
Summarized using gpt-4o-mini
Append: [基于扩散变换器的个性化图像生成新方法](https://arxiv.org/abs/2503.12590)
Token length: 1626
Summarized using gpt-4o-mini
Append: [Being-0: 一种高效的人形机器人自主代理框架](https://arxiv.org/abs/2503.12533)
Token length: 895
Summarized using gpt-4o-mini
Append: [视觉语言模型中的基本水平分类研究](https://arxiv.org/abs/2503.12530)
Token length: 777
Summarized using gpt-4o-mini
Append: [量化大语言模型不确定性以增强用户信任](https://arxiv.org/abs/2503.12528)
Token length: 1330
Summarized using gpt-4o-mini
Append: [强化奖励模型的鲁棒性研究](https://arxiv.org/abs/2503.11751)
Token length: 1527
Summarized using gpt-4o-mini
Append: [视频时空推理基准V-STaR的提出及视频大语言模型评估](https://arxiv.org/abs/2503.11495)
Token length: 1775
Summarized using gpt-4o-mini
Append: [MTV-Inpaint：统一多任务视频修复框架](https://arxiv.org/abs/2503.11412)
Token length: 1247
Summarized using gpt-4o-mini
Append: [理论分析与改进：自回归视频扩散模型的统一框架](https://arxiv.org/abs/2503.10704)
append_entries: 15
Finish: 2025-03-18 06:02:09.945038
------------------------------------------------------
Started: 2025-03-18 09:00:45.126613
Existing_entries: 672
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1218
Summarized using gpt-4o-mini
Append: [BlobCtrl：精确灵活的元素级视觉内容生成与编辑框架](https://arxiv.org/abs/2503.13434)
Token length: 1558
Summarized using gpt-4o-mini
Append: [提升视频生成的时空一致性研究](https://arxiv.org/abs/2503.06053)
append_entries: 2
Finish: 2025-03-18 09:00:54.258603
------------------------------------------------------
Started: 2025-03-18 12:00:58.596425
Existing_entries: 674
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1009
Summarized using gpt-4o-mini
Append: [Sightation：提升视觉障碍者图表描述的模型评估与数据集](https://arxiv.org/abs/2503.13369)
Token length: 1498
Summarized using gpt-4o-mini
Append: [基于人类指令的混杂物品抓取任务研究](https://arxiv.org/abs/2503.13082)
Token length: 1251
Summarized using gpt-4o-mini
Append: [多模态链条思维推理的系统性综述](https://arxiv.org/abs/2503.12605)
Token length: 1221
Summarized using gpt-4o-mini
Append: [LVAS-Agent: 长视频音频合成的新框架](https://arxiv.org/abs/2503.10719)
append_entries: 4
Finish: 2025-03-18 12:01:23.051761
------------------------------------------------------
Started: 2025-03-18 15:00:45.199332
Existing_entries: 678
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1600
Summarized using gpt-4o-mini
Append: [SPIN-Bench: 评估战略规划与社会推理的新基准](https://arxiv.org/abs/2503.12349)
append_entries: 1
Finish: 2025-03-18 15:00:51.542455
------------------------------------------------------
Started: 2025-03-18 18:00:44.837111
Existing_entries: 679
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1431
Summarized using gpt-4o-mini
Append: [GenStereo：高质量立体图像生成的新方法](https://arxiv.org/abs/2503.12720)
Token length: 1763
Summarized using gpt-4o-mini
Append: [WISA: 提升文本生成视频模型物理理解的新框架](https://arxiv.org/abs/2503.08153)
append_entries: 2
Finish: 2025-03-18 18:00:55.283478
------------------------------------------------------
Started: 2025-03-18 21:00:54.425873
Existing_entries: 681
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 607
Summarized using gpt-4o-mini
Append: [可扩展的开源视频基础模型训练管道](https://arxiv.org/abs/2503.12964)
append_entries: 1
Finish: 2025-03-18 21:00:58.354225
------------------------------------------------------
Started: 2025-03-19 00:36:48.815960
Existing_entries: 682
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "利用机械解释性技术的白盒对抗攻击新方法",
  "short_summary": "提出一种新方法，通过机械解释性技术提高对抗攻击成功率。",
  "summary": "本文介绍了一种新颖的白盒对抗攻击方法，结合了机械解释性技术以生成实用的对抗输入。该方法通过识别接受子空间，即不会触发模型拒绝机制的特征向量集合，采用基于梯度的优化技术将嵌入从拒绝子空间重新引导到接受子空间，以实现快速的‘越狱’效果。这种针对性的策略显著降低了计算成本，相较于现有技术，该方法在包括Gemma2、Llama3.2和Qwen2.5的先进模型上取得了80-95%的攻击成功率，仅需数分钟或甚至几秒钟。此外，该方法为攻击研究和防御开发开辟了新的方向，并展示了机械解释性的实际应用价值。相关代码和生成的数据集可在 https:
  "keyword": ["对抗攻击", "机械解释性", "接受子空间"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 281 (char 366). Line: 406.
Append: [Using Mechanistic Interpretability to Craft Adversarial Attacks against Large Language Models](https://arxiv.org/abs/2503.06269)
append_entries: 1
Finish: 2025-03-19 00:36:53.026687
------------------------------------------------------
Started: 2025-03-19 03:21:36.817233
Existing_entries: 683
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "RWKV-7 "Goose": 一种新的序列建模架构与多语言任务的最佳性能表现",
  "keyword": ["RWKV-7", "序列建模", "语言模型"],
  "short_summary": "RWKV-7在多语言任务上创造了新的最佳性能记录。",
  "summary": "RWKV-7 "Goose"是一种新型序列建模架构，提供了三十亿参数规模下的预训练语言模型，在多语言任务上创造了新的最佳性能，尽管其训练所用的语料远少于其他顶级模型。该模型在每个token的推理时间和内存使用上均保持恒定，展现出其新的广义delta规则与向量值门控及上下文学习率的结合。RWKV-7不仅能够进行状态跟踪和识别所有正规语言，还保留了训练的并行性，超越了标准复杂性猜想下的Transformer能力。同时，我们还推出了一个扩展的开源多语言语料库，包含3.1万亿个token，并基于此数据集训练了四个不同参数规模的RWKV-7模型。为促进开放性和复现性，我们发布了模型及数据集组件，代码托管在公有GitHub上，以Apache 2.0 License开放。"
}Summarization failed, append the original article
error: Expecting ',' delimiter: line 2 column 21 (char 22). Line: 406.
Append: [RWKV-7 "Goose" with Expressive Dynamic State Evolution](https://arxiv.org/abs/2503.14456)
Token length: 1301
Summarized using gpt-4o-mini
Append: [IPV-Bench：评估生成与理解不可能视频的新基准](https://arxiv.org/abs/2503.14378)
Token length: 941
Summarized using gpt-4o-mini
Append: [Frac-Connections：一种新型的深度学习连接方法](https://arxiv.org/abs/2503.14125)
Token length: 892
Summarized using gpt-4o-mini
Append: [Infinite Mobility：一种生成高保真关节物体的新方法](https://arxiv.org/abs/2503.13424)
Token length: 1280
Summarized using gpt-4o-mini
Append: [提升多模态大语言模型安全性的机器去学习基准研究](https://arxiv.org/abs/2503.12545)
Token length: 1252
Summarized using gpt-4o-mini
Append: [MPBench：评估过程级奖励模型的多任务基准](https://arxiv.org/abs/2503.12505)
Token length: 1348
Summarized using gpt-4o-mini
Append: [KUDA：集成动态学习与视觉提示的开放词汇操控系统](https://arxiv.org/abs/2503.10546)
Token length: 1619
Summarized using gpt-4o-mini
Append: [RoCo-Sim：提升路边协同感知的新模拟框架](https://arxiv.org/abs/2503.10410)
append_entries: 8
Finish: 2025-03-19 03:22:18.476850
------------------------------------------------------
Started: 2025-03-19 06:11:35.474812
Existing_entries: 691
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1561
Summarized using gpt-4o-mini
Append: [多模态大语言模型的对齐算法综述](https://arxiv.org/abs/2503.14504)
Token length: 1297
Summarized using gpt-4o-mini
Append: [AI系统任务完成时间的新度量与未来展望](https://arxiv.org/abs/2503.14499)
Json decode failed:
{
  "title": "基于时间一致性的数学验证方法",
  "keyword": ["时间一致性", "数学验证", "深度学习"],
  "short_summary": "提出一种新型时间一致性方法以提升数学验证的准确性。",
  "summary": "本文介绍了一种新颖的时间一致性方法旨在提升数学验证的效果。与传统的一轮验证或多模型辩论方法不同，我们的方法通过迭代反思的方式，基于先前的评估来逐步精炼判断，从而提高验证准确性。通过在多种数学过程错误识别基准（Mathcheck、ProcessBench和PRM800K）上的实证评估，证明了该方法在性能上一致性地优于基准方法。特别是在近期的DeepSeek R1蒸馏模型应用中，我们的方法使得7B/8B蒸馏模型的表现超越所有70B/72B模型及GPT-4o。同时，蒸馏的14B模型在应用该方法后表现可与Deepseek-R1相媲美。相关代码已发布在https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 295 (char 413). Line: 406.
Append: [Temporal Consistency for LLM Reasoning Process Error Identification](https://arxiv.org/abs/2503.14495)
Token length: 951
Summarized using gpt-4o-mini
Append: [Cosmos-Transfer: 基于多模态输入的条件世界生成模型](https://arxiv.org/abs/2503.14492)
Token length: 1309
Summarized using gpt-4o-mini
Append: [Creation-MMBench: 评估多模态大语言模型创意能力的新基准](https://arxiv.org/abs/2503.14478)
Token length: 985
Summarized using gpt-4o-mini
Append: [开放源码的大规模强化学习系统提升LLM推理能力](https://arxiv.org/abs/2503.14476)
Token length: 1640
Summarized using gpt-4o-mini
Append: [DeepPerception: 融合认知视觉感知的多模态大型语言模型](https://arxiv.org/abs/2503.12797)
Token length: 1415
Summarized using gpt-4o-mini
Append: [CapArena：评估视觉语言模型在图像描述中的表现](https://arxiv.org/abs/2503.12329)
Token length: 1600
Summarized using gpt-4o-mini
Append: [Reflect-DiT：用于文本到图像生成的推理时间扩展](https://arxiv.org/abs/2503.12271)
append_entries: 9
Finish: 2025-03-19 06:12:28.307277
------------------------------------------------------
Started: 2025-03-19 09:01:00.163050
Existing_entries: 700
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 902
Summarized using gpt-4o-mini
Append: [Concat-ID：统一的身份保持视频生成框架](https://arxiv.org/abs/2503.14151)
append_entries: 1
Finish: 2025-03-19 09:01:06.583142
------------------------------------------------------
Started: 2025-03-19 12:13:47.378051
Existing_entries: 701
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1419
Summarized using gpt-4o-mini
Append: [小规模高质量数据集提升大型语言模型推理能力的研究](https://arxiv.org/abs/2503.13661)
Token length: 1240
Summarized using gpt-4o-mini
Append: [FlexWorld: 从单幅图像生成灵活视角3D场景](https://arxiv.org/abs/2503.13265)
Token length: 1007
Summarized using gpt-4o-mini
Append: [提升3D空间理解能力的多模态大型语言模型研究](https://arxiv.org/abs/2503.13111)
Token length: 1491
Summarized using gpt-4o-mini
Append: [基于超曲率空间的安全意识视觉-语言模型HySAC的提出](https://arxiv.org/abs/2503.12127)
Token length: 1544
Summarized using gpt-4o-mini
Append: [Florenz: 单语视觉语言模型在多语种任务中的系统性泛化研究](https://arxiv.org/abs/2503.09443)
append_entries: 5
Finish: 2025-03-19 12:14:18.742300
------------------------------------------------------
Started: 2025-03-19 15:01:10.265220
Existing_entries: 706
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1843
Summarized using gpt-4o-mini
Append: [自我提升认知框架：构建下一代多模态大型语言模型](https://arxiv.org/abs/2503.12303)
append_entries: 1
Finish: 2025-03-19 15:01:21.558913
------------------------------------------------------
Started: 2025-03-19 18:01:12.947140
Existing_entries: 707
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1278
Summarized using gpt-4o-mini
Append: [MeshFleet：高质量三维车辆数据集的自动过滤与注释](https://arxiv.org/abs/2503.14002)
Token length: 1136
Summarized using gpt-4o-mini
Append: [Multi-Scale Attention模型与Atlas架构在大规模图像建模中的应用](https://arxiv.org/abs/2503.12355)
Token length: 1159
Summarized using gpt-4o-mini
Append: [AdaLLaVA：一种自适应的多模态大型语言模型推断框架](https://arxiv.org/abs/2503.10905)
Token length: 1416
Summarized using gpt-4o-mini
Append: [AudioX：统一的音频与音乐生成模型](https://arxiv.org/abs/2503.10522)
Token length: 1428
Summarized using gpt-4o-mini
Append: [EvalTree: 生成语言模型弱点档案的创新方法](https://arxiv.org/abs/2503.08893)
Token length: 1502
Summarized using gpt-4o-mini
Append: [CoLMDriver: 基于大语言模型的协作驾驶系统](https://arxiv.org/abs/2503.08683)
append_entries: 6
Finish: 2025-03-19 18:01:48.265665
------------------------------------------------------
Started: 2025-03-19 21:00:52.365228
Existing_entries: 713
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-19 21:00:52.780095
------------------------------------------------------
Started: 2025-03-20 00:35:57.844266
Existing_entries: 713
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-20 00:35:58.061026
------------------------------------------------------
Started: 2025-03-20 03:20:03.099189
Existing_entries: 713
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1241
Summarized using gpt-4o-mini
Append: [PyGDA：开源图域适配库的发布](https://arxiv.org/abs/2503.10284)
append_entries: 1
Finish: 2025-03-20 03:20:07.143458
------------------------------------------------------
Started: 2025-03-20 06:11:07.971825
Existing_entries: 714
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-20 06:11:08.228982
------------------------------------------------------
Started: 2025-03-20 09:00:48.241911
Existing_entries: 714
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1377
Summarized using gpt-4o-mini
Append: [TULIP：提升图像理解的开源CLIP替代模型](https://arxiv.org/abs/2503.15485)
Token length: 1110
Summarized using gpt-4o-mini
Append: [构建3D智能的基础模型：Roblox的探索与设计](https://arxiv.org/abs/2503.15475)
Token length: 919
Summarized using gpt-4o-mini
Append: [FluxFlow: 提升视频生成的时间质量](https://arxiv.org/abs/2503.15417)
Token length: 1087
Summarized using gpt-4o-mini
Append: [DeepMesh：优化三维网格生成的框架](https://arxiv.org/abs/2503.15265)
Token length: 1257
Summarized using gpt-4o-mini
Append: [ELTEX框架：专用领域合成训练数据生成的有效解决方案](https://arxiv.org/abs/2503.15055)
Token length: 1686
Summarized using gpt-4o-mini
Append: [基于文本反演的扩散模型个性化量化方法](https://arxiv.org/abs/2503.14868)
Json decode failed:
{
  "title": "MusicInfuser：基于音乐生成高质量舞蹈视频的方法",
  "keyword": ["音频视频模型", "舞蹈视频生成", "音乐同步"],
  "short_summary": "MusicInfuser利用现有模型实现与音乐同步的舞蹈视频生成。",
  "summary": "MusicInfuser是一种生成高质量舞蹈视频的创新方法，能够与指定的音乐曲目同步。该方法通过引入轻量级的音乐-视频交叉注意机制和低秩适配器，改进了现有的视频扩散模型，而不需设计新的多模态音视频模型。与以往需要运动捕捉数据的研究不同，MusicInfuser只针对舞蹈视频进行微调，从而实现高质量的音乐驱动视频生成，并保持基础模型的灵活性和生成能力。此外，项目还引入了一种评估框架，利用视频大语言模型（Video-LLMs）来评估舞蹈生成质量的多个维度。项目页面和代码可以访问https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 260 (char 404). Line: 406.
Append: [MusicInfuser: Making Video Diffusion Listen and Dance](https://arxiv.org/abs/2503.14505)
Token length: 1244
Summarized using gpt-4o-mini
Append: [扩展流媒体视频理解的新任务与ViSpeak模型](https://arxiv.org/abs/2503.12769)
Token length: 1233
Summarized using gpt-4o-mini
Append: [STEVE：高效训练计算机使用代理的步骤验证管道](https://arxiv.org/abs/2503.12532)
append_entries: 9
Finish: 2025-03-20 09:01:22.798884
------------------------------------------------------
Started: 2025-03-20 12:13:54.029026
Existing_entries: 723
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1592
Summarized using gpt-4o-mini
Append: [SynthScars: 高质量合成图像数据集与LEGION图像伪造分析框架](https://arxiv.org/abs/2503.15264)
Token length: 1413
Summarized using gpt-4o-mini
Append: [提升多模态推理：取向视觉条件化的新方法](https://arxiv.org/abs/2503.13360)
Json decode failed:
{
  "title": "基于前瞻采样的phi-Decoding解码策略",
  "short_summary": "phi-Decoding通过前瞻采样优化推理过程，提升性能与效率。",
  "summary": "本文提出了一种新的解码策略phi-Decoding，以前瞻采样为基础，旨在高效地平衡推理过程中的探索与利用。尽管以往的基于搜索的方法解决了自回归生成中的短视问题，但广泛的搜索空间往往导致过度探索和不足的利用。而phi-Decoding通过模拟未来步骤来获得全局最优步骤估计，提高了步骤价值的精确性与表现力。该策略还支持适应性计算分配，利用宽度和深度剪枝策略实现了推理效率的轻量化。通过在七个基准测试上进行的广泛实验，phi-Decoding在性能与效率上超越了多个强基线。此外，分析表明其在多种大语言模型中可泛化，并能够在不同的计算预算下扩展。代码将发布于https:
  "keyword": ["推理优化", "phi-Decoding", "前瞻采样"]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 299 (char 394). Line: 406.
Append: [φ-Decoding: Adaptive Foresight Sampling for Balanced Inference-Time Exploration and Exploitation](https://arxiv.org/abs/2503.13288)
Token length: 1127
Summarized using gpt-4o-mini
Append: [统一构建广义知识图谱的框架研究](https://arxiv.org/abs/2503.11227)
append_entries: 4
Finish: 2025-03-20 12:14:17.183712
------------------------------------------------------
Started: 2025-03-20 15:00:47.183131
Existing_entries: 727
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1503
Summarized using gpt-4o-mini
Append: [KDTalker：结合无监督3D关键点与时空扩散模型的音频驱动人像生成框架](https://arxiv.org/abs/2503.12963)
append_entries: 1
Finish: 2025-03-20 15:02:32.682724
------------------------------------------------------
Started: 2025-03-20 18:10:22.618249
Existing_entries: 728
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1091
Summarized using gpt-4o-mini
Append: [动态解构框架提升长文本验证的准确性](https://arxiv.org/abs/2503.15354)
Token length: 1393
Summarized using gpt-4o-mini
Append: [MetaLadder：基于类比问题的数学推理框架](https://arxiv.org/abs/2503.14891)
Token length: 1228
Summarized using gpt-4o-mini
Append: [CURIE基准：评估大语言模型在科学问题解决中的能力](https://arxiv.org/abs/2503.13517)
append_entries: 3
Finish: 2025-03-20 18:10:33.519015
------------------------------------------------------
Started: 2025-03-20 21:00:57.081599
Existing_entries: 731
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1166
Summarized using gpt-4o-mini
Append: [基于多轮交互的新一代强化学习算法SWEET-RL](https://arxiv.org/abs/2503.15478)
Token length: 1039
Summarized using gpt-4o-mini
Append: [SkyLadder：一种优化的上下文窗口调度策略提升大规模语言模型预训练效率](https://arxiv.org/abs/2503.15450)
Token length: 1633
Summarized using gpt-4o-mini
Append: [DP-Recon: 使用扩散先验优化3D场景重建](https://arxiv.org/abs/2503.14830)
Token length: 1367
Summarized using gpt-4o-mini
Append: [LLM-FE: 基于大语言模型的自动化特征工程框架](https://arxiv.org/abs/2503.14434)
Json decode failed:
{
  "title": "VERIFY: A Benchmark for Visual Reasoning in Multimodal Large Language Models",
  "short_summary": "VERIFY introduces a new benchmark to rigorously evaluate the visual reasoning capabilities of MLLMs.",
  "summary": "VERIFY is a new benchmark designed to evaluate the visual reasoning abilities of Multimodal Large Language Models (MLLMs). Unlike existing benchmarks that mainly test recognition skills, VERIFY focuses on the models" ability to reason from visual data with minimal textual context. Each task is accompanied by a human-annotated reasoning path, making it unique in evaluating the model"s decision-making process. The benchmark also introduces novel metrics that assess visual reasoning fidelity, revealing critical shortcomings in current MLLMs" reasoning patterns. The findings emphasize the need for a more balanced approach to model development, integrating both perception and reasoning capabilities.",
  "keyword": ["visual reasoning", "MLLMs", "benchmark"]
}Summarization failed, append the original article
error: Expecting ',' delimiter: line 4 column 232 (char 447). Line: 406.
Append: [VERIFY: A Benchmark of Visual Explanation and Reasoning for Investigating Multimodal Reasoning Fidelity](https://arxiv.org/abs/2503.11557)
append_entries: 5
Finish: 2025-03-20 21:02:19.515954
------------------------------------------------------
Started: 2025-03-21 00:37:17.431333
Existing_entries: 736
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-21 00:37:17.632661
------------------------------------------------------
Started: 2025-03-21 03:22:08.242865
Existing_entries: 736
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1464
Summarized using gpt-4o-mini
Append: [三维空间多模态记忆系统M3的设计与应用](https://arxiv.org/abs/2503.16413)
Token length: 1316
Summarized using gpt-4o-mini
Append: [CaKE：一种有效的知识编辑方法提升LLM的多跳推理能力](https://arxiv.org/abs/2503.16356)
Json decode failed:
{
  "title": "Uni-3DAR：无缝集成3D结构生成与理解的统一框架",
  "keyword": ["3D结构生成", "自回归预测", "深度学习"],
  "short_summary": "Uni-3DAR通过自回归预测无缝整合3D结构生成与理解任务。",
  "summary": "Uni-3DAR是一个统一框架，旨在通过自回归预测集成3D结构生成与理解任务。该框架采用新颖的分层标记技术，通过八叉树压缩3D空间，充分利用3D结构的稀疏性，并细化了结构的关键属性如原子类型和精确的空间坐标。此外，Uni-3DAR提出了两项优化策略：一是双层子树压缩，能够将八叉树标记序列缩减至最多8倍；二是针对动态变化标记位置的掩码下一个标记预测机制，显著提高模型性能。通过这些策略，Uni-3DAR在多个微观3D生成与理解任务中展现出优异的效果和多样性，超越了最先进的扩散模型，取得了高达256\%的相对提升，并且推理速度提高了21.8倍。"
}Summarization failed, append the original article
error: Invalid \escape: line 5 column 264 (char 403). Line: 406.
Append: [Uni-3DAR: Unified 3D Generation and Understanding via Autoregression on Compressed Spatial Tokens](https://arxiv.org/abs/2503.16278)
Token length: 1008
Summarized using gpt-4o-mini
Append: [Fin-R1：专为金融领域设计的推理大型语言模型](https://arxiv.org/abs/2503.16252)
Token length: 1228
Summarized using gpt-4o-mini
Append: [欺骗幽默数据集（DHD）的构建与分析](https://arxiv.org/abs/2503.16031)
Token length: 1258
Summarized using gpt-4o-mini
Append: [Unified Variational Auto-Encoder在3D分子生成中的应用](https://arxiv.org/abs/2503.15567)
Token length: 1457
Summarized using gpt-4o-mini
Append: [Cosmos-Reason1模型：启用物理AI的链式推理与决策](https://arxiv.org/abs/2503.15558)
append_entries: 7
Finish: 2025-03-21 03:22:40.371971
------------------------------------------------------
Started: 2025-03-21 06:01:51.660038
Existing_entries: 743
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-21 06:01:51.873173
------------------------------------------------------
Started: 2025-03-21 09:00:47.358455
Existing_entries: 743
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1471
Summarized using gpt-4o-mini
Append: [XAttention: 高效的长上下文Transformer模型稀疏注意力框架](https://arxiv.org/abs/2503.16428)
Token length: 1408
Summarized using gpt-4o-mini
Append: [4D Gaussian Splatting的优化与提升](https://arxiv.org/abs/2503.16422)
Token length: 1667
Summarized using gpt-4o-mini
Append: [MagicMotion：精确轨迹控制的视频生成框架](https://arxiv.org/abs/2503.16421)
Token length: 1539
Summarized using gpt-4o-mini
Append: [优化大语言模型的高效推理方法综述](https://arxiv.org/abs/2503.16419)
Token length: 1143
Summarized using gpt-4o-mini
Append: [InfiniteYou：基于扩散变换器的高保真身份保留图像生成框架](https://arxiv.org/abs/2503.16418)
Token length: 1394
Summarized using gpt-4o-mini
Append: [基于视觉语言的后训练行动决策模型提升](https://arxiv.org/abs/2503.16365)
Token length: 1358
Summarized using gpt-4o-mini
Append: [超分辨率适应的关键指南URAE](https://arxiv.org/abs/2503.16322)
Token length: 1509
Summarized using gpt-4o-mini
Append: [FlashVDM：加速3D形状生成的新框架](https://arxiv.org/abs/2503.16302)
Token length: 1634
Summarized using gpt-4o-mini
Append: [MathFusion: 跨问题指令合成增强数学推理能力的框架](https://arxiv.org/abs/2503.16212)
Token length: 1469
Summarized using gpt-4o-mini
Append: [基于粗细预测的自回归图像生成模型](https://arxiv.org/abs/2503.16194)
Token length: 1919
Summarized using gpt-4o-mini
Append: [基于强化学习的少样本分类策略研究](https://arxiv.org/abs/2503.16188)
Token length: 978
Summarized using gpt-4o-mini
Append: [缓解视觉语言模型中的主导模态偏见的BalGrad框架](https://arxiv.org/abs/2503.13834)
Token length: 1403
Summarized using gpt-4o-mini
Append: [MagicID: 实现动态丰富且一致身份的视频生成](https://arxiv.org/abs/2503.12689)
append_entries: 13
Finish: 2025-03-21 09:01:44.921739
------------------------------------------------------
Started: 2025-03-21 12:13:22.975342
Existing_entries: 756
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1210
Summarized using gpt-4o-mini
Append: [LLM驱动代理的评估方法综述](https://arxiv.org/abs/2503.16416)
Token length: 1176
Summarized using gpt-4o-mini
Append: [高效生成多样化户外场景的方法研究](https://arxiv.org/abs/2503.16375)
Token length: 1426
Summarized using gpt-4o-mini
Append: [小型语言模型的强化学习推理能力提升研究](https://arxiv.org/abs/2503.16219)
Token length: 843
Summarized using gpt-4o-mini
Append: [Race-DiT: 一种新型混合专家模型在扩散变换器中的应用](https://arxiv.org/abs/2503.16057)
Token length: 1483
Summarized using gpt-4o-mini
Append: [SALT: 结合低秩变换的奇异值适应医学图像分割方法](https://arxiv.org/abs/2503.16055)
Token length: 1498
Summarized using gpt-4o-mini
Append: [Zero-1-to-A：提高4D可动画化头像生成质量的方法](https://arxiv.org/abs/2503.15851)
Token length: 1231
Summarized using gpt-4o-mini
Append: [MotionStreamer: 基于文本的流式动作生成新框架](https://arxiv.org/abs/2503.15451)
Token length: 1254
Summarized using gpt-4o-mini
Append: [DiffMoE：提升扩散模型图像生成能力的新方法](https://arxiv.org/abs/2503.14487)
Token length: 1330
Summarized using gpt-4o-mini
Append: [多智能体系统中的挑战与解决方案：综合研究与探索](https://arxiv.org/abs/2503.13657)
Token length: 1374
Summarized using gpt-4o-mini
Append: [基于单幅图像的高保真可动画人类重建模型LHM](https://arxiv.org/abs/2503.10625)
append_entries: 10
Finish: 2025-03-21 12:14:22.476848
------------------------------------------------------
Started: 2025-03-21 15:00:37.924568
Existing_entries: 766
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1219
Summarized using gpt-4o-mini
Append: [基于集合代币化的图像生成新范式](https://arxiv.org/abs/2503.16425)
Token length: 1051
Summarized using gpt-4o-mini
Append: [SwD：扩展的扩散模型蒸馏框架](https://arxiv.org/abs/2503.16397)
Token length: 1607
Summarized using gpt-4o-mini
Append: [VidKV：一种新型的低位数KV缓存量化方法用于视频大语言模型](https://arxiv.org/abs/2503.16257)
Token length: 1601
Summarized using gpt-4o-mini
Append: [机器智能驱动的药物依从性预测与干预系统](https://arxiv.org/abs/2503.16091)
Token length: 1626
Summarized using gpt-4o-mini
Append: [VideoRFSplat：一种直接的文本到3D模型生成方法](https://arxiv.org/abs/2503.15855)
Token length: 1215
Summarized using gpt-4o-mini
Append: [BigO(Bench)：评估生成模型理解和生成代码复杂性的基准](https://arxiv.org/abs/2503.15242)
Token length: 1236
Summarized using gpt-4o-mini
Append: [优化视频训练方法的令牌选择与增强工具Flux](https://arxiv.org/abs/2503.14237)
Token length: 1254
Summarized using gpt-4o-mini
Append: [RSD: 一种加速超分辨率扩散模型的新型蒸馏方法](https://arxiv.org/abs/2503.13358)
append_entries: 8
Finish: 2025-03-21 15:01:23.316043
------------------------------------------------------
Started: 2025-03-21 18:09:57.088917
Existing_entries: 774
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1295
Summarized using gpt-4o-mini
Append: [Sonata：高效自监督点云学习模型的创新与应用](https://arxiv.org/abs/2503.16429)
Token length: 803
Summarized using gpt-4o-mini
Append: [基于文本描述的3D世界生成方法SynCity](https://arxiv.org/abs/2503.16420)
Token length: 1573
Summarized using gpt-4o-mini
Append: [评估大型语言模型的事实知识编码能力](https://arxiv.org/abs/2503.15299)
Token length: 1628
Summarized using gpt-4o-mini
Append: [PORTAL：一种新型AI框架实现多3D游戏智能代理](https://arxiv.org/abs/2503.13356)
Token length: 1172
Summarized using gpt-4o-mini
Append: [TikZero：从图像到图形程序的文本驱动生成](https://arxiv.org/abs/2503.11509)
Token length: 1526
Summarized using gpt-4o-mini
Append: [利用多模态大语言模型评估AI生成视频的有效性](https://arxiv.org/abs/2503.09949)
append_entries: 6
Finish: 2025-03-21 18:10:31.141015
------------------------------------------------------
Started: 2025-03-21 21:00:35.738089
Existing_entries: 780
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-21 21:00:36.019804
------------------------------------------------------
Started: 2025-03-22 00:35:40.350777
Existing_entries: 780
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1517
Summarized using gpt-4o-mini
Append: [GASP：自主驾驶中的几何与语义自监督预训练方法](https://arxiv.org/abs/2503.15672)
Token length: 1828
Summarized using gpt-4o-mini
Append: [基于深度学习的代码补全工具的组织和开发者特定微调研究](https://arxiv.org/abs/2503.14201)
Json decode failed:
{
  "title": "分析大型视觉语言模型的视觉理解行为",
  "keyword": ["视觉语言模型", "视觉理解", "热图可视化"],
  "short_summary": "本文探讨了大型视觉语言模型在视觉理解中的依赖程度及其行为特征。",
  "summary": "本文旨在探讨大型视觉语言模型（LVLMs）在视觉理解和推理任务中的表现，尤其是它们对视觉输入的依赖程度及不同图像区域对响应的贡献。我们扩展了现有的热图可视化方法，以支持LVLM在开放式视觉问答中的应用。通过选择与生成答案相关的视觉标记，我们分析了LVLMs在需要视觉信息以作答的基准测试中的表现。研究发现了LVLM行为的多个重要见解，包括聚焦区域与答案正确性之间的关系、不同架构之间的视觉注意力差异以及大语言模型规模对视觉理解的影响。本文的代码和数据可在https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 248 (char 377). Line: 406.
Append: [Where do Large Vision-Language Models Look at when Answering Questions?](https://arxiv.org/abs/2503.13891)
Token length: 1420
Summarized using gpt-4o-mini
Append: [DeCapBench与DCScore：细节图像标注的新标准](https://arxiv.org/abs/2503.07906)
append_entries: 4
Finish: 2025-03-22 00:35:59.737910
------------------------------------------------------
Started: 2025-03-22 03:20:56.267744
Existing_entries: 784
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-22 03:20:56.476407
------------------------------------------------------
Started: 2025-03-22 06:00:41.001471
Existing_entries: 784
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-22 06:00:41.174974
------------------------------------------------------
Started: 2025-03-22 09:01:01.099162
Existing_entries: 784
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-22 09:01:01.313280
------------------------------------------------------
Started: 2025-03-22 12:00:41.781205
Existing_entries: 784
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-22 12:00:42.039994
------------------------------------------------------
Started: 2025-03-22 15:00:35.860586
Existing_entries: 784
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-22 15:00:36.103059
------------------------------------------------------
Started: 2025-03-22 18:00:35.367749
Existing_entries: 784
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-22 18:00:35.716844
------------------------------------------------------
Started: 2025-03-22 21:00:55.427536
Existing_entries: 784
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-22 21:00:55.589182
------------------------------------------------------
Started: 2025-03-23 00:40:03.004860
Existing_entries: 784
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-23 00:40:03.176627
------------------------------------------------------
Started: 2025-03-23 03:25:21.218669
Existing_entries: 784
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-23 03:25:21.392124
------------------------------------------------------
Started: 2025-03-23 06:00:44.871777
Existing_entries: 784
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-23 06:00:45.109608
------------------------------------------------------
Started: 2025-03-23 09:00:32.763465
Existing_entries: 784
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-23 09:00:33.008254
------------------------------------------------------
Started: 2025-03-23 12:12:07.787324
Existing_entries: 784
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-23 12:12:07.970750
------------------------------------------------------
Started: 2025-03-23 15:00:30.844179
Existing_entries: 784
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-23 15:00:31.085023
------------------------------------------------------
Started: 2025-03-23 18:00:57.054803
Existing_entries: 784
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-23 18:00:57.227434
------------------------------------------------------
Started: 2025-03-23 21:00:32.867473
Existing_entries: 784
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-23 21:00:33.079261
------------------------------------------------------
Started: 2025-03-24 00:38:34.315211
Existing_entries: 784
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-24 00:38:34.544106
------------------------------------------------------
Started: 2025-03-24 03:26:53.479476
Existing_entries: 784
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-24 03:26:53.742427
------------------------------------------------------
Started: 2025-03-24 06:11:29.587031
Existing_entries: 784
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1435
Summarized using gpt-4o-mini
Append: [深度视觉语言模型OpenVLThinker的推理能力提升研究](https://arxiv.org/abs/2503.17352)
Token length: 1151
Summarized using gpt-4o-mini
Append: [FastCuRL：高效的课程强化学习方法提升推理模型性能](https://arxiv.org/abs/2503.17287)
Token length: 1199
Summarized using gpt-4o-mini
Append: [提升创意写作生成的多样性与质量](https://arxiv.org/abs/2503.17126)
Token length: 1202
Summarized using gpt-4o-mini
Append: [VCtrl：提升视频生成中的细粒度控制能力](https://arxiv.org/abs/2503.16983)
Token length: 1359
Summarized using gpt-4o-mini
Append: [基于适应性DPO的图像生成模型偏好数据研究](https://arxiv.org/abs/2503.16921)
Token length: 1320
Summarized using gpt-4o-mini
Append: [基于多智能体框架的多模态科学问题解决策略](https://arxiv.org/abs/2503.16905)
Token length: 1230
Summarized using gpt-4o-mini
Append: [基于多智能体框架的自动化提示优化方法](https://arxiv.org/abs/2503.16874)
Token length: 1551
Summarized using gpt-4o-mini
Append: [TokenBridge：结合离散与连续Token的视觉生成模型](https://arxiv.org/abs/2503.16430)
Token length: 1134
Summarized using gpt-4o-mini
Append: [多智能体系统的组合约束与自动数据收集框架设计](https://arxiv.org/abs/2503.16408)
append_entries: 9
Finish: 2025-03-24 06:12:37.780198
------------------------------------------------------
Started: 2025-03-24 09:00:55.560196
Existing_entries: 793
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1570
Summarized using gpt-4o-mini
Append: [MathFlow：提升多模态大语言模型视觉数学问题解决能力的框架](https://arxiv.org/abs/2503.16549)
Token length: 1423
Summarized using gpt-4o-mini
Append: [针对长尾问题的自适应数据精炼框架在大视觉语言模型中的应用](https://arxiv.org/abs/2503.12821)
Token length: 985
Summarized using gpt-4o-mini
Append: [人工智能中的隐性偏见：通过推理模型隐性联想测试的研究](https://arxiv.org/abs/2503.11572)
append_entries: 3
Finish: 2025-03-24 09:01:20.104104
------------------------------------------------------
Started: 2025-03-24 12:14:31.765675
Existing_entries: 796
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1716
Summarized using gpt-4o-mini
Append: [PVChat：个性化视频大语言模型的单次学习框架](https://arxiv.org/abs/2503.17069)
Token length: 1395
Summarized using gpt-4o-mini
Append: [ETVA：一种新的文本到视频对齐评估方法](https://arxiv.org/abs/2503.16867)
Token length: 1385
Summarized using gpt-4o-mini
Append: [基于特征效用评估的视觉编码器优化方法](https://arxiv.org/abs/2503.16660)
append_entries: 3
Finish: 2025-03-24 12:14:48.311521
------------------------------------------------------
Started: 2025-03-24 15:00:43.804824
Existing_entries: 799
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1270
Summarized using gpt-4o-mini
Append: [FFaceNeRF：一种灵活的3D人脸编辑技术](https://arxiv.org/abs/2503.17095)
Token length: 1289
Summarized using gpt-4o-mini
Append: [TaoAvatar：高保真轻量级全身虚拟头像的实时渲染](https://arxiv.org/abs/2503.17032)
Token length: 1488
Summarized using gpt-4o-mini
Append: [融合3D视觉语言模型的通用少样本点云分割框架](https://arxiv.org/abs/2503.16282)
Token length: 1249
Summarized using gpt-4o-mini
Append: [SISO：基于单图像的个性化图像生成与编辑方法](https://arxiv.org/abs/2503.16025)
append_entries: 4
Finish: 2025-03-24 15:01:06.751301
------------------------------------------------------
Started: 2025-03-24 18:00:34.073742
Existing_entries: 803
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1555
Summarized using gpt-4o-mini
Append: [GAEA：图像地理定位中的对话模型创新](https://arxiv.org/abs/2503.16423)
append_entries: 1
Finish: 2025-03-24 18:00:39.598884
------------------------------------------------------
Started: 2025-03-24 21:00:28.411825
Existing_entries: 804
Fetching from https://rsshub.app/huggingface/daily-papers
Json decode failed:
{
  "title": "MapBench：针对人类可读的像素地图导航的首个数据集",
  "keyword": ["地图导航", "数据集", "空间推理"],
  "short_summary": "MapBench是首个为像素地图导航设计的数据集，挑战现有语言模型的推理能力。",
  "summary": "本文介绍了MapBench，这是首个专门为人类可读的像素地图导航设计的数据集，涵盖了复杂路径寻找场景。MapBench包含来自100个多样化地图的1600多个像素空间地图路径问题。通过提供Map Space Scene Graph（MSSG）作为索引数据结构，该数据集支持将自然语言转换并评估大型视觉语言模型（LVLM）生成的导航指令。我们的研究表明，MapBench显著提高了对先进LVLM的挑战，特别是在零-shot提示及基于思维链推理框架下，展示了地图导航过程的分解和认知过程的序列化。对开源和闭源LVLM的评估凸显了MapBench所带来的重大挑战，揭示这些模型在空间推理和结构化决策能力上的关键局限性。所有代码和数据集已在https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 337 (char 481). Line: 406.
Append: [Can Large Vision Language Models Read Maps Like a Human?](https://arxiv.org/abs/2503.14607)
append_entries: 1
Finish: 2025-03-24 21:00:32.693092
------------------------------------------------------
Started: 2025-03-25 00:37:29.529171
Existing_entries: 805
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-25 00:37:29.729463
------------------------------------------------------
Started: 2025-03-25 03:23:38.194872
Existing_entries: 805
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-25 03:23:38.420832
------------------------------------------------------
Started: 2025-03-25 06:00:42.269971
Existing_entries: 805
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1557
Summarized using gpt-4o-mini
Append: [Bottleneck Sampling：一种高效的扩散模型推理框架](https://arxiv.org/abs/2503.18940)
Token length: 691
Summarized using gpt-4o-mini
Append: [AlphaSpace：提升大型语言模型在3D空间导航中的空间推理能力](https://arxiv.org/abs/2503.18769)
Token length: 1848
Summarized using gpt-4o-mini
Append: [利用多模态LLM评估跨模态理解与生成任务](https://arxiv.org/abs/2503.17489)
Token length: 1016
Summarized using gpt-4o-mini
Append: [推动游戏开发革新的生成游戏引擎](https://arxiv.org/abs/2503.17359)
Token length: 1467
Summarized using gpt-4o-mini
Append: [通过错误学习提升大型语言模型的数学推理能力](https://arxiv.org/abs/2503.17439)
Token length: 1362
Summarized using gpt-4o-mini
Append: [MagicComp: 通过双阶段精炼提升文本生成视频的组合能力](https://arxiv.org/abs/2503.14428)
append_entries: 6
Finish: 2025-03-25 06:01:10.736318
------------------------------------------------------
Started: 2025-03-25 09:00:47.215375
Existing_entries: 811
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1308
Summarized using gpt-4o-mini
Append: [Aether框架：结合几何重建与生成建模的智能空间推理系统](https://arxiv.org/abs/2503.18945)
Token length: 1704
Summarized using gpt-4o-mini
Append: [探索测试时间扩展对视频生成质量的影响](https://arxiv.org/abs/2503.18942)
Token length: 1831
Summarized using gpt-4o-mini
Append: [Video SimpleQA：评估大型视频语言模型的事实性基准](https://arxiv.org/abs/2503.18923)
Token length: 1327
Summarized using gpt-4o-mini
Append: [FFN Fusion: 提升大规模语言模型推理效率的新技术](https://arxiv.org/abs/2503.18908)
Token length: 1536
Summarized using gpt-4o-mini
Append: [基于零强化学习的多模型链式推理训练研究](https://arxiv.org/abs/2503.18892)
Token length: 1570
Summarized using gpt-4o-mini
Append: [利用潜在思维推断提升语言模型预训练数据效率](https://arxiv.org/abs/2503.18866)
Token length: 857
Summarized using gpt-4o-mini
Append: [CaMeL：增强大语言模型安全性的防御措施](https://arxiv.org/abs/2503.18813)
Token length: 1787
Summarized using gpt-4o-mini
Append: [Hummingbird: 高效的文本到视频生成框架](https://arxiv.org/abs/2503.18559)
Token length: 1486
Summarized using gpt-4o-mini
Append: [AgentRxiv：促进科学研究的协作框架](https://arxiv.org/abs/2503.18102)
Token length: 1401
Summarized using gpt-4o-mini
Append: [Vision-R1: 一种新型的视觉引导强化学习算法](https://arxiv.org/abs/2503.18013)
Token length: 1902
Summarized using gpt-4o-mini
Append: [资源受限条件下视频生成模型的训练策略研究](https://arxiv.org/abs/2503.17735)
Token length: 933
Summarized using gpt-4o-mini
Append: [优化大语言模型预训练的权重初始化与方差控制策略](https://arxiv.org/abs/2503.17500)
Token length: 953
Summarized using gpt-4o-mini
Append: [优化RISC-V CPU上的大型语言模型推理](https://arxiv.org/abs/2503.17422)
Token length: 1746
Summarized using gpt-4o-mini
Append: [优化最小高斯表示法（OMG）在3D场景渲染中的应用](https://arxiv.org/abs/2503.16924)
Token length: 1318
Summarized using gpt-4o-mini
Append: [Typed-RAG: 面向非事实问答的多维度框架](https://arxiv.org/abs/2503.15879)
append_entries: 15
Finish: 2025-03-25 09:01:51.859378
------------------------------------------------------
Started: 2025-03-25 12:13:54.518544
Existing_entries: 826
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1398
Summarized using gpt-4o-mini
Append: [新型平衡图像建模框架的提出](https://arxiv.org/abs/2503.18948)
Token length: 1036
Summarized using gpt-4o-mini
Append: [CFG-Zero*: 改进的分类器自由引导技术](https://arxiv.org/abs/2503.18886)
Token length: 1145
Summarized using gpt-4o-mini
Append: [探究大型语言模型的推理机制：基于稀疏自编码器的分析](https://arxiv.org/abs/2503.18878)
Token length: 864
Summarized using gpt-4o-mini
Append: [CURA: 提升软件工程任务的代码理解与推理代理系统](https://arxiv.org/abs/2503.18494)
Token length: 1478
Summarized using gpt-4o-mini
Append: [MetaSpatial：基于强化学习的3D空间推理框架](https://arxiv.org/abs/2503.18470)
Token length: 1303
Summarized using gpt-4o-mini
Append: [Diffusion-4K：基于文本生成的超高分辨率图像合成框架](https://arxiv.org/abs/2503.18352)
Token length: 1273
Summarized using gpt-4o-mini
Append: [OmnimatteZero：一种无训练视频分层提取的新方法](https://arxiv.org/abs/2503.18033)
append_entries: 7
Finish: 2025-03-25 12:14:26.486228
------------------------------------------------------
Started: 2025-03-25 15:00:39.861052
Existing_entries: 833
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1839
Summarized using gpt-4o-mini
Append: [文化适应性对大型语言模型数学推理能力的影响研究](https://arxiv.org/abs/2503.18018)
append_entries: 1
Finish: 2025-03-25 15:00:46.062400
------------------------------------------------------
Started: 2025-03-25 18:00:42.076489
Existing_entries: 834
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1006
Summarized using gpt-4o-mini
Append: [人类运动去学习：防止合成有害动画的新方法](https://arxiv.org/abs/2503.18674)
Token length: 1244
Summarized using gpt-4o-mini
Append: [多模态推理的发展与挑战综述](https://arxiv.org/abs/2503.18071)
Token length: 1095
Summarized using gpt-4o-mini
Append: [Feather-SQL: 一种针对小型语言模型的轻量级NL2SQL框架](https://arxiv.org/abs/2503.17811)
Token length: 1234
Summarized using gpt-4o-mini
Append: [CODA：一种有效的视觉离散化框架](https://arxiv.org/abs/2503.17760)
Token length: 1916
Summarized using gpt-4o-mini
Append: [DynamicVis：面向遥感图像的动态视觉感知基础模型](https://arxiv.org/abs/2503.16426)
Token length: 1071
Summarized using gpt-4o-mini
Append: [基于变换器的多光源白平衡修正方法](https://arxiv.org/abs/2503.14774)
Token length: 1739
Summarized using gpt-4o-mini
Append: [揭示图像超分辨率评估中的地面真实图像质量影响](https://arxiv.org/abs/2503.13074)
append_entries: 7
Finish: 2025-03-25 18:01:06.688882
------------------------------------------------------
Started: 2025-03-25 21:00:35.997771
Existing_entries: 841
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-25 21:00:36.156533
------------------------------------------------------
Started: 2025-03-26 00:36:42.663719
Existing_entries: 841
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-26 00:36:42.857083
------------------------------------------------------
Started: 2025-03-26 03:22:17.708726
Existing_entries: 841
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1530
Summarized using gpt-4o-mini
Append: [基于视觉语言模型的3D室内场景生成算法研究](https://arxiv.org/abs/2503.18476)
Token length: 1485
Summarized using gpt-4o-mini
Append: [Instruct-CLIP：改进图像编辑指令对齐的自监督方法](https://arxiv.org/abs/2503.18406)
Token length: 1470
Summarized using gpt-4o-mini
Append: [QuartDepth：优化单目深度估计在ASIC上的应用](https://arxiv.org/abs/2503.16709)
append_entries: 3
Finish: 2025-03-26 03:22:35.459932
------------------------------------------------------
Started: 2025-03-26 06:00:39.224228
Existing_entries: 844
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1812
Summarized using gpt-4o-mini
Append: [CoLLM：增强复杂图像检索的综合框架](https://arxiv.org/abs/2503.19910)
Token length: 1702
Summarized using gpt-4o-mini
Append: [PS3：革命性的高分辨率视觉预训练方法](https://arxiv.org/abs/2503.19903)
Token length: 1321
Summarized using gpt-4o-mini
Append: [Multi-round Thinking：一种提升大语言模型推理性能的新方法](https://arxiv.org/abs/2503.19855)
Token length: 1391
Summarized using gpt-4o-mini
Append: [研究视频模态大规模多模态模型的幻觉问题](https://arxiv.org/abs/2503.19622)
Token length: 1066
Summarized using gpt-4o-mini
Append: [ReSearch：通过强化学习整合推理与搜索的框架](https://arxiv.org/abs/2503.19470)
Token length: 1495
Summarized using gpt-4o-mini
Append: [流模型的推理时刻扩展方法研究](https://arxiv.org/abs/2503.19385)
Token length: 1627
Summarized using gpt-4o-mini
Append: [长时间上下文视频生成的进展与Frame AutoRegressive模型](https://arxiv.org/abs/2503.19325)
Json decode failed:
{
  "title": "LookAhead Tuning：提升大语言模型安全性的有效方法",
  "short_summary": "LookAhead Tuning通过数据调整保持大语言模型的安全性。",
  "summary": "Fine-tuning尽管能让大型语言模型（LLMs）适应特定领域，却常常削弱其已建立的安全性。为了解决这个问题，本文提出了一种名为LookAhead Tuning的方法，包含两种简单、低资源、有效的数据驱动方法，通过预览部分答案前缀来修改训练数据。这两种方法旨在通过最小化初始令牌分布的扰动，保护模型固有的安全机制。综合实验表明，LookAhead Tuning在不牺牲下游任务强大性能的情况下，有效保持了模型的安全性。我们的研究定位LookAhead Tuning为安全、有效地调整LLMs的可靠解决方案，并将在https:
  "keyword": [
    "大型语言模型",
    "安全性",
    "LookAhead Tuning"
  ]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 279 (char 384). Line: 406.
Append: [LookAhead Tuning: Safer Language Models via Partial Answer Previews](https://arxiv.org/abs/2503.19041)
Token length: 1097
Summarized using gpt-4o-mini
Append: [通过CoMP实现的视觉基础模型的多模态预训练](https://arxiv.org/abs/2503.18931)
Token length: 1622
Summarized using gpt-4o-mini
Append: [Frequency Dynamic Convolution: 一种高效的自适应卷积方法](https://arxiv.org/abs/2503.18783)
Token length: 1161
Summarized using gpt-4o-mini
Append: [LSRNA：基于潜在空间的图像超分辨率生成框架](https://arxiv.org/abs/2503.18446)
Token length: 1492
Summarized using gpt-4o-mini
Append: [基于Gumbel-Softmax的流匹配框架用于高维简约体的序列生成](https://arxiv.org/abs/2503.17361)
Token length: 1309
Summarized using gpt-4o-mini
Append: [提升视觉语言模型的人本决策能力](https://arxiv.org/abs/2503.16965)
append_entries: 13
Finish: 2025-03-26 06:01:45.197464
------------------------------------------------------
Started: 2025-03-26 09:00:57.790328
Existing_entries: 857
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1037
Summarized using gpt-4o-mini
Append: [基于YOLOv12与BoT-SORT的多无人机跟踪方法](https://arxiv.org/abs/2503.17237)
Json decode failed:
{
  "title": "FakeVLM: 一种新型多模态模型用于合成图像及深伪检测",
  "short_summary": "FakeVLM模型提升了合成图像的真实性评估与解析能力。",
  "summary": "随着人工智能生成内容技术的快速发展，合成图像在日常生活中日益普遍，这也对真实性评估和检测提出了新挑战。为了解决这些问题，本文介绍了FakeVLM，这是一种专门为合成图像和深伪检测任务设计的大型多模态模型。FakeVLM在区分真实与虚假图像方面表现出色，并提供自然语言的解释，以增强可解释性。此外，我们提出了FakeClue，一个包含超过10万张图像的综合数据集，涵盖七个类别，并附有细致的自然语言伪造线索注释。FakeVLM的性能与专家模型相媲美，且无需额外的分类器，为合成数据检测提供了一个强大的解决方案。通过在多个数据集上的广泛评估，FakeVLM在真实性分类和伪造解析任务中展现优越性，为合成图像检测设定了新基准。相关数据集和代码将发布在：https:
  "keyword": [
    "合成图像",
    "深伪检测",
    "人工智能"
  ]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 344 (char 440). Line: 406.
Append: [Spot the Fake: Large Multimodal Model-Based Synthetic Image Detection with Artifact Explanation](https://arxiv.org/abs/2503.14905)
Token length: 1514
Summarized using gpt-4o-mini
Append: [MDocAgent：一种多模态多智能体文档理解框架](https://arxiv.org/abs/2503.13964)
append_entries: 3
Finish: 2025-03-26 09:01:08.193135
------------------------------------------------------
Started: 2025-03-26 12:13:46.418801
Existing_entries: 860
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-26 12:13:46.667234
------------------------------------------------------
Started: 2025-03-26 15:01:03.558330
Existing_entries: 860
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-26 15:01:03.758188
------------------------------------------------------
Started: 2025-03-26 18:01:00.145264
Existing_entries: 860
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1204
Summarized using gpt-4o-mini
Append: [FullDiT：统一的视频生成基础模型](https://arxiv.org/abs/2503.19907)
Token length: 1002
Summarized using gpt-4o-mini
Append: [无训练开放词汇语义分割的方法LPOSS+](https://arxiv.org/abs/2503.19777)
Token length: 1315
Summarized using gpt-4o-mini
Append: [实时交互视频数据集：评估AI模型的对话能力](https://arxiv.org/abs/2503.19356)
Token length: 1596
Summarized using gpt-4o-mini
Append: [基于少量图像的个性化3D人类头像重建与动画技术](https://arxiv.org/abs/2503.19207)
Token length: 1248
Summarized using gpt-4o-mini
Append: [VocAgnoLM：解决教师与学生模型词汇不匹配的问题](https://arxiv.org/abs/2503.19123)
Token length: 1483
Summarized using gpt-4o-mini
Append: [WikiAutoGen：一款自动化多模态维基百科式文章生成系统](https://arxiv.org/abs/2503.19065)
Token length: 1476
Summarized using gpt-4o-mini
Append: [xKV：提升长上下文语言模型内存效率的新方法](https://arxiv.org/abs/2503.18893)
Json decode failed:
{
  "title": "下一代地球观测基础模型的进展",
  "keyword": ["地球观测", "Copernicus", "基础模型"],
  "short_summary": "本研究提出了下一代地球观测基础模型的三个关键组成部分。",
  "summary": "本文介绍了在地球观测（EO）基础模型领域的最新进展，重点关注如何利用大规模卫星数据进行更通用的空间表示学习。研究提出了三个关键组件：首先是Copernicus-Pretrain，这是一个包含来自主要Copernicus Sentinel任务的1870万幅对齐图像的大规模预训练数据集，涵盖了地球表面到大气层的多个层面；其次是Copernicus-FM，一个统一的基础模型，能够处理任何光谱或非光谱传感器模态，利用扩展动态超网络和灵活的元数据编码；最后是Copernicus-Bench，一个系统化评估基准，涵盖15个分层下游任务，横跨从预处理到特殊应用的各个方面。这些组件显著提高了EO基础模型的可扩展性、灵活性和多模态适应能力，同时为连接EO、天气与气候研究创造了新的机会。相关代码、数据集和模型可以在 https:
}Summarization failed, append the original article
error: Invalid control character at: line 5 column 374 (char 499). Line: 406.
Append: [Towards a Unified Copernicus Foundation Model for Earth Vision](https://arxiv.org/abs/2503.11849)
append_entries: 8
Finish: 2025-03-26 18:01:38.561911
------------------------------------------------------
Started: 2025-03-26 21:00:32.644637
Existing_entries: 868
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1084
Summarized using gpt-4o-mini
Append: [基于单目相机的无人机深度和语义地图预测](https://arxiv.org/abs/2503.17982)
Token length: 1292
Summarized using gpt-4o-mini
Append: [PhysTwin: 基于稀疏视频的动态物体物理数字双胞胎框架](https://arxiv.org/abs/2503.17973)
append_entries: 2
Finish: 2025-03-26 21:00:41.094539
------------------------------------------------------
Started: 2025-03-27 00:36:52.581006
Existing_entries: 870
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1463
Summarized using gpt-4o-mini
Append: [提升时空推理能力的视觉语言模型ST-VLM及其基准评测](https://arxiv.org/abs/2503.19355)
Token length: 843
Summarized using gpt-4o-mini
Append: [OpenCity3D：城市规模环境的语言驱动分析新范式](https://arxiv.org/abs/2503.16776)
append_entries: 2
Finish: 2025-03-27 00:37:00.623893
------------------------------------------------------
Started: 2025-03-27 03:23:09.455003
Existing_entries: 872
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1885
Summarized using gpt-4o-mini
Append: [高效的微调转移策略：提升预训练模型的性能](https://arxiv.org/abs/2503.20110)
Token length: 1270
Summarized using gpt-4o-mini
Append: [多模态大语言模型在复杂行为识别中的应用与提升](https://arxiv.org/abs/2503.18712)
Token length: 914
Summarized using gpt-4o-mini
Append: [Any6D：无模型框架实现6D物体姿态估计](https://arxiv.org/abs/2503.18673)
Token length: 1291
Summarized using gpt-4o-mini
Append: [高质量360度人头视图生成的新方法](https://arxiv.org/abs/2503.15667)
Token length: 1134
Summarized using gpt-4o-mini
Append: [基于多模态大语言模型的3D场景生成研究](https://arxiv.org/abs/2503.04919)
append_entries: 5
Finish: 2025-03-27 03:23:39.501069
------------------------------------------------------
Started: 2025-03-27 06:11:10.339046
Existing_entries: 877
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1171
Summarized using gpt-4o-mini
Append: [MCTS-RAG：提升小型语言模型推理能力的新方法](https://arxiv.org/abs/2503.20757)
Json decode failed:
{
  "title": "利用知识编辑改善自动驾驶系统中的大规模多模态模型应用",
  "short_summary": "提出知识编辑方法以解决自动驾驶系统中的多模态模型应用挑战。",
  "summary": "本文探讨了大型多模态模型（LMMs）在自动驾驶系统（ADS）中的应用前景，但面临交通知识理解、复杂路况和车辆状态多样性等挑战。为了解决这些问题，提出了一种知识编辑的方法，可以针对性地修改模型行为，无需完整的重训练。同时，创建了ADS-Edit，这是一个专门为ADS设计的多模态知识编辑数据集，包含了各种真实场景和多种数据类型及全面的评估指标。通过综合实验，我们得出了一些有趣的结论，期望本研究能够推动知识编辑在自动驾驶领域的进一步应用。代码和数据可在 https:
  "keyword": [
    "自动驾驶",
    "多模态模型",
    "知识编辑"
  ]
}Summarization failed, append the original article
error: Invalid control character at: line 4 column 247 (char 341). Line: 406.
Append: [ADS-Edit: A Multimodal Knowledge Editing Dataset for Autonomous Driving Systems](https://arxiv.org/abs/2503.20756)
Token length: 1729
Summarized using gpt-4o-mini
Append: [突破性商业内容生成：以超密布局为基础的文本到图像生成模型](https://arxiv.org/abs/2503.20672)
Token length: 1867
Summarized using gpt-4o-mini
Append: [Wan：一套开源视频基础模型的创新与应用](https://arxiv.org/abs/2503.20314)
Token length: 1209
Summarized using gpt-4o-mini
Append: [优化条件扩散模型的无条件噪声预测](https://arxiv.org/abs/2503.20240)
Token length: 1383
Summarized using gpt-4o-mini
Append: [DINeMo：无3D注释的神经网格模型与伪对应生成](https://arxiv.org/abs/2503.20220)
Token length: 1419
Summarized using gpt-4o-mini
Append: [开放深度搜索（ODS）：提升开源搜索AI性能的新框架](https://arxiv.org/abs/2503.20201)
Json decode failed:
{
  "title": "长文本图像生成的新突破：\ModelName的创新与应用",
  "keyword": ["长文本生成", "图像生成", "模型优化"],
  "short_summary": "本文介绍了一种新模型\ModelName，用于生成高质量长文本图像。", 
  "summary": "虽然自回归和扩散模型在短文本图像生成上取得了显著进展，但生成连贯的长文本图像仍是一个主要挑战。本文首次专注于长文本图像生成，填补现有文本到图像系统的空白。通过对最新自回归生成模型的深入分析，识别出图像分词器作为文本生成质量的关键瓶颈。为此，我们提出了一种新的文本聚焦二进制分词器，旨在捕捉详细的场景文本特征。利用该分词器，我们开发了\ModelName，一个多模态自回归模型，能够以空前的精准度生成高质量的长文本图像。我们的模型具有强大的可控性，允许用户自定义文本属性如字体样式、大小、颜色和对齐方式。实验表明，\ModelName在长文本生成的准确性、一致性和灵活性上显著优于其他模型，如SD3.5 Large和GPT4o与DALL-E 3。除了其技术成就外，\ModelName还为创新应用如交错文档和PowerPoint生成开辟了新的前沿。"
}Summarization failed, append the original article
error: Invalid \escape: line 2 column 25 (char 26). Line: 406.
Append: [Beyond Words: Advancing Long-Text Image Generation via Multimodal Autoregressive Models](https://arxiv.org/abs/2503.20198)
Token length: 1849
Summarized using gpt-4o-mini
Append: [Gemini Robotics：革命性的机器人视觉-语言-动作模型](https://arxiv.org/abs/2503.20020)
Token length: 974
Summarized using gpt-4o-mini
Append: [无监督视频中运动估计的新方法](https://arxiv.org/abs/2503.19953)
Token length: 1107
Summarized using gpt-4o-mini
Append: [利用Attention-IoU度量揭示计算机视觉模型中的偏见](https://arxiv.org/abs/2503.19846)
Token length: 1154
Summarized using gpt-4o-mini
Append: [LogQuant：高效的2位量化技术提升大语言模型推理性能](https://arxiv.org/abs/2503.19950)
Token length: 1570
Summarized using gpt-4o-mini
Append: [Dita：一种可扩展的多模态扩散框架用于机器人行动决策](https://arxiv.org/abs/2503.19757)
Token length: 1811
Summarized using gpt-4o-mini
Append: [GenHancer：提升CLIP表征能力的生成模型探索](https://arxiv.org/abs/2503.19480)
Token length: 1515
Summarized using gpt-4o-mini
Append: [AccVideo: 高效视频扩散模型加速方法](https://arxiv.org/abs/2503.19462)
Json decode failed:
{
  "title": "基于随机抽样的知识蒸馏方法提升稀疏知识蒸馏性能",
  "keyword": ["知识蒸馏", "大语言模型", "随机抽样"],
  "short_summary": "提出一种随机抽样知识蒸馏方法，提升稀疏知识蒸馏的性能与效率。",
  "summary": "知识蒸馏是一种在大语言模型中有效提取知识的成本效益技术，但其在预训练中的应用仍然探索不足。本研究表明，简单的稀疏知识蒸馏方法如缓存Top-K概率，虽然直观，但会导致教师概率分布对学生的偏差估计，进而降低模型性能和校准效果。为了克服这个问题，我们提出了一种基于重要性抽样的"随机抽样知识蒸馏"方法，该方法提供无偏估计，保持梯度的期望值，并需求存储更稀疏的logits。我们的实验表明，相比于交叉熵训练，采用该方法进行学生模型的训练不仅可以加速训练过程，且附加开销低于10%，同时在300M到3B范围的模型上保持了竞争力的性能。"
}Summarization failed, append the original article
error: Expecting ',' delimiter: line 5 column 151 (char 283). Line: 406.
Append: [Sparse Logit Sampling: Accelerating Knowledge Distillation in LLMs](https://arxiv.org/abs/2503.16870)
append_entries: 16
Finish: 2025-03-27 06:12:40.295241
------------------------------------------------------
Started: 2025-03-27 09:00:54.256257
Existing_entries: 893
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1775
Summarized using gpt-4o-mini
Append: [Qwen2.5-Omni：多模态流处理模型的创新与应用](https://arxiv.org/abs/2503.20215)
Token length: 1555
Summarized using gpt-4o-mini
Append: [评估多模态大语言模型的空间推理能力：LEGO-Puzzles基准测试](https://arxiv.org/abs/2503.19990)
append_entries: 2
Finish: 2025-03-27 09:01:08.699800
------------------------------------------------------
Started: 2025-03-27 12:18:55.232831
Existing_entries: 895
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1470
Summarized using gpt-4o-mini
Append: [Vision-Language奖励模型的评估与进展](https://arxiv.org/abs/2503.20271)
Token length: 1105
Summarized using gpt-4o-mini
Append: [利用运动模糊进行稳健的相机运动估计](https://arxiv.org/abs/2503.17358)
append_entries: 2
Finish: 2025-03-27 12:19:07.777418
------------------------------------------------------
Started: 2025-03-27 15:00:48.815512
Existing_entries: 897
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1587
Summarized using gpt-4o-mini
Append: [PathoHR：提高乳腺癌生存预测的计算病理新方法](https://arxiv.org/abs/2503.17970)
append_entries: 1
Finish: 2025-03-27 15:00:54.646519
------------------------------------------------------
Started: 2025-03-27 18:01:11.496145
Existing_entries: 898
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1847
Summarized using gpt-4o-mini
Append: [模型合并在长期到短期推理中的应用研究](https://arxiv.org/abs/2503.20641)
Token length: 1265
Summarized using gpt-4o-mini
Append: [基于轨迹平衡与异步的强化学习系统TBA](https://arxiv.org/abs/2503.18929)
Token length: 1658
Summarized using gpt-4o-mini
Append: [UniHDSA: 一种统一的文档层次结构分析方法](https://arxiv.org/abs/2503.15893)
Token length: 838
Summarized using gpt-4o-mini
Append: [RONA：增强多模态大语言模型图像标注多样性的策略](https://arxiv.org/abs/2503.10997)
append_entries: 4
Finish: 2025-03-27 18:01:32.285161
------------------------------------------------------
Started: 2025-03-27 21:00:50.481420
Existing_entries: 902
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 810
Summarized using gpt-4o-mini
Append: [RecTable: 高效生成高质量表格数据的新模型](https://arxiv.org/abs/2503.20731)
Token length: 957
Summarized using gpt-4o-mini
Append: [Gemma 3：多模态轻量级模型的升级版](https://arxiv.org/abs/2503.19786)
append_entries: 2
Finish: 2025-03-27 21:01:00.142902
------------------------------------------------------
Started: 2025-03-28 00:36:57.495033
Existing_entries: 904
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-28 00:36:57.815091
------------------------------------------------------
Started: 2025-03-28 03:24:20.926145
Existing_entries: 904
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-28 03:24:21.181249
------------------------------------------------------
Started: 2025-03-28 06:11:40.743539
Existing_entries: 904
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-28 06:11:40.990204
------------------------------------------------------
Started: 2025-03-28 09:00:42.420555
Existing_entries: 904
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1333
Summarized using gpt-4o-mini
Append: [Video-R1: 基于多模态大语言模型的视频推理探索](https://arxiv.org/abs/2503.21776)
Token length: 903
Summarized using gpt-4o-mini
Append: [优化步长调度的扩散模型提高生成效率](https://arxiv.org/abs/2503.21774)
Token length: 1783
Summarized using gpt-4o-mini
Append: [视频生成中的物理认知进展及其挑战](https://arxiv.org/abs/2503.21765)
Token length: 1281
Summarized using gpt-4o-mini
Append: [Lumina-Image 2.0：先进的文本生成图像框架](https://arxiv.org/abs/2503.21758)
Token length: 1913
Summarized using gpt-4o-mini
Append: [推进视频生成模型的内在真实性评估](https://arxiv.org/abs/2503.21755)
Token length: 1122
Summarized using gpt-4o-mini
Append: [LeX-Art: 高质量文本-图像合成的完整解决方案](https://arxiv.org/abs/2503.21749)
Token length: 1299
Summarized using gpt-4o-mini
Append: [ReaRAG：增强准确性的推理模型](https://arxiv.org/abs/2503.21729)
Token length: 1418
Summarized using gpt-4o-mini
Append: [基于规则的强化学习提升多模态大语言模型的GUI动作预测能力](https://arxiv.org/abs/2503.21620)
Token length: 1177
Summarized using gpt-4o-mini
Append: [智能代理时代的到来：大语言模型驱动下的研究综述](https://arxiv.org/abs/2503.21460)
Token length: 1526
Summarized using gpt-4o-mini
Append: [OlymMATH: 新的奥林匹克数学基准测试大规模推理模型](https://arxiv.org/abs/2503.21380)
Token length: 1713
Summarized using gpt-4o-mini
Append: [基于音频输入的实时互动视频生成框架](https://arxiv.org/abs/2503.21144)
Token length: 1281
Summarized using gpt-4o-mini
Append: [ZJUKLAB团队在SemEval-2025任务中的敏感内容去除研究](https://arxiv.org/abs/2503.21088)
Token length: 1416
Summarized using gpt-4o-mini
Append: [统一多模态离散扩散模型UniDisc的探索与应用](https://arxiv.org/abs/2503.20853)
Token length: 1681
Summarized using gpt-4o-mini
Append: [Feature4X：扩展2D视觉模型至4D领域的通用框架](https://arxiv.org/abs/2503.20776)
Token length: 966
Summarized using gpt-4o-mini
Append: [基于大型语言模型的故障诱发输入提取研究](https://arxiv.org/abs/2503.20578)
Token length: 914
Summarized using gpt-4o-mini
Append: [利用合成视频提升视频生成模型的物理真实性](https://arxiv.org/abs/2503.20822)
append_entries: 16
Finish: 2025-03-28 09:02:16.501297
------------------------------------------------------
Started: 2025-03-28 12:00:58.871206
Existing_entries: 920
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1513
Summarized using gpt-4o-mini
Append: [Embodied Reasoner：提升交互式体态搜索任务的推理能力](https://arxiv.org/abs/2503.21696)
Token length: 1158
Summarized using gpt-4o-mini
Append: [大语言模型在科学发现中的潜力与新基准](https://arxiv.org/abs/2503.21248)
Token length: 1195
Summarized using gpt-4o-mini
Append: [FinAudio: 金融领域音频语言模型评估基准](https://arxiv.org/abs/2503.20990)
append_entries: 3
Finish: 2025-03-28 12:01:18.204313
------------------------------------------------------
Started: 2025-03-28 15:01:03.011478
Existing_entries: 923
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1140
Summarized using gpt-4o-mini
Append: [LOCATEdit：基于图的文本引导图像编辑方法](https://arxiv.org/abs/2503.21541)
append_entries: 1
Finish: 2025-03-28 15:01:08.390842
------------------------------------------------------
Started: 2025-03-28 18:00:52.069980
Existing_entries: 924
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1175
Summarized using gpt-4o-mini
Append: [无训练的测试时领域适应框架SemLA在开放词汇语义分割中的应用](https://arxiv.org/abs/2503.21780)
append_entries: 1
Finish: 2025-03-28 18:01:04.432348
------------------------------------------------------
Started: 2025-03-28 21:00:40.502594
Existing_entries: 925
Fetching from https://rsshub.app/huggingface/daily-papers
Token length: 1193
Summarized using gpt-4o-mini
Append: [Tracktention Layer：提升视频预测中的时间一致性](https://arxiv.org/abs/2503.19904)
append_entries: 1
Finish: 2025-03-28 21:00:45.642617
------------------------------------------------------
Started: 2025-03-29 00:36:38.343419
Existing_entries: 926
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-29 00:36:38.536546
------------------------------------------------------
Started: 2025-03-29 03:20:45.131082
Existing_entries: 926
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-29 03:20:45.314703
------------------------------------------------------
Started: 2025-03-29 06:09:43.686411
Existing_entries: 926
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-29 06:09:43.910853
------------------------------------------------------
Started: 2025-03-29 09:00:45.580370
Existing_entries: 926
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-29 09:00:45.834637
------------------------------------------------------
Started: 2025-03-29 12:00:45.893587
Existing_entries: 926
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-29 12:00:46.075395
------------------------------------------------------
Started: 2025-03-29 15:00:45.028991
Existing_entries: 926
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-29 15:00:45.209687
------------------------------------------------------
Started: 2025-03-29 18:00:31.394722
Existing_entries: 926
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-29 18:00:31.729272
------------------------------------------------------
Started: 2025-03-29 21:00:42.014229
Existing_entries: 926
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-29 21:00:42.200272
------------------------------------------------------
Started: 2025-03-30 00:40:32.810804
Existing_entries: 926
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-30 00:40:32.977083
------------------------------------------------------
Started: 2025-03-30 03:28:59.511314
Existing_entries: 926
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-30 03:28:59.742888
------------------------------------------------------
Started: 2025-03-30 06:00:52.850901
Existing_entries: 926
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-30 06:00:53.006318
------------------------------------------------------
Started: 2025-03-30 09:00:50.900841
Existing_entries: 926
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-30 09:00:51.091699
------------------------------------------------------
Started: 2025-03-30 12:12:04.569544
Existing_entries: 926
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-30 12:12:04.790443
------------------------------------------------------
Started: 2025-03-30 15:00:35.712302
Existing_entries: 926
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-30 15:00:35.894642
------------------------------------------------------
Started: 2025-03-30 18:00:34.882817
Existing_entries: 926
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-30 18:00:35.056433
------------------------------------------------------
Started: 2025-03-30 21:00:45.781865
Existing_entries: 926
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-30 21:00:45.975453
------------------------------------------------------
Started: 2025-03-31 00:40:08.291180
Existing_entries: 926
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-31 00:40:08.740995
------------------------------------------------------
Started: 2025-03-31 03:29:27.829720
Existing_entries: 926
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-31 03:29:28.031684
------------------------------------------------------
Started: 2025-03-31 06:11:58.420826
Existing_entries: 926
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Sequential Recommendation (SeqRec) aims to predict the next item by capturing sequential patterns from users' historical interactions, playing a crucial role in many real-world recommender systems. However, existing approaches predominantly adopt a direct forward computation paradigm, where the final hidden state of the sequence encoder serves as the user representation. We argue that this inference paradigm, due to its limited computational depth, struggles to model the complex evolving nature of user preferences and lacks a nuanced understanding of long-tail items, leading to suboptimal performance. To address this issue, we propose ReaRec, the first inference-time computing framework for recommender systems, which enhances user representations through implicit multi-step reasoning. Specifically, ReaRec autoregressively feeds the sequence's last hidden state into the sequential recommender while incorporating special reasoning position embeddings to decouple the original item encoding space from the multi-step reasoning space. Moreover, we introduce two lightweight reasoning-based learning methods, Ensemble Reasoning Learning (ERL) and Progressive Reasoning Learning (PRL), to further effectively exploit ReaRec's reasoning potential. Extensive experiments on five public real-world datasets and different SeqRec architectures demonstrate the generality and effectiveness of our proposed ReaRec. Remarkably, post-hoc analyses reveal that ReaRec significantly elevates the performance ceiling of multiple sequential recommendation backbones by approximately 30\\%-50\\%. Thus, we believe this work can open a new and promising avenue for future research in inference-time computing for sequential recommendation."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Think Before Recommend: Unleashing the Latent Reasoning Power for Sequential Recommendation](https://arxiv.org/abs/2503.22675)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We introduce ORIGEN, the first zero-shot method for 3D orientation grounding in text-to-image generation across multiple objects and diverse categories. While previous work on spatial grounding in image generation has mainly focused on 2D positioning, it lacks control over 3D orientation. To address this, we propose a reward-guided sampling approach using a pretrained discriminative model for 3D orientation estimation and a one-step text-to-image generative flow model. While gradient-ascent-based optimization is a natural choice for reward-based guidance, it struggles to maintain image realism. Instead, we adopt a sampling-based approach using Langevin dynamics, which extends gradient ascent by simply injecting random noise--requiring just a single additional line of code. Additionally, we introduce adaptive time rescaling based on the reward function to accelerate convergence. Our experiments show that ORIGEN outperforms both training-based and test-time guidance methods across quantitative metrics and user studies.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [ORIGEN: Zero-Shot 3D Orientation Grounding in Text-to-Image Generation](https://arxiv.org/abs/2503.22194)
append_entries: 2
Finish: 2025-03-31 06:11:59.681915
------------------------------------------------------
Started: 2025-03-31 09:00:36.706444
Existing_entries: 928
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Motivated in part by their relevance for low-precision training and quantization, massive activations in large language models (LLMs) have recently emerged as a topic of interest. However, existing analyses are limited in scope, and generalizability across architectures is unclear. This paper helps address some of these gaps by conducting an analysis of massive activations across a broad range of LLMs, including both GLU-based and non-GLU-based architectures. Our findings challenge several prior assumptions, most importantly: (1) not all massive activations are detrimental, i.e. suppressing them does not lead to an explosion of perplexity or a collapse in downstream task performance; (2) proposed mitigation strategies such as Attention KV bias are model-specific and ineffective in certain cases. We consequently investigate novel hybrid mitigation strategies; in particular pairing Target Variance Rescaling (TVR) with Attention KV bias or Dynamic Tanh (DyT) successfully balances the mitigation of massive activations with preserved downstream model performance in the scenarios we investigated. Our code is available at: https://github.com/bluorion-com/refine_massive_activations.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [A Refined Analysis of Massive Activations in LLMs](https://arxiv.org/abs/2503.22329)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Moving object segmentation is a crucial task for achieving a high-level understanding of visual scenes and has numerous downstream applications. Humans can effortlessly segment moving objects in videos. Previous work has largely relied on optical flow to provide motion cues; however, this approach often results in imperfect predictions due to challenges such as partial motion, complex deformations, motion blur and background distractions. We propose a novel approach for moving object segmentation that combines long-range trajectory motion cues with DINO-based semantic features and leverages SAM2 for pixel-level mask densification through an iterative prompting strategy. Our model employs Spatio-Temporal Trajectory Attention and Motion-Semantic Decoupled Embedding to prioritize motion while integrating semantic support. Extensive testing on diverse datasets demonstrates state-of-the-art performance, excelling in challenging scenarios and fine-grained segmentation of multiple objects. Our code is available at https://motion-seg.github.io/.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Segment Any Motion in Videos](https://arxiv.org/abs/2503.22268)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'With the growing demand for high-fidelity 3D models from 2D images, existing methods still face significant challenges in accurately reproducing fine-grained geometric details due to limitations in domain gaps and inherent ambiguities in RGB images. To address these issues, we propose Hi3DGen, a novel framework for generating high-fidelity 3D geometry from images via normal bridging. Hi3DGen consists of three key components: (1) an image-to-normal estimator that decouples the low-high frequency image pattern with noise injection and dual-stream training to achieve generalizable, stable, and sharp estimation; (2) a normal-to-geometry learning approach that uses normal-regularized latent diffusion learning to enhance 3D geometry generation fidelity; and (3) a 3D data synthesis pipeline that constructs a high-quality dataset to support training. Extensive experiments demonstrate the effectiveness and superiority of our framework in generating rich geometric details, outperforming state-of-the-art methods in terms of fidelity. Our work provides a new direction for high-fidelity 3D geometry generation from images by leveraging normal maps as an intermediate representation.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Hi3DGen: High-fidelity 3D Geometry Generation from Images via Normal Bridging](https://arxiv.org/abs/2503.22236)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Reinforcement Learning from Human Feedback (RLHF) is crucial for aligning large language models with human preferences. While recent research has focused on algorithmic improvements, the importance of prompt-data construction has been overlooked. This paper addresses this gap by exploring data-driven bottlenecks in RLHF performance scaling, particularly reward hacking and decreasing response diversity. We introduce a hybrid reward system combining reasoning task verifiers (RTV) and a generative reward model (GenRM) to mitigate reward hacking. We also propose a novel prompt-selection method, Pre-PPO, to maintain response diversity and enhance learning effectiveness. Additionally, we find that prioritizing mathematical and coding tasks early in RLHF training significantly improves performance. Experiments across two model sizes validate our methods' effectiveness and scalability. Results show that RTV is most resistant to reward hacking, followed by GenRM with ground truth, and then GenRM with SFT Best-of-N responses. Our strategies enable rapid capture of subtle task-specific distinctions, leading to substantial improvements in overall RLHF performance. This work highlights the importance of careful data construction and provides practical methods to overcome performance barriers in RLHF."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Exploring Data Scaling Trends and Effects in Reinforcement Learning from Human Feedback](https://arxiv.org/abs/2503.22230)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Four-dimensional computed tomography (4D CT) reconstruction is crucial for capturing dynamic anatomical changes but faces inherent limitations from conventional phase-binning workflows. Current methods discretize temporal resolution into fixed phases with respiratory gating devices, introducing motion misalignment and restricting clinical practicality. In this paper, We propose X^2-Gaussian, a novel framework that enables continuous-time 4D-CT reconstruction by integrating dynamic radiative Gaussian splatting with self-supervised respiratory motion learning. Our approach models anatomical dynamics through a spatiotemporal encoder-decoder architecture that predicts time-varying Gaussian deformations, eliminating phase discretization. To remove dependency on external gating devices, we introduce a physiology-driven periodic consistency loss that learns patient-specific breathing cycles directly from projections via differentiable optimization. Extensive experiments demonstrate state-of-the-art performance, achieving a 9.93 dB PSNR gain over traditional methods and 2.25 dB improvement against prior Gaussian splatting techniques. By unifying continuous motion modeling with hardware-free period learning, X^2-Gaussian advances high-fidelity 4D CT reconstruction for dynamic clinical imaging. Project website at: https://x2-gaussian.github.io/.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [X^{2}-Gaussian: 4D Radiative Gaussian Splatting for Continuous-time Tomographic Reconstruction](https://arxiv.org/abs/2503.21779)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Creating high-fidelity 3D meshes with arbitrary topology, including open surfaces and complex interiors, remains a significant challenge. Existing implicit field methods often require costly and detail-degrading watertight conversion, while other approaches struggle with high resolutions. This paper introduces SparseFlex, a novel sparse-structured isosurface representation that enables differentiable mesh reconstruction at resolutions up to 1024^3 directly from rendering losses. SparseFlex combines the accuracy of Flexicubes with a sparse voxel structure, focusing computation on surface-adjacent regions and efficiently handling open surfaces. Crucially, we introduce a frustum-aware sectional voxel training strategy that activates only relevant voxels during rendering, dramatically reducing memory consumption and enabling high-resolution training. This also allows, for the first time, the reconstruction of mesh interiors using only rendering supervision. Building upon this, we demonstrate a complete shape modeling pipeline by training a variational autoencoder (VAE) and a rectified flow transformer for high-quality 3D shape generation. Our experiments show state-of-the-art reconstruction accuracy, with a ~82% reduction in Chamfer Distance and a ~88% increase in F-score compared to previous methods, and demonstrate the generation of high-resolution, detailed 3D shapes with arbitrary topology. By enabling high-resolution, differentiable mesh reconstruction and generation with rendering losses, SparseFlex significantly advances the state-of-the-art in 3D shape representation and modeling.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [SparseFlex: High-Resolution and Arbitrary-Topology 3D Shape Modeling](https://arxiv.org/abs/2503.21732)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Traditional image classification requires a predefined list of semantic categories. In contrast, Large Multimodal Models (LMMs) can sidestep this requirement by classifying images directly using natural language (e.g., answering the prompt "What is the main object in the image?"). Despite this remarkable capability, most existing studies on LMM classification performance are surprisingly limited in scope, often assuming a closed-world setting with a predefined set of categories. In this work, we address this gap by thoroughly evaluating LMM classification performance in a truly open-world setting. We first formalize the task and introduce an evaluation protocol, defining various metrics to assess the alignment between predicted and ground truth classes. We then evaluate 13 models across 10 benchmarks, encompassing prototypical, non-prototypical, fine-grained, and very fine-grained classes, demonstrating the challenges LMMs face in this task. Further analyses based on the proposed metrics reveal the types of errors LMMs make, highlighting challenges related to granularity and fine-grained capabilities, showing how tailored prompting and reasoning can alleviate them.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [On Large Multimodal Models as Open-World Image Classifiers](https://arxiv.org/abs/2503.21851)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Recent Large Reasoning Models (LRMs), such as DeepSeek-R1 and OpenAI o1, have demonstrated strong performance gains by scaling up the length of Chain-of-Thought (CoT) reasoning during inference. However, a growing concern lies in their tendency to produce excessively long reasoning traces, which are often filled with redundant content (e.g., repeated definitions), over-analysis of simple problems, and superficial exploration of multiple reasoning paths for harder tasks. This inefficiency introduces significant challenges for training, inference, and real-world deployment (e.g., in agent-based systems), where token economy is critical. In this survey, we provide a comprehensive overview of recent efforts aimed at improving reasoning efficiency in LRMs, with a particular focus on the unique challenges that arise in this new paradigm. We identify common patterns of inefficiency, examine methods proposed across the LRM lifecycle, i.e., from pretraining to inference, and discuss promising future directions for research. To support ongoing development, we also maintain a real-time GitHub repository tracking recent progress in the field. We hope this survey serves as a foundation for further exploration and inspires innovation in this rapidly evolving area.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [A Survey of Efficient Reasoning for Large Reasoning Models: Language, Multimodality, and Beyond](https://arxiv.org/abs/2503.21614)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Summarization refinement faces challenges when extending to multi-dimension. In this paper, we introduce ReFeed, a powerful summarization refinement pipeline that enhances multiple dimensions through reflective reasoning on feedback. To achieve this, we release SumFeed-CoT, a large-scale Long-CoT-based dataset optimized for training a lightweight model with reflective reasoning. Our experiments reveal how the number of dimensions, feedback exposure, and reasoning policy influence refinement performance, highlighting reflective reasoning and simultaneously addressing multiple feedback is crucial to mitigate trade-off between dimensions. Furthermore, ReFeed is robust to noisy feedback and feedback order. Lastly, our finding emphasizes that creating data with a proper goal and guideline constitutes a fundamental pillar of effective reasoning. The dataset and model will be released.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [ReFeed: Multi-dimensional Summarization Refinement with Reflective Reasoning on Feedback](https://arxiv.org/abs/2503.21332)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We present Free4D, a novel tuning-free framework for 4D scene generation from a single image. Existing methods either focus on object-level generation, making scene-level generation infeasible, or rely on large-scale multi-view video datasets for expensive training, with limited generalization ability due to the scarcity of 4D scene data. In contrast, our key insight is to distill pre-trained foundation models for consistent 4D scene representation, which offers promising advantages such as efficiency and generalizability. 1) To achieve this, we first animate the input image using image-to-video diffusion models followed by 4D geometric structure initialization. 2) To turn this coarse structure into spatial-temporal consistent multiview videos, we design an adaptive guidance mechanism with a point-guided denoising strategy for spatial consistency and a novel latent replacement strategy for temporal coherence. 3) To lift these generated observations into consistent 4D representation, we propose a modulation-based refinement to mitigate inconsistencies while fully leveraging the generated information. The resulting 4D representation enables real-time, controllable rendering, marking a significant advancement in single-image-based 4D scene generation.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Free4D: Tuning-free 4D Scene Generation with Spatial-Temporal Consistency](https://arxiv.org/abs/2503.20785)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Recent advancements in speech-driven 3D talking head generation have made significant progress in lip synchronization. However, existing models still struggle to capture the perceptual alignment between varying speech characteristics and corresponding lip movements. In this work, we claim that three criteria -- Temporal Synchronization, Lip Readability, and Expressiveness -- are crucial for achieving perceptually accurate lip movements. Motivated by our hypothesis that a desirable representation space exists to meet these three criteria, we introduce a speech-mesh synchronized representation that captures intricate correspondences between speech signals and 3D face meshes. We found that our learned representation exhibits desirable characteristics, and we plug it into existing models as a perceptual loss to better align lip movements to the given speech. In addition, we utilize this representation as a perceptual metric and introduce two other physically grounded lip synchronization metrics to assess how well the generated 3D talking heads align with these three criteria. Experiments show that training 3D talking head generation models with our perceptual loss significantly improve all three aspects of perceptually accurate lip synchronization. Codes and datasets are available at https://perceptual-3d-talking-head.github.io/.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Perceptually Accurate 3D Talking Head Generation: New Definitions, Speech-Mesh Representation, and Evaluation Metrics](https://arxiv.org/abs/2503.20308)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We introduce PHYSICS, a comprehensive benchmark for university-level physics problem solving. It contains 1297 expert-annotated problems covering six core areas: classical mechanics, quantum mechanics, thermodynamics and statistical mechanics, electromagnetism, atomic physics, and optics. Each problem requires advanced physics knowledge and mathematical reasoning. We develop a robust automated evaluation system for precise and reliable validation. Our evaluation of leading foundation models reveals substantial limitations. Even the most advanced model, o3-mini, achieves only 59.9% accuracy, highlighting significant challenges in solving high-level scientific problems. Through comprehensive error analysis, exploration of diverse prompting strategies, and Retrieval-Augmented Generation (RAG)-based knowledge augmentation, we identify key areas for improvement, laying the foundation for future advancements.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [PHYSICS: Benchmarking Foundation Models on University-Level Physics Problem Solving](https://arxiv.org/abs/2503.21821)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Large Language Models (LLMs) have shown impressive versatility as general purpose models. However, their broad applicability comes at a high-cost computational overhead, particularly in auto-regressive decoding where each step requires a forward pass. In domain-specific settings, general-purpose capabilities are unnecessary and can be exchanged for efficiency. In this work, we take a novel perspective on domain adaptation, reducing latency and computational costs by adapting the vocabulary to focused domains of interest. We introduce AdaptiVocab, an end-to-end approach for vocabulary adaptation, designed to enhance LLM efficiency in low-resource domains. AdaptiVocab can be applied to any tokenizer and architecture, modifying the vocabulary by replacing tokens with domain-specific n-gram-based tokens, thereby reducing the number of tokens required for both input processing and output generation. AdaptiVocab initializes new n-token embeddings using an exponentially weighted combination of existing embeddings and employs a lightweight fine-tuning phase that can be efficiently performed on a single GPU. We evaluate two 7B LLMs across three niche domains, assessing efficiency, generation quality, and end-task performance. Our results show that AdaptiVocab reduces token usage by over 25% without compromising performance'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [AdaptiVocab: Enhancing LLM Efficiency in Focused Domains through Lightweight Vocabulary Adaptation](https://arxiv.org/abs/2503.19693)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Developing reliable AI systems to assist human clinicians in multi-modal medical diagnosis has long been a key objective for researchers. Recently, Multi-modal Large Language Models (MLLMs) have gained significant attention and achieved success across various domains. With strong reasoning capabilities and the ability to perform diverse tasks based on user instructions, they hold great potential for enhancing medical diagnosis. However, directly applying MLLMs to the medical domain still presents challenges. They lack detailed perception of visual inputs, limiting their ability to perform quantitative image analysis, which is crucial for medical diagnostics. Additionally, MLLMs often exhibit hallucinations and inconsistencies in reasoning, whereas clinical diagnoses must adhere strictly to established criteria. To address these challenges, we propose MedAgent-Pro, an evidence-based reasoning agentic system designed to achieve reliable, explainable, and precise medical diagnoses. This is accomplished through a hierarchical workflow: at the task level, knowledge-based reasoning generate reliable diagnostic plans for specific diseases following retrieved clinical criteria. While at the case level, multiple tool agents process multi-modal inputs, analyze different indicators according to the plan, and provide a final diagnosis based on both quantitative and qualitative evidence. Comprehensive experiments on both 2D and 3D medical diagnosis tasks demonstrate the superiority and effectiveness of MedAgent-Pro, while case studies further highlight its reliability and interpretability. The code is available at https://github.com/jinlab-imvr/MedAgent-Pro.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [MedAgent-Pro: Towards Multi-modal Evidence-based Medical Diagnosis via Reasoning Agentic Workflow](https://arxiv.org/abs/2503.18968)
append_entries: 14
Finish: 2025-03-31 09:00:42.139602
------------------------------------------------------
Started: 2025-03-31 12:00:59.587969
Existing_entries: 942
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-31 12:00:59.800642
------------------------------------------------------
Started: 2025-03-31 15:00:40.015548
Existing_entries: 942
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'In this paper, we introduce a method for reconstructing 3D humans from a single image using a biomechanically accurate skeleton model. To achieve this, we train a transformer that takes an image as input and estimates the parameters of the model. Due to the lack of training data for this task, we build a pipeline to produce pseudo ground truth model parameters for single images and implement a training procedure that iteratively refines these pseudo labels. Compared to state-of-the-art methods for 3D human mesh recovery, our model achieves competitive performance on standard benchmarks, while it significantly outperforms them in settings with extreme 3D poses and viewpoints. Additionally, we show that previous reconstruction methods frequently violate joint angle limits, leading to unnatural rotations. In contrast, our approach leverages the biomechanically plausible degrees of freedom making more realistic joint rotation estimates. We validate our approach across multiple human pose estimation benchmarks. We make the code, models and data available at: https://isshikihugh.github.io/HSMR/'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Reconstructing Humans with a Biomechanically Accurate Skeleton](https://arxiv.org/abs/2503.21751)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Vision Transformers (ViTs) have shown remarkable performance and scalability across various computer vision tasks. To apply single-scale ViTs to image segmentation, existing methods adopt a convolutional adapter to generate multi-scale features, a pixel decoder to fuse these features, and a Transformer decoder that uses the fused features to make predictions. In this paper, we show that the inductive biases introduced by these task-specific components can instead be learned by the ViT itself, given sufficiently large models and extensive pre-training. Based on these findings, we introduce the Encoder-only Mask Transformer (EoMT), which repurposes the plain ViT architecture to conduct image segmentation. With large-scale models and pre-training, EoMT obtains a segmentation accuracy similar to state-of-the-art models that use task-specific components. At the same time, EoMT is significantly faster than these methods due to its architectural simplicity, e.g., up to 4x faster with ViT-L. Across a range of model sizes, EoMT demonstrates an optimal balance between segmentation accuracy and prediction speed, suggesting that compute resources are better spent on scaling the ViT itself rather than adding architectural complexity. Code: https://www.tue-mps.org/eomt/.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Your ViT is Secretly an Image Segmentation Model](https://arxiv.org/abs/2503.19108)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Multimodal Large Language Models (MLLMs) have demonstrated impressive 2D image/video understanding capabilities. However, there are no publicly standardized benchmarks to assess the abilities of MLLMs in understanding the 4D objects (3D objects with temporal evolution over time). In this paper, we introduce 4D-Bench, the first benchmark to evaluate the capabilities of MLLMs in 4D object understanding, featuring tasks in 4D object Question Answering (4D object QA) and 4D object captioning. 4D-Bench provides 4D objects with diverse categories, high-quality annotations, and tasks necessitating multi-view spatial-temporal understanding, different from existing 2D image/video-based benchmarks. With 4D-Bench, we evaluate a wide range of open-source and closed-source MLLMs. The results from the 4D object captioning experiment indicate that MLLMs generally exhibit weaker temporal understanding compared to their appearance understanding, notably, while open-source models approach closed-source performance in appearance understanding, they show larger performance gaps in temporal understanding. 4D object QA yields surprising findings: even with simple single-object videos, MLLMs perform poorly, with state-of-the-art GPT-4o achieving only 63\\% accuracy compared to the human baseline of 91\\%. These findings highlight a substantial gap in 4D object understanding and the need for further advancements in MLLMs.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [4D-Bench: Benchmarking Multi-modal Large Language Models for 4D Object Understanding](https://arxiv.org/abs/2503.17827)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Multimodal Large Language Models (MLLMs) have gained significant traction for their ability to process diverse input data types and generate coherent, contextually relevant outputs across various applications. While supervised fine-tuning (SFT) has been the predominant approach to enhance MLLM capabilities in task-specific optimization, it often falls short in fostering crucial generalized reasoning abilities. Although reinforcement learning (RL) holds great promise in overcoming these limitations, it encounters two significant challenges: (1) its generalized capacities in multimodal tasks remain largely unexplored, and (2) its training constraints, including the constant Kullback-Leibler divergence or the clamp strategy, often result in suboptimal bottlenecks. To address these challenges, we propose OThink-MR1, an advanced MLLM equipped with profound comprehension and reasoning capabilities across multimodal tasks. Specifically, we introduce Group Relative Policy Optimization with a dynamic Kullback-Leibler strategy (GRPO-D), which markedly enhances reinforcement learning (RL) performance. For Qwen2-VL-2B-Instruct, GRPO-D achieves a relative improvement of more than 5.72% over SFT and more than 13.59% over GRPO in same-task evaluation on two adapted datasets. Furthermore, GRPO-D demonstrates remarkable cross-task generalization capabilities, with an average relative improvement of more than 61.63% over SFT in cross-task evaluation. These results highlight that the MLLM trained with GRPO-D on one multimodal task can be effectively transferred to another task, underscoring the superior generalized reasoning capabilities of our proposed OThink-MR1 model.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [OThink-MR1: Stimulating multimodal generalized reasoning capabilities via dynamic reinforcement learning](https://arxiv.org/abs/2503.16081)
append_entries: 4
Finish: 2025-03-31 15:00:41.912631
------------------------------------------------------
Started: 2025-03-31 18:00:48.971080
Existing_entries: 946
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-03-31 18:00:49.252402
------------------------------------------------------
Started: 2025-03-31 21:00:58.730923
Existing_entries: 946
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Intent, typically clearly formulated and planned, functions as a cognitive framework for reasoning and problem-solving. This paper introduces the concept of Speaking with Intent (SWI) in large language models (LLMs), where the explicitly generated intent encapsulates the model's underlying intention and provides high-level planning to guide subsequent analysis and communication. By emulating deliberate and purposeful thoughts in the human mind, SWI is hypothesized to enhance the reasoning capabilities and generation quality of LLMs. Extensive experiments on mathematical reasoning benchmarks consistently demonstrate the superiority of Speaking with Intent over Baseline (i.e., generation without explicit intent). Moreover, SWI outperforms answer-trigger prompting methods Chain-of-Thought and Plan-and-Solve and maintains competitive performance with the strong method ARR (Analyzing, Retrieving, and Reasoning). Additionally, the effectiveness and generalizability of SWI are solidified on reasoning-intensive question answering (QA) and text summarization benchmarks, where SWI brings consistent improvement to the Baseline generation. In text summarization, SWI-generated summaries exhibit greater accuracy, conciseness, and factual correctness, with fewer hallucinations. Furthermore, human evaluations verify the coherence, effectiveness, and interpretability of the intent produced by SWI. This proof-of-concept study creates a novel avenue for enhancing LLMs' reasoning abilities with cognitive notions."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [SWI: Speaking with Intent in Large Language Models](https://arxiv.org/abs/2503.21544)
append_entries: 1
Finish: 2025-03-31 21:00:59.638190
------------------------------------------------------
Started: 2025-04-01 00:42:53.296303
Existing_entries: 947
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-01 00:42:53.469403
------------------------------------------------------
Started: 2025-04-01 03:35:19.720672
Existing_entries: 947
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-01 03:35:19.887942
------------------------------------------------------
Started: 2025-04-01 06:00:49.490880
Existing_entries: 947
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Reasoning-enhanced large language models (LLMs) explicitly generate intermediate reasoning steps prior to generating final answers, helping the model excel in complex problem-solving. In this paper, we demonstrate that this emerging generation framework offers a unique opportunity for more fine-grained control over model behavior. We propose Thinking Intervention, a novel paradigm designed to explicitly guide the internal reasoning processes of LLMs by strategically inserting or revising specific thinking tokens. We conduct comprehensive evaluations across multiple tasks, including instruction following on IFEval, instruction hierarchy on SEP, and safety alignment on XSTest and SORRY-Bench. Our results demonstrate that Thinking Intervention significantly outperforms baseline prompting approaches, achieving up to 6.7% accuracy gains in instruction-following scenarios, 15.4% improvements in reasoning about instruction hierarchies, and a 40.0% increase in refusal rates for unsafe prompts using open-source DeepSeek R1 models. Overall, our work opens a promising new research avenue for controlling reasoning LLMs.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Effectively Controlling Reasoning Models through Thinking Intervention](https://arxiv.org/abs/2503.24370)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'The detection of telecom fraud faces significant challenges due to the lack of high-quality multimodal training data that integrates audio signals with reasoning-oriented textual analysis. To address this gap, we present TeleAntiFraud-28k, the first open-source audio-text slow-thinking dataset specifically designed for automated telecom fraud analysis. Our dataset is constructed through three strategies: (1) Privacy-preserved text-truth sample generation using automatically speech recognition (ASR)-transcribed call recordings (with anonymized original audio), ensuring real-world consistency through text-to-speech (TTS) model regeneration; (2) Semantic enhancement via large language model (LLM)-based self-instruction sampling on authentic ASR outputs to expand scenario coverage; (3) Multi-agent adversarial synthesis that simulates emerging fraud tactics through predefined communication scenarios and fraud typologies. The generated dataset contains 28,511 rigorously processed speech-text pairs, complete with detailed annotations for fraud reasoning. The dataset is divided into three tasks: scenario classification, fraud detection, fraud type classification. Furthermore, we construct TeleAntiFraud-Bench, a standardized evaluation benchmark comprising proportionally sampled instances from the dataset, to facilitate systematic testing of model performance on telecom fraud detection tasks. We also contribute a production-optimized supervised fine-tuning (SFT) model trained on hybrid real/synthetic data, while open-sourcing the data processing framework to enable community-driven dataset expansion. This work establishes a foundational framework for multimodal anti-fraud research while addressing critical challenges in data privacy and scenario diversity. The project will be released at https://github.com/JimmyMa99/TeleAntiFraud.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [TeleAntiFraud-28k: A Audio-Text Slow-Thinking Dataset for Telecom Fraud Detection](https://arxiv.org/abs/2503.24115)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Recent advancements in video generation have achieved impressive motion realism, yet they often overlook character-driven storytelling, a crucial task for automated film, animation generation. We introduce Talking Characters, a more realistic task to generate talking character animations directly from speech and text. Unlike talking head, Talking Characters aims at generating the full portrait of one or more characters beyond the facial region. In this paper, we propose MoCha, the first of its kind to generate talking characters. To ensure precise synchronization between video and speech, we propose a speech-video window attention mechanism that effectively aligns speech and video tokens. To address the scarcity of large-scale speech-labeled video datasets, we introduce a joint training strategy that leverages both speech-labeled and text-labeled video data, significantly improving generalization across diverse character actions. We also design structured prompt templates with character tags, enabling, for the first time, multi-character conversation with turn-based dialogue-allowing AI-generated characters to engage in context-aware conversations with cinematic coherence. Extensive qualitative and quantitative evaluations, including human preference studies and benchmark comparisons, demonstrate that MoCha sets a new standard for AI-generated cinematic storytelling, achieving superior realism, expressiveness, controllability and generalization.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [MoCha: Towards Movie-Grade Talking Character Synthesis](https://arxiv.org/abs/2503.23307)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Evolutionary multiobjective optimization (EMO) has made significant strides over the past two decades. However, as problem scales and complexities increase, traditional EMO algorithms face substantial performance limitations due to insufficient parallelism and scalability. While most work has focused on algorithm design to address these challenges, little attention has been given to hardware acceleration, thereby leaving a clear gap between EMO algorithms and advanced computing devices, such as GPUs. To bridge the gap, we propose to parallelize EMO algorithms on GPUs via the tensorization methodology. By employing tensorization, the data structures and operations of EMO algorithms are transformed into concise tensor representations, which seamlessly enables automatic utilization of GPU computing. We demonstrate the effectiveness of our approach by applying it to three representative EMO algorithms: NSGA-III, MOEA/D, and HypE. To comprehensively assess our methodology, we introduce a multiobjective robot control benchmark using a GPU-accelerated physics engine. Our experiments show that the tensorized EMO algorithms achieve speedups of up to 1113x compared to their CPU-based counterparts, while maintaining solution quality and effectively scaling population sizes to hundreds of thousands. Furthermore, the tensorized EMO algorithms efficiently tackle complex multiobjective robot control tasks, producing high-quality solutions with diverse behaviors. Source codes are available at https://github.com/EMI-Group/evomo.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Bridging Evolutionary Multiobjective Optimization and GPU Acceleration via Tensorization](https://arxiv.org/abs/2503.20286)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'In recent years, large language models (LLMs) have shown remarkable capabilities in various artificial intelligence problems. However, they fail to plan reliably, even when prompted with a detailed definition of the planning task. Attempts to improve their planning capabilities, such as chain-of-thought prompting, fine-tuning, and explicit "reasoning" still yield incorrect plans and usually fail to generalize to larger tasks. In this paper, we show how to use LLMs to generate correct plans, even for out-of-distribution tasks of increasing size. For a given planning domain, we ask an LLM to generate several domain-dependent heuristic functions in the form of Python code, evaluate them on a set of training tasks within a greedy best-first search, and choose the strongest one. The resulting LLM-generated heuristics solve many more unseen test tasks than state-of-the-art domain-independent heuristics for classical planning. They are even competitive with the strongest learning algorithm for domain-dependent planning. These findings are especially remarkable given that our proof-of-concept implementation is based on an unoptimized Python planner and the baselines all build upon highly optimized C++ code. In some domains, the LLM-generated heuristics expand fewer states than the baselines, revealing that they are not only efficiently computable, but sometimes even more informative than the state-of-the-art heuristics. Overall, our results show that sampling a set of planning heuristic function programs can significantly improve the planning capabilities of LLMs.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Classical Planning with LLM-Generated Heuristics: Challenging the State of the Art with Python Code](https://arxiv.org/abs/2503.18809)
append_entries: 5
Finish: 2025-04-01 06:00:52.449090
------------------------------------------------------
Started: 2025-04-01 09:00:44.873222
Existing_entries: 952
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Reasoning before action and imagining potential outcomes (i.e., world models) are essential for embodied agents operating in complex open-world environments. Yet, prior work either incorporates only one of these abilities in an end-to-end agent or integrates multiple specialized models into an agent system, limiting the learning efficiency and generalization of the policy. Thus, this paper makes the first attempt to synergize Reasoning and Imagination in an end-to-end Generalist policy, termed RIG. To train RIG in an end-to-end manner, we construct a data pipeline that progressively integrates and enriches the content of imagination and reasoning in the trajectories collected from existing agents. The joint learning of reasoning and next image generation explicitly models the inherent correlation between reasoning, action, and dynamics of environments, and thus exhibits more than 17times sample efficiency improvements and generalization in comparison with previous works. During inference, RIG first reasons about the next action, produces potential action, and then predicts the action outcomes, which offers the agent a chance to review and self-correct based on the imagination before taking real actions. Experimental results show that the synergy of reasoning and imagination not only improves the robustness, generalization, and interoperability of generalist policy but also enables test-time scaling to enhance overall performance.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [RIG: Synergizing Reasoning and Imagination in End-to-End Generalist Policy](https://arxiv.org/abs/2503.24388)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We propose a novel approach for generating complex outputs that significantly improves accuracy in text-to-SQL tasks. Our method leverages execution results to select the most semantically consistent query from multiple candidates, enabling smaller, cost-effective models to surpass computationally intensive reasoning methods such as o1, o3-mini, and DeepSeek R1 while reducing inference cost by as much as 30 times. It integrates effortlessly with existing models, offering a practical and scalable pathway to state-of-the-art SQL generation.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Query and Conquer: Execution-Guided SQL Generation](https://arxiv.org/abs/2503.24364)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We introduce Open-Reasoner-Zero, the first open source implementation of large-scale reasoning-oriented RL training focusing on scalability, simplicity and accessibility. Through extensive experiments, we demonstrate that a minimalist approach, vanilla PPO with GAE (lambda=1, gamma=1) and straightforward rule-based rewards, without any KL regularization, is sufficient to scale up both response length and benchmark performance, similar to the phenomenon observed in DeepSeek-R1-Zero. Using the same base model as DeepSeek-R1-Zero-Qwen-32B, our implementation achieves superior performance on AIME2024, MATH500, and the GPQA Diamond benchmark while demonstrating remarkable efficiency -- requiring only a tenth of the training steps, compared to DeepSeek-R1-Zero pipeline. In the spirit of open source, we release our source code, parameter settings, training data, and model weights across various sizes.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Open-Reasoner-Zero: An Open Source Approach to Scaling Up Reinforcement Learning on the Base Model](https://arxiv.org/abs/2503.24290)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "As enthusiasm for scaling computation (data and parameters) in the pretraining era gradually diminished, test-time scaling (TTS), also referred to as ``test-time computing'' has emerged as a prominent research focus. Recent studies demonstrate that TTS can further elicit the problem-solving capabilities of large language models (LLMs), enabling significant breakthroughs not only in specialized reasoning tasks, such as mathematics and coding, but also in general tasks like open-ended Q&A. However, despite the explosion of recent efforts in this area, there remains an urgent need for a comprehensive survey offering a systemic understanding. To fill this gap, we propose a unified, multidimensional framework structured along four core dimensions of TTS research: what to scale, how to scale, where to scale, and how well to scale. Building upon this taxonomy, we conduct an extensive review of methods, application scenarios, and assessment aspects, and present an organized decomposition that highlights the unique functional roles of individual techniques within the broader TTS landscape. From this analysis, we distill the major developmental trajectories of TTS to date and offer hands-on guidelines for practical deployment. Furthermore, we identify several open challenges and offer insights into promising future directions, including further scaling, clarifying the functional essence of techniques, generalizing to more tasks, and more attributions."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [What, How, Where, and How Well? A Survey on Test-Time Scaling in Large Language Models](https://arxiv.org/abs/2503.24235)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Reinforcement learning (RL) with verifiable rewards (RLVR) has shown promising results in mathematical reasoning and coding tasks where well-structured reference answers are available. However, its applicability to broader domains remains underexplored. In this work, we study the extension of RLVR to more diverse domains such as medicine, chemistry, psychology, and economics. We observe high agreement in binary judgments across different large language models (LLMs) when objective reference answers exist, which challenges the necessity of large-scale annotation for training domain-specific reward models. To address the limitations of binary rewards when handling unstructured reference answers, we further incorporate model-based soft scoring into RLVR to improve its flexibility. Our experiments show that a distilled generative reward model can serve as an effective cross-domain verifier, providing reliable reward signals for RL without requiring domain-specific annotations. By fine-tuning a base 7B model using various RL algorithms against our reward model, we obtain policies that outperform state-of-the-art open-source aligned LLMs such as Qwen2.5-72B-Instruct and DeepSeek-R1-Distill-Qwen-32B by a large margin, across domains in free-form answer settings. This also strengthens RLVR's robustness and scalability, highlighting its potential for real-world applications with noisy or weak labels."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Expanding RL with Verifiable Rewards Across Diverse Domains](https://arxiv.org/abs/2503.23829)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'The recent emergence of Large Vision-Language Models(VLMs) has resulted in a variety of different benchmarks for evaluating such models. Despite this, we observe that most existing evaluation methods suffer from the fact that they either require the model to choose from pre-determined responses, sacrificing open-endedness, or evaluate responses using a judge model, resulting in subjective and unreliable evaluation. In addition, we observe a lack of benchmarks for VLMs in the Korean language, which are necessary as a separate metric from more common English language benchmarks, as the performance of generative language models can differ significantly based on the language being used. Therefore, we present KOFFVQA, a general-purpose free-form visual question answering benchmark in the Korean language for the evaluation of VLMs. Our benchmark consists of 275 carefully crafted questions each paired with an image and grading criteria covering 10 different aspects of VLM performance. The grading criteria eliminate the problem of unreliability by allowing the judge model to grade each response based on a pre-determined set of rules. By defining the evaluation criteria in an objective manner, even a small open-source model can be used to evaluate models on our benchmark reliably. In addition to evaluating a large number of existing VLMs on our benchmark, we also experimentally verify that our method of using pre-existing grading criteria for evaluation is much more reliable than existing methods. Our evaluation code is available at https://github.com/maum-ai/KOFFVQA'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [KOFFVQA: An Objectively Evaluated Free-form VQA Benchmark for Large Vision-Language Models in the Korean Language](https://arxiv.org/abs/2503.23730)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'This paper explores the task of Complex Visual Text Generation (CVTG), which centers on generating intricate textual content distributed across diverse regions within visual images. In CVTG, image generation models often rendering distorted and blurred visual text or missing some visual text. To tackle these challenges, we propose TextCrafter, a novel multi-visual text rendering method. TextCrafter employs a progressive strategy to decompose complex visual text into distinct components while ensuring robust alignment between textual content and its visual carrier. Additionally, it incorporates a token focus enhancement mechanism to amplify the prominence of visual text during the generation process. TextCrafter effectively addresses key challenges in CVTG tasks, such as text confusion, omissions, and blurriness. Moreover, we present a new benchmark dataset, CVTG-2K, tailored to rigorously evaluate the performance of generative models on CVTG tasks. Extensive experiments demonstrate that our method surpasses state-of-the-art approaches.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [TextCrafter: Accurately Rendering Multiple Texts in Complex Visual Scenes](https://arxiv.org/abs/2503.23461)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Video generation and editing conditioned on text prompts or images have undergone significant advancements. However, challenges remain in accurately controlling global layout and geometry details solely by texts, and supporting motion control and local modification through images. In this paper, we aim to achieve sketch-based spatial and motion control for video generation and support fine-grained editing of real or synthetic videos. Based on the DiT video generation model, we propose a memory-efficient control structure with sketch control blocks that predict residual features of skipped DiT blocks. Sketches are drawn on one or two keyframes (at arbitrary time points) for easy interaction. To propagate such temporally sparse sketch conditions across all frames, we propose an inter-frame attention mechanism to analyze the relationship between the keyframes and each video frame. For sketch-based video editing, we design an additional video insertion module that maintains consistency between the newly edited content and the original video's spatial feature and dynamic motion. During inference, we use latent fusion for the accurate preservation of unedited regions. Extensive experiments demonstrate that our SketchVideo achieves superior performance in controllable video generation and editing."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [SketchVideo: Sketch-based Video Generation and Editing](https://arxiv.org/abs/2503.23284)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Large Reasoning Models (LRMs) significantly improve the reasoning ability of Large Language Models (LLMs) by learning to reason, exhibiting promising performance in complex task-solving. However, their deliberative reasoning process leads to inefficiencies in token usage, memory consumption, and inference time. Thus, this survey provides a review of efficient inference methods designed specifically for LRMs, focusing on mitigating token inefficiency while preserving the reasoning quality. First, we introduce a taxonomy to group the recent methods into two main categories: (a) explicit compact Chain-of-Thought (CoT), which reduces tokens while keeping the explicit reasoning structure, and (b) implicit latent CoT, which encodes reasoning steps within hidden representations instead of explicit tokens. Meanwhile, we discuss their strengths and weaknesses. Then, we conduct empirical analyses on existing methods from performance and efficiency aspects. Besides, we present open challenges in this field, including human-centric controllable reasoning, trade-off between interpretability and efficiency of reasoning, ensuring safety of efficient reasoning, and broader applications of efficient reasoning. In addition, we highlight key insights for enhancing LRMs' inference efficiency via techniques such as model merging, new architectures, and agent routers. We hope this work serves as a valuable guide, helping researchers overcome challenges in this vibrant fieldhttps://github.com/yueliu1999/Awesome-Efficient-Inference-for-LRMs."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Efficient Inference for Large Reasoning Models: A Survey](https://arxiv.org/abs/2503.23077)
append_entries: 9
Finish: 2025-04-01 09:00:48.638030
------------------------------------------------------
Started: 2025-04-01 12:14:29.579380
Existing_entries: 961
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Recent advances in DUSt3R have enabled robust estimation of dense point clouds and camera parameters of static scenes, leveraging Transformer network architectures and direct supervision on large-scale 3D datasets. In contrast, the limited scale and diversity of available 4D datasets present a major bottleneck for training a highly generalizable 4D model. This constraint has driven conventional 4D methods to fine-tune 3D models on scalable dynamic video data with additional geometric priors such as optical flow and depths. In this work, we take an opposite path and introduce Easi3R, a simple yet efficient training-free method for 4D reconstruction. Our approach applies attention adaptation during inference, eliminating the need for from-scratch pre-training or network fine-tuning. We find that the attention layers in DUSt3R inherently encode rich information about camera and object motion. By carefully disentangling these attention maps, we achieve accurate dynamic region segmentation, camera pose estimation, and 4D dense point map reconstruction. Extensive experiments on real-world dynamic videos demonstrate that our lightweight attention adaptation significantly outperforms previous state-of-the-art methods that are trained or finetuned on extensive dynamic datasets. Our code is publicly available for research purpose at https://easi3r.github.io/'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Easi3R: Estimating Disentangled Motion from DUSt3R Without Training](https://arxiv.org/abs/2503.24391)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'It is highly desirable to obtain a model that can generate high-quality 3D meshes from text prompts in just seconds. While recent attempts have adapted pre-trained text-to-image diffusion models, such as Stable Diffusion (SD), into generators of 3D representations (e.g., Triplane), they often suffer from poor quality due to the lack of sufficient high-quality 3D training data. Aiming at overcoming the data shortage, we propose a novel training scheme, termed as Progressive Rendering Distillation (PRD), eliminating the need for 3D ground-truths by distilling multi-view diffusion models and adapting SD into a native 3D generator. In each iteration of training, PRD uses the U-Net to progressively denoise the latent from random noise for a few steps, and in each step it decodes the denoised latent into 3D output. Multi-view diffusion models, including MVDream and RichDreamer, are used in joint with SD to distill text-consistent textures and geometries into the 3D outputs through score distillation. Since PRD supports training without 3D ground-truths, we can easily scale up the training data and improve generation quality for challenging text prompts with creative concepts. Meanwhile, PRD can accelerate the inference speed of the generation model in just a few steps. With PRD, we train a Triplane generator, namely TriplaneTurbo, which adds only 2.5% trainable parameters to adapt SD for Triplane generation. TriplaneTurbo outperforms previous text-to-3D generators in both efficiency and quality. Specifically, it can produce high-quality 3D meshes in 1.2 seconds and generalize well for challenging text input. The code is available at https://github.com/theEricMa/TriplaneTurbo.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Progressive Rendering Distillation: Adapting Stable Diffusion for Instant Text-to-Mesh Generation without 3D Data](https://arxiv.org/abs/2503.21694)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Synthesizing diverse and physically plausible Human-Scene Interactions (HSI) is pivotal for both computer animation and embodied AI. Despite encouraging progress, current methods mainly focus on developing separate controllers, each specialized for a specific interaction task. This significantly hinders the ability to tackle a wide variety of challenging HSI tasks that require the integration of multiple skills, e.g., sitting down while carrying an object. To address this issue, we present TokenHSI, a single, unified transformer-based policy capable of multi-skill unification and flexible adaptation. The key insight is to model the humanoid proprioception as a separate shared token and combine it with distinct task tokens via a masking mechanism. Such a unified policy enables effective knowledge sharing across skills, thereby facilitating the multi-task training. Moreover, our policy architecture supports variable length inputs, enabling flexible adaptation of learned skills to new scenarios. By training additional task tokenizers, we can not only modify the geometries of interaction targets but also coordinate multiple skills to address complex tasks. The experiments demonstrate that our approach can significantly improve versatility, adaptability, and extensibility in various HSI tasks. Website: https://liangpan99.github.io/TokenHSI/'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [TokenHSI: Unified Synthesis of Physical Human-Scene Interactions through Task Tokenization](https://arxiv.org/abs/2503.19901)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Multimodal Large Language Models (MLLMs) have emerged to tackle the challenges of Visual Question Answering (VQA), sparking a new research focus on conducting objective evaluations of these models. Existing evaluation methods face limitations due to the significant human workload required to design Q&A pairs for visual images, which inherently restricts the scale and scope of evaluations. Although automated MLLM-as-judge approaches attempt to reduce the human workload through automatic evaluations, they often introduce biases. To address these problems, we propose an Unsupervised Peer review MLLM Evaluation framework. It utilizes only image data, allowing models to automatically generate questions and conduct peer review assessments of answers from other models, effectively alleviating the reliance on human workload. Additionally, we introduce the vision-language scoring system to mitigate the bias issues, which focuses on three aspects: (i) response correctness; (ii) visual understanding and reasoning; and (iii) image-text correlation. Experimental results demonstrate that UPME achieves a Pearson correlation of 0.944 with human evaluations on the MMstar dataset and 0.814 on the ScienceQA dataset, indicating that our framework closely aligns with human-designed benchmarks and inherent human preferences.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [UPME: An Unsupervised Peer Review Framework for Multimodal Large Language Model Evaluation](https://arxiv.org/abs/2503.14941)
append_entries: 4
Finish: 2025-04-01 12:14:31.391025
------------------------------------------------------
Started: 2025-04-01 15:00:34.515406
Existing_entries: 965
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'The mathematical problem-solving capabilities of large language models have become a focal point of research, with growing interests in leveraging self-generated reasoning paths as a promising way to refine and enhance these models. These paths capture step-by-step logical processes while requiring only the correct answer for supervision. The self-training method has been shown to be effective in reasoning tasks while eliminating the need for external models and manual annotations. However, optimizing the use of self-generated data for model training remains an open challenge. In this work, we propose Entropy-Based Adaptive Weighting for Self-Training (EAST), an adaptive weighting strategy designed to prioritize uncertain data during self-training. Specifically, EAST employs a mapping function with a tunable parameter that controls the sharpness of the weighting, assigning higher weights to data where the model exhibits greater uncertainty. This approach guides the model to focus on more informative and challenging examples, thereby enhancing its reasoning ability. We evaluate our approach on GSM8K and MATH benchmarks. Empirical results show that, while the vanilla method yields virtually no improvement (0%) on MATH, EAST achieves around a 1% gain over backbone model. On GSM8K, EAST attains a further 1-2% performance boost compared to the vanilla method.'}]}]Summarization failed, append the original article
error: Request timed out.. Line: 406.
Append: [Entropy-Based Adaptive Weighting for Self-Training](https://arxiv.org/abs/2503.23913)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'In the domain of 3D content creation, achieving optimal mesh topology through AI models has long been a pursuit for 3D artists. Previous methods, such as MeshGPT, have explored the generation of ready-to-use 3D objects via mesh auto-regressive techniques. While these methods produce visually impressive results, their reliance on token-by-token predictions in the auto-regressive process leads to several significant limitations. These include extremely slow generation speeds and an uncontrollable number of mesh faces. In this paper, we introduce MeshCraft, a novel framework for efficient and controllable mesh generation, which leverages continuous spatial diffusion to generate discrete triangle faces. Specifically, MeshCraft consists of two core components: 1) a transformer-based VAE that encodes raw meshes into continuous face-level tokens and decodes them back to the original meshes, and 2) a flow-based diffusion transformer conditioned on the number of faces, enabling the generation of high-quality 3D meshes with a predefined number of faces. By utilizing the diffusion model for the simultaneous generation of the entire mesh topology, MeshCraft achieves high-fidelity mesh generation at significantly faster speeds compared to auto-regressive methods. Specifically, MeshCraft can generate an 800-face mesh in just 3.2 seconds (35times faster than existing baselines). Extensive experiments demonstrate that MeshCraft outperforms state-of-the-art techniques in both qualitative and quantitative evaluations on ShapeNet dataset and demonstrates superior performance on Objaverse dataset. Moreover, it integrates seamlessly with existing conditional guidance strategies, showcasing its potential to relieve artists from the time-consuming manual work involved in mesh creation.'}]}]Summarization failed, append the original article
error: Request timed out.. Line: 406.
Append: [MeshCraft: Exploring Efficient and Controllable Mesh Generation with Flow-based DiTs](https://arxiv.org/abs/2503.23022)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Parameter-Efficient FineTuning (PEFT) methods have recently gained significant popularity thanks to the widespread availability of large-scale pretrained models. These methods allow for quick adaptation to downstream tasks with minimal computational cost. However, popular finetuning methods such as LoRA exhibit limited robustness when it comes to hyperparameter choices or extended training regimes, preventing optimal out-of-the-box performance. In contrast, bounded approaches, such as ETHER, provide greater robustness but are limited to extremely low-rank adaptations and fixed-strength transformations, reducing their adaptation expressive power. In this work, we propose Decoupled Low-rank Adaptation (DeLoRA), a novel finetuning method that normalizes and scales learnable low-rank matrices. By bounding the distance of the transformation, DeLoRA effectively decouples the angular learning from the adaptation strength, enhancing robustness without compromising performance. Through evaluations on subject-driven image generation, natural language understanding, and instruction tuning, we show that DeLoRA matches or surpasses performance of competing PEFT methods, while exhibiting stronger robustness. Code is available at https://github.com/ExplainableML/DeLoRA.'}]}]Summarization failed, append the original article
error: Request timed out.. Line: 406.
Append: [Decoupling Angles and Strength in Low-rank Adaptation](https://arxiv.org/abs/2503.18225)
append_entries: 3
Finish: 2025-04-01 15:01:24.072257
------------------------------------------------------
Started: 2025-04-01 18:00:38.063888
Existing_entries: 968
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Co-speech gestures play a vital role in non-verbal communication. In this paper, we introduce a new framework for co-speech gesture understanding in the wild. Specifically, we propose three new tasks and benchmarks to evaluate a model's capability to comprehend gesture-text-speech associations: (i) gesture-based retrieval, (ii) gestured word spotting, and (iii) active speaker detection using gestures. We present a new approach that learns a tri-modal speech-text-video-gesture representation to solve these tasks. By leveraging a combination of global phrase contrastive loss and local gesture-word coupling loss, we demonstrate that a strong gesture representation can be learned in a weakly supervised manner from videos in the wild. Our learned representations outperform previous methods, including large vision-language models (VLMs), across all three tasks. Further analysis reveals that speech and text modalities capture distinct gesture-related signals, underscoring the advantages of learning a shared tri-modal embedding space. The dataset, model, and code are available at: https://www.robots.ox.ac.uk/~vgg/research/jegal"}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Understanding Co-speech Gestures in-the-wild](https://arxiv.org/abs/2503.22668)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Training vision-language models (VLMs) typically requires large-scale, high-quality image-text pairs, but collecting or synthesizing such data is costly. In contrast, text data is abundant and inexpensive, prompting the question: can high-quality multimodal training data be synthesized purely from text? To tackle this, we propose a cross-integrated three-stage multimodal data synthesis framework, which generates two datasets: Unicorn-1.2M and Unicorn-471K-Instruction. In Stage 1: Diverse Caption Data Synthesis, we construct 1.2M semantically diverse high-quality captions by expanding sparse caption seeds using large language models (LLMs). In Stage 2: Instruction-Tuning Data Generation, we further process 471K captions into multi-turn instruction-tuning tasks to support complex reasoning. Finally, in Stage 3: Modality Representation Transfer, these textual captions representations are transformed into visual representations, resulting in diverse synthetic image representations. This three-stage process enables us to construct Unicorn-1.2M for pretraining and Unicorn-471K-Instruction for instruction-tuning, without relying on real images. By eliminating the dependency on real images while maintaining data quality and diversity, our framework offers a cost-effective and scalable solution for VLMs training. Code is available at https://github.com/Yu-xm/Unicorn.git.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Unicorn: Text-Only Data Synthesis for Vision Language Model Training](https://arxiv.org/abs/2503.22655)
append_entries: 2
Finish: 2025-04-01 18:00:39.107647
------------------------------------------------------
Started: 2025-04-01 21:00:38.429985
Existing_entries: 970
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Pre-trained video large language models (Video LLMs) exhibit remarkable reasoning capabilities, yet adapting these models to new tasks involving additional modalities or data types (e.g., audio or 3D information) remains challenging. In this paper, we present PAVE, a flexible framework for adapting pre-trained Video LLMs to downstream tasks with side-channel signals, such as audio, 3D cues, or multi-view videos. PAVE introduces lightweight adapters, referred to as "patches," which add a small number of parameters and operations to a base model without modifying its architecture or pre-trained weights. In doing so, PAVE can effectively adapt the pre-trained base model to support diverse downstream tasks, including audio-visual question answering, 3D reasoning, multi-view video recognition, and high frame rate video understanding. Across these tasks, PAVE significantly enhances the performance of the base model, surpassing state-of-the-art task-specific models while incurring a minor cost of ~0.1% additional FLOPs and parameters. Further, PAVE supports multi-task learning and generalizes well across different Video LLMs. Our code is available at https://github.com/dragonlzm/PAVE.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [PAVE: Patching and Adapting Video Large Language Models](https://arxiv.org/abs/2503.19794)
append_entries: 1
Finish: 2025-04-01 21:00:39.217485
------------------------------------------------------
Started: 2025-04-02 00:37:45.135559
Existing_entries: 971
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Action models are essential for enabling autonomous agents to perform complex tasks. However, training large action models remains challenging due to the diversity of agent environments and the complexity of agentic data. Despite growing interest, existing infrastructure provides limited support for scalable, agent-specific fine-tuning. We present ActionStudio, a lightweight and extensible data and training framework designed for large action models. ActionStudio unifies heterogeneous agent trajectories through a standardized format, supports diverse training paradigms including LoRA, full fine-tuning, and distributed setups, and integrates robust preprocessing and verification tools. We validate its effectiveness across both public and realistic industry benchmarks, demonstrating strong performance and practical scalability. We open-sourced code and data at https://github.com/SalesforceAIResearch/xLAM to facilitate research in the community.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [ActionStudio: A Lightweight Framework for Data and Training of Large Action Models](https://arxiv.org/abs/2503.22673)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'This work focuses on open-domain 4D avatarization, with the purpose of creating a 4D avatar from a portrait image in an arbitrary style. We select parametric triplanes as the intermediate 4D representation and propose a practical training paradigm that takes advantage of both generative adversarial networks (GANs) and diffusion models. Our design stems from the observation that 4D GANs excel at bridging images and triplanes without supervision yet usually face challenges in handling diverse data distributions. A robust 2D diffusion prior emerges as the solution, assisting the GAN in transferring its expertise across various domains. The synergy between these experts permits the construction of a multi-domain image-triplane dataset, which drives the development of a general 4D avatar creator. Extensive experiments suggest that our model, AvatarArtist, is capable of producing high-quality 4D avatars with strong robustness to various source image domains. The code, the data, and the models will be made publicly available to facilitate future studies..'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [AvatarArtist: Open-Domain 4D Avatarization](https://arxiv.org/abs/2503.19906)
append_entries: 2
Finish: 2025-04-02 00:37:46.321605
------------------------------------------------------
Started: 2025-04-02 03:24:52.275308
Existing_entries: 973
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Most 3D object generators focus on aesthetic quality, often neglecting physical constraints necessary in applications. One such constraint is that the 3D object should be self-supporting, i.e., remains balanced under gravity. Prior approaches to generating stable 3D objects used differentiable physics simulators to optimize geometry at test-time, which is slow, unstable, and prone to local optima. Inspired by the literature on aligning generative models to external feedback, we propose Direct Simulation Optimization (DSO), a framework to use the feedback from a (non-differentiable) simulator to increase the likelihood that the 3D generator outputs stable 3D objects directly. We construct a dataset of 3D objects labeled with a stability score obtained from the physics simulator. We can then fine-tune the 3D generator using the stability score as the alignment metric, via direct preference optimization (DPO) or direct reward optimization (DRO), a novel objective, which we introduce, to align diffusion models without requiring pairwise preferences. Our experiments show that the fine-tuned feed-forward generator, using either DPO or DRO objective, is much faster and more likely to produce stable objects than test-time optimization. Notably, the DSO framework works even without any ground-truth 3D objects for training, allowing the 3D generator to self-improve by automatically collecting simulation feedback on its own outputs.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [DSO: Aligning 3D Generators with Simulation Feedback for Physical Soundness](https://arxiv.org/abs/2503.22677)
append_entries: 1
Finish: 2025-04-02 03:24:53.044151
------------------------------------------------------
Started: 2025-04-02 06:00:42.826672
Existing_entries: 974
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Despite remarkable advancements in video depth estimation, existing methods exhibit inherent limitations in achieving geometric fidelity through the affine-invariant predictions, limiting their applicability in reconstruction and other metrically grounded downstream tasks. We propose GeometryCrafter, a novel framework that recovers high-fidelity point map sequences with temporal coherence from open-world videos, enabling accurate 3D/4D reconstruction, camera parameter estimation, and other depth-based applications. At the core of our approach lies a point map Variational Autoencoder (VAE) that learns a latent space agnostic to video latent distributions for effective point map encoding and decoding. Leveraging the VAE, we train a video diffusion model to model the distribution of point map sequences conditioned on the input videos. Extensive evaluations on diverse datasets demonstrate that GeometryCrafter achieves state-of-the-art 3D accuracy, temporal consistency, and generalization capability.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [GeometryCrafter: Consistent Geometry Estimation for Open-world Videos with Diffusion Priors](https://arxiv.org/abs/2504.01016)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Scaling test-time compute has emerged as a key strategy for enhancing the reasoning capabilities of large language models (LLMs), particularly in tasks like mathematical problem-solving. A traditional approach, Self-Consistency (SC), generates multiple solutions to a problem and selects the most common answer via majority voting. Another common method involves scoring each solution with a reward model (verifier) and choosing the best one. Recent advancements in Generative Reward Models (GenRM) reframe verification as a next-token prediction task, enabling inference-time scaling along a new axis. Specifically, GenRM generates multiple verification chains-of-thought to score each solution. Under a limited inference budget, this introduces a fundamental trade-off: should you spend the budget on scaling solutions via SC or generate fewer solutions and allocate compute to verification via GenRM? To address this, we evaluate GenRM against SC under a fixed inference budget. Interestingly, we find that SC is more compute-efficient than GenRM for most practical inference budgets across diverse models and datasets. For instance, GenRM first matches SC after consuming up to 8x the inference compute and requires significantly more compute to outperform it. Furthermore, we derive inference scaling laws for the GenRM paradigm, revealing that compute-optimal inference favors scaling solution generation more aggressively than scaling the number of verifications. Our work provides practical guidance on optimizing test-time scaling by balancing solution generation and verification. The code is available at https://github.com/nishadsinghi/sc-genrm-scaling.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [When To Solve, When To Verify: Compute-Optimal Problem Solving and Generative Verification for LLM Reasoning](https://arxiv.org/abs/2504.01005)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Computer use agents automate digital tasks by directly interacting with graphical user interfaces (GUIs) on computers and mobile devices, offering significant potential to enhance human productivity by completing an open-ended space of user queries. However, current agents face significant challenges: imprecise grounding of GUI elements, difficulties with long-horizon task planning, and performance bottlenecks from relying on single generalist models for diverse cognitive tasks. To this end, we introduce Agent S2, a novel compositional framework that delegates cognitive responsibilities across various generalist and specialist models. We propose a novel Mixture-of-Grounding technique to achieve precise GUI localization and introduce Proactive Hierarchical Planning, dynamically refining action plans at multiple temporal scales in response to evolving observations. Evaluations demonstrate that Agent S2 establishes new state-of-the-art (SOTA) performance on three prominent computer use benchmarks. Specifically, Agent S2 achieves 18.9% and 32.7% relative improvements over leading baseline agents such as Claude Computer Use and UI-TARS on the OSWorld 15-step and 50-step evaluation. Moreover, Agent S2 generalizes effectively to other operating systems and applications, surpassing previous best methods by 52.8% on WindowsAgentArena and by 16.52% on AndroidWorld relatively. Code available at https://github.com/simular-ai/Agent-S.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Agent S2: A Compositional Generalist-Specialist Framework for Computer Use Agents](https://arxiv.org/abs/2504.00906)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'To address the bottleneck of accurate user intent interpretation within the current video generation community, we present Any2Caption, a novel framework for controllable video generation under any condition. The key idea is to decouple various condition interpretation steps from the video synthesis step. By leveraging modern multimodal large language models (MLLMs), Any2Caption interprets diverse inputs--text, images, videos, and specialized cues such as region, motion, and camera poses--into dense, structured captions that offer backbone video generators with better guidance. We also introduce Any2CapIns, a large-scale dataset with 337K instances and 407K conditions for any-condition-to-caption instruction tuning. Comprehensive evaluations demonstrate significant improvements of our system in controllability and video quality across various aspects of existing video generation models. Project Page: https://sqwu.top/Any2Cap/'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Any2Caption:Interpreting Any Condition to Caption for Controllable Video Generation](https://arxiv.org/abs/2503.24379)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Recent advancements in Large Language Models (LLMs) have significantly enhanced their ability to perform complex reasoning tasks, transitioning from fast and intuitive thinking (System 1) to slow and deep reasoning (System 2). While System 2 reasoning improves task accuracy, it often incurs substantial computational costs due to its slow thinking nature and inefficient or unnecessary reasoning behaviors. In contrast, System 1 reasoning is computationally efficient but leads to suboptimal performance. Consequently, it is critical to balance the trade-off between performance (benefits) and computational costs (budgets), giving rise to the concept of reasoning economy. In this survey, we provide a comprehensive analysis of reasoning economy in both the post-training and test-time inference stages of LLMs, encompassing i) the cause of reasoning inefficiency, ii) behavior analysis of different reasoning patterns, and iii) potential solutions to achieve reasoning economy. By offering actionable insights and highlighting open challenges, we aim to shed light on strategies for improving the reasoning economy of LLMs, thereby serving as a valuable resource for advancing research in this evolving area. We also provide a public repository to continually track developments in this fast-evolving field.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Harnessing the Reasoning Economy: A Survey of Efficient Reasoning for Large Language Models](https://arxiv.org/abs/2503.24377)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Recent advancements in Chain of Thought (COT) generation have significantly improved the reasoning capabilities of Large Language Models (LLMs), with reinforcement learning (RL) emerging as an effective post-training approach. Multimodal Large Language Models (MLLMs) inherit this reasoning potential but remain underexplored in tasks requiring both perception and logical reasoning. To address this, we introduce SEED-Bench-R1, a benchmark designed to systematically evaluate post-training methods for MLLMs in video understanding. It includes intricate real-world videos and complex everyday planning tasks in the format of multiple-choice questions, requiring sophisticated perception and reasoning. SEED-Bench-R1 assesses generalization through a three-level hierarchy: in-distribution, cross-environment, and cross-environment-task scenarios, equipped with a large-scale training dataset with easily verifiable ground-truth answers. Using Qwen2-VL-Instruct-7B as a base model, we compare RL with supervised fine-tuning (SFT), demonstrating RL's data efficiency and superior performance on both in-distribution and out-of-distribution tasks, even outperforming SFT on general video understanding benchmarks like LongVideoBench. Our detailed analysis reveals that RL enhances visual perception but often produces less logically coherent reasoning chains. We identify key limitations such as inconsistent reasoning and overlooked visual cues, and suggest future improvements in base model reasoning, reward modeling, and RL robustness against noisy signals."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Exploring the Effect of Reinforcement Learning on Video Understanding: Insights from SEED-Bench-R1](https://arxiv.org/abs/2503.24376)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Recently, model merging methods have demonstrated powerful strengths in combining abilities on various tasks from multiple Large Language Models (LLMs). While previous model merging methods mainly focus on merging homogeneous models with identical architecture, they meet challenges when dealing with Multimodal Large Language Models (MLLMs) with inherent heterogeneous property, including differences in model architecture and the asymmetry in the parameter space. In this work, we propose AdaMMS, a novel model merging method tailored for heterogeneous MLLMs. Our method tackles the challenges in three steps: mapping, merging and searching. Specifically, we first design mapping function between models to apply model merging on MLLMs with different architecture. Then we apply linear interpolation on model weights to actively adapt the asymmetry in the heterogeneous MLLMs. Finally in the hyper-parameter searching step, we propose an unsupervised hyper-parameter selection method for model merging. As the first model merging method capable of merging heterogeneous MLLMs without labeled data, extensive experiments on various model combinations demonstrated that AdaMMS outperforms previous model merging methods on various vision-language benchmarks.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [AdaMMS: Model Merging for Heterogeneous Multimodal Large Language Models with Unsupervised Coefficient Optimization](https://arxiv.org/abs/2503.23733)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Large language models (LLMs) possess impressive linguistic capabilities but often fail to faithfully retain factual knowledge, leading to hallucinations and unreliable outputs. Understanding LLMs' knowledge deficiencies by exhaustively evaluating against full-scale knowledge bases is computationally prohibitive, especially for closed-weight models. We propose stochastic error ascent (SEA), a scalable and efficient framework for discovering knowledge deficiencies (errors) in closed-weight LLMs under a strict query budget. Rather than naively probing all knowledge candidates, SEA formulates error discovery as a stochastic optimization process: it iteratively retrieves new high-error candidates by leveraging the semantic similarity to previously observed failures. To further enhance search efficiency and coverage, SEA employs hierarchical retrieval across document and paragraph levels, and constructs a relation directed acyclic graph to model error propagation and identify systematic failure modes. Empirically, SEA uncovers 40.7x more knowledge errors than Automated Capability Discovery and 26.7% more than AutoBencher, while reducing the cost-per-error by 599x and 9x, respectively. Human evaluation confirms the high quality of generated questions, while ablation and convergence analyses validate the contribution of each component in SEA. Further analysis on the discovered errors reveals correlated failure patterns across LLM families and recurring deficits, highlighting the need for better data coverage and targeted fine-tuning in future LLM development."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Discovering Knowledge Deficiencies of Language Models on Massive Knowledge Base](https://arxiv.org/abs/2503.23361)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Human hands play a central role in interacting, motivating increasing research in dexterous robotic manipulation. Data-driven embodied AI algorithms demand precise, large-scale, human-like manipulation sequences, which are challenging to obtain with conventional reinforcement learning or real-world teleoperation. To address this, we introduce ManipTrans, a novel two-stage method for efficiently transferring human bimanual skills to dexterous robotic hands in simulation. ManipTrans first pre-trains a generalist trajectory imitator to mimic hand motion, then fine-tunes a specific residual module under interaction constraints, enabling efficient learning and accurate execution of complex bimanual tasks. Experiments show that ManipTrans surpasses state-of-the-art methods in success rate, fidelity, and efficiency. Leveraging ManipTrans, we transfer multiple hand-object datasets to robotic hands, creating DexManipNet, a large-scale dataset featuring previously unexplored tasks like pen capping and bottle unscrewing. DexManipNet comprises 3.3K episodes of robotic manipulation and is easily extensible, facilitating further policy training for dexterous hands and enabling real-world deployments.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [ManipTrans: Efficient Dexterous Bimanual Manipulation Transfer via Residual Learning](https://arxiv.org/abs/2503.21860)
append_entries: 9
Finish: 2025-04-02 06:00:47.380561
------------------------------------------------------
Started: 2025-04-02 09:00:53.789392
Existing_entries: 983
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Soft attention is a critical mechanism powering LLMs to locate relevant parts within a given context. However, individual attention weights are determined by the similarity of only a single query and key token vector. This "single token attention" bottlenecks the amount of information used in distinguishing a relevant part from the rest of the context. To address this issue, we propose a new attention method, Multi-Token Attention (MTA), which allows LLMs to condition their attention weights on multiple query and key vectors simultaneously. This is achieved by applying convolution operations over queries, keys and heads, allowing nearby queries and keys to affect each other\'s attention weights for more precise attention. As a result, our method can locate relevant context using richer, more nuanced information that can exceed a single vector\'s capacity. Through extensive evaluations, we demonstrate that MTA achieves enhanced performance on a range of popular benchmarks. Notably, it outperforms Transformer baseline models on standard language modeling tasks, and on tasks that require searching for information within long contexts, where our method\'s ability to leverage richer information proves particularly beneficial.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Multi-Token Attention](https://arxiv.org/abs/2504.00927)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Test-time scaling has emerged as a powerful technique for enhancing the reasoning capabilities of large language models. However, its effectiveness in medical reasoning remains uncertain, as the medical domain fundamentally differs from mathematical tasks in terms of knowledge representation and decision-making processes. In this paper, we provide the first comprehensive investigation of test-time scaling for medical reasoning and present m1, a simple yet effective approach that increases a model's medical reasoning capability at inference. Our evaluation across diverse medical tasks demonstrates that test-time scaling consistently enhances medical reasoning, enabling lightweight fine-tuned models under 10B parameters to establish new state-of-the-art performance, while our 32B model rivals previous 70B-scale medical LLMs. However, we identify an optimal reasoning token budget of approximately 4K, beyond which performance may degrade due to overthinking. Budget forcing, which extends test-time computation through iterative prompts, helps models double-check answers but does not necessarily improve the overall medical QA performance and, in some cases, even introduces errors into previously correct responses. Our case-by-case analysis identifies insufficient medical knowledge as a key bottleneck that prevents further performance gains through test-time scaling. We find that increasing data scale, improving data quality, and expanding model capacity consistently enhance medical knowledge grounding, enabling continued performance improvements, particularly on challenging medical benchmarks where smaller models reach saturation. These findings underscore fundamental differences between medical and mathematical reasoning in LLMs, highlighting that enriched medical knowledge, other than increased reasoning depth alone, is essential for realizing the benefits of test-time scaling."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [m1: Unleash the Potential of Test-Time Scaling for Medical Reasoning with Large Language Models](https://arxiv.org/abs/2504.00869)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Large Language Models (LLMs) can achieve enhanced complex problem-solving through test-time computing scaling, yet this often entails longer contexts and numerous reasoning token costs. In this paper, we propose an efficient test-time scaling method that trains LLMs on code-related reasoning trajectories, facilitating their reduction of excess thinking tokens while maintaining performance. First, we create Z1-Code-Reasoning-107K, a curated dataset of simple and complex coding problems paired with their short and long solution trajectories. Second, we present a novel Shifted Thinking Window to mitigate overthinking overhead by removing context-delimiting tags (e.g., . . . ) and capping reasoning tokens. Trained with long and short trajectory data and equipped with Shifted Thinking Window, our model, Z1-7B, demonstrates the ability to adjust its reasoning level as the complexity of problems and exhibits efficient test-time scaling across different reasoning tasks that matches R1-Distill-Qwen-7B performance with about 30% of its average thinking tokens. Notably, fine-tuned with only code trajectories, Z1-7B demonstrates generalization to broader reasoning tasks (47.5% on GPQA Diamond). Our analysis of efficient reasoning elicitation also provides valuable insights for future research.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Z1: Efficient Test-time Scaling with Code](https://arxiv.org/abs/2504.00810)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'In this report we describe the development of Command A, a powerful large language model purpose-built to excel at real-world enterprise use cases. Command A is an agent-optimised and multilingual-capable model, with support for 23 languages of global business, and a novel hybrid architecture balancing efficiency with top of the range performance. It offers best-in-class Retrieval Augmented Generation (RAG) capabilities with grounding and tool use to automate sophisticated business processes. These abilities are achieved through a decentralised training approach, including self-refinement algorithms and model merging techniques. We also include results for Command R7B which shares capability and architectural similarities to Command A. Weights for both models have been released for research purposes. This technical report details our original training pipeline and presents an extensive evaluation of our models across a suite of enterprise-relevant tasks and public benchmarks, demonstrating excellent performance and efficiency.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Command A: An Enterprise-Ready Large Language Model](https://arxiv.org/abs/2504.00698)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'The reproduction of state-of-the-art multimodal LLM pre-training faces barriers at every stage of the pipeline, including high-quality data filtering, multimodal data mixture strategies, sequence packing techniques, and training frameworks. We introduce Open-Qwen2VL, a fully open-source 2B-parameter Multimodal Large Language Model pre-trained efficiently on 29M image-text pairs using only 442 A100-40G GPU hours. Our approach employs low-to-high dynamic image resolution and multimodal sequence packing to significantly enhance pre-training efficiency. The training dataset was carefully curated using both MLLM-based filtering techniques (e.g., MLM-Filter) and conventional CLIP-based filtering methods, substantially improving data quality and training efficiency. The Open-Qwen2VL pre-training is conducted on academic level 8xA100-40G GPUs at UCSB on 5B packed multimodal tokens, which is 0.36\\% of 1.4T multimodal pre-training tokens of Qwen2-VL. The final instruction-tuned Open-Qwen2VL outperforms partially-open state-of-the-art MLLM Qwen2-VL-2B on various multimodal benchmarks of MMBench, SEEDBench, MMstar, and MathVista, indicating the remarkable training efficiency of Open-Qwen2VL. We open-source all aspects of our work, including compute-efficient and data-efficient training details, data filtering methods, sequence packing scripts, pre-training data in WebDataset format, FSDP-based training codebase, and both base and instruction-tuned model checkpoints. We redefine "fully open" for multimodal LLMs as the complete release of: 1) the training codebase, 2) detailed data filtering techniques, and 3) all pre-training and supervised fine-tuning data used to develop the model.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Open-Qwen2VL: Compute-Efficient Pre-Training of Fully-Open Multimodal LLMs on Academic Resources](https://arxiv.org/abs/2504.00595)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Visual token reduction lowers inference costs caused by extensive image features in large vision-language models (LVLMs). Unlike relevant studies that prune tokens in self-attention-only LVLMs, our work uniquely addresses cross-attention-based models, which achieve superior performance. We identify that the key-value (KV) cache size for image tokens in cross-attention layers significantly exceeds that of text tokens in self-attention layers, posing a major compute bottleneck. To mitigate this issue, we exploit the sparse nature in cross-attention maps to selectively prune redundant visual features. Our Trimmed Llama effectively reduces KV cache demands without requiring additional training. By benefiting from 50%-reduced visual features, our model can reduce inference latency and memory usage while achieving benchmark parity.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Efficient LLaMA-3.2-Vision by Trimming Cross-attended Visual Features](https://arxiv.org/abs/2504.00557)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "The rapid escalation from elementary school-level to frontier problems of the difficulty for LLM benchmarks in recent years have weaved a miracle for researchers that we are only inches away from surpassing human intelligence. However, is the LLMs' remarkable reasoning ability indeed comes from true intelligence by human standards, or are they simply reciting solutions witnessed during training at an Internet level? To study this problem, we propose RoR-Bench, a novel, multi-modal benchmark for detecting LLM's recitation behavior when asked simple reasoning problems but with conditions subtly shifted, and conduct empirical analysis on our benchmark. Surprisingly, we found existing cutting-edge LLMs unanimously exhibits extremely severe recitation behavior; by changing one phrase in the condition, top models such as OpenAI-o1 and DeepSeek-R1 can suffer 60% performance loss on elementary school-level arithmetic and reasoning problems. Such findings are a wake-up call to the LLM community that compels us to re-evaluate the true intelligence level of cutting-edge LLMs."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Recitation over Reasoning: How Cutting-Edge Language Models Can Fail on Elementary School-Level Reasoning Problems?](https://arxiv.org/abs/2504.00509)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Inference-time scaling can enhance the reasoning capabilities of large language models (LLMs) on complex problems that benefit from step-by-step problem solving. Although lengthening generated scratchpads has proven effective for mathematical tasks, the broader impact of this approach on other tasks remains less clear. In this work, we investigate the benefits and limitations of scaling methods across nine state-of-the-art models and eight challenging tasks, including math and STEM reasoning, calendar planning, NP-hard problems, navigation, and spatial reasoning. We compare conventional models (e.g., GPT-4o) with models fine-tuned for inference-time scaling (e.g., o1) through evaluation protocols that involve repeated model calls, either independently or sequentially with feedback. These evaluations approximate lower and upper performance bounds and potential for future performance improvements for each model, whether through enhanced training or multi-model inference systems. Our extensive empirical analysis reveals that the advantages of inference-time scaling vary across tasks and diminish as problem complexity increases. In addition, simply using more tokens does not necessarily translate to higher accuracy in these challenging regimes. Results from multiple independent runs with conventional models using perfect verifiers show that, for some tasks, these models can achieve performance close to the average performance of today's most advanced reasoning models. However, for other tasks, a significant performance gap remains, even in very high scaling regimes. Encouragingly, all models demonstrate significant gains when inference is further scaled with perfect verifiers or strong feedback, suggesting ample potential for future improvements."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Inference-Time Scaling for Complex Tasks: Where We Stand and What Lies Ahead](https://arxiv.org/abs/2504.00294)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "We address the task of video chaptering, i.e., partitioning a long video timeline into semantic units and generating corresponding chapter titles. While relatively underexplored, automatic chaptering has the potential to enable efficient navigation and content retrieval in long-form videos. In this paper, we achieve strong chaptering performance on hour-long videos by efficiently addressing the problem in the text domain with our 'Chapter-Llama' framework. Specifically, we leverage a pretrained large language model (LLM) with large context window, and feed as input (i) speech transcripts and (ii) captions describing video frames, along with their respective timestamps. Given the inefficiency of exhaustively captioning all frames, we propose a lightweight speech-guided frame selection strategy based on speech transcript content, and experimentally demonstrate remarkable advantages. We train the LLM to output timestamps for the chapter boundaries, as well as free-form chapter titles. This simple yet powerful approach scales to processing one-hour long videos in a single forward pass. Our results demonstrate substantial improvements (e.g., 45.3 vs 26.7 F1 score) over the state of the art on the recent VidChapters-7M benchmark. To promote further research, we release our code and models at our project page."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Chapter-Llama: Efficient Chaptering in Hour-Long Videos with LLMs](https://arxiv.org/abs/2504.00072)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Inductive program synthesis, or programming by example, requires synthesizing functions from input-output examples that generalize to unseen inputs. While large language model agents have shown promise in programming tasks guided by natural language, their ability to perform inductive program synthesis is underexplored. Existing evaluation protocols rely on static sets of examples and held-out tests, offering no feedback when synthesized functions are incorrect and failing to reflect real-world scenarios such as reverse engineering. We propose CodeARC, the Code Abstraction and Reasoning Challenge, a new evaluation framework where agents interact with a hidden target function by querying it with new inputs, synthesizing candidate functions, and iteratively refining their solutions using a differential testing oracle. This interactive setting encourages agents to perform function calls and self-correction based on feedback. We construct the first large-scale benchmark for general-purpose inductive program synthesis, featuring 1114 functions. Among 18 models evaluated, o3-mini performs best with a success rate of 52.7%, highlighting the difficulty of this task. Fine-tuning LLaMA-3.1-8B-Instruct on curated synthesis traces yields up to a 31% relative performance gain. CodeARC provides a more realistic and challenging testbed for evaluating LLM-based program synthesis and inductive reasoning.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [CodeARC: Benchmarking Reasoning Capabilities of LLM Agents for Inductive Program Synthesis](https://arxiv.org/abs/2503.23145)
append_entries: 10
Finish: 2025-04-02 09:00:58.701826
------------------------------------------------------
Started: 2025-04-02 12:13:54.447888
Existing_entries: 993
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Generating human motion guided by conditions such as textual descriptions is challenging due to the need for datasets with pairs of high-quality motion and their corresponding conditions. The difficulty increases when aiming for finer control in the generation. To that end, prior works have proposed to combine several motion diffusion models pre-trained on datasets with different types of conditions, thus allowing control with multiple conditions. However, the proposed merging strategies overlook that the optimal way to combine the generation processes might depend on the particularities of each pre-trained generative model and also the specific textual descriptions. In this context, we introduce MixerMDM, the first learnable model composition technique for combining pre-trained text-conditioned human motion diffusion models. Unlike previous approaches, MixerMDM provides a dynamic mixing strategy that is trained in an adversarial fashion to learn to combine the denoising process of each model depending on the set of conditions driving the generation. By using MixerMDM to combine single- and multi-person motion diffusion models, we achieve fine-grained control on the dynamics of every person individually, and also on the overall interaction. Furthermore, we propose a new evaluation technique that, for the first time in this task, measures the interaction and individual quality by computing the alignment between the mixed generated motions and their conditions as well as the capabilities of MixerMDM to adapt the mixing throughout the denoising process depending on the motions to mix.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [MixerMDM: Learnable Composition of Human Motion Diffusion Models](https://arxiv.org/abs/2504.01019)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Visual Self-Supervised Learning (SSL) currently underperforms Contrastive Language-Image Pretraining (CLIP) in multimodal settings such as Visual Question Answering (VQA). This multimodal gap is often attributed to the semantics introduced by language supervision, even though visual SSL and CLIP models are often trained on different data. In this work, we ask the question: "Do visual self-supervised approaches lag behind CLIP due to the lack of language supervision, or differences in the training data?" We study this question by training both visual SSL and CLIP models on the same MetaCLIP data, and leveraging VQA as a diverse testbed for vision encoders. In this controlled setup, visual SSL models scale better than CLIP models in terms of data and model capacity, and visual SSL performance does not saturate even after scaling up to 7B parameters. Consequently, we observe visual SSL methods achieve CLIP-level performance on a wide range of VQA and classic vision benchmarks. These findings demonstrate that pure visual SSL can match language-supervised visual pretraining at scale, opening new opportunities for vision-centric representation learning.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Scaling Language-Free Visual Representation Learning](https://arxiv.org/abs/2504.01017)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Reconstructing sharp 3D representations from blurry multi-view images are long-standing problem in computer vision. Recent works attempt to enhance high-quality novel view synthesis from the motion blur by leveraging event-based cameras, benefiting from high dynamic range and microsecond temporal resolution. However, they often reach sub-optimal visual quality in either restoring inaccurate color or losing fine-grained details. In this paper, we present DiET-GS, a diffusion prior and event stream-assisted motion deblurring 3DGS. Our framework effectively leverages both blur-free event streams and diffusion prior in a two-stage training strategy. Specifically, we introduce the novel framework to constraint 3DGS with event double integral, achieving both accurate color and well-defined details. Additionally, we propose a simple technique to leverage diffusion prior to further enhance the edge details. Qualitative and quantitative results on both synthetic and real-world data demonstrate that our DiET-GS is capable of producing significantly better quality of novel views compared to the existing baselines. Our project page is https://diet-gs.github.io'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [DiET-GS: Diffusion Prior and Event Stream-Assisted Motion Deblurring 3D Gaussian Splatting](https://arxiv.org/abs/2503.24210)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'The rise of Large Language Models (LLMs) as evaluators offers a scalable alternative to human annotation, yet existing Supervised Fine-Tuning (SFT) for judges approaches often fall short in domains requiring complex reasoning. In this work, we investigate whether LLM judges truly benefit from enhanced reasoning capabilities. Through a detailed analysis of reasoning requirements across evaluation tasks, we reveal a negative correlation between SFT performance gains and the proportion of reasoning-demanding samples - highlighting the limitations of SFT in such scenarios. To address this, we introduce JudgeLRM, a family of judgment-oriented LLMs trained using reinforcement learning (RL) with judge-wise, outcome-driven rewards. JudgeLRM models consistently outperform both SFT-tuned and state-of-the-art reasoning models. Notably, JudgeLRM-3B surpasses GPT-4, and JudgeLRM-7B outperforms DeepSeek-R1 by 2.79% in F1 score, particularly excelling in judge tasks requiring deep reasoning.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [JudgeLRM: Large Reasoning Models as a Judge](https://arxiv.org/abs/2504.00050)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'GUI agents, powered by large foundation models, can interact with digital interfaces, enabling various applications in web automation, mobile navigation, and software testing. However, their increasing autonomy has raised critical concerns about their security, privacy, and safety. This survey examines the trustworthiness of GUI agents in five critical dimensions: security vulnerabilities, reliability in dynamic environments, transparency and explainability, ethical considerations, and evaluation methodologies. We also identify major challenges such as vulnerability to adversarial attacks, cascading failure modes in sequential decision-making, and a lack of realistic evaluation benchmarks. These issues not only hinder real-world deployment but also call for comprehensive mitigation strategies beyond task success. As GUI agents become more widespread, establishing robust safety standards and responsible development practices is essential. This survey provides a foundation for advancing trustworthy GUI agents through systematic understanding and future research.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Towards Trustworthy GUI Agents: A Survey](https://arxiv.org/abs/2503.23434)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'The rapid advancement of multi-modal language models (MLLMs) like GPT-4o has propelled the development of Omni language models, designed to process and proactively respond to continuous streams of multi-modal data. Despite their potential, evaluating their real-world interactive capabilities in streaming video contexts remains a formidable challenge. In this work, we introduce OmniMMI, a comprehensive multi-modal interaction benchmark tailored for OmniLLMs in streaming video contexts. OmniMMI encompasses over 1,121 videos and 2,290 questions, addressing two critical yet underexplored challenges in existing video benchmarks: streaming video understanding and proactive reasoning, across six distinct subtasks. Moreover, we propose a novel framework, Multi-modal Multiplexing Modeling (M4), designed to enable an inference-efficient streaming model that can see, listen while generating.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [OmniMMI: A Comprehensive Multi-modal Interaction Benchmark in Streaming Video Contexts](https://arxiv.org/abs/2503.22952)
append_entries: 6
Finish: 2025-04-02 12:13:56.826388
------------------------------------------------------
Started: 2025-04-02 15:00:53.393556
Existing_entries: 999
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We propose a unified framework that integrates object detection (OD) and visual grounding (VG) for remote sensing (RS) imagery. To support conventional OD and establish an intuitive prior for VG task, we fine-tune an open-set object detector using referring expression data, framing it as a partially supervised OD task. In the first stage, we construct a graph representation of each image, comprising object queries, class embeddings, and proposal locations. Then, our task-aware architecture processes this graph to perform the VG task. The model consists of: (i) a multi-branch network that integrates spatial, visual, and categorical features to generate task-aware proposals, and (ii) an object reasoning network that assigns probabilities across proposals, followed by a soft selection mechanism for final referring object localization. Our model demonstrates superior performance on the OPT-RSVG and DIOR-RSVG datasets, achieving significant improvements over state-of-the-art methods while retaining classical OD capabilities. The code will be available in our repository: https://github.com/rd20karim/MB-ORES.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [MB-ORES: A Multi-Branch Object Reasoner for Visual Grounding in Remote Sensing](https://arxiv.org/abs/2503.24219)
append_entries: 1
Finish: 2025-04-02 15:00:54.235507
------------------------------------------------------
Started: 2025-04-02 18:10:54.723701
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Text-to-SQL is a challenging task involving multiple reasoning-intensive subtasks, including natural language understanding, database schema comprehension, and precise SQL query formulation. Existing approaches often rely on handcrafted reasoning paths with inductive biases that can limit their overall effectiveness. Motivated by the recent success of reasoning-enhanced models such as DeepSeek R1 and OpenAI o1, which effectively leverage reward-driven self-exploration to enhance reasoning capabilities and generalization, we propose a novel set of partial rewards tailored specifically for the Text-to-SQL task. Our reward set includes schema-linking, AI feedback, n-gram similarity, and syntax check, explicitly designed to address the reward sparsity issue prevalent in reinforcement learning (RL). Leveraging group relative policy optimization (GRPO), our approach explicitly encourages large language models (LLMs) to develop intrinsic reasoning skills necessary for accurate SQL query generation. With models of different sizes, we demonstrate that RL-only training with our proposed rewards consistently achieves higher accuracy and superior generalization compared to supervised fine-tuning (SFT). Remarkably, our RL-trained 14B-parameter model significantly outperforms larger proprietary models, e.g. o3-mini by 4% and Gemini-1.5-Pro-002 by 3% on the BIRD benchmark. These highlight the efficacy of our proposed RL-training framework with partial rewards for enhancing both accuracy and reasoning capabilities in Text-to-SQL tasks.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Reasoning-SQL: Reinforcement Learning with SQL Tailored Partial Rewards for Reasoning-Enhanced Text-to-SQL](https://arxiv.org/abs/2503.23157)
append_entries: 1
Finish: 2025-04-02 18:10:55.741298
------------------------------------------------------
Started: 2025-04-02 21:00:35.976505
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-02 21:00:36.205619
------------------------------------------------------
Started: 2025-04-03 00:36:58.969750
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Numerous applications of large language models (LLMs) rely on their ability to perform step-by-step reasoning. However, the reasoning behavior of LLMs remains poorly understood, posing challenges to research, development, and safety. To address this gap, we introduce landscape of thoughts-the first visualization tool for users to inspect the reasoning paths of chain-of-thought and its derivatives on any multi-choice dataset. Specifically, we represent the states in a reasoning path as feature vectors that quantify their distances to all answer choices. These features are then visualized in two-dimensional plots using t-SNE. Qualitative and quantitative analysis with the landscape of thoughts effectively distinguishes between strong and weak models, correct and incorrect answers, as well as different reasoning tasks. It also uncovers undesirable reasoning patterns, such as low consistency and high uncertainty. Additionally, users can adapt our tool to a model that predicts the property they observe. We showcase this advantage by adapting our tool to a lightweight verifier that evaluates the correctness of reasoning paths. The code is publicly available at: https://github.com/tmlr-group/landscape-of-thoughts.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Landscape of Thoughts: Visualizing the Reasoning Process of Large Language Models](https://arxiv.org/abs/2503.22165)
append_entries: 1
Finish: 2025-04-03 00:36:59.764438
------------------------------------------------------
Started: 2025-04-03 03:24:23.591891
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-03 03:24:23.860590
------------------------------------------------------
Started: 2025-04-03 06:11:21.345685
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "We introduce PaperBench, a benchmark evaluating the ability of AI agents to replicate state-of-the-art AI research. Agents must replicate 20 ICML 2024 Spotlight and Oral papers from scratch, including understanding paper contributions, developing a codebase, and successfully executing experiments. For objective evaluation, we develop rubrics that hierarchically decompose each replication task into smaller sub-tasks with clear grading criteria. In total, PaperBench contains 8,316 individually gradable tasks. Rubrics are co-developed with the author(s) of each ICML paper for accuracy and realism. To enable scalable evaluation, we also develop an LLM-based judge to automatically grade replication attempts against rubrics, and assess our judge's performance by creating a separate benchmark for judges. We evaluate several frontier models on PaperBench, finding that the best-performing tested agent, Claude 3.5 Sonnet (New) with open-source scaffolding, achieves an average replication score of 21.0\\%. Finally, we recruit top ML PhDs to attempt a subset of PaperBench, finding that models do not yet outperform the human baseline. We https://github.com/openai/preparedness{open-source our code} to facilitate future research in understanding the AI engineering capabilities of AI agents."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [PaperBench: Evaluating AI's Ability to Replicate AI Research](https://arxiv.org/abs/2504.01848)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'While recent image-based human animation methods achieve realistic body and facial motion synthesis, critical gaps remain in fine-grained holistic controllability, multi-scale adaptability, and long-term temporal coherence, which leads to their lower expressiveness and robustness. We propose a diffusion transformer (DiT) based framework, DreamActor-M1, with hybrid guidance to overcome these limitations. For motion guidance, our hybrid control signals that integrate implicit facial representations, 3D head spheres, and 3D body skeletons achieve robust control of facial expressions and body movements, while producing expressive and identity-preserving animations. For scale adaptation, to handle various body poses and image scales ranging from portraits to full-body views, we employ a progressive training strategy using data with varying resolutions and scales. For appearance guidance, we integrate motion patterns from sequential frames with complementary visual references, ensuring long-term temporal coherence for unseen regions during complex movements. Experiments demonstrate that our method outperforms the state-of-the-art works, delivering expressive results for portraits, upper-body, and full-body generation with robust long-term consistency. Project Page: https://grisoon.github.io/DreamActor-M1/.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [DreamActor-M1: Holistic, Expressive and Robust Human Image Animation with Hybrid Guidance](https://arxiv.org/abs/2504.01724)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Vision-Language Models (VLMs) extend the capabilities of Large Language Models (LLMs) by incorporating visual information, yet they remain vulnerable to jailbreak attacks, especially when processing noisy or corrupted images. Although existing VLMs adopt security measures during training to mitigate such attacks, vulnerabilities associated with noise-augmented visual inputs are overlooked. In this work, we identify that missing noise-augmented training causes critical security gaps: many VLMs are susceptible to even simple perturbations such as Gaussian noise. To address this challenge, we propose Robust-VLGuard, a multimodal safety dataset with aligned / misaligned image-text pairs, combined with noise-augmented fine-tuning that reduces attack success rates while preserving functionality of VLM. For stronger optimization-based visual perturbation attacks, we propose DiffPure-VLM, leveraging diffusion models to convert adversarial perturbations into Gaussian-like noise, which can be defended by VLMs with noise-augmented safety fine-tuning. Experimental results demonstrate that the distribution-shifting property of diffusion model aligns well with our fine-tuned VLMs, significantly mitigating adversarial perturbations across varying intensities. The dataset and code are available at https://github.com/JarvisUSTC/DiffPure-RobustVLM.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Safeguarding Vision-Language Models: Mitigating Vulnerabilities to Gaussian Noise in Perturbation-based Attacks](https://arxiv.org/abs/2504.01308)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We present Articulated Kinematics Distillation (AKD), a framework for generating high-fidelity character animations by merging the strengths of skeleton-based animation and modern generative models. AKD uses a skeleton-based representation for rigged 3D assets, drastically reducing the Degrees of Freedom (DoFs) by focusing on joint-level control, which allows for efficient, consistent motion synthesis. Through Score Distillation Sampling (SDS) with pre-trained video diffusion models, AKD distills complex, articulated motions while maintaining structural integrity, overcoming challenges faced by 4D neural deformation fields in preserving shape consistency. This approach is naturally compatible with physics-based simulation, ensuring physically plausible interactions. Experiments show that AKD achieves superior 3D consistency and motion quality compared with existing works on text-to-4D generation. Project page: https://research.nvidia.com/labs/dir/akd/'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Articulated Kinematics Distillation from Video Diffusion Models](https://arxiv.org/abs/2504.01204)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Recent advancements in image and video synthesis have opened up new promise in generative games. One particularly intriguing application is transforming characters from anime films into interactive, playable entities. This allows players to immerse themselves in the dynamic anime world as their favorite characters for life simulation through language instructions. Such games are defined as infinite game since they eliminate predetermined boundaries and fixed gameplay rules, where players can interact with the game world through open-ended language and experience ever-evolving storylines and environments. Recently, a pioneering approach for infinite anime life simulation employs large language models (LLMs) to translate multi-turn text dialogues into language instructions for image generation. However, it neglects historical visual context, leading to inconsistent gameplay. Furthermore, it only generates static images, failing to incorporate the dynamics necessary for an engaging gaming experience. In this work, we propose AnimeGamer, which is built upon Multimodal Large Language Models (MLLMs) to generate each game state, including dynamic animation shots that depict character movements and updates to character states, as illustrated in Figure 1. We introduce novel action-aware multimodal representations to represent animation shots, which can be decoded into high-quality video clips using a video diffusion model. By taking historical animation shot representations as context and predicting subsequent representations, AnimeGamer can generate games with contextual consistency and satisfactory dynamics. Extensive evaluations using both automated metrics and human evaluations demonstrate that AnimeGamer outperforms existing methods in various aspects of the gaming experience. Codes and checkpoints are available at https://github.com/TencentARC/AnimeGamer.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [AnimeGamer: Infinite Anime Life Simulation with Next Game State Prediction](https://arxiv.org/abs/2504.01014)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Masked Image Modeling (MIM) with Vector Quantization (VQ) has achieved great success in both self-supervised pre-training and image generation. However, most existing methods struggle to address the trade-off in shared latent space for generation quality vs. representation learning and efficiency. To push the limits of this paradigm, we propose MergeVQ, which incorporates token merging techniques into VQ-based generative models to bridge the gap between image generation and visual representation learning in a unified architecture. During pre-training, MergeVQ decouples top-k semantics from latent space with the token merge module after self-attention blocks in the encoder for subsequent Look-up Free Quantization (LFQ) and global alignment and recovers their fine-grained details through cross-attention in the decoder for reconstruction. As for the second-stage generation, we introduce MergeAR, which performs KV Cache compression for efficient raster-order prediction. Extensive experiments on ImageNet verify that MergeVQ as an AR generative model achieves competitive performance in both visual representation learning and image generation tasks while maintaining favorable token efficiency and inference speed. The code and model will be available at https://apexgen-x.github.io/MergeVQ.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [MergeVQ: A Unified Framework for Visual Generation and Representation with Disentangled Token Merging and Quantization](https://arxiv.org/abs/2504.00999)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Increasing attention has been placed on improving the reasoning capacities of multi-modal large language models (MLLMs). As the cornerstone for AI agents that function in the physical realm, video-based visual-spatial intelligence (VSI) emerges as one of the most pivotal reasoning capabilities of MLLMs. This work conducts a first, in-depth study on improving the visual-spatial reasoning of MLLMs via R1-Zero-like training. Technically, we first identify that the visual-spatial reasoning capacities of small- to medium-sized Qwen2-VL models cannot be activated via Chain of Thought (CoT) prompts. We then incorporate GRPO training for improved visual-spatial reasoning, using the carefully curated VSI-100k dataset, following DeepSeek-R1-Zero. During the investigation, we identify the necessity to keep the KL penalty (even with a small value) in GRPO. With just 120 GPU hours, our vsGRPO-2B model, fine-tuned from Qwen2-VL-2B, can outperform the base model by 12.1% and surpass GPT-4o. Moreover, our vsGRPO-7B model, fine-tuned from Qwen2-VL-7B, achieves performance comparable to that of the best open-source model LLaVA-NeXT-Video-72B. Additionally, we compare vsGRPO to supervised fine-tuning and direct preference optimization baselines and observe strong performance superiority. The code and dataset will be available soon.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Improved Visual-Spatial Reasoning via R1-Zero-Like Training](https://arxiv.org/abs/2504.00883)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Academic writing requires both coherent text generation and precise citation of relevant literature. Although recent Retrieval-Augmented Generation (RAG) systems have significantly improved factual accuracy in general-purpose text generation, their capacity to adequately support professional academic writing remains limited. In this work, we introduce ScholarCopilot, a unified framework designed to enhance existing large language models for generating professional academic articles with accurate and contextually relevant citations. ScholarCopilot dynamically determines when to retrieve scholarly references by generating a retrieval token [RET], and then utilizes its representation to look up relevant citations from a database. The retrieved references are fed into the model to augment the generation process. We jointly optimize both the generation and citation tasks within a single framework to increase efficiency. Trained on 500K papers from arXiv, our model achieves a top-1 retrieval accuracy of 40.1% on our evaluation dataset, outperforming baselines such as E5-Mistral-7B-Instruct (15.0%) and BM25 (9.8%). On a dataset of 1,000 academic writing samples, ScholarCopilot scores 16.2/25 in generation quality (measured across relevance, coherence, academic rigor, completeness, and innovation), surpassing models with 10x more parameters such as Qwen-2.5-72B-Instruct (15.8/25). Human studies also confirm ScholarCopilot's superior performance in citation recall, writing efficiency, and overall user experience, confirming the effectiveness of our approach."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [ScholarCopilot: Training Large Language Models for Academic Writing with Accurate Citations](https://arxiv.org/abs/2504.00824)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Vision network designs, including Convolutional Neural Networks and Vision Transformers, have significantly advanced the field of computer vision. Yet, their complex computations pose challenges for practical deployments, particularly in real-time applications. To tackle this issue, researchers have explored various lightweight and efficient network designs. However, existing lightweight models predominantly leverage self-attention mechanisms and convolutions for token mixing. This dependence brings limitations in effectiveness and efficiency in the perception and aggregation processes of lightweight networks, hindering the balance between performance and efficiency under limited computational budgets. In this paper, we draw inspiration from the dynamic heteroscale vision ability inherent in the efficient human vision system and propose a ``See Large, Focus Small'' strategy for lightweight vision network design. We introduce LS (Large-Small) convolution, which combines large-kernel perception and small-kernel aggregation. It can efficiently capture a wide range of perceptual information and achieve precise feature aggregation for dynamic and complex visual representations, thus enabling proficient processing of visual information. Based on LS convolution, we present LSNet, a new family of lightweight models. Extensive experiments demonstrate that LSNet achieves superior performance and efficiency over existing lightweight networks in various vision tasks. Codes and models are available at https://github.com/jameslahm/lsnet."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [LSNet: See Large, Focus Small](https://arxiv.org/abs/2503.23135)
append_entries: 9
Finish: 2025-04-03 06:11:25.743524
------------------------------------------------------
Started: 2025-04-03 09:00:49.032919
Existing_entries: 1009
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Recovering 3D scenes from sparse views is a challenging task due to its inherent ill-posed problem. Conventional methods have developed specialized solutions (e.g., geometry regularization or feed-forward deterministic model) to mitigate the issue. However, they still suffer from performance degradation by minimal overlap across input views with insufficient visual information. Fortunately, recent video generative models show promise in addressing this challenge as they are capable of generating video clips with plausible 3D structures. Powered by large pretrained video diffusion models, some pioneering research start to explore the potential of video generative prior and create 3D scenes from sparse views. Despite impressive improvements, they are limited by slow inference time and the lack of 3D constraint, leading to inefficiencies and reconstruction artifacts that do not align with real-world geometry structure. In this paper, we propose VideoScene to distill the video diffusion model to generate 3D scenes in one step, aiming to build an efficient and effective tool to bridge the gap from video to 3D. Specifically, we design a 3D-aware leap flow distillation strategy to leap over time-consuming redundant information and train a dynamic denoising policy network to adaptively determine the optimal leap timestep during inference. Extensive experiments demonstrate that our VideoScene achieves faster and superior 3D scene generation results than previous video diffusion models, highlighting its potential as an efficient tool for future video to 3D applications. Project Page: https://hanyang-21.github.io/VideoScene'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [VideoScene: Distilling Video Diffusion Model to Generate 3D Scenes in One Step](https://arxiv.org/abs/2504.01956)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We present ILLUME+ that leverages dual visual tokenization and a diffusion decoder to improve both deep semantic understanding and high-fidelity image generation. Existing unified models have struggled to simultaneously handle the three fundamental capabilities in a unified model: understanding, generation, and editing. Models like Chameleon and EMU3 utilize VQGAN for image discretization, due to the lack of deep semantic interaction, they lag behind specialist models like LLaVA in visual understanding tasks. To mitigate this, LaViT and ILLUME employ semantic encoders for tokenization, but they struggle with image editing due to poor texture preservation. Meanwhile, Janus series decouples the input and output image representation, limiting their abilities to seamlessly handle interleaved image-text understanding and generation. In contrast, ILLUME+ introduces a unified dual visual tokenizer, DualViTok, which preserves both fine-grained textures and text-aligned semantics while enabling a coarse-to-fine image representation strategy for multimodal understanding and generation. Additionally, we employ a diffusion model as the image detokenizer for enhanced generation quality and efficient super-resolution. ILLUME+ follows a continuous-input, discrete-output scheme within the unified MLLM and adopts a progressive training procedure that supports dynamic resolution across the vision tokenizer, MLLM, and diffusion decoder. This design allows for flexible and efficient context-aware image editing and generation across diverse tasks. ILLUME+ (3B) exhibits competitive performance against existing unified MLLMs and specialized models across multimodal understanding, generation, and editing benchmarks. With its strong performance, ILLUME+ provides a scalable and versatile foundation for future multimodal applications. Project Page: https://illume-unified-mllm.github.io/.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [ILLUME+: Illuminating Unified MLLM with Dual Visual Tokenization and Diffusion Refinement](https://arxiv.org/abs/2504.01934)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "DeepSeek-R1-Zero has shown that reinforcement learning (RL) at scale can directly enhance the reasoning capabilities of LLMs without supervised fine-tuning. In this work, we critically examine R1-Zero-like training by analyzing its two core components: base models and RL. We investigate a wide range of base models, including DeepSeek-V3-Base, to understand how pretraining characteristics influence RL performance. Our analysis reveals that DeepSeek-V3-Base already exhibit ''Aha moment'', while Qwen2.5 base models demonstrate strong reasoning capabilities even without prompt templates, suggesting potential pretraining biases. Additionally, we identify an optimization bias in Group Relative Policy Optimization (GRPO), which artificially increases response length (especially for incorrect outputs) during training. To address this, we introduce Dr. GRPO, an unbiased optimization method that improves token efficiency while maintaining reasoning performance. Leveraging these insights, we present a minimalist R1-Zero recipe that achieves 43.3% accuracy on AIME 2024 with a 7B base model, establishing a new state-of-the-art. Our code is available at https://github.com/sail-sg/understand-r1-zero."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Understanding R1-Zero-Like Training: A Critical Perspective](https://arxiv.org/abs/2503.20783)
append_entries: 3
Finish: 2025-04-03 09:00:50.823972
------------------------------------------------------
Started: 2025-04-03 12:13:53.426444
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Large language models demonstrate remarkable reasoning capabilities but often produce unreliable or incorrect responses. Existing verification methods are typically model-specific or domain-restricted, requiring significant computational resources and lacking scalability across diverse reasoning tasks. To address these limitations, we propose VerifiAgent, a unified verification agent that integrates two levels of verification: meta-verification, which assesses completeness and consistency in model responses, and tool-based adaptive verification, where VerifiAgent autonomously selects appropriate verification tools based on the reasoning type, including mathematical, logical, or commonsense reasoning. This adaptive approach ensures both efficiency and robustness across different verification scenarios. Experimental results show that VerifiAgent outperforms baseline verification methods (e.g., deductive verifier, backward verifier) among all reasoning tasks. Additionally, it can further enhance reasoning accuracy by leveraging feedback from verification results. VerifiAgent can also be effectively applied to inference scaling, achieving better results with fewer generated samples and costs compared to existing process reward models in the mathematical reasoning domain. Code is available at https://github.com/Jiuzhouh/VerifiAgent'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [VerifiAgent: a Unified Verification Agent in Language Model Reasoning](https://arxiv.org/abs/2504.00406)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Prior research on out-of-distribution detection (OoDD) has primarily focused on single-modality models. Recently, with the advent of large-scale pretrained vision-language models such as CLIP, OoDD methods utilizing such multi-modal representations through zero-shot and prompt learning strategies have emerged. However, these methods typically involve either freezing the pretrained weights or only partially tuning them, which can be suboptimal for downstream datasets. In this paper, we highlight that multi-modal fine-tuning (MMFT) can achieve notable OoDD performance. Despite some recent works demonstrating the impact of fine-tuning methods for OoDD, there remains significant potential for performance improvement. We investigate the limitation of na\\"ive fine-tuning methods, examining why they fail to fully leverage the pretrained knowledge. Our empirical analysis suggests that this issue could stem from the modality gap within in-distribution (ID) embeddings. To address this, we propose a training objective that enhances cross-modal alignment by regularizing the distances between image and text embeddings of ID data. This adjustment helps in better utilizing pretrained textual information by aligning similar semantics from different modalities (i.e., text and image) more closely in the hyperspherical representation space. We theoretically demonstrate that the proposed regularization corresponds to the maximum likelihood estimation of an energy-based model on a hypersphere. Utilizing ImageNet-1k OoD benchmark datasets, we show that our method, combined with post-hoc OoDD approaches leveraging pretrained knowledge (e.g., NegLabel), significantly outperforms existing methods, achieving state-of-the-art OoDD performance and leading ID accuracy.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Enhanced OoD Detection through Cross-Modal Alignment of Multi-Modal Representations](https://arxiv.org/abs/2503.18817)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'The generation of high-quality human images through text-to-image (T2I) methods is a significant yet challenging task. Distinct from general image generation, human image synthesis must satisfy stringent criteria related to human pose, anatomy, and alignment with textual prompts, making it particularly difficult to achieve realistic results. Recent advancements in T2I generation based on diffusion models have shown promise, yet challenges remain in meeting human-specific preferences. In this paper, we introduce a novel approach tailored specifically for human image generation utilizing Direct Preference Optimization (DPO). Specifically, we introduce an efficient method for constructing a specialized DPO dataset for training human image generation models without the need for costly human feedback. We also propose a modified loss function that enhances the DPO training process by minimizing artifacts and improving image fidelity. Our method demonstrates its versatility and effectiveness in generating human images, including personalized text-to-image generation. Through comprehensive evaluations, we show that our approach significantly advances the state of human image generation, achieving superior results in terms of natural anatomies, poses, and text-image alignment.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Boost Your Own Human Image Generation Model via Direct Preference Optimization with AI Feedback](https://arxiv.org/abs/2405.20216)
append_entries: 3
Finish: 2025-04-03 12:13:54.941772
------------------------------------------------------
Started: 2025-04-03 15:00:42.813619
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Vision-language models (VLMs) are prone to object hallucinations, where they erroneously indicate the presenceof certain objects in an image. Existing benchmarks quantify hallucinations using relatively small, labeled datasets. However, this approach is i) insufficient to assess hallucinations that arise in open-world settings, where VLMs are widely used, and ii) inadequate for detecting systematic errors in VLMs. We propose DASH (Detection and Assessment of Systematic Hallucinations), an automatic, large-scale pipeline designed to identify systematic hallucinations of VLMs on real-world images in an open-world setting. A key component is DASH-OPT for image-based retrieval, where we optimize over the ''natural image manifold'' to generate images that mislead the VLM. The output of DASH consists of clusters of real and semantically similar images for which the VLM hallucinates an object. We apply DASH to PaliGemma and two LLaVA-NeXT models across 380 object classes and, in total, find more than 19k clusters with 950k images. We study the transfer of the identified systematic hallucinations to other VLMs and show that fine-tuning PaliGemma with the model-specific images obtained with DASH mitigates object hallucinations. Code and data are available at https://YanNeu.github.io/DASH."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [DASH: Detection and Assessment of Systematic Hallucinations of VLMs](https://arxiv.org/abs/2503.23573)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Video diffusion models (VDMs) have advanced significantly in recent years, enabling the generation of highly realistic videos and drawing the attention of the community in their potential as world simulators. However, despite their capabilities, VDMs often fail to produce physically plausible videos due to an inherent lack of understanding of physics, resulting in incorrect dynamics and event sequences. To address this limitation, we propose a novel two-stage image-to-video generation framework that explicitly incorporates physics. In the first stage, we employ a Vision Language Model (VLM) as a coarse-grained motion planner, integrating chain-of-thought and physics-aware reasoning to predict a rough motion trajectories/changes that approximate real-world physical dynamics while ensuring the inter-frame consistency. In the second stage, we use the predicted motion trajectories/changes to guide the video generation of a VDM. As the predicted motion trajectories/changes are rough, noise is added during inference to provide freedom to the VDM in generating motion with more fine details. Extensive experimental results demonstrate that our framework can produce physically plausible motion, and comparative evaluations highlight the notable superiority of our approach over existing methods. More video results are available on our Project Page: https://madaoer.github.io/projects/physically_plausible_video_generation.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Towards Physically Plausible Video Generation via VLM Planning](https://arxiv.org/abs/2503.23368)
append_entries: 2
Finish: 2025-04-03 15:00:44.226454
------------------------------------------------------
Started: 2025-04-03 18:00:54.456640
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Large language models (LLMs) have the potential to transform medicine, but real-world clinical scenarios contain extraneous information that can hinder performance. The rise of assistive technologies like ambient dictation, which automatically generates draft notes from live patient encounters, has the potential to introduce additional noise making it crucial to assess the ability of LLM's to filter relevant data. To investigate this, we developed MedDistractQA, a benchmark using USMLE-style questions embedded with simulated real-world distractions. Our findings show that distracting statements (polysemous words with clinical meanings used in a non-clinical context or references to unrelated health conditions) can reduce LLM accuracy by up to 17.9%. Commonly proposed solutions to improve model performance such as retrieval-augmented generation (RAG) and medical fine-tuning did not change this effect and in some cases introduced their own confounders and further degraded performance. Our findings suggest that LLMs natively lack the logical mechanisms necessary to distinguish relevant from irrelevant clinical information, posing challenges for real-world applications. MedDistractQA and our results highlights the need for robust mitigation strategies to enhance LLM resilience to extraneous information."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Medical large language models are easily distracted](https://arxiv.org/abs/2504.01201)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'While recent zero-shot text-to-speech (TTS) models have significantly improved speech quality and expressiveness, mainstream systems still suffer from issues related to speech-text alignment modeling: 1) models without explicit speech-text alignment modeling exhibit less robustness, especially for hard sentences in practical applications; 2) predefined alignment-based models suffer from naturalness constraints of forced alignments. This paper introduces MegaTTS 3, a TTS system featuring an innovative sparse alignment algorithm that guides the latent diffusion transformer (DiT). Specifically, we provide sparse alignment boundaries to MegaTTS 3 to reduce the difficulty of alignment without limiting the search space, thereby achieving high naturalness. Moreover, we employ a multi-condition classifier-free guidance strategy for accent intensity adjustment and adopt the piecewise rectified flow technique to accelerate the generation process. Experiments demonstrate that MegaTTS 3 achieves state-of-the-art zero-shot TTS speech quality and supports highly flexible control over accent intensity. Notably, our system can generate high-quality one-minute speech with only 8 sampling steps. Audio samples are available at https://sditdemo.github.io/sditdemo/.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [MegaTTS 3: Sparse Alignment Enhanced Latent Diffusion Transformer for Zero-Shot Speech Synthesis](https://arxiv.org/abs/2502.18924)
append_entries: 2
Finish: 2025-04-03 18:00:55.782784
------------------------------------------------------
Started: 2025-04-03 21:00:55.818798
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "We present a target-aware video diffusion model that generates videos from an input image in which an actor interacts with a specified target while performing a desired action. The target is defined by a segmentation mask and the desired action is described via a text prompt. Unlike existing controllable image-to-video diffusion models that often rely on dense structural or motion cues to guide the actor's movements toward the target, our target-aware model requires only a simple mask to indicate the target, leveraging the generalization capabilities of pretrained models to produce plausible actions. This makes our method particularly effective for human-object interaction (HOI) scenarios, where providing precise action guidance is challenging, and further enables the use of video diffusion models for high-level action planning in applications such as robotics. We build our target-aware model by extending a baseline model to incorporate the target mask as an additional input. To enforce target awareness, we introduce a special token that encodes the target's spatial information within the text prompt. We then fine-tune the model with our curated dataset using a novel cross-attention loss that aligns the cross-attention maps associated with this token with the input target mask. To further improve performance, we selectively apply this loss to the most semantically relevant transformer blocks and attention regions. Experimental results show that our target-aware model outperforms existing solutions in generating videos where actors interact accurately with the specified targets. We further demonstrate its efficacy in two downstream applications: video content creation and zero-shot 3D HOI motion synthesis."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Target-Aware Video Diffusion Models](https://arxiv.org/abs/2503.18950)
append_entries: 1
Finish: 2025-04-03 21:00:56.576683
------------------------------------------------------
Started: 2025-04-04 00:37:03.309058
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'State Space Models (SSMs) are emerging as a compelling alternative to Transformers because of their consistent memory usage and high performance. Despite this, scaling up SSMs on cloud services or limited-resource devices is challenging due to their storage requirements and computational power. To overcome this, quantizing SSMs with low bit-width data formats can reduce model size and benefit from hardware acceleration. As SSMs are prone to quantization-induced errors, recent efforts have focused on optimizing a particular model or bit-width for efficiency without sacrificing performance. However, distinct bit-width configurations are essential for different scenarios, like W4A8 for boosting large-batch decoding speed, and W4A16 for enhancing generation speed in short prompt applications for a single user. To this end, we present Quamba2, compatible with W8A8, W4A8, and W4A16 for both Mamba1 and Mamba2 backbones, addressing the growing demand for SSM deployment on various platforms. Based on the channel order preserving and activation persistence of SSMs, we propose an offline approach to quantize inputs of a linear recurrence in 8-bit by sorting and clustering for input x, combined with a per-state-group quantization for input-dependent parameters B and C. To ensure compute-invariance in the SSM output, we rearrange weights offline according to the clustering sequence. The experiments show that Quamba2-8B outperforms several state-of-the-art SSM quantization methods and delivers 1.3times and 3times speed-ups in the pre-filling and generation stages, respectively, while offering 4times memory reduction with only a 1.6% average accuracy drop. The evaluation on MMLU shows the generalizability and robustness of our framework. The code and quantized models will be released at: https://github.com/enyac-group/Quamba.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Quamba2: A Robust and Scalable Post-training Quantization Framework for Selective State Space Models](https://arxiv.org/abs/2503.22879)
append_entries: 1
Finish: 2025-04-04 00:37:03.974087
------------------------------------------------------
Started: 2025-04-04 03:23:44.328153
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Various layer-skipping methods have been proposed to accelerate token generation in large language models (LLMs). However, they have overlooked a fundamental question: How do computational demands vary across the generation of different tokens? In this work, we introduce FlexiDepth, a method that dynamically adjusts the number of Transformer layers used in text generation. By incorporating a plug-in router and adapter, FlexiDepth enables adaptive layer-skipping in LLMs without modifying their original parameters. Introducing FlexiDepth to Llama-3-8B model achieves layer skipping of 8 layers out of 32, and meanwhile maintains the full 100\\% benchmark performance. Experimental results with FlexiDepth demonstrate that computational demands in LLMs significantly vary based on token type. Specifically, generating repetitive tokens or fixed phrases requires fewer layers, whereas producing tokens involving computation or high uncertainty requires more layers. Interestingly, this adaptive allocation pattern aligns with human intuition. To advance research in this area, we open sourced FlexiDepth and a dataset documenting FlexiDepth's layer allocation patterns for future exploration."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Adaptive Layer-skipping in Pre-trained LLMs](https://arxiv.org/abs/2503.23798)
append_entries: 1
Finish: 2025-04-04 03:23:45.015570
------------------------------------------------------
Started: 2025-04-04 06:11:15.446038
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Large Multi-modality Models (LMMs) have made significant progress in visual understanding and generation, but they still face challenges in General Visual Editing, particularly in following complex instructions, preserving appearance consistency, and supporting flexible input formats. To address this gap, we introduce RISEBench, the first benchmark for evaluating Reasoning-Informed viSual Editing (RISE). RISEBench focuses on four key reasoning types: Temporal, Causal, Spatial, and Logical Reasoning. We curate high-quality test cases for each category and propose an evaluation framework that assesses Instruction Reasoning, Appearance Consistency, and Visual Plausibility with both human judges and an LMM-as-a-judge approach. Our experiments reveal that while GPT-4o-Native significantly outperforms other open-source and proprietary models, even this state-of-the-art system struggles with logical reasoning tasks, highlighting an area that remains underexplored. As an initial effort, RISEBench aims to provide foundational insights into reasoning-aware visual editing and to catalyze future research. Though still in its early stages, we are committed to continuously expanding and refining the benchmark to support more comprehensive, reliable, and scalable evaluations of next-generation multimodal systems. Our code and data will be released at https://github.com/PhoenixZ810/RISEBench.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Envisioning Beyond the Pixels: Benchmarking Reasoning-Informed Visual Editing](https://arxiv.org/abs/2504.02826)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "The recent breakthroughs in OpenAI's GPT4o model have demonstrated surprisingly good capabilities in image generation and editing, resulting in significant excitement in the community. This technical report presents the first-look evaluation benchmark (named GPT-ImgEval), quantitatively and qualitatively diagnosing GPT-4o's performance across three critical dimensions: (1) generation quality, (2) editing proficiency, and (3) world knowledge-informed semantic synthesis. Across all three tasks, GPT-4o demonstrates strong performance, significantly surpassing existing methods in both image generation control and output quality, while also showcasing exceptional knowledge reasoning capabilities. Furthermore, based on the GPT-4o's generated data, we propose a classification-model-based approach to investigate the underlying architecture of GPT-4o, where our empirical results suggest the model consists of an auto-regressive (AR) combined with a diffusion-based head for image decoding, rather than the VAR-like architectures. We also provide a complete speculation on GPT-4o's overall architecture. In addition, we conduct a series of analyses to identify and visualize GPT-4o's specific limitations and the synthetic artifacts commonly observed in its image generation. We also present a comparative study of multi-round image editing between GPT-4o and Gemini 2.0 Flash, and discuss the safety implications of GPT-4o's outputs, particularly their detectability by existing image forensic models. We hope that our work can offer valuable insight and provide a reliable benchmark to guide future research, foster reproducibility, and accelerate innovation in the field of image generation and beyond. The codes and datasets used for evaluating GPT-4o can be found at https://github.com/PicoTrex/GPT-ImgEval."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [GPT-ImgEval: A Comprehensive Benchmark for Diagnosing GPT4o in Image Generation](https://arxiv.org/abs/2504.02782)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Reinforcement learning (RL) has recently shown strong potential in improving the reasoning capabilities of large language models and is now being actively extended to vision-language models (VLMs). However, existing RL applications in VLMs often rely on heavily engineered frameworks that hinder reproducibility and accessibility, while lacking standardized evaluation protocols, making it difficult to compare results or interpret training dynamics. This work introduces a transparent, from-scratch framework for RL in VLMs, offering a minimal yet functional four-step pipeline validated across multiple models and datasets. In addition, a standardized evaluation scheme is proposed to assess training dynamics and reflective behaviors. Extensive experiments on visual reasoning tasks uncover key empirical findings: response length is sensitive to random seeds, reflection correlates with output length, and RL consistently outperforms supervised fine-tuning (SFT) in generalization, even with high-quality data. These findings, together with the proposed framework, aim to establish a reproducible baseline and support broader engagement in RL-based VLM research.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Rethinking RL Scaling for Vision Language Models: A Transparent, From-Scratch Framework and Comprehensive Evaluation Scheme](https://arxiv.org/abs/2504.02587)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Talking head synthesis is vital for virtual avatars and human-computer interaction. However, most existing methods are typically limited to accepting control from a single primary modality, restricting their practical utility. To this end, we introduce ACTalker, an end-to-end video diffusion framework that supports both multi-signals control and single-signal control for talking head video generation. For multiple control, we design a parallel mamba structure with multiple branches, each utilizing a separate driving signal to control specific facial regions. A gate mechanism is applied across all branches, providing flexible control over video generation. To ensure natural coordination of the controlled video both temporally and spatially, we employ the mamba structure, which enables driving signals to manipulate feature tokens across both dimensions in each branch. Additionally, we introduce a mask-drop strategy that allows each driving signal to independently control its corresponding facial region within the mamba structure, preventing control conflicts. Experimental results demonstrate that our method produces natural-looking facial videos driven by diverse signals and that the mamba layer seamlessly integrates multiple driving modalities without conflict.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Audio-visual Controlled Video Diffusion with Masked Selective State Spaces Modeling for Natural Talking Head Generation](https://arxiv.org/abs/2504.02542)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'This paper presents SkyReels-A2, a controllable video generation framework capable of assembling arbitrary visual elements (e.g., characters, objects, backgrounds) into synthesized videos based on textual prompts while maintaining strict consistency with reference images for each element. We term this task elements-to-video (E2V), whose primary challenges lie in preserving the fidelity of each reference element, ensuring coherent composition of the scene, and achieving natural outputs. To address these, we first design a comprehensive data pipeline to construct prompt-reference-video triplets for model training. Next, we propose a novel image-text joint embedding model to inject multi-element representations into the generative process, balancing element-specific consistency with global coherence and text alignment. We also optimize the inference pipeline for both speed and output stability. Moreover, we introduce a carefully curated benchmark for systematic evaluation, i.e, A2 Bench. Experiments demonstrate that our framework can generate diverse, high-quality videos with precise element control. SkyReels-A2 is the first open-source commercial grade model for the generation of E2V, performing favorably against advanced closed-source commercial models. We anticipate SkyReels-A2 will advance creative applications such as drama and virtual e-commerce, pushing the boundaries of controllable video generation.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [SkyReels-A2: Compose Anything in Video Diffusion Transformers](https://arxiv.org/abs/2504.02436)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Model selection is a critical step in time series forecasting, traditionally requiring extensive performance evaluations across various datasets. Meta-learning approaches aim to automate this process, but they typically depend on pre-constructed performance matrices, which are costly to build. In this work, we propose to leverage Large Language Models (LLMs) as a lightweight alternative for model selection. Our method eliminates the need for explicit performance matrices by utilizing the inherent knowledge and reasoning capabilities of LLMs. Through extensive experiments with LLaMA, GPT and Gemini, we demonstrate that our approach outperforms traditional meta-learning techniques and heuristic baselines, while significantly reducing computational overhead. These findings underscore the potential of LLMs in efficient model selection for time series forecasting.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Efficient Model Selection for Time Series Forecasting via LLMs](https://arxiv.org/abs/2504.02119)
append_entries: 6
Finish: 2025-04-04 06:11:18.943614
------------------------------------------------------
Started: 2025-04-04 09:00:48.643065
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Training large language models (LLMs) presents numerous challenges, including gradient instability and loss spikes. These phenomena can lead to catastrophic divergence, requiring costly checkpoint restoration and data batch skipping. Traditional gradient clipping techniques, such as constant or norm-based methods, fail to address these issues effectively due to their reliance on fixed thresholds or heuristics, leading to inefficient learning and requiring frequent manual intervention. In this work, we propose ZClip, an adaptive gradient clipping algorithm that dynamically adjusts the clipping threshold based on statistical properties of gradient norms over time. Unlike prior reactive strategies, ZClip proactively adapts to training dynamics without making any prior assumptions on the scale and the temporal evolution of gradient norms. At its core, it leverages z-score-based anomaly detection to identify and mitigate large gradient spikes, preventing malignant loss spikes while not interfering with convergence otherwise. Our code is available at: https://github.com/bluorion-com/ZClip.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [ZClip: Adaptive Spike Mitigation for LLM Pre-Training](https://arxiv.org/abs/2504.02507)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Existing Speech Language Model (SLM) scaling analysis paints a bleak picture. They predict that SLMs require much more compute and data compared to text, leading some to question the feasibility of training high-quality SLMs. However, modern SLMs are often initialised from pre-trained TextLMs using speech-text interleaving to allow knowledge transfer. This raises the question - Do interleaved SLMs scale more efficiently than textless-SLMs? In this paper we answer a resounding, yes! We conduct scaling analysis of interleaved SLMs by training several dozen and analysing the scaling trends. We see that under this setup SLMs scale more efficiently with compute. Additionally, our results indicate that the scaling-dynamics are significantly different than textless-SLMs, suggesting one should allocate notably more of the compute budget for increasing model size over training tokens. We also study the role of synthetic data and TextLM model families in unlocking this potential. Results suggest, that our scaled up model achieves comparable performance with leading models on speech semantic metrics while using less compute and data than other approaches. We open source models, samples, and data - https://pages.cs.huji.ac.il/adiyoss-lab/sims.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Scaling Analysis of Interleaved Speech-Text Language Models](https://arxiv.org/abs/2504.02398)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Learning to generate neural network parameters conditioned on task descriptions and architecture specifications is pivotal for advancing model adaptability and transfer learning. Existing methods especially those based on diffusion models suffer from limited scalability to large architectures, rigidity in handling varying network depths, and disjointed parameter generation that undermines inter-layer coherence. In this work, we propose IGPG (Instruction Guided Parameter Generation), an autoregressive framework that unifies parameter synthesis across diverse tasks and architectures. IGPG leverages a VQ-VAE and an autoregressive model to generate neural network parameters, conditioned on task instructions, dataset, and architecture details. By autoregressively generating neural network weights' tokens, IGPG ensures inter-layer coherence and enables efficient adaptation across models and datasets. Operating at the token level, IGPG effectively captures complex parameter distributions aggregated from a broad spectrum of pretrained models. Extensive experiments on multiple vision datasets demonstrate that IGPG consolidates diverse pretrained models into a single, flexible generative framework. The synthesized parameters achieve competitive or superior performance relative to state-of-the-art methods, especially in terms of scalability and efficiency when applied to large architectures. These results underscore ICPG potential as a powerful tool for pretrained weight retrieval, model selection, and rapid task-specific fine-tuning."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Instruction-Guided Autoregressive Neural Network Parameter Generation](https://arxiv.org/abs/2504.02012)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Recent advancements in Large Language Models (LLMs) have shown that it is promising to utilize Process Reward Models (PRMs) as verifiers to enhance the performance of LLMs. However, current PRMs face three key challenges: (1) limited process supervision and generalization capabilities, (2) dependence on scalar value prediction without leveraging the generative abilities of LLMs, and (3) inability to scale the test-time compute of PRMs. In this work, we introduce GenPRM, a generative process reward model that performs explicit Chain-of-Thought (CoT) reasoning with code verification before providing judgment for each reasoning step. To obtain high-quality process supervision labels and rationale data, we propose Relative Progress Estimation (RPE) and a rationale synthesis framework that incorporates code verification. Experimental results on ProcessBench and several mathematical reasoning tasks show that GenPRM significantly outperforms prior PRMs with only 23K training data from MATH dataset. Through test-time scaling, a 1.5B GenPRM outperforms GPT-4o, and a 7B GenPRM surpasses Qwen2.5-Math-PRM-72B on ProcessBench. Additionally, GenPRM demonstrates strong abilities to serve as a critic model for policy model refinement. This work establishes a new paradigm for process supervision that bridges the gap between PRMs and critic models in LLMs. Our code, model, and data will be available in https://ryanliu112.github.io/GenPRM.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [GenPRM: Scaling Test-Time Compute of Process Reward Models via Generative Reasoning](https://arxiv.org/abs/2504.00891)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Multimodal Large Language Models (MLLMs) suffer from high computational costs due to their massive size and the large number of visual tokens. In this paper, we investigate layer-wise redundancy in MLLMs by introducing a novel metric, Layer Contribution (LC), which quantifies the impact of a layer's transformations on visual and text tokens, respectively. The calculation of LC involves measuring the divergence in model output that results from removing the layer's transformations on the specified tokens. Our pilot experiment reveals that many layers of MLLMs exhibit minimal contribution during the processing of visual tokens. Motivated by this observation, we propose ShortV, a training-free method that leverages LC to identify ineffective layers, and freezes visual token updates in these layers. Experiments show that ShortV can freeze visual token in approximately 60\\% of the MLLM layers, thereby dramatically reducing computational costs related to updating visual tokens. For example, it achieves a 50\\% reduction in FLOPs on LLaVA-NeXT-13B while maintaining superior performance. The code will be publicly available at https://github.com/icip-cas/ShortV"}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [ShortV: Efficient Multimodal Large Language Models by Freezing Visual Tokens in Ineffective Layers](https://arxiv.org/abs/2504.00502)
append_entries: 5
Finish: 2025-04-04 09:00:50.801963
------------------------------------------------------
Started: 2025-04-04 12:13:38.827335
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Sparse Autoencoders (SAEs) have recently been shown to enhance interpretability and steerability in Large Language Models (LLMs). In this work, we extend the application of SAEs to Vision-Language Models (VLMs), such as CLIP, and introduce a comprehensive framework for evaluating monosemanticity in vision representations. Our experimental results reveal that SAEs trained on VLMs significantly enhance the monosemanticity of individual neurons while also exhibiting hierarchical representations that align well with expert-defined structures (e.g., iNaturalist taxonomy). Most notably, we demonstrate that applying SAEs to intervene on a CLIP vision encoder, directly steer output from multimodal LLMs (e.g., LLaVA) without any modifications to the underlying model. These findings emphasize the practicality and efficacy of SAEs as an unsupervised approach for enhancing both the interpretability and control of VLMs.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Sparse Autoencoders Learn Monosemantic Features in Vision-Language Models](https://arxiv.org/abs/2504.02821)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "We present the first mechanistic evidence that model-free reinforcement learning agents can learn to plan. This is achieved by applying a methodology based on concept-based interpretability to a model-free agent in Sokoban -- a commonly used benchmark for studying planning. Specifically, we demonstrate that DRC, a generic model-free agent introduced by Guez et al. (2019), uses learned concept representations to internally formulate plans that both predict the long-term effects of actions on the environment and influence action selection. Our methodology involves: (1) probing for planning-relevant concepts, (2) investigating plan formation within the agent's representations, and (3) verifying that discovered plans (in the agent's representations) have a causal effect on the agent's behavior through interventions. We also show that the emergence of these plans coincides with the emergence of a planning-like property: the ability to benefit from additional test-time compute. Finally, we perform a qualitative analysis of the planning algorithm learned by the agent and discover a strong resemblance to parallelized bidirectional search. Our findings advance understanding of the internal mechanisms underlying planning behavior in agents, which is important given the recent trend of emergent planning and reasoning capabilities in LLMs through RL"}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Interpreting Emergent Planning in Model-Free Reinforcement Learning](https://arxiv.org/abs/2504.01871)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'The advent of large language models (LLMs) has catalyzed a transformative shift in artificial intelligence, paving the way for advanced intelligent agents capable of sophisticated reasoning, robust perception, and versatile action across diverse domains. As these agents increasingly drive AI research and practical applications, their design, evaluation, and continuous improvement present intricate, multifaceted challenges. This survey provides a comprehensive overview, framing intelligent agents within a modular, brain-inspired architecture that integrates principles from cognitive science, neuroscience, and computational research. We structure our exploration into four interconnected parts. First, we delve into the modular foundation of intelligent agents, systematically mapping their cognitive, perceptual, and operational modules onto analogous human brain functionalities, and elucidating core components such as memory, world modeling, reward processing, and emotion-like systems. Second, we discuss self-enhancement and adaptive evolution mechanisms, exploring how agents autonomously refine their capabilities, adapt to dynamic environments, and achieve continual learning through automated optimization paradigms, including emerging AutoML and LLM-driven optimization strategies. Third, we examine collaborative and evolutionary multi-agent systems, investigating the collective intelligence emerging from agent interactions, cooperation, and societal structures, highlighting parallels to human social dynamics. Finally, we address the critical imperative of building safe, secure, and beneficial AI systems, emphasizing intrinsic and extrinsic security threats, ethical alignment, robustness, and practical mitigation strategies necessary for trustworthy real-world deployment.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Advances and Challenges in Foundation Agents: From Brain-Inspired Intelligence to Evolutionary, Collaborative, and Safe Systems](https://arxiv.org/abs/2504.01990)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Scientific discovery is poised for rapid advancement through advanced robotics and artificial intelligence. Current scientific practices face substantial limitations as manual experimentation remains time-consuming and resource-intensive, while multidisciplinary research demands knowledge integration beyond individual researchers' expertise boundaries. Here, we envision an autonomous generalist scientist (AGS) concept combines agentic AI and embodied robotics to automate the entire research lifecycle. This system could dynamically interact with both physical and virtual environments while facilitating the integration of knowledge across diverse scientific disciplines. By deploying these technologies throughout every research stage -- spanning literature review, hypothesis generation, experimentation, and manuscript writing -- and incorporating internal reflection alongside external feedback, this system aims to significantly reduce the time and resources needed for scientific discovery. Building on the evolution from virtual AI scientists to versatile generalist AI-based robot scientists, AGS promises groundbreaking potential. As these autonomous systems become increasingly integrated into the research process, we hypothesize that scientific discovery might adhere to new scaling laws, potentially shaped by the number and capabilities of these autonomous systems, offering novel perspectives on how knowledge is generated and evolves. The adaptability of embodied robots to extreme environments, paired with the flywheel effect of accumulating scientific knowledge, holds the promise of continually pushing beyond both physical and intellectual frontiers."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Scaling Laws in Scientific Discovery with AI and Robot Scientists](https://arxiv.org/abs/2503.22444)
append_entries: 4
Finish: 2025-04-04 12:13:40.625560
------------------------------------------------------
Started: 2025-04-04 15:00:39.049265
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Reinforcement learning (RL) has been widely adopted in post-training for large language models (LLMs) at scale. Recently, the incentivization of reasoning capabilities in LLMs from RL indicates that proper learning methods could enable effective inference-time scalability. A key challenge of RL is to obtain accurate reward signals for LLMs in various domains beyond verifiable questions or artificial rules. In this work, we investigate how to improve reward modeling (RM) with more inference compute for general queries, i.e. the inference-time scalability of generalist RM, and further, how to improve the effectiveness of performance-compute scaling with proper learning methods. For the RM approach, we adopt pointwise generative reward modeling (GRM) to enable flexibility for different input types and potential for inference-time scaling. For the learning method, we propose Self-Principled Critique Tuning (SPCT) to foster scalable reward generation behaviors in GRMs through online RL, to generate principles adaptively and critiques accurately, resulting in DeepSeek-GRM models. Furthermore, for effective inference-time scaling, we use parallel sampling to expand compute usage, and introduce a meta RM to guide voting process for better scaling performance. Empirically, we show that SPCT significantly improves the quality and scalability of GRMs, outperforming existing methods and models in various RM benchmarks without severe biases, and could achieve better performance compared to training-time scaling. DeepSeek-GRM still meets challenges in some tasks, which we believe can be addressed by future efforts in generalist reward systems. The models will be released and open-sourced.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Inference-Time Scaling for Generalist Reward Modeling](https://arxiv.org/abs/2504.02495)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Automatic speech recognition systems have undoubtedly advanced with the integration of multilingual and multitask models such as Whisper, which have shown a promising ability to understand and process speech across a wide range of languages. Despite their robustness, these models often fall short in handling the linguistic distinctions of minority languages. This study addresses this gap by integrating traditional and novel language models with fine-tuned Whisper models to raise their performance in less commonly studied languages. Through rigorous fine-tuning and evaluation across multiple datasets, we demonstrate substantial improvements in word error rate, particularly in low-resource scenarios. Our approach not only does take advantage of the extensive data Whisper was pre-trained on, but also complements its linguistic adaptability by incorporating language models. We obtained improvements up to 51\\% for in-distribution datasets and up to 34\\% for out-of-distribution sentences using statistical language models, while large language models provided moderate but consistently robust improvement across diverse linguistic contexts. The findings reveal that, while the integration reliably benefits all model sizes, the extent of improvement varies, highlighting the importance of optimized language model parameters. Finally, we emphasize the importance of selecting appropriate evaluation parameters when reporting the results using transformer-based ASR models. In summary, this research clears the way for more inclusive ASR technologies that perform better across languages by enriching their linguistic knowledge. For further implementation details of this study, the technical documentation and source code are available at http://www.github.com/hitz-zentroa/whisper-lm.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Whisper-LM: Improving ASR Models with Language Models for Low-Resource Languages](https://arxiv.org/abs/2503.23542)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': '3D Gaussian Splatting (3DGS) demonstrates superior quality and rendering speed, but with millions of 3D Gaussians and significant storage and transmission costs. Recent 3DGS compression methods mainly concentrate on compressing Scaffold-GS, achieving impressive performance but with an additional voxel structure and a complex encoding and quantization strategy. In this paper, we aim to develop a simple yet effective method called NeuralGS that explores in another way to compress the original 3DGS into a compact representation without the voxel structure and complex quantization strategies. Our observation is that neural fields like NeRF can represent complex 3D scenes with Multi-Layer Perceptron (MLP) neural networks using only a few megabytes. Thus, NeuralGS effectively adopts the neural field representation to encode the attributes of 3D Gaussians with MLPs, only requiring a small storage size even for a large-scale scene. To achieve this, we adopt a clustering strategy and fit the Gaussians with different tiny MLPs for each cluster, based on importance scores of Gaussians as fitting weights. We experiment on multiple datasets, achieving a 45-times average model size reduction without harming the visual quality. The compression performance of our method on original 3DGS is comparable to the dedicated Scaffold-GS-based compression methods, which demonstrate the huge potential of directly compressing original 3DGS with neural fields.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [NeuralGS: Bridging Neural Fields and 3D Gaussian Splatting for Compact 3D Representations](https://arxiv.org/abs/2503.23162)
append_entries: 3
Finish: 2025-04-04 15:00:40.492653
------------------------------------------------------
Started: 2025-04-04 18:10:13.853128
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Diffusion models offer impressive controllability for image tasks, primarily through noise predictions that encode task-specific information and classifier-free guidance enabling adjustable scaling. This scaling mechanism implicitly defines a ``scaling space'' whose potential for fine-grained semantic manipulation remains underexplored. We investigate this space, starting with inversion-based editing where the difference between conditional/unconditional noise predictions carries key semantic information. Our core contribution stems from a Fourier analysis of noise predictions, revealing that its low- and high-frequency components evolve differently throughout diffusion. Based on this insight, we introduce FreSca, a straightforward method that applies guidance scaling independently to different frequency bands in the Fourier domain. FreSca demonstrably enhances existing image editing methods without retraining. Excitingly, its effectiveness extends to image understanding tasks such as depth estimation, yielding quantitative gains across multiple datasets."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [FreSca: Unveiling the Scaling Space in Diffusion Models](https://arxiv.org/abs/2504.02154)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "We present the challenging task of automatically creating a high-level Wikipedia-style article that aggregates information from multiple diverse videos about real-world events, such as natural disasters or political elections. Videos are intuitive sources for retrieval-augmented generation (RAG), but most contemporary RAG workflows focus heavily on text and existing methods for video-based summarization focus on low-level scene understanding rather than high-level event semantics. To close this gap, we introduce WikiVideo, a benchmark consisting of expert-written articles and densely annotated videos that provide evidence for articles' claims, facilitating the integration of video into RAG pipelines and enabling the creation of in-depth content that is grounded in multimodal sources. We further propose Collaborative Article Generation (CAG), a novel interactive method for article creation from multiple videos. CAG leverages an iterative interaction between an r1-style reasoning model and a VideoLLM to draw higher level inferences about the target event than is possible with VideoLLMs alone, which fixate on low-level visual features. We benchmark state-of-the-art VideoLLMs and CAG in both oracle retrieval and RAG settings and find that CAG consistently outperforms alternative methods, while suggesting intriguing avenues for future work."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [WikiVideo: Article Generation from Multiple Videos](https://arxiv.org/abs/2504.00939)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'This paper introduces JavisDiT, a novel Joint Audio-Video Diffusion Transformer designed for synchronized audio-video generation (JAVG). Built upon the powerful Diffusion Transformer (DiT) architecture, JavisDiT is able to generate high-quality audio and video content simultaneously from open-ended user prompts. To ensure optimal synchronization, we introduce a fine-grained spatio-temporal alignment mechanism through a Hierarchical Spatial-Temporal Synchronized Prior (HiST-Sypo) Estimator. This module extracts both global and fine-grained spatio-temporal priors, guiding the synchronization between the visual and auditory components. Furthermore, we propose a new benchmark, JavisBench, consisting of 10,140 high-quality text-captioned sounding videos spanning diverse scenes and complex real-world scenarios. Further, we specifically devise a robust metric for evaluating the synchronization between generated audio-video pairs in real-world complex content. Experimental results demonstrate that JavisDiT significantly outperforms existing methods by ensuring both high-quality generation and precise synchronization, setting a new standard for JAVG tasks. Our code, model, and dataset will be made publicly available at https://javisdit.github.io/.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [JavisDiT: Joint Audio-Video Diffusion Transformer with Hierarchical Spatio-Temporal Prior Synchronization](https://arxiv.org/abs/2503.23377)
append_entries: 3
Finish: 2025-04-04 18:10:15.707417
------------------------------------------------------
Started: 2025-04-04 21:00:38.953652
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Unsupervised panoptic segmentation aims to partition an image into semantically meaningful regions and distinct object instances without training on manually annotated data. In contrast to prior work on unsupervised panoptic scene understanding, we eliminate the need for object-centric training data, enabling the unsupervised understanding of complex scenes. To that end, we present the first unsupervised panoptic method that directly trains on scene-centric imagery. In particular, we propose an approach to obtain high-resolution panoptic pseudo labels on complex scene-centric data, combining visual representations, depth, and motion cues. Utilizing both pseudo-label training and a panoptic self-training strategy yields a novel approach that accurately predicts panoptic segmentation of complex scenes without requiring any human annotations. Our approach significantly improves panoptic quality, e.g., surpassing the recent state of the art in unsupervised panoptic segmentation on Cityscapes by 9.4% points in PQ.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Scene-Centric Unsupervised Panoptic Segmentation](https://arxiv.org/abs/2504.01955)
append_entries: 1
Finish: 2025-04-04 21:00:39.706989
------------------------------------------------------
Started: 2025-04-05 00:36:25.697177
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-05 00:36:25.876910
------------------------------------------------------
Started: 2025-04-05 03:21:54.990439
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Since the advent of reasoning-based large language models, many have found great success from distilling reasoning capabilities into student models. Such techniques have significantly bridged the gap between reasoning and standard LLMs on coding tasks. Despite this, much of the progress on distilling reasoning models remains locked behind proprietary datasets or lacks details on data curation, filtering and subsequent training. To address this, we construct a superior supervised fine-tuning (SFT) dataset that we use to achieve state-of-the-art coding capability results in models of various sizes. Our distilled models use only SFT to achieve 61.8% on LiveCodeBench and 24.6% on CodeContests, surpassing alternatives trained with reinforcement learning. We then perform analysis on the data sources used to construct our dataset, the impact of code execution filtering, and the importance of instruction/solution diversity. We observe that execution filtering negatively affected benchmark accuracy, leading us to prioritize instruction diversity over solution correctness. Finally, we also analyze the token efficiency and reasoning patterns utilized by these models. We will open-source these datasets and distilled models to the community.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [OpenCodeReasoning: Advancing Data Distillation for Competitive Coding](https://arxiv.org/abs/2504.01943)
append_entries: 1
Finish: 2025-04-05 03:21:55.666316
------------------------------------------------------
Started: 2025-04-05 06:00:46.014530
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-05 06:00:46.236807
------------------------------------------------------
Started: 2025-04-05 09:00:32.644717
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-05 09:00:32.868462
------------------------------------------------------
Started: 2025-04-05 12:11:57.065145
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-05 12:11:57.441927
------------------------------------------------------
Started: 2025-04-05 15:00:35.479127
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-05 15:00:35.686013
------------------------------------------------------
Started: 2025-04-05 18:00:54.444595
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-05 18:00:54.679027
------------------------------------------------------
Started: 2025-04-05 21:00:50.351559
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-05 21:00:50.641358
------------------------------------------------------
Started: 2025-04-06 00:40:18.999937
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-06 00:40:19.186234
------------------------------------------------------
Started: 2025-04-06 03:26:37.546821
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-06 03:26:37.826662
------------------------------------------------------
Started: 2025-04-06 06:00:52.259424
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-06 06:00:52.454535
------------------------------------------------------
Started: 2025-04-06 09:00:49.133618
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-06 09:00:49.348230
------------------------------------------------------
Started: 2025-04-06 12:00:39.030697
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-06 12:00:39.382470
------------------------------------------------------
Started: 2025-04-06 15:00:30.338736
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-06 15:00:30.506516
------------------------------------------------------
Started: 2025-04-06 18:08:51.776843
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-06 18:08:51.983035
------------------------------------------------------
Started: 2025-04-06 21:00:46.863827
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-06 21:00:47.094376
------------------------------------------------------
Started: 2025-04-07 00:38:50.060512
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-07 00:38:50.290330
------------------------------------------------------
Started: 2025-04-07 03:27:59.597115
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-07 03:27:59.761357
------------------------------------------------------
Started: 2025-04-07 06:00:40.512337
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Existing MLLM benchmarks face significant challenges in evaluating Unified MLLMs (U-MLLMs) due to: 1) lack of standardized benchmarks for traditional tasks, leading to inconsistent comparisons; 2) absence of benchmarks for mixed-modality generation, which fails to assess multimodal reasoning capabilities. We present a comprehensive evaluation framework designed to systematically assess U-MLLMs. Our benchmark includes: Standardized Traditional Task Evaluation. We sample from 12 datasets, covering 10 tasks with 30 subtasks, ensuring consistent and fair comparisons across studies." 2. Unified Task Assessment. We introduce five novel tasks testing multimodal reasoning, including image editing, commonsense QA with image generation, and geometric reasoning. 3. Comprehensive Model Benchmarking. We evaluate 12 leading U-MLLMs, such as Janus-Pro, EMU3, VILA-U, and Gemini2-flash, alongside specialized understanding (e.g., Claude-3.5-Sonnet) and generation models (e.g., DALL-E-3). Our findings reveal substantial performance gaps in existing U-MLLMs, highlighting the need for more robust models capable of handling mixed-modality tasks effectively. The code and evaluation data can be found in https://mme-unify.github.io/.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [MME-Unify: A Comprehensive Benchmark for Unified Multimodal Understanding and Generation Models](https://arxiv.org/abs/2504.03641)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'In the interaction between agents and their environments, agents expand their capabilities by planning and executing actions. However, LLM-based agents face substantial challenges when deployed in novel environments or required to navigate unconventional action spaces. To empower agents to autonomously explore environments, optimize workflows, and enhance their understanding of actions, we propose SynWorld, a framework that allows agents to synthesize possible scenarios with multi-step action invocation within the action space and perform Monte Carlo Tree Search (MCTS) exploration to effectively refine their action knowledge in the current environment. Our experiments demonstrate that SynWorld is an effective and general approach to learning action knowledge in new environments. Code is available at https://github.com/zjunlp/SynWorld.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [SynWorld: Virtual Scenario Synthesis for Agentic Action Knowledge Refinement](https://arxiv.org/abs/2504.03561)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Large Language Models (LLMs) have achieved considerable performance across various agentic planning tasks. However, traditional agent planning approaches adopt a "flood irrigation" methodology that indiscriminately injects gold trajectories, external feedback, and domain knowledge into agent models. This practice overlooks the fundamental human cognitive principle of situational self-awareness during decision-making-the ability to dynamically assess situational demands and strategically employ resources during decision-making. We propose agentic knowledgeable self-awareness to address this gap, a novel paradigm enabling LLM-based agents to autonomously regulate knowledge utilization. Specifically, we propose KnowSelf, a data-centric approach that applies agents with knowledgeable self-awareness like humans. Concretely, we devise a heuristic situation judgement criterion to mark special tokens on the agent\'s self-explored trajectories for collecting training data. Through a two-stage training process, the agent model can switch between different situations by generating specific special tokens, achieving optimal planning effects with minimal costs. Our experiments demonstrate that KnowSelf can outperform various strong baselines on different tasks and models with minimal use of external knowledge. Code is available at https://github.com/zjunlp/KnowSelf.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Agentic Knowledgeable Self-awareness](https://arxiv.org/abs/2504.03553)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'In this work, we present VARGPT-v1.1, an advanced unified visual autoregressive model that builds upon our previous framework VARGPT. The model preserves the dual paradigm of next-token prediction for visual understanding and next-scale generation for image synthesis. Specifically, VARGPT-v1.1 integrates: (1) a novel training strategy combining iterative visual instruction tuning with reinforcement learning through Direct Preference Optimization (DPO), (2) an expanded training corpus containing 8.3M visual-generative instruction pairs, (3) an upgraded language model backbone using Qwen2, (4) enhanced image generation resolution, and (5) emergent image editing capabilities without architectural modifications. These advancements enable VARGPT-v1.1 to achieve state-of-the-art performance in multimodal understanding and text-to-image instruction-following tasks, demonstrating significant improvements in both comprehension and generation metrics. Notably, through visual instruction tuning, the model acquires image editing functionality while maintaining architectural consistency with its predecessor, revealing the potential for unified visual understanding, generation, and editing. Our findings suggest that well-designed unified visual autoregressive models can effectively adopt flexible training strategies from large language models (LLMs), exhibiting promising scalability. The codebase and model weights are publicly available at https://github.com/VARGPT-family/VARGPT-v1.1.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [VARGPT-v1.1: Improve Visual Autoregressive Large Unified Model via Iterative Instruction Tuning and Reinforcement Learning](https://arxiv.org/abs/2504.02949)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'The task of issue resolving is to modify a codebase to generate a patch that addresses a given issue. However, existing benchmarks, such as SWE-bench, focus almost exclusively on Python, making them insufficient for evaluating Large Language Models (LLMs) across diverse software ecosystems. To address this, we introduce a multilingual issue-resolving benchmark, called Multi-SWE-bench, covering Java, TypeScript, JavaScript, Go, Rust, C, and C++. It includes a total of 1,632 high-quality instances, which were carefully annotated from 2,456 candidates by 68 expert annotators, ensuring that the benchmark can provide an accurate and reliable evaluation. Based on Multi-SWE-bench, we evaluate a series of state-of-the-art models using three representative methods (Agentless, SWE-agent, and OpenHands) and present a comprehensive analysis with key empirical insights. In addition, we launch a Multi-SWE-RL open-source community, aimed at building large-scale reinforcement learning (RL) training datasets for issue-resolving tasks. As an initial contribution, we release a set of 4,723 well-structured instances spanning seven programming languages, laying a solid foundation for RL research in this domain. More importantly, we open-source our entire data production pipeline, along with detailed tutorials, encouraging the open-source community to continuously contribute and expand the dataset. We envision our Multi-SWE-bench and the ever-growing Multi-SWE-RL community as catalysts for advancing RL toward its full potential, bringing us one step closer to the dawn of AGI.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Multi-SWE-bench: A Multilingual Benchmark for Issue Resolving](https://arxiv.org/abs/2504.02605)
append_entries: 5
Finish: 2025-04-07 06:00:43.164623
------------------------------------------------------
Started: 2025-04-07 09:00:35.328018
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Training effective AI agents for multi-turn interactions requires high-quality data that captures realistic human-agent dynamics, yet such data is scarce and expensive to collect manually. We introduce APIGen-MT, a two-phase framework that generates verifiable and diverse multi-turn agent data. In the first phase, our agentic pipeline produces detailed task blueprints with ground-truth actions, leveraging a committee of LLM reviewers and iterative feedback loops. These blueprints are then transformed into complete interaction trajectories through simulated human-agent interplay. We train a family of models -- the xLAM-2-fc-r series with sizes ranging from 1B to 70B parameters. Our models outperform frontier models such as GPT-4o and Claude 3.5 on tau-bench and BFCL benchmarks, with the smaller models surpassing their larger counterparts, particularly in multi-turn settings, while maintaining superior consistency across multiple trials. Comprehensive experiments demonstrate that our verified blueprint-to-details approach yields high-quality training data, enabling the development of more reliable, efficient, and capable agents. We open-source both the synthetic data collected and the trained xLAM-2-fc-r models to advance research in AI agents. Models are available on HuggingFace at https://huggingface.co/collections/Salesforce/xlam-2-67ef5be12949d8dcdae354c4 and project website is https://apigen-mt.github.io'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [APIGen-MT: Agentic Pipeline for Multi-Turn Data Generation via Simulated Agent-Human Interplay](https://arxiv.org/abs/2504.03601)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Single-image human reconstruction is vital for digital human modeling applications but remains an extremely challenging task. Current approaches rely on generative models to synthesize multi-view images for subsequent 3D reconstruction and animation. However, directly generating multiple views from a single human image suffers from geometric inconsistencies, resulting in issues like fragmented or blurred limbs in the reconstructed models. To tackle these limitations, we introduce HumanDreamer-X, a novel framework that integrates multi-view human generation and reconstruction into a unified pipeline, which significantly enhances the geometric consistency and visual fidelity of the reconstructed 3D models. In this framework, 3D Gaussian Splatting serves as an explicit 3D representation to provide initial geometry and appearance priority. Building upon this foundation, HumanFixer is trained to restore 3DGS renderings, which guarantee photorealistic results. Furthermore, we delve into the inherent challenges associated with attention mechanisms in multi-view human generation, and propose an attention modulation strategy that effectively enhances geometric details identity consistency across multi-view. Experimental results demonstrate that our approach markedly improves generation and reconstruction PSNR quality metrics by 16.45% and 12.65%, respectively, achieving a PSNR of up to 25.62 dB, while also showing generalization capabilities on in-the-wild data and applicability to various human reconstruction backbone models.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [HumanDreamer-X: Photorealistic Single-image Human Avatars Reconstruction via Gaussian Restoration](https://arxiv.org/abs/2504.03536)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'This paper introduces Comprehensive Relighting, the first all-in-one approach that can both control and harmonize the lighting from an image or video of humans with arbitrary body parts from any scene. Building such a generalizable model is extremely challenging due to the lack of dataset, restricting existing image-based relighting models to a specific scenario (e.g., face or static human). To address this challenge, we repurpose a pre-trained diffusion model as a general image prior and jointly model the human relighting and background harmonization in the coarse-to-fine framework. To further enhance the temporal coherence of the relighting, we introduce an unsupervised temporal lighting model that learns the lighting cycle consistency from many real-world videos without any ground truth. In inference time, our temporal lighting module is combined with the diffusion models through the spatio-temporal feature blending algorithms without extra training; and we apply a new guided refinement as a post-processing to preserve the high-frequency details from the input image. In the experiments, Comprehensive Relighting shows a strong generalizability and lighting temporal coherence, outperforming existing image-based human relighting and harmonization methods.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Comprehensive Relighting: Generalizable and Consistent Monocular Human Relighting and Harmonization](https://arxiv.org/abs/2504.03011)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'When sound waves hit an object, they induce vibrations that produce high-frequency and subtle visual changes, which can be used for recovering the sound. Early studies always encounter trade-offs related to sampling rate, bandwidth, field of view, and the simplicity of the optical path. Recent advances in event camera hardware show good potential for its application in visual sound recovery, because of its superior ability in capturing high-frequency signals. However, existing event-based vibration recovery methods are still sub-optimal for sound recovery. In this work, we propose a novel pipeline for non-contact sound recovery, fully utilizing spatial-temporal information from the event stream. We first generate a large training set using a novel simulation pipeline. Then we designed a network that leverages the sparsity of events to capture spatial information and uses Mamba to model long-term temporal information. Lastly, we train a spatial aggregation block to aggregate information from different locations to further improve signal quality. To capture event signals caused by sound waves, we also designed an imaging system using a laser matrix to enhance the gradient and collected multiple data sequences for testing. Experimental results on synthetic and real-world data demonstrate the effectiveness of our method.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [EvMic: Event-based Non-contact sound recovery from effective spatial-temporal modeling](https://arxiv.org/abs/2504.02402)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'In this research, we introduce BEATS, a novel framework for evaluating Bias, Ethics, Fairness, and Factuality in Large Language Models (LLMs). Building upon the BEATS framework, we present a bias benchmark for LLMs that measure performance across 29 distinct metrics. These metrics span a broad range of characteristics, including demographic, cognitive, and social biases, as well as measures of ethical reasoning, group fairness, and factuality related misinformation risk. These metrics enable a quantitative assessment of the extent to which LLM generated responses may perpetuate societal prejudices that reinforce or expand systemic inequities. To achieve a high score on this benchmark a LLM must show very equitable behavior in their responses, making it a rigorous standard for responsible AI evaluation. Empirical results based on data from our experiment show that, 37.65\\% of outputs generated by industry leading models contained some form of bias, highlighting a substantial risk of using these models in critical decision making systems. BEATS framework and benchmark offer a scalable and statistically rigorous methodology to benchmark LLMs, diagnose factors driving biases, and develop mitigation strategies. With the BEATS framework, our goal is to help the development of more socially responsible and ethically aligned AI models.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [BEATS: Bias Evaluation and Assessment Test Suite for Large Language Models](https://arxiv.org/abs/2503.24310)
append_entries: 5
Finish: 2025-04-07 09:00:38.027016
------------------------------------------------------
Started: 2025-04-07 12:14:29.913562
Existing_entries: 1005
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Transformers are the cornerstone of modern large language models, but their quadratic computational complexity limits efficiency in long-sequence processing. Recent advancements in Mamba, a state space model (SSM) with linear complexity, offer promising efficiency gains but suffer from unstable contextual learning and multitask generalization. This paper proposes TransMamba, a novel framework that unifies Transformer and Mamba through shared parameter matrices (e.g., QKV and CBx), and thus could dynamically switch between attention and SSM mechanisms at different token lengths and layers. We design the Memory converter to bridge Transformer and Mamba by converting attention outputs into SSM-compatible states, ensuring seamless information flow at TransPoints where the transformation happens. The TransPoint scheduling is also thoroughly explored for further improvements. We conducted extensive experiments demonstrating that TransMamba achieves superior training efficiency and performance compared to baselines, and validated the deeper consistency between Transformer and Mamba paradigms, offering a scalable solution for next-generation sequence modeling.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [TransMamba: Flexibly Switching between Transformer and Mamba](https://arxiv.org/abs/2503.24067)
append_entries: 1
Finish: 2025-04-07 12:14:30.676679
------------------------------------------------------
Started: 2025-04-07 15:00:37.520485
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Medical image and video segmentation is a critical task for precision medicine, which has witnessed considerable progress in developing task or modality-specific and generalist models for 2D images. However, there have been limited studies on building general-purpose models for 3D images and videos with comprehensive user studies. Here, we present MedSAM2, a promptable segmentation foundation model for 3D image and video segmentation. The model is developed by fine-tuning the Segment Anything Model 2 on a large medical dataset with over 455,000 3D image-mask pairs and 76,000 frames, outperforming previous models across a wide range of organs, lesions, and imaging modalities. Furthermore, we implement a human-in-the-loop pipeline to facilitate the creation of large-scale datasets resulting in, to the best of our knowledge, the most extensive user study to date, involving the annotation of 5,000 CT lesions, 3,984 liver MRI lesions, and 251,550 echocardiogram video frames, demonstrating that MedSAM2 can reduce manual costs by more than 85%. MedSAM2 is also integrated into widely used platforms with user-friendly interfaces for local and cloud deployment, making it a practical tool for supporting efficient, scalable, and high-quality segmentation in both research and healthcare environments.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [MedSAM2: Segment Anything in 3D Medical Images and Videos](https://arxiv.org/abs/2504.03600)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Mathematical reasoning is a cornerstone of human intelligence and a key benchmark for advanced capabilities in large language models (LLMs). However, the research community still lacks an open, large-scale, high-quality corpus tailored to the demands of math-centric LLM pre-training. We present MegaMath, an open dataset curated from diverse, math-focused sources through following practices: (1) Revisiting web data: We re-extracted mathematical documents from Common Crawl with math-oriented HTML optimizations, fasttext-based filtering and deduplication, all for acquiring higher-quality data on the Internet. (2) Recalling Math-related code data: We identified high quality math-related code from large code training corpus, Stack-V2, further enhancing data diversity. (3) Exploring Synthetic data: We synthesized QA-style text, math-related code, and interleaved text-code blocks from web data or code data. By integrating these strategies and validating their effectiveness through extensive ablations, MegaMath delivers 371B tokens with the largest quantity and top quality among existing open math pre-training datasets.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [MegaMath: Pushing the Limits of Open Math Corpora](https://arxiv.org/abs/2504.02807)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Balancing temporal resolution and spatial detail under limited compute budget remains a key challenge for video-based multi-modal large language models (MLLMs). Existing methods typically compress video representations using predefined rules before feeding them into the LLM, resulting in irreversible information loss and often ignoring input instructions. To address this, we propose a novel slow-fast architecture that naturally circumvents this trade-off, enabling the use of more input frames while preserving spatial details. Inspired by how humans first skim a video before focusing on relevant parts, our slow-fast design employs a dual-token strategy: 1) "fast" visual tokens -- a compact set of compressed video features -- are fed into the LLM alongside text embeddings to provide a quick overview; 2) "slow" visual tokens -- uncompressed video features -- are cross-attended by text embeddings through specially designed hybrid decoder layers, enabling instruction-aware extraction of relevant visual details with linear complexity. We conduct systematic exploration to optimize both the overall architecture and key components. Experiments show that our model significantly outperforms self-attention-only baselines, extending the input capacity from 16 to 128 frames with just a 3% increase in computation, and achieving a 16% average performance improvement across five video understanding benchmarks. Our 7B model achieves state-of-the-art performance among models of similar size. Furthermore, our slow-fast architecture is a plug-and-play design that can be integrated into other video MLLMs to improve efficiency and scalability.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Slow-Fast Architecture for Video Multi-Modal Large Language Models](https://arxiv.org/abs/2504.01328)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Fine-tuning a pre-trained Text-to-Image (T2I) model on a tailored portrait dataset is the mainstream method for text-driven customization of portrait attributes. Due to Semantic Pollution during fine-tuning, existing methods struggle to maintain the original model's behavior and achieve incremental learning while customizing target attributes. To address this issue, we propose SPF-Portrait, a pioneering work to purely understand customized semantics while eliminating semantic pollution in text-driven portrait customization. In our SPF-Portrait, we propose a dual-path pipeline that introduces the original model as a reference for the conventional fine-tuning path. Through contrastive learning, we ensure adaptation to target attributes and purposefully align other unrelated attributes with the original portrait. We introduce a novel Semantic-Aware Fine Control Map, which represents the precise response regions of the target semantics, to spatially guide the alignment process between the contrastive paths. This alignment process not only effectively preserves the performance of the original model but also avoids over-alignment. Furthermore, we propose a novel response enhancement mechanism to reinforce the performance of target attributes, while mitigating representation discrepancy inherent in direct cross-modal supervision. Extensive experiments demonstrate that SPF-Portrait achieves state-of-the-art performance. Project webpage: https://spf-portrait.github.io/SPF-Portrait/"}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [SPF-Portrait: Towards Pure Portrait Customization with Semantic Pollution-Free Fine-tuning](https://arxiv.org/abs/2504.00396)
append_entries: 4
Finish: 2025-04-07 15:00:39.673364
------------------------------------------------------
Started: 2025-04-07 18:10:40.166084
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Recent advancements in behavior cloning have enabled robots to perform complex manipulation tasks. However, accurately assessing training performance remains challenging, particularly for real-world applications, as behavior cloning losses often correlate poorly with actual task success. Consequently, researchers resort to success rate metrics derived from costly and time-consuming real-world evaluations, making the identification of optimal policies and detection of overfitting or underfitting impractical. To address these issues, we propose real-is-sim, a novel behavior cloning framework that incorporates a dynamic digital twin (based on Embodied Gaussians) throughout the entire policy development pipeline: data collection, training, and deployment. By continuously aligning the simulated world with the physical world, demonstrations can be collected in the real world with states extracted from the simulator. The simulator enables flexible state representations by rendering image inputs from any viewpoint or extracting low-level state information from objects embodied within the scene. During training, policies can be directly evaluated within the simulator in an offline and highly parallelizable manner. Finally, during deployment, policies are run within the simulator where the real robot directly tracks the simulated robot's joints, effectively decoupling policy execution from real hardware and mitigating traditional domain-transfer challenges. We validate real-is-sim on the PushT manipulation task, demonstrating strong correlation between success rates obtained in the simulator and real-world evaluations. Videos of our system can be found at https://realissim.rai-inst.com."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Real-is-Sim: Bridging the Sim-to-Real Gap with a Dynamic Digital Twin for Real-World Robot Policy Evaluation](https://arxiv.org/abs/2504.03597)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'The accurate delineation of agricultural field boundaries from satellite imagery is vital for land management and crop monitoring. However, current methods face challenges due to limited dataset sizes, resolution discrepancies, and diverse environmental conditions. We address this by reformulating the task as instance segmentation and introducing the Field Boundary Instance Segmentation - 22M dataset (FBIS-22M), a large-scale, multi-resolution dataset comprising 672,909 high-resolution satellite image patches (ranging from 0.25 m to 10 m) and 22,926,427 instance masks of individual fields, significantly narrowing the gap between agricultural datasets and those in other computer vision domains. We further propose Delineate Anything, an instance segmentation model trained on our new FBIS-22M dataset. Our proposed model sets a new state-of-the-art, achieving a substantial improvement of 88.5% in mAP@0.5 and 103% in mAP@0.5:0.95 over existing methods, while also demonstrating significantly faster inference and strong zero-shot generalization across diverse image resolutions and unseen geographic regions. Code, pre-trained models, and the FBIS-22M dataset are available at https://lavreniuk.github.io/Delineate-Anything.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Delineate Anything: Resolution-Agnostic Field Boundary Delineation on Satellite Imagery](https://arxiv.org/abs/2504.02534)
append_entries: 2
Finish: 2025-04-07 18:10:41.476688
------------------------------------------------------
Started: 2025-04-07 21:00:43.487411
Existing_entries: 1002
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-07 21:00:43.697464
------------------------------------------------------
Started: 2025-04-08 00:37:08.580459
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Autonomous agents powered by foundation models have seen widespread adoption across various real-world applications. However, they remain highly vulnerable to malicious instructions and attacks, which can result in severe consequences such as privacy breaches and financial losses. More critically, existing guardrails for LLMs are not applicable due to the complex and dynamic nature of agents. To tackle these challenges, we propose ShieldAgent, the first guardrail agent designed to enforce explicit safety policy compliance for the action trajectory of other protected agents through logical reasoning. Specifically, ShieldAgent first constructs a safety policy model by extracting verifiable rules from policy documents and structuring them into a set of action-based probabilistic rule circuits. Given the action trajectory of the protected agent, ShieldAgent retrieves relevant rule circuits and generates a shielding plan, leveraging its comprehensive tool library and executable code for formal verification. In addition, given the lack of guardrail benchmarks for agents, we introduce ShieldAgent-Bench, a dataset with 3K safety-related pairs of agent instructions and action trajectories, collected via SOTA attacks across 6 web environments and 7 risk categories. Experiments show that ShieldAgent achieves SOTA on ShieldAgent-Bench and three existing benchmarks, outperforming prior methods by 11.3% on average with a high recall of 90.1%. Additionally, ShieldAgent reduces API queries by 64.7% and inference time by 58.2%, demonstrating its high precision and efficiency in safeguarding agents.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [ShieldAgent: Shielding Agents via Verifiable Safety Policy Reasoning](https://arxiv.org/abs/2503.22738)
append_entries: 1
Finish: 2025-04-08 00:37:09.385719
------------------------------------------------------
Started: 2025-04-08 03:24:40.095456
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-08 03:24:40.362981
------------------------------------------------------
Started: 2025-04-08 06:00:53.915760
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Region-level captioning aims to generate natural language descriptions for specific image regions while highlighting their distinguishing features. However, existing methods struggle to produce unique captions across multi-granularity, limiting their real-world applicability. To address the need for detailed region-level understanding, we introduce URECA dataset, a large-scale dataset tailored for multi-granularity region captioning. Unlike prior datasets that focus primarily on salient objects, URECA dataset ensures a unique and consistent mapping between regions and captions by incorporating a diverse set of objects, parts, and background elements. Central to this is a stage-wise data curation pipeline, where each stage incrementally refines region selection and caption generation. By leveraging Multimodal Large Language Models (MLLMs) at each stage, our pipeline produces distinctive and contextually grounded captions with improved accuracy and semantic diversity. Building upon this dataset, we present URECA, a novel captioning model designed to effectively encode multi-granularity regions. URECA maintains essential spatial properties such as position and shape through simple yet impactful modifications to existing MLLMs, enabling fine-grained and semantically rich region descriptions. Our approach introduces dynamic mask modeling and a high-resolution mask encoder to enhance caption uniqueness. Experiments show that URECA achieves state-of-the-art performance on URECA dataset and generalizes well to existing region-level captioning benchmarks.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [URECA: Unique Region Caption Anything](https://arxiv.org/abs/2504.05305)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Diffusion models approximate the denoising distribution as a Gaussian and predict its mean, whereas flow matching models reparameterize the Gaussian mean as flow velocity. However, they underperform in few-step sampling due to discretization error and tend to produce over-saturated colors under classifier-free guidance (CFG). To address these limitations, we propose a novel Gaussian mixture flow matching (GMFlow) model: instead of predicting the mean, GMFlow predicts dynamic Gaussian mixture (GM) parameters to capture a multi-modal flow velocity distribution, which can be learned with a KL divergence loss. We demonstrate that GMFlow generalizes previous diffusion and flow matching models where a single Gaussian is learned with an L_2 denoising loss. For inference, we derive GM-SDE/ODE solvers that leverage analytic denoising distributions and velocity fields for precise few-step sampling. Furthermore, we introduce a novel probabilistic guidance scheme that mitigates the over-saturation issues of CFG and improves image generation quality. Extensive experiments demonstrate that GMFlow consistently outperforms flow matching baselines in generation quality, achieving a Precision of 0.942 with only 6 sampling steps on ImageNet 256times256.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Gaussian Mixture Flow Matching Models](https://arxiv.org/abs/2504.05304)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Transformers today still struggle to generate one-minute videos because self-attention layers are inefficient for long context. Alternatives such as Mamba layers struggle with complex multi-scene stories because their hidden states are less expressive. We experiment with Test-Time Training (TTT) layers, whose hidden states themselves can be neural networks, therefore more expressive. Adding TTT layers into a pre-trained Transformer enables it to generate one-minute videos from text storyboards. For proof of concept, we curate a dataset based on Tom and Jerry cartoons. Compared to baselines such as Mamba~2, Gated DeltaNet, and sliding-window attention layers, TTT layers generate much more coherent videos that tell complex stories, leading by 34 Elo points in a human evaluation of 100 videos per method. Although promising, results still contain artifacts, likely due to the limited capability of the pre-trained 5B model. The efficiency of our implementation can also be improved. We have only experimented with one-minute videos due to resource constraints, but the approach can be extended to longer videos and more complex stories. Sample videos, code and annotations are available at: https://test-time-training.github.io/video-dit'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [One-Minute Video Generation with Test-Time Training](https://arxiv.org/abs/2504.05298)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Recent advancements in reasoning language models have demonstrated remarkable performance in complex tasks, but their extended chain-of-thought reasoning process increases inference overhead. While quantization has been widely adopted to reduce the inference cost of large language models, its impact on reasoning models remains understudied. In this study, we conduct the first systematic study on quantized reasoning models, evaluating the open-sourced DeepSeek-R1-Distilled Qwen and LLaMA families ranging from 1.5B to 70B parameters, and QwQ-32B. Our investigation covers weight, KV cache, and activation quantization using state-of-the-art algorithms at varying bit-widths, with extensive evaluation across mathematical (AIME, MATH-500), scientific (GPQA), and programming (LiveCodeBench) reasoning benchmarks. Our findings reveal that while lossless quantization can be achieved with W8A8 or W4A16 quantization, lower bit-widths introduce significant accuracy risks. We further identify model size, model origin, and task difficulty as critical determinants of performance. Contrary to expectations, quantized models do not exhibit increased output lengths. In addition, strategically scaling the model sizes or reasoning steps can effectively enhance the performance. All quantized models and codes will be open-sourced in https://github.com/ruikangliu/Quantized-Reasoning-Models.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Quantization Hurts Reasoning? An Empirical Study on Quantized Reasoning Models](https://arxiv.org/abs/2504.04823)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'The proliferation of Large Language Models (LLMs) accessed via black-box APIs introduces a significant trust challenge: users pay for services based on advertised model capabilities (e.g., size, performance), but providers may covertly substitute the specified model with a cheaper, lower-quality alternative to reduce operational costs. This lack of transparency undermines fairness, erodes trust, and complicates reliable benchmarking. Detecting such substitutions is difficult due to the black-box nature, typically limiting interaction to input-output queries. This paper formalizes the problem of model substitution detection in LLM APIs. We systematically evaluate existing verification techniques, including output-based statistical tests, benchmark evaluations, and log probability analysis, under various realistic attack scenarios like model quantization, randomized substitution, and benchmark evasion. Our findings reveal the limitations of methods relying solely on text outputs, especially against subtle or adaptive attacks. While log probability analysis offers stronger guarantees when available, its accessibility is often limited. We conclude by discussing the potential of hardware-based solutions like Trusted Execution Environments (TEEs) as a pathway towards provable model integrity, highlighting the trade-offs between security, performance, and provider adoption. Code is available at https://github.com/sunblaze-ucb/llm-api-audit'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Are You Getting What You Pay For? Auditing Model Substitution in LLM APIs](https://arxiv.org/abs/2504.04715)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Diffusion models are widely used for image editing tasks. Existing editing methods often design a representation manipulation procedure by curating an edit direction in the text embedding or score space. However, such a procedure faces a key challenge: overestimating the edit strength harms visual consistency while underestimating it fails the editing task. Notably, each source image may require a different editing strength, and it is costly to search for an appropriate strength via trial-and-error. To address this challenge, we propose Concept Lancet (CoLan), a zero-shot plug-and-play framework for principled representation manipulation in diffusion-based image editing. At inference time, we decompose the source input in the latent (text embedding or diffusion score) space as a sparse linear combination of the representations of the collected visual concepts. This allows us to accurately estimate the presence of concepts in each image, which informs the edit. Based on the editing task (replace/add/remove), we perform a customized concept transplant process to impose the corresponding editing direction. To sufficiently model the concept space, we curate a conceptual representation dataset, CoLan-150K, which contains diverse descriptions and scenarios of visual terms and phrases for the latent dictionary. Experiments on multiple diffusion-based image editing baselines show that methods equipped with CoLan achieve state-of-the-art performance in editing effectiveness and consistency preservation.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Concept Lancet: Image Editing with Compositional Representation Transplant](https://arxiv.org/abs/2504.02828)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Multimodal large language models (MLLMs) excel in vision-language tasks but also pose significant risks of generating harmful content, particularly through jailbreak attacks. Jailbreak attacks refer to intentional manipulations that bypass safety mechanisms in models, leading to the generation of inappropriate or unsafe content. Detecting such attacks is critical to ensuring the responsible deployment of MLLMs. Existing jailbreak detection methods face three primary challenges: (1) Many rely on model hidden states or gradients, limiting their applicability to white-box models, where the internal workings of the model are accessible; (2) They involve high computational overhead from uncertainty-based analysis, which limits real-time detection, and (3) They require fully labeled harmful datasets, which are often scarce in real-world settings. To address these issues, we introduce a test-time adaptive framework called JAILDAM. Our method leverages a memory-based approach guided by policy-driven unsafe knowledge representations, eliminating the need for explicit exposure to harmful data. By dynamically updating unsafe knowledge during test-time, our framework improves generalization to unseen jailbreak strategies while maintaining efficiency. Experiments on multiple VLM jailbreak benchmarks demonstrate that JAILDAM delivers state-of-the-art performance in harmful content detection, improving both accuracy and speed.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [JailDAM: Jailbreak Detection with Adaptive Memory for Vision-Language Model](https://arxiv.org/abs/2504.03770)
append_entries: 7
Finish: 2025-04-08 06:00:57.380831
------------------------------------------------------
Started: 2025-04-08 09:00:58.390017
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-08 09:00:58.607802
------------------------------------------------------
Started: 2025-04-08 12:00:38.535200
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Large Vision-Language Models (VLMs) deliver exceptional performance but require significant computational resources, limiting their deployment on mobile and edge devices. Smaller VLMs typically mirror design choices of larger models, such as extensive image tokenization, leading to inefficient GPU memory usage and constrained practicality for on-device applications.   We introduce SmolVLM, a series of compact multimodal models specifically engineered for resource-efficient inference. We systematically explore architectural configurations, tokenization strategies, and data curation optimized for low computational overhead. Through this, we identify key design choices that yield substantial performance gains on image and video tasks with minimal memory footprints.   Our smallest model, SmolVLM-256M, uses less than 1GB GPU memory during inference and outperforms the 300-times larger Idefics-80B model, despite an 18-month development gap. Our largest model, at 2.2B parameters, rivals state-of-the-art VLMs consuming twice the GPU memory. SmolVLM models extend beyond static images, demonstrating robust video comprehension capabilities.   Our results emphasize that strategic architectural optimizations, aggressive yet efficient tokenization, and carefully curated training data significantly enhance multimodal performance, facilitating practical, energy-efficient deployments at significantly smaller scales.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [SmolVLM: Redefining small and efficient multimodal models](https://arxiv.org/abs/2504.05299)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We introduce LiveVQA, an automatically collected dataset of latest visual knowledge from the Internet with synthesized VQA problems. LiveVQA consists of 3,602 single- and multi-hop visual questions from 6 news websites across 14 news categories, featuring high-quality image-text coherence and authentic information. Our evaluation across 15 MLLMs (e.g., GPT-4o, Gemma-3, and Qwen-2.5-VL family) demonstrates that stronger models perform better overall, with advanced visual reasoning capabilities proving crucial for complex multi-hop questions. Despite excellent performance on textual problems, models with tools like search engines still show significant gaps when addressing visual questions requiring latest visual knowledge, highlighting important areas for future research.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [LiveVQA: Live Visual Knowledge Seeking](https://arxiv.org/abs/2504.05288)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Recent studies have demonstrated that test-time compute scaling effectively improves the performance of small language models (sLMs). However, prior research has mainly examined test-time compute scaling with an additional larger model as a verifier, leaving self-verification by sLMs underexplored. In this work, we investigate whether sLMs can reliably self-verify their outputs under test-time scaling. We find that even with knowledge distillation from larger verifiers, sLMs struggle with verification tasks requiring memorization, such as numerical calculations and fact-checking. To address this limitation, we propose Tool-integrated self-verification (T1), which delegates memorization-heavy verification steps to external tools, such as a code interpreter. Our theoretical analysis shows that tool integration reduces memorization demands and improves test-time scaling performance. Experiments on the MATH benchmark demonstrate that, with T1, a Llama-3.2 1B model under test-time scaling outperforms the significantly larger Llama-3.1 8B model. Moreover, T1 generalizes effectively to both mathematical (MATH500) and multi-domain knowledge-intensive tasks (MMLU-Pro). Our findings highlight the potential of tool integration to substantially improve the self-verification abilities of sLMs.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [T1: Tool-integrated Self-verification for Test-time Compute Scaling in Small Language Models](https://arxiv.org/abs/2504.04718)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We introduce Clinical ModernBERT, a transformer based encoder pretrained on large scale biomedical literature, clinical notes, and medical ontologies, incorporating PubMed abstracts, MIMIC IV clinical data, and medical codes with their textual descriptions. Building on ModernBERT the current state of the art natural language text encoder featuring architectural upgrades such as rotary positional embeddings (RoPE), Flash Attention, and extended context length up to 8,192 tokens our model adapts these innovations specifically for biomedical and clinical domains. Clinical ModernBERT excels at producing semantically rich representations tailored for long context tasks. We validate this both by analyzing its pretrained weights and through empirical evaluation on a comprehensive suite of clinical NLP benchmarks.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Clinical ModernBERT: An efficient and long context encoder for biomedical text](https://arxiv.org/abs/2504.03964)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Vision Foundation Models (VFMs) and Vision-Language Models (VLMs) have gained traction in Domain Generalized Semantic Segmentation (DGSS) due to their strong generalization capabilities. However, existing DGSS methods often rely exclusively on either VFMs or VLMs, overlooking their complementary strengths. VFMs (e.g., DINOv2) excel at capturing fine-grained features, while VLMs (e.g., CLIP) provide robust text alignment but struggle with coarse granularity. Despite their complementary strengths, effectively integrating VFMs and VLMs with attention mechanisms is challenging, as the increased patch tokens complicate long-sequence modeling. To address this, we propose MFuser, a novel Mamba-based fusion framework that efficiently combines the strengths of VFMs and VLMs while maintaining linear scalability in sequence length. MFuser consists of two key components: MVFuser, which acts as a co-adapter to jointly fine-tune the two models by capturing both sequential and spatial dynamics; and MTEnhancer, a hybrid attention-Mamba module that refines text embeddings by incorporating image priors. Our approach achieves precise feature locality and strong text alignment without incurring significant computational overhead. Extensive experiments demonstrate that MFuser significantly outperforms state-of-the-art DGSS methods, achieving 68.20 mIoU on synthetic-to-real and 71.87 mIoU on real-to-real benchmarks. The code is available at https://github.com/devinxzhang/MFuser.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Mamba as a Bridge: Where Vision Foundation Models Meet Vision Language Models for Domain-Generalized Semantic Segmentation](https://arxiv.org/abs/2504.03193)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We present the evaluation methodology, datasets and results of the BOP Challenge 2024, the sixth in a series of public competitions organized to capture the state of the art in 6D object pose estimation and related tasks. In 2024, our goal was to transition BOP from lab-like setups to real-world scenarios. First, we introduced new model-free tasks, where no 3D object models are available and methods need to onboard objects just from provided reference videos. Second, we defined a new, more practical 6D object detection task where identities of objects visible in a test image are not provided as input. Third, we introduced new BOP-H3 datasets recorded with high-resolution sensors and AR/VR headsets, closely resembling real-world scenarios. BOP-H3 include 3D models and onboarding videos to support both model-based and model-free tasks. Participants competed on seven challenge tracks, each defined by a task, object onboarding setup, and dataset group. Notably, the best 2024 method for model-based 6D localization of unseen objects (FreeZeV2.1) achieves 22% higher accuracy on BOP-Classic-Core than the best 2023 method (GenFlow), and is only 4% behind the best 2023 method for seen objects (GPose2023) although being significantly slower (24.9 vs 2.7s per image). A more practical 2024 method for this task is Co-op which takes only 0.8s per image and is 25X faster and 13% more accurate than GenFlow. Methods have a similar ranking on 6D detection as on 6D localization but higher run time. On model-based 2D detection of unseen objects, the best 2024 method (MUSE) achieves 21% relative improvement compared to the best 2023 method (CNOS). However, the 2D detection accuracy for unseen objects is still noticealy (-53%) behind the accuracy for seen objects (GDet2023). The online evaluation system stays open and is available at http://bop.felk.cvut.cz/'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [BOP Challenge 2024 on Model-Based and Model-Free 6D Object Pose Estimation](https://arxiv.org/abs/2504.02812)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Tool-Augmented Larage Language Models (TA-LLMs) have shown promise in real-world applications, but face challenges in handling incomplete queries and out-of-scope requests. While existing approaches rely mainly on Supervised Fine-Tuning with expert trajectories, we propose DiaTool-DPO, a novel method that enhances TA-LLM's dialogue capabilities through Direct Preference Optimization. We model TA-LLM interactions as a Markov Decision Process with 5 distinct dialogue states and categorize user queries into 3 types based on their state transition trajectories. We automatically construct paired trajectory datasets of correct and incorrect dialogue flows and introduce a specialized objective loss for dialogue control. Our comprehensive evaluation demonstrates that DiaTool-DPO approaches GPT-4o's performance (94.8% in information gathering, 91% in tool call rejection) with substantial improvements over baseline (44% and 9.6% respectively) while maintaining core functionality. Our approach opens new possibilities for developing TA-LLMs that can handle diverse real-world scenarios without requiring additional expert demonstrations or human labeling."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [DiaTool-DPO: Multi-Turn Direct Preference Optimization for Tool-Augmented Large Language Models](https://arxiv.org/abs/2504.02882)
append_entries: 7
Finish: 2025-04-08 12:00:42.098417
------------------------------------------------------
Started: 2025-04-08 21:00:35.220321
Existing_entries: 1007
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We present VAPO, Value-based Augmented Proximal Policy Optimization framework for reasoning models., a novel framework tailored for reasoning models within the value-based paradigm. Benchmarked the AIME 2024 dataset, VAPO, built on the Qwen 32B pre-trained model, attains a state-of-the-art score of 60.4. In direct comparison under identical experimental settings, VAPO outperforms the previously reported results of DeepSeek-R1-Zero-Qwen-32B and DAPO by more than 10 points. The training process of VAPO stands out for its stability and efficiency. It reaches state-of-the-art performance within a mere 5,000 steps. Moreover, across multiple independent runs, no training crashes occur, underscoring its reliability. This research delves into long chain-of-thought (long-CoT) reasoning using a value-based reinforcement learning framework. We pinpoint three key challenges that plague value-based methods: value model bias, the presence of heterogeneous sequence lengths, and the sparsity of reward signals. Through systematic design, VAPO offers an integrated solution that effectively alleviates these challenges, enabling enhanced performance in long-CoT reasoning tasks.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [VAPO: Efficient and Reliable Reinforcement Learning for Advanced Reasoning Tasks](https://arxiv.org/abs/2504.05118)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Large language models (LLMs) are advancing at an unprecedented pace globally, with regions increasingly adopting these models for applications in their primary language. Evaluation of these models in diverse linguistic environments, especially in low-resource languages, has become a major challenge for academia and industry. Existing evaluation frameworks are disproportionately focused on English and a handful of high-resource languages, thereby overlooking the realistic performance of LLMs in multilingual and lower-resource scenarios. To address this gap, we introduce GlotEval, a lightweight framework designed for massively multilingual evaluation. Supporting seven key tasks (machine translation, text classification, summarization, open-ended generation, reading comprehension, sequence labeling, and intrinsic evaluation), spanning over dozens to hundreds of languages, GlotEval highlights consistent multilingual benchmarking, language-specific prompt templates, and non-English-centric machine translation. This enables a precise diagnosis of model strengths and weaknesses in diverse linguistic contexts. A multilingual translation case study demonstrates GlotEval's applicability for multilingual and language-specific evaluations."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [GlotEval: A Test Suite for Massively Multilingual Evaluation of Large Language Models](https://arxiv.org/abs/2504.04155)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Large Language Models (LLMs) exhibit significant disparities in performance across languages, primarily benefiting high-resource languages while marginalizing underrepresented ones. Continual Pretraining (CPT) has emerged as a promising approach to address this imbalance, although the relative effectiveness of monolingual, bilingual, and code-augmented data strategies remains unclear. This study systematically evaluates 36 CPT configurations involving three multilingual base models, across 30+ languages categorized as altruistic, selfish, and stagnant, spanning various resource levels. Our findings reveal three major insights: (1) Bilingual CPT improves multilingual classification but often causes language mixing issues during generation. (2) Including programming code data during CPT consistently enhances multilingual classification accuracy, particularly benefiting low-resource languages, but introduces a trade-off by slightly degrading generation quality. (3) Contrary to prior work, we observe substantial deviations from language classifications according to their impact on cross-lingual transfer: Languages classified as altruistic often negatively affect related languages, selfish languages show conditional and configuration-dependent behavior, and stagnant languages demonstrate surprising adaptability under certain CPT conditions. These nuanced interactions emphasize the complexity of multilingual representation learning, underscoring the importance of systematic studies on generalizable language classification to inform future multilingual CPT strategies.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Rethinking Multilingual Continual Pretraining: Data Mixing for Adapting LLMs Across Languages and Resources](https://arxiv.org/abs/2504.04152)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "A language model's ability to reflect on its own reasoning provides a key advantage for solving complex problems. While most recent research has focused on how this ability develops during reinforcement learning, we show that it actually begins to emerge much earlier - during the model's pre-training. To study this, we introduce deliberate errors into chains-of-thought and test whether the model can still arrive at the correct answer by recognizing and correcting these mistakes. By tracking performance across different stages of pre-training, we observe that this self-correcting ability appears early and improves steadily over time. For instance, an OLMo2-7B model pre-trained on 4 trillion tokens displays self-correction on our six self-reflection tasks."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Rethinking Reflection in Pre-Training](https://arxiv.org/abs/2504.04022)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Reasoning is central to human intelligence, enabling structured problem-solving across diverse tasks. Recent advances in large language models (LLMs) have greatly enhanced their reasoning abilities in arithmetic, commonsense, and symbolic domains. However, effectively extending these capabilities into multimodal contexts-where models must integrate both visual and textual inputs-continues to be a significant challenge. Multimodal reasoning introduces complexities, such as handling conflicting information across modalities, which require models to adopt advanced interpretative strategies. Addressing these challenges involves not only sophisticated algorithms but also robust methodologies for evaluating reasoning accuracy and coherence. This paper offers a concise yet insightful overview of reasoning techniques in both textual and multimodal LLMs. Through a thorough and up-to-date comparison, we clearly formulate core reasoning challenges and opportunities, highlighting practical methods for post-training optimization and test-time inference. Our work provides valuable insights and guidance, bridging theoretical frameworks and practical implementations, and sets clear directions for future research.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Why Reasoning Matters? A Survey of Advancements in Multimodal Reasoning (v1)](https://arxiv.org/abs/2504.03151)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Increasing test-time computation has emerged as a promising direction for improving language model performance, particularly in scenarios where model finetuning is impractical or impossible due to computational constraints or private model weights. However, existing test-time search methods using a reward model (RM) often degrade in quality as compute scales, due to the over-optimization of what are inherently imperfect reward proxies. We introduce QAlign, a new test-time alignment approach. As we scale test-time compute, QAlign converges to sampling from the optimal aligned distribution for each individual prompt. By adopting recent advances in Markov chain Monte Carlo for text generation, our method enables better-aligned outputs without modifying the underlying model or even requiring logit access. We demonstrate the effectiveness of QAlign on mathematical reasoning benchmarks (GSM8K and GSM-Symbolic) using a task-specific RM, showing consistent improvements over existing test-time compute methods like best-of-n and majority voting. Furthermore, when applied with more realistic RMs trained on the Tulu 3 preference dataset, QAlign outperforms direct preference optimization (DPO), best-of-n, majority voting, and weighted majority voting on a diverse range of datasets (GSM8K, MATH500, IFEval, MMLU-Redux, and TruthfulQA). A practical solution to aligning language models at test time using additional computation without degradation, our approach expands the limits of the capability that can be obtained from off-the-shelf language models without further training.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Sample, Don't Search: Rethinking Test-Time Alignment for Language Models](https://arxiv.org/abs/2504.03790)
append_entries: 6
Finish: 2025-04-08 21:00:37.761212
------------------------------------------------------
Started: 2025-04-09 00:37:28.274262
Existing_entries: 1006
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We present a novel approach for training small language models for reasoning-intensive document ranking that combines knowledge distillation with reinforcement learning optimization. While existing methods often rely on expensive human annotations or large black-box language models, our methodology leverages web data and a teacher LLM to automatically generate high-quality training examples with relevance explanations. By framing document ranking as a reinforcement learning problem and incentivizing explicit reasoning capabilities, we train a compact 3B parameter language model that achieves state-of-the-art performance on the BRIGHT benchmark. Our model ranks third on the leaderboard while using substantially fewer parameters than other approaches, outperforming models that are over 20 times larger. Through extensive experiments, we demonstrate that generating explanations during inference, rather than directly predicting relevance scores, enables more effective reasoning with smaller language models. The self-supervised nature of our method offers a scalable and interpretable solution for modern information retrieval systems.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Distillation and Refinement of Reasoning in Small Language Models for Document Re-ranking](https://arxiv.org/abs/2504.03947)
append_entries: 1
Finish: 2025-04-09 00:37:28.955994
------------------------------------------------------
Started: 2025-04-09 03:25:19.465915
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': '3D scene understanding from single images is a pivotal problem in computer vision with numerous downstream applications in graphics, augmented reality, and robotics. While diffusion-based modeling approaches have shown promise, they often struggle to maintain object and scene consistency, especially in complex real-world scenarios. To address these limitations, we propose an autoregressive generative approach called Local Random Access Sequence (LRAS) modeling, which uses local patch quantization and randomly ordered sequence generation. By utilizing optical flow as an intermediate representation for 3D scene editing, our experiments demonstrate that LRAS achieves state-of-the-art novel view synthesis and 3D object manipulation capabilities. Furthermore, we show that our framework naturally extends to self-supervised depth estimation through a simple modification of the sequence design. By achieving strong performance on multiple 3D scene understanding tasks, LRAS provides a unified and effective framework for building the next generation of 3D vision models.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [3D Scene Understanding Through Local Random Access Sequence Modeling](https://arxiv.org/abs/2504.03875)
append_entries: 1
Finish: 2025-04-09 03:25:20.019638
------------------------------------------------------
Started: 2025-04-09 06:11:36.424732
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-09 06:11:36.610027
------------------------------------------------------
Started: 2025-04-09 09:00:50.963965
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Scalable Vector Graphics (SVG) is an important image format widely adopted in graphic design because of their resolution independence and editability. The study of generating high-quality SVG has continuously drawn attention from both designers and researchers in the AIGC community. However, existing methods either produces unstructured outputs with huge computational cost or is limited to generating monochrome icons of over-simplified structures. To produce high-quality and complex SVG, we propose OmniSVG, a unified framework that leverages pre-trained Vision-Language Models (VLMs) for end-to-end multimodal SVG generation. By parameterizing SVG commands and coordinates into discrete tokens, OmniSVG decouples structural logic from low-level geometry for efficient training while maintaining the expressiveness of complex SVG structure. To further advance the development of SVG synthesis, we introduce MMSVG-2M, a multimodal dataset with two million richly annotated SVG assets, along with a standardized evaluation protocol for conditional SVG generation tasks. Extensive experiments show that OmniSVG outperforms existing methods and demonstrates its potential for integration into professional SVG design workflows.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [OmniSVG: A Unified Scalable Vector Graphics Generation Model](https://arxiv.org/abs/2504.06263)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Large Language Models (LLMs) have demonstrated the ability to tackle increasingly complex tasks through advanced reasoning, long-form content generation, and tool use. Solving these tasks often involves long inference-time computations. In human problem solving, a common strategy to expedite work is collaboration: by dividing the problem into sub-tasks, exploring different strategies concurrently, etc. Recent research has shown that LLMs can also operate in parallel by implementing explicit cooperation frameworks, such as voting mechanisms or the explicit creation of independent sub-tasks that can be executed in parallel. However, each of these frameworks may not be suitable for all types of tasks, which can hinder their applicability. In this work, we propose a different design approach: we run LLM "workers" in parallel , allowing them to synchronize via a concurrently-updated attention cache and prompt these workers to decide how best to collaborate. Our approach allows the instances to come up with their own collaboration strategy for the problem at hand, all the while "seeing" each other\'s partial progress in the concurrent cache. We implement this approach via Hogwild! Inference: a parallel LLM inference engine where multiple instances of the same LLM run in parallel with the same attention cache, with "instant" access to each other\'s generated tokens. Hogwild! inference takes advantage of Rotary Position Embeddings (RoPE) to avoid recomputation while improving parallel hardware utilization. We find that modern reasoning-capable LLMs can perform inference with shared Key-Value cache out of the box, without additional fine-tuning.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Hogwild! Inference: Parallel LLM Generation via Concurrent Attention](https://arxiv.org/abs/2504.06261)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "The landscape of image generation has rapidly evolved, from early GAN-based approaches to diffusion models and, most recently, to unified generative architectures that seek to bridge understanding and generation tasks. Recent advances, especially the GPT-4o, have demonstrated the feasibility of high-fidelity multimodal generation, their architectural design remains mysterious and unpublished. This prompts the question of whether image and text generation have already been successfully integrated into a unified framework for those methods. In this work, we conduct an empirical study of GPT-4o's image generation capabilities, benchmarking it against leading open-source and commercial models. Our evaluation covers four main categories, including text-to-image, image-to-image, image-to-3D, and image-to-X generation, with more than 20 tasks. Our analysis highlights the strengths and limitations of GPT-4o under various settings, and situates it within the broader evolution of generative modeling. Through this investigation, we identify promising directions for future unified generative models, emphasizing the role of architectural design and data scaling."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [An Empirical Study of GPT-4o Image Generation Capabilities](https://arxiv.org/abs/2504.05979)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We introduce Skywork R1V, a multimodal reasoning model extending the an R1-series Large language models (LLM) to visual modalities via an efficient multimodal transfer method. Leveraging a lightweight visual projector, Skywork R1V facilitates seamless multimodal adaptation without necessitating retraining of either the foundational language model or the vision encoder. To strengthen visual-text alignment, we propose a hybrid optimization strategy that combines Iterative Supervised Fine-Tuning (SFT) with Group Relative Policy Optimization (GRPO), significantly enhancing cross-modal integration efficiency. Additionally, we introduce an adaptive-length Chain-of-Thought distillation approach for reasoning data generation. This approach dynamically optimizes reasoning chain lengths, thereby enhancing inference efficiency and preventing excessive reasoning overthinking. Empirical evaluations demonstrate that Skywork R1V, with only 38B parameters, delivers competitive performance, achieving a score of 69.0 on the MMMU benchmark and 67.5 on MathVista. Meanwhile, it maintains robust textual reasoning performance, evidenced by impressive scores of 72.0 on AIME and 94.0 on MATH500. The Skywork R1V model weights have been publicly released to promote openness and reproducibility.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Skywork R1V: Pioneering Multimodal Reasoning with Chain-of-Thought](https://arxiv.org/abs/2504.05599)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Balancing fidelity and editability is essential in text-based image editing (TIE), where failures commonly lead to over- or under-editing issues. Existing methods typically rely on attention injections for structure preservation and leverage the inherent text alignment capabilities of pre-trained text-to-image (T2I) models for editability, but they lack explicit and unified mechanisms to properly balance these two objectives. In this work, we introduce UnifyEdit, a tuning-free method that performs diffusion latent optimization to enable a balanced integration of fidelity and editability within a unified framework. Unlike direct attention injections, we develop two attention-based constraints: a self-attention (SA) preservation constraint for structural fidelity, and a cross-attention (CA) alignment constraint to enhance text alignment for improved editability. However, simultaneously applying both constraints can lead to gradient conflicts, where the dominance of one constraint results in over- or under-editing. To address this challenge, we introduce an adaptive time-step scheduler that dynamically adjusts the influence of these constraints, guiding the diffusion latent toward an optimal balance. Extensive quantitative and qualitative experiments validate the effectiveness of our approach, demonstrating its superiority in achieving a robust balance between structure preservation and text alignment across various editing tasks, outperforming other state-of-the-art methods. The source code will be available at https://github.com/CUC-MIPG/UnifyEdit.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Tuning-Free Image Editing with Fidelity and Editability via Unified Latent Diffusion Model](https://arxiv.org/abs/2504.05594)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "With powerful large language models (LLMs) demonstrating superhuman reasoning capabilities, a critical question arises: Do LLMs genuinely reason, or do they merely recall answers from their extensive, web-scraped training datasets? Publicly released benchmarks inevitably become contaminated once incorporated into subsequent LLM training sets, undermining their reliability as faithful assessments. To address this, we introduce KUMO, a generative evaluation framework designed specifically for assessing reasoning in LLMs. KUMO synergistically combines LLMs with symbolic engines to dynamically produce diverse, multi-turn reasoning tasks that are partially observable and adjustable in difficulty. Through an automated pipeline, KUMO continuously generates novel tasks across open-ended domains, compelling models to demonstrate genuine generalization rather than memorization. We evaluated 23 state-of-the-art LLMs on 5,000 tasks across 100 domains created by KUMO, benchmarking their reasoning abilities against university students. Our findings reveal that many LLMs have outperformed university-level performance on easy reasoning tasks, and reasoning-scaled LLMs reach university-level performance on complex reasoning challenges. Moreover, LLM performance on KUMO tasks correlates strongly with results on newly released real-world reasoning benchmarks, underscoring KUMO's value as a robust, enduring assessment tool for genuine LLM reasoning capabilities."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Generative Evaluation of Complex Reasoning in Large Language Models](https://arxiv.org/abs/2504.02810)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Although subject-driven generation has been extensively explored in image generation due to its wide applications, it still has challenges in data scalability and subject expansibility. For the first challenge, moving from curating single-subject datasets to multiple-subject ones and scaling them is particularly difficult. For the second, most recent methods center on single-subject generation, making it hard to apply when dealing with multi-subject scenarios. In this study, we propose a highly-consistent data synthesis pipeline to tackle this challenge. This pipeline harnesses the intrinsic in-context generation capabilities of diffusion transformers and generates high-consistency multi-subject paired data. Additionally, we introduce UNO, which consists of progressive cross-modal alignment and universal rotary position embedding. It is a multi-image conditioned subject-to-image model iteratively trained from a text-to-image model. Extensive experiments show that our method can achieve high consistency while ensuring controllability in both single-subject and multi-subject driven generation.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Less-to-More Generalization: Unlocking More Controllability by In-Context Generation](https://arxiv.org/abs/2504.02160)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Existing reasoning evaluation frameworks for Large Language Models (LLMs) and Large Vision-Language Models (LVLMs) predominantly either assess text-based reasoning or vision-language understanding capabilities, with limited dynamic interplay between textual and visual constraints. To address this limitation, we introduce CrossWordBench, a benchmark designed to evaluate the reasoning capabilities of both LLMs and LVLMs through the medium of crossword puzzles-a task requiring multimodal adherence to semantic constraints from text-based clues and intersectional constraints from visual grid structures. CrossWordBench leverages a controllable puzzle generation framework that produces puzzles in multiple formats (text and image) and offers different evaluation strategies ranging from direct puzzle solving to interactive modes. Our extensive evaluation of over 20 models reveals that reasoning LLMs outperform non-reasoning models substantially by effectively leveraging crossing-letter constraints. We further demonstrate that LVLMs struggle with the task, showing a strong correlation between their puzzle-solving performance and grid-parsing accuracy. Our findings offer insights into the limitations of the reasoning capabilities of current LLMs and LVLMs, and provide an effective approach for creating multimodal constrained tasks for future evaluations.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [CrossWordBench: Evaluating the Reasoning Capabilities of LLMs and LVLMs with Controllable Puzzle Generation](https://arxiv.org/abs/2504.00043)
append_entries: 8
Finish: 2025-04-09 09:00:54.220862
------------------------------------------------------
Started: 2025-04-09 12:13:48.099561
Existing_entries: 1008
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Text-to-image (T2I) diffusion/flow models have drawn considerable attention recently due to their remarkable ability to deliver flexible visual creations. Still, high-resolution image synthesis presents formidable challenges due to the scarcity and complexity of high-resolution content. To this end, we present HiFlow, a training-free and model-agnostic framework to unlock the resolution potential of pre-trained flow models. Specifically, HiFlow establishes a virtual reference flow within the high-resolution space that effectively captures the characteristics of low-resolution flow information, offering guidance for high-resolution generation through three key aspects: initialization alignment for low-frequency consistency, direction alignment for structure preservation, and acceleration alignment for detail fidelity. By leveraging this flow-aligned guidance, HiFlow substantially elevates the quality of high-resolution image synthesis of T2I models and demonstrates versatility across their personalized variants. Extensive experiments validate HiFlow's superiority in achieving superior high-resolution image quality over current state-of-the-art methods."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [HiFlow: Training-free High-Resolution Image Generation with Flow-Aligned Guidance](https://arxiv.org/abs/2504.06232)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Recent advancements in Multimodal Large Language Models (MLLMs) have led to significant improvements across various multimodal benchmarks. However, as evaluations shift from static datasets to open-world, dynamic environments, current game-based benchmarks remain inadequate because they lack visual-centric tasks and fail to assess the diverse reasoning skills required for real-world decision-making. To address this, we introduce Visual-centric Multiple Abilities Game Evaluation (V-MAGE), a game-based evaluation framework designed to assess visual reasoning capabilities of MLLMs. V-MAGE features five diverse games with 30+ handcrafted levels, testing models on core visual skills such as positioning, trajectory tracking, timing, and visual memory, alongside higher-level reasoning like long-term planning and deliberation. We use V-MAGE to evaluate leading MLLMs, revealing significant challenges in their visual perception and reasoning. In all game environments, the top-performing MLLMs, as determined by Elo rating comparisons, exhibit a substantial performance gap compared to humans. Our findings highlight critical limitations, including various types of perceptual errors made by the models, and suggest potential avenues for improvement from an agent-centric perspective, such as refining agent strategies and addressing perceptual inaccuracies. Code is available at https://github.com/CSU-JPG/V-MAGE.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [V-MAGE: A Game Evaluation Framework for Assessing Visual-Centric Capabilities in Multimodal Large Language Models](https://arxiv.org/abs/2504.06148)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Aligning large language models (LLMs) with human preferences has achieved remarkable success. However, existing Chinese preference datasets are limited by small scale, narrow domain coverage, and lack of rigorous data validation. Additionally, the reliance on human annotators for instruction and response labeling significantly constrains the scalability of human preference datasets. To address these challenges, we design an LLM-based Chinese preference dataset annotation pipeline with no human intervention. Specifically, we crawled and carefully filtered 92k high-quality Chinese queries and employed 15 mainstream LLMs to generate and score chosen-rejected response pairs. Based on it, we introduce COIG-P (Chinese Open Instruction Generalist - Preference), a high-quality, large-scale Chinese preference dataset, comprises 1,009k Chinese preference pairs spanning 6 diverse domains: Chat, Code, Math, Logic, Novel, and Role. Building upon COIG-P, to reduce the overhead of using LLMs for scoring, we trained a 8B-sized Chinese Reward Model (CRM) and meticulously constructed a Chinese Reward Benchmark (CRBench). Evaluation results based on AlignBench liu2024alignbenchbenchmarkingchinesealignment show that that COIG-P significantly outperforms other Chinese preference datasets, and it brings significant performance improvements ranging from 2% to 12% for the Qwen2/2.5 and Infinity-Instruct-3M-0625 model series, respectively. The results on CRBench demonstrate that our CRM has a strong and robust scoring ability. We apply it to filter chosen-rejected response pairs in a test split of COIG-P, and our experiments show that it is comparable to GPT-4o in identifying low-quality samples while maintaining efficiency and cost-effectiveness. Our codes and data are released in https://github.com/multimodal-art-projection/COIG-P.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [COIG-P: A High-Quality and Large-Scale Chinese Preference Dataset for Alignment with Human Values](https://arxiv.org/abs/2504.05535)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Recent advances in reasoning models have demonstrated significant improvements in accuracy, particularly for complex tasks such as mathematical reasoning, by employing detailed and comprehensive reasoning processes. However, generating these lengthy reasoning sequences is computationally expensive and time-consuming. To address this inefficiency, we leverage the inherent parallelizability of certain tasks to accelerate the reasoning process. Specifically, when multiple parallel reasoning branches exist, we decode multiple tokens per step using a specialized attention mask, processing them within a single sequence, avoiding additional memory usage. Experimental results show that our method achieves over 100% speedup in decoding time while maintaining the answer quality.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Accelerate Parallelizable Reasoning via Parallel Decoding within One Sequence](https://arxiv.org/abs/2503.20533)
append_entries: 4
Finish: 2025-04-09 12:13:50.618174
------------------------------------------------------
Started: 2025-04-09 15:01:16.919240
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-09 15:01:17.128291
------------------------------------------------------
Started: 2025-04-09 18:11:01.716518
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Recent advances in automated theorem proving (ATP) through LLMs have highlighted the potential of formal reasoning with Lean 4 codes. However, ATP has not yet be revolutionized by the recent posttraining scaling as demonstrated by Open AI O1/O3 and Deepseek R1. In this work, we investigate the entire posttraining of ATP, aiming to align it with breakthroughs in reasoning models in natural languages.To begin, we continual train current ATP models with a hybrid dataset, which consists of numerous statement-proof pairs, and additional data aimed at incorporating cognitive behaviors that emulate human reasoning and hypothesis refinement. Next, we explore reinforcement learning with the use of outcome reward returned by Lean 4 compiler. Through our designed continual training and reinforcement learning processes, we have successfully improved existing formal provers, including both DeepSeek-Prover-v1.5 and Goedel-Prover, achieving state-of-the-art performance in the field of whole-proof generation. For example, we achieve a 59.8% pass rate (pass@32) on MiniF2F. This is an on-going project and we will progressively update our findings, release our data and training details.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Leanabell-Prover: Posttraining Scaling in Formal Reasoning](https://arxiv.org/abs/2504.06122)
append_entries: 1
Finish: 2025-04-09 18:11:02.436421
------------------------------------------------------
Started: 2025-04-09 21:00:34.527164
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'The Mixture of Experts (MoE) architecture has demonstrated significant advantages as it enables to increase the model capacity without a proportional increase in computation. However, the large MoE model size still introduces substantial memory demands, which usually requires expert offloading on resource-constrained platforms and incurs significant overhead. Hybrid CPU-GPU inference has been proposed to leverage CPU computation to reduce expert loading overhead but faces major challenges: on one hand, the expert activation patterns of MoE models are highly unstable, rendering the fixed mapping strategies in existing works inefficient; on the other hand, the hybrid CPU-GPU schedule for MoE is inherently complex due to the diverse expert sizes, structures, uneven workload distribution, etc. To address these challenges, in this paper, we propose HybriMoE, a hybrid CPU-GPU inference framework that improves resource utilization through a novel CPU-GPU scheduling and cache management system. HybriMoE introduces (i) a dynamic intra-layer scheduling strategy to balance workloads across CPU and GPU, (ii) an impact-driven inter-layer prefetching algorithm, and (iii) a score-based caching algorithm to mitigate expert activation instability. We implement HybriMoE on top of the kTransformers framework and evaluate it on three widely used MoE-based LLMs. Experimental results demonstrate that HybriMoE achieves an average speedup of 1.33times in the prefill stage and 1.70times in the decode stage compared to state-of-the-art hybrid MoE inference framework. Our code is available at: https://github.com/PKU-SEC-Lab/HybriMoE.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [HybriMoE: Hybrid CPU-GPU Scheduling and Cache Management for Efficient MoE Inference](https://arxiv.org/abs/2504.05897)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Reinforcement finetuning (RFT) has shown great potential for enhancing the mathematical reasoning capabilities of large language models (LLMs), but it is often sample- and compute-inefficient, requiring extensive training. In this work, we introduce AdaRFT (Adaptive Curriculum Reinforcement Finetuning), a method that significantly improves both the efficiency and final accuracy of RFT through adaptive curriculum learning. AdaRFT dynamically adjusts the difficulty of training problems based on the model's recent reward signals, ensuring that the model consistently trains on tasks that are challenging but solvable. This adaptive sampling strategy accelerates learning by maintaining an optimal difficulty range, avoiding wasted computation on problems that are too easy or too hard. AdaRFT requires only a lightweight extension to standard RFT algorithms like Proximal Policy Optimization (PPO), without modifying the reward function or model architecture. Experiments on competition-level math datasets-including AMC, AIME, and IMO-style problems-demonstrate that AdaRFT significantly improves both training efficiency and reasoning performance. We evaluate AdaRFT across multiple data distributions and model sizes, showing that it reduces the number of training steps by up to 2x and improves accuracy by a considerable margin, offering a more scalable and effective RFT framework."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Efficient Reinforcement Finetuning via Adaptive Curriculum Learning](https://arxiv.org/abs/2504.05520)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Generalized category discovery (GCD) is a pragmatic but underexplored problem, which requires models to automatically cluster and discover novel categories by leveraging the labeled samples from old classes. The challenge is that unlabeled data contain both old and new classes. Early works leveraging pseudo-labeling with parametric classifiers handle old and new classes separately, which brings about imbalanced accuracy between them. Recent methods employing contrastive learning neglect potential positives and are decoupled from the clustering objective, leading to biased representations and sub-optimal results. To address these issues, we introduce a unified and unbiased prototype learning framework, namely ProtoGCD, wherein old and new classes are modeled with joint prototypes and unified learning objectives, {enabling unified modeling between old and new classes}. Specifically, we propose a dual-level adaptive pseudo-labeling mechanism to mitigate confirmation bias, together with two regularization terms to collectively help learn more suitable representations for GCD. Moreover, for practical considerations, we devise a criterion to estimate the number of new classes. Furthermore, we extend ProtoGCD to detect unseen outliers, achieving task-level unification. Comprehensive experiments show that ProtoGCD achieves state-of-the-art performance on both generic and fine-grained datasets. The code is available at https://github.com/mashijie1028/ProtoGCD.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [ProtoGCD: Unified and Unbiased Prototype Learning for Generalized Category Discovery](https://arxiv.org/abs/2504.03755)
append_entries: 3
Finish: 2025-04-09 21:00:36.090386
------------------------------------------------------
Started: 2025-04-10 00:37:15.122967
Existing_entries: 1003
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-10 00:37:15.403780
------------------------------------------------------
Started: 2025-04-10 03:25:44.698861
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
append_entries: 0
Finish: 2025-04-10 03:26:04.666102
------------------------------------------------------
Started: 2025-04-10 06:11:27.003331
Existing_entries: 1000
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Diffusion transformers have demonstrated remarkable generation quality, albeit requiring longer training iterations and numerous inference steps. In each denoising step, diffusion transformers encode the noisy inputs to extract the lower-frequency semantic component and then decode the higher frequency with identical modules. This scheme creates an inherent optimization dilemma: encoding low-frequency semantics necessitates reducing high-frequency components, creating tension between semantic encoding and high-frequency decoding. To resolve this challenge, we propose a new \\color{ddtD}ecoupled \\color{ddtD}iffusion \\color{ddtT}ransformer~(\\color{ddtDDT}), with a decoupled design of a dedicated condition encoder for semantic extraction alongside a specialized velocity decoder. Our experiments reveal that a more substantial encoder yields performance improvements as model size increases. For ImageNet 256times256, Our DDT-XL/2 achieves a new state-of-the-art performance of {1.31 FID}~(nearly 4times faster training convergence compared to previous diffusion transformers). For ImageNet 512times512, Our DDT-XL/2 achieves a new state-of-the-art FID of 1.28. Additionally, as a beneficial by-product, our decoupled architecture enhances inference speed by enabling the sharing self-condition between adjacent denoising steps. To minimize performance degradation, we propose a novel statistical dynamic programming approach to identify optimal sharing strategies.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [DDT: Decoupled Diffusion Transformer](https://arxiv.org/abs/2504.05741)
append_entries: 1
Finish: 2025-04-10 06:11:27.801978
------------------------------------------------------
Started: 2025-04-10 09:00:35.370528
Existing_entries: 1001
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We present OLMoTrace, the first system that traces the outputs of language models back to their full, multi-trillion-token training data in real time. OLMoTrace finds and shows verbatim matches between segments of language model output and documents in the training text corpora. Powered by an extended version of infini-gram (Liu et al., 2024), our system returns tracing results within a few seconds. OLMoTrace can help users understand the behavior of language models through the lens of their training data. We showcase how it can be used to explore fact checking, hallucination, and the creativity of language models. OLMoTrace is publicly available and fully open-source.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [OLMoTrace: Tracing Language Model Outputs Back to Trillions of Training Tokens](https://arxiv.org/abs/2504.07096)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Camera trajectory design plays a crucial role in video production, serving as a fundamental tool for conveying directorial intent and enhancing visual storytelling. In cinematography, Directors of Photography meticulously craft camera movements to achieve expressive and intentional framing. However, existing methods for camera trajectory generation remain limited: Traditional approaches rely on geometric optimization or handcrafted procedural systems, while recent learning-based methods often inherit structural biases or lack textual alignment, constraining creative synthesis. In this work, we introduce an auto-regressive model inspired by the expertise of Directors of Photography to generate artistic and expressive camera trajectories. We first introduce DataDoP, a large-scale multi-modal dataset containing 29K real-world shots with free-moving camera trajectories, depth maps, and detailed captions in specific movements, interaction with the scene, and directorial intent. Thanks to the comprehensive and diverse database, we further train an auto-regressive, decoder-only Transformer for high-quality, context-aware camera movement generation based on text guidance and RGBD inputs, named GenDoP. Extensive experiments demonstrate that compared to existing methods, GenDoP offers better controllability, finer-grained trajectory adjustments, and higher motion stability. We believe our approach establishes a new standard for learning-based cinematography, paving the way for future advancements in camera control and filmmaking. Our project website: https://kszpxxzmc.github.io/GenDoP/.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [GenDoP: Auto-regressive Camera Trajectory Generation as a Director of Photography](https://arxiv.org/abs/2504.07083)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "We find that the response length of reasoning LLMs, whether trained by reinforcement learning or supervised learning, drastically increases for ill-posed questions with missing premises (MiP), ending up with redundant and ineffective thinking. This newly introduced scenario exacerbates the general overthinking issue to a large extent, which we name as the MiP-Overthinking. Such failures are against the ``test-time scaling law'' but have been widely observed on multiple datasets we curated with MiP, indicating the harm of cheap overthinking and a lack of critical thinking. Surprisingly, LLMs not specifically trained for reasoning exhibit much better performance on the MiP scenario, producing much shorter responses that quickly identify ill-posed queries. This implies a critical flaw of the current training recipe for reasoning LLMs, which does not encourage efficient thinking adequately, leading to the abuse of thinking patterns. To further investigate the reasons behind such failures, we conduct fine-grained analyses of the reasoning length, overthinking patterns, and location of critical thinking on different types of LLMs. Moreover, our extended ablation study reveals that the overthinking is contagious through the distillation of reasoning models' responses. These results improve the understanding of overthinking and shed novel insights into mitigating the problem."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [Missing Premise exacerbates Overthinking: Are Reasoning Models losing Critical Thinking Skill?](https://arxiv.org/abs/2504.06514)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Creating a realistic animatable avatar from a single static portrait remains challenging. Existing approaches often struggle to capture subtle facial expressions, the associated global body movements, and the dynamic background. To address these limitations, we propose a novel framework that leverages a pretrained video diffusion transformer model to generate high-fidelity, coherent talking portraits with controllable motion dynamics. At the core of our work is a dual-stage audio-visual alignment strategy. In the first stage, we employ a clip-level training scheme to establish coherent global motion by aligning audio-driven dynamics across the entire scene, including the reference portrait, contextual objects, and background. In the second stage, we refine lip movements at the frame level using a lip-tracing mask, ensuring precise synchronization with audio signals. To preserve identity without compromising motion flexibility, we replace the commonly used reference network with a facial-focused cross-attention module that effectively maintains facial consistency throughout the video. Furthermore, we integrate a motion intensity modulation module that explicitly controls expression and body motion intensity, enabling controllable manipulation of portrait movements beyond mere lip motion. Extensive experimental results show that our proposed approach achieves higher quality with better realism, coherence, motion intensity, and identity preservation. Ours project page: https://fantasy-amap.github.io/fantasy-talking/.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [FantasyTalking: Realistic Talking Portrait Generation via Coherent Motion Synthesis](https://arxiv.org/abs/2504.04842)
append_entries: 4
Finish: 2025-04-10 09:00:37.158957
------------------------------------------------------
Started: 2025-04-10 12:00:42.980906
Existing_entries: 1004
Fetching from https://rsshub.app/huggingface/daily-papers
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'We propose OmniCaptioner, a versatile visual captioning framework for generating fine-grained textual descriptions across a wide variety of visual domains. Unlike prior methods limited to specific image types (e.g., natural images or geometric visuals), our framework provides a unified solution for captioning natural images, visual text (e.g., posters, UIs, textbooks), and structured visuals (e.g., documents, tables, charts). By converting low-level pixel information into semantically rich textual representations, our framework bridges the gap between visual and textual modalities. Our results highlight three key advantages: (i) Enhanced Visual Reasoning with LLMs, where long-context captions of visual modalities empower LLMs, particularly the DeepSeek-R1 series, to reason effectively in multimodal scenarios; (ii) Improved Image Generation, where detailed captions improve tasks like text-to-image generation and image transformation; and (iii) Efficient Supervised Fine-Tuning (SFT), which enables faster convergence with less data. We believe the versatility and adaptability of OmniCaptioner can offer a new perspective for bridging the gap between language and visual modalities.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [OmniCaptioner: One Captioner to Rule Them All](https://arxiv.org/abs/2504.07089)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Reasoning has emerged as the next major frontier for language models (LMs), with rapid advances from both academic and industrial labs. However, this progress often outpaces methodological rigor, with many evaluations relying on benchmarking practices that lack transparency, robustness, or statistical grounding. In this work, we conduct a comprehensive empirical study and find that current mathematical reasoning benchmarks are highly sensitive to subtle implementation choices - including decoding parameters, random seeds, prompt formatting, and even hardware and software-framework configurations. Performance gains reported in recent studies frequently hinge on unclear comparisons or unreported sources of variance. To address these issues, we propose a standardized evaluation framework with clearly defined best practices and reporting standards. Using this framework, we reassess recent methods and find that reinforcement learning (RL) approaches yield only modest improvements - far below prior claims - and are prone to overfitting, especially on small-scale benchmarks like AIME24. In contrast, supervised finetuning (SFT) methods show consistently stronger generalization. To foster reproducibility, we release all code, prompts, and model outputs, for reasoning benchmarks, establishing more rigorous foundations for future work.'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [A Sober Look at Progress in Language Model Reasoning: Pitfalls and Paths to Reproducibility](https://arxiv.org/abs/2504.07086)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Robust grasping of various objects from single-view perception is fundamental for dexterous robots. Previous works often rely on fully observable objects, expert demonstrations, or static grasping poses, which restrict their generalization ability and adaptability to external disturbances. In this paper, we present a reinforcement-learning-based framework that enables zero-shot dynamic dexterous grasping of a wide range of unseen objects from single-view perception, while performing adaptive motions to external disturbances. We utilize a hand-centric object representation for shape feature extraction that emphasizes interaction-relevant local shapes, enhancing robustness to shape variance and uncertainty. To enable effective hand adaptation to disturbances with limited observations, we propose a mixed curriculum learning strategy, which first utilizes imitation learning to distill a policy trained with privileged real-time visual-tactile feedback, and gradually transfers to reinforcement learning to learn adaptive motions under disturbances caused by observation noises and dynamic randomization. Our experiments demonstrate strong generalization in grasping unseen objects with random poses, achieving success rates of 97.0% across 247,786 simulated objects and 94.6% across 512 real objects. We also demonstrate the robustness of our method to various disturbances, including unobserved object movement and external forces, through both quantitative and qualitative evaluations. Project Page: https://zdchan.github.io/Robust_DexGrasp/'}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [RobustDexGrasp: Robust Dexterous Grasping of General Objects from Single-view Perception](https://arxiv.org/abs/2504.05287)
Unexpected error happened when requesting. Prompt:
[{'role': 'system', 'content': "你是一位顶尖的中文摘要专家，擅长从各种语种的文章中提取核心信息，并生成精准、凝练的中文摘要。你的任务是为给定的文章生成一个合适的标题，3个关键词，以及两段不同长度的摘要。请严格遵循以下要求：\n\n### 任务要求：\n\n1. **使用中文**：生成中文标题和摘要。\n2. **生成标题**：为文章生成一个简洁、准确的标题，概括文章的主题和主旨。\n3. **提取关键词**：从文章中提取3个能够概括文章主要内容的关键词。\n4. **生成两段摘要**：\n   - **简短摘要**：用一句话总结文章主旨，不超过40个字，适合快速预览。\n   - **详细摘要**：用不超过300个字的段落来更全面地概括文章的内容和关键信息，保持条理清晰。\n5. **输出格式**：结果必须按照 JSON 格式输出，确保每个字段都准确填写。以 JSON 格式输出以下信息: 'title', 'short_summary' , 'summary', 'keyword'。输出内容请使用 ``` ``` 包围。\n6. **识别广告**：如果这是一篇营销广告或促销活动，则 'keyword' 设置为 'ADs'。\n\n### 工作流程（链式思维）：\n\n请遵循以下步骤来生成准确的摘要和标题：\n\n1. **阅读与理解**：\n   - 仔细阅读文章，识别文章的主题和主要内容。\n   - 记录文章的主要观点、关键信息以及结论。\n\n2. **生成标题**：\n   - 基于文章主题和内容，生成一个简洁、准确的标题。\n   - 确保标题能概括文章的核心主旨。\n\n3. **提取关键词**：\n   - 选择3个能够概括文章内容的关键词，确保它们能代表文章的主要信息和主题。\n\n4. **生成简短摘要**：\n   - 提炼文章的核心信息，用一句话总结，不超过40个字。\n   - 确保简短摘要适合快速预览，能让读者迅速理解文章主旨。\n\n5. **生成详细摘要**：\n   - 在不超过300字的范围内，全面概括文章内容，包括关键论点、重要数据或结论。\n   - 避免包含无关或次要信息，确保摘要简洁有力。\n\n6. **检查与调整**：\n   - 再次检查标题、关键词和摘要，确保它们与原文内容一致。\n   - 确保输出为准确的 JSON 格式，无任何拼写或格式错误。\n\n### 避免以下行为（What Not To Do）：\n\n- **不要生成幻觉**：切勿加入原文中未提及的内容，任何额外的推测或信息都是禁止的。\n- **不要随意翻译专有名词**：对于专业术语，应保留其原有专有名词或通用术语，而不是直白翻译。\n- **不要生成模糊或冗长的摘要**：简短摘要必须简洁明了，详细摘要必须在300字内。\n"}, {'role': 'user', 'content': [{'type': 'text', 'text': "Generating naturalistic and nuanced listener motions for extended interactions remains an open problem. Existing methods often rely on low-dimensional motion codes for facial behavior generation followed by photorealistic rendering, limiting both visual fidelity and expressive richness. To address these challenges, we introduce DiTaiListener, powered by a video diffusion model with multimodal conditions. Our approach first generates short segments of listener responses conditioned on the speaker's speech and facial motions with DiTaiListener-Gen. It then refines the transitional frames via DiTaiListener-Edit for a seamless transition. Specifically, DiTaiListener-Gen adapts a Diffusion Transformer (DiT) for the task of listener head portrait generation by introducing a Causal Temporal Multimodal Adapter (CTM-Adapter) to process speakers' auditory and visual cues. CTM-Adapter integrates speakers' input in a causal manner into the video generation process to ensure temporally coherent listener responses. For long-form video generation, we introduce DiTaiListener-Edit, a transition refinement video-to-video diffusion model. The model fuses video segments into smooth and continuous videos, ensuring temporal consistency in facial expressions and image quality when merging short video segments produced by DiTaiListener-Gen. Quantitatively, DiTaiListener achieves the state-of-the-art performance on benchmark datasets in both photorealism (+73.8% in FID on RealTalk) and motion representation (+6.1% in FD metric on VICO) spaces. User studies confirm the superior performance of DiTaiListener, with the model being the clear preference in terms of feedback, diversity, and smoothness, outperforming competitors by a significant margin."}]}]Summarization failed, append the original article
error: Error code: 401 - {'code': 402, 'msg': 'api_key余额不足', 'data': None}. Line: 406.
Append: [DiTaiListener: Controllable High Fidelity Listener Video Generation with Diffusion](https://arxiv.org/abs/2504.04010)
append_entries: 4
Finish: 2025-04-10 12:00:44.673149
